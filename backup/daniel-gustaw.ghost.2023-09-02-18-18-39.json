{
  "db": [
    {
      "meta": {
        "exported_on": 1693678719407,
        "version": "5.42.0"
      },
      "data": {
        "benefits": [],
        "custom_theme_settings": [],
        "newsletters": [
          {
            "id": "640b49df34d6052b1eeb85ec",
            "name": "Daniel Gustaw",
            "description": "Blog Programisty",
            "slug": "default-newsletter",
            "sender_email": null,
            "sender_reply_to": "newsletter",
            "status": "active",
            "visibility": "members",
            "subscribe_on_signup": 1,
            "sort_order": 0,
            "header_image": null,
            "show_header_icon": 1,
            "show_header_title": 1,
            "title_font_category": "sans_serif",
            "title_alignment": "center",
            "show_feature_image": 1,
            "body_font_category": "sans_serif",
            "footer_content": "",
            "show_badge": 1,
            "sender_name": null,
            "created_at": "2023-03-10T15:16:47.000Z",
            "updated_at": null,
            "show_header_name": 0,
            "uuid": "7d1114e4-acb0-4d0b-8d39-273b14be42d1",
            "feedback_enabled": 0,
            "show_post_title_section": 1,
            "show_comment_cta": 1,
            "show_subscription_details": 0,
            "show_latest_posts": 0,
            "background_color": "light",
            "border_color": null,
            "title_color": null
          }
        ],
        "offer_redemptions": [],
        "offers": [],
        "posts": [
          {
            "id": "601940361446cd10bd8d9dae",
            "uuid": "09491af3-22bd-476a-8404-6bfb69d90c97",
            "title": "Strukturyzacja danych na przykładzie kursu CHF NBP",
            "slug": "strukturyzacja-historycznych-kursow-walut-nbp",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-16-19-13-56.png\",\"width\":564,\"height\":358,\"caption\":\"https://stooq.com/q/?s=chfpln&amp;c=mx&amp;t=l&amp;a=ln&amp;b=0\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-16-19-16-59.png\",\"cardWidth\":\"\",\"caption\":\"https://stooq.com/q/d/l/?s=chfpln&amp;i=d\"}],[\"hr\",{}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-02-13-13-17-1.png\",\"width\":614,\"height\":583,\"cardWidth\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-02-14-16-42.png\",\"width\":1434,\"height\":408,\"cardWidth\":\"full\"}],[\"code\",{\"code\":\"[...document.querySelectorAll('.normal_2 a')]\\n    .map(a => `wget ${a.href}`)\\n    .filter(link => /archiwum_tab/.test(link))\\n    .join(' && ')\",\"language\":\"js\"}],[\"code\",{\"code\":\"wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2020.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2021.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2010.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2011.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2012.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2013.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2014.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2015.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2016.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2017.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2018.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2019.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2000.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2001.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2002.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2003.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2004.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2005.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2006.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2007.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2008.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2009.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1990.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1991.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1992.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1993.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1994.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1995.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1996.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1997.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1998.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1999.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1984.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1985.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1986.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1987.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1988.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1989.xls\",\"language\":\"bash\"}],[\"code\",{\"code\":\"for i in *.xls; do  libreoffice --headless --convert-to csv \\\"$i\\\" ; done                                                     \",\"language\":\"bash\"}],[\"code\",{\"code\":\"tsc --init\\nnpm init -y\\nnpm install chai\\nnpm i --save-dev @types/node @types/chai\\ntouch app.ts\",\"language\":\"bash\"}],[\"code\",{\"code\":\"// declarations\\nimports ...\\n\\nconstants ...\\n\\nfunctions ...\\n\\nmain function\\n\\n// execution\\nconsole.log(main())\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"import fs from 'fs'\\nimport chai from 'chai'\\n\\nconst main = () => {\\n    const rawDir = process.cwd() + `/raw`\\n\\n    const res = fs.readdirSync(rawDir).filter(f => f.endsWith('csv'));\\n    res.forEach(r => chai.expect(r).to.be.a('string'))\\n\\n    return res;\\n}\\n\\nconsole.dir(main(), {depth: Infinity, maxArrayLength: Infinity})\",\"language\":\"ts\"}],[\"code\",{\"code\":\" ts-node app.ts\",\"language\":\"bash\"}],[\"code\",{\"code\":\"[\\n  'archiwum_tab_a_1984.csv',\\n  'archiwum_tab_a_1985.csv',\\n...\",\"language\":\"json\"}],[\"code\",{\"code\":\"import fs from 'fs'\\nimport chai from 'chai'\\n\\n+ const FILES_FILTER = (e: string, i: number) => i <= 0\\n\\nconst main = () => {\\n  const rawDir = process.cwd() + `/raw`\\n\\n  const res = fs.readdirSync(rawDir).filter(f => f.endsWith('csv'))\\n+    .filter(FILES_FILTER)\\n+    .map((name, i) => {\\n+      return fs\\n+        .readFileSync(`${rawDir}/${name}`)\\n+        .toString()\\n+    })\\n  res.forEach(r => chai.expect(r).to.be.a('string'))\\n  return res;\\n}\\n\\nconsole.dir(main(), {depth: Infinity, maxArrayLength: Infinity})\",\"language\":\"diff\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-03-23-41-05.png\",\"width\":1918,\"height\":145,\"cardWidth\":\"full\"}],[\"code\",{\"code\":\"const dict: { [key: string]: string } = {\\n  'Szwajcaria': 'CHF'\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"interface YearData {\\n  [key: string]: {\\n    col: number,\\n    div: number,\\n    values: { [key: string]: number }[]\\n  }\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"return fs.readFileSync(`${rawDir}/${name}`).toString()\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const arr = fs\\n  .readFileSync(`${rawDir}/${name}`)\\n  .toString()\\n  .split(`\\\\n`)\\n  .map(l => l.split(','));\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const decomposeBaseSettingsFromNames = (localArr: string[]) => localArr.reduce((p: YearData, n: string, i: number): YearData => {\\n  if (Object.keys(dict).includes(n)) {\\n    p[dict[n]] = { col: i, div: 1, values: [] }\\n  }\\n  return p\\n}, {})\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const head = arr.shift()\\nif (!head) throw Error('File do not have header line.')\\nlet settings: YearData = decomposeBaseSettingsFromNames(head)\",\"language\":\"ts\"}],[\"code\",{\"code\":\"if (Object.keys(settings).length) {\\n  const subHead = arr.shift()\\n  if (!subHead) throw Error('File do not have sub-header line.')\\n  Object.keys(settings).forEach(key => {\\n    settings[key].div = parseInt(subHead[settings[key].col])\\n  })\\n}\\n\\nreturn settings;\",\"language\":\"ts\"}],[\"code\",{\"code\":\"res.forEach(r => {\\n        chai.expect(r).to.haveOwnProperty('CHF');\\n        chai.expect(r.CHF).to.haveOwnProperty('col');\\n        chai.expect(r.CHF).to.haveOwnProperty('div');\\n        chai.expect(r.CHF).to.haveOwnProperty('values');\\n        chai.expect(r.CHF.col).to.be.a('number');\\n        chai.expect(r.CHF.div).to.be.a('number');\\n        chai.expect(r.CHF.values).to.be.a('array');\\n    })\"}],[\"code\",{\"code\":\"[ { CHF: { col: 25, div: 1, values: [] } } ]\",\"language\":\"json\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/blob/ccd18f1f1f96ad13fad8157101f7632c4c1df73b/app.ts\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/blob/ccd18f1f1f96ad13fad8157101f7632c4c1df73b/app.ts\",\"title\":\"app.ts · ccd18f1f1f96ad13fad8157101f7632c4c1df73b · gustawdaniel / nbp\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"code\",{\"code\":\"const getDate = (input: string) => {\\n  if (/\\\\d{2}\\\\.\\\\d{2}\\\\.\\\\d{4}/.test(input)) {\\n    return input.split('.').reverse().join('-')\\n  }\\n  return false\\n}\\n\",\"language\":\"ts\"}],[\"code\",{\"code\":\"arr.forEach(localArr => {\\n  const date = getDate(localArr[0])\\n  if (typeof date === 'string') {\\n    Object.keys(settings).forEach(key => {\\n      settings[key].values.push({ [date]: parseFloat(localArr[settings[key].col]) / settings[key].div })\\n    })\\n  }\\n})\",\"language\":\"ts\"}],[\"code\",{\"code\":\"[\\n  {\\n    CHF: {\\n      col: 28,\\n      div: 1,\\n      values: [\\n        { '1984-01-02': 140.84 },\\n        { '1984-01-09': 140.08 },\\n        { '1984-01-16': 138.62 },\\n...\",\"language\":\"json\"}],[\"code\",{\"code\":\"    res.forEach(r => {\\n        chai.expect(r).to.haveOwnProperty('CHF');\\n        chai.expect(r.CHF).to.haveOwnProperty('col');\\n        chai.expect(r.CHF).to.haveOwnProperty('div');\\n        chai.expect(r.CHF).to.haveOwnProperty('values');\\n        chai.expect(r.CHF.col).to.be.a('number');\\n        chai.expect(r.CHF.div).to.be.a('number');\\n        chai.expect(r.CHF.values).to.be.a('array');\\n        r.CHF.values.forEach(v => {\\n            chai.expect(Object.keys(v)[0]).to.be.a('string');\\n            chai.expect(/\\\\d{4}-\\\\d{2}-\\\\d{2}/.test(Object.keys(v)[0])).to.be.true;\\n            chai.expect(Object.values(v)[0]).to.be.a('number');\\n            chai.expect(Object.values(v)[0]).to.be.greaterThan(0);\\n        })\\n    })\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/blob/9d401a925bc9e115dfaf9efe6528484f62cf2263/app.ts\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/blob/9d401a925bc9e115dfaf9efe6528484f62cf2263/app.ts\",\"title\":\"app.ts · 9d401a925bc9e115dfaf9efe6528484f62cf2263 · gustawdaniel / nbp\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"code\",{\"code\":\"const FILES_FILTER = (e: string, i: number) => i === 5\",\"language\":\"ts\"}],[\"code\",{\"code\":\"[ { CHF: { col: 27, div: 1, values: [] } } ]\",\"language\":\"json\"}],[\"code\",{\"code\":\".split(`\\\\n`)\",\"language\":\"ts\"}],[\"code\",{\"code\":\".filter(ROWS_FILTER)\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const ROWS_FILTER = (e: string, i: number) => i <= 4\\n\",\"language\":\"ts\"}],[\"code\",{\"code\":\"console.table(arr.map(l => l.filter((e,i) => i < 5 || Math.abs(i - 30) < 4)));\\n\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-00-43-43.png\",\"width\":1276,\"height\":162,\"cardWidth\":\"full\",\"caption\":\"\"}],[\"code\",{\"code\":\"if (/\\\\d{2}\\\\/\\\\d{2}\\\\/\\\\d{4}/.test(input)) {\\n  const [m, d, y] = input.split('/')\\n  return [y, m, d].join('-')\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const DROP_SPACES = (l: string): string => l.replace(/\\\\s+/g, '')\",\"language\":\"ts\"}],[\"code\",{\"code\":\".split(`\\\\n`)\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const testYearData = (r:YearData):void => {\\n    chai.expect(r).to.haveOwnProperty('CHF');\\n    chai.expect(r.CHF).to.haveOwnProperty('col');\\n    chai.expect(r.CHF).to.haveOwnProperty('div');\\n    chai.expect(r.CHF).to.haveOwnProperty('values');\\n    chai.expect(r.CHF.col).to.be.a('number');\\n    chai.expect(r.CHF.div).to.be.a('number');\\n    chai.expect(r.CHF.values).to.be.a('array');\\n    chai.expect(r.CHF.values.length).to.be.greaterThan(0);\\n    r.CHF.values.forEach(v => {\\n        chai.expect(Object.keys(v)[0]).to.be.a('string');\\n        chai.expect(/\\\\d{4}-\\\\d{2}-\\\\d{2}/.test(Object.keys(v)[0])).to.be.true;\\n        chai.expect(Object.values(v)[0]).to.be.a('number');\\n        chai.expect(Object.values(v)[0]).to.be.greaterThan(0);\\n    })\\n};\",\"language\":\"ts\"}],[\"code\",{\"code\":\"testYearData(settings);\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const FILES_FILTER = (e: string, i: number) => i < Infinity\\nconst ROWS_FILTER = (e: string, i: number) => i <= Infinity\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-12-17-50.png\",\"width\":352,\"height\":48}],[\"code\",{\"code\":\"console.table(arr.map(l => l.filter((e,i) => i < 3 || Math.abs(i - 27) < 5)));\",\"language\":\"ts\"}],[\"code\",{\"code\":\"console.dir(settings, {depth: Infinity});\\n\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-12-19-38.png\",\"width\":1463,\"height\":201,\"cardWidth\":\"full\"}],[\"code\",{\"code\":\"const DROP_EMPTY_LINES = (e:string) => !/^,*$/.test(e)\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const arr = fs\\n  .readFileSync(`${rawDir}/${name}`)\\n  .toString()\\n  .split(`\\\\n`)\\n  .map(DROP_SPACES)\\n  .filter(DROP_EMPTY_LINES)\\n  .filter(ROWS_FILTER)\\n  .map(l => l.split(',')\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-03-49-20.png\",\"width\":480,\"height\":143}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-03-52-11.png\",\"width\":337,\"height\":67}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-04-05-50.png\",\"width\":981,\"height\":263}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/blob/845527b631054744329b53293bfbf6705956b361/app.ts\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/blob/845527b631054744329b53293bfbf6705956b361/app.ts\",\"title\":\"app.ts · 845527b631054744329b53293bfbf6705956b361 · gustawdaniel / nbp\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"code\",{\"code\":\"[\\n  {\\n    CHF: {\\n      col: 27,\\n      div: NaN,\\n      values: [ { '1988-12-27': NaN }, { '1989-01-02': NaN } ]\\n    }\\n  }\\n]\",\"language\":\"json\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-01-02-13.png\",\"width\":329,\"height\":127}],[\"code\",{\"code\":\"const DROP_JUNK_LINES = (l: string): string => l.replace(/(Nr)|(data)|(WALUTA\\\\/CURRENCY)|(\\\\.tab)/ig, '')\\n\",\"language\":\"ts\"}],[\"code\",{\"code\":\"     .split(`\\\\n`)\\n     .map(DROP_SPACES)\\n+    .map(DROP_JUNK_LINES)\\n     .filter(DROP_EMPTY_LINES)\\n     .filter(ROWS_FILTER)\\n\",\"language\":\"diff\"}],[\"code\",{\"code\":\"[\\n  {\\n    CHF: {\\n      col: 30,\\n      div: 1,\\n      values: [\\n        { '1988-12-27': 910.9 },\\n        { '1989-01-02': 904.29 },\\n        { '1989-01-09': 915.44 }\\n...\",\"language\":\"json\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/commit/fd13a96ceb1effe2471445a1e954600fb51c56af\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/commit/fd13a96ceb1effe2471445a1e954600fb51c56af\",\"title\":\"Dropped junk lines (fd13a96c) · Commits · gustawdaniel / nbp\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"code\",{\"code\":\"[ {} ]\",\"language\":\"json\"}],[\"code\",{\"code\":\"console.table(arr.map(e => e.filter((e,i) => i < 10)));\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-01-16-10.png\",\"width\":811,\"height\":119}],[\"code\",{\"code\":\"if (Object.keys(settings).length) {\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const decomposeBaseSettingsFromCodes = (localArr: string[]) => localArr.reduce((p: YearData, n: string, i: number): YearData => {\\n  const [, div, curr] = n.match(/^(\\\\d+)(\\\\w+)$/) || []\\n  if (parseInt(div) && curr && Object.values(dict).includes(curr)) {\\n    p[curr] = { col: i, div: parseInt(div), values: [] }\\n  }\\n  return p\\n}, {})\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const head = arr.shift()\\nif (!head) throw Error('File do not have header line.')\\nlet settings: YearData = decomposeBaseSettingsFromNames(head)\\nif (Object.keys(settings).length) {\\n  const subHead = arr.shift()\\n  if (!subHead) throw Error('File do not have sub-header line.')\\n  Object.keys(settings).forEach(key => {\\n    settings[key].div = parseInt(subHead[settings[key].col])\\n  })\\n} else {\\n  settings = decomposeBaseSettingsFromCodes(head)\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const getDateFromArr = (arr: string[]) => {\\n  return getDate(arr[0]) || getDate(arr[1])\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"arr.forEach(localArr => {\\n-  const date = getDate(localArr[0])\\n+  const date = getDateFromArr(localArr)\\n  if (typeof date === 'string') {\\n    Object.keys(settings).forEach(key => {\\n      settings[key].values.push({ [date]: parseFloat(localArr[settings[key].col]) / settings[key].div })\\n    })\\n  }\\n})\",\"language\":\"diff\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/commit/81db32a6bb6d1b25569680a1605961d6efa8b190\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/commit/81db32a6bb6d1b25569680a1605961d6efa8b190\",\"title\":\"Fixed decoding codes and column with indexes (81db32a6) · Commits · gustawdaniel / nbp\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-10-20-49.png\",\"width\":1516,\"height\":159,\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-10-40-20.png\",\"width\":607,\"height\":738}],[\"code\",{\"code\":\"const extendSettingsByDivCoefficient = (arr: string[][], settings: YearData) => {\\n  const subHead = arr.shift()\\n  if (!subHead) throw Error('File do not have sub-header line.')\\n  Object.keys(settings).forEach(key => {\\n    settings[key].div = parseInt(subHead[settings[key].col])\\n  })\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const recognizeSettingsFromHead = (arr: string[][]):YearData => {\\n  const head = arr.shift()\\n  if (!head) throw Error('File do not have header line.')\\n  let settings: YearData = decomposeBaseSettingsFromNames(head)\\n  if (Object.keys(settings).length) {\\n    extendSettingsByDivCoefficient(arr, settings);\\n  } else {\\n    settings = decomposeBaseSettingsFromCodes(head);\\n    while (Object.keys(settings).some(key => Number.isNaN(settings[key].div))) {\\n      extendSettingsByDivCoefficient(arr, settings);\\n    }\\n  }\\n  \\n  return settings;\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const settings = recognizeSettingsFromHead(arr);\"}],[\"code\",{\"code\":\"Number.isNaN(settings[key].div)\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-11-01-30.png\",\"width\":1914,\"height\":262,\"cardWidth\":\"full\"}],[\"code\",{\"code\":\"const decomposeBaseSettingsFromNames = (localArr: string[]) => localArr.reduce((p: YearData, n: string, i: number): YearData => {\\n    if (Object.keys(dict).includes(n)) {\\n        p[dict[n]] = { col: i, div: NaN, values: [] }\\n    }\\n    return p\\n}, {})\\n\\nconst decomposeBaseSettingsFromCodes = (localArr: string[]) => localArr.reduce((p: YearData, n: string, i: number): YearData => {\\n    const [, div, curr] = n.match(/^(\\\\d*)(\\\\w+)$/) || []\\n    if (curr && Object.values(dict).includes(curr)) {\\n        p[curr] = { col: i, div: parseInt(div), values: [] }\\n    }\\n    return p\\n}, {})\",\"language\":\"ts\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/blob/4bca2afc7fcac9779ea4afdf0bcda89a08f6ab52/app.ts\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/blob/4bca2afc7fcac9779ea4afdf0bcda89a08f6ab52/app.ts\",\"title\":\"app.ts · 4bca2afc7fcac9779ea4afdf0bcda89a08f6ab52 · gustawdaniel / nbp\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"code\",{\"code\":\"ts-node app.ts\",\"language\":\"bash\"}],[\"code\",{\"code\":\"interface OutData {\\n  [key: string]: {\\n    [key: string]: number\\n  }\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const mergeYears = (payload: YearData[]): OutData => {\\n  return payload.reduce((p: OutData, n: YearData) => {\\n    Object.keys(n).forEach(key => {\\n      if (p.hasOwnProperty(key)) {\\n        p[key] = {...p[key], ...n[key].values.reduce((p,n) => ({...p,...n}))}\\n      } else {\\n        p[key] = n[key].values.reduce((p,n) => ({...p,...n}))\\n      }\\n    })\\n    return p\\n  }, {})\\n}\\n\",\"language\":\"ts\"}],[\"code\",{\"code\":\"return mergeYears(fs.readdirSync(rawDir).filter(f => f.endsWith('csv'))\\n\",\"language\":\"ts\"}],[\"code\",{\"code\":\"{\\n  CHF: {\\n    '1984-01-02': 140.84,\\n    '1984-01-09': 140.08,\\n    '1984-01-16': 138.62,\\n...\",\"language\":\"json\"}],[\"code\",{\"code\":\"!fs.existsSync(process.cwd() + '/out') && fs.mkdirSync(process.cwd() + '/out', {recursive: true})\\nfs.writeFileSync(process.cwd() + '/out/chf.json', JSON.stringify(main()))\",\"language\":\"ts\"}],[\"code\",{\"code\":\"time ts-node app.ts\",\"language\":\"bash\"}],[\"code\",{\"code\":\"ts-node app.ts  7.67s user 0.29s system 147% cpu 5.412 total\",\"language\":\"bash\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/blob/12edf429a1ddba80f04f29e0f9d2a0309aa372e2/app.ts\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/nbp/-/blob/12edf429a1ddba80f04f29e0f9d2a0309aa372e2/app.ts\",\"title\":\"app.ts · 12edf429a1ddba80f04f29e0f9d2a0309aa372e2 · gustawdaniel / nbp\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"code\",{\"code\":\"<html>\\n<body>\\n<script src=\\\"./index.ts\\\"></script>\\n</body>\\n</html>\\n\",\"language\":\"html\"}],[\"code\",{\"code\":\"npm install -g parcel-bundler\",\"language\":\"bash\"}],[\"code\",{\"code\":\"parcel index.html\",\"language\":\"bash\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-02-14-30.png\",\"width\":468,\"height\":75}],[\"code\",{\"code\":\"npm install apexcharts --save\\n\",\"language\":\"bash\",\"caption\":\"\"}],[\"code\",{\"code\":\"<main id='chart'></main>\"}],[\"code\",{\"code\":\"import ApexCharts from 'apexcharts'\\n\\nconst options = {\\n  series: [{\\n    data: [{\\n      x: new Date(1538778600000),\\n      y: [6629.81, 6650.5, 6623.04, 6633.33]\\n    },\\n      {\\n        x: new Date(1538780400000),\\n        y: [6632.01, 6643.59, 6620, 6630.11]\\n      }\\n    ]\\n  }],\\n  chart: {\\n    type: 'candlestick',\\n    height: 350\\n  },\\n  title: {\\n    text: 'CandleStick Chart',\\n    align: 'left'\\n  },\\n  xaxis: {\\n    type: 'datetime'\\n  },\\n  yaxis: {\\n    tooltip: {\\n      enabled: true\\n    }\\n  }\\n};\\n\\nconst chart = new ApexCharts(document.querySelector(\\\"#chart\\\"), options);\\nchart.render().then(console.log).catch(console.error);\\n\",\"language\":\"js\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-02-29-51.png\",\"width\":1254,\"height\":362}],[\"code\",{\"code\":\"{\\n  CHF: {\\n    'YYYY-MM-DD': number,\\n    ...\\n  }\\n}\"}],[\"code\",{\"code\":\"{\\n  x: Date,\\n  y: [number, number, number, number] // open, high, low, close\\n}[]\"}],[\"code\",{\"code\":\"import {CHF} from './out/chf.json'\\n\",\"language\":\"ts\"}],[\"code\",{\"code\":\"{\\n  \\\"compilerOptions\\\": {\\n    \\\"resolveJsonModule\\\": true,\\n    ...\",\"language\":\"json\"}],[\"code\",{\"code\":\"interface StockRecord {\\n  x: Date,\\n  y: [number, number, number, number]\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const splitDateIntoEqualIntervals = (startDate: Date, endDate: Date, numberOfIntervals: number): { start: Date, end: Date, avg: Date }[] => {\\n  const intervalLength = (endDate.getTime() - startDate.getTime()) / numberOfIntervals\\n  return [...(new Array(numberOfIntervals))]\\n    .map((e, i) => {\\n      return {\\n        start: new Date(startDate.getTime() + i * intervalLength),\\n        avg: new Date(startDate.getTime() + (i + 0.5) * intervalLength),\\n        end: new Date(startDate.getTime() + (i + 1) * intervalLength)\\n      }\\n    })\\n}\",\"language\":\"ts\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://stackoverflow.com/questions/63273494/divide-date-range-into-known-number-of-equal-chunks\",\"metadata\":{\"url\":\"https://stackoverflow.com/questions/63273494/divide-date-range-into-known-number-of-equal-chunks\",\"title\":\"divide date range into known number of equal chunks\",\"description\":\"I’ve seen Split date range into date range chunks\\nand Split date range into several specific date range chunks, that is not what I’m looking for.\\nI’m looking for simple function from momenjs, that ...\",\"author\":\"deathfry\",\"publisher\":\"Stack Overflow\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded\",\"icon\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a\"}}],[\"code\",{\"code\":\"const mapToStockData = (values: { [key: string]: number }, parts: number):StockRecord[] => {\\n  const entries = Object.entries(values)\\n  const start = new Date(entries[0][0])\\n  const end = new Date(entries[entries.length - 1][0])\\n  const intervals = splitDateIntoEqualIntervals(start, end, parts)\\n\\n  const stockData: StockRecord[] = []\\n\\n  while (intervals.length) {\\n    const int = intervals.shift()\\n    if (!int) break\\n    let currDate = int.start\\n    stockData.push({\\n      x: int.avg,\\n      y: [NaN, NaN, NaN, NaN]\\n    })\\n\\n    const currStock = stockData[stockData.length - 1]\\n    let stat = {\\n      min: Infinity,\\n      max: -Infinity\\n    }\\n\\n    while (currDate < int.end) {\\n      const [dateString, value] = entries.shift() || []\\n      if (!dateString || typeof value !== 'number') break\\n      currDate = new Date(dateString)\\n      if (isNaN(currStock.y[0])) currStock.y[0] = value\\n      currStock.y[3] = value\\n      stat.min = Math.min(stat.min, value)\\n      stat.max = Math.max(stat.max, value)\\n    }\\n    currStock.y[1] = stat.max\\n    currStock.y[2] = stat.min\\n  }\\n\\n  return stockData\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const generateOptions = (data: StockRecord[]) => ({\\n  series: [{\\n    data\\n  }],\\n  chart: {\\n    type: 'candlestick',\\n    height: window.innerHeight - 50,\\n    zoom: {\\n      autoScaleYaxis: true\\n    }\\n  },\\n  title: {\\n    text: 'CandleStick Chart',\\n    align: 'left'\\n  },\\n  xaxis: {\\n    type: 'datetime'\\n  },\\n  yaxis: {\\n    tooltip: {\\n      enabled: true\\n    }\\n  }\\n})\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const chart = new ApexCharts(document.querySelector('#chart'), generateOptions(mapToStockData(CHF, 500)))\\nchart.render().then(console.log).catch(console.error)\\n\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-34-49.png\",\"width\":1907,\"height\":1006,\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-36-04.png\",\"width\":1161,\"height\":1054}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-40-24.png\",\"width\":1620,\"height\":109,\"cardWidth\":\"full\"}],[\"code\",{\"code\":\"             arr.forEach(localArr => {\\n                 const date = getDateFromArr(localArr)\\n+\\n+                const newSettings = decomposeBaseSettingsFromCodes(localArr)\\n+                if (Object.keys(newSettings).length) {\\n+                    Object.keys(settings).forEach(key => {\\n+                        settings[key].div = newSettings[key].div\\n+                    })\\n+                }\\n+\\n                 if (typeof date === 'string') {\\n                     Object.keys(settings).forEach(key => {\\n\",\"language\":\"diff\"}],[\"code\",{\"code\":\"const denominationFactor = (date:string): number => {\\n    return Number.parseInt(date.substr(0,4)) <= 1994 ? 1e4 : 1;\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"settings[key].values.push({[date]: parseFloat(localArr[settings[key].col]) / settings[key].div / denominationFactor(date)})\\n\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-56-59.png\",\"width\":1916,\"height\":1115,\"cardWidth\":\"full\"}],[\"bookmark\",{\"url\":\"https://chf-pln.netlify.app/\",\"metadata\":{\"url\":\"https://goofy-franklin-2f9df8.netlify.app\",\"title\":\"Kurs CHF w PLN\",\"description\":\"Wykres kursu Polskiej złotówki wzglęm Franka Szwajcarskiego. Od 1995 są PLN, wcześniej były PLZ.\",\"author\":\"Daniel Gustaw\",\"publisher\":\"Precise Lab\",\"thumbnail\":\"https://blog.gustawdaniel.com/content/images/size/w1000/2021/02/Screenshot-from-2021-02-04-04-56-56.png\",\"icon\":null}}],[\"code\",{\"code\":\" npm install -D parcel-bundler\"}],[\"code\",{\"code\":\"  \\\"scripts\\\": {\\n    \\\"build\\\": \\\"parcel build index.html\\\",\\n  },\",\"language\":\"json\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-06-15-27.png\",\"width\":1271,\"height\":954}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-11-09-21.png\",\"width\":1849,\"height\":1016,\"cardWidth\":\"full\"}],[\"html\",{\"html\":\"<!-- Calendly inline widget begin -->\\n<div class=\\\"calendly-inline-widget\\\" data-url=\\\"https://calendly.com/gustaw-daniel?hide_gdpr_banner=1\\\" style=\\\"min-width:320px;height:630px;\\\"></div>\\n<script type=\\\"text/javascript\\\" src=\\\"https://assets.calendly.com/assets/external/widget.js\\\"></script>\\n<!-- Calendly inline widget end -->\"}],[\"html\",{\"html\":\"<iframe class=\\\"clickup-embed clickup-dynamic-height\\\" src=\\\"https://forms.clickup.com/f/21qbj-1184/44GF096HL1E9EGEGUW\\\" onwheel=\\\"\\\" width=\\\"100%\\\" height=\\\"100%\\\" style=\\\"background: transparent; border: 1px solid #ccc;\\\"></iframe><script async src=\\\"https://app-cdn.clickup.com/assets/js/forms-embed/v1.js\\\"></script>\"}],[\"hr\",{}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.bankier.pl/wiadomosc/Zlote-czasy-franka-jak-sie-zaczal-kredytowy-boom-2894462.html\",\"metadata\":{\"url\":\"https://www.bankier.pl/wiadomosc/Zlote-czasy-franka-jak-sie-zaczal-kredytowy-boom-2894462.html\",\"title\":\"Złote czasy franka - jak się zaczął kredytowy boom?\",\"description\":\"Nagła kredytowa kariera szwajcarskiego franka sprawiła, że tysiące Polaków co najmniej raz w miesiącu z niepokojem zerkają na notowania. Popularność zobowiązań w helweckiej walucie była wynikiem zbiegu kilku okoliczności w określonym momencie gospodarczej historii Polski. Kredytobiorcy, którzy w poł…\",\"author\":\"Michał Kisiel\",\"publisher\":\"Bankier.pl\",\"thumbnail\":\"https://galeria.bankier.pl/p/0/f/c054fce945dcfc-thumb-2500.jpg\",\"icon\":\"https://www.bankier.pl/favicon.ico\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://muzhp.pl/pl/e/1357/denominacja-zlotego\",\"metadata\":{\"url\":\"https://muzhp.pl/pl/e/1357/denominacja-zlotego\",\"title\":\"Denominacja złotego - Muzeum Historii Polski\",\"description\":null,\"author\":null,\"publisher\":\"Muzeum Historii Polski\",\"thumbnail\":\"https://muzhp.pl/files/events/13/57/800_img.jpg\",\"icon\":\"https://muzhp.pl/assets/favicon.ico\"}}]],\"markups\":[[\"a\",[\"href\",\"https://stooq.com/\"]],[\"a\",[\"href\",\"https://stooq.com/q/d/?s=chfpln\"]],[\"em\"],[\"strong\"],[\"a\",[\"href\",\"https://www.nbp.pl/home.aspx?f=/kursy/arch_a.html\"]],[\"code\"],[\"a\",[\"href\",\"https://goofy-franklin-2f9df8.netlify.app/chf.json\"]],[\"a\",[\"href\",\"https://chf-pln.netlify.app/chf.json\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Strukturyzacja danych to nadawanie danym kształtu pozwalającego na ich analizę i wygodne przetwarzanie. W tym wpisie pokażę jak może wyglądać taki proces na przykładzie danych pochodzących z NBP, które są składowane w plikach, których konwencja układania nagłówków ulegała zmianom na przestrzeni lat. \"]]],[1,\"p\",[[0,[],0,\"Dane z NBP nie nadają się przez to do natychmiastowego użycia i należy je uporządkować, jeśli chcieli byśmy je przetwarzać.\"]]],[1,\"p\",[[0,[],0,\"Od razu zaznaczę, że historyczne kursy walut są świetnie prezentowane na stronie:\"]]],[1,\"p\",[[0,[0],1,\"https://stooq.com/\"]]],[1,\"p\",[[0,[],0,\"Za przykład weźmy kurs franka szwajcarskiego:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Aby pobrać te dane wystarczy przejść na stronę:\"]]],[1,\"p\",[[0,[1],1,\"https://stooq.com/q/d/?s=chfpln\"]]],[1,\"p\",[[0,[],0,\"i kliknąć przycisk poniżej tabeli\"]]],[10,1],[1,\"p\",[[0,[],0,\"W tym artykule nie rozwiązuję \"],[0,[2],1,\"realnego problemu\"],[0,[],0,\", tylko prezentuję możliwe do zastosowania \"],[0,[2],0,\"metody strukturyzacji danych \"],[0,[3],2,\"na przykładzie\"],[0,[],0,\" konkretnego zbioru plików o niespójnej i nieprzewidywalnej konwencji.\"]]],[1,\"p\",[[0,[],0,\"Kolejno przejdziemy przez problemy:\"]]],[3,\"ol\",[[[0,[],0,\"Pobrania danych\"]],[[0,[],0,\"Przetworzenia ich\"]],[[0,[],0,\"Wyświetlenia wykresu\"]]]],[1,\"p\",[[0,[],0,\"Główną wartością dla czytelnika jest śledzenie całego procesu od początku do końca i poznanie stosowanych tu narzędzi.\"]]],[10,2],[1,\"p\",[[0,[],0,\"Dane z kursami pobierzemy ze strony\"]]],[1,\"blockquote\",[[0,[4],1,\"https://www.nbp.pl/home.aspx?f=/kursy/arch_a.html\"]]],[10,3],[1,\"p\",[[0,[],0,\"Dane są podzielone na osobne arkusze \"],[0,[5],1,\"xls\"],[0,[],0,\".\"]]],[1,\"h1\",[[0,[],0,\"Pobranie danych\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od pobrania tych danych. Z kodu \"],[0,[5],1,\"HTML\"],[0,[],0,\" odczytujemy selektor.\"]]],[10,4],[1,\"p\",[[0,[],0,\"W konsoli przeglądarki wpisujemy:\"]]],[10,5],[1,\"p\",[[0,[],0,\"Wynikiem jest połączona \"],[0,[5],1,\"&&\"],[0,[],0,\" lista poleceń \"],[0,[5],1,\"wget\"],[0,[],0,\" pobierających kolejne pliki. \"]]],[10,6],[1,\"p\",[[0,[],0,\"Po wklejeniu ich do terminala pliki zostaną pobrane na nasz komputer.\"]]],[1,\"p\",[[0,[],0,\"Zalecam stosowanie konwencji w której takie surowe pobrane z internetu pliki lądują w osobnym katalogu np \"],[0,[5],1,\"raw\"],[0,[],0,\".\"]]],[1,\"h1\",[[0,[],0,\"Konwersja\"]]],[1,\"p\",[[0,[],0,\"Wykonujemy konwersję wszystkich plików do formatu \"],[0,[5],1,\"csv\"],[0,[],0,\" ponieważ jest wygodniejszy w przetwarzaniu maszynowym niż \"],[0,[5],1,\"xls\"],[0,[],0,\".\"]]],[10,7],[1,\"p\",[[0,[],0,\"Po wykonaniu tej komendy w naszym katalogu zobaczymy zarówno pliki \"],[0,[5],1,\"xls\"],[0,[],0,\" jak i odpowiadające im \"],[0,[5],1,\"csv\"],[0,[],0,\".\"]]],[1,\"h1\",[[0,[],0,\"Strukturyzacja\"]]],[1,\"p\",[[0,[],0,\"Niestety osoby przygotowujące te pliki nie zadbały o trzymanie wspólnej konwencji i pierwszy wiersz czasami należy wyrzucić, innym razem zawiera nazwy waluty, kraju a jeszcze innym kod waluty.\"]]],[1,\"p\",[[0,[],0,\"Co możemy z tym zrobić?\"]]],[1,\"p\",[[0,[],0,\"Najlepiej ustalić własną normę zapisu i ujednolicić strukturę danych w obrębie całego zbioru.\"]]],[1,\"p\",[[0,[],0,\"Konwencja zapisu dat, walut i kursów: \"]]],[3,\"ul\",[[[0,[],0,\"data YYYY-MM-DD - ponieważ wygodnie się sortuje i jest to naturalny format dat w wielu językach\"]],[[0,[],0,\"waluta - za pomocą kodu ISO_4217 (3 literowy kod walut)\"]],[[0,[],0,\"kurs - za pomocą formatu z kropką do oznaczania ułamków\"]]]],[1,\"p\",[[0,[],0,\"Konwencja struktury danych (kompozycji):\"]]],[3,\"ul\",[[[0,[],0,\"JSON w którym pierwszy klucz to waluta a drugi to data, wartość to wartość w złotówkach - ten format pozwala łatwo wyszukiwać po walutach a następnie po datach, wygodnie rzutuje się go względem walut. Mimo narzutu objętościowego względem CSV łatwość dalszego procesowania jest tu czynnikiem decydującym.\"]]]],[1,\"p\",[[0,[],0,\"Kiedy mamy już konwencję możemy napisać kod. Użyjemy do tego \"],[0,[5],1,\"typescript\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Przygotowanie projektu\"]]],[1,\"p\",[[0,[],0,\"Zaczynamy projekt komendami\"]]],[10,8],[1,\"p\",[[0,[],0,\"Paczka którą zainstalowaliśmy - \"],[0,[5],1,\"chai\"],[0,[],0,\" pozwoli nam na pisanie testów automatycznych sprawdzających zgodność wyników z naszymi oczekiwaniami. Oszczędzi nam to czas na ich manualną weryfikację.\"]]],[1,\"p\",[[0,[],0,\"Do zadania powinniśmy dobrać strukturę katalogów i paradygmat. W naszym przypadku zakładamy max 100 linii kodu przetwarzającego i z tego powodu wystarczy jeden plik z proceduralnym kodem o szkielecie:\"]]],[10,9],[1,\"h2\",[[0,[],0,\"Odczyt plików\"]]],[1,\"p\",[[0,[],0,\"Pierwszą funkcją będzie tu \"],[0,[5],1,\"main\"],[0,[],0,\". Zaczniemy od pokazania listy plików.\"]]],[10,10],[1,\"p\",[[0,[],0,\"Wykonanie komendą \"]]],[10,11],[1,\"p\",[[0,[],0,\"Daje nazwy plików, które przetworzymy:\"]]],[10,12],[1,\"p\",[[0,[],0,\"Dzięki linii korzystającej z \"],[0,[5],1,\"chai\"],[0,[],0,\" mamy pewność, że wszystkie wyniki mają odpowiedni typ. Teraz może to nie robić wrażenia, ale na późniejszym etapie takie testowanie pozwoli nam szybko wykrywać i łatać błędy związane z odkrywaniem kolejnych niuansów w konwencji użytej w badanych plikach. \"]]],[1,\"p\",[[0,[],0,\"Aby wyświetlić zawartość pierwszego pliku skorzystamy z funkcji \"],[0,[5],1,\"readFileSync\"],[0,[],0,\". Wybór filtrów i map nie jest przypadkowy. Te funkcje wraz z reduce idealnie nadają się do przetwarzania danych i zobaczymy je tu jeszcze wiele razy.\"]]],[10,13],[1,\"p\",[[0,[],0,\"Okazuje się, że pierwszy plik nie zawiera kodów walut.\"]]],[10,14],[1,\"p\",[[0,[],0,\"Więc zmuszeni jesteśmy do zbudowania słownika, który mapuje nazwy krajów na kody walutowe.\"]]],[10,15],[1,\"h2\",[[0,[],0,\"Przetworzenie nagłówków\"]]],[1,\"p\",[[0,[],0,\"Przyjrzenie się nagłówkom definiuje też podstawowe reguły dalszego przetwarzania.\"]]],[3,\"ol\",[[[0,[],0,\"Mamy w pierwszym wierszu wykonać wyszukanie nazwy kraju. \"]],[[0,[],0,\"Na tej podstawie ustalić kolumnę \"],[0,[5],1,\"col\"],[0,[],0,\" w której znajdują się dane.\"]],[[0,[],0,\"W drugim wierszu w kolumnie \"],[0,[5],1,\"col\"],[0,[],0,\" znajduje się dzielnik \"],[0,[5],1,\"div\"]],[[0,[],0,\"Później bierzemy tylko te wiersze, które zawierają datę w pierwszej kolumnie.\"]],[[0,[],0,\"W tych wierszach w kolumnie \"],[0,[5],1,\"col\"],[0,[],0,\" znajduje się wartość, która powinna być podzielona przez dzielnik \"],[0,[5],1,\"div\"],[0,[],0,\" aby mieć wartość kursu walutowego.\"]]]],[1,\"p\",[[0,[],0,\"Dzięki interfejsom w TypeScript możemy zdefiniować jak będzie wyglądała nasza docelowa struktura danych z pojedynczego pliku:\"]]],[10,16],[1,\"p\",[[0,[],0,\"Linię zwracającą zawartość pliku:\"]]],[10,17],[1,\"p\",[[0,[],0,\"zmienimy na przypisanie do stałej \"],[0,[5],1,\"arr\"],[0,[],0,\" tablicy tablic z plikiem \"],[0,[5],1,\"csv\"],[0,[],0,\" rozbitym na znakach nowej linii oraz przecinkach\"]]],[10,18],[1,\"p\",[[0,[],0,\"Do rozkładu pierwszej linii posłuży nam funkcja:\"]]],[10,19],[1,\"p\",[[0,[],0,\"Użyjemy jej zaraz po rozłożeniu pliku na tablicę \"],[0,[5],1,\"arr\"],[0,[],0,\" w liniach\"]]],[10,20],[1,\"p\",[[0,[],0,\"W przypadku sukcesu ustawienia będą zawierały klucz \"],[0,[5],1,\"CHF\"],[0,[],0,\" z dobrze wyliczoną wartością kolumny. Do tego była nam potrzebna funkcja \"],[0,[5],1,\"decomposeBaseSettingsFromNames\"],[0,[],0,\", zwróćmy jednak uwagę, że wartość dzielnika ustawiłem na \"],[0,[5],1,\"1\"],[0,[],0,\". To dlatego, że dzielniki są dopiero w kolejnej linii. Znajdziemy je dzięki następującym liniom:\"]]],[10,21],[1,\"p\",[[0,[],0,\"Zmianie ulegnie też test i obecnie przyjmie formę:\"]]],[10,22],[1,\"p\",[[0,[],0,\"Wykonanie powyższego kodu da nam\"]]],[10,23],[1,\"p\",[[0,[],0,\"I jest to świetny wynik, ponieważ dokładnie takie wartości mieliśmy wydobyć z pierwszego pliku. Mówi nam on, że kolumna z funtami znajduje się na 26 pozycji (numerujemy od 0) oraz, że dzielnik to 1. Używamy go głównie przy okazji denominacji, więc w roku \"],[0,[5],1,\"1984\"],[0,[],0,\" nie był nam potrzebny.\"]]],[1,\"p\",[[0,[],0,\"Cały kod \"],[0,[5],1,\"app.ts\"],[0,[],0,\" na tym etapie można znaleźć pod linkiem:\"]]],[10,24],[1,\"h2\",[[0,[],0,\"Przetworzenie wartości\"]]],[1,\"p\",[[0,[],0,\"Daty w formacie \"],[0,[5],1,\"DD.MM.YYYY\"],[0,[],0,\", nie pasują do opisanej przez nas konwencji więc piszemy konwerter \"]]],[10,25],[1,\"p\",[[0,[],0,\"Teraz za przetworzeniem nagłówków możemy dodać kod strukturyzujący wartości kursów \"]]],[10,26],[1,\"p\",[[0,[],0,\"Jak widzimy nagłówki były najtrudniejszą częścią. Kiedy je mamy, to ułożenie samych wartości staje się formalnością. Wykonanie kodu daje:\"]]],[10,27],[1,\"p\",[[0,[],0,\"Test poprawnej struktury danych mógł by wyglądać tak:\"]]],[10,28],[1,\"p\",[[0,[],0,\"Cały kod można przejrzeć tutaj:\"]]],[10,29],[1,\"p\",[[0,[],0,\"Tu artykuł by mógł kończyć się połączeniem plików jedną funkcją i prezentacją ostatecznego wyniku...\"]]],[1,\"p\",[[0,[],0,\"Jednak tak nie jest. Teraz zaczyna się brudna robota z wykrywaniem niespójności w konwencji plików n NBP.\"]]],[1,\"h2\",[[0,[],0,\"Normalizacja i czyszczenie danych\"]]],[1,\"p\",[[0,[],0,\"Jeśli sprawdzimy za pomocą tego kodu plik \"],[0,[5],1,\"6\"],[0,[],0,\" ustawiając funkcję filtrującą pliki na taką:\"]]],[10,30],[1,\"p\",[[0,[],0,\"to wynik będzie zaskakująco rozczarowujący\"]]],[10,31],[1,\"p\",[[0,[],0,\"Aby to zdebugować za linią:\"]]],[10,32],[1,\"p\",[[0,[],0,\"dodamy \"]]],[10,33],[1,\"p\",[[0,[],0,\"z wartością \"],[0,[5],1,\"ROWS_FILTER\"],[0,[],0,\" zdefiniowaną jako\"]]],[10,34],[1,\"p\",[[0,[],0,\"Aby uczynić czytanie bardziej wygodne wyświetliłem chwilowo tablicę \"],[0,[5],1,\"arr\"],[0,[],0,\" używając \"],[0,[5],1,\"console.table\"],[0,[],0,\" i wycinając tylko najciekawsze kolumny:\"]]],[10,35],[10,36],[1,\"p\",[[0,[],0,\"Co widzimy?\"]]],[1,\"p\",[[0,[],0,\"Że zmieniła się konwencja zapisu daty na \"],[0,[5],1,\"MM/DD/YYYY\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Problem obsłużymy rozszerzając konwerter dat o kolejny \"],[0,[5],1,\"if\"]]],[10,37],[1,\"p\",[[0,[],0,\"Możemy dodać też filter, który usunie spacje z nazw krajów:\"]]],[10,38],[1,\"p\",[[0,[],0,\"włożoną do mapy za linią\"]]],[10,39],[1,\"p\",[[0,[],0,\"Pozwoli to na traktowanie kraju \"],[0,[5],1,\"W. Brytania\"],[0,[],0,\" oraz \"],[0,[5],1,\"W.Brytania\"],[0,[],0,\" tak samo.\"]]],[1,\"p\",[[0,[],0,\"Po tych zmianach wprowadzimy też zmianę w testowaniu. Wymusimy niezerową długość wartości z cenami. Przeniesiemy też testowanie do osobnej funkcji \"]]],[10,40],[1,\"p\",[[0,[],0,\"I wykonujmy ją przez zwróceniem \"],[0,[5],1,\"settings\"],[0,[],0,\".\"]]],[10,41],[1,\"p\",[[0,[],0,\"Po odblokowaniu filtrów\"]]],[10,42],[1,\"p\",[[0,[],0,\"Wykonanie zakończy się błędem\"]]],[10,43],[1,\"p\",[[0,[],0,\"Dzięki liniom z pozwalającym na debug:\"]]],[10,44],[1,\"p\",[[0,[],0,\"oraz \"]]],[10,45],[1,\"p\",[[0,[],0,\"widzimy, że problemem są zupełnie puste linie.\"]]],[10,46],[1,\"p\",[[0,[],0,\"Przyczyną błędu jest sztywne trzymanie się konkretnego wiersza jako miejsca gdzie trzymamy dzielniki czy nazwy walut, a tymczasem powinniśmy skasować puste linie przez wykryciem nagłówków.\"]]],[1,\"p\",[[0,[],0,\"Jest to powszechny problem przy parsowaniu plików excel. Użytkownicy mogąc przygotować dane w bardzo dowolnej strukturze często nie trzymają się konwencji umieszczania nagłówków w tan sam sposób we wszystkich plikach.\"]]],[1,\"p\",[[0,[],0,\"Użyjemy tu funkcji \"],[0,[5],1,\"test\"],[0,[],0,\" i wyrażenia regularnego oznaczającego same przecinki lub nic w całej linii:\"]]],[10,47],[1,\"p\",[[0,[],0,\"Dołączymy ją za \"],[0,[5],1,\"DROP_SPACES\"],[0,[],0,\" w funkcji \"],[0,[5],1,\"filter\"],[0,[],0,\".\"]]],[10,48],[1,\"p\",[[0,[],0,\"Tym razem znowu nie działa. Powodem jest bardzo nietypowa linia w jednym z plików.\"]]],[10,49],[1,\"p\",[[0,[],0,\" Korekta Kursu z 1987? Jak to? Faktycznie w \"],[0,[5],1,\"xls\"],[0,[],0,\" mamy coś takiego:\"]]],[10,50],[1,\"p\",[[0,[],0,\"Jednak dotyczy ona waluty \"],[0,[5],1,\"ECU\"],[0,[],0,\" więc najrozsądniej jest pominąć tą linię zaostrzając kryteria rozpoznawania dat.\"]]],[10,51],[1,\"p\",[[0,[],0,\"Cały kod z tego etapu znajduje się pod linkiem:\"]]],[10,52],[1,\"p\",[[0,[],0,\"Jednak jego wykonanie wciąż powoduje błędy\"]]],[10,53],[1,\"p\",[[0,[],0,\"Po głębszym sprawdzeniu okazuje się, że problem stanowi linia, która była prawie pusta, ale nie całkowicie pusta:\"]]],[10,54],[1,\"p\",[[0,[],0,\"Ktoś umieścił w niej \"],[0,[5],1,\"Nr\"],[0,[],0,\" na zupełnie nie znaczącej kolumnie. Wracamy więc do kodu i usuniemy tą linię kolejnym filtrem: \"],[0,[5],1,\"DROP_JUNK_LINES\"],[0,[],0,\", umieszczonym przed \"],[0,[5],1,\"DROP_EMPTY_LINES\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Kiedy pisałem ten kod wracałem do tego filtru jeszcze kilka razy. Nie będę odtwarzał tego tym razem lecz uproszczę i podam finalną wartość tej funkcji:\"]]],[10,55],[1,\"p\",[[0,[],0,\"Okazało się, że w tej linii były:\"]]],[3,\"ul\",[[[0,[],0,\"Nr\"]],[[0,[],0,\"data\"]],[[0,[],0,\"Waluta/Currency\"]],[[0,[],0,\".tab\"]]]],[1,\"p\",[[0,[],0,\"Te rzeczy czasami z dużych liter, a co mnie najbardziej zaskoczyło było też `W A L U T A / C U R R E N C Y`. Na szczęście dzięki mapie \"],[0,[5],1,\"DROP_SPACES\"],[0,[],0,\" i flagom \"],[0,[5],1,\"g\"],[0,[],0,\" oraz \"],[0,[5],1,\"i\"],[0,[],0,\" w mapie \"],[0,[5],1,\"DROP_JUNK_LINES\"],[0,[],0,\" filter \"],[0,[5],1,\"DROP_EMPTY_LINES\"],[0,[],0,\" traktuje te wszystkie linie jako tak samo puste czyli potrzebne.\"]]],[10,56],[1,\"p\",[[0,[],0,\"Po wprowadzeniu tych poprawek możemy zobaczyć wymaganą strukturę dla kolejnych plików:\"]]],[10,57],[1,\"p\",[[0,[],0,\"Link do zmiany w kodzie\"]]],[10,58],[1,\"p\",[[0,[],0,\"Wystarczy jednak zmienić przetworzyć kilka kolejnych plików aby wrócić do punktu wyjścia, zobaczyć\"]]],[10,59],[1,\"p\",[[0,[],0,\"i naprawiać od nowa.\"]]],[1,\"p\",[[0,[],0,\"Co stało się tym razem?\"]]],[1,\"p\",[[0,[],0,\"Pomoże nam wydrukowanie tablicy z plikiem \"],[0,[5],1,\"CSV\"],[0,[],0,\" po przetworzeniu\"]]],[10,60],[1,\"p\",[[0,[],0,\"żeby zobaczyć zupełnie nową organizację nagłówka oraz zmianę kolumny z datą\"]]],[10,61],[1,\"p\",[[0,[],0,\"Tym razem zarówno waluta jak i dzielnik umieszczone są w tej samej linii. Więc obsłużymy przypadek \"],[0,[5],1,\"else\"],[0,[],0,\" po linii\"]]],[10,62],[1,\"p\",[[0,[],0,\"użyjemy do tego funkcji \"],[0,[5],1,\"decomposeBaseSettingsFromCodes\"],[0,[],0,\" zdefiniowanej jako \"]]],[10,63],[1,\"p\",[[0,[],0,\"Co ona zmienia? \"]]],[3,\"ul\",[[[0,[],0,\"Rozkłada za pomocą \"],[0,[5],1,\"match\"],[0,[],0,\" wartość na dzielnik \"],[0,[5],1,\"div\"],[0,[],0,\" oraz kod waluty\"]],[[0,[],0,\"Nie potrzebuje kolejnej instrukcji \"],[0,[5],1,\"shift\"],[0,[],0,\" do wydobycia dzielnika\"]]]],[1,\"p\",[[0,[],0,\"Z tego względu zostanie ona wkomponowana w kod następująco\"]]],[10,64],[1,\"p\",[[0,[],0,\"Kolejny problem to liczby porządkowe w pierwszej kolumnie zamiast dat. Datami zajmiemy się zastępując funkcję \"],[0,[5],1,\"getDate\"],[0,[],0,\" funkcją \"],[0,[5],1,\"getDateFromArr\"]]],[10,65],[1,\"p\",[[0,[],0,\"teraz jest ona używana tak:\"]]],[10,66],[1,\"p\",[[0,[],0,\"Poprawki można zobaczyć w commicie:\"]]],[10,67],[1,\"p\",[[0,[],0,\"Czy to wszystkie problemy? Absolutnie nie. W roku 2008 zastosowano jeszcze inną konwencję.\"]]],[10,68],[1,\"p\",[[0,[],0,\"Polega ona na nie umieszczeniu nigdzie \\\"Szwajcaria\\\", ani nigdzie \\\"1CHF\\\", zatem obie metody rozpoznające zawodzą. Co powinniśmy zrobić? Możemy rozpisać algorytm rozpoznawania nagłówków następująco:\"]]],[10,69],[1,\"p\",[[0,[],0,\"Kolorem pomarańczowym zaznaczyliśmy brakujące elementy.\"]]],[1,\"p\",[[0,[],0,\"Ponieważ wyszukiwanie dzielnika się powtarza wydzielimy to do osobnej funkcji:\"]]],[10,70],[1,\"p\",[[0,[],0,\"Nie powinniśmy trzymać w \"],[0,[5],1,\"main\"],[0,[],0,\" zbyt dużo kodu, bo traci on czytelność, więc całą logikę rozpoznawania nagłówków wyrzucamy do osobnej funkcji:\"]]],[10,71],[1,\"p\",[[0,[],0,\"W main zostanie w tym miejscu tylko:\"]]],[10,72],[1,\"p\",[[0,[],0,\"Dla parsowania dzielników kluczowy stał się warunek:\"]]],[10,73],[1,\"p\",[[0,[],0,\"Zatem w rozkładzie ustawień na kody nie możemy już optymistycznie zakładać ustawienia tam \"],[0,[5],1,\"1\"],[0,[],0,\" jako wartości domyślnej, ani wymuszać wystąpienia liczby przy kodzie waluty, anie wymagać.\"]]],[1,\"p\",[[0,[],0,\"Zmiany w funkcjach wykonujących wcześniej przetwarzanie nagłówków wyglądają tak\"]]],[10,74],[1,\"p\",[[0,[],0,\"W ten sposób natomiast wygląda ich aktualny kod\"]]],[10,75],[1,\"p\",[[0,[],0,\"Całość projektu na tym etapie:\"]]],[10,76],[1,\"p\",[[0,[],0,\"Jak widać, czyszczenie danych jest żmudnym procesem w którym problemy nigdy się nie kończą. Na szczęście te dane napływają w tempie jeden plik na rok i wygląda na to, że udało się je ustrukturyzować zanim upłynął ten czas.\"]]],[1,\"p\",[[0,[],0,\"Wykonanie kodu komendą\"]]],[10,77],[1,\"p\",[[0,[],0,\"wyświetli długie listy tabel i konfiguracji, ale nie rzuci żadnego błędu.\"]]],[1,\"h2\",[[0,[],0,\"Łączenie plików\"]]],[1,\"p\",[[0,[],0,\"Do połączenia plików wymagane są:\"]]],[1,\"p\",[[0,[],0,\"1. dodanie typu wynikowego\"]]],[10,78],[1,\"p\",[[0,[],0,\"3. Przygotowanie funkcji łączącej\"]]],[10,79],[1,\"p\",[[0,[],0,\"4. Dołączenie \"],[0,[5],1,\"mergeYears\"],[0,[],0,\" przed \"],[0,[5],1,\"return\"],[0,[],0,\" w funkcji \"],[0,[5],1,\"main\"],[0,[],0,\".\"]]],[10,80],[1,\"p\",[[0,[],0,\"Wprowadzenie tych zmian pozwala zobaczyć kursy z całego zakresu\"]]],[10,81],[1,\"p\",[[0,[],0,\"Aby zapisać wynik dopiszemy lini:\"]]],[10,82],[1,\"p\",[[0,[],0,\"Wykonanie:\"]]],[10,83],[1,\"p\",[[0,[],0,\"zwróci:\"]]],[10,84],[1,\"p\",[[0,[],0,\"i spowoduje utworzenie pliku \"],[0,[5],1,\"/out/chf.json\"],[0,[],0,\" o wadze \"],[0,[5],1,\"156K\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Plik projektu zawierający \"],[0,[5],1,\"126\"],[0,[],0,\" linii kodu dostępny jest pod linkiem:\"]]],[10,85],[1,\"p\",[[0,[],0,\"Jeśli potrzebujesz tych danych, możesz samodzielnie odtworzyć wszystkie kroki lub pobrać gotowe dane JSON z linku\"]]],[1,\"p\",[[0,[6,7],2,\"https://chf-pnl.netlify.app/chf.json\"]]],[1,\"h1\",[[0,[],0,\"Wizualizacja\"]]],[1,\"p\",[[0,[],0,\"Nie mogę się oprzeć pokusie narysowania i omówienia kursu Franka Szwajcarskiego kiedy już udało mi się wydobyć kurs sprzed tak wielu lat. Szczególnie interesujący jest okres przed początkiem obecnego stulecia i boomem na kredyty w CHF z lat 2005-2008. \"]]],[1,\"h2\",[[0,[],0,\"Przygotowanie projektu\"]]],[1,\"p\",[[0,[],0,\"Do rysowania wykresów posłuży nam plik \"],[0,[5],1,\"index.html\"],[0,[],0,\" o zawartości:\"]]],[10,86],[1,\"p\",[[0,[],0,\"oraz pustego \"],[0,[5],1,\"index.ts\"],[0,[],0,\". Teraz instalujemy \"],[0,[5],1,\"parcel\"]]],[10,87],[1,\"p\",[[0,[],0,\"Jest to narzędzie do budowania jak \"],[0,[5],1,\"webpack\"],[0,[],0,\", \"],[0,[5],1,\"gulp\"],[0,[],0,\" czy \"],[0,[5],1,\"grunt\"],[0,[],0,\" z tym, że w przeciwieństwie do wymienionych jego konfiguracja nie zajmuje setek lat i nie wymaga wklejania konfiguracja oraz szukania paczek.\"]]],[1,\"p\",[[0,[],0,\"Po wpisaniu:\"]]],[10,88],[1,\"p\",[[0,[],0,\"zobaczymy komunikat o zbudowaniu oraz link do strony\"]]],[10,89],[1,\"p\",[[0,[],0,\"Po otworzeniu linku i konsoli deweloperskiej a następnie dodaniu do \"],[0,[5],1,\"index.ts\"],[0,[],0,\" linii \"],[0,[5,2,3],2,\"console\"],[0,[],1,\".log(\\\"test\\\")\"],[0,[],0,\" zobaczymy automatyczne przeładowanie się strony i wpisanie \\\"test\\\" do konsoli. \"]]],[1,\"h2\",[[0,[],0,\"Integracja biblioteki do wykresów\"]]],[1,\"p\",[[0,[],0,\"Do rysowania wykresów użyjemy Apex Chatrs.\"]]],[10,90],[1,\"p\",[[0,[],0,\"Do body w pliku \"],[0,[5],1,\"index.html\"],[0,[],0,\" dołączymy:\"]]],[10,91],[1,\"p\",[[0,[],0,\"żeby móc przyczepić wykres. Natomiast w \"],[0,[5],1,\"index.ts\"],[0,[],0,\" konfigurację prostego wykresu giełdowego\"]]],[10,92],[1,\"p\",[[0,[],0,\"Można powiedzieć - super prostego:\"]]],[10,93],[1,\"p\",[[0,[],0,\"Jednak ta prostota ma cel. Pozwala nie zaśmiecać artykułu testowymi danymi, tylko kiedy już mamy strukturę danych do wykresu możemy wykonać transformację naszej struktury wydobytej z plików \"],[0,[5],1,\"xls\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Ułożenie danych na wykresie\"]]],[1,\"p\",[[0,[],0,\"Podsumujmy:\"]]],[3,\"ol\",[[[0,[],0,\"Nasza struktura\"]]]],[10,94],[1,\"p\",[[0,[],0,\"Struktura do wykresu:\"]]],[10,95],[1,\"p\",[[0,[],0,\"Aby wykonać tą transformację musimy podzielić nasze dane na zakresy, to znaczy wybrać ile świec ma zawierać wykres. Następnie po wyliczeniu granicznych dat będziemy iterować po zakresach wybierając z dostępnych dat te, które mieszczą się w zakresie, z nich z kolei wyszukamy wartości początkowe, końcowe oraz skrajne.\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od importu pliku z danymi zapisanym przez skrypt z poprzedniej części:\"]]],[10,96],[1,\"p\",[[0,[],0,\"Aby to poprawnie obsłużyć w pliku \"],[0,[5],1,\"tsconfig.json\"],[0,[],0,\" dodajemy flagę \"],[0,[5],1,\"resolveJsonModule\"]]],[10,97],[1,\"p\",[[0,[],0,\"Teraz definiujemy interfejs z danymi wyjściowymi\"]]],[10,98],[1,\"p\",[[0,[],0,\"Do rozkładu funkcji na interwały wykorzystamy funkcję:\"]]],[10,99],[1,\"p\",[[0,[],0,\"opisaną pod linkiem:\"]]],[10,100],[1,\"p\",[[0,[],0,\"Samo mapowanie danych zostało ułożone w kolejnej funkcji\"]]],[10,101],[1,\"p\",[[0,[],0,\"Ten dłuższy fragment kodu wymaga komentarza. Można było to zadanie zrealizować za pomocą map filtrów i pętli forEach, ale wybrałem podwójny while z podwójnym shiftem. Nie jest to przypadek. W tym wypadku chodzi o wydajność. O ile te bardziej modne i eleganckie metody są zawsze moim pierwszym wyborem, to w przypadku gdy redukcja złożoności obliczeniowej wymaga trzymania pewnego rodzaju cache robię wyjątek. Komunikacja między osobnymi wykonaniami metod \"],[0,[5],1,\"map\"],[0,[],0,\", \"],[0,[5],1,\"filter\"],[0,[],0,\", \"],[0,[5],1,\"reduce\"],[0,[],0,\", \"],[0,[5],1,\"forEach\"],[0,[],0,\" jest trudniejsza, wymaga posługiwania się zmiennymi z wyższego zakresu. W szczególności zagnieżdżanie pętli domyślnie zakłada wykonanie \"],[0,[5],1,\"n x m\"],[0,[],0,\" operacji gdzie \"],[0,[5],1,\"n\"],[0,[],0,\" i \"],[0,[5],1,\"m\"],[0,[],0,\" są wymiarami tablic. U nas jednak chcę wykonać raczej \"],[0,[5],1,\"n + m\"],[0,[],0,\" przebiegów, nie chcę dwa razy przetwarzać, odrzucać, filtrować czy sprawdzać tego samego klucza w obiekcie z kursami jeśli to nie jest potrzebne. \"]]],[1,\"p\",[[0,[],0,\"O jakiej oszczędności mówimy?   \"]]],[1,\"p\",[[0,[],0,\"Jeśli ten kod został by napisany nie wydajnie i nie ułożyli byśmy dobrze iteracji to może wyglądał by na bardziej czytelny i zwięzły, ale przy granulacji na 500 świec wykonał by \"],[0,[5],1,\"7200 x 500 = 3.6e6\"],[0,[],0,\" pętli, tym czasem mamy ich około \"],[0,[5],1,\"7200 + 500 = 7.7e4\"],[0,[],0,\" czyli około 50 razy krótszy czas ładowania.\"]]],[1,\"p\",[[0,[],0,\"Generowanie opcji to po prostu funkcja wkładająca dane do szablonu konfiguracji Apex Chart\"]]],[10,102],[1,\"p\",[[0,[],0,\"Na końcu wykonanie programu, czyli załączenie danych do konfiguracji i utworzenie za jej pomocą wykresu:\"]]],[10,103],[1,\"p\",[[0,[],0,\"Wykres wygląda świetnie. Idealnie oddaje realia walutowego dzikiego zachodu z początku lat 90. Widzimy jak w 1991 inflacja wywindowała cenę franka o rzędy wielkości, oraz drastyczny spadek na początku 1995 spowodowany wejściem w życie ustawy o denominacji z 7 lipca 1994.\"]]],[10,104],[1,\"p\",[[0,[],0,\"Nie wykrytym wcześniej problemem okazuje się tutaj błędne skalowanie z roku 1995.\"]]],[10,105],[1,\"p\",[[0,[],0,\"Faktycznie mamy zmianę mnożnika w trakcie roku 1995\"]]],[10,106],[1,\"p\",[[0,[],0,\"Ten problem możemy naprawić dodając linie przestawiające dzielnik jeśli jego zmiana nastąpi między wartościami, a nie w nagłówku:\"]]],[10,107],[1,\"p\",[[0,[],0,\"Kolejną zmianą będzie wprowadzenie normalizacji. Jeśli chcemy porównywać wartości na wykresie powinniśmy uwzględnić denominację. Pomoże nam w tym funkcja\"]]],[10,108],[1,\"p\",[[0,[],0,\"i włączenie jej wyniku w linii:\"]]],[10,109],[1,\"p\",[[0,[],0,\"Ponowne wygenerowanie danych pozwala zobaczyć wykres\"]]],[10,110],[1,\"p\",[[0,[],0,\"Aby wykonać deployment użyjemy serwisu Netlify.\"]]],[10,111],[1,\"p\",[[0,[],0,\"W tym celu dołączamy \"],[0,[5],1,\"parcel\"],[0,[],0,\" do zależności deweloperskich projektu:\"]]],[10,112],[1,\"p\",[[0,[],0,\"I dodajemy w \"],[0,[5],1,\"package.json\"],[0,[],0,\" komendę budującą\"]]],[10,113],[1,\"p\",[[0,[],0,\"Po wybraniu w panelu Netlify katalogu \"],[0,[5],1,\"dist\"],[0,[],0,\" oraz komendy \"],[0,[5],1,\"npm run build\"],[0,[],0,\" możemy cieszyć się skonfigurowanym deploymentem CI.\"]]],[10,114],[1,\"p\",[[0,[],0,\"Na koniec kurs CHF od końcówki lat 90 do czasów współczesnych\"]]],[10,115],[1,\"p\",[[0,[],0,\"Tu dobrze widać, że rosnące osoby biorące kredyty w CHF w roku 2004 mogły przez 5 lat cieszyć się spadkiem siły nabywczej swojego zadłużenia, kolejne 4 lata wartość franka wracała do pierwotnego poziomu, lecz wówczas kredyt mógł być już spłacony. Osoby biorące go w latach 2006-2007 popełniały błąd zakładając, że ten trend będzie się utrzymywał przez dziesięciolecia.\"]]],[1,\"h1\",[[0,[],0,\"Wnioski\"]]],[1,\"p\",[[0,[],0,\"Czasami zdarza się, że w internecie nie potrafimy znaleźć danych, których potrzebujemy. W rozważanym scenariuszu potrzebowaliśmy pełnej historii kursu CHF do PLN. W takim przypadku może się zdarzyć, że musimy je składać samodzielnie. Jest to uciążliwe zadanie jeśli dane te są zaśmiecone ludzkimi modyfikacjami i nie mają nałożonej jednolitej struktury. Narysowanie wykresu, wybranie nagłówków oraz danych łącznie zajęło tyle samo czasu co poprawki i debugowanie oraz zmiany w logice spowodowane odkrywaniem różnych konwencji i zapisów w plikach NBP.\"]]],[1,\"p\",[[0,[],0,\"Jeśli chcesz ze mną porozmawiać o problemie podobnym do tego umów się na niezobowiązującą, bezpłatną konsultację.\"]]],[10,116],[1,\"p\",[[0,[],0,\"Możesz też napisać do nas wypełniając formularz:\"]]],[10,117],[10,118],[1,\"p\",[[0,[],0,\"Artykuły, które pomogły w przygotowaniu tego wpisu\"]]],[10,119],[10,120],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "html": "<p>Strukturyzacja danych to nadawanie danym kształtu pozwalającego na ich analizę i wygodne przetwarzanie. W tym wpisie pokażę jak może wyglądać taki proces na przykładzie danych pochodzących z NBP, które są składowane w plikach, których konwencja układania nagłówków ulegała zmianom na przestrzeni lat. </p><p>Dane z NBP nie nadają się przez to do natychmiastowego użycia i należy je uporządkować, jeśli chcieli byśmy je przetwarzać.</p><p>Od razu zaznaczę, że historyczne kursy walut są świetnie prezentowane na stronie:</p><p><a href=\"https://stooq.com/\">https://stooq.com/</a></p><p>Za przykład weźmy kurs franka szwajcarskiego:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-16-19-13-56.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"564\" height=\"358\"><figcaption>https://stooq.com/q/?s=chfpln&amp;c=mx&amp;t=l&amp;a=ln&amp;b=0</figcaption></figure><p>Aby pobrać te dane wystarczy przejść na stronę:</p><p><a href=\"https://stooq.com/q/d/?s=chfpln\">https://stooq.com/q/d/?s=chfpln</a></p><p>i kliknąć przycisk poniżej tabeli</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-16-19-16-59.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>https://stooq.com/q/d/l/?s=chfpln&amp;i=d</figcaption></figure><p>W tym artykule nie rozwiązuję <em>realnego problemu</em>, tylko prezentuję możliwe do zastosowania <em>metody strukturyzacji danych <strong>na przykładzie</strong></em> konkretnego zbioru plików o niespójnej i nieprzewidywalnej konwencji.</p><p>Kolejno przejdziemy przez problemy:</p><ol><li>Pobrania danych</li><li>Przetworzenia ich</li><li>Wyświetlenia wykresu</li></ol><p>Główną wartością dla czytelnika jest śledzenie całego procesu od początku do końca i poznanie stosowanych tu narzędzi.</p><hr><p>Dane z kursami pobierzemy ze strony</p><blockquote><a href=\"https://www.nbp.pl/home.aspx?f=/kursy/arch_a.html\">https://www.nbp.pl/home.aspx?f=/kursy/arch_a.html</a></blockquote><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-02-13-13-17-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"614\" height=\"583\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-02-13-13-17-1.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-02-13-13-17-1.png 614w\"></figure><p>Dane są podzielone na osobne arkusze <code>xls</code>.</p><h1 id=\"pobranie-danych\">Pobranie danych</h1><p>Zaczniemy od pobrania tych danych. Z kodu <code>HTML</code> odczytujemy selektor.</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-02-14-16-42.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1434\" height=\"408\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-02-14-16-42.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-02-14-16-42.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-02-14-16-42.png 1434w\"></figure><p>W konsoli przeglądarki wpisujemy:</p><pre><code class=\"language-js\">[...document.querySelectorAll('.normal_2 a')]\n    .map(a =&gt; `wget ${a.href}`)\n    .filter(link =&gt; /archiwum_tab/.test(link))\n    .join(' &amp;&amp; ')</code></pre><p>Wynikiem jest połączona <code>&amp;&amp;</code> lista poleceń <code>wget</code> pobierających kolejne pliki. </p><pre><code class=\"language-bash\">wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2020.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2021.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2010.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2011.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2012.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2013.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2014.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2015.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2016.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2017.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2018.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2019.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2000.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2001.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2002.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2003.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2004.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2005.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2006.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2007.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2008.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2009.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1990.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1991.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1992.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1993.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1994.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1995.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1996.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1997.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1998.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1999.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1984.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1985.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1986.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1987.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1988.xls &amp;&amp; wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1989.xls</code></pre><p>Po wklejeniu ich do terminala pliki zostaną pobrane na nasz komputer.</p><p>Zalecam stosowanie konwencji w której takie surowe pobrane z internetu pliki lądują w osobnym katalogu np <code>raw</code>.</p><h1 id=\"konwersja\">Konwersja</h1><p>Wykonujemy konwersję wszystkich plików do formatu <code>csv</code> ponieważ jest wygodniejszy w przetwarzaniu maszynowym niż <code>xls</code>.</p><pre><code class=\"language-bash\">for i in *.xls; do  libreoffice --headless --convert-to csv \"$i\" ; done                                                     </code></pre><p>Po wykonaniu tej komendy w naszym katalogu zobaczymy zarówno pliki <code>xls</code> jak i odpowiadające im <code>csv</code>.</p><h1 id=\"strukturyzacja\">Strukturyzacja</h1><p>Niestety osoby przygotowujące te pliki nie zadbały o trzymanie wspólnej konwencji i pierwszy wiersz czasami należy wyrzucić, innym razem zawiera nazwy waluty, kraju a jeszcze innym kod waluty.</p><p>Co możemy z tym zrobić?</p><p>Najlepiej ustalić własną normę zapisu i ujednolicić strukturę danych w obrębie całego zbioru.</p><p>Konwencja zapisu dat, walut i kursów: </p><ul><li>data YYYY-MM-DD - ponieważ wygodnie się sortuje i jest to naturalny format dat w wielu językach</li><li>waluta - za pomocą kodu ISO_4217 (3 literowy kod walut)</li><li>kurs - za pomocą formatu z kropką do oznaczania ułamków</li></ul><p>Konwencja struktury danych (kompozycji):</p><ul><li>JSON w którym pierwszy klucz to waluta a drugi to data, wartość to wartość w złotówkach - ten format pozwala łatwo wyszukiwać po walutach a następnie po datach, wygodnie rzutuje się go względem walut. Mimo narzutu objętościowego względem CSV łatwość dalszego procesowania jest tu czynnikiem decydującym.</li></ul><p>Kiedy mamy już konwencję możemy napisać kod. Użyjemy do tego <code>typescript</code>.</p><h2 id=\"przygotowanie-projektu\">Przygotowanie projektu</h2><p>Zaczynamy projekt komendami</p><pre><code class=\"language-bash\">tsc --init\nnpm init -y\nnpm install chai\nnpm i --save-dev @types/node @types/chai\ntouch app.ts</code></pre><p>Paczka którą zainstalowaliśmy - <code>chai</code> pozwoli nam na pisanie testów automatycznych sprawdzających zgodność wyników z naszymi oczekiwaniami. Oszczędzi nam to czas na ich manualną weryfikację.</p><p>Do zadania powinniśmy dobrać strukturę katalogów i paradygmat. W naszym przypadku zakładamy max 100 linii kodu przetwarzającego i z tego powodu wystarczy jeden plik z proceduralnym kodem o szkielecie:</p><pre><code class=\"language-typescript\">// declarations\nimports ...\n\nconstants ...\n\nfunctions ...\n\nmain function\n\n// execution\nconsole.log(main())</code></pre><h2 id=\"odczyt-plik-w\">Odczyt plików</h2><p>Pierwszą funkcją będzie tu <code>main</code>. Zaczniemy od pokazania listy plików.</p><pre><code class=\"language-ts\">import fs from 'fs'\nimport chai from 'chai'\n\nconst main = () =&gt; {\n    const rawDir = process.cwd() + `/raw`\n\n    const res = fs.readdirSync(rawDir).filter(f =&gt; f.endsWith('csv'));\n    res.forEach(r =&gt; chai.expect(r).to.be.a('string'))\n\n    return res;\n}\n\nconsole.dir(main(), {depth: Infinity, maxArrayLength: Infinity})</code></pre><p>Wykonanie komendą </p><pre><code class=\"language-bash\"> ts-node app.ts</code></pre><p>Daje nazwy plików, które przetworzymy:</p><pre><code class=\"language-json\">[\n  'archiwum_tab_a_1984.csv',\n  'archiwum_tab_a_1985.csv',\n...</code></pre><p>Dzięki linii korzystającej z <code>chai</code> mamy pewność, że wszystkie wyniki mają odpowiedni typ. Teraz może to nie robić wrażenia, ale na późniejszym etapie takie testowanie pozwoli nam szybko wykrywać i łatać błędy związane z odkrywaniem kolejnych niuansów w konwencji użytej w badanych plikach. </p><p>Aby wyświetlić zawartość pierwszego pliku skorzystamy z funkcji <code>readFileSync</code>. Wybór filtrów i map nie jest przypadkowy. Te funkcje wraz z reduce idealnie nadają się do przetwarzania danych i zobaczymy je tu jeszcze wiele razy.</p><pre><code class=\"language-diff\">import fs from 'fs'\nimport chai from 'chai'\n\n+ const FILES_FILTER = (e: string, i: number) =&gt; i &lt;= 0\n\nconst main = () =&gt; {\n  const rawDir = process.cwd() + `/raw`\n\n  const res = fs.readdirSync(rawDir).filter(f =&gt; f.endsWith('csv'))\n+    .filter(FILES_FILTER)\n+    .map((name, i) =&gt; {\n+      return fs\n+        .readFileSync(`${rawDir}/${name}`)\n+        .toString()\n+    })\n  res.forEach(r =&gt; chai.expect(r).to.be.a('string'))\n  return res;\n}\n\nconsole.dir(main(), {depth: Infinity, maxArrayLength: Infinity})</code></pre><p>Okazuje się, że pierwszy plik nie zawiera kodów walut.</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-03-23-41-05.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1918\" height=\"145\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-03-23-41-05.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-03-23-41-05.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-03-23-41-05.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-03-23-41-05.png 1918w\"></figure><p>Więc zmuszeni jesteśmy do zbudowania słownika, który mapuje nazwy krajów na kody walutowe.</p><pre><code class=\"language-ts\">const dict: { [key: string]: string } = {\n  'Szwajcaria': 'CHF'\n}</code></pre><h2 id=\"przetworzenie-nag-wk-w\">Przetworzenie nagłówków</h2><p>Przyjrzenie się nagłówkom definiuje też podstawowe reguły dalszego przetwarzania.</p><ol><li>Mamy w pierwszym wierszu wykonać wyszukanie nazwy kraju. </li><li>Na tej podstawie ustalić kolumnę <code>col</code> w której znajdują się dane.</li><li>W drugim wierszu w kolumnie <code>col</code> znajduje się dzielnik <code>div</code></li><li>Później bierzemy tylko te wiersze, które zawierają datę w pierwszej kolumnie.</li><li>W tych wierszach w kolumnie <code>col</code> znajduje się wartość, która powinna być podzielona przez dzielnik <code>div</code> aby mieć wartość kursu walutowego.</li></ol><p>Dzięki interfejsom w TypeScript możemy zdefiniować jak będzie wyglądała nasza docelowa struktura danych z pojedynczego pliku:</p><pre><code class=\"language-ts\">interface YearData {\n  [key: string]: {\n    col: number,\n    div: number,\n    values: { [key: string]: number }[]\n  }\n}</code></pre><p>Linię zwracającą zawartość pliku:</p><pre><code class=\"language-ts\">return fs.readFileSync(`${rawDir}/${name}`).toString()</code></pre><p>zmienimy na przypisanie do stałej <code>arr</code> tablicy tablic z plikiem <code>csv</code> rozbitym na znakach nowej linii oraz przecinkach</p><pre><code class=\"language-ts\">const arr = fs\n  .readFileSync(`${rawDir}/${name}`)\n  .toString()\n  .split(`\\n`)\n  .map(l =&gt; l.split(','));</code></pre><p>Do rozkładu pierwszej linii posłuży nam funkcja:</p><pre><code class=\"language-ts\">const decomposeBaseSettingsFromNames = (localArr: string[]) =&gt; localArr.reduce((p: YearData, n: string, i: number): YearData =&gt; {\n  if (Object.keys(dict).includes(n)) {\n    p[dict[n]] = { col: i, div: 1, values: [] }\n  }\n  return p\n}, {})</code></pre><p>Użyjemy jej zaraz po rozłożeniu pliku na tablicę <code>arr</code> w liniach</p><pre><code class=\"language-ts\">const head = arr.shift()\nif (!head) throw Error('File do not have header line.')\nlet settings: YearData = decomposeBaseSettingsFromNames(head)</code></pre><p>W przypadku sukcesu ustawienia będą zawierały klucz <code>CHF</code> z dobrze wyliczoną wartością kolumny. Do tego była nam potrzebna funkcja <code>decomposeBaseSettingsFromNames</code>, zwróćmy jednak uwagę, że wartość dzielnika ustawiłem na <code>1</code>. To dlatego, że dzielniki są dopiero w kolejnej linii. Znajdziemy je dzięki następującym liniom:</p><pre><code class=\"language-ts\">if (Object.keys(settings).length) {\n  const subHead = arr.shift()\n  if (!subHead) throw Error('File do not have sub-header line.')\n  Object.keys(settings).forEach(key =&gt; {\n    settings[key].div = parseInt(subHead[settings[key].col])\n  })\n}\n\nreturn settings;</code></pre><p>Zmianie ulegnie też test i obecnie przyjmie formę:</p><pre><code>res.forEach(r =&gt; {\n        chai.expect(r).to.haveOwnProperty('CHF');\n        chai.expect(r.CHF).to.haveOwnProperty('col');\n        chai.expect(r.CHF).to.haveOwnProperty('div');\n        chai.expect(r.CHF).to.haveOwnProperty('values');\n        chai.expect(r.CHF.col).to.be.a('number');\n        chai.expect(r.CHF.div).to.be.a('number');\n        chai.expect(r.CHF.values).to.be.a('array');\n    })</code></pre><p>Wykonanie powyższego kodu da nam</p><pre><code class=\"language-json\">[ { CHF: { col: 25, div: 1, values: [] } } ]</code></pre><p>I jest to świetny wynik, ponieważ dokładnie takie wartości mieliśmy wydobyć z pierwszego pliku. Mówi nam on, że kolumna z funtami znajduje się na 26 pozycji (numerujemy od 0) oraz, że dzielnik to 1. Używamy go głównie przy okazji denominacji, więc w roku <code>1984</code> nie był nam potrzebny.</p><p>Cały kod <code>app.ts</code> na tym etapie można znaleźć pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/nbp/-/blob/ccd18f1f1f96ad13fad8157101f7632c4c1df73b/app.ts\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">app.ts · ccd18f1f1f96ad13fad8157101f7632c4c1df73b · gustawdaniel / nbp</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><h2 id=\"przetworzenie-warto-ci\">Przetworzenie wartości</h2><p>Daty w formacie <code>DD.MM.YYYY</code>, nie pasują do opisanej przez nas konwencji więc piszemy konwerter </p><pre><code class=\"language-ts\">const getDate = (input: string) =&gt; {\n  if (/\\d{2}\\.\\d{2}\\.\\d{4}/.test(input)) {\n    return input.split('.').reverse().join('-')\n  }\n  return false\n}\n</code></pre><p>Teraz za przetworzeniem nagłówków możemy dodać kod strukturyzujący wartości kursów </p><pre><code class=\"language-ts\">arr.forEach(localArr =&gt; {\n  const date = getDate(localArr[0])\n  if (typeof date === 'string') {\n    Object.keys(settings).forEach(key =&gt; {\n      settings[key].values.push({ [date]: parseFloat(localArr[settings[key].col]) / settings[key].div })\n    })\n  }\n})</code></pre><p>Jak widzimy nagłówki były najtrudniejszą częścią. Kiedy je mamy, to ułożenie samych wartości staje się formalnością. Wykonanie kodu daje:</p><pre><code class=\"language-json\">[\n  {\n    CHF: {\n      col: 28,\n      div: 1,\n      values: [\n        { '1984-01-02': 140.84 },\n        { '1984-01-09': 140.08 },\n        { '1984-01-16': 138.62 },\n...</code></pre><p>Test poprawnej struktury danych mógł by wyglądać tak:</p><pre><code>    res.forEach(r =&gt; {\n        chai.expect(r).to.haveOwnProperty('CHF');\n        chai.expect(r.CHF).to.haveOwnProperty('col');\n        chai.expect(r.CHF).to.haveOwnProperty('div');\n        chai.expect(r.CHF).to.haveOwnProperty('values');\n        chai.expect(r.CHF.col).to.be.a('number');\n        chai.expect(r.CHF.div).to.be.a('number');\n        chai.expect(r.CHF.values).to.be.a('array');\n        r.CHF.values.forEach(v =&gt; {\n            chai.expect(Object.keys(v)[0]).to.be.a('string');\n            chai.expect(/\\d{4}-\\d{2}-\\d{2}/.test(Object.keys(v)[0])).to.be.true;\n            chai.expect(Object.values(v)[0]).to.be.a('number');\n            chai.expect(Object.values(v)[0]).to.be.greaterThan(0);\n        })\n    })</code></pre><p>Cały kod można przejrzeć tutaj:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/nbp/-/blob/9d401a925bc9e115dfaf9efe6528484f62cf2263/app.ts\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">app.ts · 9d401a925bc9e115dfaf9efe6528484f62cf2263 · gustawdaniel / nbp</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><p>Tu artykuł by mógł kończyć się połączeniem plików jedną funkcją i prezentacją ostatecznego wyniku...</p><p>Jednak tak nie jest. Teraz zaczyna się brudna robota z wykrywaniem niespójności w konwencji plików n NBP.</p><h2 id=\"normalizacja-i-czyszczenie-danych\">Normalizacja i czyszczenie danych</h2><p>Jeśli sprawdzimy za pomocą tego kodu plik <code>6</code> ustawiając funkcję filtrującą pliki na taką:</p><pre><code class=\"language-ts\">const FILES_FILTER = (e: string, i: number) =&gt; i === 5</code></pre><p>to wynik będzie zaskakująco rozczarowujący</p><pre><code class=\"language-json\">[ { CHF: { col: 27, div: 1, values: [] } } ]</code></pre><p>Aby to zdebugować za linią:</p><pre><code class=\"language-ts\">.split(`\\n`)</code></pre><p>dodamy </p><pre><code class=\"language-ts\">.filter(ROWS_FILTER)</code></pre><p>z wartością <code>ROWS_FILTER</code> zdefiniowaną jako</p><pre><code class=\"language-ts\">const ROWS_FILTER = (e: string, i: number) =&gt; i &lt;= 4\n</code></pre><p>Aby uczynić czytanie bardziej wygodne wyświetliłem chwilowo tablicę <code>arr</code> używając <code>console.table</code> i wycinając tylko najciekawsze kolumny:</p><pre><code class=\"language-ts\">console.table(arr.map(l =&gt; l.filter((e,i) =&gt; i &lt; 5 || Math.abs(i - 30) &lt; 4)));\n</code></pre><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-00-43-43.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1276\" height=\"162\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-04-00-43-43.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-04-00-43-43.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-00-43-43.png 1276w\"></figure><p>Co widzimy?</p><p>Że zmieniła się konwencja zapisu daty na <code>MM/DD/YYYY</code>.</p><p>Problem obsłużymy rozszerzając konwerter dat o kolejny <code>if</code></p><pre><code class=\"language-ts\">if (/\\d{2}\\/\\d{2}\\/\\d{4}/.test(input)) {\n  const [m, d, y] = input.split('/')\n  return [y, m, d].join('-')\n}</code></pre><p>Możemy dodać też filter, który usunie spacje z nazw krajów:</p><pre><code class=\"language-ts\">const DROP_SPACES = (l: string): string =&gt; l.replace(/\\s+/g, '')</code></pre><p>włożoną do mapy za linią</p><pre><code class=\"language-ts\">.split(`\\n`)</code></pre><p>Pozwoli to na traktowanie kraju <code>W. Brytania</code> oraz <code>W.Brytania</code> tak samo.</p><p>Po tych zmianach wprowadzimy też zmianę w testowaniu. Wymusimy niezerową długość wartości z cenami. Przeniesiemy też testowanie do osobnej funkcji </p><pre><code class=\"language-ts\">const testYearData = (r:YearData):void =&gt; {\n    chai.expect(r).to.haveOwnProperty('CHF');\n    chai.expect(r.CHF).to.haveOwnProperty('col');\n    chai.expect(r.CHF).to.haveOwnProperty('div');\n    chai.expect(r.CHF).to.haveOwnProperty('values');\n    chai.expect(r.CHF.col).to.be.a('number');\n    chai.expect(r.CHF.div).to.be.a('number');\n    chai.expect(r.CHF.values).to.be.a('array');\n    chai.expect(r.CHF.values.length).to.be.greaterThan(0);\n    r.CHF.values.forEach(v =&gt; {\n        chai.expect(Object.keys(v)[0]).to.be.a('string');\n        chai.expect(/\\d{4}-\\d{2}-\\d{2}/.test(Object.keys(v)[0])).to.be.true;\n        chai.expect(Object.values(v)[0]).to.be.a('number');\n        chai.expect(Object.values(v)[0]).to.be.greaterThan(0);\n    })\n};</code></pre><p>I wykonujmy ją przez zwróceniem <code>settings</code>.</p><pre><code class=\"language-ts\">testYearData(settings);</code></pre><p>Po odblokowaniu filtrów</p><pre><code class=\"language-ts\">const FILES_FILTER = (e: string, i: number) =&gt; i &lt; Infinity\nconst ROWS_FILTER = (e: string, i: number) =&gt; i &lt;= Infinity</code></pre><p>Wykonanie zakończy się błędem</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-12-17-50.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"352\" height=\"48\"></figure><p>Dzięki liniom z pozwalającym na debug:</p><pre><code class=\"language-ts\">console.table(arr.map(l =&gt; l.filter((e,i) =&gt; i &lt; 3 || Math.abs(i - 27) &lt; 5)));</code></pre><p>oraz </p><pre><code class=\"language-ts\">console.dir(settings, {depth: Infinity});\n</code></pre><p>widzimy, że problemem są zupełnie puste linie.</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-12-19-38.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1463\" height=\"201\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-12-19-38.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-12-19-38.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-12-19-38.png 1463w\"></figure><p>Przyczyną błędu jest sztywne trzymanie się konkretnego wiersza jako miejsca gdzie trzymamy dzielniki czy nazwy walut, a tymczasem powinniśmy skasować puste linie przez wykryciem nagłówków.</p><p>Jest to powszechny problem przy parsowaniu plików excel. Użytkownicy mogąc przygotować dane w bardzo dowolnej strukturze często nie trzymają się konwencji umieszczania nagłówków w tan sam sposób we wszystkich plikach.</p><p>Użyjemy tu funkcji <code>test</code> i wyrażenia regularnego oznaczającego same przecinki lub nic w całej linii:</p><pre><code class=\"language-ts\">const DROP_EMPTY_LINES = (e:string) =&gt; !/^,*$/.test(e)</code></pre><p>Dołączymy ją za <code>DROP_SPACES</code> w funkcji <code>filter</code>.</p><pre><code class=\"language-ts\">const arr = fs\n  .readFileSync(`${rawDir}/${name}`)\n  .toString()\n  .split(`\\n`)\n  .map(DROP_SPACES)\n  .filter(DROP_EMPTY_LINES)\n  .filter(ROWS_FILTER)\n  .map(l =&gt; l.split(',')</code></pre><p>Tym razem znowu nie działa. Powodem jest bardzo nietypowa linia w jednym z plików.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-03-49-20.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"480\" height=\"143\"></figure><p> Korekta Kursu z 1987? Jak to? Faktycznie w <code>xls</code> mamy coś takiego:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-03-52-11.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"337\" height=\"67\"></figure><p>Jednak dotyczy ona waluty <code>ECU</code> więc najrozsądniej jest pominąć tą linię zaostrzając kryteria rozpoznawania dat.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-04-05-50.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"981\" height=\"263\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-04-04-05-50.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-04-05-50.png 981w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Cały kod z tego etapu znajduje się pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/nbp/-/blob/845527b631054744329b53293bfbf6705956b361/app.ts\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">app.ts · 845527b631054744329b53293bfbf6705956b361 · gustawdaniel / nbp</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><p>Jednak jego wykonanie wciąż powoduje błędy</p><pre><code class=\"language-json\">[\n  {\n    CHF: {\n      col: 27,\n      div: NaN,\n      values: [ { '1988-12-27': NaN }, { '1989-01-02': NaN } ]\n    }\n  }\n]</code></pre><p>Po głębszym sprawdzeniu okazuje się, że problem stanowi linia, która była prawie pusta, ale nie całkowicie pusta:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-01-02-13.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"329\" height=\"127\"></figure><p>Ktoś umieścił w niej <code>Nr</code> na zupełnie nie znaczącej kolumnie. Wracamy więc do kodu i usuniemy tą linię kolejnym filtrem: <code>DROP_JUNK_LINES</code>, umieszczonym przed <code>DROP_EMPTY_LINES</code>.</p><p>Kiedy pisałem ten kod wracałem do tego filtru jeszcze kilka razy. Nie będę odtwarzał tego tym razem lecz uproszczę i podam finalną wartość tej funkcji:</p><pre><code class=\"language-ts\">const DROP_JUNK_LINES = (l: string): string =&gt; l.replace(/(Nr)|(data)|(WALUTA\\/CURRENCY)|(\\.tab)/ig, '')\n</code></pre><p>Okazało się, że w tej linii były:</p><ul><li>Nr</li><li>data</li><li>Waluta/Currency</li><li>.tab</li></ul><p>Te rzeczy czasami z dużych liter, a co mnie najbardziej zaskoczyło było też `W A L U T A / C U R R E N C Y`. Na szczęście dzięki mapie <code>DROP_SPACES</code> i flagom <code>g</code> oraz <code>i</code> w mapie <code>DROP_JUNK_LINES</code> filter <code>DROP_EMPTY_LINES</code> traktuje te wszystkie linie jako tak samo puste czyli potrzebne.</p><pre><code class=\"language-diff\">     .split(`\\n`)\n     .map(DROP_SPACES)\n+    .map(DROP_JUNK_LINES)\n     .filter(DROP_EMPTY_LINES)\n     .filter(ROWS_FILTER)\n</code></pre><p>Po wprowadzeniu tych poprawek możemy zobaczyć wymaganą strukturę dla kolejnych plików:</p><pre><code class=\"language-json\">[\n  {\n    CHF: {\n      col: 30,\n      div: 1,\n      values: [\n        { '1988-12-27': 910.9 },\n        { '1989-01-02': 904.29 },\n        { '1989-01-09': 915.44 }\n...</code></pre><p>Link do zmiany w kodzie</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/nbp/-/commit/fd13a96ceb1effe2471445a1e954600fb51c56af\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Dropped junk lines (fd13a96c) · Commits · gustawdaniel / nbp</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><p>Wystarczy jednak zmienić przetworzyć kilka kolejnych plików aby wrócić do punktu wyjścia, zobaczyć</p><pre><code class=\"language-json\">[ {} ]</code></pre><p>i naprawiać od nowa.</p><p>Co stało się tym razem?</p><p>Pomoże nam wydrukowanie tablicy z plikiem <code>CSV</code> po przetworzeniu</p><pre><code class=\"language-ts\">console.table(arr.map(e =&gt; e.filter((e,i) =&gt; i &lt; 10)));</code></pre><p>żeby zobaczyć zupełnie nową organizację nagłówka oraz zmianę kolumny z datą</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-01-16-10.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"811\" height=\"119\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-04-01-16-10.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-01-16-10.png 811w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Tym razem zarówno waluta jak i dzielnik umieszczone są w tej samej linii. Więc obsłużymy przypadek <code>else</code> po linii</p><pre><code class=\"language-ts\">if (Object.keys(settings).length) {</code></pre><p>użyjemy do tego funkcji <code>decomposeBaseSettingsFromCodes</code> zdefiniowanej jako </p><pre><code class=\"language-ts\">const decomposeBaseSettingsFromCodes = (localArr: string[]) =&gt; localArr.reduce((p: YearData, n: string, i: number): YearData =&gt; {\n  const [, div, curr] = n.match(/^(\\d+)(\\w+)$/) || []\n  if (parseInt(div) &amp;&amp; curr &amp;&amp; Object.values(dict).includes(curr)) {\n    p[curr] = { col: i, div: parseInt(div), values: [] }\n  }\n  return p\n}, {})</code></pre><p>Co ona zmienia? </p><ul><li>Rozkłada za pomocą <code>match</code> wartość na dzielnik <code>div</code> oraz kod waluty</li><li>Nie potrzebuje kolejnej instrukcji <code>shift</code> do wydobycia dzielnika</li></ul><p>Z tego względu zostanie ona wkomponowana w kod następująco</p><pre><code class=\"language-ts\">const head = arr.shift()\nif (!head) throw Error('File do not have header line.')\nlet settings: YearData = decomposeBaseSettingsFromNames(head)\nif (Object.keys(settings).length) {\n  const subHead = arr.shift()\n  if (!subHead) throw Error('File do not have sub-header line.')\n  Object.keys(settings).forEach(key =&gt; {\n    settings[key].div = parseInt(subHead[settings[key].col])\n  })\n} else {\n  settings = decomposeBaseSettingsFromCodes(head)\n}</code></pre><p>Kolejny problem to liczby porządkowe w pierwszej kolumnie zamiast dat. Datami zajmiemy się zastępując funkcję <code>getDate</code> funkcją <code>getDateFromArr</code></p><pre><code class=\"language-ts\">const getDateFromArr = (arr: string[]) =&gt; {\n  return getDate(arr[0]) || getDate(arr[1])\n}</code></pre><p>teraz jest ona używana tak:</p><pre><code class=\"language-diff\">arr.forEach(localArr =&gt; {\n-  const date = getDate(localArr[0])\n+  const date = getDateFromArr(localArr)\n  if (typeof date === 'string') {\n    Object.keys(settings).forEach(key =&gt; {\n      settings[key].values.push({ [date]: parseFloat(localArr[settings[key].col]) / settings[key].div })\n    })\n  }\n})</code></pre><p>Poprawki można zobaczyć w commicie:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/nbp/-/commit/81db32a6bb6d1b25569680a1605961d6efa8b190\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Fixed decoding codes and column with indexes (81db32a6) · Commits · gustawdaniel / nbp</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><p>Czy to wszystkie problemy? Absolutnie nie. W roku 2008 zastosowano jeszcze inną konwencję.</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-10-20-49.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1516\" height=\"159\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-10-20-49.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-05-10-20-49.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-10-20-49.png 1516w\"></figure><p>Polega ona na nie umieszczeniu nigdzie \"Szwajcaria\", ani nigdzie \"1CHF\", zatem obie metody rozpoznające zawodzą. Co powinniśmy zrobić? Możemy rozpisać algorytm rozpoznawania nagłówków następująco:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-10-40-20.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"607\" height=\"738\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-10-40-20.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-10-40-20.png 607w\"></figure><p>Kolorem pomarańczowym zaznaczyliśmy brakujące elementy.</p><p>Ponieważ wyszukiwanie dzielnika się powtarza wydzielimy to do osobnej funkcji:</p><pre><code class=\"language-ts\">const extendSettingsByDivCoefficient = (arr: string[][], settings: YearData) =&gt; {\n  const subHead = arr.shift()\n  if (!subHead) throw Error('File do not have sub-header line.')\n  Object.keys(settings).forEach(key =&gt; {\n    settings[key].div = parseInt(subHead[settings[key].col])\n  })\n}</code></pre><p>Nie powinniśmy trzymać w <code>main</code> zbyt dużo kodu, bo traci on czytelność, więc całą logikę rozpoznawania nagłówków wyrzucamy do osobnej funkcji:</p><pre><code class=\"language-ts\">const recognizeSettingsFromHead = (arr: string[][]):YearData =&gt; {\n  const head = arr.shift()\n  if (!head) throw Error('File do not have header line.')\n  let settings: YearData = decomposeBaseSettingsFromNames(head)\n  if (Object.keys(settings).length) {\n    extendSettingsByDivCoefficient(arr, settings);\n  } else {\n    settings = decomposeBaseSettingsFromCodes(head);\n    while (Object.keys(settings).some(key =&gt; Number.isNaN(settings[key].div))) {\n      extendSettingsByDivCoefficient(arr, settings);\n    }\n  }\n  \n  return settings;\n}</code></pre><p>W main zostanie w tym miejscu tylko:</p><pre><code>const settings = recognizeSettingsFromHead(arr);</code></pre><p>Dla parsowania dzielników kluczowy stał się warunek:</p><pre><code>Number.isNaN(settings[key].div)</code></pre><p>Zatem w rozkładzie ustawień na kody nie możemy już optymistycznie zakładać ustawienia tam <code>1</code> jako wartości domyślnej, ani wymuszać wystąpienia liczby przy kodzie waluty, anie wymagać.</p><p>Zmiany w funkcjach wykonujących wcześniej przetwarzanie nagłówków wyglądają tak</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-11-01-30.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1914\" height=\"262\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-11-01-30.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-05-11-01-30.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-05-11-01-30.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-11-01-30.png 1914w\"></figure><p>W ten sposób natomiast wygląda ich aktualny kod</p><pre><code class=\"language-ts\">const decomposeBaseSettingsFromNames = (localArr: string[]) =&gt; localArr.reduce((p: YearData, n: string, i: number): YearData =&gt; {\n    if (Object.keys(dict).includes(n)) {\n        p[dict[n]] = { col: i, div: NaN, values: [] }\n    }\n    return p\n}, {})\n\nconst decomposeBaseSettingsFromCodes = (localArr: string[]) =&gt; localArr.reduce((p: YearData, n: string, i: number): YearData =&gt; {\n    const [, div, curr] = n.match(/^(\\d*)(\\w+)$/) || []\n    if (curr &amp;&amp; Object.values(dict).includes(curr)) {\n        p[curr] = { col: i, div: parseInt(div), values: [] }\n    }\n    return p\n}, {})</code></pre><p>Całość projektu na tym etapie:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/nbp/-/blob/4bca2afc7fcac9779ea4afdf0bcda89a08f6ab52/app.ts\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">app.ts · 4bca2afc7fcac9779ea4afdf0bcda89a08f6ab52 · gustawdaniel / nbp</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><p>Jak widać, czyszczenie danych jest żmudnym procesem w którym problemy nigdy się nie kończą. Na szczęście te dane napływają w tempie jeden plik na rok i wygląda na to, że udało się je ustrukturyzować zanim upłynął ten czas.</p><p>Wykonanie kodu komendą</p><pre><code class=\"language-bash\">ts-node app.ts</code></pre><p>wyświetli długie listy tabel i konfiguracji, ale nie rzuci żadnego błędu.</p><h2 id=\"-czenie-plik-w\">Łączenie plików</h2><p>Do połączenia plików wymagane są:</p><p>1. dodanie typu wynikowego</p><pre><code class=\"language-ts\">interface OutData {\n  [key: string]: {\n    [key: string]: number\n  }\n}</code></pre><p>3. Przygotowanie funkcji łączącej</p><pre><code class=\"language-ts\">const mergeYears = (payload: YearData[]): OutData =&gt; {\n  return payload.reduce((p: OutData, n: YearData) =&gt; {\n    Object.keys(n).forEach(key =&gt; {\n      if (p.hasOwnProperty(key)) {\n        p[key] = {...p[key], ...n[key].values.reduce((p,n) =&gt; ({...p,...n}))}\n      } else {\n        p[key] = n[key].values.reduce((p,n) =&gt; ({...p,...n}))\n      }\n    })\n    return p\n  }, {})\n}\n</code></pre><p>4. Dołączenie <code>mergeYears</code> przed <code>return</code> w funkcji <code>main</code>.</p><pre><code class=\"language-ts\">return mergeYears(fs.readdirSync(rawDir).filter(f =&gt; f.endsWith('csv'))\n</code></pre><p>Wprowadzenie tych zmian pozwala zobaczyć kursy z całego zakresu</p><pre><code class=\"language-json\">{\n  CHF: {\n    '1984-01-02': 140.84,\n    '1984-01-09': 140.08,\n    '1984-01-16': 138.62,\n...</code></pre><p>Aby zapisać wynik dopiszemy lini:</p><pre><code class=\"language-ts\">!fs.existsSync(process.cwd() + '/out') &amp;&amp; fs.mkdirSync(process.cwd() + '/out', {recursive: true})\nfs.writeFileSync(process.cwd() + '/out/chf.json', JSON.stringify(main()))</code></pre><p>Wykonanie:</p><pre><code class=\"language-bash\">time ts-node app.ts</code></pre><p>zwróci:</p><pre><code class=\"language-bash\">ts-node app.ts  7.67s user 0.29s system 147% cpu 5.412 total</code></pre><p>i spowoduje utworzenie pliku <code>/out/chf.json</code> o wadze <code>156K</code>. </p><p>Plik projektu zawierający <code>126</code> linii kodu dostępny jest pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/nbp/-/blob/12edf429a1ddba80f04f29e0f9d2a0309aa372e2/app.ts\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">app.ts · 12edf429a1ddba80f04f29e0f9d2a0309aa372e2 · gustawdaniel / nbp</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><p>Jeśli potrzebujesz tych danych, możesz samodzielnie odtworzyć wszystkie kroki lub pobrać gotowe dane JSON z linku</p><p><a href=\"https://goofy-franklin-2f9df8.netlify.app/chf.json\"><a href=\"https://chf-pln.netlify.app/chf.json\">https://chf-pnl.netlify.app/chf.json</a></a></p><h1 id=\"wizualizacja\">Wizualizacja</h1><p>Nie mogę się oprzeć pokusie narysowania i omówienia kursu Franka Szwajcarskiego kiedy już udało mi się wydobyć kurs sprzed tak wielu lat. Szczególnie interesujący jest okres przed początkiem obecnego stulecia i boomem na kredyty w CHF z lat 2005-2008. </p><h2 id=\"przygotowanie-projektu-1\">Przygotowanie projektu</h2><p>Do rysowania wykresów posłuży nam plik <code>index.html</code> o zawartości:</p><pre><code class=\"language-html\">&lt;html&gt;\n&lt;body&gt;\n&lt;script src=\"./index.ts\"&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre><p>oraz pustego <code>index.ts</code>. Teraz instalujemy <code>parcel</code></p><pre><code class=\"language-bash\">npm install -g parcel-bundler</code></pre><p>Jest to narzędzie do budowania jak <code>webpack</code>, <code>gulp</code> czy <code>grunt</code> z tym, że w przeciwieństwie do wymienionych jego konfiguracja nie zajmuje setek lat i nie wymaga wklejania konfiguracja oraz szukania paczek.</p><p>Po wpisaniu:</p><pre><code class=\"language-bash\">parcel index.html</code></pre><p>zobaczymy komunikat o zbudowaniu oraz link do strony</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-02-14-30.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"468\" height=\"75\"></figure><p>Po otworzeniu linku i konsoli deweloperskiej a następnie dodaniu do <code>index.ts</code> linii <code><em><strong>console</strong></em>.log(\"test\")</code> zobaczymy automatyczne przeładowanie się strony i wpisanie \"test\" do konsoli. </p><h2 id=\"integracja-biblioteki-do-wykres-w\">Integracja biblioteki do wykresów</h2><p>Do rysowania wykresów użyjemy Apex Chatrs.</p><pre><code class=\"language-bash\">npm install apexcharts --save\n</code></pre><p>Do body w pliku <code>index.html</code> dołączymy:</p><pre><code>&lt;main id='chart'&gt;&lt;/main&gt;</code></pre><p>żeby móc przyczepić wykres. Natomiast w <code>index.ts</code> konfigurację prostego wykresu giełdowego</p><pre><code class=\"language-js\">import ApexCharts from 'apexcharts'\n\nconst options = {\n  series: [{\n    data: [{\n      x: new Date(1538778600000),\n      y: [6629.81, 6650.5, 6623.04, 6633.33]\n    },\n      {\n        x: new Date(1538780400000),\n        y: [6632.01, 6643.59, 6620, 6630.11]\n      }\n    ]\n  }],\n  chart: {\n    type: 'candlestick',\n    height: 350\n  },\n  title: {\n    text: 'CandleStick Chart',\n    align: 'left'\n  },\n  xaxis: {\n    type: 'datetime'\n  },\n  yaxis: {\n    tooltip: {\n      enabled: true\n    }\n  }\n};\n\nconst chart = new ApexCharts(document.querySelector(\"#chart\"), options);\nchart.render().then(console.log).catch(console.error);\n</code></pre><p>Można powiedzieć - super prostego:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-02-29-51.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1254\" height=\"362\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-04-02-29-51.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-04-02-29-51.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-02-29-51.png 1254w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Jednak ta prostota ma cel. Pozwala nie zaśmiecać artykułu testowymi danymi, tylko kiedy już mamy strukturę danych do wykresu możemy wykonać transformację naszej struktury wydobytej z plików <code>xls</code>.</p><h2 id=\"u-o-enie-danych-na-wykresie\">Ułożenie danych na wykresie</h2><p>Podsumujmy:</p><ol><li>Nasza struktura</li></ol><pre><code>{\n  CHF: {\n    'YYYY-MM-DD': number,\n    ...\n  }\n}</code></pre><p>Struktura do wykresu:</p><pre><code>{\n  x: Date,\n  y: [number, number, number, number] // open, high, low, close\n}[]</code></pre><p>Aby wykonać tą transformację musimy podzielić nasze dane na zakresy, to znaczy wybrać ile świec ma zawierać wykres. Następnie po wyliczeniu granicznych dat będziemy iterować po zakresach wybierając z dostępnych dat te, które mieszczą się w zakresie, z nich z kolei wyszukamy wartości początkowe, końcowe oraz skrajne.</p><p>Zaczniemy od importu pliku z danymi zapisanym przez skrypt z poprzedniej części:</p><pre><code class=\"language-ts\">import {CHF} from './out/chf.json'\n</code></pre><p>Aby to poprawnie obsłużyć w pliku <code>tsconfig.json</code> dodajemy flagę <code>resolveJsonModule</code></p><pre><code class=\"language-json\">{\n  \"compilerOptions\": {\n    \"resolveJsonModule\": true,\n    ...</code></pre><p>Teraz definiujemy interfejs z danymi wyjściowymi</p><pre><code class=\"language-ts\">interface StockRecord {\n  x: Date,\n  y: [number, number, number, number]\n}</code></pre><p>Do rozkładu funkcji na interwały wykorzystamy funkcję:</p><pre><code class=\"language-ts\">const splitDateIntoEqualIntervals = (startDate: Date, endDate: Date, numberOfIntervals: number): { start: Date, end: Date, avg: Date }[] =&gt; {\n  const intervalLength = (endDate.getTime() - startDate.getTime()) / numberOfIntervals\n  return [...(new Array(numberOfIntervals))]\n    .map((e, i) =&gt; {\n      return {\n        start: new Date(startDate.getTime() + i * intervalLength),\n        avg: new Date(startDate.getTime() + (i + 0.5) * intervalLength),\n        end: new Date(startDate.getTime() + (i + 1) * intervalLength)\n      }\n    })\n}</code></pre><p>opisaną pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://stackoverflow.com/questions/63273494/divide-date-range-into-known-number-of-equal-chunks\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">divide date range into known number of equal chunks</div><div class=\"kg-bookmark-description\">I’ve seen Split date range into date range chunksand Split date range into several specific date range chunks, that is not what I’m looking for.I’m looking for simple function from momenjs, that ...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v&#x3D;c78bd457575a\"><span class=\"kg-bookmark-author\">Stack Overflow</span><span class=\"kg-bookmark-publisher\">deathfry</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v&#x3D;73d79a89bded\"></div></a></figure><p>Samo mapowanie danych zostało ułożone w kolejnej funkcji</p><pre><code class=\"language-ts\">const mapToStockData = (values: { [key: string]: number }, parts: number):StockRecord[] =&gt; {\n  const entries = Object.entries(values)\n  const start = new Date(entries[0][0])\n  const end = new Date(entries[entries.length - 1][0])\n  const intervals = splitDateIntoEqualIntervals(start, end, parts)\n\n  const stockData: StockRecord[] = []\n\n  while (intervals.length) {\n    const int = intervals.shift()\n    if (!int) break\n    let currDate = int.start\n    stockData.push({\n      x: int.avg,\n      y: [NaN, NaN, NaN, NaN]\n    })\n\n    const currStock = stockData[stockData.length - 1]\n    let stat = {\n      min: Infinity,\n      max: -Infinity\n    }\n\n    while (currDate &lt; int.end) {\n      const [dateString, value] = entries.shift() || []\n      if (!dateString || typeof value !== 'number') break\n      currDate = new Date(dateString)\n      if (isNaN(currStock.y[0])) currStock.y[0] = value\n      currStock.y[3] = value\n      stat.min = Math.min(stat.min, value)\n      stat.max = Math.max(stat.max, value)\n    }\n    currStock.y[1] = stat.max\n    currStock.y[2] = stat.min\n  }\n\n  return stockData\n}</code></pre><p>Ten dłuższy fragment kodu wymaga komentarza. Można było to zadanie zrealizować za pomocą map filtrów i pętli forEach, ale wybrałem podwójny while z podwójnym shiftem. Nie jest to przypadek. W tym wypadku chodzi o wydajność. O ile te bardziej modne i eleganckie metody są zawsze moim pierwszym wyborem, to w przypadku gdy redukcja złożoności obliczeniowej wymaga trzymania pewnego rodzaju cache robię wyjątek. Komunikacja między osobnymi wykonaniami metod <code>map</code>, <code>filter</code>, <code>reduce</code>, <code>forEach</code> jest trudniejsza, wymaga posługiwania się zmiennymi z wyższego zakresu. W szczególności zagnieżdżanie pętli domyślnie zakłada wykonanie <code>n x m</code> operacji gdzie <code>n</code> i <code>m</code> są wymiarami tablic. U nas jednak chcę wykonać raczej <code>n + m</code> przebiegów, nie chcę dwa razy przetwarzać, odrzucać, filtrować czy sprawdzać tego samego klucza w obiekcie z kursami jeśli to nie jest potrzebne. </p><p>O jakiej oszczędności mówimy?   </p><p>Jeśli ten kod został by napisany nie wydajnie i nie ułożyli byśmy dobrze iteracji to może wyglądał by na bardziej czytelny i zwięzły, ale przy granulacji na 500 świec wykonał by <code>7200 x 500 = 3.6e6</code> pętli, tym czasem mamy ich około <code>7200 + 500 = 7.7e4</code> czyli około 50 razy krótszy czas ładowania.</p><p>Generowanie opcji to po prostu funkcja wkładająca dane do szablonu konfiguracji Apex Chart</p><pre><code class=\"language-ts\">const generateOptions = (data: StockRecord[]) =&gt; ({\n  series: [{\n    data\n  }],\n  chart: {\n    type: 'candlestick',\n    height: window.innerHeight - 50,\n    zoom: {\n      autoScaleYaxis: true\n    }\n  },\n  title: {\n    text: 'CandleStick Chart',\n    align: 'left'\n  },\n  xaxis: {\n    type: 'datetime'\n  },\n  yaxis: {\n    tooltip: {\n      enabled: true\n    }\n  }\n})</code></pre><p>Na końcu wykonanie programu, czyli załączenie danych do konfiguracji i utworzenie za jej pomocą wykresu:</p><pre><code>const chart = new ApexCharts(document.querySelector('#chart'), generateOptions(mapToStockData(CHF, 500)))\nchart.render().then(console.log).catch(console.error)\n</code></pre><p>Wykres wygląda świetnie. Idealnie oddaje realia walutowego dzikiego zachodu z początku lat 90. Widzimy jak w 1991 inflacja wywindowała cenę franka o rzędy wielkości, oraz drastyczny spadek na początku 1995 spowodowany wejściem w życie ustawy o denominacji z 7 lipca 1994.</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-34-49.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1907\" height=\"1006\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-14-34-49.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-14-34-49.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-17-14-34-49.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-34-49.png 1907w\"></figure><p>Nie wykrytym wcześniej problemem okazuje się tutaj błędne skalowanie z roku 1995.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-36-04.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1161\" height=\"1054\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-14-36-04.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-14-36-04.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-36-04.png 1161w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Faktycznie mamy zmianę mnożnika w trakcie roku 1995</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-40-24.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1620\" height=\"109\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-14-40-24.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-14-40-24.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-17-14-40-24.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-40-24.png 1620w\"></figure><p>Ten problem możemy naprawić dodając linie przestawiające dzielnik jeśli jego zmiana nastąpi między wartościami, a nie w nagłówku:</p><pre><code class=\"language-diff\">             arr.forEach(localArr =&gt; {\n                 const date = getDateFromArr(localArr)\n+\n+                const newSettings = decomposeBaseSettingsFromCodes(localArr)\n+                if (Object.keys(newSettings).length) {\n+                    Object.keys(settings).forEach(key =&gt; {\n+                        settings[key].div = newSettings[key].div\n+                    })\n+                }\n+\n                 if (typeof date === 'string') {\n                     Object.keys(settings).forEach(key =&gt; {\n</code></pre><p>Kolejną zmianą będzie wprowadzenie normalizacji. Jeśli chcemy porównywać wartości na wykresie powinniśmy uwzględnić denominację. Pomoże nam w tym funkcja</p><pre><code class=\"language-ts\">const denominationFactor = (date:string): number =&gt; {\n    return Number.parseInt(date.substr(0,4)) &lt;= 1994 ? 1e4 : 1;\n}</code></pre><p>i włączenie jej wyniku w linii:</p><pre><code class=\"language-ts\">settings[key].values.push({[date]: parseFloat(localArr[settings[key].col]) / settings[key].div / denominationFactor(date)})\n</code></pre><p>Ponowne wygenerowanie danych pozwala zobaczyć wykres</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-56-59.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1916\" height=\"1115\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-14-56-59.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-14-56-59.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-17-14-56-59.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-14-56-59.png 1916w\"></figure><p>Aby wykonać deployment użyjemy serwisu Netlify.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://chf-pln.netlify.app/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Kurs CHF w PLN</div><div class=\"kg-bookmark-description\">Wykres kursu Polskiej złotówki wzglęm Franka Szwajcarskiego. Od 1995 są PLN, wcześniej były PLZ.</div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">Precise Lab</span><span class=\"kg-bookmark-publisher\">Daniel Gustaw</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://blog.gustawdaniel.com/content/images/size/w1000/2021/02/Screenshot-from-2021-02-04-04-56-56.png\"></div></a></figure><p>W tym celu dołączamy <code>parcel</code> do zależności deweloperskich projektu:</p><pre><code> npm install -D parcel-bundler</code></pre><p>I dodajemy w <code>package.json</code> komendę budującą</p><pre><code class=\"language-json\">  \"scripts\": {\n    \"build\": \"parcel build index.html\",\n  },</code></pre><p>Po wybraniu w panelu Netlify katalogu <code>dist</code> oraz komendy <code>npm run build</code> możemy cieszyć się skonfigurowanym deploymentem CI.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-06-15-27.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1271\" height=\"954\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-04-06-15-27.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-04-06-15-27.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-04-06-15-27.png 1271w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Na koniec kurs CHF od końcówki lat 90 do czasów współczesnych</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-11-09-21.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1849\" height=\"1016\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-11-09-21.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-05-11-09-21.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-05-11-09-21.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-11-09-21.png 1849w\"></figure><p>Tu dobrze widać, że rosnące osoby biorące kredyty w CHF w roku 2004 mogły przez 5 lat cieszyć się spadkiem siły nabywczej swojego zadłużenia, kolejne 4 lata wartość franka wracała do pierwotnego poziomu, lecz wówczas kredyt mógł być już spłacony. Osoby biorące go w latach 2006-2007 popełniały błąd zakładając, że ten trend będzie się utrzymywał przez dziesięciolecia.</p><h1 id=\"wnioski\">Wnioski</h1><p>Czasami zdarza się, że w internecie nie potrafimy znaleźć danych, których potrzebujemy. W rozważanym scenariuszu potrzebowaliśmy pełnej historii kursu CHF do PLN. W takim przypadku może się zdarzyć, że musimy je składać samodzielnie. Jest to uciążliwe zadanie jeśli dane te są zaśmiecone ludzkimi modyfikacjami i nie mają nałożonej jednolitej struktury. Narysowanie wykresu, wybranie nagłówków oraz danych łącznie zajęło tyle samo czasu co poprawki i debugowanie oraz zmiany w logice spowodowane odkrywaniem różnych konwencji i zapisów w plikach NBP.</p><p>Jeśli chcesz ze mną porozmawiać o problemie podobnym do tego umów się na niezobowiązującą, bezpłatną konsultację.</p><!--kg-card-begin: html--><!-- Calendly inline widget begin -->\n<div class=\"calendly-inline-widget\" data-url=\"https://calendly.com/gustaw-daniel?hide_gdpr_banner=1\" style=\"min-width:320px;height:630px;\"></div>\n<script type=\"text/javascript\" src=\"https://assets.calendly.com/assets/external/widget.js\"></script>\n<!-- Calendly inline widget end --><!--kg-card-end: html--><p>Możesz też napisać do nas wypełniając formularz:</p><!--kg-card-begin: html--><iframe class=\"clickup-embed clickup-dynamic-height\" src=\"https://forms.clickup.com/f/21qbj-1184/44GF096HL1E9EGEGUW\" onwheel=\"\" width=\"100%\" height=\"100%\" style=\"background: transparent; border: 1px solid #ccc;\"></iframe><script async src=\"https://app-cdn.clickup.com/assets/js/forms-embed/v1.js\"></script><!--kg-card-end: html--><hr><p>Artykuły, które pomogły w przygotowaniu tego wpisu</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.bankier.pl/wiadomosc/Zlote-czasy-franka-jak-sie-zaczal-kredytowy-boom-2894462.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Złote czasy franka - jak się zaczął kredytowy boom?</div><div class=\"kg-bookmark-description\">Nagła kredytowa kariera szwajcarskiego franka sprawiła, że tysiące Polaków co najmniej raz w miesiącu z niepokojem zerkają na notowania. Popularność zobowiązań w helweckiej walucie była wynikiem zbiegu kilku okoliczności w określonym momencie gospodarczej historii Polski. Kredytobiorcy, którzy w poł…</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.bankier.pl/favicon.ico\"><span class=\"kg-bookmark-author\">Bankier.pl</span><span class=\"kg-bookmark-publisher\">Michał Kisiel</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://galeria.bankier.pl/p/0/f/c054fce945dcfc-thumb-2500.jpg\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://muzhp.pl/pl/e/1357/denominacja-zlotego\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Denominacja złotego - Muzeum Historii Polski</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://muzhp.pl/assets/favicon.ico\"><span class=\"kg-bookmark-author\">Muzeum Historii Polski</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://muzhp.pl/files/events/13/57/800_img.jpg\"></div></a></figure>",
            "comment_id": "601940361446cd10bd8d9dae",
            "plaintext": "Strukturyzacja danych to nadawanie danym kształtu pozwalającego na ich analizę i\nwygodne przetwarzanie. W tym wpisie pokażę jak może wyglądać taki proces na\nprzykładzie danych pochodzących z NBP, które są składowane w plikach, których\nkonwencja układania nagłówków ulegała zmianom na przestrzeni lat. \n\nDane z NBP nie nadają się przez to do natychmiastowego użycia i należy je\nuporządkować, jeśli chcieli byśmy je przetwarzać.\n\nOd razu zaznaczę, że historyczne kursy walut są świetnie prezentowane na\nstronie:\n\nhttps://stooq.com/\n\nZa przykład weźmy kurs franka szwajcarskiego:\n\nhttps://stooq.com/q/?s=chfpln&c=mx&t=l&a=ln&b=0Aby pobrać te dane wystarczy\nprzejść na stronę:\n\nhttps://stooq.com/q/d/?s=chfpln\n\ni kliknąć przycisk poniżej tabeli\n\nhttps://stooq.com/q/d/l/?s=chfpln&i=dW tym artykule nie rozwiązuję realnego problemu, tylko prezentuję możliwe do\nzastosowania metody strukturyzacji danych na przykładzie konkretnego zbioru\nplików o niespójnej i nieprzewidywalnej konwencji.\n\nKolejno przejdziemy przez problemy:\n\n 1. Pobrania danych\n 2. Przetworzenia ich\n 3. Wyświetlenia wykresu\n\nGłówną wartością dla czytelnika jest śledzenie całego procesu od początku do\nkońca i poznanie stosowanych tu narzędzi.\n\n\n--------------------------------------------------------------------------------\n\nDane z kursami pobierzemy ze strony\n\n> https://www.nbp.pl/home.aspx?f=/kursy/arch_a.html\nDane są podzielone na osobne arkusze xls.\n\nPobranie danych\nZaczniemy od pobrania tych danych. Z kodu HTML odczytujemy selektor.\n\nW konsoli przeglądarki wpisujemy:\n\n[...document.querySelectorAll('.normal_2 a')]\n    .map(a => `wget ${a.href}`)\n    .filter(link => /archiwum_tab/.test(link))\n    .join(' && ')\n\nWynikiem jest połączona && lista poleceń wget pobierających kolejne pliki. \n\nwget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2020.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2021.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2010.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2011.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2012.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2013.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2014.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2015.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2016.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2017.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2018.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2019.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2000.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2001.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2002.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2003.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2004.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2005.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2006.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2007.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2008.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_2009.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1990.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1991.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1992.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1993.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1994.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1995.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1996.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1997.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1998.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1999.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1984.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1985.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1986.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1987.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1988.xls && wget https://www.nbp.pl/kursy/Archiwum/archiwum_tab_a_1989.xls\n\nPo wklejeniu ich do terminala pliki zostaną pobrane na nasz komputer.\n\nZalecam stosowanie konwencji w której takie surowe pobrane z internetu pliki\nlądują w osobnym katalogu np raw.\n\nKonwersja\nWykonujemy konwersję wszystkich plików do formatu csv ponieważ jest wygodniejszy\nw przetwarzaniu maszynowym niż xls.\n\nfor i in *.xls; do  libreoffice --headless --convert-to csv \"$i\" ; done                                                     \n\nPo wykonaniu tej komendy w naszym katalogu zobaczymy zarówno pliki xls jak i\nodpowiadające im csv.\n\nStrukturyzacja\nNiestety osoby przygotowujące te pliki nie zadbały o trzymanie wspólnej\nkonwencji i pierwszy wiersz czasami należy wyrzucić, innym razem zawiera nazwy\nwaluty, kraju a jeszcze innym kod waluty.\n\nCo możemy z tym zrobić?\n\nNajlepiej ustalić własną normę zapisu i ujednolicić strukturę danych w obrębie\ncałego zbioru.\n\nKonwencja zapisu dat, walut i kursów: \n\n * data YYYY-MM-DD - ponieważ wygodnie się sortuje i jest to naturalny format\n   dat w wielu językach\n * waluta - za pomocą kodu ISO_4217 (3 literowy kod walut)\n * kurs - za pomocą formatu z kropką do oznaczania ułamków\n\nKonwencja struktury danych (kompozycji):\n\n * JSON w którym pierwszy klucz to waluta a drugi to data, wartość to wartość w\n   złotówkach - ten format pozwala łatwo wyszukiwać po walutach a następnie po\n   datach, wygodnie rzutuje się go względem walut. Mimo narzutu objętościowego\n   względem CSV łatwość dalszego procesowania jest tu czynnikiem decydującym.\n\nKiedy mamy już konwencję możemy napisać kod. Użyjemy do tego typescript.\n\nPrzygotowanie projektu\nZaczynamy projekt komendami\n\ntsc --init\nnpm init -y\nnpm install chai\nnpm i --save-dev @types/node @types/chai\ntouch app.ts\n\nPaczka którą zainstalowaliśmy - chai pozwoli nam na pisanie testów\nautomatycznych sprawdzających zgodność wyników z naszymi oczekiwaniami.\nOszczędzi nam to czas na ich manualną weryfikację.\n\nDo zadania powinniśmy dobrać strukturę katalogów i paradygmat. W naszym\nprzypadku zakładamy max 100 linii kodu przetwarzającego i z tego powodu\nwystarczy jeden plik z proceduralnym kodem o szkielecie:\n\n// declarations\nimports ...\n\nconstants ...\n\nfunctions ...\n\nmain function\n\n// execution\nconsole.log(main())\n\nOdczyt plików\nPierwszą funkcją będzie tu main. Zaczniemy od pokazania listy plików.\n\nimport fs from 'fs'\nimport chai from 'chai'\n\nconst main = () => {\n    const rawDir = process.cwd() + `/raw`\n\n    const res = fs.readdirSync(rawDir).filter(f => f.endsWith('csv'));\n    res.forEach(r => chai.expect(r).to.be.a('string'))\n\n    return res;\n}\n\nconsole.dir(main(), {depth: Infinity, maxArrayLength: Infinity})\n\nWykonanie komendą \n\n ts-node app.ts\n\nDaje nazwy plików, które przetworzymy:\n\n[\n  'archiwum_tab_a_1984.csv',\n  'archiwum_tab_a_1985.csv',\n...\n\nDzięki linii korzystającej z chai mamy pewność, że wszystkie wyniki mają\nodpowiedni typ. Teraz może to nie robić wrażenia, ale na późniejszym etapie\ntakie testowanie pozwoli nam szybko wykrywać i łatać błędy związane z\nodkrywaniem kolejnych niuansów w konwencji użytej w badanych plikach. \n\nAby wyświetlić zawartość pierwszego pliku skorzystamy z funkcji readFileSync.\nWybór filtrów i map nie jest przypadkowy. Te funkcje wraz z reduce idealnie\nnadają się do przetwarzania danych i zobaczymy je tu jeszcze wiele razy.\n\nimport fs from 'fs'\nimport chai from 'chai'\n\n+ const FILES_FILTER = (e: string, i: number) => i <= 0\n\nconst main = () => {\n  const rawDir = process.cwd() + `/raw`\n\n  const res = fs.readdirSync(rawDir).filter(f => f.endsWith('csv'))\n+    .filter(FILES_FILTER)\n+    .map((name, i) => {\n+      return fs\n+        .readFileSync(`${rawDir}/${name}`)\n+        .toString()\n+    })\n  res.forEach(r => chai.expect(r).to.be.a('string'))\n  return res;\n}\n\nconsole.dir(main(), {depth: Infinity, maxArrayLength: Infinity})\n\nOkazuje się, że pierwszy plik nie zawiera kodów walut.\n\nWięc zmuszeni jesteśmy do zbudowania słownika, który mapuje nazwy krajów na kody\nwalutowe.\n\nconst dict: { [key: string]: string } = {\n  'Szwajcaria': 'CHF'\n}\n\nPrzetworzenie nagłówków\nPrzyjrzenie się nagłówkom definiuje też podstawowe reguły dalszego\nprzetwarzania.\n\n 1. Mamy w pierwszym wierszu wykonać wyszukanie nazwy kraju. \n 2. Na tej podstawie ustalić kolumnę col w której znajdują się dane.\n 3. W drugim wierszu w kolumnie col znajduje się dzielnik div\n 4. Później bierzemy tylko te wiersze, które zawierają datę w pierwszej\n    kolumnie.\n 5. W tych wierszach w kolumnie col znajduje się wartość, która powinna być\n    podzielona przez dzielnik div aby mieć wartość kursu walutowego.\n\nDzięki interfejsom w TypeScript możemy zdefiniować jak będzie wyglądała nasza\ndocelowa struktura danych z pojedynczego pliku:\n\ninterface YearData {\n  [key: string]: {\n    col: number,\n    div: number,\n    values: { [key: string]: number }[]\n  }\n}\n\nLinię zwracającą zawartość pliku:\n\nreturn fs.readFileSync(`${rawDir}/${name}`).toString()\n\nzmienimy na przypisanie do stałej arr tablicy tablic z plikiem csv rozbitym na\nznakach nowej linii oraz przecinkach\n\nconst arr = fs\n  .readFileSync(`${rawDir}/${name}`)\n  .toString()\n  .split(`\\n`)\n  .map(l => l.split(','));\n\nDo rozkładu pierwszej linii posłuży nam funkcja:\n\nconst decomposeBaseSettingsFromNames = (localArr: string[]) => localArr.reduce((p: YearData, n: string, i: number): YearData => {\n  if (Object.keys(dict).includes(n)) {\n    p[dict[n]] = { col: i, div: 1, values: [] }\n  }\n  return p\n}, {})\n\nUżyjemy jej zaraz po rozłożeniu pliku na tablicę arr w liniach\n\nconst head = arr.shift()\nif (!head) throw Error('File do not have header line.')\nlet settings: YearData = decomposeBaseSettingsFromNames(head)\n\nW przypadku sukcesu ustawienia będą zawierały klucz CHF z dobrze wyliczoną\nwartością kolumny. Do tego była nam potrzebna funkcja \ndecomposeBaseSettingsFromNames, zwróćmy jednak uwagę, że wartość dzielnika\nustawiłem na 1. To dlatego, że dzielniki są dopiero w kolejnej linii. Znajdziemy\nje dzięki następującym liniom:\n\nif (Object.keys(settings).length) {\n  const subHead = arr.shift()\n  if (!subHead) throw Error('File do not have sub-header line.')\n  Object.keys(settings).forEach(key => {\n    settings[key].div = parseInt(subHead[settings[key].col])\n  })\n}\n\nreturn settings;\n\nZmianie ulegnie też test i obecnie przyjmie formę:\n\nres.forEach(r => {\n        chai.expect(r).to.haveOwnProperty('CHF');\n        chai.expect(r.CHF).to.haveOwnProperty('col');\n        chai.expect(r.CHF).to.haveOwnProperty('div');\n        chai.expect(r.CHF).to.haveOwnProperty('values');\n        chai.expect(r.CHF.col).to.be.a('number');\n        chai.expect(r.CHF.div).to.be.a('number');\n        chai.expect(r.CHF.values).to.be.a('array');\n    })\n\nWykonanie powyższego kodu da nam\n\n[ { CHF: { col: 25, div: 1, values: [] } } ]\n\nI jest to świetny wynik, ponieważ dokładnie takie wartości mieliśmy wydobyć z\npierwszego pliku. Mówi nam on, że kolumna z funtami znajduje się na 26 pozycji\n(numerujemy od 0) oraz, że dzielnik to 1. Używamy go głównie przy okazji\ndenominacji, więc w roku 1984 nie był nam potrzebny.\n\nCały kod app.ts na tym etapie można znaleźć pod linkiem:\n\napp.ts · ccd18f1f1f96ad13fad8157101f7632c4c1df73b · gustawdaniel /\nnbpGitLab.com\nGitLab\n[https://gitlab.com/gustawdaniel/nbp/-/blob/ccd18f1f1f96ad13fad8157101f7632c4c1df73b/app.ts]\nPrzetworzenie wartości\nDaty w formacie DD.MM.YYYY, nie pasują do opisanej przez nas konwencji więc\npiszemy konwerter \n\nconst getDate = (input: string) => {\n  if (/\\d{2}\\.\\d{2}\\.\\d{4}/.test(input)) {\n    return input.split('.').reverse().join('-')\n  }\n  return false\n}\n\n\nTeraz za przetworzeniem nagłówków możemy dodać kod strukturyzujący wartości\nkursów \n\narr.forEach(localArr => {\n  const date = getDate(localArr[0])\n  if (typeof date === 'string') {\n    Object.keys(settings).forEach(key => {\n      settings[key].values.push({ [date]: parseFloat(localArr[settings[key].col]) / settings[key].div })\n    })\n  }\n})\n\nJak widzimy nagłówki były najtrudniejszą częścią. Kiedy je mamy, to ułożenie\nsamych wartości staje się formalnością. Wykonanie kodu daje:\n\n[\n  {\n    CHF: {\n      col: 28,\n      div: 1,\n      values: [\n        { '1984-01-02': 140.84 },\n        { '1984-01-09': 140.08 },\n        { '1984-01-16': 138.62 },\n...\n\nTest poprawnej struktury danych mógł by wyglądać tak:\n\n    res.forEach(r => {\n        chai.expect(r).to.haveOwnProperty('CHF');\n        chai.expect(r.CHF).to.haveOwnProperty('col');\n        chai.expect(r.CHF).to.haveOwnProperty('div');\n        chai.expect(r.CHF).to.haveOwnProperty('values');\n        chai.expect(r.CHF.col).to.be.a('number');\n        chai.expect(r.CHF.div).to.be.a('number');\n        chai.expect(r.CHF.values).to.be.a('array');\n        r.CHF.values.forEach(v => {\n            chai.expect(Object.keys(v)[0]).to.be.a('string');\n            chai.expect(/\\d{4}-\\d{2}-\\d{2}/.test(Object.keys(v)[0])).to.be.true;\n            chai.expect(Object.values(v)[0]).to.be.a('number');\n            chai.expect(Object.values(v)[0]).to.be.greaterThan(0);\n        })\n    })\n\nCały kod można przejrzeć tutaj:\n\napp.ts · 9d401a925bc9e115dfaf9efe6528484f62cf2263 · gustawdaniel /\nnbpGitLab.com\nGitLab\n[https://gitlab.com/gustawdaniel/nbp/-/blob/9d401a925bc9e115dfaf9efe6528484f62cf2263/app.ts]\nTu artykuł by mógł kończyć się połączeniem plików jedną funkcją i prezentacją\nostatecznego wyniku...\n\nJednak tak nie jest. Teraz zaczyna się brudna robota z wykrywaniem niespójności\nw konwencji plików n NBP.\n\nNormalizacja i czyszczenie danych\nJeśli sprawdzimy za pomocą tego kodu plik 6 ustawiając funkcję filtrującą pliki\nna taką:\n\nconst FILES_FILTER = (e: string, i: number) => i === 5\n\nto wynik będzie zaskakująco rozczarowujący\n\n[ { CHF: { col: 27, div: 1, values: [] } } ]\n\nAby to zdebugować za linią:\n\n.split(`\\n`)\n\ndodamy \n\n.filter(ROWS_FILTER)\n\nz wartością ROWS_FILTER zdefiniowaną jako\n\nconst ROWS_FILTER = (e: string, i: number) => i <= 4\n\n\nAby uczynić czytanie bardziej wygodne wyświetliłem chwilowo tablicę arr używając \nconsole.table i wycinając tylko najciekawsze kolumny:\n\nconsole.table(arr.map(l => l.filter((e,i) => i < 5 || Math.abs(i - 30) < 4)));\n\n\nCo widzimy?\n\nŻe zmieniła się konwencja zapisu daty na MM/DD/YYYY.\n\nProblem obsłużymy rozszerzając konwerter dat o kolejny if\n\nif (/\\d{2}\\/\\d{2}\\/\\d{4}/.test(input)) {\n  const [m, d, y] = input.split('/')\n  return [y, m, d].join('-')\n}\n\nMożemy dodać też filter, który usunie spacje z nazw krajów:\n\nconst DROP_SPACES = (l: string): string => l.replace(/\\s+/g, '')\n\nwłożoną do mapy za linią\n\n.split(`\\n`)\n\nPozwoli to na traktowanie kraju W. Brytania oraz W.Brytania tak samo.\n\nPo tych zmianach wprowadzimy też zmianę w testowaniu. Wymusimy niezerową długość\nwartości z cenami. Przeniesiemy też testowanie do osobnej funkcji \n\nconst testYearData = (r:YearData):void => {\n    chai.expect(r).to.haveOwnProperty('CHF');\n    chai.expect(r.CHF).to.haveOwnProperty('col');\n    chai.expect(r.CHF).to.haveOwnProperty('div');\n    chai.expect(r.CHF).to.haveOwnProperty('values');\n    chai.expect(r.CHF.col).to.be.a('number');\n    chai.expect(r.CHF.div).to.be.a('number');\n    chai.expect(r.CHF.values).to.be.a('array');\n    chai.expect(r.CHF.values.length).to.be.greaterThan(0);\n    r.CHF.values.forEach(v => {\n        chai.expect(Object.keys(v)[0]).to.be.a('string');\n        chai.expect(/\\d{4}-\\d{2}-\\d{2}/.test(Object.keys(v)[0])).to.be.true;\n        chai.expect(Object.values(v)[0]).to.be.a('number');\n        chai.expect(Object.values(v)[0]).to.be.greaterThan(0);\n    })\n};\n\nI wykonujmy ją przez zwróceniem settings.\n\ntestYearData(settings);\n\nPo odblokowaniu filtrów\n\nconst FILES_FILTER = (e: string, i: number) => i < Infinity\nconst ROWS_FILTER = (e: string, i: number) => i <= Infinity\n\nWykonanie zakończy się błędem\n\nDzięki liniom z pozwalającym na debug:\n\nconsole.table(arr.map(l => l.filter((e,i) => i < 3 || Math.abs(i - 27) < 5)));\n\noraz \n\nconsole.dir(settings, {depth: Infinity});\n\n\nwidzimy, że problemem są zupełnie puste linie.\n\nPrzyczyną błędu jest sztywne trzymanie się konkretnego wiersza jako miejsca\ngdzie trzymamy dzielniki czy nazwy walut, a tymczasem powinniśmy skasować puste\nlinie przez wykryciem nagłówków.\n\nJest to powszechny problem przy parsowaniu plików excel. Użytkownicy mogąc\nprzygotować dane w bardzo dowolnej strukturze często nie trzymają się konwencji\numieszczania nagłówków w tan sam sposób we wszystkich plikach.\n\nUżyjemy tu funkcji test i wyrażenia regularnego oznaczającego same przecinki lub\nnic w całej linii:\n\nconst DROP_EMPTY_LINES = (e:string) => !/^,*$/.test(e)\n\nDołączymy ją za DROP_SPACES w funkcji filter.\n\nconst arr = fs\n  .readFileSync(`${rawDir}/${name}`)\n  .toString()\n  .split(`\\n`)\n  .map(DROP_SPACES)\n  .filter(DROP_EMPTY_LINES)\n  .filter(ROWS_FILTER)\n  .map(l => l.split(',')\n\nTym razem znowu nie działa. Powodem jest bardzo nietypowa linia w jednym z\nplików.\n\n Korekta Kursu z 1987? Jak to? Faktycznie w xls mamy coś takiego:\n\nJednak dotyczy ona waluty ECU więc najrozsądniej jest pominąć tą linię\nzaostrzając kryteria rozpoznawania dat.\n\nCały kod z tego etapu znajduje się pod linkiem:\n\napp.ts · 845527b631054744329b53293bfbf6705956b361 · gustawdaniel /\nnbpGitLab.com\nGitLab\n[https://gitlab.com/gustawdaniel/nbp/-/blob/845527b631054744329b53293bfbf6705956b361/app.ts]\nJednak jego wykonanie wciąż powoduje błędy\n\n[\n  {\n    CHF: {\n      col: 27,\n      div: NaN,\n      values: [ { '1988-12-27': NaN }, { '1989-01-02': NaN } ]\n    }\n  }\n]\n\nPo głębszym sprawdzeniu okazuje się, że problem stanowi linia, która była prawie\npusta, ale nie całkowicie pusta:\n\nKtoś umieścił w niej Nr na zupełnie nie znaczącej kolumnie. Wracamy więc do kodu\ni usuniemy tą linię kolejnym filtrem: DROP_JUNK_LINES, umieszczonym przed \nDROP_EMPTY_LINES.\n\nKiedy pisałem ten kod wracałem do tego filtru jeszcze kilka razy. Nie będę\nodtwarzał tego tym razem lecz uproszczę i podam finalną wartość tej funkcji:\n\nconst DROP_JUNK_LINES = (l: string): string => l.replace(/(Nr)|(data)|(WALUTA\\/CURRENCY)|(\\.tab)/ig, '')\n\n\nOkazało się, że w tej linii były:\n\n * Nr\n * data\n * Waluta/Currency\n * .tab\n\nTe rzeczy czasami z dużych liter, a co mnie najbardziej zaskoczyło było też `W A\nL U T A / C U R R E N C Y`. Na szczęście dzięki mapie DROP_SPACES i flagom g \noraz i w mapie DROP_JUNK_LINES filter DROP_EMPTY_LINES traktuje te wszystkie\nlinie jako tak samo puste czyli potrzebne.\n\n     .split(`\\n`)\n     .map(DROP_SPACES)\n+    .map(DROP_JUNK_LINES)\n     .filter(DROP_EMPTY_LINES)\n     .filter(ROWS_FILTER)\n\n\nPo wprowadzeniu tych poprawek możemy zobaczyć wymaganą strukturę dla kolejnych\nplików:\n\n[\n  {\n    CHF: {\n      col: 30,\n      div: 1,\n      values: [\n        { '1988-12-27': 910.9 },\n        { '1989-01-02': 904.29 },\n        { '1989-01-09': 915.44 }\n...\n\nLink do zmiany w kodzie\n\nDropped junk lines (fd13a96c) · Commits · gustawdaniel / nbpGitLab.comGitLab\n[https://gitlab.com/gustawdaniel/nbp/-/commit/fd13a96ceb1effe2471445a1e954600fb51c56af]\nWystarczy jednak zmienić przetworzyć kilka kolejnych plików aby wrócić do punktu\nwyjścia, zobaczyć\n\n[ {} ]\n\ni naprawiać od nowa.\n\nCo stało się tym razem?\n\nPomoże nam wydrukowanie tablicy z plikiem CSV po przetworzeniu\n\nconsole.table(arr.map(e => e.filter((e,i) => i < 10)));\n\nżeby zobaczyć zupełnie nową organizację nagłówka oraz zmianę kolumny z datą\n\nTym razem zarówno waluta jak i dzielnik umieszczone są w tej samej linii. Więc\nobsłużymy przypadek else po linii\n\nif (Object.keys(settings).length) {\n\nużyjemy do tego funkcji decomposeBaseSettingsFromCodes zdefiniowanej jako \n\nconst decomposeBaseSettingsFromCodes = (localArr: string[]) => localArr.reduce((p: YearData, n: string, i: number): YearData => {\n  const [, div, curr] = n.match(/^(\\d+)(\\w+)$/) || []\n  if (parseInt(div) && curr && Object.values(dict).includes(curr)) {\n    p[curr] = { col: i, div: parseInt(div), values: [] }\n  }\n  return p\n}, {})\n\nCo ona zmienia? \n\n * Rozkłada za pomocą match wartość na dzielnik div oraz kod waluty\n * Nie potrzebuje kolejnej instrukcji shift do wydobycia dzielnika\n\nZ tego względu zostanie ona wkomponowana w kod następująco\n\nconst head = arr.shift()\nif (!head) throw Error('File do not have header line.')\nlet settings: YearData = decomposeBaseSettingsFromNames(head)\nif (Object.keys(settings).length) {\n  const subHead = arr.shift()\n  if (!subHead) throw Error('File do not have sub-header line.')\n  Object.keys(settings).forEach(key => {\n    settings[key].div = parseInt(subHead[settings[key].col])\n  })\n} else {\n  settings = decomposeBaseSettingsFromCodes(head)\n}\n\nKolejny problem to liczby porządkowe w pierwszej kolumnie zamiast dat. Datami\nzajmiemy się zastępując funkcję getDate funkcją getDateFromArr\n\nconst getDateFromArr = (arr: string[]) => {\n  return getDate(arr[0]) || getDate(arr[1])\n}\n\nteraz jest ona używana tak:\n\narr.forEach(localArr => {\n-  const date = getDate(localArr[0])\n+  const date = getDateFromArr(localArr)\n  if (typeof date === 'string') {\n    Object.keys(settings).forEach(key => {\n      settings[key].values.push({ [date]: parseFloat(localArr[settings[key].col]) / settings[key].div })\n    })\n  }\n})\n\nPoprawki można zobaczyć w commicie:\n\nFixed decoding codes and column with indexes (81db32a6) · Commits ·\ngustawdaniel\n/ nbpGitLab.comGitLab\n[https://gitlab.com/gustawdaniel/nbp/-/commit/81db32a6bb6d1b25569680a1605961d6efa8b190]\nCzy to wszystkie problemy? Absolutnie nie. W roku 2008 zastosowano jeszcze inną\nkonwencję.\n\nPolega ona na nie umieszczeniu nigdzie \"Szwajcaria\", ani nigdzie \"1CHF\", zatem\nobie metody rozpoznające zawodzą. Co powinniśmy zrobić? Możemy rozpisać algorytm\nrozpoznawania nagłówków następująco:\n\nKolorem pomarańczowym zaznaczyliśmy brakujące elementy.\n\nPonieważ wyszukiwanie dzielnika się powtarza wydzielimy to do osobnej funkcji:\n\nconst extendSettingsByDivCoefficient = (arr: string[][], settings: YearData) => {\n  const subHead = arr.shift()\n  if (!subHead) throw Error('File do not have sub-header line.')\n  Object.keys(settings).forEach(key => {\n    settings[key].div = parseInt(subHead[settings[key].col])\n  })\n}\n\nNie powinniśmy trzymać w main zbyt dużo kodu, bo traci on czytelność, więc całą\nlogikę rozpoznawania nagłówków wyrzucamy do osobnej funkcji:\n\nconst recognizeSettingsFromHead = (arr: string[][]):YearData => {\n  const head = arr.shift()\n  if (!head) throw Error('File do not have header line.')\n  let settings: YearData = decomposeBaseSettingsFromNames(head)\n  if (Object.keys(settings).length) {\n    extendSettingsByDivCoefficient(arr, settings);\n  } else {\n    settings = decomposeBaseSettingsFromCodes(head);\n    while (Object.keys(settings).some(key => Number.isNaN(settings[key].div))) {\n      extendSettingsByDivCoefficient(arr, settings);\n    }\n  }\n  \n  return settings;\n}\n\nW main zostanie w tym miejscu tylko:\n\nconst settings = recognizeSettingsFromHead(arr);\n\nDla parsowania dzielników kluczowy stał się warunek:\n\nNumber.isNaN(settings[key].div)\n\nZatem w rozkładzie ustawień na kody nie możemy już optymistycznie zakładać\nustawienia tam 1 jako wartości domyślnej, ani wymuszać wystąpienia liczby przy\nkodzie waluty, anie wymagać.\n\nZmiany w funkcjach wykonujących wcześniej przetwarzanie nagłówków wyglądają tak\n\nW ten sposób natomiast wygląda ich aktualny kod\n\nconst decomposeBaseSettingsFromNames = (localArr: string[]) => localArr.reduce((p: YearData, n: string, i: number): YearData => {\n    if (Object.keys(dict).includes(n)) {\n        p[dict[n]] = { col: i, div: NaN, values: [] }\n    }\n    return p\n}, {})\n\nconst decomposeBaseSettingsFromCodes = (localArr: string[]) => localArr.reduce((p: YearData, n: string, i: number): YearData => {\n    const [, div, curr] = n.match(/^(\\d*)(\\w+)$/) || []\n    if (curr && Object.values(dict).includes(curr)) {\n        p[curr] = { col: i, div: parseInt(div), values: [] }\n    }\n    return p\n}, {})\n\nCałość projektu na tym etapie:\n\napp.ts · 4bca2afc7fcac9779ea4afdf0bcda89a08f6ab52 · gustawdaniel /\nnbpGitLab.com\nGitLab\n[https://gitlab.com/gustawdaniel/nbp/-/blob/4bca2afc7fcac9779ea4afdf0bcda89a08f6ab52/app.ts]\nJak widać, czyszczenie danych jest żmudnym procesem w którym problemy nigdy się\nnie kończą. Na szczęście te dane napływają w tempie jeden plik na rok i wygląda\nna to, że udało się je ustrukturyzować zanim upłynął ten czas.\n\nWykonanie kodu komendą\n\nts-node app.ts\n\nwyświetli długie listy tabel i konfiguracji, ale nie rzuci żadnego błędu.\n\nŁączenie plików\nDo połączenia plików wymagane są:\n\n1. dodanie typu wynikowego\n\ninterface OutData {\n  [key: string]: {\n    [key: string]: number\n  }\n}\n\n3. Przygotowanie funkcji łączącej\n\nconst mergeYears = (payload: YearData[]): OutData => {\n  return payload.reduce((p: OutData, n: YearData) => {\n    Object.keys(n).forEach(key => {\n      if (p.hasOwnProperty(key)) {\n        p[key] = {...p[key], ...n[key].values.reduce((p,n) => ({...p,...n}))}\n      } else {\n        p[key] = n[key].values.reduce((p,n) => ({...p,...n}))\n      }\n    })\n    return p\n  }, {})\n}\n\n\n4. Dołączenie mergeYears przed return w funkcji main.\n\nreturn mergeYears(fs.readdirSync(rawDir).filter(f => f.endsWith('csv'))\n\n\nWprowadzenie tych zmian pozwala zobaczyć kursy z całego zakresu\n\n{\n  CHF: {\n    '1984-01-02': 140.84,\n    '1984-01-09': 140.08,\n    '1984-01-16': 138.62,\n...\n\nAby zapisać wynik dopiszemy lini:\n\n!fs.existsSync(process.cwd() + '/out') && fs.mkdirSync(process.cwd() + '/out', {recursive: true})\nfs.writeFileSync(process.cwd() + '/out/chf.json', JSON.stringify(main()))\n\nWykonanie:\n\ntime ts-node app.ts\n\nzwróci:\n\nts-node app.ts  7.67s user 0.29s system 147% cpu 5.412 total\n\ni spowoduje utworzenie pliku /out/chf.json o wadze 156K. \n\nPlik projektu zawierający 126 linii kodu dostępny jest pod linkiem:\n\napp.ts · 12edf429a1ddba80f04f29e0f9d2a0309aa372e2 · gustawdaniel /\nnbpGitLab.com\nGitLab\n[https://gitlab.com/gustawdaniel/nbp/-/blob/12edf429a1ddba80f04f29e0f9d2a0309aa372e2/app.ts]\nJeśli potrzebujesz tych danych, możesz samodzielnie odtworzyć wszystkie kroki\nlub pobrać gotowe dane JSON z linku\n\nhttps://chf-pnl.netlify.app/chf.json [https://chf-pln.netlify.app/chf.json]\n[https://goofy-franklin-2f9df8.netlify.app/chf.json]\n\nWizualizacja\nNie mogę się oprzeć pokusie narysowania i omówienia kursu Franka Szwajcarskiego\nkiedy już udało mi się wydobyć kurs sprzed tak wielu lat. Szczególnie\ninteresujący jest okres przed początkiem obecnego stulecia i boomem na kredyty w\nCHF z lat 2005-2008. \n\nPrzygotowanie projektu\nDo rysowania wykresów posłuży nam plik index.html o zawartości:\n\n<html>\n<body>\n<script src=\"./index.ts\"></script>\n</body>\n</html>\n\n\noraz pustego index.ts. Teraz instalujemy parcel\n\nnpm install -g parcel-bundler\n\nJest to narzędzie do budowania jak webpack, gulp czy grunt z tym, że w\nprzeciwieństwie do wymienionych jego konfiguracja nie zajmuje setek lat i nie\nwymaga wklejania konfiguracja oraz szukania paczek.\n\nPo wpisaniu:\n\nparcel index.html\n\nzobaczymy komunikat o zbudowaniu oraz link do strony\n\nPo otworzeniu linku i konsoli deweloperskiej a następnie dodaniu do index.ts \nlinii console.log(\"test\") zobaczymy automatyczne przeładowanie się strony i\nwpisanie \"test\" do konsoli. \n\nIntegracja biblioteki do wykresów\nDo rysowania wykresów użyjemy Apex Chatrs.\n\nnpm install apexcharts --save\n\n\nDo body w pliku index.html dołączymy:\n\n<main id='chart'></main>\n\nżeby móc przyczepić wykres. Natomiast w index.ts konfigurację prostego wykresu\ngiełdowego\n\nimport ApexCharts from 'apexcharts'\n\nconst options = {\n  series: [{\n    data: [{\n      x: new Date(1538778600000),\n      y: [6629.81, 6650.5, 6623.04, 6633.33]\n    },\n      {\n        x: new Date(1538780400000),\n        y: [6632.01, 6643.59, 6620, 6630.11]\n      }\n    ]\n  }],\n  chart: {\n    type: 'candlestick',\n    height: 350\n  },\n  title: {\n    text: 'CandleStick Chart',\n    align: 'left'\n  },\n  xaxis: {\n    type: 'datetime'\n  },\n  yaxis: {\n    tooltip: {\n      enabled: true\n    }\n  }\n};\n\nconst chart = new ApexCharts(document.querySelector(\"#chart\"), options);\nchart.render().then(console.log).catch(console.error);\n\n\nMożna powiedzieć - super prostego:\n\nJednak ta prostota ma cel. Pozwala nie zaśmiecać artykułu testowymi danymi,\ntylko kiedy już mamy strukturę danych do wykresu możemy wykonać transformację\nnaszej struktury wydobytej z plików xls.\n\nUłożenie danych na wykresie\nPodsumujmy:\n\n 1. Nasza struktura\n\n{\n  CHF: {\n    'YYYY-MM-DD': number,\n    ...\n  }\n}\n\nStruktura do wykresu:\n\n{\n  x: Date,\n  y: [number, number, number, number] // open, high, low, close\n}[]\n\nAby wykonać tą transformację musimy podzielić nasze dane na zakresy, to znaczy\nwybrać ile świec ma zawierać wykres. Następnie po wyliczeniu granicznych dat\nbędziemy iterować po zakresach wybierając z dostępnych dat te, które mieszczą\nsię w zakresie, z nich z kolei wyszukamy wartości początkowe, końcowe oraz\nskrajne.\n\nZaczniemy od importu pliku z danymi zapisanym przez skrypt z poprzedniej części:\n\nimport {CHF} from './out/chf.json'\n\n\nAby to poprawnie obsłużyć w pliku tsconfig.json dodajemy flagę resolveJsonModule\n\n{\n  \"compilerOptions\": {\n    \"resolveJsonModule\": true,\n    ...\n\nTeraz definiujemy interfejs z danymi wyjściowymi\n\ninterface StockRecord {\n  x: Date,\n  y: [number, number, number, number]\n}\n\nDo rozkładu funkcji na interwały wykorzystamy funkcję:\n\nconst splitDateIntoEqualIntervals = (startDate: Date, endDate: Date, numberOfIntervals: number): { start: Date, end: Date, avg: Date }[] => {\n  const intervalLength = (endDate.getTime() - startDate.getTime()) / numberOfIntervals\n  return [...(new Array(numberOfIntervals))]\n    .map((e, i) => {\n      return {\n        start: new Date(startDate.getTime() + i * intervalLength),\n        avg: new Date(startDate.getTime() + (i + 0.5) * intervalLength),\n        end: new Date(startDate.getTime() + (i + 1) * intervalLength)\n      }\n    })\n}\n\nopisaną pod linkiem:\n\ndivide date range into known number of equal chunksI’ve seen Split date range\ninto date range chunksand Split date range into several specific date range\nchunks, that is not what I’m looking for.I’m looking for simple function from\nmomenjs, that ...Stack Overflowdeathfry\n[https://stackoverflow.com/questions/63273494/divide-date-range-into-known-number-of-equal-chunks]\nSamo mapowanie danych zostało ułożone w kolejnej funkcji\n\nconst mapToStockData = (values: { [key: string]: number }, parts: number):StockRecord[] => {\n  const entries = Object.entries(values)\n  const start = new Date(entries[0][0])\n  const end = new Date(entries[entries.length - 1][0])\n  const intervals = splitDateIntoEqualIntervals(start, end, parts)\n\n  const stockData: StockRecord[] = []\n\n  while (intervals.length) {\n    const int = intervals.shift()\n    if (!int) break\n    let currDate = int.start\n    stockData.push({\n      x: int.avg,\n      y: [NaN, NaN, NaN, NaN]\n    })\n\n    const currStock = stockData[stockData.length - 1]\n    let stat = {\n      min: Infinity,\n      max: -Infinity\n    }\n\n    while (currDate < int.end) {\n      const [dateString, value] = entries.shift() || []\n      if (!dateString || typeof value !== 'number') break\n      currDate = new Date(dateString)\n      if (isNaN(currStock.y[0])) currStock.y[0] = value\n      currStock.y[3] = value\n      stat.min = Math.min(stat.min, value)\n      stat.max = Math.max(stat.max, value)\n    }\n    currStock.y[1] = stat.max\n    currStock.y[2] = stat.min\n  }\n\n  return stockData\n}\n\nTen dłuższy fragment kodu wymaga komentarza. Można było to zadanie zrealizować\nza pomocą map filtrów i pętli forEach, ale wybrałem podwójny while z podwójnym\nshiftem. Nie jest to przypadek. W tym wypadku chodzi o wydajność. O ile te\nbardziej modne i eleganckie metody są zawsze moim pierwszym wyborem, to w\nprzypadku gdy redukcja złożoności obliczeniowej wymaga trzymania pewnego rodzaju\ncache robię wyjątek. Komunikacja między osobnymi wykonaniami metod map, filter, \nreduce, forEach jest trudniejsza, wymaga posługiwania się zmiennymi z wyższego\nzakresu. W szczególności zagnieżdżanie pętli domyślnie zakłada wykonanie n x m \noperacji gdzie n i m są wymiarami tablic. U nas jednak chcę wykonać raczej n + m \nprzebiegów, nie chcę dwa razy przetwarzać, odrzucać, filtrować czy sprawdzać\ntego samego klucza w obiekcie z kursami jeśli to nie jest potrzebne. \n\nO jakiej oszczędności mówimy? \n\nJeśli ten kod został by napisany nie wydajnie i nie ułożyli byśmy dobrze\niteracji to może wyglądał by na bardziej czytelny i zwięzły, ale przy granulacji\nna 500 świec wykonał by 7200 x 500 = 3.6e6 pętli, tym czasem mamy ich około 7200\n+ 500 = 7.7e4 czyli około 50 razy krótszy czas ładowania.\n\nGenerowanie opcji to po prostu funkcja wkładająca dane do szablonu konfiguracji\nApex Chart\n\nconst generateOptions = (data: StockRecord[]) => ({\n  series: [{\n    data\n  }],\n  chart: {\n    type: 'candlestick',\n    height: window.innerHeight - 50,\n    zoom: {\n      autoScaleYaxis: true\n    }\n  },\n  title: {\n    text: 'CandleStick Chart',\n    align: 'left'\n  },\n  xaxis: {\n    type: 'datetime'\n  },\n  yaxis: {\n    tooltip: {\n      enabled: true\n    }\n  }\n})\n\nNa końcu wykonanie programu, czyli załączenie danych do konfiguracji i\nutworzenie za jej pomocą wykresu:\n\nconst chart = new ApexCharts(document.querySelector('#chart'), generateOptions(mapToStockData(CHF, 500)))\nchart.render().then(console.log).catch(console.error)\n\n\nWykres wygląda świetnie. Idealnie oddaje realia walutowego dzikiego zachodu z\npoczątku lat 90. Widzimy jak w 1991 inflacja wywindowała cenę franka o rzędy\nwielkości, oraz drastyczny spadek na początku 1995 spowodowany wejściem w życie\nustawy o denominacji z 7 lipca 1994.\n\nNie wykrytym wcześniej problemem okazuje się tutaj błędne skalowanie z roku\n1995.\n\nFaktycznie mamy zmianę mnożnika w trakcie roku 1995\n\nTen problem możemy naprawić dodając linie przestawiające dzielnik jeśli jego\nzmiana nastąpi między wartościami, a nie w nagłówku:\n\n             arr.forEach(localArr => {\n                 const date = getDateFromArr(localArr)\n+\n+                const newSettings = decomposeBaseSettingsFromCodes(localArr)\n+                if (Object.keys(newSettings).length) {\n+                    Object.keys(settings).forEach(key => {\n+                        settings[key].div = newSettings[key].div\n+                    })\n+                }\n+\n                 if (typeof date === 'string') {\n                     Object.keys(settings).forEach(key => {\n\n\nKolejną zmianą będzie wprowadzenie normalizacji. Jeśli chcemy porównywać\nwartości na wykresie powinniśmy uwzględnić denominację. Pomoże nam w tym funkcja\n\nconst denominationFactor = (date:string): number => {\n    return Number.parseInt(date.substr(0,4)) <= 1994 ? 1e4 : 1;\n}\n\ni włączenie jej wyniku w linii:\n\nsettings[key].values.push({[date]: parseFloat(localArr[settings[key].col]) / settings[key].div / denominationFactor(date)})\n\n\nPonowne wygenerowanie danych pozwala zobaczyć wykres\n\nAby wykonać deployment użyjemy serwisu Netlify.\n\nKurs CHF w PLNWykres kursu Polskiej złotówki wzglęm Franka Szwajcarskiego. Od\n1995 są PLN, wcześniej były PLZ.Precise LabDaniel Gustaw\n[https://chf-pln.netlify.app/]W tym celu dołączamy parcel do zależności deweloperskich projektu:\n\n npm install -D parcel-bundler\n\nI dodajemy w package.json komendę budującą\n\n  \"scripts\": {\n    \"build\": \"parcel build index.html\",\n  },\n\nPo wybraniu w panelu Netlify katalogu dist oraz komendy npm run build możemy\ncieszyć się skonfigurowanym deploymentem CI.\n\nNa koniec kurs CHF od końcówki lat 90 do czasów współczesnych\n\nTu dobrze widać, że rosnące osoby biorące kredyty w CHF w roku 2004 mogły przez\n5 lat cieszyć się spadkiem siły nabywczej swojego zadłużenia, kolejne 4 lata\nwartość franka wracała do pierwotnego poziomu, lecz wówczas kredyt mógł być już\nspłacony. Osoby biorące go w latach 2006-2007 popełniały błąd zakładając, że ten\ntrend będzie się utrzymywał przez dziesięciolecia.\n\nWnioski\nCzasami zdarza się, że w internecie nie potrafimy znaleźć danych, których\npotrzebujemy. W rozważanym scenariuszu potrzebowaliśmy pełnej historii kursu CHF\ndo PLN. W takim przypadku może się zdarzyć, że musimy je składać samodzielnie.\nJest to uciążliwe zadanie jeśli dane te są zaśmiecone ludzkimi modyfikacjami i\nnie mają nałożonej jednolitej struktury. Narysowanie wykresu, wybranie nagłówków\noraz danych łącznie zajęło tyle samo czasu co poprawki i debugowanie oraz zmiany\nw logice spowodowane odkrywaniem różnych konwencji i zapisów w plikach NBP.\n\nJeśli chcesz ze mną porozmawiać o problemie podobnym do tego umów się na\nniezobowiązującą, bezpłatną konsultację.\n\nMożesz też napisać do nas wypełniając formularz:\n\n\n--------------------------------------------------------------------------------\n\nArtykuły, które pomogły w przygotowaniu tego wpisu\n\nZłote czasy franka - jak się zaczął kredytowy boom?Nagła kredytowa kariera\nszwajcarskiego franka sprawiła, że tysiące Polaków co najmniej raz w miesiącu z\nniepokojem zerkają na notowania. Popularność zobowiązań w helweckiej walucie\nbyła wynikiem zbiegu kilku okoliczności w określonym momencie gospodarczej\nhistorii Polski. Kredytobiorcy, którzy w poł…Bankier.plMichał Kisiel\n[https://www.bankier.pl/wiadomosc/Zlote-czasy-franka-jak-sie-zaczal-kredytowy-boom-2894462.html]\nDenominacja złotego - Muzeum Historii PolskiMuzeum Historii Polski\n[https://muzhp.pl/pl/e/1357/denominacja-zlotego]",
            "feature_image": "__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-16-22-47.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-02-02T12:06:14.000Z",
            "updated_at": "2021-02-17T15:21:43.000Z",
            "published_at": "2021-02-04T06:02:21.000Z",
            "custom_excerpt": "Naucz się jak napisać kod normalizujący i strukturyzujący dane w oparciu case study z dziedziny finansów.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "601d65141446cd10bd8da405",
            "uuid": "90a82aa6-b98e-460a-afae-82fbc5517241",
            "title": "Scraping z money.pl w 30 liniach kodu.",
            "slug": "scraping-libor-oraz-wibor-z-money-pl",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\",\"metadata\":{\"url\":\"https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\",\"title\":\"Archiwum notowa� dla LIBOR frank szwajcarski 3M (LIBORCHF3M), strona 1\",\"description\":\"Archiwum notowa� dla LIBOR frank szwajcarski 3M (LIBORCHF3M)\",\"author\":\"Grupa Wirtualna Polska\",\"publisher\":\"www.money.pl\",\"thumbnail\":\"https://static1.money.pl/i/wp-money.png\",\"icon\":\"https://static1.money.pl/i/favicon.ico\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-36-22.png\",\"width\":700,\"height\":367,\"cardWidth\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-37-15.png\",\"width\":446,\"height\":936}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-42-52.png\",\"width\":672,\"height\":870}],[\"code\",{\"code\":\"BASE_PREFIX${index}BASE_POSTFIX\"}],[\"code\",{\"code\":\"https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-44-34.png\",\"width\":894,\"height\":552}],[\"code\",{\"code\":\"LIBOR:\\n\\nhttps://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\\n\\nStron: 245\\n\\nWIBOR:\\n\\nhttps://www.money.pl/pieniadze/depozyty/zlotowearch/1921-02-05,2021-02-05,WIBOR3M,strona,1.html\\n\\nStron: 178\"}],[\"code\",{\"code\":\"for i in {1..1}; do wget \\\"https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,$i.html\\\" -O raw; done\"}],[\"code\",{\"code\":\"--2021-02-05 16:59:56--  https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\\nLoaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\\nResolving www.money.pl (www.money.pl)... 212.77.101.20\\nConnecting to www.money.pl (www.money.pl)|212.77.101.20|:443... connected.\\nHTTP request sent, awaiting response... 403 Forbidden\\n2021-02-05 16:59:56 ERROR 403: Forbidden.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-12-21.png\",\"width\":641,\"height\":179}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-13-43.png\",\"width\":697,\"height\":176}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-11-05.png\",\"width\":1885,\"height\":417,\"cardWidth\":\"full\"}],[\"code\",{\"code\":\"mkdir -p raw && for i in {1..245}; do http -b \\\"https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,$i.html\\\" > \\\"raw/l${i}.html\\\";echo $i; done\"}],[\"code\",{\"code\":\"mkdir -p raw && for i in {1..178}; do http -b \\\"https://www.money.pl/pieniadze/depozyty/zlotowearch/1921-02-05,2021-02-05,WIBOR3M,strona,$i.html\\\" > \\\"raw/w${i}.html\\\";echo $i; done \"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-24-23.png\",\"width\":1892,\"height\":132,\"cardWidth\":\"full\"}],[\"code\",{\"code\":\"{\\n   \\\"WIBOR3M\\\": { 'YYYY-MM-DD': value, ... },\\n   \\\"LIBORCHF3M\\\": { 'YYYY-MM-DD': value, ... }\\n}\"}],[\"code\",{\"code\":\"npm init -y && tsc --init && touch app.ts\"}],[\"code\",{\"code\":\"npm i jsdom @types/jsdom @types/node\"}],[\"code\",{\"code\":\"import fs from 'fs';\\nimport {JSDOM} from 'jsdom';\\n\\nconst main = () => {\\n   // get all files\\n   // process any of them\\n   // using file names and data compose final strucutre\\n   // save it\\n}\\n\\nconsole.dir(main())\"}],[\"code\",{\"code\":\"const getFiles = (): { type: string, content: string }[] => fs\\n  .readdirSync(process.cwd() + `/raw`)\\n  .map(name => ({\\n    type: name[0] === 'l' ? 'LIBORCHF3M' : 'WIBOR3M',\\n    content: fs.readFileSync(process.cwd() + '/raw/' + name).toString()\\n  }))\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-54-06.png\",\"width\":512,\"height\":570}],[\"code\",{\"code\":\"interface FileInput {\\n  type: string,\\n  content: string\\n}\\n\\ninterface Output {\\n  [key: string]: { [date: string]: number }\\n}\"}],[\"code\",{\"code\":\"const processFile = ({ type, content }: FileInput): Output => ({\\n  [type]: [...new JSDOM(content).window.document.querySelectorAll('.tabela.big.m0.tlo_biel>tbody>tr')].reduce((p, n) => ({\\n    ...p,\\n    [n.querySelector('td')?.textContent || '']: (n.querySelector('td.ar')?.textContent || '').replace(',', '.')\\n  }), {})\\n})\"}],[\"code\",{\"code\":\"const main = () => {\\n  return getFiles().map(processFile)\\n}\\n\\nconsole.dir(main())\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-18-43-21.png\",\"width\":550,\"height\":179}],[\"code\",{\"code\":\"const reducer = (p: Output, n: Output): Output => {\\n  Object.keys(n).forEach(k => {\\n    Object.keys(p).includes(k) ?  p[k] = { ...p[k], ...n[k] } : p[k] = n[k];\\n  })\\n  return p\\n}\"}],[\"code\",{\"code\":\"import fs from 'fs'\\nimport { JSDOM } from 'jsdom'\\n\\ninterface FileInput {\\n    type: string,\\n    content: string\\n}\\n\\ninterface Output {\\n    [key: string]: { [date: string]: number }\\n}\\n\\nconst getFiles = (): FileInput[] => fs.readdirSync(process.cwd() + `/raw`).map(name => ({\\n    type: name[0] === 'l' ? 'LIBORCHF3M' : 'WIBOR3M',\\n    content: fs.readFileSync(process.cwd() + '/raw/' + name).toString()\\n}))\\n\\nconst processFile = ({ type, content }: FileInput): Output => ({\\n    [type]: [...new JSDOM(content).window.document.querySelectorAll('.tabela.big.m0.tlo_biel>tbody>tr')].reduce((p, n) => ({\\n        ...p,\\n        [n.querySelector('td')?.textContent || '']: parseFloat((n.querySelector('td.ar')?.textContent || '').replace(',', '.'))\\n    }), {})\\n})\\n\\nconst reducer = (p: Output, n: Output): Output => {\\n    Object.keys(n).forEach(k => {\\n        Object.keys(p).includes(k) ?  p[k] = { ...p[k], ...n[k] } : p[k] = n[k];\\n    })\\n    return p\\n}\\n\\nconst main = () => {\\n    return getFiles().map(processFile).reduce(reducer)\\n}\\n\\n!fs.existsSync(process.cwd() + '/out') && fs.mkdirSync(process.cwd() + '/out', {recursive: true})\\nfs.writeFileSync(process.cwd() + '/out/rates.json', JSON.stringify(main()))\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-15-41-32.png\",\"width\":571,\"height\":199}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-19-15-08.png\",\"width\":531,\"height\":35}],[\"code\",{\"code\":\"15 znaków = date (4) + value (5) + cudzysłowy do nich (4), dwókropek (1), przecinek (1)\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/money-pl-scraper/-/blob/0e96ff56b983c86d0b2bb50dcd7760063a16681c/app.ts\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/money-pl-scraper/-/blob/0e96ff56b983c86d0b2bb50dcd7760063a16681c/app.ts\",\"title\":\"app.ts · 0e96ff56b983c86d0b2bb50dcd7760063a16681c · gustawdaniel / money-pl-scraper\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/cheeriojs/cheerio/issues/700\",\"metadata\":{\"url\":\"https://github.com/cheeriojs/cheerio/issues/700\",\"title\":\"Is cheerio still 8x faster than jsdom? · Issue #700 · cheeriojs/cheerio\",\"description\":\"This part of the readme has been written 3,5 years ago. ba80a89 Is it still the case (especially regarding the 4.x serie of jsdom)?\",\"author\":\"cheeriojs\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://avatars.githubusercontent.com/u/7230330?s=400&v=4\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"code\",{\"code\":\"npm i cheerio\"}],[\"code\",{\"code\":\"import cheerio from 'cheerio';\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const processFile = ({type, content}: FileInput): Output => ({\\n    [type]: cheerio.load(content)('.tabela.big.m0.tlo_biel>tbody>tr').toArray().reduce((p, n) => ({\\n        ...p,\\n        ...((el) => ({[el.find('td').text()]: parseFloat(el.find('td.ar').text().replace(',', '.'))}))(cheerio(n))\\n    }), {})\\n})\",\"language\":\"ts\"}],[\"code\",{\"code\":\"time ts-node app.ts\\nts-node app.ts  29.53s user 1.21s system 141% cpu 21.729 total\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/money-pl-scraper/-/commit/4cff4a835589976ca26a7852f67dd42f2c4f2525\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/money-pl-scraper/-/commit/4cff4a835589976ca26a7852f67dd42f2c4f2525\",\"title\":\"JSDOM replaced by Cheerio (3.4) times faster (4cff4a83) · Commits · gustawdaniel / money-pl-scraper\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://calendly.com/gustaw-daniel\",\"metadata\":{\"url\":\"https://calendly.com/gustaw-daniel\",\"title\":\"Daniel Gustaw\",\"description\":\"Welcome to my scheduling page. Please follow the instructions to add an event to my calendar.\",\"author\":null,\"publisher\":\"Calendly\",\"thumbnail\":\"https://assets.calendly.com/assets/ogimage-a63bb2f442cd9e6345a5e4d7fe75393c6cfcc1ff29e48e858742d43573a8b02c.png?source=opengraph\",\"icon\":\"https://assets.calendly.com/assets/touch-icon-ipad-retina-7a95e0c775301f4c0a22002bdf0a95d3c2b9cbe95af29c64f9c9573bac1f01e4.png\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://mariusschulz.com/blog/downlevel-iteration-for-es3-es5-in-typescript\",\"metadata\":{\"url\":\"https://mariusschulz.com/blog/downlevel-iteration-for-es3-es5-in-typescript\",\"title\":\"Downlevel Iteration for ES3/ES5 in TypeScript\",\"description\":\"TypeScript 2.3 introduced a new `--downlevelIteration` flag that adds full support for the ES2015 iteration protocol and `for...of`-loops for ES3 and ES5 targets.\",\"author\":\"Marius Schulz\",\"publisher\":\"Marius Schulz\",\"thumbnail\":\"https://mariusschulz.com/images/content/typescript_cannot_find_map-2x.JubdK2SZJP.imm.png\",\"icon\":\"https://mariusschulz.com/images/apple-touch-icon.RlWtv0iBaN.imm.png\"}}]],\"markups\":[[\"code\"],[\"a\",[\"href\",\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/bank-rates.json\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Dane finansowe w dobrej jakości i wygodne do pobrania polecam pobierać ze Stooq. \"]]],[1,\"p\",[[0,[],0,\"Zanim jednak dowiedziałem się o tym serwisie pobierałem je z innych źródeł. W tym artykule prezentuję taki właśnie przypadek, gdzie nieprzyjazny interfejs serwisu internetowego zmusił mnie do wykonania na nim scrapingu i pobrania danych, których potrzebowałem.\"]]],[1,\"p\",[[0,[],0,\"Z artykułu dowiesz się, jak robić to szybko. Zobaczysz jakich narzędzi używam i w jaki sposób organizuję kod projektów scrapingowych.\"]]],[1,\"p\",[[0,[],0,\"Jak gdyby nigdy nic wchodzę do internetu i chcę pobrać sobie \"],[0,[0],1,\"LIBORCHF3M\"],[0,[],0,\" i \"],[0,[0],1,\"WIBOR3M\"],[0,[],0,\". Znajduję nawet stronę, która takie dane udostępnia:\"]]],[10,0],[10,1],[1,\"p\",[[0,[],0,\"Klikam pobierz i nawet dostaję plik, ale po zaznaczeniu pełnego okresu, wybraniu poprawnych danych widzę:\"]]],[10,2],[1,\"blockquote\",[[0,[],0,\"Liczba wierszy ograniczona do 50\"]]],[1,\"p\",[[0,[],0,\"Kto to ograniczył? Po co ten formularz, jak nie można z niego skorzystać!? Wiadomo, że jak ktoś chce przetwarzać dane to najlepiej najszerszy możliwy zakres.\"]]],[1,\"p\",[[0,[],0,\"W tym wpisie pokażę jak minimalną liczbą linii kodu ominąć problem i wykonać szybki scraping. Poniżej plan działań jakie zaprezentuję:\"]]],[3,\"ol\",[[[0,[],0,\"Sprawdzenie jak dostać się do tych danych.\"]],[[0,[],0,\"Pobranie danych na maszynę lokalną.\"]],[[0,[],0,\"Opisanie docelowej struktury.\"]],[[0,[],0,\"Przetworzenie pobranych stron.\"]]]],[1,\"p\",[[0,[],0,\"Główne cele:\"]]],[3,\"ul\",[[[0,[],0,\"minimalizacja czasu i linii kodu na to zadanie\"]]]],[1,\"h1\",[[0,[],0,\"Jak dostać się do danych\"]]],[1,\"p\",[[0,[],0,\"Okazuje się, że jak wyświetlimy tabelę to dane można z niej odczytać i będzie ona paginowana.\"]]],[10,3],[1,\"p\",[[0,[],0,\"Linki mają kształt:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Na przykład\"]]],[10,5],[1,\"p\",[[0,[],0,\"Renderowane są po stronie backendu co widzimy sprawdzając źródło strony:\"]]],[10,6],[1,\"p\",[[0,[],0,\"Potencjalnie plan 1:\"]]],[3,\"ul\",[[[0,[],0,\"pobrać wszystkie pętlą w bashu na wget - jedna linia\"]],[[0,[],0,\"przetworzyć wszystkie pobrane pliki w \"],[0,[0],1,\"node\"],[0,[],0,\" z \"],[0,[0],1,\"jsdom\"],[0,[],0,\" 30 linii\"]]]],[1,\"p\",[[0,[],0,\"Potencjalnie plan 2\"]]],[3,\"ul\",[[[0,[],0,\"pobrać pliki CSV co 50 dni z zakresie dat - około 40 linii \"],[0,[0],1,\"node\"]],[[0,[],0,\"przetworzyć je około 1 linii w sed / awk / perl / bash\"]]]],[1,\"p\",[[0,[],0,\"Opcja z CSV była by prostsza gdyby nie problematyczne paginowanie po datach. Operowanie na datach w \"],[0,[0],1,\"js\"],[0,[],0,\" jest raczej nieprzyjemne, mimo to obie strategie są racjonalne. Jeśli oszczędzał bym transfer sieciowy czy moc obliczeniową to plan 2 bije na głowę plan 1. Jednak celujemy w minimalizację ilości kodu więc zrobimy to pierwszym sposobem.\"]]],[1,\"h1\",[[0,[],0,\"Pobranie danych\"]]],[1,\"p\",[[0,[],0,\"Linki:\"]]],[10,7],[1,\"p\",[[0,[],0,\"Będziemy potrzebować pętli \"],[0,[0],1,\"for\"],[0,[],0,\" oraz \"],[0,[0],1,\"wget\"],[0,[],0,\". Testowo sprawdzimy \"],[0,[0],1,\"i=1\"]]],[10,8],[1,\"p\",[[0,[],0,\"Okazuje się jednak, że odpowiedź do \"],[0,[0],1,\"403\"]]],[10,9],[1,\"p\",[[0,[],0,\"Czyżby ta strona była tak często czesana \"],[0,[0],1,\"wgetem\"],[0,[],0,\", że admini zablokowali żądania dla domyślnego user agent wgeta?\"]]],[10,10],[1,\"p\",[[0,[],0,\"Nie zdziwił bym się, biorąc po uwagę fakt, że Wget wcale się nie kryje ze swoją tożsamością. Httpie nie jest lepszy\"]]],[10,11],[1,\"p\",[[0,[],0,\"ale jest mniej znany, dlatego działa\"]]],[10,12],[1,\"p\",[[0,[],0,\"Do pobrania plików jak obiecałem wystarczy po 1 linii dla każdego rodzaju:\"]]],[1,\"p\",[[0,[],0,\"Dla \"],[0,[0],1,\"LIBORCHF3M\"]]],[10,13],[1,\"p\",[[0,[],0,\"Dla \"],[0,[0],1,\"WIBOR3M\"]]],[10,14],[1,\"p\",[[0,[],0,\"W katalogu \"],[0,[0],1,\"raw\"],[0,[],0,\" mamy już wszystkie pliki wymagane do przetworzenia\"]]],[10,15],[1,\"h1\",[[0,[],0,\"Opisanie docelowej struktury\"]]],[1,\"p\",[[0,[],0,\"Na wyjściu chcę mieć plik \"],[0,[0],1,\"json\"],[0,[],0,\" o następującej strukturze\"]]],[10,16],[1,\"h1\",[[0,[],0,\"Przetworzenie pobranych stron\"]]],[1,\"p\",[[0,[],0,\"Startujemy projekt\"]]],[10,17],[1,\"p\",[[0,[],0,\"Instalujemy \"],[0,[0],1,\"jsdom\"],[0,[],0,\" do parsowania drzewa dom po stronie node js.\"]]],[10,18],[1,\"p\",[[0,[],0,\"Na koniec porównamy \"],[0,[0],1,\"jsdom\"],[0,[],0,\" z \"],[0,[0],1,\"cheerio\"],[0,[],0,\". Lecz teraz załóżmy, że wykonamy zadanie używając tej pierwszej biblioteki.\"]]],[1,\"p\",[[0,[],0,\"Bazowy szkielet jest dość przewidywalny.\"]]],[10,19],[1,\"p\",[[0,[],0,\"Chcemy teraz odczytać wszystkie pliki. Piszemy do tego funkcję:\"]]],[10,20],[1,\"p\",[[0,[],0,\"Teraz je przetworzymy pojedynczą tabelę:\"]]],[10,21],[1,\"p\",[[0,[],0,\"Ta linia wykonana w kosoli przeglądarki jest sercem całego programu. Należy ją przenieść do \"],[0,[0],1,\"node js\"],[0,[],0,\". Abyśmy bez problemu wykonali dynamiczną destrukturyzację potrzebujemy zmienić \"],[0,[0],1,\"target\"],[0,[],0,\" w \"],[0,[0],1,\"tsconfig.json\"],[0,[],0,\" na wyższy niż \"],[0,[0],1,\"es5\"],[0,[],0,\" na przykład \"],[0,[0],1,\"ES2020\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Definiujemy interfejsy\"]]],[10,22],[1,\"p\",[[0,[],0,\"Funkcja przetwarzająca pliki przyjmie kształt:\"]]],[10,23],[1,\"p\",[[0,[],0,\"jej użycie mogło by wyglądać tak\"]]],[10,24],[1,\"p\",[[0,[],0,\"Wykonanie zwraca dane, które musimy jeszcze zredukować do tylko pary kluczy - \"],[0,[0],1,\"LIBORCHF3M\"],[0,[],0,\" oraz \"],[0,[0],1,\"WIBOR3M\"]]],[10,25],[1,\"p\",[[0,[],0,\"Redukcja wymaga mergowania objektów na kluczach, dlatego dopiszemy do niej funkcję\"]]],[10,26],[1,\"p\",[[0,[],0,\"Całość kodu może finalnie wygląda tak\"]]],[10,27],[1,\"p\",[[0,[],0,\"Ilość linii prawdziwego kodu: 30\"]]],[10,28],[1,\"p\",[[0,[],0,\"Czas wykonania: 1min 15sec\"]]],[10,29],[1,\"p\",[[0,[],0,\"Waga pobranych plików html 43MB. Waga wydobytych danych 244KB w formacie json. Gdybyśmy chcieli je trzymać w CSV, oszczędność wyniosła by jedynie 2 cudzysłowy na linię. Przy około 13 tys linii daje to 26KB zbędnych znaków przy konwersji do CSV czyli 10%. Jest to bardzo mało.\"]]],[1,\"p\",[[0,[],0,\"Jednak pamiętajmy, że kolejne 4 znaki można zaoszczędzić na zmiane konwencji zapisu dat z \"],[0,[0],1,\"YYYY-MM-DD\"],[0,[],0,\" na \"],[0,[0],1,\"YYMMDD\"],[0,[],0,\", a pewnie jeszcze więcej kodując daty w formacie o wyższej entropii niż używany przez ludzi na codzień.\"]]],[1,\"p\",[[0,[],0,\"Znacznie więcej, bo 15 znaków na linię oszczędziliśmy na decyzji, że daty będą tu kluczami.\"]]],[10,30],[1,\"p\",[[0,[],0,\"Dane są dostępne do pobrania pod linkiem:\"]]],[1,\"p\",[[0,[1],1,\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/bank-rates.json\"]]],[1,\"p\",[[0,[],0,\"Kod programu w tej wersji znajdziecie w repozytorium\"]]],[10,31],[1,\"h2\",[[0,[],0,\"Cheerio vs JSDOM\"]]],[1,\"p\",[[0,[],0,\"Jakiś czas po napisaniu tego artykułu spotkałem się z problemem wysokiego zużycia pamięci w JSDOM. Potwierdziłem to eksperymentalnie w issue:\"]]],[10,32],[1,\"p\",[[0,[],0,\"Teraz pokażę jak przepisać ten kod na \"],[0,[0],1,\"cheerio\"],[0,[],0,\" oraz jak podniesie się jego wydajność\"]]],[3,\"ol\",[[[0,[],0,\"Instalujemy Cheerio\"]]]],[10,33],[1,\"p\",[[0,[],0,\"2. Podmieniamy import na\"]]],[10,34],[1,\"p\",[[0,[],0,\"3. Podmieniamy funkcję przetwarzającą plik na\"]]],[10,35],[1,\"p\",[[0,[],0,\"Wynik poprawił się \"],[0,[0],1,\"3.4\"],[0,[],0,\" krotnie\"]]],[10,36],[1,\"p\",[[0,[],0,\"Pełny DIFF jest dostępny pod linkiem:\"]]],[10,37],[1,\"p\",[[0,[],0,\"Jeśli chcesz porozmawiać o scrapingu w ramach bezpłatnej, nie zobowiązującej konsultacji, zapraszam Cię na mój Calendy.\"]]],[10,38],[1,\"p\",[[0,[],0,\"Warto przeczytać też\"]]],[10,39],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "html": "<p>Dane finansowe w dobrej jakości i wygodne do pobrania polecam pobierać ze Stooq. </p><p>Zanim jednak dowiedziałem się o tym serwisie pobierałem je z innych źródeł. W tym artykule prezentuję taki właśnie przypadek, gdzie nieprzyjazny interfejs serwisu internetowego zmusił mnie do wykonania na nim scrapingu i pobrania danych, których potrzebowałem.</p><p>Z artykułu dowiesz się, jak robić to szybko. Zobaczysz jakich narzędzi używam i w jaki sposób organizuję kod projektów scrapingowych.</p><p>Jak gdyby nigdy nic wchodzę do internetu i chcę pobrać sobie <code>LIBORCHF3M</code> i <code>WIBOR3M</code>. Znajduję nawet stronę, która takie dane udostępnia:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Archiwum notowa� dla LIBOR frank szwajcarski 3M (LIBORCHF3M), strona 1</div><div class=\"kg-bookmark-description\">Archiwum notowa� dla LIBOR frank szwajcarski 3M (LIBORCHF3M)</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://static1.money.pl/i/favicon.ico\"><span class=\"kg-bookmark-author\">www.money.pl</span><span class=\"kg-bookmark-publisher\">Grupa Wirtualna Polska</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://static1.money.pl/i/wp-money.png\"></div></a></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-36-22.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"700\" height=\"367\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-16-36-22.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-36-22.png 700w\"></figure><p>Klikam pobierz i nawet dostaję plik, ale po zaznaczeniu pełnego okresu, wybraniu poprawnych danych widzę:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-37-15.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"446\" height=\"936\"></figure><blockquote>Liczba wierszy ograniczona do 50</blockquote><p>Kto to ograniczył? Po co ten formularz, jak nie można z niego skorzystać!? Wiadomo, że jak ktoś chce przetwarzać dane to najlepiej najszerszy możliwy zakres.</p><p>W tym wpisie pokażę jak minimalną liczbą linii kodu ominąć problem i wykonać szybki scraping. Poniżej plan działań jakie zaprezentuję:</p><ol><li>Sprawdzenie jak dostać się do tych danych.</li><li>Pobranie danych na maszynę lokalną.</li><li>Opisanie docelowej struktury.</li><li>Przetworzenie pobranych stron.</li></ol><p>Główne cele:</p><ul><li>minimalizacja czasu i linii kodu na to zadanie</li></ul><h1 id=\"jak-dosta-si-do-danych\">Jak dostać się do danych</h1><p>Okazuje się, że jak wyświetlimy tabelę to dane można z niej odczytać i będzie ona paginowana.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-42-52.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"672\" height=\"870\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-16-42-52.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-42-52.png 672w\"></figure><p>Linki mają kształt:</p><pre><code>BASE_PREFIX${index}BASE_POSTFIX</code></pre><p>Na przykład</p><pre><code>https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html</code></pre><p>Renderowane są po stronie backendu co widzimy sprawdzając źródło strony:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-44-34.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"894\" height=\"552\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-16-44-34.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-16-44-34.png 894w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Potencjalnie plan 1:</p><ul><li>pobrać wszystkie pętlą w bashu na wget - jedna linia</li><li>przetworzyć wszystkie pobrane pliki w <code>node</code> z <code>jsdom</code> 30 linii</li></ul><p>Potencjalnie plan 2</p><ul><li>pobrać pliki CSV co 50 dni z zakresie dat - około 40 linii <code>node</code></li><li>przetworzyć je około 1 linii w sed / awk / perl / bash</li></ul><p>Opcja z CSV była by prostsza gdyby nie problematyczne paginowanie po datach. Operowanie na datach w <code>js</code> jest raczej nieprzyjemne, mimo to obie strategie są racjonalne. Jeśli oszczędzał bym transfer sieciowy czy moc obliczeniową to plan 2 bije na głowę plan 1. Jednak celujemy w minimalizację ilości kodu więc zrobimy to pierwszym sposobem.</p><h1 id=\"pobranie-danych\">Pobranie danych</h1><p>Linki:</p><pre><code>LIBOR:\n\nhttps://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\n\nStron: 245\n\nWIBOR:\n\nhttps://www.money.pl/pieniadze/depozyty/zlotowearch/1921-02-05,2021-02-05,WIBOR3M,strona,1.html\n\nStron: 178</code></pre><p>Będziemy potrzebować pętli <code>for</code> oraz <code>wget</code>. Testowo sprawdzimy <code>i=1</code></p><pre><code>for i in {1..1}; do wget \"https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,$i.html\" -O raw; done</code></pre><p>Okazuje się jednak, że odpowiedź do <code>403</code></p><pre><code>--2021-02-05 16:59:56--  https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\nLoaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\nResolving www.money.pl (www.money.pl)... 212.77.101.20\nConnecting to www.money.pl (www.money.pl)|212.77.101.20|:443... connected.\nHTTP request sent, awaiting response... 403 Forbidden\n2021-02-05 16:59:56 ERROR 403: Forbidden.</code></pre><p>Czyżby ta strona była tak często czesana <code>wgetem</code>, że admini zablokowali żądania dla domyślnego user agent wgeta?</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-12-21.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"641\" height=\"179\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-17-12-21.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-12-21.png 641w\"></figure><p>Nie zdziwił bym się, biorąc po uwagę fakt, że Wget wcale się nie kryje ze swoją tożsamością. Httpie nie jest lepszy</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-13-43.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"697\" height=\"176\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-17-13-43.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-13-43.png 697w\"></figure><p>ale jest mniej znany, dlatego działa</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-11-05.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1885\" height=\"417\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-17-11-05.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-05-17-11-05.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-05-17-11-05.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-11-05.png 1885w\"></figure><p>Do pobrania plików jak obiecałem wystarczy po 1 linii dla każdego rodzaju:</p><p>Dla <code>LIBORCHF3M</code></p><pre><code>mkdir -p raw &amp;&amp; for i in {1..245}; do http -b \"https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,$i.html\" &gt; \"raw/l${i}.html\";echo $i; done</code></pre><p>Dla <code>WIBOR3M</code></p><pre><code>mkdir -p raw &amp;&amp; for i in {1..178}; do http -b \"https://www.money.pl/pieniadze/depozyty/zlotowearch/1921-02-05,2021-02-05,WIBOR3M,strona,$i.html\" &gt; \"raw/w${i}.html\";echo $i; done </code></pre><p>W katalogu <code>raw</code> mamy już wszystkie pliki wymagane do przetworzenia</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-24-23.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1892\" height=\"132\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-05-17-24-23.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-05-17-24-23.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-05-17-24-23.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-24-23.png 1892w\"></figure><h1 id=\"opisanie-docelowej-struktury\">Opisanie docelowej struktury</h1><p>Na wyjściu chcę mieć plik <code>json</code> o następującej strukturze</p><pre><code>{\n   \"WIBOR3M\": { 'YYYY-MM-DD': value, ... },\n   \"LIBORCHF3M\": { 'YYYY-MM-DD': value, ... }\n}</code></pre><h1 id=\"przetworzenie-pobranych-stron\">Przetworzenie pobranych stron</h1><p>Startujemy projekt</p><pre><code>npm init -y &amp;&amp; tsc --init &amp;&amp; touch app.ts</code></pre><p>Instalujemy <code>jsdom</code> do parsowania drzewa dom po stronie node js.</p><pre><code>npm i jsdom @types/jsdom @types/node</code></pre><p>Na koniec porównamy <code>jsdom</code> z <code>cheerio</code>. Lecz teraz załóżmy, że wykonamy zadanie używając tej pierwszej biblioteki.</p><p>Bazowy szkielet jest dość przewidywalny.</p><pre><code>import fs from 'fs';\nimport {JSDOM} from 'jsdom';\n\nconst main = () =&gt; {\n   // get all files\n   // process any of them\n   // using file names and data compose final strucutre\n   // save it\n}\n\nconsole.dir(main())</code></pre><p>Chcemy teraz odczytać wszystkie pliki. Piszemy do tego funkcję:</p><pre><code>const getFiles = (): { type: string, content: string }[] =&gt; fs\n  .readdirSync(process.cwd() + `/raw`)\n  .map(name =&gt; ({\n    type: name[0] === 'l' ? 'LIBORCHF3M' : 'WIBOR3M',\n    content: fs.readFileSync(process.cwd() + '/raw/' + name).toString()\n  }))</code></pre><p>Teraz je przetworzymy pojedynczą tabelę:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-17-54-06.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"512\" height=\"570\"></figure><p>Ta linia wykonana w kosoli przeglądarki jest sercem całego programu. Należy ją przenieść do <code>node js</code>. Abyśmy bez problemu wykonali dynamiczną destrukturyzację potrzebujemy zmienić <code>target</code> w <code>tsconfig.json</code> na wyższy niż <code>es5</code> na przykład <code>ES2020</code>. </p><p>Definiujemy interfejsy</p><pre><code>interface FileInput {\n  type: string,\n  content: string\n}\n\ninterface Output {\n  [key: string]: { [date: string]: number }\n}</code></pre><p>Funkcja przetwarzająca pliki przyjmie kształt:</p><pre><code>const processFile = ({ type, content }: FileInput): Output =&gt; ({\n  [type]: [...new JSDOM(content).window.document.querySelectorAll('.tabela.big.m0.tlo_biel&gt;tbody&gt;tr')].reduce((p, n) =&gt; ({\n    ...p,\n    [n.querySelector('td')?.textContent || '']: (n.querySelector('td.ar')?.textContent || '').replace(',', '.')\n  }), {})\n})</code></pre><p>jej użycie mogło by wyglądać tak</p><pre><code>const main = () =&gt; {\n  return getFiles().map(processFile)\n}\n\nconsole.dir(main())</code></pre><p>Wykonanie zwraca dane, które musimy jeszcze zredukować do tylko pary kluczy - <code>LIBORCHF3M</code> oraz <code>WIBOR3M</code></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-18-43-21.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"550\" height=\"179\"></figure><p>Redukcja wymaga mergowania objektów na kluczach, dlatego dopiszemy do niej funkcję</p><pre><code>const reducer = (p: Output, n: Output): Output =&gt; {\n  Object.keys(n).forEach(k =&gt; {\n    Object.keys(p).includes(k) ?  p[k] = { ...p[k], ...n[k] } : p[k] = n[k];\n  })\n  return p\n}</code></pre><p>Całość kodu może finalnie wygląda tak</p><pre><code class=\"language-ts\">import fs from 'fs'\nimport { JSDOM } from 'jsdom'\n\ninterface FileInput {\n    type: string,\n    content: string\n}\n\ninterface Output {\n    [key: string]: { [date: string]: number }\n}\n\nconst getFiles = (): FileInput[] =&gt; fs.readdirSync(process.cwd() + `/raw`).map(name =&gt; ({\n    type: name[0] === 'l' ? 'LIBORCHF3M' : 'WIBOR3M',\n    content: fs.readFileSync(process.cwd() + '/raw/' + name).toString()\n}))\n\nconst processFile = ({ type, content }: FileInput): Output =&gt; ({\n    [type]: [...new JSDOM(content).window.document.querySelectorAll('.tabela.big.m0.tlo_biel&gt;tbody&gt;tr')].reduce((p, n) =&gt; ({\n        ...p,\n        [n.querySelector('td')?.textContent || '']: parseFloat((n.querySelector('td.ar')?.textContent || '').replace(',', '.'))\n    }), {})\n})\n\nconst reducer = (p: Output, n: Output): Output =&gt; {\n    Object.keys(n).forEach(k =&gt; {\n        Object.keys(p).includes(k) ?  p[k] = { ...p[k], ...n[k] } : p[k] = n[k];\n    })\n    return p\n}\n\nconst main = () =&gt; {\n    return getFiles().map(processFile).reduce(reducer)\n}\n\n!fs.existsSync(process.cwd() + '/out') &amp;&amp; fs.mkdirSync(process.cwd() + '/out', {recursive: true})\nfs.writeFileSync(process.cwd() + '/out/rates.json', JSON.stringify(main()))</code></pre><p>Ilość linii prawdziwego kodu: 30</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-15-41-32.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"571\" height=\"199\"></figure><p>Czas wykonania: 1min 15sec</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-05-19-15-08.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"531\" height=\"35\"></figure><p>Waga pobranych plików html 43MB. Waga wydobytych danych 244KB w formacie json. Gdybyśmy chcieli je trzymać w CSV, oszczędność wyniosła by jedynie 2 cudzysłowy na linię. Przy około 13 tys linii daje to 26KB zbędnych znaków przy konwersji do CSV czyli 10%. Jest to bardzo mało.</p><p>Jednak pamiętajmy, że kolejne 4 znaki można zaoszczędzić na zmiane konwencji zapisu dat z <code>YYYY-MM-DD</code> na <code>YYMMDD</code>, a pewnie jeszcze więcej kodując daty w formacie o wyższej entropii niż używany przez ludzi na codzień.</p><p>Znacznie więcej, bo 15 znaków na linię oszczędziliśmy na decyzji, że daty będą tu kluczami.</p><pre><code>15 znaków = date (4) + value (5) + cudzysłowy do nich (4), dwókropek (1), przecinek (1)</code></pre><p>Dane są dostępne do pobrania pod linkiem:</p><p><a href=\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/bank-rates.json\">https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/bank-rates.json</a></p><p>Kod programu w tej wersji znajdziecie w repozytorium</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/money-pl-scraper/-/blob/0e96ff56b983c86d0b2bb50dcd7760063a16681c/app.ts\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">app.ts · 0e96ff56b983c86d0b2bb50dcd7760063a16681c · gustawdaniel / money-pl-scraper</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><h2 id=\"cheerio-vs-jsdom\">Cheerio vs JSDOM</h2><p>Jakiś czas po napisaniu tego artykułu spotkałem się z problemem wysokiego zużycia pamięci w JSDOM. Potwierdziłem to eksperymentalnie w issue:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/cheeriojs/cheerio/issues/700\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Is cheerio still 8x faster than jsdom? · Issue #700 · cheeriojs/cheerio</div><div class=\"kg-bookmark-description\">This part of the readme has been written 3,5 years ago. ba80a89 Is it still the case (especially regarding the 4.x serie of jsdom)?</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">cheeriojs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://avatars.githubusercontent.com/u/7230330?s&#x3D;400&amp;v&#x3D;4\"></div></a></figure><p>Teraz pokażę jak przepisać ten kod na <code>cheerio</code> oraz jak podniesie się jego wydajność</p><ol><li>Instalujemy Cheerio</li></ol><pre><code>npm i cheerio</code></pre><p>2. Podmieniamy import na</p><pre><code class=\"language-ts\">import cheerio from 'cheerio';</code></pre><p>3. Podmieniamy funkcję przetwarzającą plik na</p><pre><code class=\"language-ts\">const processFile = ({type, content}: FileInput): Output =&gt; ({\n    [type]: cheerio.load(content)('.tabela.big.m0.tlo_biel&gt;tbody&gt;tr').toArray().reduce((p, n) =&gt; ({\n        ...p,\n        ...((el) =&gt; ({[el.find('td').text()]: parseFloat(el.find('td.ar').text().replace(',', '.'))}))(cheerio(n))\n    }), {})\n})</code></pre><p>Wynik poprawił się <code>3.4</code> krotnie</p><pre><code>time ts-node app.ts\nts-node app.ts  29.53s user 1.21s system 141% cpu 21.729 total</code></pre><p>Pełny DIFF jest dostępny pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/money-pl-scraper/-/commit/4cff4a835589976ca26a7852f67dd42f2c4f2525\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">JSDOM replaced by Cheerio (3.4) times faster (4cff4a83) · Commits · gustawdaniel / money-pl-scraper</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><p>Jeśli chcesz porozmawiać o scrapingu w ramach bezpłatnej, nie zobowiązującej konsultacji, zapraszam Cię na mój Calendy.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://calendly.com/gustaw-daniel\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Daniel Gustaw</div><div class=\"kg-bookmark-description\">Welcome to my scheduling page. Please follow the instructions to add an event to my calendar.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.calendly.com/assets/touch-icon-ipad-retina-7a95e0c775301f4c0a22002bdf0a95d3c2b9cbe95af29c64f9c9573bac1f01e4.png\"><span class=\"kg-bookmark-author\">Calendly</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.calendly.com/assets/ogimage-a63bb2f442cd9e6345a5e4d7fe75393c6cfcc1ff29e48e858742d43573a8b02c.png?source&#x3D;opengraph\"></div></a></figure><p>Warto przeczytać też</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://mariusschulz.com/blog/downlevel-iteration-for-es3-es5-in-typescript\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Downlevel Iteration for ES3/ES5 in TypeScript</div><div class=\"kg-bookmark-description\">TypeScript 2.3 introduced a new &#x60;--downlevelIteration&#x60; flag that adds full support for the ES2015 iteration protocol and &#x60;for...of&#x60;-loops for ES3 and ES5 targets.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://mariusschulz.com/images/apple-touch-icon.RlWtv0iBaN.imm.png\"><span class=\"kg-bookmark-author\">Marius Schulz</span><span class=\"kg-bookmark-publisher\">Marius Schulz</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://mariusschulz.com/images/content/typescript_cannot_find_map-2x.JubdK2SZJP.imm.png\"></div></a></figure>",
            "comment_id": "601d65141446cd10bd8da405",
            "plaintext": "Dane finansowe w dobrej jakości i wygodne do pobrania polecam pobierać ze Stooq. \n\nZanim jednak dowiedziałem się o tym serwisie pobierałem je z innych źródeł. W\ntym artykule prezentuję taki właśnie przypadek, gdzie nieprzyjazny interfejs\nserwisu internetowego zmusił mnie do wykonania na nim scrapingu i pobrania\ndanych, których potrzebowałem.\n\nZ artykułu dowiesz się, jak robić to szybko. Zobaczysz jakich narzędzi używam i\nw jaki sposób organizuję kod projektów scrapingowych.\n\nJak gdyby nigdy nic wchodzę do internetu i chcę pobrać sobie LIBORCHF3M i \nWIBOR3M. Znajduję nawet stronę, która takie dane udostępnia:\n\nArchiwum notowa� dla LIBOR frank szwajcarski 3M (LIBORCHF3M), strona 1Archiwum\nnotowa� dla LIBOR frank szwajcarski 3M (LIBORCHF3M)www.money.plGrupa Wirtualna\nPolska\n[https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html]\nKlikam pobierz i nawet dostaję plik, ale po zaznaczeniu pełnego okresu, wybraniu\npoprawnych danych widzę:\n\n> Liczba wierszy ograniczona do 50\nKto to ograniczył? Po co ten formularz, jak nie można z niego skorzystać!?\nWiadomo, że jak ktoś chce przetwarzać dane to najlepiej najszerszy możliwy\nzakres.\n\nW tym wpisie pokażę jak minimalną liczbą linii kodu ominąć problem i wykonać\nszybki scraping. Poniżej plan działań jakie zaprezentuję:\n\n 1. Sprawdzenie jak dostać się do tych danych.\n 2. Pobranie danych na maszynę lokalną.\n 3. Opisanie docelowej struktury.\n 4. Przetworzenie pobranych stron.\n\nGłówne cele:\n\n * minimalizacja czasu i linii kodu na to zadanie\n\nJak dostać się do danych\nOkazuje się, że jak wyświetlimy tabelę to dane można z niej odczytać i będzie\nona paginowana.\n\nLinki mają kształt:\n\nBASE_PREFIX${index}BASE_POSTFIX\n\nNa przykład\n\nhttps://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\n\nRenderowane są po stronie backendu co widzimy sprawdzając źródło strony:\n\nPotencjalnie plan 1:\n\n * pobrać wszystkie pętlą w bashu na wget - jedna linia\n * przetworzyć wszystkie pobrane pliki w node z jsdom 30 linii\n\nPotencjalnie plan 2\n\n * pobrać pliki CSV co 50 dni z zakresie dat - około 40 linii node\n * przetworzyć je około 1 linii w sed / awk / perl / bash\n\nOpcja z CSV była by prostsza gdyby nie problematyczne paginowanie po datach.\nOperowanie na datach w js jest raczej nieprzyjemne, mimo to obie strategie są\nracjonalne. Jeśli oszczędzał bym transfer sieciowy czy moc obliczeniową to plan\n2 bije na głowę plan 1. Jednak celujemy w minimalizację ilości kodu więc zrobimy\nto pierwszym sposobem.\n\nPobranie danych\nLinki:\n\nLIBOR:\n\nhttps://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\n\nStron: 245\n\nWIBOR:\n\nhttps://www.money.pl/pieniadze/depozyty/zlotowearch/1921-02-05,2021-02-05,WIBOR3M,strona,1.html\n\nStron: 178\n\nBędziemy potrzebować pętli for oraz wget. Testowo sprawdzimy i=1\n\nfor i in {1..1}; do wget \"https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,$i.html\" -O raw; done\n\nOkazuje się jednak, że odpowiedź do 403\n\n--2021-02-05 16:59:56--  https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,1.html\nLoaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\nResolving www.money.pl (www.money.pl)... 212.77.101.20\nConnecting to www.money.pl (www.money.pl)|212.77.101.20|:443... connected.\nHTTP request sent, awaiting response... 403 Forbidden\n2021-02-05 16:59:56 ERROR 403: Forbidden.\n\nCzyżby ta strona była tak często czesana wgetem, że admini zablokowali żądania\ndla domyślnego user agent wgeta?\n\nNie zdziwił bym się, biorąc po uwagę fakt, że Wget wcale się nie kryje ze swoją\ntożsamością. Httpie nie jest lepszy\n\nale jest mniej znany, dlatego działa\n\nDo pobrania plików jak obiecałem wystarczy po 1 linii dla każdego rodzaju:\n\nDla LIBORCHF3M\n\nmkdir -p raw && for i in {1..245}; do http -b \"https://www.money.pl/pieniadze/depozyty/walutowearch/1921-02-05,2021-02-05,LIBORCHF3M,strona,$i.html\" > \"raw/l${i}.html\";echo $i; done\n\nDla WIBOR3M\n\nmkdir -p raw && for i in {1..178}; do http -b \"https://www.money.pl/pieniadze/depozyty/zlotowearch/1921-02-05,2021-02-05,WIBOR3M,strona,$i.html\" > \"raw/w${i}.html\";echo $i; done \n\nW katalogu raw mamy już wszystkie pliki wymagane do przetworzenia\n\nOpisanie docelowej struktury\nNa wyjściu chcę mieć plik json o następującej strukturze\n\n{\n   \"WIBOR3M\": { 'YYYY-MM-DD': value, ... },\n   \"LIBORCHF3M\": { 'YYYY-MM-DD': value, ... }\n}\n\nPrzetworzenie pobranych stron\nStartujemy projekt\n\nnpm init -y && tsc --init && touch app.ts\n\nInstalujemy jsdom do parsowania drzewa dom po stronie node js.\n\nnpm i jsdom @types/jsdom @types/node\n\nNa koniec porównamy jsdom z cheerio. Lecz teraz załóżmy, że wykonamy zadanie\nużywając tej pierwszej biblioteki.\n\nBazowy szkielet jest dość przewidywalny.\n\nimport fs from 'fs';\nimport {JSDOM} from 'jsdom';\n\nconst main = () => {\n   // get all files\n   // process any of them\n   // using file names and data compose final strucutre\n   // save it\n}\n\nconsole.dir(main())\n\nChcemy teraz odczytać wszystkie pliki. Piszemy do tego funkcję:\n\nconst getFiles = (): { type: string, content: string }[] => fs\n  .readdirSync(process.cwd() + `/raw`)\n  .map(name => ({\n    type: name[0] === 'l' ? 'LIBORCHF3M' : 'WIBOR3M',\n    content: fs.readFileSync(process.cwd() + '/raw/' + name).toString()\n  }))\n\nTeraz je przetworzymy pojedynczą tabelę:\n\nTa linia wykonana w kosoli przeglądarki jest sercem całego programu. Należy ją\nprzenieść do node js. Abyśmy bez problemu wykonali dynamiczną destrukturyzację\npotrzebujemy zmienić target w tsconfig.json na wyższy niż es5 na przykład ES2020\n. \n\nDefiniujemy interfejsy\n\ninterface FileInput {\n  type: string,\n  content: string\n}\n\ninterface Output {\n  [key: string]: { [date: string]: number }\n}\n\nFunkcja przetwarzająca pliki przyjmie kształt:\n\nconst processFile = ({ type, content }: FileInput): Output => ({\n  [type]: [...new JSDOM(content).window.document.querySelectorAll('.tabela.big.m0.tlo_biel>tbody>tr')].reduce((p, n) => ({\n    ...p,\n    [n.querySelector('td')?.textContent || '']: (n.querySelector('td.ar')?.textContent || '').replace(',', '.')\n  }), {})\n})\n\njej użycie mogło by wyglądać tak\n\nconst main = () => {\n  return getFiles().map(processFile)\n}\n\nconsole.dir(main())\n\nWykonanie zwraca dane, które musimy jeszcze zredukować do tylko pary kluczy - \nLIBORCHF3M oraz WIBOR3M\n\nRedukcja wymaga mergowania objektów na kluczach, dlatego dopiszemy do niej\nfunkcję\n\nconst reducer = (p: Output, n: Output): Output => {\n  Object.keys(n).forEach(k => {\n    Object.keys(p).includes(k) ?  p[k] = { ...p[k], ...n[k] } : p[k] = n[k];\n  })\n  return p\n}\n\nCałość kodu może finalnie wygląda tak\n\nimport fs from 'fs'\nimport { JSDOM } from 'jsdom'\n\ninterface FileInput {\n    type: string,\n    content: string\n}\n\ninterface Output {\n    [key: string]: { [date: string]: number }\n}\n\nconst getFiles = (): FileInput[] => fs.readdirSync(process.cwd() + `/raw`).map(name => ({\n    type: name[0] === 'l' ? 'LIBORCHF3M' : 'WIBOR3M',\n    content: fs.readFileSync(process.cwd() + '/raw/' + name).toString()\n}))\n\nconst processFile = ({ type, content }: FileInput): Output => ({\n    [type]: [...new JSDOM(content).window.document.querySelectorAll('.tabela.big.m0.tlo_biel>tbody>tr')].reduce((p, n) => ({\n        ...p,\n        [n.querySelector('td')?.textContent || '']: parseFloat((n.querySelector('td.ar')?.textContent || '').replace(',', '.'))\n    }), {})\n})\n\nconst reducer = (p: Output, n: Output): Output => {\n    Object.keys(n).forEach(k => {\n        Object.keys(p).includes(k) ?  p[k] = { ...p[k], ...n[k] } : p[k] = n[k];\n    })\n    return p\n}\n\nconst main = () => {\n    return getFiles().map(processFile).reduce(reducer)\n}\n\n!fs.existsSync(process.cwd() + '/out') && fs.mkdirSync(process.cwd() + '/out', {recursive: true})\nfs.writeFileSync(process.cwd() + '/out/rates.json', JSON.stringify(main()))\n\nIlość linii prawdziwego kodu: 30\n\nCzas wykonania: 1min 15sec\n\nWaga pobranych plików html 43MB. Waga wydobytych danych 244KB w formacie json.\nGdybyśmy chcieli je trzymać w CSV, oszczędność wyniosła by jedynie 2 cudzysłowy\nna linię. Przy około 13 tys linii daje to 26KB zbędnych znaków przy konwersji do\nCSV czyli 10%. Jest to bardzo mało.\n\nJednak pamiętajmy, że kolejne 4 znaki można zaoszczędzić na zmiane konwencji\nzapisu dat z YYYY-MM-DD na YYMMDD, a pewnie jeszcze więcej kodując daty w\nformacie o wyższej entropii niż używany przez ludzi na codzień.\n\nZnacznie więcej, bo 15 znaków na linię oszczędziliśmy na decyzji, że daty będą\ntu kluczami.\n\n15 znaków = date (4) + value (5) + cudzysłowy do nich (4), dwókropek (1), przecinek (1)\n\nDane są dostępne do pobrania pod linkiem:\n\nhttps://preciselab.fra1.digitaloceanspaces.com/blog/scraping/bank-rates.json\n\nKod programu w tej wersji znajdziecie w repozytorium\n\napp.ts · 0e96ff56b983c86d0b2bb50dcd7760063a16681c · gustawdaniel /\nmoney-pl-scraperGitLab.comGitLab\n[https://gitlab.com/gustawdaniel/money-pl-scraper/-/blob/0e96ff56b983c86d0b2bb50dcd7760063a16681c/app.ts]\nCheerio vs JSDOM\nJakiś czas po napisaniu tego artykułu spotkałem się z problemem wysokiego\nzużycia pamięci w JSDOM. Potwierdziłem to eksperymentalnie w issue:\n\nIs cheerio still 8x faster than jsdom? · Issue #700 · cheeriojs/cheerioThis\npart\nof the readme has been written 3,5 years ago. ba80a89 Is it still the case\n(especially regarding the 4.x serie of jsdom)?GitHubcheeriojs\n[https://github.com/cheeriojs/cheerio/issues/700]Teraz pokażę jak przepisać ten\nkod na cheerio oraz jak podniesie się jego wydajność\n\n 1. Instalujemy Cheerio\n\nnpm i cheerio\n\n2. Podmieniamy import na\n\nimport cheerio from 'cheerio';\n\n3. Podmieniamy funkcję przetwarzającą plik na\n\nconst processFile = ({type, content}: FileInput): Output => ({\n    [type]: cheerio.load(content)('.tabela.big.m0.tlo_biel>tbody>tr').toArray().reduce((p, n) => ({\n        ...p,\n        ...((el) => ({[el.find('td').text()]: parseFloat(el.find('td.ar').text().replace(',', '.'))}))(cheerio(n))\n    }), {})\n})\n\nWynik poprawił się 3.4 krotnie\n\ntime ts-node app.ts\nts-node app.ts  29.53s user 1.21s system 141% cpu 21.729 total\n\nPełny DIFF jest dostępny pod linkiem:\n\nJSDOM replaced by Cheerio (3.4) times faster (4cff4a83) · Commits ·\ngustawdaniel\n/ money-pl-scraperGitLab.comGitLab\n[https://gitlab.com/gustawdaniel/money-pl-scraper/-/commit/4cff4a835589976ca26a7852f67dd42f2c4f2525]\nJeśli chcesz porozmawiać o scrapingu w ramach bezpłatnej, nie zobowiązującej\nkonsultacji, zapraszam Cię na mój Calendy.\n\nDaniel GustawWelcome to my scheduling page. Please follow the instructions to\nadd an event to my calendar.Calendly [https://calendly.com/gustaw-daniel]Warto\nprzeczytać też\n\nDownlevel Iteration for ES3/ES5 in TypeScriptTypeScript 2.3 introduced a new\n`--downlevelIteration` flag that adds full support for the ES2015 iteration\nprotocol and `for...of`-loops for ES3 and ES5 targets.Marius SchulzMarius Schulz\n[https://mariusschulz.com/blog/downlevel-iteration-for-es3-es5-in-typescript]",
            "feature_image": "__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-16-20-23.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-02-05T15:32:36.000Z",
            "updated_at": "2021-02-17T21:03:26.000Z",
            "published_at": "2021-02-17T15:10:17.000Z",
            "custom_excerpt": "Zobacz proste case study pobrania i przetworzenia danych z paginowanej tabeli.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60225c2d1446cd10bd8da59a",
            "uuid": "bfc38ad3-919b-4ae8-9f98-5ecf8890aabc",
            "title": "Ugoda KNF, Odfrankowienie oraz Unieważnienie kredytu indeksowanego w CHF",
            "slug": "obliczanie-alternatywnych-rozliczen-dla-kredytow-indeksowanych-w-chf",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"| Warunki | Obecne | Knf | Odfrankowienie | Unieważnienie |\\n|---|---|---|---|---|\\n| Indeksowanie | CHF | PLN | PLN | PLN |\\n| Marża poza bankowa | LIBOR | WIBOR | LIBOR | BRAK |\\n| Marża bankowa | ZWYKŁA | ZWYKŁA | ZWYKŁA | BRAK |\"}]],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Kredytem CHF nazywa się potocznie w Polsce kredyt który został zaciągnięty w tej walucie mimo, że spłacany był często w złotówkach przez osoby mieszkające w naszym kraju. Popularność tego rozwiązania w latach 2004-2008 spowodowana była niskim kursem franka szwajcarskiego oraz niską wartością LIBOR, czyli stawką po której największe banki świata pożyczają sobie pieniądze. Tym czasem WIBOR, który doliczany był do marży polskich kredytów był wyższy przez to potencjalne warunki tego kredytu w momencie jego zaciągania mogły się wydawać lepsze.\"]]],[1,\"p\",[[0,[],0,\"Aby przedstawić wyliczenia przyjmiemy kilka założeń. Przede wszystkim ograniczymy parametry kredytu do:\"]]],[3,\"ul\",[[[0,[],0,\"daty jego zaciągnięcia (zawsze 1 dzień miesiąca)\"]],[[0,[],0,\"ilości miesięcy na który brany jest kredyt (zawsze liczba całkowita)\"]],[[0,[],0,\"wartość kredytu (zawsze podawana w PLN)\"]],[[0,[],0,\"typ raty (Stała lub Malejąca)\"]],[[0,[],0,\"marża banku (wartość procentowa)\"]]]],[1,\"p\",[[0,[],0,\"Rozważane warunki dalszej spłaty przedstawia tabela:\"]]],[10,0],[1,\"p\",[[0,[],0,\"W przedstawionej symulacji przyjmiemy, że spłacano cały czas kredyt zgodnie z obecnymi warunkami. Nie było żadnych opóźnień, wakacji, nadpłat, a bank nie pobierał dodatkowych prowizji za przewalutowanie.\"]]],[1,\"p\",[[0,[],0,\"W takim modelu zewnętrzne dane, których potrzebujemy to:\"]]],[3,\"ol\",[[[0,[],0,\"Kurs CHF\"]],[[0,[],0,\"Wartość LIBOR\"]],[[0,[],0,\"Wartość WIBOR\"]]]],[1,\"p\",[[0,[],0,\"Na początek rozważamy ratę stałą. Algorytm obliczeń jest następujący.\"]]],[3,\"ol\",[[[0,[],0,\"Dla każdego z rozwiązań wyliczamy wartość w kursie po którym indeksujemy kredyt.\"]],[[0,[],0,\"Przyjmujemy stałą stopę spłaty na podstawie obecnej wartości marży.\"]],[[0,[],0,\"Wyliczamy z niej udział kapitału oraz marży w spłacie na dany miesiąc.\"]],[[0,[],0,\"Porównujemy to z wartością realnie zapłaconą sprowadzając to do waluty po której indeksujemy w danym wariancie.\"]],[[0,[],0,\"Dodajemy nadpłatę lub odejmujemy niedopłatę od kapitału pozostałego do spłaty.\"]]]],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "html": "<p>Kredytem CHF nazywa się potocznie w Polsce kredyt który został zaciągnięty w tej walucie mimo, że spłacany był często w złotówkach przez osoby mieszkające w naszym kraju. Popularność tego rozwiązania w latach 2004-2008 spowodowana była niskim kursem franka szwajcarskiego oraz niską wartością LIBOR, czyli stawką po której największe banki świata pożyczają sobie pieniądze. Tym czasem WIBOR, który doliczany był do marży polskich kredytów był wyższy przez to potencjalne warunki tego kredytu w momencie jego zaciągania mogły się wydawać lepsze.</p><p>Aby przedstawić wyliczenia przyjmiemy kilka założeń. Przede wszystkim ograniczymy parametry kredytu do:</p><ul><li>daty jego zaciągnięcia (zawsze 1 dzień miesiąca)</li><li>ilości miesięcy na który brany jest kredyt (zawsze liczba całkowita)</li><li>wartość kredytu (zawsze podawana w PLN)</li><li>typ raty (Stała lub Malejąca)</li><li>marża banku (wartość procentowa)</li></ul><p>Rozważane warunki dalszej spłaty przedstawia tabela:</p><!--kg-card-begin: markdown--><table>\n<thead>\n<tr>\n<th>Warunki</th>\n<th>Obecne</th>\n<th>Knf</th>\n<th>Odfrankowienie</th>\n<th>Unieważnienie</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Indeksowanie</td>\n<td>CHF</td>\n<td>PLN</td>\n<td>PLN</td>\n<td>PLN</td>\n</tr>\n<tr>\n<td>Marża poza bankowa</td>\n<td>LIBOR</td>\n<td>WIBOR</td>\n<td>LIBOR</td>\n<td>BRAK</td>\n</tr>\n<tr>\n<td>Marża bankowa</td>\n<td>ZWYKŁA</td>\n<td>ZWYKŁA</td>\n<td>ZWYKŁA</td>\n<td>BRAK</td>\n</tr>\n</tbody>\n</table>\n<!--kg-card-end: markdown--><p>W przedstawionej symulacji przyjmiemy, że spłacano cały czas kredyt zgodnie z obecnymi warunkami. Nie było żadnych opóźnień, wakacji, nadpłat, a bank nie pobierał dodatkowych prowizji za przewalutowanie.</p><p>W takim modelu zewnętrzne dane, których potrzebujemy to:</p><ol><li>Kurs CHF</li><li>Wartość LIBOR</li><li>Wartość WIBOR</li></ol><p>Na początek rozważamy ratę stałą. Algorytm obliczeń jest następujący.</p><ol><li>Dla każdego z rozwiązań wyliczamy wartość w kursie po którym indeksujemy kredyt.</li><li>Przyjmujemy stałą stopę spłaty na podstawie obecnej wartości marży.</li><li>Wyliczamy z niej udział kapitału oraz marży w spłacie na dany miesiąc.</li><li>Porównujemy to z wartością realnie zapłaconą sprowadzając to do waluty po której indeksujemy w danym wariancie.</li><li>Dodajemy nadpłatę lub odejmujemy niedopłatę od kapitału pozostałego do spłaty.</li></ol>",
            "comment_id": "60225c2d1446cd10bd8da59a",
            "plaintext": "Kredytem CHF nazywa się potocznie w Polsce kredyt który został zaciągnięty w tej\nwalucie mimo, że spłacany był często w złotówkach przez osoby mieszkające w\nnaszym kraju. Popularność tego rozwiązania w latach 2004-2008 spowodowana była\nniskim kursem franka szwajcarskiego oraz niską wartością LIBOR, czyli stawką po\nktórej największe banki świata pożyczają sobie pieniądze. Tym czasem WIBOR,\nktóry doliczany był do marży polskich kredytów był wyższy przez to potencjalne\nwarunki tego kredytu w momencie jego zaciągania mogły się wydawać lepsze.\n\nAby przedstawić wyliczenia przyjmiemy kilka założeń. Przede wszystkim\nograniczymy parametry kredytu do:\n\n * daty jego zaciągnięcia (zawsze 1 dzień miesiąca)\n * ilości miesięcy na który brany jest kredyt (zawsze liczba całkowita)\n * wartość kredytu (zawsze podawana w PLN)\n * typ raty (Stała lub Malejąca)\n * marża banku (wartość procentowa)\n\nRozważane warunki dalszej spłaty przedstawia tabela:\n\nWarunkiObecneKnfOdfrankowienieUnieważnienieIndeksowanieCHFPLNPLNPLNMarża poza\nbankowaLIBORWIBORLIBORBRAKMarża bankowaZWYKŁAZWYKŁAZWYKŁABRAKW przedstawionej\nsymulacji przyjmiemy, że spłacano cały czas kredyt zgodnie z obecnymi warunkami.\nNie było żadnych opóźnień, wakacji, nadpłat, a bank nie pobierał dodatkowych\nprowizji za przewalutowanie.\n\nW takim modelu zewnętrzne dane, których potrzebujemy to:\n\n 1. Kurs CHF\n 2. Wartość LIBOR\n 3. Wartość WIBOR\n\nNa początek rozważamy ratę stałą. Algorytm obliczeń jest następujący.\n\n 1. Dla każdego z rozwiązań wyliczamy wartość w kursie po którym indeksujemy\n    kredyt.\n 2. Przyjmujemy stałą stopę spłaty na podstawie obecnej wartości marży.\n 3. Wyliczamy z niej udział kapitału oraz marży w spłacie na dany miesiąc.\n 4. Porównujemy to z wartością realnie zapłaconą sprowadzając to do waluty po\n    której indeksujemy w danym wariancie.\n 5. Dodajemy nadpłatę lub odejmujemy niedopłatę od kapitału pozostałego do\n    spłaty.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-02-09T09:55:57.000Z",
            "updated_at": "2021-02-09T10:20:01.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "6025a6251446cd10bd8da614",
            "uuid": "6ba46c12-6e51-4ede-a565-db5ed0145d6f",
            "title": "Dotnet",
            "slug": "dotnet",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"yay -S dotnet-sdk-bin\"}],[\"code\",{\"code\":\"ssh daniel@192.168.1.2  \"}],[\"code\",{\"code\":\"npm i\\nnpm run start\"}],[\"code\",{\"code\":\"dotnet run  \"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.rabbitmq.com/tutorials/tutorial-one-dotnet.html\",\"metadata\":{\"url\":\"https://www.rabbitmq.com/tutorials/tutorial-one-dotnet.html\",\"title\":\"RabbitMQ tutorial - “Hello World!” — RabbitMQ\",\"description\":null,\"author\":null,\"publisher\":\"RabbitMQ\",\"thumbnail\":\"https://www.rabbitmq.com/img/logo-rabbitmq.svg\",\"icon\":\"https://www.rabbitmq.com/favicon.ico\"}}],[\"code\",{\"code\":\"dotnet run --project src\"}],[\"code\",{\"code\":\"yay -S aspnet-runtime-bin\"}],[\"code\",{\"code\":\"yay -S rabbitmq\\nsystemctl start rabbitmq.service\\nsystemctl enable rabbitmq.service\\n\"}],[\"code\",{\"code\":\"yay -S mssql-tools\"}],[\"code\",{\"code\":\" docker run -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=pass' -p 1433:1433 -d mcr.microsoft.com/mssql/server:2017-latest\"}]],\"markups\":[[\"a\",[\"href\",\"https://dotnet.microsoft.com/learn/dotnet/hello-world-tutorial/run\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Instalacja dotnet 5.0\"]]],[10,0],[1,\"p\",[[0,[],0,\"Login \"]]],[10,1],[1,\"p\",[[0,[],0,\"Plugin\"]]],[10,2],[1,\"p\",[[0,[],0,\"Dotent run\"]]],[10,3],[10,4],[1,\"p\",[[0,[0],1,\"https://dotnet.microsoft.com/learn/dotnet/hello-world-tutorial/run\"]]],[10,5],[10,6],[10,7],[1,\"p\",[[0,[],0,\"Brakuje bazy danych\"]]],[10,8],[1,\"p\",[]],[1,\"p\",[]],[10,9],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "html": "<p>Instalacja dotnet 5.0</p><pre><code>yay -S dotnet-sdk-bin</code></pre><p>Login </p><pre><code>ssh daniel@192.168.1.2  </code></pre><p>Plugin</p><pre><code>npm i\nnpm run start</code></pre><p>Dotent run</p><pre><code>dotnet run  </code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.rabbitmq.com/tutorials/tutorial-one-dotnet.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">RabbitMQ tutorial - “Hello World!” — RabbitMQ</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.rabbitmq.com/favicon.ico\"><span class=\"kg-bookmark-author\">RabbitMQ</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.rabbitmq.com/img/logo-rabbitmq.svg\"></div></a></figure><p><a href=\"https://dotnet.microsoft.com/learn/dotnet/hello-world-tutorial/run\">https://dotnet.microsoft.com/learn/dotnet/hello-world-tutorial/run</a></p><pre><code>dotnet run --project src</code></pre><pre><code>yay -S aspnet-runtime-bin</code></pre><pre><code>yay -S rabbitmq\nsystemctl start rabbitmq.service\nsystemctl enable rabbitmq.service\n</code></pre><p>Brakuje bazy danych</p><pre><code>yay -S mssql-tools</code></pre><p></p><p></p><pre><code> docker run -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=pass' -p 1433:1433 -d mcr.microsoft.com/mssql/server:2017-latest</code></pre>",
            "comment_id": "6025a6251446cd10bd8da614",
            "plaintext": "Instalacja dotnet 5.0\n\nyay -S dotnet-sdk-bin\n\nLogin \n\nssh daniel@192.168.1.2  \n\nPlugin\n\nnpm i\nnpm run start\n\nDotent run\n\ndotnet run  \n\nRabbitMQ tutorial - “Hello World!” — RabbitMQRabbitMQ\n[https://www.rabbitmq.com/tutorials/tutorial-one-dotnet.html]\nhttps://dotnet.microsoft.com/learn/dotnet/hello-world-tutorial/run\n\ndotnet run --project src\n\nyay -S aspnet-runtime-bin\n\nyay -S rabbitmq\nsystemctl start rabbitmq.service\nsystemctl enable rabbitmq.service\n\n\nBrakuje bazy danych\n\nyay -S mssql-tools\n\n\n\n\n\n docker run -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=pass' -p 1433:1433 -d mcr.microsoft.com/mssql/server:2017-latest",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-02-11T21:48:21.000Z",
            "updated_at": "2021-02-12T15:31:59.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "602d352c1446cd10bd8da869",
            "uuid": "7e8ff30c-4e52-4227-8002-85d57cc886f4",
            "title": "Jak pobrać dane kontaktowe 20k adwokatów w godzinę",
            "slug": "jak-pobrac-dane-kontaktowe-20k-adwokatow-w-godzine",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://rejestradwokatow.pl/adwokat\",\"metadata\":{\"url\":\"https://rejestradwokatow.pl/adwokat\",\"title\":\":: KRAIA - adwokaci, prawnicy zagraniczni, aplikanci ::\",\"description\":\"Krajowy Rejestr Adwokatów i Aplikantów Adwokackich\",\"author\":null,\"publisher\":\"adwokaci, prawnicy zagraniczni, aplikanci ::\",\"thumbnail\":\"https://rejestradwokatow.pl/templates/client_tpl/pl/_images/grafika/logo.png\",\"icon\":\"https://rejestradwokatow.pl/favicon16x16.ico\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://rejestradwokatow.pl/adwokat\",\"metadata\":{\"url\":\"https://rejestradwokatow.pl/adwokat\",\"title\":\":: KRAIA - adwokaci, prawnicy zagraniczni, aplikanci ::\",\"description\":\"Krajowy Rejestr Adwokatów i Aplikantów Adwokackich\",\"author\":null,\"publisher\":\"adwokaci, prawnicy zagraniczni, aplikanci ::\",\"thumbnail\":\"https://rejestradwokatow.pl/templates/client_tpl/pl/_images/grafika/logo.png\",\"icon\":\"https://rejestradwokatow.pl/favicon16x16.ico\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-16-48-01.png\",\"width\":1247,\"height\":849}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-16-49-24.png\",\"width\":1251,\"height\":390,\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-16-58.png\",\"width\":1228,\"height\":1005}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-17-45.png\",\"width\":1216,\"height\":402}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-18-34.png\",\"width\":1219,\"height\":333}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-19-00.png\",\"width\":1223,\"height\":250}],[\"code\",{\"code\":\"mkdir -p raw && for i in {1..272}; do wget \\\"https://rejestradwokatow.pl/adwokat/wyszukaj/strona/$i\\\" -O raw/$i.html; done\",\"language\":\"bash\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-29-47.png\",\"width\":450,\"height\":383}],[\"code\",{\"code\":\"npm init -y && tsc --init && touch entry.ts\"}],[\"code\",{\"code\":\"npm i cheerio axios @types/node\"}],[\"code\",{\"code\":\"NAZWISKO\\nIMIĘ\\nDRUGIE IMIĘ\\nMIEJSCOWOŚĆ\\nIZBA ADWOKACKA\\nSTATUS\\nSZCZEGÓŁY\"}],[\"code\",{\"code\":\"export enum LawyerStatus {\\n    active = \\\"Wykonujący zawód\\\",\\n    former = \\\"Były adwokat\\\",\\n    inavtive = \\\"Niewykonujący zawodu\\\",\\n    undefined = \\\"\\\"\\n}\\n\\nexport interface Output {\\n    surname: string\\n    name: string\\n    second_name: string\\n    city: string\\n    office: string\\n    status: LawyerStatus\\n    link: string\\n}\"}],[\"code\",{\"code\":\"import fs from 'fs';\\nimport cheerio from 'cheerio';\\n\\nimport {LawyerStatus, Output} from './helpers'\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const getFiles = (): string[] => fs\\n    .readdirSync(process.cwd() + `/raw`)\\n    .filter((name) => /^\\\\d+\\\\.html/.test(name))\\n    .map(name =>\\n        fs.readFileSync(process.cwd() + '/raw/' + name).toString()\\n    );\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const processFile = (content: string): Output[] => cheerio\\n    .load(content)('.rejestr tbody tr')\\n    .toArray()\\n    .map(row => ({\\n        surname: cheerio(row).find('td:nth-of-type(2)').text(),\\n        name: cheerio(row).find('td:nth-of-type(3)').text().trim(),\\n        second_name: cheerio(row).find('td:nth-of-type(4)').text(),\\n        city: cheerio(row).find('td:nth-of-type(5)').text(),\\n        office: cheerio(row).find('td:nth-of-type(6)').text(),\\n        status: cheerio(row).find('td:nth-of-type(7)').text() as LawyerStatus,\\n        link: cheerio(row).find('td:nth-of-type(8) a').attr('href') || '',\\n    }))\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const reducer = (a:Output[], b:Output[]):Output[] => [...a, ...b];\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const main = () => {\\n    return getFiles().map(processFile).reduce(reducer);\\n}\\n\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const out = main();\\n\\n!fs.existsSync(process.cwd() + '/out') && fs.mkdirSync(process.cwd() + '/out', {recursive: true})\\nfs.writeFileSync(process.cwd() + '/out/basic_data.json', JSON.stringify(out))\\n\\nconsole.dir(out)\"}],[\"code\",{\"code\":\"ts-node entry.ts\"}],[\"code\",{\"code\":\"35.95s user 0.98s system 125% cpu 29.466 total\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-18-08-48.png\",\"width\":614,\"height\":332}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/lawyers-scraper/-/commit/1b87854fd741d6bfc10f8c36c21b7390a3095260\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/lawyers-scraper/-/commit/1b87854fd741d6bfc10f8c36c21b7390a3095260\",\"title\":\"Processing tables with lawyers data (1b87854f) · Commits · gustawdaniel / lawyers-scraper\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"code\",{\"code\":\"import {readFileSync} from \\\"fs\\\";\\n\\nexport const getConfig = () => JSON.parse(readFileSync(process.cwd() + '/out/basic_data.json').toString());\"}],[\"code\",{\"code\":\"import fs from \\\"fs\\\";\\nimport axios from 'axios';\\nimport {getConfig} from \\\"./helpers\\\";\\n\\nconst Reset = \\\"\\\\x1b[0m\\\"\\nconst FgRed = \\\"\\\\x1b[31m\\\"\\nconst FgGreen = \\\"\\\\x1b[32m\\\"\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const init = new Date().getTime();\\nlet last = new Date().getTime();\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const main = async () => {\\n    const links = getConfig().map((a:{link:string}):string => a.link);\\n\\n    while (links.length) {\\n        const link = links.pop();\\n        const name = link.split('/').reverse()[0];\\n        const {data, status} = await axios.get(link);\\n        fs.writeFileSync(process.cwd() + `/raw/${name}.html`, data);\\n        const now = new Date().getTime();\\n        console.log(status === 200 ? `${FgGreen}%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s${Reset}` : `${FgRed}%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s${Reset}`, status, links.length, now - last, now - init, name);\\n        last = new Date().getTime();\\n    }\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"main().then(() => console.log(\\\"ok\\\")).catch(console.error);\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-18-30-20.png\",\"width\":502,\"height\":487}],[\"code\",{\"code\":\"let queueLength = 0;\\nconst MAX_QUEUE_LENGTH = 500;\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const append = async (links: string[]) => {\\n    queueLength++;\\n    const link: string = links.pop() || '';\\n    const name = link.split('/').reverse()[0];\\n    const {data, status} = await axios.get(link);\\n    fs.writeFileSync(process.cwd() + `/raw/${name}.html`, data);\\n    const now = new Date().getTime();\\n    console.log(status === 200 ? `${FgGreen}%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s${Reset}` : `${FgRed}%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s${Reset}`,\\n        status, links.length, queueLength, now - last, now - init, name\\n    );\\n    last = new Date().getTime();\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const sleep = (time: number) => new Promise((resolve) => setTimeout(resolve, time))\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const main = async () => {\\n    const links = getConfig().map((a: { link: string }): string => a.link);\\n\\n    while (links.length) {\\n        await sleep(9);\\n        if (queueLength < MAX_QUEUE_LENGTH)\\n            append(links).finally(() => queueLength--)\\n    }\\n}\",\"language\":\"ts\"}],[\"embed\",{\"url\":\"https://youtu.be/5S2Mszhjbuw\",\"html\":\"<iframe width=\\\"200\\\" height=\\\"150\\\" src=\\\"https://www.youtube.com/embed/5S2Mszhjbuw?feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\",\"metadata\":{\"title\":\"Scraping Rejestr Adwokatów\",\"author_name\":\"gustawdaniel\",\"author_url\":\"https://www.youtube.com/user/gustawdaniel\",\"height\":150,\"width\":200,\"version\":\"1.0\",\"provider_name\":\"YouTube\",\"provider_url\":\"https://www.youtube.com/\",\"thumbnail_height\":360,\"thumbnail_width\":480,\"thumbnail_url\":\"https://i.ytimg.com/vi/5S2Mszhjbuw/hqdefault.jpg\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gitlab.com/gustawdaniel/lawyers-scraper/-/commit/ca8895f1d3474881269fbf3ef088a7ff03f9010f\",\"metadata\":{\"url\":\"https://gitlab.com/gustawdaniel/lawyers-scraper/-/commit/ca8895f1d3474881269fbf3ef088a7ff03f9010f\",\"title\":\"Parallel scraping of profile pages (ca8895f1) · Commits · gustawdaniel / lawyers-scraper\",\"description\":\"GitLab.com\",\"author\":null,\"publisher\":\"GitLab\",\"thumbnail\":\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\",\"icon\":\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"}}],[\"code\",{\"code\":\"export interface ActiveOutput {\\n    id: string\\n    date: string\\n    address: string\\n    phone: string\\n    email: string\\n    workplace: string\\n    speciality: string[]\\n}\\n\\nexport interface FormerOutput {\\n    id: string\\n    date: string\\n    date_end: string\\n    last_place: string\\n    replaced_by: string\\n}\\n\\nexport interface UndefinedOutput {\\n    id: string\\n}\\n\\nexport interface InactiveOutput {\\n    id: string\\n    date: string\\n}\\n\\nexport type ExtraOutput = ActiveOutput | FormerOutput | UndefinedOutput | InactiveOutput\"}],[\"code\",{\"code\":\"import {FormerOutput, getConfig} from \\\"./helpers\\\";\\nimport {Output, ExtraOutput, LawyerStatus} from './helpers'\\nimport {readFileSync, writeFileSync} from \\\"fs\\\";\\nimport cheerio from 'cheerio';\\n\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const cleanText = (text: string): string => text.split(/[\\\\n|\\\\t]/).map((t: string): string => t.trim()).filter(t => t).join('\\\\n');\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const processFile = (content: string, status: LawyerStatus): ExtraOutput => {\\n    const $ = cheerio.load(content);\\n\\n    const section = (n: number): string => `section .line_list_K div:nth-of-type(${n}) div:nth-of-type(1)`\\n\\n    const id = $('main section h3').text();\\n\\n    switch (status) {\\n        case LawyerStatus.active:\\n            return {\\n                id,\\n                date: $(section(2)).text(),\\n                address: cleanText($('.line_list_K div:nth-of-type(3) div:nth-of-type(1)').text()),\\n                phone: $('.line_list_K div:nth-of-type(4) div:nth-of-type(1)').text(),\\n                email: (el => el.attr('data-ea') + `@` + el.attr('data-eb'))($('.line_list_K div:last-of-type div:nth-of-type(1)')),\\n                speciality: $('.line_list_A > div').toArray().map((el): string => cheerio(el).text().trim()),\\n                workplace: cleanText($('.mb_tab_content.special_one .line_list_K').text())\\n            };\\n        case LawyerStatus.former:\\n            return {\\n                id,\\n                date: $(section(2)).text(),\\n                date_end: $(section(3)).text().trim(),\\n                last_place: $(section(4)).text().trim(),\\n                replaced_by: $(section(5)).text().trim()\\n            }\\n        case LawyerStatus.inavtive:\\n            return {\\n                id,\\n                date: $(section(2)).text(),\\n            }\\n        case LawyerStatus.undefined:\\n            return {\\n                id\\n            }\\n    }\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"let initDate = new Date().getTime();\\nlet lastDate = new Date().getTime();\\n\\nconst main = () => {\\n    const lawyers = getConfig().reverse().filter((e: Output, i: number) => i < Infinity);\\n    const res: (Output & ExtraOutput)[] = [];\\n\\n    while (lawyers.length) {\\n        const lawyer = lawyers.shift();\\n        const name = lawyer.link.split('/').reverse()[0];\\n        const extraLawyerInfo = processFile(readFileSync(process.cwd() + `/raw/${name}.html`).toString(), lawyer.status)\\n\\n        res.push({...lawyer, ...extraLawyerInfo});\\n\\n        if (lawyers.length % 100 === 0) {\\n            const now = new Date().getTime();\\n            console.log(res.length, lawyers.length, now - lastDate, now - initDate);\\n            lastDate = new Date().getTime();\\n        }\\n    }\\n\\n    return res;\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const out = main();\\nwriteFileSync(process.cwd() + '/out/extended_data.json', JSON.stringify(out))\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-20-17-27.png\",\"width\":158,\"height\":111}],[\"code\",{\"code\":\"ts-node parser.ts  124.32s user 1.81s system 131% cpu 1:35.98 total\"}],[\"code\",{\"code\":\"du -h out/extended_data.json \\n13M\\tout/extended_data.json\"}],[\"code\",{\"code\":\"mongoimport --db test --collection lawyer --jsonArray --drop --file ./out/extended_data.json\",\"language\":\"bash\"}],[\"code\",{\"code\":\"2021-02-17T20:26:58.455+0100\\tconnected to: mongodb://localhost/\\n2021-02-17T20:26:58.455+0100\\tdropping: test.lawyer\\n2021-02-17T20:27:00.013+0100\\t27191 document(s) imported successfully. 0 document(s) failed to import.\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"mongo test\"}],[\"code\",{\"code\":\"db.lawyer.aggregate([{$group:{_id: \\\"$status\\\", sum:{$sum: 1}, link:{$first: \\\"$link\\\"}}}])\"}],[\"code\",{\"code\":\"{ \\\"_id\\\" : \\\"\\\", \\\"sum\\\" : 7, \\\"link\\\" : \\\"https://rejestradwokatow.pl/adwokat/jawor-marcin-51297\\\" }\\n{ \\\"_id\\\" : \\\"Niewykonujący zawodu\\\", \\\"sum\\\" : 4410, \\\"link\\\" : \\\"https://rejestradwokatow.pl/adwokat/konopacka-izabela-83958\\\" }\\n{ \\\"_id\\\" : \\\"Wykonujący zawód\\\", \\\"sum\\\" : 19930, \\\"link\\\" : \\\"https://rejestradwokatow.pl/adwokat/konrad-adam-33796\\\" }\\n{ \\\"_id\\\" : \\\"Były adwokat\\\", \\\"sum\\\" : 2844, \\\"link\\\" : \\\"https://rejestradwokatow.pl/adwokat/konopiski-sawomir-48480\\\" }\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-20-33-57.png\",\"width\":1564,\"height\":812}],[\"code\",{\"code\":\"mongoimport --collection lawyer <connection-string>  --jsonArray --drop --file ./out/extended_data.json\"}],[\"code\",{\"code\":\"mongodb+srv://user:pass@cluseter_number.mongodb.net/db_name\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-21-01-11.png\",\"width\":1857,\"height\":798}],[\"html\",{\"html\":\"<iframe style=\\\"background: #FFFFFF;border: none;border-radius: 2px;box-shadow: 0 2px 10px 0 rgba(70, 76, 79, .2);\\\" width=\\\"640\\\" height=\\\"480\\\" src=\\\"https://charts.mongodb.com/charts-project-0-oreyr/embed/charts?id=b1bd9eb7-ff8c-4cdd-8999-fb66d8c252e3&theme=light\\\"></iframe>\"}],[\"code\",{\"code\":\"{status: {$ne: \\\"\\\"}, date:{$nin: [\\\"\\\",\\\"0000-00-00\\\",\\\"2019-00-01\\\"]}}\",\"language\":\"json\"}],[\"code\",{\"code\":\"{computed_date: {\\n  $dateFromString: {\\n    dateString: \\\"$date\\\"\\n  }\\n},\\n  year:  {$year:{\\n  $dateFromString: {\\n    dateString: \\\"$date\\\"\\n  }\\n}}\\n}\",\"language\":\"json\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-21-34-30.png\",\"width\":1840,\"height\":980}],[\"html\",{\"html\":\"<iframe style=\\\"background: #FFFFFF;border: none;border-radius: 2px;box-shadow: 0 2px 10px 0 rgba(70, 76, 79, .2);\\\" width=\\\"640\\\" height=\\\"480\\\" src=\\\"https://charts.mongodb.com/charts-project-0-oreyr/embed/charts?id=696d81ab-c2e7-4ae9-9011-38048cb2595f&theme=light\\\"></iframe>\"}],[\"html\",{\"html\":\"<iframe style=\\\"background: #FFFFFF;border: none;border-radius: 2px;box-shadow: 0 2px 10px 0 rgba(70, 76, 79, .2);\\\" width=\\\"640\\\" height=\\\"480\\\" src=\\\"https://charts.mongodb.com/charts-project-0-oreyr/embed/charts?id=4b75fd41-8d05-422c-bae0-b642342842b4&theme=light\\\"></iframe>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-21-46-31.png\",\"width\":255,\"height\":415}],[\"html\",{\"html\":\"<iframe style=\\\"background: #FFFFFF;border: none;border-radius: 2px;box-shadow: 0 2px 10px 0 rgba(70, 76, 79, .2);\\\" width=\\\"640\\\" height=\\\"480\\\" src=\\\"https://charts.mongodb.com/charts-project-0-oreyr/embed/charts?id=9fe8232b-7a1d-444b-9ccb-05dd85743fae&theme=light\\\"></iframe>\"}],[\"code\",{\"code\":\"{phone: /^(\\\\d|-)+$/}\",\"language\":\"json\"}],[\"html\",{\"html\":\"<iframe style=\\\"background: #FFFFFF;border: none;border-radius: 2px;box-shadow: 0 2px 10px 0 rgba(70, 76, 79, .2);\\\" width=\\\"640\\\" height=\\\"480\\\" src=\\\"https://charts.mongodb.com/charts-project-0-oreyr/embed/charts?id=69075db2-104d-45c4-ae3f-98ff90f5f9f0&theme=light\\\"></iframe>\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://calendly.com/gustaw-daniel\",\"metadata\":{\"url\":\"https://calendly.com/gustaw-daniel\",\"title\":\"Daniel Gustaw\",\"description\":\"Welcome to my scheduling page. Please follow the instructions to add an event to my calendar.\",\"author\":null,\"publisher\":\"Calendly\",\"thumbnail\":\"https://assets.calendly.com/assets/ogimage-a63bb2f442cd9e6345a5e4d7fe75393c6cfcc1ff29e48e858742d43573a8b02c.png?source=opengraph\",\"icon\":\"https://assets.calendly.com/assets/touch-icon-ipad-retina-7a95e0c775301f4c0a22002bdf0a95d3c2b9cbe95af29c64f9c9573bac1f01e4.png\"}}]],\"markups\":[[\"a\",[\"href\",\"https://rejestradwokatow.pl/adwokat/wyszukaj\"]],[\"a\",[\"href\",\"https://rejestradwokatow.pl/adwokat/wyszukaj/strona/272\"]],[\"a\",[\"href\",\"https://rejestradwokatow.pl/adwokat/urek-macias-paulina-54635\"]],[\"a\",[\"href\",\"https://rejestradwokatow.pl/adwokat/urkowska-trzciska-justyna-48516\"]],[\"a\",[\"href\",\"https://rejestradwokatow.pl/adwokat/urowski-jan-52462\"]],[\"a\",[\"href\",\"https://rejestradwokatow.pl/adwokat/urek-wanda-54247\"]],[\"code\"],[\"a\",[\"href\",\"https://gitlab.com/gustawdaniel/lawyers-scraper/-/raw/8259451e89ef695a89576a8229c440301c53009e/out/extended_data.json\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Strona internetowa \\\"Rejestr Adwokatów\\\" jest publicznym zbiorem danych. Zgodnie z obwiązującym prawem można gromadzić i przetwarzać publicznie dostępne dane osobowe z rejestrów.\"]]],[10,0],[1,\"p\",[[0,[],0,\"W tym artykule przygotujemy zestaw danych pozwalających na kontakt z prawnikami z tego rejestru. Jeśli po prostu szukasz prawnika, to możesz go tam znaleźć i nie potrzebujesz pobierać całej bazy.\"]]],[1,\"p\",[[0,[],0,\"Jeśli jednak prowadzisz działalność w której adwokaci stanowią Twoją grupę docelową, to dostrzeżesz korzyści z możliwości załadowania tych danych do swojego systemu CRM.\"]]],[1,\"p\",[[0,[],0,\"Ten artykuł pokazuje jak w napisać kod programu pobierającego te dane z publicznego rejestru. Jeśli interesują Cię same dane przejdź do końca artykułu.\"]]],[1,\"p\",[[0,[],0,\"Projekt podzielimy na etapy:\"]]],[3,\"ol\",[[[0,[],0,\"Zbadanie strony z danymi i wyznaczenie strategii pobierania\"]],[[0,[],0,\"Pobranie tabel z podstawowymi danymi\"]],[[0,[],0,\"Przetworzenie tabel i wydobycie linków do podstron\"]],[[0,[],0,\"Pobranie podstron z danymi kontaktowymi\"]],[[0,[],0,\"Przetworzenie danych kontaktowych\"]],[[0,[],0,\"Załadowanie danych do bazy i pokazanie wyników zapytań\"]]]],[1,\"h2\",[[0,[],0,\"Badanie strony z danymi (strategia)\"]]],[1,\"p\",[[0,[],0,\"Rejestr adwokatów dostępny pod linkiem:\"]]],[10,1],[1,\"p\",[[0,[],0,\"zawiera zielony przycisk wyszukaj. Po jego kliknięciu przechodzimy na stronę\"]]],[1,\"blockquote\",[[0,[0],1,\"https://rejestradwokatow.pl/adwokat/wyszukaj\"]]],[1,\"p\",[[0,[],0,\"zawierającą klasyczną tabelę\"]]],[10,2],[1,\"p\",[[0,[],0,\"Schodząc na sam dół i klikając \\\"ostatnia\\\"\"]]],[10,3],[1,\"p\",[[0,[],0,\"zostaniemy przekierowani na stronę z klasyczną paginacją\"]]],[1,\"blockquote\",[[0,[1],1,\"https://rejestradwokatow.pl/adwokat/wyszukaj/strona/272\"]]],[1,\"p\",[[0,[],0,\"Adwokatów na tel liście można podzielić na:\"]]],[3,\"ul\",[[[0,[],0,\"wykonujących zawód\"]],[[0,[],0,\"byłych adwokatów\"]],[[0,[],0,\"nie wykonujących zawodu\"]]]],[1,\"p\",[[0,[],0,\"Każda z kategorii ma nieco inną stronę profilową:\"]]],[1,\"blockquote\",[[0,[2],1,\"https://rejestradwokatow.pl/adwokat/urek-macias-paulina-54635\"]]],[1,\"p\",[[0,[],0,\"Adwokat wykonujący zawód ma najpełniejszy profil\"]]],[10,4],[1,\"p\",[[0,[],0,\"Niektórzy mają do tego telefon komórkowy\"]]],[1,\"blockquote\",[[0,[3],1,\"https://rejestradwokatow.pl/adwokat/urkowska-trzciska-justyna-48516\"]]],[10,5],[1,\"p\",[[0,[],0,\"Dane o byłych adwokatach są ograniczone\"]]],[1,\"blockquote\",[[0,[4],1,\"https://rejestradwokatow.pl/adwokat/urowski-jan-52462\"]]],[10,6],[1,\"p\",[[0,[],0,\"Jeszcze bardziej o nie wykonujących zawodu\"]]],[1,\"blockquote\",[[0,[5],1,\"https://rejestradwokatow.pl/adwokat/urek-wanda-54247\"]]],[10,7],[1,\"p\",[[0,[],0,\"Strategia pobrania tych danych jest prosta. Na początku przejdziemy tabelę budując bazową listę z podstawowymi danymi. Wśród nich znajdą się linki do profili. Pobierzemy je wszystkie i z nich uzyskamy rozszerzenie tej bazowej listy o najcenniejsze dane, na przykład kontaktowe.\"]]],[1,\"h2\",[[0,[],0,\"Pobranie tabel z bazowymi danymi\"]]],[1,\"p\",[[0,[],0,\"Wszystkie podstrony pobieramy jedną komendą w bashu\"]]],[10,8],[1,\"p\",[[0,[],0,\"Mogli byśmy to przyśpieszyć pobierając kilka stron jednocześnie, ale dla naszych celów taki jedno-liniowy kod jest znacznie lepszy, bo czas jego napisania jest bardzo krótki. Czas pobranie wszystkich stron zależy oczywiście od szybkości łącza internetowego, u mnie było to \"],[0,[6],1,\"0.54\"],[0,[],0,\" pliku na sekundę czyli około \"],[0,[6],1,\"8.39\"],[0,[],0,\" minuty.\"]]],[1,\"h2\",[[0,[],0,\"Przetworzenie tabel\"]]],[1,\"p\",[[0,[],0,\"Na każdej podstronie mamy taką samą tabelę\"]]],[10,9],[1,\"p\",[[0,[],0,\"Projekt inicjalizujemy komendą\"]]],[10,10],[1,\"p\",[[0,[],0,\"Instalujemy \"],[0,[6],1,\"cheerio\"],[0,[],0,\" oraz \"],[0,[6],1,\"axios\"],[0,[],0,\" które będą nam potrzebne do przetwarzania plików \"],[0,[6],1,\"html\"],[0,[],0,\" oraz wysyłania żądań \"],[0,[6],1,\"http\"],[0,[],0,\". Dodamy jeszcze \"],[0,[6],1,\"@types/node\"],[0,[],0,\" które pozwalają nam importować na przykład \"],[0,[6],1,\"fs\"],[0,[],0,\".\"]]],[10,11],[1,\"p\",[[0,[],0,\"Ponieważ projekt będzie zawierał kilka plików utworzymy też plik \"],[0,[6],1,\"helpers.ts\"],[0,[],0,\", w którym będziemy umieszczać współdzielony kod. Przede wszystkim interfejsy.\"]]],[1,\"p\",[[0,[],0,\"Pisanie kodu zaczniemy od zdefiniowania interfejsów danych wyjściowych z przetwarzania tabeli. Zamiast trzymania polskich nazw jak w nagłówku tabeli:\"]]],[10,12],[1,\"p\",[[0,[],0,\"Zdecydujemy się na ich angielskie odpowiedniki\"]]],[10,13],[1,\"p\",[[0,[],0,\"i umieścimy je w pliku \"],[0,[6],1,\"helpers.ts\"]]],[1,\"p\",[[0,[],0,\"W \"],[0,[6],1,\"entry.ts\"],[0,[],0,\" znajdzie się kod który na plikach wykona klasyczną procedurę mapowania i redukcji.\"]]],[1,\"p\",[[0,[],0,\"Plik zaczyna się od niezbędnych importów\"]]],[10,14],[1,\"p\",[[0,[],0,\"Następnie dodajemy funkcję odczytującą pliki i oddającą tablicę z ich zawartościami.\"]]],[10,15],[1,\"p\",[[0,[],0,\"Kolejną funkcją, kluczową dla tego skryptu jest \"],[0,[6],1,\"processFile\"],[0,[],0,\", która za pomocą \"],[0,[6],1,\"cheerio\"],[0,[],0,\" przetwarza ciągi znaków z \"],[0,[6],1,\"html\"],[0,[],0,\" na tablice z danymi adwokatów, które zawarte są w tabeli.\"]]],[10,16],[1,\"p\",[[0,[],0,\"Ponieważ każda podstrona tabeli zwraca osobną tablicę, musimy połączyć je w jedną aby uniknąć problemów z nienaturalną dla naszych potrzeb paginacją. Pomoże nam w tym funkcja \"],[0,[6],1,\"reducer\"],[0,[],0,\".\"]]],[10,17],[1,\"p\",[[0,[],0,\"Cały program to po prostu wykonanie kolejno tych funkcji, tak aby przekazywały sobie nawzajem wyniki jako argumenty.\"]]],[10,18],[1,\"p\",[[0,[],0,\"Finalnie tworzymy katalog \"],[0,[6],1,\"out\"],[0,[],0,\" i umieszczamy w nim plik \"],[0,[6],1,\"basic_data.json\"],[0,[],0,\" z danymi odczytanymi z plików\"]]],[10,19],[1,\"p\",[[0,[],0,\"Wykonanie:\"]]],[10,20],[1,\"p\",[[0,[],0,\"zajmuje pół minuty\"]]],[10,21],[1,\"p\",[[0,[],0,\"i generuje plik o wadze \"],[0,[6],1,\"5.1M\"]]],[10,22],[1,\"p\",[[0,[],0,\"Repozytorium z kodem można znaleźć tutaj:\"]]],[10,23],[1,\"h2\",[[0,[],0,\"Pobranie podstron\"]]],[1,\"p\",[[0,[],0,\"Pobranie podstron zrealizujemy już nie przez \"],[0,[6],1,\"wget\"],[0,[],0,\" lecz w \"],[0,[6],1,\"node\"],[0,[],0,\". W pliku \"],[0,[6],1,\"helpers.ts\"],[0,[],0,\" umieścimy pomocniczy kod do odczytu wytworzonego właśnie zbioru danych bazowych.\"]]],[10,24],[1,\"p\",[[0,[],0,\"Bardzo pomocne przy scrapingu jest kolorowanie na zielono poprawnie wykonanych requestów oraz na czerwono tych zakończonych błędem.\"]]],[1,\"p\",[[0,[],0,\"Mimo, że istnieją gotowe biblioteki do kolorowania, w tak prostym przypadku wygodniej jest zapisać kolory w stałych.\"]]],[1,\"p\",[[0,[],0,\"Nowy plik \"],[0,[6],1,\"scraper.ts\"],[0,[],0,\" zaczniemy właśnie od importów i definiowania kolorów.\"]]],[10,25],[1,\"p\",[[0,[],0,\"Kolejną obok graficznego oznaczania sukcesu i porażki cenną informacją jest czas. Dlatego w kolejnych liniach zdefiniujemy sobie zmienne pozwalające przechowywać punkty czasowe rozpoczęcia programu oraz zakończenia poprzedniej pętli.\"]]],[10,26],[1,\"p\",[[0,[],0,\"W funkcji \"],[0,[6],1,\"main\"],[0,[],0,\" umieścimy kod pobierający zbiór danych bazowych i iterujący po nim w celu pobrania wszystkich linków i zapisania stron w plikach.\"]]],[10,27],[1,\"p\",[[0,[],0,\"Najmniej oczywiste jest tu wyświetlanie, ale napiszę tylko, że dzięki znacznikom z kolorami mamy tu zielone lub czerwone linie. Prezentują one kolejno.\"]]],[3,\"ul\",[[[0,[],0,\"kod odpowiedzi (spodziewany to 200)\"]],[[0,[],0,\"ilość pozostałych do końca rekordów\"]],[[0,[],0,\"czas od ostatniego wykonania pętli w ms\"]],[[0,[],0,\"czas od początku działania programu w ms\"]],[[0,[],0,\"nazwę tworzonego pliku\"]]]],[1,\"p\",[[0,[],0,\"Wykonanie to linia:\"]]],[10,28],[1,\"p\",[[0,[],0,\"Tak wyglądają przykładowe wywołania, jedno z, a drugie bez zapisu plików.\"]]],[10,29],[1,\"p\",[[0,[],0,\"Widać, że nie różnią się od siebie w zauważalny sposób i średni czas na zapis jednego adwokata to koło 150 ms. Daje to łącznie \"],[0,[6],1,\"27190*0.15\"],[0,[],0,\" = \"],[0,[6],1,\"4078\"],[0,[],0,\" sekund. Jednak to więcej niż \"],[0,[6],1,\"3600\"],[0,[],0,\". Ponad godzina!\"]]],[1,\"p\",[[0,[],0,\"Nie możemy sobie na to pozwolić, ponieważ w tytule artykułu obiecuję, że pobierzemy te dane w czasie krótszym niż godzinę, a ponad 8 minut zużyto już na pobranie bazowych danych.\"]]],[1,\"h2\",[[0,[],0,\"Jednoczesne żądania\"]]],[1,\"p\",[[0,[],0,\"Na szczęście dzięki możliwości wysyłania kolejnych żądań zanim spłyną wyniki z poprzednich jesteśmy w stanie podnieść szybkość pobierania z około \"],[0,[6],1,\"6.6\"],[0,[],0,\" plików na sekundę (1 plik co 150 ms) do około \"],[0,[6],1,\"40\"],[0,[],0,\" plików na sekundę (średnio 1 plik co 25 ms).\"]]],[1,\"p\",[[0,[],0,\"Finalnie wynik pobierania to  \"],[0,[6],1,\"27191/(11*60+24.20)\"],[0,[],0,\" = \"],[0,[6],1,\"39.74\"],[0,[],0,\" plików / sekundę. Czyli łączny czas wyniósł 11 minut 24 sekundy zamiast szacowanej w poprzednim akapicie 1 godziny i 8 minut.\"]]],[1,\"p\",[[0,[],0,\"Jak udało się tak bardzo podnieść czas pobierania danych? Spójrzmy na kod. Przede wszystkim zacząłem od dołączenia dwóch kolejnych zmiennych:\"]]],[10,30],[1,\"p\",[[0,[],0,\"Stała oznacza liczbę plików które mogą być jednocześnie przetwarzane. To znaczy, że jeśli czekamy na 500 plików jednocześnie, to skrypt nie będzie wysyłał kolejnych żądań. Nie ma to sensu, bo nie chcemy przecież niepotrzebnie obciążyć zbyt dużej ilości RAM ani zostać odcięci przez serwer z powodu przekroczenia liczby żądań, które ten może zakolejkować. \"]]],[1,\"p\",[[0,[],0,\"Stała \"],[0,[6],1,\"queueLength\"],[0,[],0,\" jest naszą aktualną liczbą żądań, które wysłaliśmy i na których odpowiedzi jeszcze czekamy.\"]]],[1,\"p\",[[0,[],0,\"Całą logikę, która wcześniej znalazła się w \"],[0,[6],1,\"main\"],[0,[],0,\" przenosimy do funkcji \"],[0,[6],1,\"append\"],[0,[],0,\". Jej zadaniem jest załączenie żądania do kolejki.\"]]],[10,31],[1,\"p\",[[0,[],0,\"Od poprzedniego kodu różni się tym, że podnosi \"],[0,[6],1,\"queueLength\"],[0,[],0,\" oraz wyświetla jej aktualną wartość.\"]]],[1,\"p\",[[0,[],0,\"Do tego dołączamy funkcję \"],[0,[6],1,\"sleep\"],[0,[],0,\", która pozwoli nam na odczekiwania między kolejnymi żądaniami. \"]]],[10,32],[1,\"p\",[[0,[],0,\"Jak widać przy wysyłaniu wielu żądań jednocześnie ważne są mechanizmy zabezpieczające nas przed ryzykiem, że przygnieciemy serwer nadmierną ilością ruchu sieciowego i doprowadzimy do gubienia się pakietów.\"]]],[1,\"p\",[[0,[],0,\"Sama funkcja \"],[0,[6],1,\"main\"],[0,[],0,\" przyjmuje teraz rolę tę samą co ostatnia, le nie czeka na wypełnianie \"],[0,[6],1,\"promises\"],[0,[],0,\" z funkcji \"],[0,[6],1,\"append\"],[0,[],0,\". Zamiast tego limituje jej wywołania na podstawie oczekiwania na \"],[0,[6],1,\"sleep\"],[0,[],0,\" i warunku nie przekroczenia \"],[0,[6],1,\"MAX_QUEUE_LENGTH\"],[0,[],0,\".\"]]],[10,33],[1,\"p\",[[0,[],0,\"Poniżej widzimy fragment z wywołania tak przepisanego programu:\"]]],[10,34],[1,\"p\",[[0,[],0,\"Kod można sprawdzić w commicie:\"]]],[10,35],[1,\"h2\",[[0,[],0,\"Przetworzenie stron profilowych\"]]],[1,\"p\",[[0,[],0,\"Kiedy mamy już podstrony z profilami adwokatów, możemy utworzyć ostatni już plik \"],[0,[6],1,\"parser.ts\"],[0,[],0,\" i za jego pomocą wzbogacić bazowy zbiór danych o informacje widoczne na stronach profilowych. Zanim jednak przejdziemy do kodu skupimy się na danych, jakie chcemy zebrać o prawnikach o różnych statusach:\"]]],[10,36],[1,\"p\",[[0,[],0,\"Status \\\"Undefined\\\" oznacza prawnika, który nie ma statusu. Jest w tej bazie kilku takich prawników, często jest to związane ze znalezieniem duplikatu konta. Nie będziemy w to wnikać, bo to margines tej bazy.\"]]],[1,\"p\",[[0,[],0,\"W pliku \"],[0,[6],1,\"parser.ts\"],[0,[],0,\" dołączamy importy\"]]],[10,37],[1,\"p\",[[0,[],0,\"Ponieważ teksty są często wypełnione znakami nowej linii i pustymi znakami między nimi zwykły \"],[0,[6],1,\"trim\"],[0,[],0,\" nie wystarczy. Dlatego napisaliśmy funkcję do czyszczenia tekstów wieloliniowych\"]]],[10,38],[1,\"p\",[[0,[],0,\"Samo przetwarzanie plików wygląda tak samo jak zawsze, z tym, że zależy ono od statusu prawnika\"]]],[10,39],[1,\"p\",[[0,[],0,\"Kolejny dość przewidywalny fragment kodu to funkcja \"],[0,[6],1,\"main\"],[0,[],0,\". \"]]],[10,40],[1,\"p\",[[0,[],0,\"Na końcu zapis pliku \"]]],[10,41],[1,\"p\",[[0,[],0,\"Wykonanie tego pliku pokazuje kolumny z\"]]],[3,\"ul\",[[[0,[],0,\"ilością przetworzonych plików\"]],[[0,[],0,\"ilością pozostałych plików\"]],[[0,[],0,\"czasem miedzy kolejnymi setkami\"]],[[0,[],0,\"łącznym czasem od włączenia aplikacji\"]]]],[10,42],[1,\"p\",[[0,[],0,\"Przetworzenie każdej setki plików zajmuje około 340 ms. Co oznacza mniej więcej 300 na sekundę, czyli całość powinna zająć około półtorej minuty. Faktycznie:\"]]],[10,43],[1,\"p\",[[0,[],0,\"Wygenerowany plik z danymi dotyczącymi prawników warzy \"],[0,[6],1,\"13MB\"]]],[10,44],[1,\"p\",[[0,[],0,\"Jeśli chcesz pobrać ten plik, znajduje się on pod linkiem:\"]]],[1,\"blockquote\",[[0,[7],1,\"https://gitlab.com/gustawdaniel/lawyers-scraper/-/raw/8259451e89ef695a89576a8229c440301c53009e/out/extended_data.json\"]]],[1,\"h2\",[[0,[],0,\"Załadowanie danych do bazy\"]]],[1,\"p\",[[0,[],0,\"Plik \"],[0,[6],1,\"json\"],[0,[],0,\" jest bardzo wygodny jako nośnik wymiany danych. Nie nadaje się niestety do tego, żeby bezpośrednio wygodnie go przetwarzać i budować na nim zapytania. Na szczęście od załadowania tego pliku do bazy \"],[0,[6],1,\"mongo\"],[0,[],0,\" dzieli nas tylko jedna komenda. Jest to:\"]]],[10,45],[1,\"p\",[[0,[],0,\"Pokaże ona \"]]],[10,46],[1,\"p\",[[0,[],0,\"Włączając bazę poleceniem\"]]],[10,47],[1,\"p\",[[0,[],0,\"dostaniemy się do konsoli z której możemy wykonywać zapytania:\"]]],[10,48],[1,\"p\",[[0,[],0,\"Zwróci rozkład względem wykonywanych zawodów i przykładowe linki:\"]]],[10,49],[1,\"p\",[[0,[],0,\"Dzięki interfejsowi Compass możemy przeglądać znacznie więcej takich grupowań w trybie graficznym\"]]],[10,50],[1,\"p\",[[0,[],0,\"Jeśli chcemy wrzucić te dane do mongo atlas możemy użyć komendy\"]]],[10,51],[1,\"p\",[[0,[],0,\"gdzie \"],[0,[6],1,\"connection-string\"],[0,[],0,\" to ciąg znakowy pozwalający łączyć się z bazą:\"]]],[10,52],[1,\"p\",[[0,[],0,\"W mongo charts możemy w chwilę wyklikać kilka wykresów, np wspomniany wcześniej rozkład statusu prawników\"]]],[10,53],[1,\"p\",[[0,[],0,\"Interaktywny wykres dostępny do zagnieżdżenia jako \"],[0,[6],1,\"iframe\"],[0,[],0,\" możemy zobaczyć poniżej.\"]]],[10,54],[1,\"p\",[[0,[],0,\"Kolejny wykres przedstawia roczną liczbę wpisów do rejestru. Można się było spodziewać, że w danych pobieranych z internetu są błędy. Tak było i tym razem. Musieliśmy wyrzucić wszystkie wpisy pozbawione dat, z datami \\\"0000-00-00\\\" i jeden z datą \\\"2019-00-01\\\". za pomocą filtru\"]]],[10,55],[1,\"p\",[[0,[],0,\"Po dodaniu wyliczanego pola z datą i rokiem:\"]]],[10,56],[1,\"p\",[[0,[],0,\"Możemy zdefiniować wykres\"]]],[10,57],[10,58],[1,\"p\",[[0,[],0,\"Podobnie przygotowujemy wykres ze średnią liczbą specjalizacji\"]]],[10,59],[1,\"p\",[[0,[],0,\"Za pomocą konfiguracji\"]]],[10,60],[1,\"p\",[[0,[],0,\"możemy pokazać częstotliwość wybieranych specjalizacji \"]]],[10,61],[1,\"p\",[[0,[],0,\"Na koniec załączam tabelę z danymi kontaktowymi. Nie zawiera ona wszystkich adwokatów, lecz jedynie tych mających poprawne numery telefonów, czyli spełniających warunek\"]]],[10,62],[10,63],[1,\"p\",[[0,[],0,\"Mam nadzieję, że lektura tego wpisu rozszerzyła Twój arsenał narzędzi do scrapingu i wizualizacji danych. Jeśli chcesz porozmawiać o projektach z tego zakresu, myślisz o zamówieniu scrapingu lub po prostu chcesz wymienić się doświadczeniem zapraszam do kontaktu.\"]]],[10,64],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "html": "<p>Strona internetowa \"Rejestr Adwokatów\" jest publicznym zbiorem danych. Zgodnie z obwiązującym prawem można gromadzić i przetwarzać publicznie dostępne dane osobowe z rejestrów.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://rejestradwokatow.pl/adwokat\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">:: KRAIA - adwokaci, prawnicy zagraniczni, aplikanci ::</div><div class=\"kg-bookmark-description\">Krajowy Rejestr Adwokatów i Aplikantów Adwokackich</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://rejestradwokatow.pl/favicon16x16.ico\"><span class=\"kg-bookmark-author\">adwokaci, prawnicy zagraniczni, aplikanci ::</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://rejestradwokatow.pl/templates/client_tpl/pl/_images/grafika/logo.png\"></div></a></figure><p>W tym artykule przygotujemy zestaw danych pozwalających na kontakt z prawnikami z tego rejestru. Jeśli po prostu szukasz prawnika, to możesz go tam znaleźć i nie potrzebujesz pobierać całej bazy.</p><p>Jeśli jednak prowadzisz działalność w której adwokaci stanowią Twoją grupę docelową, to dostrzeżesz korzyści z możliwości załadowania tych danych do swojego systemu CRM.</p><p>Ten artykuł pokazuje jak w napisać kod programu pobierającego te dane z publicznego rejestru. Jeśli interesują Cię same dane przejdź do końca artykułu.</p><p>Projekt podzielimy na etapy:</p><ol><li>Zbadanie strony z danymi i wyznaczenie strategii pobierania</li><li>Pobranie tabel z podstawowymi danymi</li><li>Przetworzenie tabel i wydobycie linków do podstron</li><li>Pobranie podstron z danymi kontaktowymi</li><li>Przetworzenie danych kontaktowych</li><li>Załadowanie danych do bazy i pokazanie wyników zapytań</li></ol><h2 id=\"badanie-strony-z-danymi-strategia-\">Badanie strony z danymi (strategia)</h2><p>Rejestr adwokatów dostępny pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://rejestradwokatow.pl/adwokat\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">:: KRAIA - adwokaci, prawnicy zagraniczni, aplikanci ::</div><div class=\"kg-bookmark-description\">Krajowy Rejestr Adwokatów i Aplikantów Adwokackich</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://rejestradwokatow.pl/favicon16x16.ico\"><span class=\"kg-bookmark-author\">adwokaci, prawnicy zagraniczni, aplikanci ::</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://rejestradwokatow.pl/templates/client_tpl/pl/_images/grafika/logo.png\"></div></a></figure><p>zawiera zielony przycisk wyszukaj. Po jego kliknięciu przechodzimy na stronę</p><blockquote><a href=\"https://rejestradwokatow.pl/adwokat/wyszukaj\">https://rejestradwokatow.pl/adwokat/wyszukaj</a></blockquote><p>zawierającą klasyczną tabelę</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-16-48-01.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1247\" height=\"849\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-16-48-01.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-16-48-01.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-16-48-01.png 1247w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Schodząc na sam dół i klikając \"ostatnia\"</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-16-49-24.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1251\" height=\"390\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-16-49-24.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-16-49-24.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-16-49-24.png 1251w\" sizes=\"(min-width: 720px) 720px\"></figure><p>zostaniemy przekierowani na stronę z klasyczną paginacją</p><blockquote><a href=\"https://rejestradwokatow.pl/adwokat/wyszukaj/strona/272\">https://rejestradwokatow.pl/adwokat/wyszukaj/strona/272</a></blockquote><p>Adwokatów na tel liście można podzielić na:</p><ul><li>wykonujących zawód</li><li>byłych adwokatów</li><li>nie wykonujących zawodu</li></ul><p>Każda z kategorii ma nieco inną stronę profilową:</p><blockquote><a href=\"https://rejestradwokatow.pl/adwokat/urek-macias-paulina-54635\">https://rejestradwokatow.pl/adwokat/urek-macias-paulina-54635</a></blockquote><p>Adwokat wykonujący zawód ma najpełniejszy profil</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-16-58.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1228\" height=\"1005\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-17-16-58.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-17-16-58.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-16-58.png 1228w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Niektórzy mają do tego telefon komórkowy</p><blockquote><a href=\"https://rejestradwokatow.pl/adwokat/urkowska-trzciska-justyna-48516\">https://rejestradwokatow.pl/adwokat/urkowska-trzciska-justyna-48516</a></blockquote><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-17-45.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1216\" height=\"402\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-17-17-45.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-17-17-45.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-17-45.png 1216w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Dane o byłych adwokatach są ograniczone</p><blockquote><a href=\"https://rejestradwokatow.pl/adwokat/urowski-jan-52462\">https://rejestradwokatow.pl/adwokat/urowski-jan-52462</a></blockquote><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-18-34.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1219\" height=\"333\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-17-18-34.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-17-18-34.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-18-34.png 1219w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Jeszcze bardziej o nie wykonujących zawodu</p><blockquote><a href=\"https://rejestradwokatow.pl/adwokat/urek-wanda-54247\">https://rejestradwokatow.pl/adwokat/urek-wanda-54247</a></blockquote><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-19-00.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1223\" height=\"250\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-17-19-00.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-17-19-00.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-19-00.png 1223w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Strategia pobrania tych danych jest prosta. Na początku przejdziemy tabelę budując bazową listę z podstawowymi danymi. Wśród nich znajdą się linki do profili. Pobierzemy je wszystkie i z nich uzyskamy rozszerzenie tej bazowej listy o najcenniejsze dane, na przykład kontaktowe.</p><h2 id=\"pobranie-tabel-z-bazowymi-danymi\">Pobranie tabel z bazowymi danymi</h2><p>Wszystkie podstrony pobieramy jedną komendą w bashu</p><pre><code class=\"language-bash\">mkdir -p raw &amp;&amp; for i in {1..272}; do wget \"https://rejestradwokatow.pl/adwokat/wyszukaj/strona/$i\" -O raw/$i.html; done</code></pre><p>Mogli byśmy to przyśpieszyć pobierając kilka stron jednocześnie, ale dla naszych celów taki jedno-liniowy kod jest znacznie lepszy, bo czas jego napisania jest bardzo krótki. Czas pobranie wszystkich stron zależy oczywiście od szybkości łącza internetowego, u mnie było to <code>0.54</code> pliku na sekundę czyli około <code>8.39</code> minuty.</p><h2 id=\"przetworzenie-tabel\">Przetworzenie tabel</h2><p>Na każdej podstronie mamy taką samą tabelę</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-17-29-47.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"450\" height=\"383\"></figure><p>Projekt inicjalizujemy komendą</p><pre><code>npm init -y &amp;&amp; tsc --init &amp;&amp; touch entry.ts</code></pre><p>Instalujemy <code>cheerio</code> oraz <code>axios</code> które będą nam potrzebne do przetwarzania plików <code>html</code> oraz wysyłania żądań <code>http</code>. Dodamy jeszcze <code>@types/node</code> które pozwalają nam importować na przykład <code>fs</code>.</p><pre><code>npm i cheerio axios @types/node</code></pre><p>Ponieważ projekt będzie zawierał kilka plików utworzymy też plik <code>helpers.ts</code>, w którym będziemy umieszczać współdzielony kod. Przede wszystkim interfejsy.</p><p>Pisanie kodu zaczniemy od zdefiniowania interfejsów danych wyjściowych z przetwarzania tabeli. Zamiast trzymania polskich nazw jak w nagłówku tabeli:</p><pre><code>NAZWISKO\nIMIĘ\nDRUGIE IMIĘ\nMIEJSCOWOŚĆ\nIZBA ADWOKACKA\nSTATUS\nSZCZEGÓŁY</code></pre><p>Zdecydujemy się na ich angielskie odpowiedniki</p><pre><code>export enum LawyerStatus {\n    active = \"Wykonujący zawód\",\n    former = \"Były adwokat\",\n    inavtive = \"Niewykonujący zawodu\",\n    undefined = \"\"\n}\n\nexport interface Output {\n    surname: string\n    name: string\n    second_name: string\n    city: string\n    office: string\n    status: LawyerStatus\n    link: string\n}</code></pre><p>i umieścimy je w pliku <code>helpers.ts</code></p><p>W <code>entry.ts</code> znajdzie się kod który na plikach wykona klasyczną procedurę mapowania i redukcji.</p><p>Plik zaczyna się od niezbędnych importów</p><pre><code class=\"language-ts\">import fs from 'fs';\nimport cheerio from 'cheerio';\n\nimport {LawyerStatus, Output} from './helpers'</code></pre><p>Następnie dodajemy funkcję odczytującą pliki i oddającą tablicę z ich zawartościami.</p><pre><code class=\"language-ts\">const getFiles = (): string[] =&gt; fs\n    .readdirSync(process.cwd() + `/raw`)\n    .filter((name) =&gt; /^\\d+\\.html/.test(name))\n    .map(name =&gt;\n        fs.readFileSync(process.cwd() + '/raw/' + name).toString()\n    );</code></pre><p>Kolejną funkcją, kluczową dla tego skryptu jest <code>processFile</code>, która za pomocą <code>cheerio</code> przetwarza ciągi znaków z <code>html</code> na tablice z danymi adwokatów, które zawarte są w tabeli.</p><pre><code class=\"language-ts\">const processFile = (content: string): Output[] =&gt; cheerio\n    .load(content)('.rejestr tbody tr')\n    .toArray()\n    .map(row =&gt; ({\n        surname: cheerio(row).find('td:nth-of-type(2)').text(),\n        name: cheerio(row).find('td:nth-of-type(3)').text().trim(),\n        second_name: cheerio(row).find('td:nth-of-type(4)').text(),\n        city: cheerio(row).find('td:nth-of-type(5)').text(),\n        office: cheerio(row).find('td:nth-of-type(6)').text(),\n        status: cheerio(row).find('td:nth-of-type(7)').text() as LawyerStatus,\n        link: cheerio(row).find('td:nth-of-type(8) a').attr('href') || '',\n    }))</code></pre><p>Ponieważ każda podstrona tabeli zwraca osobną tablicę, musimy połączyć je w jedną aby uniknąć problemów z nienaturalną dla naszych potrzeb paginacją. Pomoże nam w tym funkcja <code>reducer</code>.</p><pre><code class=\"language-ts\">const reducer = (a:Output[], b:Output[]):Output[] =&gt; [...a, ...b];</code></pre><p>Cały program to po prostu wykonanie kolejno tych funkcji, tak aby przekazywały sobie nawzajem wyniki jako argumenty.</p><pre><code class=\"language-ts\">const main = () =&gt; {\n    return getFiles().map(processFile).reduce(reducer);\n}\n</code></pre><p>Finalnie tworzymy katalog <code>out</code> i umieszczamy w nim plik <code>basic_data.json</code> z danymi odczytanymi z plików</p><pre><code>const out = main();\n\n!fs.existsSync(process.cwd() + '/out') &amp;&amp; fs.mkdirSync(process.cwd() + '/out', {recursive: true})\nfs.writeFileSync(process.cwd() + '/out/basic_data.json', JSON.stringify(out))\n\nconsole.dir(out)</code></pre><p>Wykonanie:</p><pre><code>ts-node entry.ts</code></pre><p>zajmuje pół minuty</p><pre><code>35.95s user 0.98s system 125% cpu 29.466 total</code></pre><p>i generuje plik o wadze <code>5.1M</code></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-18-08-48.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"614\" height=\"332\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-18-08-48.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-18-08-48.png 614w\"></figure><p>Repozytorium z kodem można znaleźć tutaj:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/lawyers-scraper/-/commit/1b87854fd741d6bfc10f8c36c21b7390a3095260\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Processing tables with lawyers data (1b87854f) · Commits · gustawdaniel / lawyers-scraper</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><h2 id=\"pobranie-podstron\">Pobranie podstron</h2><p>Pobranie podstron zrealizujemy już nie przez <code>wget</code> lecz w <code>node</code>. W pliku <code>helpers.ts</code> umieścimy pomocniczy kod do odczytu wytworzonego właśnie zbioru danych bazowych.</p><pre><code>import {readFileSync} from \"fs\";\n\nexport const getConfig = () =&gt; JSON.parse(readFileSync(process.cwd() + '/out/basic_data.json').toString());</code></pre><p>Bardzo pomocne przy scrapingu jest kolorowanie na zielono poprawnie wykonanych requestów oraz na czerwono tych zakończonych błędem.</p><p>Mimo, że istnieją gotowe biblioteki do kolorowania, w tak prostym przypadku wygodniej jest zapisać kolory w stałych.</p><p>Nowy plik <code>scraper.ts</code> zaczniemy właśnie od importów i definiowania kolorów.</p><pre><code class=\"language-ts\">import fs from \"fs\";\nimport axios from 'axios';\nimport {getConfig} from \"./helpers\";\n\nconst Reset = \"\\x1b[0m\"\nconst FgRed = \"\\x1b[31m\"\nconst FgGreen = \"\\x1b[32m\"</code></pre><p>Kolejną obok graficznego oznaczania sukcesu i porażki cenną informacją jest czas. Dlatego w kolejnych liniach zdefiniujemy sobie zmienne pozwalające przechowywać punkty czasowe rozpoczęcia programu oraz zakończenia poprzedniej pętli.</p><pre><code class=\"language-ts\">const init = new Date().getTime();\nlet last = new Date().getTime();</code></pre><p>W funkcji <code>main</code> umieścimy kod pobierający zbiór danych bazowych i iterujący po nim w celu pobrania wszystkich linków i zapisania stron w plikach.</p><pre><code class=\"language-ts\">const main = async () =&gt; {\n    const links = getConfig().map((a:{link:string}):string =&gt; a.link);\n\n    while (links.length) {\n        const link = links.pop();\n        const name = link.split('/').reverse()[0];\n        const {data, status} = await axios.get(link);\n        fs.writeFileSync(process.cwd() + `/raw/${name}.html`, data);\n        const now = new Date().getTime();\n        console.log(status === 200 ? `${FgGreen}%s\\t%s\\t%s\\t%s\\t%s${Reset}` : `${FgRed}%s\\t%s\\t%s\\t%s\\t%s${Reset}`, status, links.length, now - last, now - init, name);\n        last = new Date().getTime();\n    }\n}</code></pre><p>Najmniej oczywiste jest tu wyświetlanie, ale napiszę tylko, że dzięki znacznikom z kolorami mamy tu zielone lub czerwone linie. Prezentują one kolejno.</p><ul><li>kod odpowiedzi (spodziewany to 200)</li><li>ilość pozostałych do końca rekordów</li><li>czas od ostatniego wykonania pętli w ms</li><li>czas od początku działania programu w ms</li><li>nazwę tworzonego pliku</li></ul><p>Wykonanie to linia:</p><pre><code class=\"language-ts\">main().then(() =&gt; console.log(\"ok\")).catch(console.error);</code></pre><p>Tak wyglądają przykładowe wywołania, jedno z, a drugie bez zapisu plików.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-18-30-20.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"502\" height=\"487\"></figure><p>Widać, że nie różnią się od siebie w zauważalny sposób i średni czas na zapis jednego adwokata to koło 150 ms. Daje to łącznie <code>27190*0.15</code> = <code>4078</code> sekund. Jednak to więcej niż <code>3600</code>. Ponad godzina!</p><p>Nie możemy sobie na to pozwolić, ponieważ w tytule artykułu obiecuję, że pobierzemy te dane w czasie krótszym niż godzinę, a ponad 8 minut zużyto już na pobranie bazowych danych.</p><h2 id=\"jednoczesne-dania\">Jednoczesne żądania</h2><p>Na szczęście dzięki możliwości wysyłania kolejnych żądań zanim spłyną wyniki z poprzednich jesteśmy w stanie podnieść szybkość pobierania z około <code>6.6</code> plików na sekundę (1 plik co 150 ms) do około <code>40</code> plików na sekundę (średnio 1 plik co 25 ms).</p><p>Finalnie wynik pobierania to  <code>27191/(11*60+24.20)</code> = <code>39.74</code> plików / sekundę. Czyli łączny czas wyniósł 11 minut 24 sekundy zamiast szacowanej w poprzednim akapicie 1 godziny i 8 minut.</p><p>Jak udało się tak bardzo podnieść czas pobierania danych? Spójrzmy na kod. Przede wszystkim zacząłem od dołączenia dwóch kolejnych zmiennych:</p><pre><code class=\"language-ts\">let queueLength = 0;\nconst MAX_QUEUE_LENGTH = 500;</code></pre><p>Stała oznacza liczbę plików które mogą być jednocześnie przetwarzane. To znaczy, że jeśli czekamy na 500 plików jednocześnie, to skrypt nie będzie wysyłał kolejnych żądań. Nie ma to sensu, bo nie chcemy przecież niepotrzebnie obciążyć zbyt dużej ilości RAM ani zostać odcięci przez serwer z powodu przekroczenia liczby żądań, które ten może zakolejkować. </p><p>Stała <code>queueLength</code> jest naszą aktualną liczbą żądań, które wysłaliśmy i na których odpowiedzi jeszcze czekamy.</p><p>Całą logikę, która wcześniej znalazła się w <code>main</code> przenosimy do funkcji <code>append</code>. Jej zadaniem jest załączenie żądania do kolejki.</p><pre><code class=\"language-ts\">const append = async (links: string[]) =&gt; {\n    queueLength++;\n    const link: string = links.pop() || '';\n    const name = link.split('/').reverse()[0];\n    const {data, status} = await axios.get(link);\n    fs.writeFileSync(process.cwd() + `/raw/${name}.html`, data);\n    const now = new Date().getTime();\n    console.log(status === 200 ? `${FgGreen}%s\\t%s\\t%s\\t%s\\t%s\\t%s${Reset}` : `${FgRed}%s\\t%s\\t%s\\t%s\\t%s\\t%s${Reset}`,\n        status, links.length, queueLength, now - last, now - init, name\n    );\n    last = new Date().getTime();\n}</code></pre><p>Od poprzedniego kodu różni się tym, że podnosi <code>queueLength</code> oraz wyświetla jej aktualną wartość.</p><p>Do tego dołączamy funkcję <code>sleep</code>, która pozwoli nam na odczekiwania między kolejnymi żądaniami. </p><pre><code class=\"language-ts\">const sleep = (time: number) =&gt; new Promise((resolve) =&gt; setTimeout(resolve, time))</code></pre><p>Jak widać przy wysyłaniu wielu żądań jednocześnie ważne są mechanizmy zabezpieczające nas przed ryzykiem, że przygnieciemy serwer nadmierną ilością ruchu sieciowego i doprowadzimy do gubienia się pakietów.</p><p>Sama funkcja <code>main</code> przyjmuje teraz rolę tę samą co ostatnia, le nie czeka na wypełnianie <code>promises</code> z funkcji <code>append</code>. Zamiast tego limituje jej wywołania na podstawie oczekiwania na <code>sleep</code> i warunku nie przekroczenia <code>MAX_QUEUE_LENGTH</code>.</p><pre><code class=\"language-ts\">const main = async () =&gt; {\n    const links = getConfig().map((a: { link: string }): string =&gt; a.link);\n\n    while (links.length) {\n        await sleep(9);\n        if (queueLength &lt; MAX_QUEUE_LENGTH)\n            append(links).finally(() =&gt; queueLength--)\n    }\n}</code></pre><p>Poniżej widzimy fragment z wywołania tak przepisanego programu:</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"150\" src=\"https://www.youtube.com/embed/5S2Mszhjbuw?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p>Kod można sprawdzić w commicie:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gitlab.com/gustawdaniel/lawyers-scraper/-/commit/ca8895f1d3474881269fbf3ef088a7ff03f9010f\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Parallel scraping of profile pages (ca8895f1) · Commits · gustawdaniel / lawyers-scraper</div><div class=\"kg-bookmark-description\">GitLab.com</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.gitlab-static.net/assets/touch-icon-ipad-retina-8ebe416f5313483d9c1bc772b5bbe03ecad52a54eba443e5215a22caed2a16a2.png\"><span class=\"kg-bookmark-author\">GitLab</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.gitlab-static.net/assets/gitlab_logo-7ae504fe4f68fdebb3c2034e36621930cd36ea87924c11ff65dbcb8ed50dca58.png\"></div></a></figure><h2 id=\"przetworzenie-stron-profilowych\">Przetworzenie stron profilowych</h2><p>Kiedy mamy już podstrony z profilami adwokatów, możemy utworzyć ostatni już plik <code>parser.ts</code> i za jego pomocą wzbogacić bazowy zbiór danych o informacje widoczne na stronach profilowych. Zanim jednak przejdziemy do kodu skupimy się na danych, jakie chcemy zebrać o prawnikach o różnych statusach:</p><pre><code>export interface ActiveOutput {\n    id: string\n    date: string\n    address: string\n    phone: string\n    email: string\n    workplace: string\n    speciality: string[]\n}\n\nexport interface FormerOutput {\n    id: string\n    date: string\n    date_end: string\n    last_place: string\n    replaced_by: string\n}\n\nexport interface UndefinedOutput {\n    id: string\n}\n\nexport interface InactiveOutput {\n    id: string\n    date: string\n}\n\nexport type ExtraOutput = ActiveOutput | FormerOutput | UndefinedOutput | InactiveOutput</code></pre><p>Status \"Undefined\" oznacza prawnika, który nie ma statusu. Jest w tej bazie kilku takich prawników, często jest to związane ze znalezieniem duplikatu konta. Nie będziemy w to wnikać, bo to margines tej bazy.</p><p>W pliku <code>parser.ts</code> dołączamy importy</p><pre><code class=\"language-ts\">import {FormerOutput, getConfig} from \"./helpers\";\nimport {Output, ExtraOutput, LawyerStatus} from './helpers'\nimport {readFileSync, writeFileSync} from \"fs\";\nimport cheerio from 'cheerio';\n</code></pre><p>Ponieważ teksty są często wypełnione znakami nowej linii i pustymi znakami między nimi zwykły <code>trim</code> nie wystarczy. Dlatego napisaliśmy funkcję do czyszczenia tekstów wieloliniowych</p><pre><code class=\"language-ts\">const cleanText = (text: string): string =&gt; text.split(/[\\n|\\t]/).map((t: string): string =&gt; t.trim()).filter(t =&gt; t).join('\\n');</code></pre><p>Samo przetwarzanie plików wygląda tak samo jak zawsze, z tym, że zależy ono od statusu prawnika</p><pre><code class=\"language-ts\">const processFile = (content: string, status: LawyerStatus): ExtraOutput =&gt; {\n    const $ = cheerio.load(content);\n\n    const section = (n: number): string =&gt; `section .line_list_K div:nth-of-type(${n}) div:nth-of-type(1)`\n\n    const id = $('main section h3').text();\n\n    switch (status) {\n        case LawyerStatus.active:\n            return {\n                id,\n                date: $(section(2)).text(),\n                address: cleanText($('.line_list_K div:nth-of-type(3) div:nth-of-type(1)').text()),\n                phone: $('.line_list_K div:nth-of-type(4) div:nth-of-type(1)').text(),\n                email: (el =&gt; el.attr('data-ea') + `@` + el.attr('data-eb'))($('.line_list_K div:last-of-type div:nth-of-type(1)')),\n                speciality: $('.line_list_A &gt; div').toArray().map((el): string =&gt; cheerio(el).text().trim()),\n                workplace: cleanText($('.mb_tab_content.special_one .line_list_K').text())\n            };\n        case LawyerStatus.former:\n            return {\n                id,\n                date: $(section(2)).text(),\n                date_end: $(section(3)).text().trim(),\n                last_place: $(section(4)).text().trim(),\n                replaced_by: $(section(5)).text().trim()\n            }\n        case LawyerStatus.inavtive:\n            return {\n                id,\n                date: $(section(2)).text(),\n            }\n        case LawyerStatus.undefined:\n            return {\n                id\n            }\n    }\n}</code></pre><p>Kolejny dość przewidywalny fragment kodu to funkcja <code>main</code>. </p><pre><code class=\"language-ts\">let initDate = new Date().getTime();\nlet lastDate = new Date().getTime();\n\nconst main = () =&gt; {\n    const lawyers = getConfig().reverse().filter((e: Output, i: number) =&gt; i &lt; Infinity);\n    const res: (Output &amp; ExtraOutput)[] = [];\n\n    while (lawyers.length) {\n        const lawyer = lawyers.shift();\n        const name = lawyer.link.split('/').reverse()[0];\n        const extraLawyerInfo = processFile(readFileSync(process.cwd() + `/raw/${name}.html`).toString(), lawyer.status)\n\n        res.push({...lawyer, ...extraLawyerInfo});\n\n        if (lawyers.length % 100 === 0) {\n            const now = new Date().getTime();\n            console.log(res.length, lawyers.length, now - lastDate, now - initDate);\n            lastDate = new Date().getTime();\n        }\n    }\n\n    return res;\n}</code></pre><p>Na końcu zapis pliku </p><pre><code class=\"language-ts\">const out = main();\nwriteFileSync(process.cwd() + '/out/extended_data.json', JSON.stringify(out))</code></pre><p>Wykonanie tego pliku pokazuje kolumny z</p><ul><li>ilością przetworzonych plików</li><li>ilością pozostałych plików</li><li>czasem miedzy kolejnymi setkami</li><li>łącznym czasem od włączenia aplikacji</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-20-17-27.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"158\" height=\"111\"></figure><p>Przetworzenie każdej setki plików zajmuje około 340 ms. Co oznacza mniej więcej 300 na sekundę, czyli całość powinna zająć około półtorej minuty. Faktycznie:</p><pre><code>ts-node parser.ts  124.32s user 1.81s system 131% cpu 1:35.98 total</code></pre><p>Wygenerowany plik z danymi dotyczącymi prawników warzy <code>13MB</code></p><pre><code>du -h out/extended_data.json \n13M\tout/extended_data.json</code></pre><p>Jeśli chcesz pobrać ten plik, znajduje się on pod linkiem:</p><blockquote><a href=\"https://gitlab.com/gustawdaniel/lawyers-scraper/-/raw/8259451e89ef695a89576a8229c440301c53009e/out/extended_data.json\">https://gitlab.com/gustawdaniel/lawyers-scraper/-/raw/8259451e89ef695a89576a8229c440301c53009e/out/extended_data.json</a></blockquote><h2 id=\"za-adowanie-danych-do-bazy\">Załadowanie danych do bazy</h2><p>Plik <code>json</code> jest bardzo wygodny jako nośnik wymiany danych. Nie nadaje się niestety do tego, żeby bezpośrednio wygodnie go przetwarzać i budować na nim zapytania. Na szczęście od załadowania tego pliku do bazy <code>mongo</code> dzieli nas tylko jedna komenda. Jest to:</p><pre><code class=\"language-bash\">mongoimport --db test --collection lawyer --jsonArray --drop --file ./out/extended_data.json</code></pre><p>Pokaże ona </p><pre><code class=\"language-bash\">2021-02-17T20:26:58.455+0100\tconnected to: mongodb://localhost/\n2021-02-17T20:26:58.455+0100\tdropping: test.lawyer\n2021-02-17T20:27:00.013+0100\t27191 document(s) imported successfully. 0 document(s) failed to import.\n</code></pre><p>Włączając bazę poleceniem</p><pre><code>mongo test</code></pre><p>dostaniemy się do konsoli z której możemy wykonywać zapytania:</p><pre><code>db.lawyer.aggregate([{$group:{_id: \"$status\", sum:{$sum: 1}, link:{$first: \"$link\"}}}])</code></pre><p>Zwróci rozkład względem wykonywanych zawodów i przykładowe linki:</p><pre><code>{ \"_id\" : \"\", \"sum\" : 7, \"link\" : \"https://rejestradwokatow.pl/adwokat/jawor-marcin-51297\" }\n{ \"_id\" : \"Niewykonujący zawodu\", \"sum\" : 4410, \"link\" : \"https://rejestradwokatow.pl/adwokat/konopacka-izabela-83958\" }\n{ \"_id\" : \"Wykonujący zawód\", \"sum\" : 19930, \"link\" : \"https://rejestradwokatow.pl/adwokat/konrad-adam-33796\" }\n{ \"_id\" : \"Były adwokat\", \"sum\" : 2844, \"link\" : \"https://rejestradwokatow.pl/adwokat/konopiski-sawomir-48480\" }</code></pre><p>Dzięki interfejsowi Compass możemy przeglądać znacznie więcej takich grupowań w trybie graficznym</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-20-33-57.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1564\" height=\"812\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-20-33-57.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-20-33-57.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-20-33-57.png 1564w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Jeśli chcemy wrzucić te dane do mongo atlas możemy użyć komendy</p><pre><code>mongoimport --collection lawyer &lt;connection-string&gt;  --jsonArray --drop --file ./out/extended_data.json</code></pre><p>gdzie <code>connection-string</code> to ciąg znakowy pozwalający łączyć się z bazą:</p><pre><code>mongodb+srv://user:pass@cluseter_number.mongodb.net/db_name</code></pre><p>W mongo charts możemy w chwilę wyklikać kilka wykresów, np wspomniany wcześniej rozkład statusu prawników</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-21-01-11.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1857\" height=\"798\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-21-01-11.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-21-01-11.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-17-21-01-11.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-21-01-11.png 1857w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Interaktywny wykres dostępny do zagnieżdżenia jako <code>iframe</code> możemy zobaczyć poniżej.</p><!--kg-card-begin: html--><iframe style=\"background: #FFFFFF;border: none;border-radius: 2px;box-shadow: 0 2px 10px 0 rgba(70, 76, 79, .2);\" width=\"640\" height=\"480\" src=\"https://charts.mongodb.com/charts-project-0-oreyr/embed/charts?id=b1bd9eb7-ff8c-4cdd-8999-fb66d8c252e3&theme=light\"></iframe><!--kg-card-end: html--><p>Kolejny wykres przedstawia roczną liczbę wpisów do rejestru. Można się było spodziewać, że w danych pobieranych z internetu są błędy. Tak było i tym razem. Musieliśmy wyrzucić wszystkie wpisy pozbawione dat, z datami \"0000-00-00\" i jeden z datą \"2019-00-01\". za pomocą filtru</p><pre><code class=\"language-json\">{status: {$ne: \"\"}, date:{$nin: [\"\",\"0000-00-00\",\"2019-00-01\"]}}</code></pre><p>Po dodaniu wyliczanego pola z datą i rokiem:</p><pre><code class=\"language-json\">{computed_date: {\n  $dateFromString: {\n    dateString: \"$date\"\n  }\n},\n  year:  {$year:{\n  $dateFromString: {\n    dateString: \"$date\"\n  }\n}}\n}</code></pre><p>Możemy zdefiniować wykres</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-21-34-30.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1840\" height=\"980\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-21-34-30.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-21-34-30.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-17-21-34-30.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-21-34-30.png 1840w\" sizes=\"(min-width: 720px) 720px\"></figure><!--kg-card-begin: html--><iframe style=\"background: #FFFFFF;border: none;border-radius: 2px;box-shadow: 0 2px 10px 0 rgba(70, 76, 79, .2);\" width=\"640\" height=\"480\" src=\"https://charts.mongodb.com/charts-project-0-oreyr/embed/charts?id=696d81ab-c2e7-4ae9-9011-38048cb2595f&theme=light\"></iframe><!--kg-card-end: html--><p>Podobnie przygotowujemy wykres ze średnią liczbą specjalizacji</p><!--kg-card-begin: html--><iframe style=\"background: #FFFFFF;border: none;border-radius: 2px;box-shadow: 0 2px 10px 0 rgba(70, 76, 79, .2);\" width=\"640\" height=\"480\" src=\"https://charts.mongodb.com/charts-project-0-oreyr/embed/charts?id=4b75fd41-8d05-422c-bae0-b642342842b4&theme=light\"></iframe><!--kg-card-end: html--><p>Za pomocą konfiguracji</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-21-46-31.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"255\" height=\"415\"></figure><p>możemy pokazać częstotliwość wybieranych specjalizacji </p><!--kg-card-begin: html--><iframe style=\"background: #FFFFFF;border: none;border-radius: 2px;box-shadow: 0 2px 10px 0 rgba(70, 76, 79, .2);\" width=\"640\" height=\"480\" src=\"https://charts.mongodb.com/charts-project-0-oreyr/embed/charts?id=9fe8232b-7a1d-444b-9ccb-05dd85743fae&theme=light\"></iframe><!--kg-card-end: html--><p>Na koniec załączam tabelę z danymi kontaktowymi. Nie zawiera ona wszystkich adwokatów, lecz jedynie tych mających poprawne numery telefonów, czyli spełniających warunek</p><pre><code class=\"language-json\">{phone: /^(\\d|-)+$/}</code></pre><!--kg-card-begin: html--><iframe style=\"background: #FFFFFF;border: none;border-radius: 2px;box-shadow: 0 2px 10px 0 rgba(70, 76, 79, .2);\" width=\"640\" height=\"480\" src=\"https://charts.mongodb.com/charts-project-0-oreyr/embed/charts?id=69075db2-104d-45c4-ae3f-98ff90f5f9f0&theme=light\"></iframe><!--kg-card-end: html--><p>Mam nadzieję, że lektura tego wpisu rozszerzyła Twój arsenał narzędzi do scrapingu i wizualizacji danych. Jeśli chcesz porozmawiać o projektach z tego zakresu, myślisz o zamówieniu scrapingu lub po prostu chcesz wymienić się doświadczeniem zapraszam do kontaktu.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://calendly.com/gustaw-daniel\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Daniel Gustaw</div><div class=\"kg-bookmark-description\">Welcome to my scheduling page. Please follow the instructions to add an event to my calendar.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.calendly.com/assets/touch-icon-ipad-retina-7a95e0c775301f4c0a22002bdf0a95d3c2b9cbe95af29c64f9c9573bac1f01e4.png\"><span class=\"kg-bookmark-author\">Calendly</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.calendly.com/assets/ogimage-a63bb2f442cd9e6345a5e4d7fe75393c6cfcc1ff29e48e858742d43573a8b02c.png?source&#x3D;opengraph\"></div></a></figure>",
            "comment_id": "602d352c1446cd10bd8da869",
            "plaintext": "Strona internetowa \"Rejestr Adwokatów\" jest publicznym zbiorem danych. Zgodnie z\nobwiązującym prawem można gromadzić i przetwarzać publicznie dostępne dane\nosobowe z rejestrów.\n\n:: KRAIA - adwokaci, prawnicy zagraniczni, aplikanci ::Krajowy Rejestr\nAdwokatów\ni Aplikantów Adwokackichadwokaci, prawnicy zagraniczni, aplikanci ::\n[https://rejestradwokatow.pl/adwokat]W tym artykule przygotujemy zestaw danych\npozwalających na kontakt z prawnikami z tego rejestru. Jeśli po prostu szukasz\nprawnika, to możesz go tam znaleźć i nie potrzebujesz pobierać całej bazy.\n\nJeśli jednak prowadzisz działalność w której adwokaci stanowią Twoją grupę\ndocelową, to dostrzeżesz korzyści z możliwości załadowania tych danych do\nswojego systemu CRM.\n\nTen artykuł pokazuje jak w napisać kod programu pobierającego te dane z\npublicznego rejestru. Jeśli interesują Cię same dane przejdź do końca artykułu.\n\nProjekt podzielimy na etapy:\n\n 1. Zbadanie strony z danymi i wyznaczenie strategii pobierania\n 2. Pobranie tabel z podstawowymi danymi\n 3. Przetworzenie tabel i wydobycie linków do podstron\n 4. Pobranie podstron z danymi kontaktowymi\n 5. Przetworzenie danych kontaktowych\n 6. Załadowanie danych do bazy i pokazanie wyników zapytań\n\nBadanie strony z danymi (strategia)\nRejestr adwokatów dostępny pod linkiem:\n\n:: KRAIA - adwokaci, prawnicy zagraniczni, aplikanci ::Krajowy Rejestr\nAdwokatów\ni Aplikantów Adwokackichadwokaci, prawnicy zagraniczni, aplikanci ::\n[https://rejestradwokatow.pl/adwokat]zawiera zielony przycisk wyszukaj. Po jego\nkliknięciu przechodzimy na stronę\n\n> https://rejestradwokatow.pl/adwokat/wyszukaj\nzawierającą klasyczną tabelę\n\nSchodząc na sam dół i klikając \"ostatnia\"\n\nzostaniemy przekierowani na stronę z klasyczną paginacją\n\n> https://rejestradwokatow.pl/adwokat/wyszukaj/strona/272\nAdwokatów na tel liście można podzielić na:\n\n * wykonujących zawód\n * byłych adwokatów\n * nie wykonujących zawodu\n\nKażda z kategorii ma nieco inną stronę profilową:\n\n> https://rejestradwokatow.pl/adwokat/urek-macias-paulina-54635\nAdwokat wykonujący zawód ma najpełniejszy profil\n\nNiektórzy mają do tego telefon komórkowy\n\n> https://rejestradwokatow.pl/adwokat/urkowska-trzciska-justyna-48516\nDane o byłych adwokatach są ograniczone\n\n> https://rejestradwokatow.pl/adwokat/urowski-jan-52462\nJeszcze bardziej o nie wykonujących zawodu\n\n> https://rejestradwokatow.pl/adwokat/urek-wanda-54247\nStrategia pobrania tych danych jest prosta. Na początku przejdziemy tabelę\nbudując bazową listę z podstawowymi danymi. Wśród nich znajdą się linki do\nprofili. Pobierzemy je wszystkie i z nich uzyskamy rozszerzenie tej bazowej\nlisty o najcenniejsze dane, na przykład kontaktowe.\n\nPobranie tabel z bazowymi danymi\nWszystkie podstrony pobieramy jedną komendą w bashu\n\nmkdir -p raw && for i in {1..272}; do wget \"https://rejestradwokatow.pl/adwokat/wyszukaj/strona/$i\" -O raw/$i.html; done\n\nMogli byśmy to przyśpieszyć pobierając kilka stron jednocześnie, ale dla naszych\ncelów taki jedno-liniowy kod jest znacznie lepszy, bo czas jego napisania jest\nbardzo krótki. Czas pobranie wszystkich stron zależy oczywiście od szybkości\nłącza internetowego, u mnie było to 0.54 pliku na sekundę czyli około 8.39 \nminuty.\n\nPrzetworzenie tabel\nNa każdej podstronie mamy taką samą tabelę\n\nProjekt inicjalizujemy komendą\n\nnpm init -y && tsc --init && touch entry.ts\n\nInstalujemy cheerio oraz axios które będą nam potrzebne do przetwarzania plików \nhtml oraz wysyłania żądań http. Dodamy jeszcze @types/node które pozwalają nam\nimportować na przykład fs.\n\nnpm i cheerio axios @types/node\n\nPonieważ projekt będzie zawierał kilka plików utworzymy też plik helpers.ts, w\nktórym będziemy umieszczać współdzielony kod. Przede wszystkim interfejsy.\n\nPisanie kodu zaczniemy od zdefiniowania interfejsów danych wyjściowych z\nprzetwarzania tabeli. Zamiast trzymania polskich nazw jak w nagłówku tabeli:\n\nNAZWISKO\nIMIĘ\nDRUGIE IMIĘ\nMIEJSCOWOŚĆ\nIZBA ADWOKACKA\nSTATUS\nSZCZEGÓŁY\n\nZdecydujemy się na ich angielskie odpowiedniki\n\nexport enum LawyerStatus {\n    active = \"Wykonujący zawód\",\n    former = \"Były adwokat\",\n    inavtive = \"Niewykonujący zawodu\",\n    undefined = \"\"\n}\n\nexport interface Output {\n    surname: string\n    name: string\n    second_name: string\n    city: string\n    office: string\n    status: LawyerStatus\n    link: string\n}\n\ni umieścimy je w pliku helpers.ts\n\nW entry.ts znajdzie się kod który na plikach wykona klasyczną procedurę\nmapowania i redukcji.\n\nPlik zaczyna się od niezbędnych importów\n\nimport fs from 'fs';\nimport cheerio from 'cheerio';\n\nimport {LawyerStatus, Output} from './helpers'\n\nNastępnie dodajemy funkcję odczytującą pliki i oddającą tablicę z ich\nzawartościami.\n\nconst getFiles = (): string[] => fs\n    .readdirSync(process.cwd() + `/raw`)\n    .filter((name) => /^\\d+\\.html/.test(name))\n    .map(name =>\n        fs.readFileSync(process.cwd() + '/raw/' + name).toString()\n    );\n\nKolejną funkcją, kluczową dla tego skryptu jest processFile, która za pomocą \ncheerio przetwarza ciągi znaków z html na tablice z danymi adwokatów, które\nzawarte są w tabeli.\n\nconst processFile = (content: string): Output[] => cheerio\n    .load(content)('.rejestr tbody tr')\n    .toArray()\n    .map(row => ({\n        surname: cheerio(row).find('td:nth-of-type(2)').text(),\n        name: cheerio(row).find('td:nth-of-type(3)').text().trim(),\n        second_name: cheerio(row).find('td:nth-of-type(4)').text(),\n        city: cheerio(row).find('td:nth-of-type(5)').text(),\n        office: cheerio(row).find('td:nth-of-type(6)').text(),\n        status: cheerio(row).find('td:nth-of-type(7)').text() as LawyerStatus,\n        link: cheerio(row).find('td:nth-of-type(8) a').attr('href') || '',\n    }))\n\nPonieważ każda podstrona tabeli zwraca osobną tablicę, musimy połączyć je w\njedną aby uniknąć problemów z nienaturalną dla naszych potrzeb paginacją. Pomoże\nnam w tym funkcja reducer.\n\nconst reducer = (a:Output[], b:Output[]):Output[] => [...a, ...b];\n\nCały program to po prostu wykonanie kolejno tych funkcji, tak aby przekazywały\nsobie nawzajem wyniki jako argumenty.\n\nconst main = () => {\n    return getFiles().map(processFile).reduce(reducer);\n}\n\n\nFinalnie tworzymy katalog out i umieszczamy w nim plik basic_data.json z danymi\nodczytanymi z plików\n\nconst out = main();\n\n!fs.existsSync(process.cwd() + '/out') && fs.mkdirSync(process.cwd() + '/out', {recursive: true})\nfs.writeFileSync(process.cwd() + '/out/basic_data.json', JSON.stringify(out))\n\nconsole.dir(out)\n\nWykonanie:\n\nts-node entry.ts\n\nzajmuje pół minuty\n\n35.95s user 0.98s system 125% cpu 29.466 total\n\ni generuje plik o wadze 5.1M\n\nRepozytorium z kodem można znaleźć tutaj:\n\nProcessing tables with lawyers data (1b87854f) · Commits · gustawdaniel /\nlawyers-scraperGitLab.comGitLab\n[https://gitlab.com/gustawdaniel/lawyers-scraper/-/commit/1b87854fd741d6bfc10f8c36c21b7390a3095260]\nPobranie podstron\nPobranie podstron zrealizujemy już nie przez wget lecz w node. W pliku \nhelpers.ts umieścimy pomocniczy kod do odczytu wytworzonego właśnie zbioru\ndanych bazowych.\n\nimport {readFileSync} from \"fs\";\n\nexport const getConfig = () => JSON.parse(readFileSync(process.cwd() + '/out/basic_data.json').toString());\n\nBardzo pomocne przy scrapingu jest kolorowanie na zielono poprawnie wykonanych\nrequestów oraz na czerwono tych zakończonych błędem.\n\nMimo, że istnieją gotowe biblioteki do kolorowania, w tak prostym przypadku\nwygodniej jest zapisać kolory w stałych.\n\nNowy plik scraper.ts zaczniemy właśnie od importów i definiowania kolorów.\n\nimport fs from \"fs\";\nimport axios from 'axios';\nimport {getConfig} from \"./helpers\";\n\nconst Reset = \"\\x1b[0m\"\nconst FgRed = \"\\x1b[31m\"\nconst FgGreen = \"\\x1b[32m\"\n\nKolejną obok graficznego oznaczania sukcesu i porażki cenną informacją jest\nczas. Dlatego w kolejnych liniach zdefiniujemy sobie zmienne pozwalające\nprzechowywać punkty czasowe rozpoczęcia programu oraz zakończenia poprzedniej\npętli.\n\nconst init = new Date().getTime();\nlet last = new Date().getTime();\n\nW funkcji main umieścimy kod pobierający zbiór danych bazowych i iterujący po\nnim w celu pobrania wszystkich linków i zapisania stron w plikach.\n\nconst main = async () => {\n    const links = getConfig().map((a:{link:string}):string => a.link);\n\n    while (links.length) {\n        const link = links.pop();\n        const name = link.split('/').reverse()[0];\n        const {data, status} = await axios.get(link);\n        fs.writeFileSync(process.cwd() + `/raw/${name}.html`, data);\n        const now = new Date().getTime();\n        console.log(status === 200 ? `${FgGreen}%s\\t%s\\t%s\\t%s\\t%s${Reset}` : `${FgRed}%s\\t%s\\t%s\\t%s\\t%s${Reset}`, status, links.length, now - last, now - init, name);\n        last = new Date().getTime();\n    }\n}\n\nNajmniej oczywiste jest tu wyświetlanie, ale napiszę tylko, że dzięki znacznikom\nz kolorami mamy tu zielone lub czerwone linie. Prezentują one kolejno.\n\n * kod odpowiedzi (spodziewany to 200)\n * ilość pozostałych do końca rekordów\n * czas od ostatniego wykonania pętli w ms\n * czas od początku działania programu w ms\n * nazwę tworzonego pliku\n\nWykonanie to linia:\n\nmain().then(() => console.log(\"ok\")).catch(console.error);\n\nTak wyglądają przykładowe wywołania, jedno z, a drugie bez zapisu plików.\n\nWidać, że nie różnią się od siebie w zauważalny sposób i średni czas na zapis\njednego adwokata to koło 150 ms. Daje to łącznie 27190*0.15 = 4078 sekund.\nJednak to więcej niż 3600. Ponad godzina!\n\nNie możemy sobie na to pozwolić, ponieważ w tytule artykułu obiecuję, że\npobierzemy te dane w czasie krótszym niż godzinę, a ponad 8 minut zużyto już na\npobranie bazowych danych.\n\nJednoczesne żądania\nNa szczęście dzięki możliwości wysyłania kolejnych żądań zanim spłyną wyniki z\npoprzednich jesteśmy w stanie podnieść szybkość pobierania z około 6.6 plików na\nsekundę (1 plik co 150 ms) do około 40 plików na sekundę (średnio 1 plik co 25\nms).\n\nFinalnie wynik pobierania to27191/(11*60+24.20) = 39.74 plików / sekundę. Czyli\nłączny czas wyniósł 11 minut 24 sekundy zamiast szacowanej w poprzednim akapicie\n1 godziny i 8 minut.\n\nJak udało się tak bardzo podnieść czas pobierania danych? Spójrzmy na kod.\nPrzede wszystkim zacząłem od dołączenia dwóch kolejnych zmiennych:\n\nlet queueLength = 0;\nconst MAX_QUEUE_LENGTH = 500;\n\nStała oznacza liczbę plików które mogą być jednocześnie przetwarzane. To znaczy,\nże jeśli czekamy na 500 plików jednocześnie, to skrypt nie będzie wysyłał\nkolejnych żądań. Nie ma to sensu, bo nie chcemy przecież niepotrzebnie obciążyć\nzbyt dużej ilości RAM ani zostać odcięci przez serwer z powodu przekroczenia\nliczby żądań, które ten może zakolejkować. \n\nStała queueLength jest naszą aktualną liczbą żądań, które wysłaliśmy i na\nktórych odpowiedzi jeszcze czekamy.\n\nCałą logikę, która wcześniej znalazła się w main przenosimy do funkcji append.\nJej zadaniem jest załączenie żądania do kolejki.\n\nconst append = async (links: string[]) => {\n    queueLength++;\n    const link: string = links.pop() || '';\n    const name = link.split('/').reverse()[0];\n    const {data, status} = await axios.get(link);\n    fs.writeFileSync(process.cwd() + `/raw/${name}.html`, data);\n    const now = new Date().getTime();\n    console.log(status === 200 ? `${FgGreen}%s\\t%s\\t%s\\t%s\\t%s\\t%s${Reset}` : `${FgRed}%s\\t%s\\t%s\\t%s\\t%s\\t%s${Reset}`,\n        status, links.length, queueLength, now - last, now - init, name\n    );\n    last = new Date().getTime();\n}\n\nOd poprzedniego kodu różni się tym, że podnosi queueLength oraz wyświetla jej\naktualną wartość.\n\nDo tego dołączamy funkcję sleep, która pozwoli nam na odczekiwania między\nkolejnymi żądaniami. \n\nconst sleep = (time: number) => new Promise((resolve) => setTimeout(resolve, time))\n\nJak widać przy wysyłaniu wielu żądań jednocześnie ważne są mechanizmy\nzabezpieczające nas przed ryzykiem, że przygnieciemy serwer nadmierną ilością\nruchu sieciowego i doprowadzimy do gubienia się pakietów.\n\nSama funkcja main przyjmuje teraz rolę tę samą co ostatnia, le nie czeka na\nwypełnianie promises z funkcji append. Zamiast tego limituje jej wywołania na\npodstawie oczekiwania na sleep i warunku nie przekroczenia MAX_QUEUE_LENGTH.\n\nconst main = async () => {\n    const links = getConfig().map((a: { link: string }): string => a.link);\n\n    while (links.length) {\n        await sleep(9);\n        if (queueLength < MAX_QUEUE_LENGTH)\n            append(links).finally(() => queueLength--)\n    }\n}\n\nPoniżej widzimy fragment z wywołania tak przepisanego programu:\n\nKod można sprawdzić w commicie:\n\nParallel scraping of profile pages (ca8895f1) · Commits · gustawdaniel /\nlawyers-scraperGitLab.comGitLab\n[https://gitlab.com/gustawdaniel/lawyers-scraper/-/commit/ca8895f1d3474881269fbf3ef088a7ff03f9010f]\nPrzetworzenie stron profilowych\nKiedy mamy już podstrony z profilami adwokatów, możemy utworzyć ostatni już plik \nparser.ts i za jego pomocą wzbogacić bazowy zbiór danych o informacje widoczne\nna stronach profilowych. Zanim jednak przejdziemy do kodu skupimy się na danych,\njakie chcemy zebrać o prawnikach o różnych statusach:\n\nexport interface ActiveOutput {\n    id: string\n    date: string\n    address: string\n    phone: string\n    email: string\n    workplace: string\n    speciality: string[]\n}\n\nexport interface FormerOutput {\n    id: string\n    date: string\n    date_end: string\n    last_place: string\n    replaced_by: string\n}\n\nexport interface UndefinedOutput {\n    id: string\n}\n\nexport interface InactiveOutput {\n    id: string\n    date: string\n}\n\nexport type ExtraOutput = ActiveOutput | FormerOutput | UndefinedOutput | InactiveOutput\n\nStatus \"Undefined\" oznacza prawnika, który nie ma statusu. Jest w tej bazie\nkilku takich prawników, często jest to związane ze znalezieniem duplikatu konta.\nNie będziemy w to wnikać, bo to margines tej bazy.\n\nW pliku parser.ts dołączamy importy\n\nimport {FormerOutput, getConfig} from \"./helpers\";\nimport {Output, ExtraOutput, LawyerStatus} from './helpers'\nimport {readFileSync, writeFileSync} from \"fs\";\nimport cheerio from 'cheerio';\n\n\nPonieważ teksty są często wypełnione znakami nowej linii i pustymi znakami\nmiędzy nimi zwykły trim nie wystarczy. Dlatego napisaliśmy funkcję do\nczyszczenia tekstów wieloliniowych\n\nconst cleanText = (text: string): string => text.split(/[\\n|\\t]/).map((t: string): string => t.trim()).filter(t => t).join('\\n');\n\nSamo przetwarzanie plików wygląda tak samo jak zawsze, z tym, że zależy ono od\nstatusu prawnika\n\nconst processFile = (content: string, status: LawyerStatus): ExtraOutput => {\n    const $ = cheerio.load(content);\n\n    const section = (n: number): string => `section .line_list_K div:nth-of-type(${n}) div:nth-of-type(1)`\n\n    const id = $('main section h3').text();\n\n    switch (status) {\n        case LawyerStatus.active:\n            return {\n                id,\n                date: $(section(2)).text(),\n                address: cleanText($('.line_list_K div:nth-of-type(3) div:nth-of-type(1)').text()),\n                phone: $('.line_list_K div:nth-of-type(4) div:nth-of-type(1)').text(),\n                email: (el => el.attr('data-ea') + `@` + el.attr('data-eb'))($('.line_list_K div:last-of-type div:nth-of-type(1)')),\n                speciality: $('.line_list_A > div').toArray().map((el): string => cheerio(el).text().trim()),\n                workplace: cleanText($('.mb_tab_content.special_one .line_list_K').text())\n            };\n        case LawyerStatus.former:\n            return {\n                id,\n                date: $(section(2)).text(),\n                date_end: $(section(3)).text().trim(),\n                last_place: $(section(4)).text().trim(),\n                replaced_by: $(section(5)).text().trim()\n            }\n        case LawyerStatus.inavtive:\n            return {\n                id,\n                date: $(section(2)).text(),\n            }\n        case LawyerStatus.undefined:\n            return {\n                id\n            }\n    }\n}\n\nKolejny dość przewidywalny fragment kodu to funkcja main. \n\nlet initDate = new Date().getTime();\nlet lastDate = new Date().getTime();\n\nconst main = () => {\n    const lawyers = getConfig().reverse().filter((e: Output, i: number) => i < Infinity);\n    const res: (Output & ExtraOutput)[] = [];\n\n    while (lawyers.length) {\n        const lawyer = lawyers.shift();\n        const name = lawyer.link.split('/').reverse()[0];\n        const extraLawyerInfo = processFile(readFileSync(process.cwd() + `/raw/${name}.html`).toString(), lawyer.status)\n\n        res.push({...lawyer, ...extraLawyerInfo});\n\n        if (lawyers.length % 100 === 0) {\n            const now = new Date().getTime();\n            console.log(res.length, lawyers.length, now - lastDate, now - initDate);\n            lastDate = new Date().getTime();\n        }\n    }\n\n    return res;\n}\n\nNa końcu zapis pliku \n\nconst out = main();\nwriteFileSync(process.cwd() + '/out/extended_data.json', JSON.stringify(out))\n\nWykonanie tego pliku pokazuje kolumny z\n\n * ilością przetworzonych plików\n * ilością pozostałych plików\n * czasem miedzy kolejnymi setkami\n * łącznym czasem od włączenia aplikacji\n\nPrzetworzenie każdej setki plików zajmuje około 340 ms. Co oznacza mniej więcej\n300 na sekundę, czyli całość powinna zająć około półtorej minuty. Faktycznie:\n\nts-node parser.ts  124.32s user 1.81s system 131% cpu 1:35.98 total\n\nWygenerowany plik z danymi dotyczącymi prawników warzy 13MB\n\ndu -h out/extended_data.json \n13M\tout/extended_data.json\n\nJeśli chcesz pobrać ten plik, znajduje się on pod linkiem:\n\n> https://gitlab.com/gustawdaniel/lawyers-scraper/-/raw/8259451e89ef695a89576a8229c440301c53009e/out/extended_data.json\nZaładowanie danych do bazy\nPlik json jest bardzo wygodny jako nośnik wymiany danych. Nie nadaje się\nniestety do tego, żeby bezpośrednio wygodnie go przetwarzać i budować na nim\nzapytania. Na szczęście od załadowania tego pliku do bazy mongo dzieli nas tylko\njedna komenda. Jest to:\n\nmongoimport --db test --collection lawyer --jsonArray --drop --file ./out/extended_data.json\n\nPokaże ona \n\n2021-02-17T20:26:58.455+0100\tconnected to: mongodb://localhost/\n2021-02-17T20:26:58.455+0100\tdropping: test.lawyer\n2021-02-17T20:27:00.013+0100\t27191 document(s) imported successfully. 0 document(s) failed to import.\n\n\nWłączając bazę poleceniem\n\nmongo test\n\ndostaniemy się do konsoli z której możemy wykonywać zapytania:\n\ndb.lawyer.aggregate([{$group:{_id: \"$status\", sum:{$sum: 1}, link:{$first: \"$link\"}}}])\n\nZwróci rozkład względem wykonywanych zawodów i przykładowe linki:\n\n{ \"_id\" : \"\", \"sum\" : 7, \"link\" : \"https://rejestradwokatow.pl/adwokat/jawor-marcin-51297\" }\n{ \"_id\" : \"Niewykonujący zawodu\", \"sum\" : 4410, \"link\" : \"https://rejestradwokatow.pl/adwokat/konopacka-izabela-83958\" }\n{ \"_id\" : \"Wykonujący zawód\", \"sum\" : 19930, \"link\" : \"https://rejestradwokatow.pl/adwokat/konrad-adam-33796\" }\n{ \"_id\" : \"Były adwokat\", \"sum\" : 2844, \"link\" : \"https://rejestradwokatow.pl/adwokat/konopiski-sawomir-48480\" }\n\nDzięki interfejsowi Compass możemy przeglądać znacznie więcej takich grupowań w\ntrybie graficznym\n\nJeśli chcemy wrzucić te dane do mongo atlas możemy użyć komendy\n\nmongoimport --collection lawyer <connection-string>  --jsonArray --drop --file ./out/extended_data.json\n\ngdzie connection-string to ciąg znakowy pozwalający łączyć się z bazą:\n\nmongodb+srv://user:pass@cluseter_number.mongodb.net/db_name\n\nW mongo charts możemy w chwilę wyklikać kilka wykresów, np wspomniany wcześniej\nrozkład statusu prawników\n\nInteraktywny wykres dostępny do zagnieżdżenia jako iframe możemy zobaczyć\nponiżej.\n\nKolejny wykres przedstawia roczną liczbę wpisów do rejestru. Można się było\nspodziewać, że w danych pobieranych z internetu są błędy. Tak było i tym razem.\nMusieliśmy wyrzucić wszystkie wpisy pozbawione dat, z datami \"0000-00-00\" i\njeden z datą \"2019-00-01\". za pomocą filtru\n\n{status: {$ne: \"\"}, date:{$nin: [\"\",\"0000-00-00\",\"2019-00-01\"]}}\n\nPo dodaniu wyliczanego pola z datą i rokiem:\n\n{computed_date: {\n  $dateFromString: {\n    dateString: \"$date\"\n  }\n},\n  year:  {$year:{\n  $dateFromString: {\n    dateString: \"$date\"\n  }\n}}\n}\n\nMożemy zdefiniować wykres\n\nPodobnie przygotowujemy wykres ze średnią liczbą specjalizacji\n\nZa pomocą konfiguracji\n\nmożemy pokazać częstotliwość wybieranych specjalizacji \n\nNa koniec załączam tabelę z danymi kontaktowymi. Nie zawiera ona wszystkich\nadwokatów, lecz jedynie tych mających poprawne numery telefonów, czyli\nspełniających warunek\n\n{phone: /^(\\d|-)+$/}\n\nMam nadzieję, że lektura tego wpisu rozszerzyła Twój arsenał narzędzi do\nscrapingu i wizualizacji danych. Jeśli chcesz porozmawiać o projektach z tego\nzakresu, myślisz o zamówieniu scrapingu lub po prostu chcesz wymienić się\ndoświadczeniem zapraszam do kontaktu.\n\nDaniel GustawWelcome to my scheduling page. Please follow the instructions to\nadd an event to my calendar.Calendly [https://calendly.com/gustaw-daniel]",
            "feature_image": "__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-20-19-30.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-02-17T15:24:28.000Z",
            "updated_at": "2021-02-17T20:59:14.000Z",
            "published_at": "2021-02-17T20:59:14.000Z",
            "custom_excerpt": "Poznaj technikę zrównoleglania scrapingu która może kilkukrotnie przyśpieszyć pobieranie danych.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "602d8a1a194a5b778b1ab9ef",
            "uuid": "46e5f436-671d-4d35-86f3-850fd580bb35",
            "title": "Scraping Rejestru Aptek",
            "slug": "scraping-rejestrow-medycznych",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-33-55.png\",\"width\":1141,\"height\":1007}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-35-22.png\",\"width\":1826,\"height\":723}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-36-55.png\",\"width\":1856,\"height\":785}],[\"code\",{\"code\":\"http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\\\?page\\\\=1\\\\&size\\\\=2\\\\&sortField\\\\=originId\\\\&sortDirection\\\\=ASC\",\"language\":\"bash\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-39-36.png\",\"width\":1263,\"height\":1169}],[\"code\",{\"code\":\"http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\\\?page\\\\=1\\\\&size\\\\=2\\\\&sortField\\\\=originId\\\\&sortDirection\\\\=ASC | jq '.[][] | {nr: .registrationNumber, name: .owners[0].name}'\",\"language\":\"bash\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-45-15.png\",\"width\":895,\"height\":188}],[\"code\",{\"code\":\"http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\\\?page\\\\=1\\\\&size\\\\=10000\\\\&sortField\\\\=originId\\\\&sortDirection\\\\=ASC | jq '.[][].owners[0].name' | wc\",\"language\":\"bash\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-48-04.png\",\"width\":878,\"height\":56}],[\"code\",{\"code\":\"http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\\\?page\\\\=1\\\\&size\\\\=15000\\\\&sortField\\\\=originId\\\\&sortDirection\\\\=ASC | jq '.[][]' > ra.json\",\"language\":\"bash\"}],[\"code\",{\"code\":\"mongoimport --db test --collection ra --drop --file ./ra.json\",\"language\":\"bash\"}],[\"code\",{\"code\":\"2021-02-17T22:59:19.216+0100\\tconnected to: mongodb://localhost/\\n2021-02-17T22:59:19.217+0100\\tdropping: test.ra\\n2021-02-17T22:59:20.234+0100\\t8006 document(s) imported successfully. 0 document(s) failed to import.\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\\\?page\\\\=1\\\\&size\\\\=10000\\\\&sortField\\\\=originId\\\\&sortDirection\\\\=ASC | jq '.[][]' > ra.json\",\"language\":\"bash\"}],[\"code\",{\"code\":\"mongoimport --db test --collection ra --drop --file ./ra.json\\n                                                                                            \\n2021-02-17T23:02:11.893+0100\\tconnected to: mongodb://localhost/\\n2021-02-17T23:02:11.894+0100\\tdropping: test.ra\\n2021-02-17T23:02:13.143+0100\\t10000 document(s) imported successfully. 0 document(s) failed to import.\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\\\?page\\\\=2\\\\&size\\\\=10000\\\\&sortField\\\\=originId\\\\&sortDirection\\\\=ASC | jq '.[][]' >> ra.json\",\"language\":\"bash\"}],[\"code\",{\"code\":\"mongoimport --db test --collection ra --drop --file ./ra.json\\n                                                                                            \\n2021-02-17T23:03:43.592+0100\\tconnected to: mongodb://localhost/\\n2021-02-17T23:03:43.592+0100\\tdropping: test.ra\\n2021-02-17T23:03:45.173+0100\\t13006 document(s) imported successfully. 0 document(s) failed to import.\",\"language\":\"bash\"}],[\"code\",{\"code\":\"http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\\\?page\\\\=0\\\\&size\\\\=10000\\\\&sortField\\\\=originId\\\\&sortDirection\\\\=ASC | jq '.[][]' >> ra.json\",\"language\":\"bash\"}],[\"code\",{\"code\":\"mongoimport --db test --collection ra --drop --file ./ra.json\\n\\n2021-02-17T23:08:02.038+0100\\tconnected to: mongodb://localhost/\\n2021-02-17T23:08:02.038+0100\\tdropping: test.ra\\n2021-02-17T23:08:04.808+0100\\t23006 document(s) imported successfully. 0 document(s) failed to import.\\n\"}],[\"code\",{\"code\":\"{\\n    '$unwind': {\\n      'path': '$owners'\\n    }\\n}\"}],[\"code\",{\"code\":\"{\\n    '$project': {\\n      'name': '$owners.name', \\n      'firstName': '$owners.firstName', \\n      'lastName': '$owners.lastName', \\n      'krs': '$owners.krs', \\n      'nip': '$owners.nip', \\n      'regon': '$owners.regon', \\n      'address': {\\n        '$concat': [\\n          '$address.street', ' ', '$address.homeNumber', ', ', '$address.postcode', ' ', '$address.city'\\n        ]\\n      }\\n    }\\n}\"}],[\"code\",{\"code\":\"const MongoClient = require('mongodb').MongoClient;\\nconst assert = require('assert');\\n\\n/*\\n * Requires the MongoDB Node.js Driver\\n * https://mongodb.github.io/node-mongodb-native\\n */\\n\\nconst agg = [\\n  {\\n    '$unwind': {\\n      'path': '$owners'\\n    }\\n  }, {\\n    '$project': {\\n      'name': '$owners.name', \\n      'firstName': '$owners.firstName', \\n      'lastName': '$owners.lastName', \\n      'krs': '$owners.krs', \\n      'nip': '$owners.nip', \\n      'regon': '$owners.regon', \\n      'address': {\\n        '$concat': [\\n          '$address.street', ' ', '$address.homeNumber', ', ', '$address.postcode', ' ', '$address.city'\\n        ]\\n      }\\n    }\\n  }\\n];\\n\\nMongoClient.connect(\\n  'mongodb://localhost:27017/?readPreference=primary&appname=MongoDB%20Compass&ssl=false',\\n  { useNewUrlParser: true, useUnifiedTopology: true },\\n  function(connectErr, client) {\\n    assert.equal(null, connectErr);\\n    const coll = client.db('test').collection('ra');\\n    coll.aggregate(agg, (cmdErr, result) => {\\n      assert.equal(null, cmdErr);\\n    });\\n    client.close();\\n  });\",\"language\":\"js\"}],[\"code\",{\"code\":\" npm init -y && npm i mongodb@3.6.3 assert\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://developer.mongodb.com/community/forums/t/warning-accessing-non-existent-property-mongoerror-of-module-exports-inside-circular-dependency/15411\",\"metadata\":{\"url\":\"https://developer.mongodb.com/community/forums/t/warning-accessing-non-existent-property-mongoerror-of-module-exports-inside-circular-dependency/15411\",\"title\":\"Warning: Accessing non-existent property ‘MongoError’ of module exports inside circular dependency\",\"description\":\"Hi, I am getting a warning consistently each time our webserver or another process connects to the DB. (node:24990) Warning: Accessing non-existent property ‘MongoError’ of module exports inside circular dependency at emitCircularRequireWarning (internal/modules/cjs/loader.js:650:11) at Ob…\",\"author\":\"Laurens\",\"publisher\":\"MongoDB Developer Community Forums\",\"thumbnail\":\"https://developer.mongodb.com/community/forums/uploads/default/original/1X/c436b6a5eb8cba8ca954e71fccfae95c4a5b569f.svg\",\"icon\":\"https://developer.mongodb.com/community/forums/uploads/default/optimized/1X/c436b6a5eb8cba8ca954e71fccfae95c4a5b569f_2_180x180.svg\"}}],[\"code\",{\"code\":\"const fs = require('fs')\"}],[\"code\",{\"code\":\"MongoClient.connect(\\n    'mongodb://localhost:27017/?readPreference=primary&appname=MongoDB%20Compass&ssl=false',\\n    { useNewUrlParser: true, useUnifiedTopology: true },\\n    function(connectErr, client) {\\n      assert.strictEqual(null, connectErr);\\n      const coll = client.db('test').collection('ra');\\n      coll.aggregate(agg, async (cmdErr, result) => {\\n        assert.strictEqual(null, cmdErr);\\n          const out = await result.toArray();\\n          fs.writeFileSync('ra-project.json', JSON.stringify(out));\\n          return client.close();\\n      });\\n    });\"}],[\"code\",{\"code\":\"du -h ra*json\\n50M\\tra.json\\n4.8M\\tra-project.json\"}],[\"embed\",{\"url\":\"https://youtu.be/vB5dO2lRHTE\",\"html\":\"<iframe width=\\\"200\\\" height=\\\"150\\\" src=\\\"https://www.youtube.com/embed/vB5dO2lRHTE?feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\",\"metadata\":{\"title\":\"Błąd w rejestrze diagnostów\",\"author_name\":\"gustawdaniel\",\"author_url\":\"https://www.youtube.com/user/gustawdaniel\",\"height\":150,\"width\":200,\"version\":\"1.0\",\"provider_name\":\"YouTube\",\"provider_url\":\"https://www.youtube.com/\",\"thumbnail_height\":360,\"thumbnail_width\":480,\"thumbnail_url\":\"https://i.ytimg.com/vi/vB5dO2lRHTE/hqdefault.jpg\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://calendly.com/gustaw-daniel\",\"metadata\":{\"url\":\"https://calendly.com/gustaw-daniel\",\"title\":\"Daniel Gustaw\",\"description\":\"Welcome to my scheduling page. Please follow the instructions to add an event to my calendar.\",\"author\":null,\"publisher\":\"Calendly\",\"thumbnail\":\"https://assets.calendly.com/assets/ogimage-a63bb2f442cd9e6345a5e4d7fe75393c6cfcc1ff29e48e858742d43573a8b02c.png?source=opengraph\",\"icon\":\"https://assets.calendly.com/assets/touch-icon-ipad-retina-7a95e0c775301f4c0a22002bdf0a95d3c2b9cbe95af29c64f9c9573bac1f01e4.png\"}}]],\"markups\":[[\"a\",[\"href\",\"https://rejestrymedyczne.ezdrowie.gov.pl/main\"]],[\"a\",[\"href\",\"https://rejestrymedyczne.ezdrowie.gov.pl/ra/search/public\"]],[\"strong\"],[\"code\"],[\"a\",[\"href\",\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/ra.json\"]],[\"a\",[\"href\",\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/ra-project.json\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Są strony lepiej lub gorzej zabezpieczone przed scrapingiem. Teraz przyjrzymy się stronie wcale nie zabezpieczonej - Rejestrowi Medycznemu zawierającemu dane o aptekach.\"]]],[1,\"p\",[[0,[],0,\"Z artykułu dowiesz się jak badać strony internetowe i na co zwracać uwagę przy scrapowaniu danych. Okazuje się, że w niektórych przypadkach wystarczają naprawdę znikome ilości kodu aby pobrać dane w wygodnym do dalszej obróbki formacie.\"]]],[1,\"p\",[[0,[],0,\"Artykuł oparty jest o analizę scrapingu na konkretnym przypadku. Tutaj jest to strona:\"]]],[1,\"blockquote\",[[0,[0],1,\"https://rejestrymedyczne.ezdrowie.gov.pl/main\"]]],[1,\"p\",[[0,[],0,\"Zawiera ona kilka rejestrów danych powiązanych z medycyną\"]]],[10,0],[1,\"p\",[[0,[],0,\"Załóżmy, że chcemy pobrać wszystkie dane o aptekach z tej strony. Klikamy na rejestr aptek i widzimy:\"]]],[1,\"blockquote\",[[0,[1],1,\"https://rejestrymedyczne.ezdrowie.gov.pl/ra/search/public\"]]],[10,1],[1,\"p\",[[0,[],0,\"Co ciekawe paginacja nie powoduje tu zmiany adresu url tylko przeładowanie strony i wyświetlenie kolejnego widoku w tabeli.\"]]],[1,\"p\",[[0,[],0,\"Po przejściu do zakładki \\\"Network\\\" w konsoli przeglądarki widzimy, że w tle wysyłany jest request\"]]],[10,2],[1,\"p\",[[0,[],0,\"Okazuje się, że bez żadnego tokena, klucza czy ciasteczka można pobrać dane, które ładowane są do tabeli bezpośrednio z api poleceniem\"]]],[10,3],[10,4],[1,\"p\",[[0,[],0,\"Nie ma problemu, żeby pobrać \"],[0,[2],1,\"dwie\"],[0,[],0,\" apteki:\"]]],[10,5],[10,6],[1,\"p\",[[0,[],0,\"Nie ma problemu, żeby pobrać \"],[0,[2],1,\"dziesięć tysięcy\"],[0,[],0,\" aptek.\"]]],[10,7],[10,8],[1,\"p\",[[0,[],0,\"Z paginacji strony widzimy, że rejestr zawiera \"],[0,[3],1,\"23006\"],[0,[],0,\" apteki. Zatem jeśli możemy pobrać 10k na raz potrzebujemy 3 requestów. Niestety wpisanie \"],[0,[3],1,\"size=23006\"],[0,[],0,\" rzuca błąd, ale warto sprawdzić \"],[0,[3],1,\"size=15000\"],[0,[],0,\". Dwa requesty to zawsze lepiej niż trzy.\"]]],[1,\"p\",[[0,[],0,\"Do pobrania 15 tys aptek służy komenda\"]]],[10,9],[1,\"p\",[[0,[],0,\"Do włożenia danych do bazy\"]]],[10,10],[1,\"p\",[[0,[],0,\"Okazuje się, że niestety mamy tylko \"],[0,[3],1,\"8006\"],[0,[],0,\" dokumentów, a nie spodziewane \"],[0,[3],1,\"15000\"],[0,[],0,\".\"]]],[10,11],[1,\"p\",[[0,[],0,\"Dla \"],[0,[3],1,\"10,000\"],[0,[],0,\" mamy poprawny wynik zarówno pobierania\"]]],[10,12],[1,\"p\",[[0,[],0,\"jak i importu\"]]],[10,13],[1,\"p\",[[0,[],0,\"Ważne, że przy pobieraniu drugiej strony dopisujemy do pliku \"],[0,[3],1,\">>\"],[0,[],0,\" a nie nadpisujemy jego zawartość \"],[0,[3],1,\">\"],[0,[],0,\".\"]]],[10,14],[1,\"p\",[[0,[],0,\"Tym razem zapis daje \"],[0,[3],1,\"13006\"],[0,[],0,\" plików i wszystko wyjaśnia się.\"]]],[10,15],[1,\"p\",[[0,[],0,\"Wynik \"],[0,[3],1,\"8006\"],[0,[],0,\" przy \"],[0,[3],1,\"size=15000\"],[0,[],0,\" wynikał z tego, że strony numerują się od \"],[0,[3],1,\"0\"],[0,[],0,\" w tym \"],[0,[3],1,\"api\"],[0,[],0,\" i \"],[0,[3],1,\"8006\"],[0,[],0,\" = \"],[0,[3],1,\"23006 - 15000\"],[0,[],0,\", co było poprawnym wynikiem.\"]]],[1,\"p\",[[0,[],0,\"Tak czy siak nie ważne czy pobieramy po 10 czy po 15 tysięcy został nam jeden request z \"],[0,[3],1,\"page=0\"],[0,[],0,\" np.:\"]]],[10,16],[1,\"p\",[[0,[],0,\"Ostatni import pozwala nam wgrać wszystkie apteki.\"]]],[10,17],[1,\"p\",[[0,[],0,\"W \"],[0,[3],1,\"compass\"],[0,[],0,\" możemy zaprojektować agregację z dwoma etapami:\"]]],[3,\"ol\",[[[0,[],0,\"Zdjęcie tablicy z \"],[0,[3],1,\"owners\"]]]],[10,18],[1,\"p\",[[0,[],0,\"2. Projekcja najbardziej interesujących pól\"]]],[10,19],[1,\"p\",[[0,[],0,\"Pozwoli nam to na wygenerowanie kodu programu\"]]],[10,20],[1,\"p\",[[0,[],0,\"Aby go włączyć musimy zainstalować sterowniki do \"],[0,[3],1,\"mongo\"],[0,[],0,\" oraz \"],[0,[3],1,\"assert\"],[0,[],0,\".\"]]],[10,21],[1,\"p\",[[0,[],0,\"Wersja \"],[0,[3],1,\"@3.6.3\"],[0,[],0,\" wynika z występowania błędu z brakującym \"],[0,[3],1,\"MongoError\"],[0,[],0,\" w wersji \"],[0,[3],1,\"3.6.4\"],[0,[],0,\".\"]]],[10,22],[1,\"p\",[[0,[],0,\"Ten zaprezentowany kod poza wykonaniem agregacji nic nie robi. Jeśli wynik agregacji chcieli byśmy zapisać do pliku należy go delikatnie zmodyfikować dodając na początku niezbędny import\"]]],[10,23],[1,\"p\",[[0,[],0,\"i zmieniając callback na taki, który faktycznie zapisuje wynik.\"]]],[10,24],[1,\"p\",[[0,[],0,\"Okazuje się, że najciekawsze dane to około 10% tych które pobraliśmy.\"]]],[10,25],[1,\"p\",[[0,[],0,\"Ten wpis pokazuje jak bardzo łatwo jest wykonywać scraping wykorzystując api przygotowane przez twórców stron.\"]]],[1,\"p\",[[0,[],0,\"Niestety nie wszystkie rejestry z tego serwisu są tak łatwe w pobraniu. Jednym z trudniejszych jest rejestr diagnostów medycznych. Tutaj jednak trudność polega na tym, że nawet człowiek nie może dostać się do części danych prezentowanych w tym rejestrze z powodu błędów w kodzie strony. \"]]],[10,26],[1,\"h2\",[[0,[],0,\"Podsumowanie\"]]],[1,\"p\",[[0,[],0,\"Pokazaliśmy jak korzystając z konsoli przeglądarki wykryć żądania do \"],[0,[3],1,\"api\"],[0,[],0,\" oraz jak wykorzystać je do scrapingu danych. Następnie włożyliśmy dane do \"],[0,[3],1,\"mongodb\"],[0,[],0,\" i dzięki agregacji wygenerowaliśmy 10 razy lżejszy zbiór danych zawierający jedynie najciekawsze informacje.\"]]],[1,\"p\",[[0,[],0,\"W tym projekcie kodu jest tak mało, że nie powstało do niego repozytorium. Dane można pobrać z linków\"]]],[1,\"p\",[[0,[],0,\"Wszystkie dane:\"]]],[1,\"blockquote\",[[0,[4],1,\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/ra.json\"]]],[1,\"p\",[[0,[],0,\"Tylko KRS, NIP, REGON, ADRES, IMIĘ, NAZWISKO, NAZWA\"]]],[1,\"blockquote\",[[0,[5],1,\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/ra-project.json\"]]],[1,\"p\",[[0,[],0,\"Jeśli chesz rzucić mi wyzwanie i zaproponować stronę, którą warto zescrapować, nie miej oporów przed umówieniem niezobowiązującej bezpłatnej konsultacji\"]]],[10,27],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "html": "<p>Są strony lepiej lub gorzej zabezpieczone przed scrapingiem. Teraz przyjrzymy się stronie wcale nie zabezpieczonej - Rejestrowi Medycznemu zawierającemu dane o aptekach.</p><p>Z artykułu dowiesz się jak badać strony internetowe i na co zwracać uwagę przy scrapowaniu danych. Okazuje się, że w niektórych przypadkach wystarczają naprawdę znikome ilości kodu aby pobrać dane w wygodnym do dalszej obróbki formacie.</p><p>Artykuł oparty jest o analizę scrapingu na konkretnym przypadku. Tutaj jest to strona:</p><blockquote><a href=\"https://rejestrymedyczne.ezdrowie.gov.pl/main\">https://rejestrymedyczne.ezdrowie.gov.pl/main</a></blockquote><p>Zawiera ona kilka rejestrów danych powiązanych z medycyną</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-33-55.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1141\" height=\"1007\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-22-33-55.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-22-33-55.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-33-55.png 1141w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Załóżmy, że chcemy pobrać wszystkie dane o aptekach z tej strony. Klikamy na rejestr aptek i widzimy:</p><blockquote><a href=\"https://rejestrymedyczne.ezdrowie.gov.pl/ra/search/public\">https://rejestrymedyczne.ezdrowie.gov.pl/ra/search/public</a></blockquote><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-35-22.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1826\" height=\"723\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-22-35-22.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-22-35-22.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-17-22-35-22.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-35-22.png 1826w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Co ciekawe paginacja nie powoduje tu zmiany adresu url tylko przeładowanie strony i wyświetlenie kolejnego widoku w tabeli.</p><p>Po przejściu do zakładki \"Network\" w konsoli przeglądarki widzimy, że w tle wysyłany jest request</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-36-55.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1856\" height=\"785\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-22-36-55.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-22-36-55.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-from-2021-02-17-22-36-55.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-36-55.png 1856w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Okazuje się, że bez żadnego tokena, klucza czy ciasteczka można pobrać dane, które ładowane są do tabeli bezpośrednio z api poleceniem</p><pre><code class=\"language-bash\">http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=1\\&amp;size\\=2\\&amp;sortField\\=originId\\&amp;sortDirection\\=ASC</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-39-36.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1263\" height=\"1169\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-22-39-36.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-17-22-39-36.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-39-36.png 1263w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Nie ma problemu, żeby pobrać <strong>dwie</strong> apteki:</p><pre><code class=\"language-bash\">http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=1\\&amp;size\\=2\\&amp;sortField\\=originId\\&amp;sortDirection\\=ASC | jq '.[][] | {nr: .registrationNumber, name: .owners[0].name}'</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-45-15.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"895\" height=\"188\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-22-45-15.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-45-15.png 895w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Nie ma problemu, żeby pobrać <strong>dziesięć tysięcy</strong> aptek.</p><pre><code class=\"language-bash\">http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=1\\&amp;size\\=10000\\&amp;sortField\\=originId\\&amp;sortDirection\\=ASC | jq '.[][].owners[0].name' | wc</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-48-04.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"878\" height=\"56\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-17-22-48-04.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-17-22-48-04.png 878w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Z paginacji strony widzimy, że rejestr zawiera <code>23006</code> apteki. Zatem jeśli możemy pobrać 10k na raz potrzebujemy 3 requestów. Niestety wpisanie <code>size=23006</code> rzuca błąd, ale warto sprawdzić <code>size=15000</code>. Dwa requesty to zawsze lepiej niż trzy.</p><p>Do pobrania 15 tys aptek służy komenda</p><pre><code class=\"language-bash\">http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=1\\&amp;size\\=15000\\&amp;sortField\\=originId\\&amp;sortDirection\\=ASC | jq '.[][]' &gt; ra.json</code></pre><p>Do włożenia danych do bazy</p><pre><code class=\"language-bash\">mongoimport --db test --collection ra --drop --file ./ra.json</code></pre><p>Okazuje się, że niestety mamy tylko <code>8006</code> dokumentów, a nie spodziewane <code>15000</code>.</p><pre><code class=\"language-bash\">2021-02-17T22:59:19.216+0100\tconnected to: mongodb://localhost/\n2021-02-17T22:59:19.217+0100\tdropping: test.ra\n2021-02-17T22:59:20.234+0100\t8006 document(s) imported successfully. 0 document(s) failed to import.\n</code></pre><p>Dla <code>10,000</code> mamy poprawny wynik zarówno pobierania</p><pre><code class=\"language-bash\">http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=1\\&amp;size\\=10000\\&amp;sortField\\=originId\\&amp;sortDirection\\=ASC | jq '.[][]' &gt; ra.json</code></pre><p>jak i importu</p><pre><code class=\"language-bash\">mongoimport --db test --collection ra --drop --file ./ra.json\n                                                                                            \n2021-02-17T23:02:11.893+0100\tconnected to: mongodb://localhost/\n2021-02-17T23:02:11.894+0100\tdropping: test.ra\n2021-02-17T23:02:13.143+0100\t10000 document(s) imported successfully. 0 document(s) failed to import.\n</code></pre><p>Ważne, że przy pobieraniu drugiej strony dopisujemy do pliku <code>&gt;&gt;</code> a nie nadpisujemy jego zawartość <code>&gt;</code>.</p><pre><code class=\"language-bash\">http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=2\\&amp;size\\=10000\\&amp;sortField\\=originId\\&amp;sortDirection\\=ASC | jq '.[][]' &gt;&gt; ra.json</code></pre><p>Tym razem zapis daje <code>13006</code> plików i wszystko wyjaśnia się.</p><pre><code class=\"language-bash\">mongoimport --db test --collection ra --drop --file ./ra.json\n                                                                                            \n2021-02-17T23:03:43.592+0100\tconnected to: mongodb://localhost/\n2021-02-17T23:03:43.592+0100\tdropping: test.ra\n2021-02-17T23:03:45.173+0100\t13006 document(s) imported successfully. 0 document(s) failed to import.</code></pre><p>Wynik <code>8006</code> przy <code>size=15000</code> wynikał z tego, że strony numerują się od <code>0</code> w tym <code>api</code> i <code>8006</code> = <code>23006 - 15000</code>, co było poprawnym wynikiem.</p><p>Tak czy siak nie ważne czy pobieramy po 10 czy po 15 tysięcy został nam jeden request z <code>page=0</code> np.:</p><pre><code class=\"language-bash\">http -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=0\\&amp;size\\=10000\\&amp;sortField\\=originId\\&amp;sortDirection\\=ASC | jq '.[][]' &gt;&gt; ra.json</code></pre><p>Ostatni import pozwala nam wgrać wszystkie apteki.</p><pre><code>mongoimport --db test --collection ra --drop --file ./ra.json\n\n2021-02-17T23:08:02.038+0100\tconnected to: mongodb://localhost/\n2021-02-17T23:08:02.038+0100\tdropping: test.ra\n2021-02-17T23:08:04.808+0100\t23006 document(s) imported successfully. 0 document(s) failed to import.\n</code></pre><p>W <code>compass</code> możemy zaprojektować agregację z dwoma etapami:</p><ol><li>Zdjęcie tablicy z <code>owners</code></li></ol><pre><code>{\n    '$unwind': {\n      'path': '$owners'\n    }\n}</code></pre><p>2. Projekcja najbardziej interesujących pól</p><pre><code>{\n    '$project': {\n      'name': '$owners.name', \n      'firstName': '$owners.firstName', \n      'lastName': '$owners.lastName', \n      'krs': '$owners.krs', \n      'nip': '$owners.nip', \n      'regon': '$owners.regon', \n      'address': {\n        '$concat': [\n          '$address.street', ' ', '$address.homeNumber', ', ', '$address.postcode', ' ', '$address.city'\n        ]\n      }\n    }\n}</code></pre><p>Pozwoli nam to na wygenerowanie kodu programu</p><pre><code class=\"language-js\">const MongoClient = require('mongodb').MongoClient;\nconst assert = require('assert');\n\n/*\n * Requires the MongoDB Node.js Driver\n * https://mongodb.github.io/node-mongodb-native\n */\n\nconst agg = [\n  {\n    '$unwind': {\n      'path': '$owners'\n    }\n  }, {\n    '$project': {\n      'name': '$owners.name', \n      'firstName': '$owners.firstName', \n      'lastName': '$owners.lastName', \n      'krs': '$owners.krs', \n      'nip': '$owners.nip', \n      'regon': '$owners.regon', \n      'address': {\n        '$concat': [\n          '$address.street', ' ', '$address.homeNumber', ', ', '$address.postcode', ' ', '$address.city'\n        ]\n      }\n    }\n  }\n];\n\nMongoClient.connect(\n  'mongodb://localhost:27017/?readPreference=primary&amp;appname=MongoDB%20Compass&amp;ssl=false',\n  { useNewUrlParser: true, useUnifiedTopology: true },\n  function(connectErr, client) {\n    assert.equal(null, connectErr);\n    const coll = client.db('test').collection('ra');\n    coll.aggregate(agg, (cmdErr, result) =&gt; {\n      assert.equal(null, cmdErr);\n    });\n    client.close();\n  });</code></pre><p>Aby go włączyć musimy zainstalować sterowniki do <code>mongo</code> oraz <code>assert</code>.</p><pre><code> npm init -y &amp;&amp; npm i mongodb@3.6.3 assert</code></pre><p>Wersja <code>@3.6.3</code> wynika z występowania błędu z brakującym <code>MongoError</code> w wersji <code>3.6.4</code>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://developer.mongodb.com/community/forums/t/warning-accessing-non-existent-property-mongoerror-of-module-exports-inside-circular-dependency/15411\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Warning: Accessing non-existent property ‘MongoError’ of module exports inside circular dependency</div><div class=\"kg-bookmark-description\">Hi, I am getting a warning consistently each time our webserver or another process connects to the DB. (node:24990) Warning: Accessing non-existent property ‘MongoError’ of module exports inside circular dependency at emitCircularRequireWarning (internal/modules/cjs/loader.js:650:11) at Ob…</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://developer.mongodb.com/community/forums/uploads/default/optimized/1X/c436b6a5eb8cba8ca954e71fccfae95c4a5b569f_2_180x180.svg\"><span class=\"kg-bookmark-author\">MongoDB Developer Community Forums</span><span class=\"kg-bookmark-publisher\">Laurens</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://developer.mongodb.com/community/forums/uploads/default/original/1X/c436b6a5eb8cba8ca954e71fccfae95c4a5b569f.svg\"></div></a></figure><p>Ten zaprezentowany kod poza wykonaniem agregacji nic nie robi. Jeśli wynik agregacji chcieli byśmy zapisać do pliku należy go delikatnie zmodyfikować dodając na początku niezbędny import</p><pre><code>const fs = require('fs')</code></pre><p>i zmieniając callback na taki, który faktycznie zapisuje wynik.</p><pre><code>MongoClient.connect(\n    'mongodb://localhost:27017/?readPreference=primary&amp;appname=MongoDB%20Compass&amp;ssl=false',\n    { useNewUrlParser: true, useUnifiedTopology: true },\n    function(connectErr, client) {\n      assert.strictEqual(null, connectErr);\n      const coll = client.db('test').collection('ra');\n      coll.aggregate(agg, async (cmdErr, result) =&gt; {\n        assert.strictEqual(null, cmdErr);\n          const out = await result.toArray();\n          fs.writeFileSync('ra-project.json', JSON.stringify(out));\n          return client.close();\n      });\n    });</code></pre><p>Okazuje się, że najciekawsze dane to około 10% tych które pobraliśmy.</p><pre><code>du -h ra*json\n50M\tra.json\n4.8M\tra-project.json</code></pre><p>Ten wpis pokazuje jak bardzo łatwo jest wykonywać scraping wykorzystując api przygotowane przez twórców stron.</p><p>Niestety nie wszystkie rejestry z tego serwisu są tak łatwe w pobraniu. Jednym z trudniejszych jest rejestr diagnostów medycznych. Tutaj jednak trudność polega na tym, że nawet człowiek nie może dostać się do części danych prezentowanych w tym rejestrze z powodu błędów w kodzie strony. </p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"150\" src=\"https://www.youtube.com/embed/vB5dO2lRHTE?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><h2 id=\"podsumowanie\">Podsumowanie</h2><p>Pokazaliśmy jak korzystając z konsoli przeglądarki wykryć żądania do <code>api</code> oraz jak wykorzystać je do scrapingu danych. Następnie włożyliśmy dane do <code>mongodb</code> i dzięki agregacji wygenerowaliśmy 10 razy lżejszy zbiór danych zawierający jedynie najciekawsze informacje.</p><p>W tym projekcie kodu jest tak mało, że nie powstało do niego repozytorium. Dane można pobrać z linków</p><p>Wszystkie dane:</p><blockquote><a href=\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/ra.json\">https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/ra.json</a></blockquote><p>Tylko KRS, NIP, REGON, ADRES, IMIĘ, NAZWISKO, NAZWA</p><blockquote><a href=\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/ra-project.json\">https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/ra-project.json</a></blockquote><p>Jeśli chesz rzucić mi wyzwanie i zaproponować stronę, którą warto zescrapować, nie miej oporów przed umówieniem niezobowiązującej bezpłatnej konsultacji</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://calendly.com/gustaw-daniel\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Daniel Gustaw</div><div class=\"kg-bookmark-description\">Welcome to my scheduling page. Please follow the instructions to add an event to my calendar.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.calendly.com/assets/touch-icon-ipad-retina-7a95e0c775301f4c0a22002bdf0a95d3c2b9cbe95af29c64f9c9573bac1f01e4.png\"><span class=\"kg-bookmark-author\">Calendly</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.calendly.com/assets/ogimage-a63bb2f442cd9e6345a5e4d7fe75393c6cfcc1ff29e48e858742d43573a8b02c.png?source&#x3D;opengraph\"></div></a></figure>",
            "comment_id": "602d8a1a194a5b778b1ab9ef",
            "plaintext": "Są strony lepiej lub gorzej zabezpieczone przed scrapingiem. Teraz przyjrzymy\nsię stronie wcale nie zabezpieczonej - Rejestrowi Medycznemu zawierającemu dane\no aptekach.\n\nZ artykułu dowiesz się jak badać strony internetowe i na co zwracać uwagę przy\nscrapowaniu danych. Okazuje się, że w niektórych przypadkach wystarczają\nnaprawdę znikome ilości kodu aby pobrać dane w wygodnym do dalszej obróbki\nformacie.\n\nArtykuł oparty jest o analizę scrapingu na konkretnym przypadku. Tutaj jest to\nstrona:\n\n> https://rejestrymedyczne.ezdrowie.gov.pl/main\nZawiera ona kilka rejestrów danych powiązanych z medycyną\n\nZałóżmy, że chcemy pobrać wszystkie dane o aptekach z tej strony. Klikamy na\nrejestr aptek i widzimy:\n\n> https://rejestrymedyczne.ezdrowie.gov.pl/ra/search/public\nCo ciekawe paginacja nie powoduje tu zmiany adresu url tylko przeładowanie\nstrony i wyświetlenie kolejnego widoku w tabeli.\n\nPo przejściu do zakładki \"Network\" w konsoli przeglądarki widzimy, że w tle\nwysyłany jest request\n\nOkazuje się, że bez żadnego tokena, klucza czy ciasteczka można pobrać dane,\nktóre ładowane są do tabeli bezpośrednio z api poleceniem\n\nhttp -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=1\\&size\\=2\\&sortField\\=originId\\&sortDirection\\=ASC\n\nNie ma problemu, żeby pobrać dwie apteki:\n\nhttp -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=1\\&size\\=2\\&sortField\\=originId\\&sortDirection\\=ASC | jq '.[][] | {nr: .registrationNumber, name: .owners[0].name}'\n\nNie ma problemu, żeby pobrać dziesięć tysięcy aptek.\n\nhttp -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=1\\&size\\=10000\\&sortField\\=originId\\&sortDirection\\=ASC | jq '.[][].owners[0].name' | wc\n\nZ paginacji strony widzimy, że rejestr zawiera 23006 apteki. Zatem jeśli możemy\npobrać 10k na raz potrzebujemy 3 requestów. Niestety wpisanie size=23006 rzuca\nbłąd, ale warto sprawdzić size=15000. Dwa requesty to zawsze lepiej niż trzy.\n\nDo pobrania 15 tys aptek służy komenda\n\nhttp -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=1\\&size\\=15000\\&sortField\\=originId\\&sortDirection\\=ASC | jq '.[][]' > ra.json\n\nDo włożenia danych do bazy\n\nmongoimport --db test --collection ra --drop --file ./ra.json\n\nOkazuje się, że niestety mamy tylko 8006 dokumentów, a nie spodziewane 15000.\n\n2021-02-17T22:59:19.216+0100\tconnected to: mongodb://localhost/\n2021-02-17T22:59:19.217+0100\tdropping: test.ra\n2021-02-17T22:59:20.234+0100\t8006 document(s) imported successfully. 0 document(s) failed to import.\n\n\nDla 10,000 mamy poprawny wynik zarówno pobierania\n\nhttp -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=1\\&size\\=10000\\&sortField\\=originId\\&sortDirection\\=ASC | jq '.[][]' > ra.json\n\njak i importu\n\nmongoimport --db test --collection ra --drop --file ./ra.json\n                                                                                            \n2021-02-17T23:02:11.893+0100\tconnected to: mongodb://localhost/\n2021-02-17T23:02:11.894+0100\tdropping: test.ra\n2021-02-17T23:02:13.143+0100\t10000 document(s) imported successfully. 0 document(s) failed to import.\n\n\nWażne, że przy pobieraniu drugiej strony dopisujemy do pliku >> a nie\nnadpisujemy jego zawartość >.\n\nhttp -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=2\\&size\\=10000\\&sortField\\=originId\\&sortDirection\\=ASC | jq '.[][]' >> ra.json\n\nTym razem zapis daje 13006 plików i wszystko wyjaśnia się.\n\nmongoimport --db test --collection ra --drop --file ./ra.json\n                                                                                            \n2021-02-17T23:03:43.592+0100\tconnected to: mongodb://localhost/\n2021-02-17T23:03:43.592+0100\tdropping: test.ra\n2021-02-17T23:03:45.173+0100\t13006 document(s) imported successfully. 0 document(s) failed to import.\n\nWynik 8006 przy size=15000 wynikał z tego, że strony numerują się od 0 w tym api \ni 8006 = 23006 - 15000, co było poprawnym wynikiem.\n\nTak czy siak nie ważne czy pobieramy po 10 czy po 15 tysięcy został nam jeden\nrequest z page=0 np.:\n\nhttp -b https://rejestrymedyczne.ezdrowie.gov.pl/api/pharmacies/search\\?page\\=0\\&size\\=10000\\&sortField\\=originId\\&sortDirection\\=ASC | jq '.[][]' >> ra.json\n\nOstatni import pozwala nam wgrać wszystkie apteki.\n\nmongoimport --db test --collection ra --drop --file ./ra.json\n\n2021-02-17T23:08:02.038+0100\tconnected to: mongodb://localhost/\n2021-02-17T23:08:02.038+0100\tdropping: test.ra\n2021-02-17T23:08:04.808+0100\t23006 document(s) imported successfully. 0 document(s) failed to import.\n\n\nW compass możemy zaprojektować agregację z dwoma etapami:\n\n 1. Zdjęcie tablicy z owners\n\n{\n    '$unwind': {\n      'path': '$owners'\n    }\n}\n\n2. Projekcja najbardziej interesujących pól\n\n{\n    '$project': {\n      'name': '$owners.name', \n      'firstName': '$owners.firstName', \n      'lastName': '$owners.lastName', \n      'krs': '$owners.krs', \n      'nip': '$owners.nip', \n      'regon': '$owners.regon', \n      'address': {\n        '$concat': [\n          '$address.street', ' ', '$address.homeNumber', ', ', '$address.postcode', ' ', '$address.city'\n        ]\n      }\n    }\n}\n\nPozwoli nam to na wygenerowanie kodu programu\n\nconst MongoClient = require('mongodb').MongoClient;\nconst assert = require('assert');\n\n/*\n * Requires the MongoDB Node.js Driver\n * https://mongodb.github.io/node-mongodb-native\n */\n\nconst agg = [\n  {\n    '$unwind': {\n      'path': '$owners'\n    }\n  }, {\n    '$project': {\n      'name': '$owners.name', \n      'firstName': '$owners.firstName', \n      'lastName': '$owners.lastName', \n      'krs': '$owners.krs', \n      'nip': '$owners.nip', \n      'regon': '$owners.regon', \n      'address': {\n        '$concat': [\n          '$address.street', ' ', '$address.homeNumber', ', ', '$address.postcode', ' ', '$address.city'\n        ]\n      }\n    }\n  }\n];\n\nMongoClient.connect(\n  'mongodb://localhost:27017/?readPreference=primary&appname=MongoDB%20Compass&ssl=false',\n  { useNewUrlParser: true, useUnifiedTopology: true },\n  function(connectErr, client) {\n    assert.equal(null, connectErr);\n    const coll = client.db('test').collection('ra');\n    coll.aggregate(agg, (cmdErr, result) => {\n      assert.equal(null, cmdErr);\n    });\n    client.close();\n  });\n\nAby go włączyć musimy zainstalować sterowniki do mongo oraz assert.\n\n npm init -y && npm i mongodb@3.6.3 assert\n\nWersja @3.6.3 wynika z występowania błędu z brakującym MongoError w wersji 3.6.4\n.\n\nWarning: Accessing non-existent property ‘MongoError’ of module exports inside\ncircular dependencyHi, I am getting a warning consistently each time our\nwebserver or another process connects to the DB. (node:24990) Warning:\nAccessing\nnon-existent property ‘MongoError’ of module exports inside circular dependency\nat emitCircularRequireWarning (internal/modules/cjs/loader.js:650:11) at Ob…\nMongoDB Developer Community ForumsLaurens\n[https://developer.mongodb.com/community/forums/t/warning-accessing-non-existent-property-mongoerror-of-module-exports-inside-circular-dependency/15411]\nTen zaprezentowany kod poza wykonaniem agregacji nic nie robi. Jeśli wynik\nagregacji chcieli byśmy zapisać do pliku należy go delikatnie zmodyfikować\ndodając na początku niezbędny import\n\nconst fs = require('fs')\n\ni zmieniając callback na taki, który faktycznie zapisuje wynik.\n\nMongoClient.connect(\n    'mongodb://localhost:27017/?readPreference=primary&appname=MongoDB%20Compass&ssl=false',\n    { useNewUrlParser: true, useUnifiedTopology: true },\n    function(connectErr, client) {\n      assert.strictEqual(null, connectErr);\n      const coll = client.db('test').collection('ra');\n      coll.aggregate(agg, async (cmdErr, result) => {\n        assert.strictEqual(null, cmdErr);\n          const out = await result.toArray();\n          fs.writeFileSync('ra-project.json', JSON.stringify(out));\n          return client.close();\n      });\n    });\n\nOkazuje się, że najciekawsze dane to około 10% tych które pobraliśmy.\n\ndu -h ra*json\n50M\tra.json\n4.8M\tra-project.json\n\nTen wpis pokazuje jak bardzo łatwo jest wykonywać scraping wykorzystując api\nprzygotowane przez twórców stron.\n\nNiestety nie wszystkie rejestry z tego serwisu są tak łatwe w pobraniu. Jednym z\ntrudniejszych jest rejestr diagnostów medycznych. Tutaj jednak trudność polega\nna tym, że nawet człowiek nie może dostać się do części danych prezentowanych w\ntym rejestrze z powodu błędów w kodzie strony. \n\nPodsumowanie\nPokazaliśmy jak korzystając z konsoli przeglądarki wykryć żądania do api oraz\njak wykorzystać je do scrapingu danych. Następnie włożyliśmy dane do mongodb i\ndzięki agregacji wygenerowaliśmy 10 razy lżejszy zbiór danych zawierający\njedynie najciekawsze informacje.\n\nW tym projekcie kodu jest tak mało, że nie powstało do niego repozytorium. Dane\nmożna pobrać z linków\n\nWszystkie dane:\n\n> https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/ra.json\nTylko KRS, NIP, REGON, ADRES, IMIĘ, NAZWISKO, NAZWA\n\n> https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/ra-project.json\nJeśli chesz rzucić mi wyzwanie i zaproponować stronę, którą warto zescrapować,\nnie miej oporów przed umówieniem niezobowiązującej bezpłatnej konsultacji\n\nDaniel GustawWelcome to my scheduling page. Please follow the instructions to\nadd an event to my calendar.Calendly [https://calendly.com/gustaw-daniel]",
            "feature_image": "__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-18-00-24-51.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-02-17T21:26:50.000Z",
            "updated_at": "2021-02-17T23:27:35.000Z",
            "published_at": "2021-02-17T23:25:12.000Z",
            "custom_excerpt": "Administratorzy danych go nienawidzą. Zobacz jak wpisując dwa polecenia w konsolę pobrał rejestr wszystkich aptek w Polsce.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "6038c0b18e39617ce723d820",
            "uuid": "20bad843-8a61-4c40-b4c3-bd356549ee45",
            "title": "Wyznaczenie różnicy plików JSON",
            "slug": "wyznaczenie-roznicy-plikow-json",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"node json-diff.js src/locales/en_old.json src/locales/en.json\",\"language\":\"bash\"}],[\"code\",{\"code\":\"const fs = require('fs')\\n\\nconst pathBase = `${process.cwd()}/${process.argv[2]}`;\\nconst pathComp = `${process.cwd()}/${process.argv[3]}`;\\n\\nif(!fs.existsSync(pathBase)) {\\n  console.error(`File ${pathBase} not existst`);\\n  process.exit()\\n}\\n\\nif(!fs.existsSync(pathComp)) {\\n  console.error(`File ${pathComp} not existst`);\\n  process.exit()\\n}\\n\",\"language\":\"js\"}],[\"code\",{\"code\":\"const base = JSON.parse(fs.readFileSync(pathBase).toString());\\nconst comp = JSON.parse(fs.readFileSync(pathComp).toString());\",\"language\":\"js\"}],[\"code\",{\"code\":\"function getDiff(a, b) {\\n  const res = {};\\n\\n  for (let key in a) {\\n    if(a.hasOwnProperty(key)) {\\n      if(!b.hasOwnProperty(key)) {\\n        res[key] = a[key]\\n      } else {\\n        if (typeof a[key] === 'object') {\\n          res[key] = getDiff(a[key], b[key])\\n        }\\n      }\\n      if(res[key] && !Object.keys(res[key]).length) {\\n        delete res[key];\\n      }\\n    }\\n  }\\n\\n  return res;\\n}\",\"language\":\"js\"}],[\"code\",{\"code\":\"process.stdout.write(JSON.stringify(getDiff(base, comp)))\",\"language\":\"js\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://stackoverflow.com/questions/31930041/using-jq-or-alternative-command-line-tools-to-compare-json-files\",\"metadata\":{\"url\":\"https://stackoverflow.com/questions/31930041/using-jq-or-alternative-command-line-tools-to-compare-json-files\",\"title\":\"Using jq or alternative command line tools to compare JSON files\",\"description\":\"Are there any command line utilities that can be used to find if two JSON files are identical with invariance to within-dictionary-key and within-list-element ordering? Could this be done with jq or\",\"author\":\"Amelio Vazquez-Reina\",\"publisher\":\"Stack Overflow\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded\",\"icon\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-26-11-10-41.png\",\"width\":1245,\"height\":899,\"caption\":\"https://codeshack.io/json-sorter/\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-26-11-06-53.png\",\"width\":1562,\"height\":694,\"caption\":\"https://www.diffchecker.com/yffDMWff\",\"cardWidth\":\"wide\"}],[\"code\",{\"code\":\"node ../DevTools/json-diff.js src/locales/en_old.json src/locales/en.json > src/locales/en-codes.json\",\"language\":\"bash\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-26-11-07-12.png\",\"width\":953,\"height\":579,\"cardWidth\":\"wide\"}],[\"code\",{\"code\":\"import Vue from 'vue'\\nimport VueI18n from 'vue-i18n'\\nimport deepmerge from 'deepmerge'\\n\\nimport en from 'vuetify/lib/locale/en'\\nimport pl from 'vuetify/lib/locale/pl'\\n\\nVue.use(VueI18n);\\n\\nconst messages = {\\n  en: deepmerge(\\n    require('@/locales/en-codes.json'),\\n    require('@/locales/en.json'),\\n    {$vuetify: en}\\n  ),\\n  pl: deepmerge(\\n    require('@/locales/pl-codes.json'),\\n    require('@/locales/pl.json'),\\n    {$vuetify: pl}\\n  ),\\n};\\n\\nexport default new VueI18n({\\n  locale: process.env.VUE_APP_I18N_LOCALE || 'en',\\n  fallbackLocale: process.env.VUE_APP_I18N_FALLBACK_LOCALE || 'en',\\n  messages,\\n})\\n\\nexport const languages = [\\n  { text: 'lang.pl', value: 'pl' },\\n  { text: 'lang.en', value: 'en' },\\n];\",\"language\":\"js\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.i18next.com/\",\"metadata\":{\"url\":\"https://www.i18next.com\",\"title\":\"Introduction\",\"description\":null,\"author\":null,\"publisher\":\"i18next documentation\",\"thumbnail\":\"https://app.gitbook.com/share/space/thumbnail/-L9iS6Wm2hynS5H9Gj7j.png\",\"icon\":\"https://gblobscdn.gitbook.com/spaces%2F-L9iS6Wm2hynS5H9Gj7j%2Favatar.png?alt=media\"}}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"W tym artykule pokażemy jak napisać funkcję do wyznaczenia różnicy między dwoma plikami JSON. \"]]],[1,\"p\",[[0,[],0,\"Z edukacyjnego punktu widzenia jest to świetny przykład zastosowania funkcji rekurencyjnej. Z praktycznego jest to przydatne narzędzie do pracy z tłumaczeniami.\"]]],[1,\"p\",[[0,[],0,\"Skryptu będziemy używali z poziomu linii komend:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Po takiej komendzie będziemy spodziewać się, że pliki zostaną odczytane i wszystkie klucze, które występują w pierwszym pliku, ale nie ma ich w drugim pliku, zostaną wypisane na standardowym wyjściu.\"]]],[1,\"p\",[[0,[],0,\"Pokażemy teraz kod źródłowy pliku \"],[0,[0],1,\"json-diff.js\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od sprawdzenia czy pliki wskazane jako argumenty istnieją:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Następnie odczytujemy zawartość tych plików i konwertujemy JSON do obiektów\"]]],[10,2],[1,\"p\",[[0,[],0,\"Teraz piszemy funkcję do znajdowania różnic\"]]],[10,3],[1,\"p\",[[0,[],0,\"Jej zadaniem jest przyjęcie pary obiektów, i przejście po kluczach pierwszego z nich (bazowego). Jeśli drugi obiekt (odejmowany) jej nie posiada to ten klucz należy włożyć do wyniku.\"]]],[1,\"p\",[[0,[],0,\"W przeciwnym wypadku należy sprawdzić, czy typ nie jest obiektem. Wówczas może się okazać, że należy wykonać sprawdzenie wewnątrz tego klucza. \"]]],[1,\"p\",[[0,[],0,\"Tu mamy kluczową linię - użycie funkcji \"],[0,[0],1,\"getDiff\"],[0,[],0,\" wewnątrz niej samej.\"]]],[1,\"p\",[[0,[],0,\"Na końcu kasujemy te klucze dla których wartością jest pusty obiekt.\"]]],[1,\"p\",[[0,[],0,\"Ostatnią linią programu jest wypisanie wyników na ekranie\"]]],[10,4],[1,\"p\",[[0,[],0,\"Ten program nie obsługuje tablic. W przypadku plików z tłumaczeniami nie są potrzebne. Jeśli chcesz poczytać o bardziej zaawansowanych metodach porównywania plików JSON dobrym punktem startu jest wątek na stack overflow.\"]]],[10,5],[1,\"p\",[[0,[],0,\"Zobaczmy teraz jak program działa w praktyce. Na plikach z tłumaczeniami. Pierwszy plik jest przygotowany ręcznie i pokrywa wszystkie tłumaczenia w aplikacji \"],[0,[0],1,\"en_old.json\"],[0,[],0,\", drugi jest wygenerowany przez \"],[0,[0],1,\"i18next\"],[0,[],0,\" nazywa się \"],[0,[0],1,\"en.json\"],[0,[],0,\". Problem stanowi to, że \"],[0,[0],1,\"i18next\"],[0,[],0,\" nie wykrył wszystkich tłumaczeń.\"]]],[1,\"p\",[[0,[],0,\"Na początku wykonałem pracę ręcznie. Posortowałem oba pliki w serwisie: \"],[0,[0],1,\"codeshack.io/json-sorter\"]]],[10,6],[1,\"p\",[[0,[],0,\"Następnie w serwisie \"],[0,[0],1,\"diffchecker\"],[0,[],0,\" wyznaczyłem różnice między \"]]],[10,7],[1,\"p\",[[0,[],0,\"Teraz utworzyłem pik z brakującymi tłumaczeniami\"]]],[10,8],[1,\"p\",[[0,[],0,\"Plik wyświetlony i formatowany przez \"],[0,[0],1,\"jq\"],[0,[],0,\" wygląda tak:\"]]],[10,9],[1,\"p\",[[0,[],0,\"Widzimy, że zawiera wszystkie brakujące klucze.\"]]],[1,\"p\",[[0,[],0,\"Importując pliki z tłumaczeniami możemy użyć paczki \"],[0,[0],1,\"deepmerge\"],[0,[],0,\". Plik z konfiguracją \"],[0,[0],1,\"i18n\"],[0,[],0,\" mógł by wyglądać na przykład tak:\"]]],[10,10],[1,\"p\",[[0,[],0,\"Jeśli chcesz wymienić doświadczenia związane z automatyzacją pracy z tłumaczeniami zapraszam do komentowania. Chętnie dowiem się jakich narzędzi używacie i czy też czasami piszecie własne pomocnicze skrypty czy polecacie jakiś zestaw narzędzi jak\"]]],[10,11],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "html": "<p>W tym artykule pokażemy jak napisać funkcję do wyznaczenia różnicy między dwoma plikami JSON. </p><p>Z edukacyjnego punktu widzenia jest to świetny przykład zastosowania funkcji rekurencyjnej. Z praktycznego jest to przydatne narzędzie do pracy z tłumaczeniami.</p><p>Skryptu będziemy używali z poziomu linii komend:</p><pre><code class=\"language-bash\">node json-diff.js src/locales/en_old.json src/locales/en.json</code></pre><p>Po takiej komendzie będziemy spodziewać się, że pliki zostaną odczytane i wszystkie klucze, które występują w pierwszym pliku, ale nie ma ich w drugim pliku, zostaną wypisane na standardowym wyjściu.</p><p>Pokażemy teraz kod źródłowy pliku <code>json-diff.js</code>.</p><p>Zaczniemy od sprawdzenia czy pliki wskazane jako argumenty istnieją:</p><pre><code class=\"language-js\">const fs = require('fs')\n\nconst pathBase = `${process.cwd()}/${process.argv[2]}`;\nconst pathComp = `${process.cwd()}/${process.argv[3]}`;\n\nif(!fs.existsSync(pathBase)) {\n  console.error(`File ${pathBase} not existst`);\n  process.exit()\n}\n\nif(!fs.existsSync(pathComp)) {\n  console.error(`File ${pathComp} not existst`);\n  process.exit()\n}\n</code></pre><p>Następnie odczytujemy zawartość tych plików i konwertujemy JSON do obiektów</p><pre><code class=\"language-js\">const base = JSON.parse(fs.readFileSync(pathBase).toString());\nconst comp = JSON.parse(fs.readFileSync(pathComp).toString());</code></pre><p>Teraz piszemy funkcję do znajdowania różnic</p><pre><code class=\"language-js\">function getDiff(a, b) {\n  const res = {};\n\n  for (let key in a) {\n    if(a.hasOwnProperty(key)) {\n      if(!b.hasOwnProperty(key)) {\n        res[key] = a[key]\n      } else {\n        if (typeof a[key] === 'object') {\n          res[key] = getDiff(a[key], b[key])\n        }\n      }\n      if(res[key] &amp;&amp; !Object.keys(res[key]).length) {\n        delete res[key];\n      }\n    }\n  }\n\n  return res;\n}</code></pre><p>Jej zadaniem jest przyjęcie pary obiektów, i przejście po kluczach pierwszego z nich (bazowego). Jeśli drugi obiekt (odejmowany) jej nie posiada to ten klucz należy włożyć do wyniku.</p><p>W przeciwnym wypadku należy sprawdzić, czy typ nie jest obiektem. Wówczas może się okazać, że należy wykonać sprawdzenie wewnątrz tego klucza. </p><p>Tu mamy kluczową linię - użycie funkcji <code>getDiff</code> wewnątrz niej samej.</p><p>Na końcu kasujemy te klucze dla których wartością jest pusty obiekt.</p><p>Ostatnią linią programu jest wypisanie wyników na ekranie</p><pre><code class=\"language-js\">process.stdout.write(JSON.stringify(getDiff(base, comp)))</code></pre><p>Ten program nie obsługuje tablic. W przypadku plików z tłumaczeniami nie są potrzebne. Jeśli chcesz poczytać o bardziej zaawansowanych metodach porównywania plików JSON dobrym punktem startu jest wątek na stack overflow.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://stackoverflow.com/questions/31930041/using-jq-or-alternative-command-line-tools-to-compare-json-files\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Using jq or alternative command line tools to compare JSON files</div><div class=\"kg-bookmark-description\">Are there any command line utilities that can be used to find if two JSON files are identical with invariance to within-dictionary-key and within-list-element ordering? Could this be done with jq or</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v&#x3D;c78bd457575a\"><span class=\"kg-bookmark-author\">Stack Overflow</span><span class=\"kg-bookmark-publisher\">Amelio Vazquez-Reina</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v&#x3D;73d79a89bded\"></div></a></figure><p>Zobaczmy teraz jak program działa w praktyce. Na plikach z tłumaczeniami. Pierwszy plik jest przygotowany ręcznie i pokrywa wszystkie tłumaczenia w aplikacji <code>en_old.json</code>, drugi jest wygenerowany przez <code>i18next</code> nazywa się <code>en.json</code>. Problem stanowi to, że <code>i18next</code> nie wykrył wszystkich tłumaczeń.</p><p>Na początku wykonałem pracę ręcznie. Posortowałem oba pliki w serwisie: <code>codeshack.io/json-sorter</code></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-26-11-10-41.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1245\" height=\"899\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-26-11-10-41.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-26-11-10-41.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-26-11-10-41.png 1245w\" sizes=\"(min-width: 720px) 720px\"><figcaption>https://codeshack.io/json-sorter/</figcaption></figure><p>Następnie w serwisie <code>diffchecker</code> wyznaczyłem różnice między </p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-26-11-06-53.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1562\" height=\"694\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-26-11-06-53.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-from-2021-02-26-11-06-53.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-26-11-06-53.png 1562w\" sizes=\"(min-width: 1200px) 1200px\"><figcaption>https://www.diffchecker.com/yffDMWff</figcaption></figure><p>Teraz utworzyłem pik z brakującymi tłumaczeniami</p><pre><code class=\"language-bash\">node ../DevTools/json-diff.js src/locales/en_old.json src/locales/en.json &gt; src/locales/en-codes.json</code></pre><p>Plik wyświetlony i formatowany przez <code>jq</code> wygląda tak:</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-26-11-07-12.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"953\" height=\"579\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-from-2021-02-26-11-07-12.png 600w, __GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-26-11-07-12.png 953w\"></figure><p>Widzimy, że zawiera wszystkie brakujące klucze.</p><p>Importując pliki z tłumaczeniami możemy użyć paczki <code>deepmerge</code>. Plik z konfiguracją <code>i18n</code> mógł by wyglądać na przykład tak:</p><pre><code class=\"language-js\">import Vue from 'vue'\nimport VueI18n from 'vue-i18n'\nimport deepmerge from 'deepmerge'\n\nimport en from 'vuetify/lib/locale/en'\nimport pl from 'vuetify/lib/locale/pl'\n\nVue.use(VueI18n);\n\nconst messages = {\n  en: deepmerge(\n    require('@/locales/en-codes.json'),\n    require('@/locales/en.json'),\n    {$vuetify: en}\n  ),\n  pl: deepmerge(\n    require('@/locales/pl-codes.json'),\n    require('@/locales/pl.json'),\n    {$vuetify: pl}\n  ),\n};\n\nexport default new VueI18n({\n  locale: process.env.VUE_APP_I18N_LOCALE || 'en',\n  fallbackLocale: process.env.VUE_APP_I18N_FALLBACK_LOCALE || 'en',\n  messages,\n})\n\nexport const languages = [\n  { text: 'lang.pl', value: 'pl' },\n  { text: 'lang.en', value: 'en' },\n];</code></pre><p>Jeśli chcesz wymienić doświadczenia związane z automatyzacją pracy z tłumaczeniami zapraszam do komentowania. Chętnie dowiem się jakich narzędzi używacie i czy też czasami piszecie własne pomocnicze skrypty czy polecacie jakiś zestaw narzędzi jak</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.i18next.com/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Introduction</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://gblobscdn.gitbook.com/spaces%2F-L9iS6Wm2hynS5H9Gj7j%2Favatar.png?alt&#x3D;media\"><span class=\"kg-bookmark-author\">i18next documentation</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://app.gitbook.com/share/space/thumbnail/-L9iS6Wm2hynS5H9Gj7j.png\"></div></a></figure>",
            "comment_id": "6038c0b18e39617ce723d820",
            "plaintext": "W tym artykule pokażemy jak napisać funkcję do wyznaczenia różnicy między dwoma\nplikami JSON. \n\nZ edukacyjnego punktu widzenia jest to świetny przykład zastosowania funkcji\nrekurencyjnej. Z praktycznego jest to przydatne narzędzie do pracy z\ntłumaczeniami.\n\nSkryptu będziemy używali z poziomu linii komend:\n\nnode json-diff.js src/locales/en_old.json src/locales/en.json\n\nPo takiej komendzie będziemy spodziewać się, że pliki zostaną odczytane i\nwszystkie klucze, które występują w pierwszym pliku, ale nie ma ich w drugim\npliku, zostaną wypisane na standardowym wyjściu.\n\nPokażemy teraz kod źródłowy pliku json-diff.js.\n\nZaczniemy od sprawdzenia czy pliki wskazane jako argumenty istnieją:\n\nconst fs = require('fs')\n\nconst pathBase = `${process.cwd()}/${process.argv[2]}`;\nconst pathComp = `${process.cwd()}/${process.argv[3]}`;\n\nif(!fs.existsSync(pathBase)) {\n  console.error(`File ${pathBase} not existst`);\n  process.exit()\n}\n\nif(!fs.existsSync(pathComp)) {\n  console.error(`File ${pathComp} not existst`);\n  process.exit()\n}\n\n\nNastępnie odczytujemy zawartość tych plików i konwertujemy JSON do obiektów\n\nconst base = JSON.parse(fs.readFileSync(pathBase).toString());\nconst comp = JSON.parse(fs.readFileSync(pathComp).toString());\n\nTeraz piszemy funkcję do znajdowania różnic\n\nfunction getDiff(a, b) {\n  const res = {};\n\n  for (let key in a) {\n    if(a.hasOwnProperty(key)) {\n      if(!b.hasOwnProperty(key)) {\n        res[key] = a[key]\n      } else {\n        if (typeof a[key] === 'object') {\n          res[key] = getDiff(a[key], b[key])\n        }\n      }\n      if(res[key] && !Object.keys(res[key]).length) {\n        delete res[key];\n      }\n    }\n  }\n\n  return res;\n}\n\nJej zadaniem jest przyjęcie pary obiektów, i przejście po kluczach pierwszego z\nnich (bazowego). Jeśli drugi obiekt (odejmowany) jej nie posiada to ten klucz\nnależy włożyć do wyniku.\n\nW przeciwnym wypadku należy sprawdzić, czy typ nie jest obiektem. Wówczas może\nsię okazać, że należy wykonać sprawdzenie wewnątrz tego klucza. \n\nTu mamy kluczową linię - użycie funkcji getDiff wewnątrz niej samej.\n\nNa końcu kasujemy te klucze dla których wartością jest pusty obiekt.\n\nOstatnią linią programu jest wypisanie wyników na ekranie\n\nprocess.stdout.write(JSON.stringify(getDiff(base, comp)))\n\nTen program nie obsługuje tablic. W przypadku plików z tłumaczeniami nie są\npotrzebne. Jeśli chcesz poczytać o bardziej zaawansowanych metodach porównywania\nplików JSON dobrym punktem startu jest wątek na stack overflow.\n\nUsing jq or alternative command line tools to compare JSON filesAre there any\ncommand line utilities that can be used to find if two JSON files are identical\nwith invariance to within-dictionary-key and within-list-element ordering?\nCould\nthis be done with jq orStack OverflowAmelio Vazquez-Reina\n[https://stackoverflow.com/questions/31930041/using-jq-or-alternative-command-line-tools-to-compare-json-files]\nZobaczmy teraz jak program działa w praktyce. Na plikach z tłumaczeniami.\nPierwszy plik jest przygotowany ręcznie i pokrywa wszystkie tłumaczenia w\naplikacji en_old.json, drugi jest wygenerowany przez i18next nazywa się en.json.\nProblem stanowi to, że i18next nie wykrył wszystkich tłumaczeń.\n\nNa początku wykonałem pracę ręcznie. Posortowałem oba pliki w serwisie: \ncodeshack.io/json-sorter\n\nhttps://codeshack.io/json-sorter/Następnie w serwisie diffchecker wyznaczyłem różnice między \n\nhttps://www.diffchecker.com/yffDMWffTeraz utworzyłem pik z brakującymi\ntłumaczeniami\n\nnode ../DevTools/json-diff.js src/locales/en_old.json src/locales/en.json > src/locales/en-codes.json\n\nPlik wyświetlony i formatowany przez jq wygląda tak:\n\nWidzimy, że zawiera wszystkie brakujące klucze.\n\nImportując pliki z tłumaczeniami możemy użyć paczki deepmerge. Plik z\nkonfiguracją i18n mógł by wyglądać na przykład tak:\n\nimport Vue from 'vue'\nimport VueI18n from 'vue-i18n'\nimport deepmerge from 'deepmerge'\n\nimport en from 'vuetify/lib/locale/en'\nimport pl from 'vuetify/lib/locale/pl'\n\nVue.use(VueI18n);\n\nconst messages = {\n  en: deepmerge(\n    require('@/locales/en-codes.json'),\n    require('@/locales/en.json'),\n    {$vuetify: en}\n  ),\n  pl: deepmerge(\n    require('@/locales/pl-codes.json'),\n    require('@/locales/pl.json'),\n    {$vuetify: pl}\n  ),\n};\n\nexport default new VueI18n({\n  locale: process.env.VUE_APP_I18N_LOCALE || 'en',\n  fallbackLocale: process.env.VUE_APP_I18N_FALLBACK_LOCALE || 'en',\n  messages,\n})\n\nexport const languages = [\n  { text: 'lang.pl', value: 'pl' },\n  { text: 'lang.en', value: 'en' },\n];\n\nJeśli chcesz wymienić doświadczenia związane z automatyzacją pracy z\ntłumaczeniami zapraszam do komentowania. Chętnie dowiem się jakich narzędzi\nużywacie i czy też czasami piszecie własne pomocnicze skrypty czy polecacie\njakiś zestaw narzędzi jak\n\nIntroductioni18next documentation [https://www.i18next.com/]",
            "feature_image": "__GHOST_URL__/content/images/2021/02/Screenshot-from-2021-02-26-11-06-53-1.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-02-26T09:34:41.000Z",
            "updated_at": "2021-02-26T10:31:42.000Z",
            "published_at": "2021-02-26T10:21:21.000Z",
            "custom_excerpt": "Zobacz jak wyznaczyć różnicę między dwoma plikami JSON. Jest to świetny przykład zastosowania funkcji rekurencyjnej.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "603a4b758e39617ce723d8e6",
            "uuid": "0056b5ac-6179-4c41-aa80-45a44c78762c",
            "title": "Ile rodzin zmieści się w samolocie - zadanie z algorytmiki",
            "slug": "ile-rodzin-zmiesci-sie-w-samolocie",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-15-46-33.png\",\"width\":668,\"height\":672}],[\"code\",{\"code\":\"S=1A 3C 2B 40G 5A\"}],[\"code\",{\"code\":\"const S = \\\"1A 2F 1C\\\"\\nconst N = 2;\"}],[\"hr\",{}],[\"code\",{\"code\":\"function solution(N, S) {\\n  const seatNames = {\\n    'A': 0,\\n    'B': 1,\\n    'C': 2,\\n    'D': 3,\\n    'E': 4,\\n    'F': 5,\\n    'G': 6,\\n    'H': 7,\\n    'J': 8,\\n    'K': 9\\n  }\\n  const freeSeats = Array.from({length: N}, () => Array.from({length: 10}, () => true))\\n  const reservedSeats = S.split(' ');\\n  reservedSeats.forEach(s => {\\n    try {\\n      freeSeats[parseInt(s.substring(0, s.length - 1)) - 1][seatNames[s[s.length - 1]]] = false;\\n    } catch (e) {\\n      console.log('Some error @ reserved seat marked: ', s)\\n    }\\n  })\\n\\n  let free3seats = 0\\n  freeSeats.forEach(rs => {\\n    if (rs[0] && rs[1] && rs[2]) free3seats++;\\n    if ((rs[3] && rs[4] && rs[5]) || (rs[4] && rs[5] && rs[6])) free3seats++;\\n    if (rs[7] && rs[8] && rs[9]) free3seats++;\\n  })\\n\\n  return free3seats\\n}\\n\\nmodule.exports = {solution};\",\"language\":\"javascript\"}],[\"code\",{\"code\":\"// DOCS\\n// slot 1 = empty\\n// slot 0 = taken\\n// slot \\\"r\\\" = taken from right\\n// slot \\\"l\\\" = taken from left\\n\\nfunction markCorner(slots, nr, side) {\\n  if (slots[(nr - 1) * 3 + 1] === 1) slots[(nr - 1) * 3 + 1] = side;\\n  else if (slots[(nr - 1) * 3 + 1] === (side === 'l' ? 'r' : 'l')) slots[(nr - 1) * 3 + 1] = 0;\\n}\\n\\nfunction solution(N, S) {\\n  const slots = [...new Array(3 * N)].map(() => 1);\\n  const places = S.split(' ');\\n  while (places.length) {\\n    const place = places.shift();\\n    const nr = place.slice(0, -1);\\n    const letter = place.charAt(place.length - 1);\\n\\n    if (['A', 'B', 'C'].includes(letter)) {\\n      slots[(nr - 1) * 3] = 0;\\n    }\\n\\n    if (['H', 'J', 'K'].includes(letter)) {\\n      slots[(nr - 1) * 3 + 2] = 0;\\n    }\\n\\n    if (['E', 'F'].includes(letter)) {\\n      slots[(nr - 1) * 3 + 1] = 0;\\n    }\\n\\n    if (['D'].includes(letter)) {\\n      markCorner(slots, nr, 'l');\\n    }\\n\\n    if (['G'].includes(letter)) {\\n      markCorner(slots, nr, 'r');\\n    }\\n  }\\n\\n  return slots.reduce((p, n) => p + Boolean(n), 0);\\n}\\n\\nmodule.exports = {solution};\",\"language\":\"javascript\"}],[\"code\",{\"code\":\"const fs = require('fs');\\n\\nfunction letter() {\\n  return ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K'][Math.floor(Math.random() * 10)];\\n}\\n\\nfunction row(N) {\\n  return Math.floor(Math.random() * N + 1);\\n}\\n\\nfunction tempPath(N, M) {\\n  return `/tmp/.cache.generate-places-${N},${M}.log`;\\n}\\n\\n// '1A 3C 2B 40G 5A'\\nfunction generatePlaces(N, M) {\\n  if (fs.existsSync(tempPath(N, M))) {\\n    return fs.readFileSync(tempPath(N, M)).toString();\\n  }\\n\\n  let res = [];\\n  while (res.length < M) {\\n    const n = `${row(N)}${letter()}`;\\n    if (!res.includes(n)) {\\n      res.push(n);\\n    }\\n  }\\n  const out = res.join(' ');\\n\\n  fs.writeFileSync(tempPath(N, M), out);\\n\\n  return out;\\n}\\n\\nmodule.exports = generatePlaces;\\n\"}],[\"code\",{\"code\":\"const d = require('./d');\\nconst m = require('./m');\\nconst generatePlaces = require('./generatePlaces');\\n\\nif (process.argv.length !== 4) {\\n  throw new Error('Type `node test.js N M`');\\n}\\n\\nconst N = parseInt(process.argv[2]) || 50;\\nconst M = parseInt(process.argv[3]) || 10;\\n\\nconst params = [N, generatePlaces(N, M)];\\n\\nconsole.time('m');\\nconst endM = m.solution(...params);\\nconsole.timeEnd('m');\\n\\nconsole.time('d');\\nconst endD = d.solution(...params);\\nconsole.timeEnd('d');\\n\\nconsole.log(endM, endD);\\n\"}],[\"code\",{\"code\":\"time node test.js 500000 1000  \\nm: 1.339s\\nd: 151.637ms\\n\"}],[\"code\",{\"code\":\"time node test.js 500000 20000 \\nm: 1.462s\\nd: 276.517ms\\n\"}],[\"code\",{\"code\":\"time node test.js 500000 40000 \\nm: 1.386s\\nd: 606.803ms\\n\"}],[\"code\",{\"code\":\"time node test.js 500000 80000\\nm: 1.385s\\nd: 2.257s\"}],[\"code\",{\"code\":\"time node test.js 500000 100000\\nm: 1.413s\\nd: 6.656s\"}],[\"hr\",{}],[\"code\",{\"code\":\"const d = require('./d');\\n// const m = require('./m');\\nconst generatePlaces = require('./generatePlaces');\\n\\nif (process.argv.length !== 4) {\\n  throw new Error('Type `node test.js N M`');\\n}\\n\\nconst N = parseInt(process.argv[2]) || 50;\\nconst M = parseInt(process.argv[3]) || 10;\\n\\nconst params = [N, generatePlaces(N, M)];\\n\\n// console.time('m');\\n// const endM = m.solution(...params);\\n// console.timeEnd('m');\\n\\nconsole.time('d');\\nconst endD = d.solution(...params);\\nconsole.timeEnd('d');\\n\\n// console.log(endM, endD);\"}],[\"code\",{\"code\":\"time node test.js 500000 100000\\nd: 26.454s\\nnode test.js 500000 100000  26.42s user 0.08s system 99% cpu 26.524 total\\n\"}],[\"code\",{\"code\":\"time node test.js 500000 100000\\nm: 1.437s\\nnode test.js 500000 100000  1.66s user 0.09s system 115% cpu 1.515 total\\n\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-50-47.png\",\"width\":859,\"height\":560}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-41-38.png\",\"width\":1013,\"height\":749}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-45-05.png\",\"width\":863,\"height\":574}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-41-13.png\",\"width\":886,\"height\":582}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-19-02-23.png\",\"width\":320,\"height\":38}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-50-01.png\",\"width\":1095,\"height\":594}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.jetbrains.com/help/webstorm/v8-cpu-and-memory-profiling.html#ws_node_cpu_profiling\",\"metadata\":{\"url\":\"https://www.jetbrains.com/help/webstorm/2021.1/v8-cpu-and-memory-profiling.html\",\"title\":\"V8 CPU and memory profiling | WebStorm\",\"description\":null,\"author\":null,\"publisher\":\"WebStorm Help\",\"thumbnail\":\"https://resources.jetbrains.com/storage/products/webstorm/img/meta/preview.png\",\"icon\":\"https://resources.jetbrains.com/storage/ui/favicons/apple-touch-icon-180x180.png\"}}],[\"code\",{\"code\":\"const place = places.shift();\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://stackoverflow.com/questions/6501160/why-is-pop-faster-than-shift\",\"metadata\":{\"url\":\"https://stackoverflow.com/questions/6501160/why-is-pop-faster-than-shift\",\"title\":\"Why is pop faster than shift?\",\"description\":\"Douglas Crockford, in JavaScript: The Good Parts, states that “shift is usually much slower than pop”. jsPerf confirms this. Does anyone know why this is the case? From an unsophisticated point of ...\",\"author\":\"zjmiller\",\"publisher\":\"Stack Overflow\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded\",\"icon\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a\"}}],[\"code\",{\"code\":\"const place = places.shift();\"}],[\"code\",{\"code\":\"const place = places.pop();\"}],[\"code\",{\"code\":\"time node test.js 500000 100000\\nm: 1.449s\\nd: 233.327ms\\n1421226 1421226\\nnode test.js 500000 100000  1.89s user 0.13s system 114% cpu 1.768 total\\n\"}],[\"code\",{\"code\":\"time node test.js 500000 100000\\nd: 238.217ms\\nnode test.js 500000 100000  0.27s user 0.04s system 101% cpu 0.311 total\\n\"}],[\"code\",{\"code\":\"let sum;\\nconst tests = new Array(8).fill(null).map((e, i) => (i + 6) * 10000);\\n\\nconsole.log(JSON.stringify(process.versions));\\n\\ntests.forEach(function (count) {\\n  console.log('Testing arrays of size ' + count);\\n  let s1 = Date.now();\\n  let sArray = new Array(count);\\n  let pArray = new Array(count);\\n  for (let i = 0; i < count; i++) {\\n    const num = Math.floor(Math.random() * 6) + 1;\\n    sArray[i] = num;\\n    pArray[i] = num;\\n  }\\n  console.log(' -> ' + (Date.now() - s1) + 'ms: built arrays with ' + count + ' random elements');\\n\\n  s1 = Date.now();\\n  sum = 0;\\n  while (pArray.length) {\\n    sum += pArray.pop();\\n  }\\n  console.log(\\n    ' -> ' + (Date.now() - s1) + 'ms: sum with pop() ' + count + ' elements, sum = ' + sum\\n  );\\n\\n  s1 = Date.now();\\n  sum = 0;\\n  while (sArray.length) {\\n    sum += sArray.shift();\\n  }\\n  console.log(\\n    ' -> ' + (Date.now() - s1) + 'ms: sum with shift() ' + count + ' elements, sum = ' + sum\\n  );\\n});\"}],[\"code\",{\"code\":\"{\\\"node\\\":\\\"15.8.0\\\",\\\"v8\\\":\\\"8.6.395.17-node.23\\\",\\\"uv\\\":\\\"1.40.0\\\",\\\"zlib\\\":\\\"1.2.11\\\",\\\"brotli\\\":\\\"1.0.9\\\",\\\"ares\\\":\\\"1.17.1\\\",\\\"modules\\\":\\\"88\\\",\\\"nghttp2\\\":\\\"1.42.0\\\",\\\"napi\\\":\\\"7\\\",\\\"llhttp\\\":\\\"2.1.3\\\",\\\"openssl\\\":\\\"1.1.1i\\\",\\\"cldr\\\":\\\"38.1\\\",\\\"icu\\\":\\\"68.2\\\",\\\"tz\\\":\\\"2020d\\\",\\\"unicode\\\":\\\"13.0\\\"}\\nTesting arrays of size 60000\\n -> 12ms: built arrays with 60000 random elements\\n -> 5ms: sum with pop() 60000 elements, sum = 209556\\n -> 1057ms: sum with shift() 60000 elements, sum = 209556\\nTesting arrays of size 70000\\n -> 20ms: built arrays with 70000 random elements\\n -> 1ms: sum with pop() 70000 elements, sum = 244919\\n -> 1476ms: sum with shift() 70000 elements, sum = 244919\\nTesting arrays of size 80000\\n -> 5ms: built arrays with 80000 random elements\\n -> 0ms: sum with pop() 80000 elements, sum = 279502\\n -> 1993ms: sum with shift() 80000 elements, sum = 279502\\nTesting arrays of size 90000\\n -> 4ms: built arrays with 90000 random elements\\n -> 0ms: sum with pop() 90000 elements, sum = 313487\\n -> 2601ms: sum with shift() 90000 elements, sum = 313487\\nTesting arrays of size 100000\\n -> 4ms: built arrays with 100000 random elements\\n -> 1ms: sum with pop() 100000 elements, sum = 350059\\n -> 3263ms: sum with shift() 100000 elements, sum = 350059\\nTesting arrays of size 110000\\n -> 8ms: built arrays with 110000 random elements\\n -> 1ms: sum with pop() 110000 elements, sum = 384719\\n -> 4154ms: sum with shift() 110000 elements, sum = 384719\\nTesting arrays of size 120000\\n -> 7ms: built arrays with 120000 random elements\\n -> 0ms: sum with pop() 120000 elements, sum = 419326\\n -> 5027ms: sum with shift() 120000 elements, sum = 419326\\nTesting arrays of size 130000\\n -> 8ms: built arrays with 130000 random elements\\n -> 0ms: sum with pop() 130000 elements, sum = 454068\\n -> 5702ms: sum with shift() 130000 elements, sum = 454068\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-19-27-03.png\",\"width\":418,\"height\":618}],[\"code\",{\"code\":\"var sum;\\nvar res = [];\\nvar tests = new Array(20).fill(null).map((e, i) => (i + 1) * 10000);\\n\\ntests.forEach(function (count) {\\n  console.log('Testing arrays of size ' + count);\\n  let s1 = Date.now();\\n  let sArray = new Array(count);\\n  let pArray = new Array(count);\\n  for (let i = 0; i < count; i++) {\\n    const num = Math.floor(Math.random() * 6) + 1;\\n    sArray[i] = num;\\n    pArray[i] = num;\\n  }\\n  console.log(' -> ' + (Date.now() - s1) + 'ms: built arrays with ' + count + ' random elements');\\n\\n  s1 = Date.now();\\n  sum = 0;\\n  while (pArray.length) {\\n    sum += pArray.pop();\\n  }\\n  console.log(\\n    ' -> ' + (Date.now() - s1) + 'ms: sum with pop() ' + count + ' elements, sum = ' + sum\\n  );\\n\\n  s1 = Date.now();\\n  sum = 0;\\n  while (sArray.length) {\\n    sum += sArray.shift();\\n  }\\n  res.push([count, Date.now() - s1]);\\n  console.log(\\n    ' -> ' + (Date.now() - s1) + 'ms: sum with shift() ' + count + ' elements, sum = ' + sum\\n  );\\n});\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.chartjs.org/docs/latest/getting-started/\",\"metadata\":{\"url\":\"https://www.chartjs.org/docs/latest/getting-started/\",\"title\":\"Getting Started | Chart.js\",\"description\":\"Open source HTML5 Charts for your website\",\"author\":null,\"publisher\":\"Chart.js\",\"thumbnail\":\"https://www.chartjs.org/docs/latest/favicon.ico\",\"icon\":\"https://www.chartjs.org/docs/latest/favicon.ico\"}}],[\"code\",{\"code\":\"let res = [[10000,3],[20000,3],[30000,4],[40000,193],[50000,304],[60000,450],[70000,625],[80000,859],[90000,1081],[100000,1419],[110000,1704],[120000,2040],[130000,2466],[140000,2936],[150000,3429],[160000,3948],[170000,4509],[180000,5158],[190000,5852],[200000,6450]];\\n\\nconst labels = res.map(r => r[0]);\\nconst data = {\\n  labels: labels,\\n  datasets: [{\\n    label: 'Time [ms] of sum of rarray computed with shift method vs array length',\\n    backgroundColor: 'rgb(255, 99, 132)',\\n    borderColor: 'rgb(255, 99, 132)',\\n    data: res.map(r => r[1]),\\n  }]\\n};\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-19-39-16.png\",\"width\":744,\"height\":387}],[\"code\",{\"code\":\"const d = require('./d');\\nconst m = require('./m');\\nconst generatePlaces = require('./generatePlaces');\\nconst res = [];\\n\\nfunction log(res) {\\n  console.log('Daniel Results');\\n  console.table(res.map(r => r.map(r => r.d)));\\n  console.log('Marcin Results');\\n  console.table(res.map(r => r.map(r => r.m)));\\n  console.log('Rations Marcin Time to Daniel Time');\\n  console.table(res.map(r => r.map(r => r.r)));\\n}\\n\\nconst start = new Date().getTime();\\n\\nfor (let N = 250000; N < 1000000; N += 250000) {\\n  res[N] = [];\\n  for (let M = 10000; M < 150000; M += 10000) {\\n    const params = [N, generatePlaces(N, M)];\\n\\n    const sm = new Date().getTime();\\n    m.solution(...params);\\n    const em = new Date().getTime();\\n\\n    const sd = new Date().getTime();\\n    d.solution(...params);\\n    const ed = new Date().getTime();\\n    res[N][M] = {\\n      d: ed - sd,\\n      m: em - sm,\\n      r: Math.round((100 * (em - sm)) / (ed - sd)) / 100\\n    };\\n\\n    const now = new Date().getTime();\\n    console.log(now - start);\\n    log(res);\\n  }\\n}\\n\",\"language\":\"javascript\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-20-30-44.png\",\"width\":800,\"height\":409,\"cardWidth\":\"\"}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Omówimy dwa rozwiązania zadania, które stosowane było podczas pewnej rekrutacji. Jeśli potraficie pisać kod, zalecam wam samodzielne rozwiązanie po przeczytaniu treści, zajmie to około 10 do 30 minut i pozwoli Wam porównać wasze rozwiązanie z tymi prezentowanymi poniżej:\"]]],[1,\"h2\",[[0,[],0,\"Treść zadania\"]]],[1,\"p\",[[0,[],0,\"W samolocie rozmieszczone są miejsca. Tworzą one trzy zestawy zawierające kolejno 3, 4 i 3 siedzenia sąsiadujące ze sobą. Zakładamy, że wiersze liczone są od 1 a kolumny indeksowane za pomocą liter alfabetu jak w tabeli EXCEL (od A do K). Schemat samolotu przedstawia poniższy rysunek. Zakładamy, że wszystkie miejsca mają taki sam układ jak te oznaczone na niebiesko.\"]]],[10,0],[1,\"p\",[[0,[],0,\"Zakładamy, że samolot ma długość \"],[0,[0],1,\"N\"],[0,[],0,\" rzędów z miejscami. Znamy też aktualne zapełnienie miejsc, które zapisane jest w postaci ciągu znakowego \"],[0,[0],1,\"S\"],[0,[],0,\" jako oddzielone spacją współrzędne numeru wiersza i kolumny, np:\"]]],[10,1],[1,\"p\",[[0,[],0,\"oznacza zajęcie miejsc \"],[0,[0],1,\"1A\"],[0,[],0,\", \"],[0,[0],1,\"3C\"],[0,[],0,\", \"],[0,[0],1,\"2B\"],[0,[],0,\", \"],[0,[0],1,\"40G\"],[0,[],0,\" oraz \"],[0,[0],1,\"5A\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Naszym celem jest napisanie funkcji, która zliczy ile 3 osobowych rodzin wymagających zajęcia miejsc bezpośrednio obok siebie zmieści się w samolocie.\"]]],[1,\"p\",[[0,[],0,\"Na przykład dla danych:\"]]],[10,2],[1,\"p\",[[0,[],0,\"poprawnym wynikiem będzie 4.\"]]],[10,3],[1,\"p\",[[0,[],0,\"To jest najlepsze miejsce, aby wykonać to zadanie samodzielnie i porównać z prezentowanymi poniżej rozwiązaniami.\"]]],[1,\"h2\",[[0,[],0,\"Rozwiązanie Marcina\"]]],[1,\"p\",[[0,[],0,\"Pierwsze rozwiązanie wytworzył mój kolega Marcin. Ma ono krótki, czytelny kod. Rozpina dwuwymiarową tablicę wszystkich miejsc, oznacza zaznaczone wartościami \"],[0,[0],1,\"false\"],[0,[],0,\", na końcu przechodzi po rzędach doliczając wolne sloty w oparciu o stosowne kryteria dla każdego z nich.\"]]],[10,4],[1,\"h2\",[[0,[],0,\"Rozwiązanie Daniela\"]]],[1,\"p\",[[0,[],0,\"Drugie posługuje się bezpośrednio tablicą slotów, składając je w jeden wymiar. Nie stosując struktury danych o indeksowaniu analogicznym do miejsc zmuszeni jesteśmy indeks slotu wyliczać za każdym razem z rzędu oraz instrukcji warunkowych nałożonych na kolumny. Kod jest trudniejszy do czytania i wymaga kilku linii komentarzy z opisem przyjętej konwencji. Jego zaletą jest operowanie na mniejszej strukturze danych, a wadą bardziej złożone instrukcje warunkowe.\"]]],[10,5],[1,\"h2\",[[0,[],0,\"Porównanie wydajności rozwiązań\"]]],[1,\"p\",[[0,[],0,\"W celu porównania szybkości działania tych kodów dopiszemy generator współrzędnych z miejscami:\"]]],[10,6],[1,\"p\",[[0,[],0,\"Linie z \"],[0,[0],1,\"fs\"],[0,[],0,\" pozwalają nam na zapis wygenerowanej listy miejsc w cache i nie generowanie jej od nowa przy powtarzaniu testów.\"]]],[1,\"p\",[[0,[],0,\"Tworzymy też skrypt testujący szybkość działania obu algorytmów:\"]]],[10,7],[1,\"p\",[[0,[],0,\"Hipotetycznie załóżmy, że mamy bardzo długi samolot (pół miliona rzędów). Sprawdzimy po kolei przypadki prawie pustego lotu \"],[0,[0],1,\"1000\"],[0,[],0,\" zajętych miejsc. Liczba występująca po \"],[0,[0],1,\"m\"],[0,[],0,\" to czas dla rozwiązania \"],[0,[0],1,\"Marcina\"],[0,[],0,\", a po \"],[0,[0],1,\"d\"],[0,[],0,\" to czas dla \"],[0,[0],1,\"Daniela\"],[0,[],0,\".\"]]],[10,8],[1,\"p\",[[0,[],0,\"Widzimy, że rozwiązanie zliczające jedynie sloty wykrywa 8.8 raza pod względem szybkości. Dla \"],[0,[0],1,\"20k\"],[0,[],0,\" zajętych już miejsc:\"]]],[10,9],[1,\"p\",[[0,[],0,\"ta przewaga spada do 5.3 raza. Jeśli zajętych miejsc będzie \"],[0,[0],1,\"40k\"],[0,[],0,\", to wyniki będą różnić się następująco:\"]]],[10,10],[1,\"p\",[[0,[],0,\"Rozwiązanie Daniela wciąż będzie szybsze, ale tylko 2.2 razy. Dla \"],[0,[0],1,\"80k\"],[0,[],0,\" zajętych miejsc sytuacja się odwraca i rozwiązanie Marcina staje się 1.62 razy szybsze.\"]]],[10,11],[1,\"p\",[[0,[],0,\"Przy \"],[0,[0],1,\"100k\"],[0,[],0,\" miejsc skrypt Marcina osiąga już 4.7 raza lepsze wyniki\"]]],[10,12],[10,13],[1,\"h2\",[[0,[],0,\"Pułapka\"]]],[1,\"p\",[[0,[],0,\"Gdybyśmy nie zachowali ostrożności mogli byśmy uznać, że finalnym wnioskiem były by zdania: \\\"Algorytm Daniela sprawdza się lepiej przy pustym samolocie, a Marcina przy pełnym\\\" oraz \\\"Algorytm Daniela silnie zależy od ilości miejsc, a Marcina ma stabilny mniej więcej stały czas działania\\\".\"]]],[1,\"p\",[[0,[],0,\"Tak wynika z testów, ale jeśli wytniemy z pomiarów kod Marcina to dla takiego kodu testującego\"]]],[10,14],[1,\"p\",[[0,[],0,\"wynik pomiaru czasu znacznie wzrośnie:\"]]],[10,15],[1,\"p\",[[0,[],0,\"A w ten sam wyizolowany sposób testując kod Marcina dostaniemy ponownie  ten sam wynik zbliżony do półtorej sekundy\"]]],[10,16],[1,\"p\",[[0,[],0,\"Do profilowania możemy użyć flagi \"],[0,[0],1,\"--porf\"],[0,[],0,\", spowoduje ona powstanie pliku z logami o wielkości około \"],[0,[0],1,\"4MB\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Jego przeglądanie nie jest łatwe jeśli nie wie się czego szukać. Ten plik wygląda mniej więcej tak: \"]]],[10,17],[1,\"p\",[[0,[],0,\"Na szczęście Webstorm ma ciekawe narzędzia do profilowania, które pod spodem robią to samo co ta flaga, ale nakładają graficzną nakładkę i wykresy, które pozwalają na odnalezienie się w logach i szybkie dotarcie do źródła problemu. Aby skonfigurować profilowanie zaznaczamy w ustawieniach \"],[0,[0],1,\"Coding assistance for Node.js\"]]],[10,18],[1,\"p\",[[0,[],0,\"Następnie tworzymy profil, który wystartuje nasz skrypt z odpowiednimi parametrami\"]]],[10,19],[1,\"p\",[[0,[],0,\"a w zakładce \"],[0,[0],1,\"V8 Profiling\"],[0,[],0,\" zaznaczamy opcję profilowania.\"]]],[10,20],[1,\"p\",[[0,[],0,\"Po wybraniu zielonego trójkąta startującego profilowanie\"]]],[10,21],[1,\"p\",[[0,[],0,\"zobaczymy logi uporządkowane względem procentowego udziału w czasie wykonywania.\"]]],[10,22],[1,\"p\",[[0,[],0,\"Ten widok pozwala wyłowić najcięższe funkcje względem całkowitego czasu wykonywania. Więcej o profilowaniu możesz poczytać w dokumentacji WebStorms.\"]]],[10,23],[1,\"p\",[[0,[],0,\"Ponowny przegląda kodu i zestawienie logów z informacją, że to ilość zajętych miejsc tak bardzo obniża wydajność skryptu wskazują, że należy szukać problemu w funkcji \"],[0,[0],1,\"shift\"]]],[10,24],[1,\"p\",[[0,[],0,\"Poświęcono temu wątek na stack overflow\"]]],[10,25],[1,\"p\",[[0,[],0,\"Zmiana tej jednej linii\"]]],[10,26],[1,\"p\",[[0,[],0,\"na\"]]],[10,27],[1,\"p\",[[0,[],0,\"w algorytmie Daniela przywraca mu poprawne tępo działania nie zależnie od tego czy kod Marcina jest wykonywany, czy nie\"]]],[10,28],[1,\"p\",[[0,[],0,\"oraz\"]]],[10,29],[1,\"p\",[[0,[],0,\"Po delikatnej modyfikacji kodu napisanego przez \"],[0,[0],1,\"bhirt\"],[0,[],0,\" na Slack Overflow:\"]]],[10,30],[1,\"p\",[[0,[],0,\"widzimy, że najnowsza wersja \"],[0,[0],1,\"node\"],[0,[],0,\" nie naprawiła tego problemu\"]]],[10,31],[1,\"p\",[[0,[],0,\"W przeglądarce te operacje trwają dwa razy krócej ale i tak różnica między \"],[0,[0],1,\"pop\"],[0,[],0,\" a \"],[0,[0],1,\"shift\"],[0,[],0,\" jest ogromna i każde 50-100 elementów tablic dodaje milisekundę do czasu wykonywania \"],[0,[0],1,\"shift\"],[0,[],0,\".\"]]],[10,32],[1,\"p\",[[0,[],0,\"Przerabiając ten kod do testowania po raz drugi możemy uzyskać wersję, która będzie dobrze działać w przeglądarce i pozwoli na wygenerowanie danych do narysowania wykresu:\"]]],[10,33],[1,\"p\",[[0,[],0,\"Wykres zależności czasu od długości tablicy wygenerujemy w \"],[0,[0],1,\"chart.js\"]]],[10,34],[10,35],[10,36],[1,\"h2\",[[0,[],0,\"Ponowne porównanie rozwiązań\"]]],[1,\"p\",[[0,[],0,\"Oryginalnie Marcin napisał lepszy kod niż Ja. Wpadka z \"],[0,[0],1,\"shift\"],[0,[],0,\" zrujnowała cały zysk wydajnościowy z koncepcji, żeby operować na slotach, a nie poszczególnych miejscach. Jeśli jednak pozwolimy na wymianę \"],[0,[0],1,\"shift\"],[0,[],0,\" na \"],[0,[0],1,\"pop\"],[0,[],0,\" w moim kodzie (Daniela) to okazuje się on ostatecznie kilka do kilkunastu razy szybszy niż kod Marcina.\"]]],[1,\"p\",[[0,[],0,\"Za zestawienie wyników odpowiada zmodyfikowany plik \"],[0,[0],1,\"test.js\"]]],[10,37],[1,\"p\",[[0,[],0,\"Wyniki prezentują czas w milisekundach. Są to kolejno czasy Daniela, Marcina i stosunki czasów Marcina do Daniela. Kolumny pokazują ilość zajętych miejsc, a wiersze ilość rzędów w samolocie.\"]]],[10,38],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "html": "<p>Omówimy dwa rozwiązania zadania, które stosowane było podczas pewnej rekrutacji. Jeśli potraficie pisać kod, zalecam wam samodzielne rozwiązanie po przeczytaniu treści, zajmie to około 10 do 30 minut i pozwoli Wam porównać wasze rozwiązanie z tymi prezentowanymi poniżej:</p><h2 id=\"tre-zadania\">Treść zadania</h2><p>W samolocie rozmieszczone są miejsca. Tworzą one trzy zestawy zawierające kolejno 3, 4 i 3 siedzenia sąsiadujące ze sobą. Zakładamy, że wiersze liczone są od 1 a kolumny indeksowane za pomocą liter alfabetu jak w tabeli EXCEL (od A do K). Schemat samolotu przedstawia poniższy rysunek. Zakładamy, że wszystkie miejsca mają taki sam układ jak te oznaczone na niebiesko.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-15-46-33.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"668\" height=\"672\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-15-46-33.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-15-46-33.png 668w\"></figure><p>Zakładamy, że samolot ma długość <code>N</code> rzędów z miejscami. Znamy też aktualne zapełnienie miejsc, które zapisane jest w postaci ciągu znakowego <code>S</code> jako oddzielone spacją współrzędne numeru wiersza i kolumny, np:</p><pre><code>S=1A 3C 2B 40G 5A</code></pre><p>oznacza zajęcie miejsc <code>1A</code>, <code>3C</code>, <code>2B</code>, <code>40G</code> oraz <code>5A</code>. </p><p>Naszym celem jest napisanie funkcji, która zliczy ile 3 osobowych rodzin wymagających zajęcia miejsc bezpośrednio obok siebie zmieści się w samolocie.</p><p>Na przykład dla danych:</p><pre><code>const S = \"1A 2F 1C\"\nconst N = 2;</code></pre><p>poprawnym wynikiem będzie 4.</p><hr><p>To jest najlepsze miejsce, aby wykonać to zadanie samodzielnie i porównać z prezentowanymi poniżej rozwiązaniami.</p><h2 id=\"rozwi-zanie-marcina\">Rozwiązanie Marcina</h2><p>Pierwsze rozwiązanie wytworzył mój kolega Marcin. Ma ono krótki, czytelny kod. Rozpina dwuwymiarową tablicę wszystkich miejsc, oznacza zaznaczone wartościami <code>false</code>, na końcu przechodzi po rzędach doliczając wolne sloty w oparciu o stosowne kryteria dla każdego z nich.</p><pre><code class=\"language-javascript\">function solution(N, S) {\n  const seatNames = {\n    'A': 0,\n    'B': 1,\n    'C': 2,\n    'D': 3,\n    'E': 4,\n    'F': 5,\n    'G': 6,\n    'H': 7,\n    'J': 8,\n    'K': 9\n  }\n  const freeSeats = Array.from({length: N}, () =&gt; Array.from({length: 10}, () =&gt; true))\n  const reservedSeats = S.split(' ');\n  reservedSeats.forEach(s =&gt; {\n    try {\n      freeSeats[parseInt(s.substring(0, s.length - 1)) - 1][seatNames[s[s.length - 1]]] = false;\n    } catch (e) {\n      console.log('Some error @ reserved seat marked: ', s)\n    }\n  })\n\n  let free3seats = 0\n  freeSeats.forEach(rs =&gt; {\n    if (rs[0] &amp;&amp; rs[1] &amp;&amp; rs[2]) free3seats++;\n    if ((rs[3] &amp;&amp; rs[4] &amp;&amp; rs[5]) || (rs[4] &amp;&amp; rs[5] &amp;&amp; rs[6])) free3seats++;\n    if (rs[7] &amp;&amp; rs[8] &amp;&amp; rs[9]) free3seats++;\n  })\n\n  return free3seats\n}\n\nmodule.exports = {solution};</code></pre><h2 id=\"rozwi-zanie-daniela\">Rozwiązanie Daniela</h2><p>Drugie posługuje się bezpośrednio tablicą slotów, składając je w jeden wymiar. Nie stosując struktury danych o indeksowaniu analogicznym do miejsc zmuszeni jesteśmy indeks slotu wyliczać za każdym razem z rzędu oraz instrukcji warunkowych nałożonych na kolumny. Kod jest trudniejszy do czytania i wymaga kilku linii komentarzy z opisem przyjętej konwencji. Jego zaletą jest operowanie na mniejszej strukturze danych, a wadą bardziej złożone instrukcje warunkowe.</p><pre><code class=\"language-javascript\">// DOCS\n// slot 1 = empty\n// slot 0 = taken\n// slot \"r\" = taken from right\n// slot \"l\" = taken from left\n\nfunction markCorner(slots, nr, side) {\n  if (slots[(nr - 1) * 3 + 1] === 1) slots[(nr - 1) * 3 + 1] = side;\n  else if (slots[(nr - 1) * 3 + 1] === (side === 'l' ? 'r' : 'l')) slots[(nr - 1) * 3 + 1] = 0;\n}\n\nfunction solution(N, S) {\n  const slots = [...new Array(3 * N)].map(() =&gt; 1);\n  const places = S.split(' ');\n  while (places.length) {\n    const place = places.shift();\n    const nr = place.slice(0, -1);\n    const letter = place.charAt(place.length - 1);\n\n    if (['A', 'B', 'C'].includes(letter)) {\n      slots[(nr - 1) * 3] = 0;\n    }\n\n    if (['H', 'J', 'K'].includes(letter)) {\n      slots[(nr - 1) * 3 + 2] = 0;\n    }\n\n    if (['E', 'F'].includes(letter)) {\n      slots[(nr - 1) * 3 + 1] = 0;\n    }\n\n    if (['D'].includes(letter)) {\n      markCorner(slots, nr, 'l');\n    }\n\n    if (['G'].includes(letter)) {\n      markCorner(slots, nr, 'r');\n    }\n  }\n\n  return slots.reduce((p, n) =&gt; p + Boolean(n), 0);\n}\n\nmodule.exports = {solution};</code></pre><h2 id=\"por-wnanie-wydajno-ci-rozwi-za-\">Porównanie wydajności rozwiązań</h2><p>W celu porównania szybkości działania tych kodów dopiszemy generator współrzędnych z miejscami:</p><pre><code>const fs = require('fs');\n\nfunction letter() {\n  return ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K'][Math.floor(Math.random() * 10)];\n}\n\nfunction row(N) {\n  return Math.floor(Math.random() * N + 1);\n}\n\nfunction tempPath(N, M) {\n  return `/tmp/.cache.generate-places-${N},${M}.log`;\n}\n\n// '1A 3C 2B 40G 5A'\nfunction generatePlaces(N, M) {\n  if (fs.existsSync(tempPath(N, M))) {\n    return fs.readFileSync(tempPath(N, M)).toString();\n  }\n\n  let res = [];\n  while (res.length &lt; M) {\n    const n = `${row(N)}${letter()}`;\n    if (!res.includes(n)) {\n      res.push(n);\n    }\n  }\n  const out = res.join(' ');\n\n  fs.writeFileSync(tempPath(N, M), out);\n\n  return out;\n}\n\nmodule.exports = generatePlaces;\n</code></pre><p>Linie z <code>fs</code> pozwalają nam na zapis wygenerowanej listy miejsc w cache i nie generowanie jej od nowa przy powtarzaniu testów.</p><p>Tworzymy też skrypt testujący szybkość działania obu algorytmów:</p><pre><code>const d = require('./d');\nconst m = require('./m');\nconst generatePlaces = require('./generatePlaces');\n\nif (process.argv.length !== 4) {\n  throw new Error('Type `node test.js N M`');\n}\n\nconst N = parseInt(process.argv[2]) || 50;\nconst M = parseInt(process.argv[3]) || 10;\n\nconst params = [N, generatePlaces(N, M)];\n\nconsole.time('m');\nconst endM = m.solution(...params);\nconsole.timeEnd('m');\n\nconsole.time('d');\nconst endD = d.solution(...params);\nconsole.timeEnd('d');\n\nconsole.log(endM, endD);\n</code></pre><p>Hipotetycznie załóżmy, że mamy bardzo długi samolot (pół miliona rzędów). Sprawdzimy po kolei przypadki prawie pustego lotu <code>1000</code> zajętych miejsc. Liczba występująca po <code>m</code> to czas dla rozwiązania <code>Marcina</code>, a po <code>d</code> to czas dla <code>Daniela</code>.</p><pre><code>time node test.js 500000 1000  \nm: 1.339s\nd: 151.637ms\n</code></pre><p>Widzimy, że rozwiązanie zliczające jedynie sloty wykrywa 8.8 raza pod względem szybkości. Dla <code>20k</code> zajętych już miejsc:</p><pre><code>time node test.js 500000 20000 \nm: 1.462s\nd: 276.517ms\n</code></pre><p>ta przewaga spada do 5.3 raza. Jeśli zajętych miejsc będzie <code>40k</code>, to wyniki będą różnić się następująco:</p><pre><code>time node test.js 500000 40000 \nm: 1.386s\nd: 606.803ms\n</code></pre><p>Rozwiązanie Daniela wciąż będzie szybsze, ale tylko 2.2 razy. Dla <code>80k</code> zajętych miejsc sytuacja się odwraca i rozwiązanie Marcina staje się 1.62 razy szybsze.</p><pre><code>time node test.js 500000 80000\nm: 1.385s\nd: 2.257s</code></pre><p>Przy <code>100k</code> miejsc skrypt Marcina osiąga już 4.7 raza lepsze wyniki</p><pre><code>time node test.js 500000 100000\nm: 1.413s\nd: 6.656s</code></pre><hr><h2 id=\"pu-apka\">Pułapka</h2><p>Gdybyśmy nie zachowali ostrożności mogli byśmy uznać, że finalnym wnioskiem były by zdania: \"Algorytm Daniela sprawdza się lepiej przy pustym samolocie, a Marcina przy pełnym\" oraz \"Algorytm Daniela silnie zależy od ilości miejsc, a Marcina ma stabilny mniej więcej stały czas działania\".</p><p>Tak wynika z testów, ale jeśli wytniemy z pomiarów kod Marcina to dla takiego kodu testującego</p><pre><code>const d = require('./d');\n// const m = require('./m');\nconst generatePlaces = require('./generatePlaces');\n\nif (process.argv.length !== 4) {\n  throw new Error('Type `node test.js N M`');\n}\n\nconst N = parseInt(process.argv[2]) || 50;\nconst M = parseInt(process.argv[3]) || 10;\n\nconst params = [N, generatePlaces(N, M)];\n\n// console.time('m');\n// const endM = m.solution(...params);\n// console.timeEnd('m');\n\nconsole.time('d');\nconst endD = d.solution(...params);\nconsole.timeEnd('d');\n\n// console.log(endM, endD);</code></pre><p>wynik pomiaru czasu znacznie wzrośnie:</p><pre><code>time node test.js 500000 100000\nd: 26.454s\nnode test.js 500000 100000  26.42s user 0.08s system 99% cpu 26.524 total\n</code></pre><p>A w ten sam wyizolowany sposób testując kod Marcina dostaniemy ponownie  ten sam wynik zbliżony do półtorej sekundy</p><pre><code>time node test.js 500000 100000\nm: 1.437s\nnode test.js 500000 100000  1.66s user 0.09s system 115% cpu 1.515 total\n</code></pre><p>Do profilowania możemy użyć flagi <code>--porf</code>, spowoduje ona powstanie pliku z logami o wielkości około <code>4MB</code>.</p><p>Jego przeglądanie nie jest łatwe jeśli nie wie się czego szukać. Ten plik wygląda mniej więcej tak: </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-50-47.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"859\" height=\"560\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-18-50-47.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-50-47.png 859w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Na szczęście Webstorm ma ciekawe narzędzia do profilowania, które pod spodem robią to samo co ta flaga, ale nakładają graficzną nakładkę i wykresy, które pozwalają na odnalezienie się w logach i szybkie dotarcie do źródła problemu. Aby skonfigurować profilowanie zaznaczamy w ustawieniach <code>Coding assistance for Node.js</code></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-41-38.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1013\" height=\"749\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-18-41-38.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/Screenshot-from-2021-04-20-18-41-38.png 1000w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-41-38.png 1013w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Następnie tworzymy profil, który wystartuje nasz skrypt z odpowiednimi parametrami</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-45-05.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"863\" height=\"574\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-18-45-05.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-45-05.png 863w\" sizes=\"(min-width: 720px) 720px\"></figure><p>a w zakładce <code>V8 Profiling</code> zaznaczamy opcję profilowania.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-41-13.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"886\" height=\"582\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-18-41-13.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-41-13.png 886w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Po wybraniu zielonego trójkąta startującego profilowanie</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-19-02-23.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"320\" height=\"38\"></figure><p>zobaczymy logi uporządkowane względem procentowego udziału w czasie wykonywania.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-50-01.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1095\" height=\"594\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-18-50-01.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/Screenshot-from-2021-04-20-18-50-01.png 1000w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-18-50-01.png 1095w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Ten widok pozwala wyłowić najcięższe funkcje względem całkowitego czasu wykonywania. Więcej o profilowaniu możesz poczytać w dokumentacji WebStorms.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.jetbrains.com/help/webstorm/v8-cpu-and-memory-profiling.html#ws_node_cpu_profiling\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">V8 CPU and memory profiling | WebStorm</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://resources.jetbrains.com/storage/ui/favicons/apple-touch-icon-180x180.png\"><span class=\"kg-bookmark-author\">WebStorm Help</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://resources.jetbrains.com/storage/products/webstorm/img/meta/preview.png\"></div></a></figure><p>Ponowny przegląda kodu i zestawienie logów z informacją, że to ilość zajętych miejsc tak bardzo obniża wydajność skryptu wskazują, że należy szukać problemu w funkcji <code>shift</code></p><pre><code>const place = places.shift();</code></pre><p>Poświęcono temu wątek na stack overflow</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://stackoverflow.com/questions/6501160/why-is-pop-faster-than-shift\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Why is pop faster than shift?</div><div class=\"kg-bookmark-description\">Douglas Crockford, in JavaScript: The Good Parts, states that “shift is usually much slower than pop”. jsPerf confirms this. Does anyone know why this is the case? From an unsophisticated point of ...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v&#x3D;c78bd457575a\"><span class=\"kg-bookmark-author\">Stack Overflow</span><span class=\"kg-bookmark-publisher\">zjmiller</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v&#x3D;73d79a89bded\"></div></a></figure><p>Zmiana tej jednej linii</p><pre><code>const place = places.shift();</code></pre><p>na</p><pre><code>const place = places.pop();</code></pre><p>w algorytmie Daniela przywraca mu poprawne tępo działania nie zależnie od tego czy kod Marcina jest wykonywany, czy nie</p><pre><code>time node test.js 500000 100000\nm: 1.449s\nd: 233.327ms\n1421226 1421226\nnode test.js 500000 100000  1.89s user 0.13s system 114% cpu 1.768 total\n</code></pre><p>oraz</p><pre><code>time node test.js 500000 100000\nd: 238.217ms\nnode test.js 500000 100000  0.27s user 0.04s system 101% cpu 0.311 total\n</code></pre><p>Po delikatnej modyfikacji kodu napisanego przez <code>bhirt</code> na Slack Overflow:</p><pre><code>let sum;\nconst tests = new Array(8).fill(null).map((e, i) =&gt; (i + 6) * 10000);\n\nconsole.log(JSON.stringify(process.versions));\n\ntests.forEach(function (count) {\n  console.log('Testing arrays of size ' + count);\n  let s1 = Date.now();\n  let sArray = new Array(count);\n  let pArray = new Array(count);\n  for (let i = 0; i &lt; count; i++) {\n    const num = Math.floor(Math.random() * 6) + 1;\n    sArray[i] = num;\n    pArray[i] = num;\n  }\n  console.log(' -&gt; ' + (Date.now() - s1) + 'ms: built arrays with ' + count + ' random elements');\n\n  s1 = Date.now();\n  sum = 0;\n  while (pArray.length) {\n    sum += pArray.pop();\n  }\n  console.log(\n    ' -&gt; ' + (Date.now() - s1) + 'ms: sum with pop() ' + count + ' elements, sum = ' + sum\n  );\n\n  s1 = Date.now();\n  sum = 0;\n  while (sArray.length) {\n    sum += sArray.shift();\n  }\n  console.log(\n    ' -&gt; ' + (Date.now() - s1) + 'ms: sum with shift() ' + count + ' elements, sum = ' + sum\n  );\n});</code></pre><p>widzimy, że najnowsza wersja <code>node</code> nie naprawiła tego problemu</p><pre><code>{\"node\":\"15.8.0\",\"v8\":\"8.6.395.17-node.23\",\"uv\":\"1.40.0\",\"zlib\":\"1.2.11\",\"brotli\":\"1.0.9\",\"ares\":\"1.17.1\",\"modules\":\"88\",\"nghttp2\":\"1.42.0\",\"napi\":\"7\",\"llhttp\":\"2.1.3\",\"openssl\":\"1.1.1i\",\"cldr\":\"38.1\",\"icu\":\"68.2\",\"tz\":\"2020d\",\"unicode\":\"13.0\"}\nTesting arrays of size 60000\n -&gt; 12ms: built arrays with 60000 random elements\n -&gt; 5ms: sum with pop() 60000 elements, sum = 209556\n -&gt; 1057ms: sum with shift() 60000 elements, sum = 209556\nTesting arrays of size 70000\n -&gt; 20ms: built arrays with 70000 random elements\n -&gt; 1ms: sum with pop() 70000 elements, sum = 244919\n -&gt; 1476ms: sum with shift() 70000 elements, sum = 244919\nTesting arrays of size 80000\n -&gt; 5ms: built arrays with 80000 random elements\n -&gt; 0ms: sum with pop() 80000 elements, sum = 279502\n -&gt; 1993ms: sum with shift() 80000 elements, sum = 279502\nTesting arrays of size 90000\n -&gt; 4ms: built arrays with 90000 random elements\n -&gt; 0ms: sum with pop() 90000 elements, sum = 313487\n -&gt; 2601ms: sum with shift() 90000 elements, sum = 313487\nTesting arrays of size 100000\n -&gt; 4ms: built arrays with 100000 random elements\n -&gt; 1ms: sum with pop() 100000 elements, sum = 350059\n -&gt; 3263ms: sum with shift() 100000 elements, sum = 350059\nTesting arrays of size 110000\n -&gt; 8ms: built arrays with 110000 random elements\n -&gt; 1ms: sum with pop() 110000 elements, sum = 384719\n -&gt; 4154ms: sum with shift() 110000 elements, sum = 384719\nTesting arrays of size 120000\n -&gt; 7ms: built arrays with 120000 random elements\n -&gt; 0ms: sum with pop() 120000 elements, sum = 419326\n -&gt; 5027ms: sum with shift() 120000 elements, sum = 419326\nTesting arrays of size 130000\n -&gt; 8ms: built arrays with 130000 random elements\n -&gt; 0ms: sum with pop() 130000 elements, sum = 454068\n -&gt; 5702ms: sum with shift() 130000 elements, sum = 454068</code></pre><p>W przeglądarce te operacje trwają dwa razy krócej ale i tak różnica między <code>pop</code> a <code>shift</code> jest ogromna i każde 50-100 elementów tablic dodaje milisekundę do czasu wykonywania <code>shift</code>.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-19-27-03.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"418\" height=\"618\"></figure><p>Przerabiając ten kod do testowania po raz drugi możemy uzyskać wersję, która będzie dobrze działać w przeglądarce i pozwoli na wygenerowanie danych do narysowania wykresu:</p><pre><code>var sum;\nvar res = [];\nvar tests = new Array(20).fill(null).map((e, i) =&gt; (i + 1) * 10000);\n\ntests.forEach(function (count) {\n  console.log('Testing arrays of size ' + count);\n  let s1 = Date.now();\n  let sArray = new Array(count);\n  let pArray = new Array(count);\n  for (let i = 0; i &lt; count; i++) {\n    const num = Math.floor(Math.random() * 6) + 1;\n    sArray[i] = num;\n    pArray[i] = num;\n  }\n  console.log(' -&gt; ' + (Date.now() - s1) + 'ms: built arrays with ' + count + ' random elements');\n\n  s1 = Date.now();\n  sum = 0;\n  while (pArray.length) {\n    sum += pArray.pop();\n  }\n  console.log(\n    ' -&gt; ' + (Date.now() - s1) + 'ms: sum with pop() ' + count + ' elements, sum = ' + sum\n  );\n\n  s1 = Date.now();\n  sum = 0;\n  while (sArray.length) {\n    sum += sArray.shift();\n  }\n  res.push([count, Date.now() - s1]);\n  console.log(\n    ' -&gt; ' + (Date.now() - s1) + 'ms: sum with shift() ' + count + ' elements, sum = ' + sum\n  );\n});</code></pre><p>Wykres zależności czasu od długości tablicy wygenerujemy w <code>chart.js</code></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.chartjs.org/docs/latest/getting-started/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Getting Started | Chart.js</div><div class=\"kg-bookmark-description\">Open source HTML5 Charts for your website</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.chartjs.org/docs/latest/favicon.ico\"><span class=\"kg-bookmark-author\">Chart.js</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.chartjs.org/docs/latest/favicon.ico\"></div></a></figure><pre><code>let res = [[10000,3],[20000,3],[30000,4],[40000,193],[50000,304],[60000,450],[70000,625],[80000,859],[90000,1081],[100000,1419],[110000,1704],[120000,2040],[130000,2466],[140000,2936],[150000,3429],[160000,3948],[170000,4509],[180000,5158],[190000,5852],[200000,6450]];\n\nconst labels = res.map(r =&gt; r[0]);\nconst data = {\n  labels: labels,\n  datasets: [{\n    label: 'Time [ms] of sum of rarray computed with shift method vs array length',\n    backgroundColor: 'rgb(255, 99, 132)',\n    borderColor: 'rgb(255, 99, 132)',\n    data: res.map(r =&gt; r[1]),\n  }]\n};</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-19-39-16.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"744\" height=\"387\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-19-39-16.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-19-39-16.png 744w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"ponowne-por-wnanie-rozwi-za-\">Ponowne porównanie rozwiązań</h2><p>Oryginalnie Marcin napisał lepszy kod niż Ja. Wpadka z <code>shift</code> zrujnowała cały zysk wydajnościowy z koncepcji, żeby operować na slotach, a nie poszczególnych miejscach. Jeśli jednak pozwolimy na wymianę <code>shift</code> na <code>pop</code> w moim kodzie (Daniela) to okazuje się on ostatecznie kilka do kilkunastu razy szybszy niż kod Marcina.</p><p>Za zestawienie wyników odpowiada zmodyfikowany plik <code>test.js</code></p><pre><code class=\"language-javascript\">const d = require('./d');\nconst m = require('./m');\nconst generatePlaces = require('./generatePlaces');\nconst res = [];\n\nfunction log(res) {\n  console.log('Daniel Results');\n  console.table(res.map(r =&gt; r.map(r =&gt; r.d)));\n  console.log('Marcin Results');\n  console.table(res.map(r =&gt; r.map(r =&gt; r.m)));\n  console.log('Rations Marcin Time to Daniel Time');\n  console.table(res.map(r =&gt; r.map(r =&gt; r.r)));\n}\n\nconst start = new Date().getTime();\n\nfor (let N = 250000; N &lt; 1000000; N += 250000) {\n  res[N] = [];\n  for (let M = 10000; M &lt; 150000; M += 10000) {\n    const params = [N, generatePlaces(N, M)];\n\n    const sm = new Date().getTime();\n    m.solution(...params);\n    const em = new Date().getTime();\n\n    const sd = new Date().getTime();\n    d.solution(...params);\n    const ed = new Date().getTime();\n    res[N][M] = {\n      d: ed - sd,\n      m: em - sm,\n      r: Math.round((100 * (em - sm)) / (ed - sd)) / 100\n    };\n\n    const now = new Date().getTime();\n    console.log(now - start);\n    log(res);\n  }\n}\n</code></pre><p>Wyniki prezentują czas w milisekundach. Są to kolejno czasy Daniela, Marcina i stosunki czasów Marcina do Daniela. Kolumny pokazują ilość zajętych miejsc, a wiersze ilość rzędów w samolocie.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-20-30-44.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"800\" height=\"409\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-20-30-44.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-20-30-44.png 800w\" sizes=\"(min-width: 720px) 720px\"></figure><p></p>",
            "comment_id": "603a4b758e39617ce723d8e6",
            "plaintext": "Omówimy dwa rozwiązania zadania, które stosowane było podczas pewnej rekrutacji.\nJeśli potraficie pisać kod, zalecam wam samodzielne rozwiązanie po przeczytaniu\ntreści, zajmie to około 10 do 30 minut i pozwoli Wam porównać wasze rozwiązanie\nz tymi prezentowanymi poniżej:\n\nTreść zadania\nW samolocie rozmieszczone są miejsca. Tworzą one trzy zestawy zawierające\nkolejno 3, 4 i 3 siedzenia sąsiadujące ze sobą. Zakładamy, że wiersze liczone są\nod 1 a kolumny indeksowane za pomocą liter alfabetu jak w tabeli EXCEL (od A do\nK). Schemat samolotu przedstawia poniższy rysunek. Zakładamy, że wszystkie\nmiejsca mają taki sam układ jak te oznaczone na niebiesko.\n\nZakładamy, że samolot ma długość N rzędów z miejscami. Znamy też aktualne\nzapełnienie miejsc, które zapisane jest w postaci ciągu znakowego S jako\noddzielone spacją współrzędne numeru wiersza i kolumny, np:\n\nS=1A 3C 2B 40G 5A\n\noznacza zajęcie miejsc 1A, 3C, 2B, 40G oraz 5A. \n\nNaszym celem jest napisanie funkcji, która zliczy ile 3 osobowych rodzin\nwymagających zajęcia miejsc bezpośrednio obok siebie zmieści się w samolocie.\n\nNa przykład dla danych:\n\nconst S = \"1A 2F 1C\"\nconst N = 2;\n\npoprawnym wynikiem będzie 4.\n\n\n--------------------------------------------------------------------------------\n\nTo jest najlepsze miejsce, aby wykonać to zadanie samodzielnie i porównać z\nprezentowanymi poniżej rozwiązaniami.\n\nRozwiązanie Marcina\nPierwsze rozwiązanie wytworzył mój kolega Marcin. Ma ono krótki, czytelny kod.\nRozpina dwuwymiarową tablicę wszystkich miejsc, oznacza zaznaczone wartościami \nfalse, na końcu przechodzi po rzędach doliczając wolne sloty w oparciu o\nstosowne kryteria dla każdego z nich.\n\nfunction solution(N, S) {\n  const seatNames = {\n    'A': 0,\n    'B': 1,\n    'C': 2,\n    'D': 3,\n    'E': 4,\n    'F': 5,\n    'G': 6,\n    'H': 7,\n    'J': 8,\n    'K': 9\n  }\n  const freeSeats = Array.from({length: N}, () => Array.from({length: 10}, () => true))\n  const reservedSeats = S.split(' ');\n  reservedSeats.forEach(s => {\n    try {\n      freeSeats[parseInt(s.substring(0, s.length - 1)) - 1][seatNames[s[s.length - 1]]] = false;\n    } catch (e) {\n      console.log('Some error @ reserved seat marked: ', s)\n    }\n  })\n\n  let free3seats = 0\n  freeSeats.forEach(rs => {\n    if (rs[0] && rs[1] && rs[2]) free3seats++;\n    if ((rs[3] && rs[4] && rs[5]) || (rs[4] && rs[5] && rs[6])) free3seats++;\n    if (rs[7] && rs[8] && rs[9]) free3seats++;\n  })\n\n  return free3seats\n}\n\nmodule.exports = {solution};\n\nRozwiązanie Daniela\nDrugie posługuje się bezpośrednio tablicą slotów, składając je w jeden wymiar.\nNie stosując struktury danych o indeksowaniu analogicznym do miejsc zmuszeni\njesteśmy indeks slotu wyliczać za każdym razem z rzędu oraz instrukcji\nwarunkowych nałożonych na kolumny. Kod jest trudniejszy do czytania i wymaga\nkilku linii komentarzy z opisem przyjętej konwencji. Jego zaletą jest operowanie\nna mniejszej strukturze danych, a wadą bardziej złożone instrukcje warunkowe.\n\n// DOCS\n// slot 1 = empty\n// slot 0 = taken\n// slot \"r\" = taken from right\n// slot \"l\" = taken from left\n\nfunction markCorner(slots, nr, side) {\n  if (slots[(nr - 1) * 3 + 1] === 1) slots[(nr - 1) * 3 + 1] = side;\n  else if (slots[(nr - 1) * 3 + 1] === (side === 'l' ? 'r' : 'l')) slots[(nr - 1) * 3 + 1] = 0;\n}\n\nfunction solution(N, S) {\n  const slots = [...new Array(3 * N)].map(() => 1);\n  const places = S.split(' ');\n  while (places.length) {\n    const place = places.shift();\n    const nr = place.slice(0, -1);\n    const letter = place.charAt(place.length - 1);\n\n    if (['A', 'B', 'C'].includes(letter)) {\n      slots[(nr - 1) * 3] = 0;\n    }\n\n    if (['H', 'J', 'K'].includes(letter)) {\n      slots[(nr - 1) * 3 + 2] = 0;\n    }\n\n    if (['E', 'F'].includes(letter)) {\n      slots[(nr - 1) * 3 + 1] = 0;\n    }\n\n    if (['D'].includes(letter)) {\n      markCorner(slots, nr, 'l');\n    }\n\n    if (['G'].includes(letter)) {\n      markCorner(slots, nr, 'r');\n    }\n  }\n\n  return slots.reduce((p, n) => p + Boolean(n), 0);\n}\n\nmodule.exports = {solution};\n\nPorównanie wydajności rozwiązań\nW celu porównania szybkości działania tych kodów dopiszemy generator\nwspółrzędnych z miejscami:\n\nconst fs = require('fs');\n\nfunction letter() {\n  return ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K'][Math.floor(Math.random() * 10)];\n}\n\nfunction row(N) {\n  return Math.floor(Math.random() * N + 1);\n}\n\nfunction tempPath(N, M) {\n  return `/tmp/.cache.generate-places-${N},${M}.log`;\n}\n\n// '1A 3C 2B 40G 5A'\nfunction generatePlaces(N, M) {\n  if (fs.existsSync(tempPath(N, M))) {\n    return fs.readFileSync(tempPath(N, M)).toString();\n  }\n\n  let res = [];\n  while (res.length < M) {\n    const n = `${row(N)}${letter()}`;\n    if (!res.includes(n)) {\n      res.push(n);\n    }\n  }\n  const out = res.join(' ');\n\n  fs.writeFileSync(tempPath(N, M), out);\n\n  return out;\n}\n\nmodule.exports = generatePlaces;\n\n\nLinie z fs pozwalają nam na zapis wygenerowanej listy miejsc w cache i nie\ngenerowanie jej od nowa przy powtarzaniu testów.\n\nTworzymy też skrypt testujący szybkość działania obu algorytmów:\n\nconst d = require('./d');\nconst m = require('./m');\nconst generatePlaces = require('./generatePlaces');\n\nif (process.argv.length !== 4) {\n  throw new Error('Type `node test.js N M`');\n}\n\nconst N = parseInt(process.argv[2]) || 50;\nconst M = parseInt(process.argv[3]) || 10;\n\nconst params = [N, generatePlaces(N, M)];\n\nconsole.time('m');\nconst endM = m.solution(...params);\nconsole.timeEnd('m');\n\nconsole.time('d');\nconst endD = d.solution(...params);\nconsole.timeEnd('d');\n\nconsole.log(endM, endD);\n\n\nHipotetycznie załóżmy, że mamy bardzo długi samolot (pół miliona rzędów).\nSprawdzimy po kolei przypadki prawie pustego lotu 1000 zajętych miejsc. Liczba\nwystępująca po m to czas dla rozwiązania Marcina, a po d to czas dla Daniela.\n\ntime node test.js 500000 1000  \nm: 1.339s\nd: 151.637ms\n\n\nWidzimy, że rozwiązanie zliczające jedynie sloty wykrywa 8.8 raza pod względem\nszybkości. Dla 20k zajętych już miejsc:\n\ntime node test.js 500000 20000 \nm: 1.462s\nd: 276.517ms\n\n\nta przewaga spada do 5.3 raza. Jeśli zajętych miejsc będzie 40k, to wyniki będą\nróżnić się następująco:\n\ntime node test.js 500000 40000 \nm: 1.386s\nd: 606.803ms\n\n\nRozwiązanie Daniela wciąż będzie szybsze, ale tylko 2.2 razy. Dla 80k zajętych\nmiejsc sytuacja się odwraca i rozwiązanie Marcina staje się 1.62 razy szybsze.\n\ntime node test.js 500000 80000\nm: 1.385s\nd: 2.257s\n\nPrzy 100k miejsc skrypt Marcina osiąga już 4.7 raza lepsze wyniki\n\ntime node test.js 500000 100000\nm: 1.413s\nd: 6.656s\n\n\n--------------------------------------------------------------------------------\n\nPułapka\nGdybyśmy nie zachowali ostrożności mogli byśmy uznać, że finalnym wnioskiem były\nby zdania: \"Algorytm Daniela sprawdza się lepiej przy pustym samolocie, a\nMarcina przy pełnym\" oraz \"Algorytm Daniela silnie zależy od ilości miejsc, a\nMarcina ma stabilny mniej więcej stały czas działania\".\n\nTak wynika z testów, ale jeśli wytniemy z pomiarów kod Marcina to dla takiego\nkodu testującego\n\nconst d = require('./d');\n// const m = require('./m');\nconst generatePlaces = require('./generatePlaces');\n\nif (process.argv.length !== 4) {\n  throw new Error('Type `node test.js N M`');\n}\n\nconst N = parseInt(process.argv[2]) || 50;\nconst M = parseInt(process.argv[3]) || 10;\n\nconst params = [N, generatePlaces(N, M)];\n\n// console.time('m');\n// const endM = m.solution(...params);\n// console.timeEnd('m');\n\nconsole.time('d');\nconst endD = d.solution(...params);\nconsole.timeEnd('d');\n\n// console.log(endM, endD);\n\nwynik pomiaru czasu znacznie wzrośnie:\n\ntime node test.js 500000 100000\nd: 26.454s\nnode test.js 500000 100000  26.42s user 0.08s system 99% cpu 26.524 total\n\n\nA w ten sam wyizolowany sposób testując kod Marcina dostaniemy ponownie  ten sam\nwynik zbliżony do półtorej sekundy\n\ntime node test.js 500000 100000\nm: 1.437s\nnode test.js 500000 100000  1.66s user 0.09s system 115% cpu 1.515 total\n\n\nDo profilowania możemy użyć flagi --porf, spowoduje ona powstanie pliku z logami\no wielkości około 4MB.\n\nJego przeglądanie nie jest łatwe jeśli nie wie się czego szukać. Ten plik\nwygląda mniej więcej tak: \n\nNa szczęście Webstorm ma ciekawe narzędzia do profilowania, które pod spodem\nrobią to samo co ta flaga, ale nakładają graficzną nakładkę i wykresy, które\npozwalają na odnalezienie się w logach i szybkie dotarcie do źródła problemu.\nAby skonfigurować profilowanie zaznaczamy w ustawieniach Coding assistance for\nNode.js\n\nNastępnie tworzymy profil, który wystartuje nasz skrypt z odpowiednimi\nparametrami\n\na w zakładce V8 Profiling zaznaczamy opcję profilowania.\n\nPo wybraniu zielonego trójkąta startującego profilowanie\n\nzobaczymy logi uporządkowane względem procentowego udziału w czasie wykonywania.\n\nTen widok pozwala wyłowić najcięższe funkcje względem całkowitego czasu\nwykonywania. Więcej o profilowaniu możesz poczytać w dokumentacji WebStorms.\n\nV8 CPU and memory profiling | WebStormWebStorm Help\n[https://www.jetbrains.com/help/webstorm/v8-cpu-and-memory-profiling.html#ws_node_cpu_profiling]\nPonowny przegląda kodu i zestawienie logów z informacją, że to ilość zajętych\nmiejsc tak bardzo obniża wydajność skryptu wskazują, że należy szukać problemu w\nfunkcji shift\n\nconst place = places.shift();\n\nPoświęcono temu wątek na stack overflow\n\nWhy is pop faster than shift?Douglas Crockford, in JavaScript: The Good Parts,\nstates that “shift is usually much slower than pop”. jsPerf confirms this. Does\nanyone know why this is the case? From an unsophisticated point of ...Stack\nOverflowzjmiller\n[https://stackoverflow.com/questions/6501160/why-is-pop-faster-than-shift]Zmiana\ntej jednej linii\n\nconst place = places.shift();\n\nna\n\nconst place = places.pop();\n\nw algorytmie Daniela przywraca mu poprawne tępo działania nie zależnie od tego\nczy kod Marcina jest wykonywany, czy nie\n\ntime node test.js 500000 100000\nm: 1.449s\nd: 233.327ms\n1421226 1421226\nnode test.js 500000 100000  1.89s user 0.13s system 114% cpu 1.768 total\n\n\noraz\n\ntime node test.js 500000 100000\nd: 238.217ms\nnode test.js 500000 100000  0.27s user 0.04s system 101% cpu 0.311 total\n\n\nPo delikatnej modyfikacji kodu napisanego przez bhirt na Slack Overflow:\n\nlet sum;\nconst tests = new Array(8).fill(null).map((e, i) => (i + 6) * 10000);\n\nconsole.log(JSON.stringify(process.versions));\n\ntests.forEach(function (count) {\n  console.log('Testing arrays of size ' + count);\n  let s1 = Date.now();\n  let sArray = new Array(count);\n  let pArray = new Array(count);\n  for (let i = 0; i < count; i++) {\n    const num = Math.floor(Math.random() * 6) + 1;\n    sArray[i] = num;\n    pArray[i] = num;\n  }\n  console.log(' -> ' + (Date.now() - s1) + 'ms: built arrays with ' + count + ' random elements');\n\n  s1 = Date.now();\n  sum = 0;\n  while (pArray.length) {\n    sum += pArray.pop();\n  }\n  console.log(\n    ' -> ' + (Date.now() - s1) + 'ms: sum with pop() ' + count + ' elements, sum = ' + sum\n  );\n\n  s1 = Date.now();\n  sum = 0;\n  while (sArray.length) {\n    sum += sArray.shift();\n  }\n  console.log(\n    ' -> ' + (Date.now() - s1) + 'ms: sum with shift() ' + count + ' elements, sum = ' + sum\n  );\n});\n\nwidzimy, że najnowsza wersja node nie naprawiła tego problemu\n\n{\"node\":\"15.8.0\",\"v8\":\"8.6.395.17-node.23\",\"uv\":\"1.40.0\",\"zlib\":\"1.2.11\",\"brotli\":\"1.0.9\",\"ares\":\"1.17.1\",\"modules\":\"88\",\"nghttp2\":\"1.42.0\",\"napi\":\"7\",\"llhttp\":\"2.1.3\",\"openssl\":\"1.1.1i\",\"cldr\":\"38.1\",\"icu\":\"68.2\",\"tz\":\"2020d\",\"unicode\":\"13.0\"}\nTesting arrays of size 60000\n -> 12ms: built arrays with 60000 random elements\n -> 5ms: sum with pop() 60000 elements, sum = 209556\n -> 1057ms: sum with shift() 60000 elements, sum = 209556\nTesting arrays of size 70000\n -> 20ms: built arrays with 70000 random elements\n -> 1ms: sum with pop() 70000 elements, sum = 244919\n -> 1476ms: sum with shift() 70000 elements, sum = 244919\nTesting arrays of size 80000\n -> 5ms: built arrays with 80000 random elements\n -> 0ms: sum with pop() 80000 elements, sum = 279502\n -> 1993ms: sum with shift() 80000 elements, sum = 279502\nTesting arrays of size 90000\n -> 4ms: built arrays with 90000 random elements\n -> 0ms: sum with pop() 90000 elements, sum = 313487\n -> 2601ms: sum with shift() 90000 elements, sum = 313487\nTesting arrays of size 100000\n -> 4ms: built arrays with 100000 random elements\n -> 1ms: sum with pop() 100000 elements, sum = 350059\n -> 3263ms: sum with shift() 100000 elements, sum = 350059\nTesting arrays of size 110000\n -> 8ms: built arrays with 110000 random elements\n -> 1ms: sum with pop() 110000 elements, sum = 384719\n -> 4154ms: sum with shift() 110000 elements, sum = 384719\nTesting arrays of size 120000\n -> 7ms: built arrays with 120000 random elements\n -> 0ms: sum with pop() 120000 elements, sum = 419326\n -> 5027ms: sum with shift() 120000 elements, sum = 419326\nTesting arrays of size 130000\n -> 8ms: built arrays with 130000 random elements\n -> 0ms: sum with pop() 130000 elements, sum = 454068\n -> 5702ms: sum with shift() 130000 elements, sum = 454068\n\nW przeglądarce te operacje trwają dwa razy krócej ale i tak różnica między pop a \nshift jest ogromna i każde 50-100 elementów tablic dodaje milisekundę do czasu\nwykonywania shift.\n\nPrzerabiając ten kod do testowania po raz drugi możemy uzyskać wersję, która\nbędzie dobrze działać w przeglądarce i pozwoli na wygenerowanie danych do\nnarysowania wykresu:\n\nvar sum;\nvar res = [];\nvar tests = new Array(20).fill(null).map((e, i) => (i + 1) * 10000);\n\ntests.forEach(function (count) {\n  console.log('Testing arrays of size ' + count);\n  let s1 = Date.now();\n  let sArray = new Array(count);\n  let pArray = new Array(count);\n  for (let i = 0; i < count; i++) {\n    const num = Math.floor(Math.random() * 6) + 1;\n    sArray[i] = num;\n    pArray[i] = num;\n  }\n  console.log(' -> ' + (Date.now() - s1) + 'ms: built arrays with ' + count + ' random elements');\n\n  s1 = Date.now();\n  sum = 0;\n  while (pArray.length) {\n    sum += pArray.pop();\n  }\n  console.log(\n    ' -> ' + (Date.now() - s1) + 'ms: sum with pop() ' + count + ' elements, sum = ' + sum\n  );\n\n  s1 = Date.now();\n  sum = 0;\n  while (sArray.length) {\n    sum += sArray.shift();\n  }\n  res.push([count, Date.now() - s1]);\n  console.log(\n    ' -> ' + (Date.now() - s1) + 'ms: sum with shift() ' + count + ' elements, sum = ' + sum\n  );\n});\n\nWykres zależności czasu od długości tablicy wygenerujemy w chart.js\n\nGetting Started | Chart.jsOpen source HTML5 Charts for your websiteChart.js\n[https://www.chartjs.org/docs/latest/getting-started/]let res = [[10000,3],[20000,3],[30000,4],[40000,193],[50000,304],[60000,450],[70000,625],[80000,859],[90000,1081],[100000,1419],[110000,1704],[120000,2040],[130000,2466],[140000,2936],[150000,3429],[160000,3948],[170000,4509],[180000,5158],[190000,5852],[200000,6450]];\n\nconst labels = res.map(r => r[0]);\nconst data = {\n  labels: labels,\n  datasets: [{\n    label: 'Time [ms] of sum of rarray computed with shift method vs array length',\n    backgroundColor: 'rgb(255, 99, 132)',\n    borderColor: 'rgb(255, 99, 132)',\n    data: res.map(r => r[1]),\n  }]\n};\n\nPonowne porównanie rozwiązań\nOryginalnie Marcin napisał lepszy kod niż Ja. Wpadka z shift zrujnowała cały\nzysk wydajnościowy z koncepcji, żeby operować na slotach, a nie poszczególnych\nmiejscach. Jeśli jednak pozwolimy na wymianę shift na pop w moim kodzie\n(Daniela) to okazuje się on ostatecznie kilka do kilkunastu razy szybszy niż kod\nMarcina.\n\nZa zestawienie wyników odpowiada zmodyfikowany plik test.js\n\nconst d = require('./d');\nconst m = require('./m');\nconst generatePlaces = require('./generatePlaces');\nconst res = [];\n\nfunction log(res) {\n  console.log('Daniel Results');\n  console.table(res.map(r => r.map(r => r.d)));\n  console.log('Marcin Results');\n  console.table(res.map(r => r.map(r => r.m)));\n  console.log('Rations Marcin Time to Daniel Time');\n  console.table(res.map(r => r.map(r => r.r)));\n}\n\nconst start = new Date().getTime();\n\nfor (let N = 250000; N < 1000000; N += 250000) {\n  res[N] = [];\n  for (let M = 10000; M < 150000; M += 10000) {\n    const params = [N, generatePlaces(N, M)];\n\n    const sm = new Date().getTime();\n    m.solution(...params);\n    const em = new Date().getTime();\n\n    const sd = new Date().getTime();\n    d.solution(...params);\n    const ed = new Date().getTime();\n    res[N][M] = {\n      d: ed - sd,\n      m: em - sm,\n      r: Math.round((100 * (em - sm)) / (ed - sd)) / 100\n    };\n\n    const now = new Date().getTime();\n    console.log(now - start);\n    log(res);\n  }\n}\n\n\nWyniki prezentują czas w milisekundach. Są to kolejno czasy Daniela, Marcina i\nstosunki czasów Marcina do Daniela. Kolumny pokazują ilość zajętych miejsc, a\nwiersze ilość rzędów w samolocie.",
            "feature_image": "__GHOST_URL__/content/images/2021/04/31742.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-02-27T13:39:01.000Z",
            "updated_at": "2021-04-20T18:41:10.000Z",
            "published_at": "2021-04-20T18:41:10.000Z",
            "custom_excerpt": "Porównujemy dwa rozwiązania zadania polegającego na zliczaniu wolnych zestawów przyległych miejsc. Dowiesz się jak używać Profilowania i jak wielką różnicę robi użycie pop oraz shift na tablicach w js.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "604118a88e39617ce723d8f3",
            "uuid": "de2561c8-fe7a-43fe-9801-8e15cd9e68b2",
            "title": "Infrastrukura defniowana przez kod (terraform + digital ocean)",
            "slug": "infrastrukura-defniowana-jako-kod",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/03/2021-03-04-184133_1326x925_scrot.png\",\"width\":1326,\"height\":925,\"caption\":\"https://www.digitalocean.com/pricing/calculator/\"}],[\"code\",{\"code\":\"yay -S terraform\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/03/2021-03-04-185052_1247x416_scrot.png\",\"width\":1247,\"height\":416}],[\"code\",{\"code\":\"export DIGITALOCEAN_TOKEN=xxxxxxxxxxxxxxxxxxxxxx\\n\"}],[\"code\",{\"code\":\"terraform {\\n  required_providers {\\n    digitalocean = {\\n      source = \\\"digitalocean/digitalocean\\\"\\n      version = \\\"2.5.1\\\"\\n    }\\n  }\\n}\\n\\nprovider \\\"digitalocean\\\" {}\"}],[\"code\",{\"code\":\"terraform init\"}],[\"code\",{\"code\":\"data \\\"digitalocean_ssh_key\\\" \\\"dell\\\" {\\n  name = \\\"Daniel Laptop Dell\\\"\\n}\\ndata \\\"digitalocean_ssh_key\\\" \\\"yoga\\\" {\\n  name = \\\"Daniel Lenovo Yoga\\\"\\n}\\ndata \\\"digitalocean_ssh_key\\\" \\\"hp\\\" {\\n  name = \\\"Daniel Stacjonarny\\\"\\n}\\n# Create a web server\\nresource \\\"digitalocean_droplet\\\" \\\"web\\\" {\\n  image  = \\\"ubuntu-18-04-x64\\\"\\n  name   = \\\"web-1\\\"\\n  region = \\\"fra1\\\"\\n  size   = \\\"s-1vcpu-1gb\\\"\\n  ssh_keys = [\\n    data.digitalocean_ssh_key.dell.id,\\n    data.digitalocean_ssh_key.yoga.id,\\n    data.digitalocean_ssh_key.hp.id\\n  ]\\n}\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/03/2021-03-04-190447_1353x386_scrot.png\",\"width\":1353,\"height\":386}],[\"code\",{\"code\":\" terraform plan\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/03/2021-03-04-190739_957x755_scrot.png\",\"width\":957,\"height\":755}],[\"code\",{\"code\":\"terraform apply -auto-approve\"}],[\"code\",{\"code\":\" terraform show terraform.tfstate\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/03/2021-03-04-191308_966x505_scrot.png\",\"width\":966,\"height\":505}],[\"code\",{\"code\":\"ssh -o \\\"StrictHostKeyChecking no\\\" root@164.90.174.250\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/03/2021-03-04-191554_965x446_scrot.png\",\"width\":965,\"height\":446}],[\"code\",{\"code\":\"exit\"}],[\"code\",{\"code\":\" terraform destroy -auto-approve\"}]],\"markups\":[[\"code\"],[\"a\",[\"href\",\"https://registry.terraform.io/providers/digitalocean/digitalocean/latest/docs\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"W scrapingu ważnym czynnikiem jest skala do jakiej możemy rozszerzyć tempo pobierania i przetwarzania danych. Kiedy kilka lat temu pisałem swój pierwszy system, który równolegle zbierał dane używając kilkunastu serwerów, każdy z tych serwerów był przeze mnie \\\"wyklikany\\\" w panelu dostawcy.\"]]],[1,\"p\",[[0,[],0,\"Teraz pokażę w jaki sposób rozstawić serwery z linii poleceń \"],[0,[0],1,\"terraform\"],[0,[],0,\". Dostawcą będzie Digital Ocean, ponieważ w porównaniu ze swoją największą konkurencją ma bardzo korzystne (8-10 razy niższe) ceny transferu sieciowego. \"]]],[10,0],[1,\"p\",[[0,[],0,\"Prezentację przeprowadzimy z systemu \"],[0,[0],1,\"arch\"],[0,[],0,\". \"]]],[1,\"h1\",[[0,[],0,\"Instalacja Terraform\"]]],[1,\"p\",[[0,[],0,\"Nie ma nic bardzej przyjemnego niż instlacja oprogramowania w arch. Aby cieszyć się gotowym do pracy terraformem wystarczy komenda\"]]],[10,1],[1,\"h1\",[[0,[],0,\"Podłączenie dostawcy\"]]],[1,\"p\",[[0,[],0,\"Aby połączyć się z Digital Ocean potrzebujemy tokenu. Jeśli go nie posiadamy, znajdziemy w zakładce API w panelu przycisk \\\"Generate New Token\\\"\"]]],[10,2],[1,\"p\",[[0,[],0,\"Token warto zapisać w \"],[0,[0],1,\"~/.zshrc\"],[0,[],0,\" lub \"],[0,[0],1,\"~/.bashrc\"]]],[10,3],[1,\"p\",[[0,[],0,\"po ponownym wykonaniu tego plik będzie on dostępny we wszystkich tworzonych przez nas projektach.\"]]],[1,\"p\",[[0,[],0,\"Oficjalna dokumentacja pokazuje jak zrobić to przez zmienną \"],[0,[0],1,\"do_token\"]]],[1,\"p\",[[0,[1],1,\"https://registry.terraform.io/providers/digitalocean/digitalocean/latest/docs\"]]],[1,\"p\",[[0,[],0,\"ale nie polecam tego sposobu, ponieważ wymusza on na nas dopisywanie argumentów \"],[0,[0],1,\"-var\"],[0,[],0,\" do poleceń \"],[0,[0],1,\"terraform\"],[0,[],0,\" a podejście prezentowane tutaj oszczędza nam ilość wpisywanych znaków.\"]]],[1,\"p\",[[0,[],0,\"Aby skonfigurować połączenie do Digital Ocean mając token w zmiennych środowiskowych tworzymy plik \"],[0,[0],1,\"provider.tf\"],[0,[],0,\" i wpisujemy do niego:\"]]],[10,4],[1,\"p\",[[0,[],0,\"A następnie wykonujemy komendę inicjalizacyjną\"]]],[10,5],[1,\"h1\",[[0,[],0,\"Rozstawianie serwerów\"]]],[1,\"p\",[[0,[],0,\"Kolejnym krokiem jest zaplanowanie i rozstawienie infrastruktury. W naszym przypadku bedzie ona bardzo prosta. Powinna zawierać dokładnie jeden droplet z kluczami do wszystkich  inoyterów, którymi chcę się na niego logować.\"]]],[1,\"p\",[[0,[],0,\"Tworzymy kolejny plik. Nazwałem go \"],[0,[0],1,\"master.tf\"]]],[10,6],[1,\"p\",[[0,[],0,\"Są to klucze, które znajdziemy w zakładce \\\"Settings -> Security\\\" w panelu Digital Ocean\"]]],[10,7],[1,\"p\",[[0,[],0,\"Wykonanie\"]]],[10,8],[1,\"p\",[[0,[],0,\"Sprawdzi, czy nasza konfiguracja jest ok i pozwoli zobaczyć jak zmieni się architektura po wdrożeniu. W tym przypadku będzie to dodanie jednego serwera - dokładnie tak jak napisaliśmy w konfiguracji\"]]],[10,9],[1,\"p\",[[0,[],0,\"Wdrożenie wykonamy wpisując\"]]],[10,10],[1,\"p\",[[0,[],0,\"Wykonanie tej komendy trwało u mnie \"],[0,[0],1,\"47s\"],[0,[],0,\".\"]]],[1,\"h1\",[[0,[],0,\"Przegląd wyników\"]]],[1,\"p\",[[0,[],0,\"Aby zobaczyć co postawiliśmy wykonujemy polecenie:\"]]],[10,11],[1,\"p\",[[0,[],0,\"Zwraca ono dane na temat zasobów zarządzanych przez \"],[0,[0],1,\"terraform\"]]],[10,12],[1,\"p\",[[0,[],0,\"Najbardziej interesujące jest dla nas \"],[0,[0],1,\"ip\"],[0,[],0,\". W tym przypadku \"],[0,[0],1,\"164.90.174.250\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Na serwer loguję się komendą \"]]],[10,13],[1,\"p\",[[0,[],0,\"Jak widać działa, bo komenda zalogowała nas na serwer \"],[0,[0],1,\"web-1\"],[0,[],0,\" jako \"],[0,[0],1,\"root\"],[0,[],0,\".\"]]],[10,14],[1,\"p\",[[0,[],0,\"Po powrocie do \"],[0,[0],1,\"localhost\"],[0,[],0,\" poleceniem\"]]],[10,15],[1,\"p\",[[0,[],0,\"możemy usunąć wszystkie utworzone droplety komendą\"]]],[10,16],[1,\"p\",[[0,[],0,\"Należy o niej pamiętać po zakończonej pracy, szczególnie jeśli operujemy na dużej skali mocy obliczeniowej!\"]]]],\"ghostVersion\":\"3.0\"}",
            "html": "<p>W scrapingu ważnym czynnikiem jest skala do jakiej możemy rozszerzyć tempo pobierania i przetwarzania danych. Kiedy kilka lat temu pisałem swój pierwszy system, który równolegle zbierał dane używając kilkunastu serwerów, każdy z tych serwerów był przeze mnie \"wyklikany\" w panelu dostawcy.</p><p>Teraz pokażę w jaki sposób rozstawić serwery z linii poleceń <code>terraform</code>. Dostawcą będzie Digital Ocean, ponieważ w porównaniu ze swoją największą konkurencją ma bardzo korzystne (8-10 razy niższe) ceny transferu sieciowego. </p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/03/2021-03-04-184133_1326x925_scrot.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1326\" height=\"925\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/03/2021-03-04-184133_1326x925_scrot.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/2021-03-04-184133_1326x925_scrot.png 1000w, __GHOST_URL__/content/images/2021/03/2021-03-04-184133_1326x925_scrot.png 1326w\" sizes=\"(min-width: 720px) 720px\"><figcaption>https://www.digitalocean.com/pricing/calculator/</figcaption></figure><p>Prezentację przeprowadzimy z systemu <code>arch</code>. </p><h1 id=\"instalacja-terraform\">Instalacja Terraform</h1><p>Nie ma nic bardzej przyjemnego niż instlacja oprogramowania w arch. Aby cieszyć się gotowym do pracy terraformem wystarczy komenda</p><pre><code>yay -S terraform</code></pre><h1 id=\"pod-czenie-dostawcy\">Podłączenie dostawcy</h1><p>Aby połączyć się z Digital Ocean potrzebujemy tokenu. Jeśli go nie posiadamy, znajdziemy w zakładce API w panelu przycisk \"Generate New Token\"</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/03/2021-03-04-185052_1247x416_scrot.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1247\" height=\"416\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/03/2021-03-04-185052_1247x416_scrot.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/2021-03-04-185052_1247x416_scrot.png 1000w, __GHOST_URL__/content/images/2021/03/2021-03-04-185052_1247x416_scrot.png 1247w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Token warto zapisać w <code>~/.zshrc</code> lub <code>~/.bashrc</code></p><pre><code>export DIGITALOCEAN_TOKEN=xxxxxxxxxxxxxxxxxxxxxx\n</code></pre><p>po ponownym wykonaniu tego plik będzie on dostępny we wszystkich tworzonych przez nas projektach.</p><p>Oficjalna dokumentacja pokazuje jak zrobić to przez zmienną <code>do_token</code></p><p><a href=\"https://registry.terraform.io/providers/digitalocean/digitalocean/latest/docs\">https://registry.terraform.io/providers/digitalocean/digitalocean/latest/docs</a></p><p>ale nie polecam tego sposobu, ponieważ wymusza on na nas dopisywanie argumentów <code>-var</code> do poleceń <code>terraform</code> a podejście prezentowane tutaj oszczędza nam ilość wpisywanych znaków.</p><p>Aby skonfigurować połączenie do Digital Ocean mając token w zmiennych środowiskowych tworzymy plik <code>provider.tf</code> i wpisujemy do niego:</p><pre><code>terraform {\n  required_providers {\n    digitalocean = {\n      source = \"digitalocean/digitalocean\"\n      version = \"2.5.1\"\n    }\n  }\n}\n\nprovider \"digitalocean\" {}</code></pre><p>A następnie wykonujemy komendę inicjalizacyjną</p><pre><code>terraform init</code></pre><h1 id=\"rozstawianie-serwer-w\">Rozstawianie serwerów</h1><p>Kolejnym krokiem jest zaplanowanie i rozstawienie infrastruktury. W naszym przypadku bedzie ona bardzo prosta. Powinna zawierać dokładnie jeden droplet z kluczami do wszystkich  inoyterów, którymi chcę się na niego logować.</p><p>Tworzymy kolejny plik. Nazwałem go <code>master.tf</code></p><pre><code>data \"digitalocean_ssh_key\" \"dell\" {\n  name = \"Daniel Laptop Dell\"\n}\ndata \"digitalocean_ssh_key\" \"yoga\" {\n  name = \"Daniel Lenovo Yoga\"\n}\ndata \"digitalocean_ssh_key\" \"hp\" {\n  name = \"Daniel Stacjonarny\"\n}\n# Create a web server\nresource \"digitalocean_droplet\" \"web\" {\n  image  = \"ubuntu-18-04-x64\"\n  name   = \"web-1\"\n  region = \"fra1\"\n  size   = \"s-1vcpu-1gb\"\n  ssh_keys = [\n    data.digitalocean_ssh_key.dell.id,\n    data.digitalocean_ssh_key.yoga.id,\n    data.digitalocean_ssh_key.hp.id\n  ]\n}</code></pre><p>Są to klucze, które znajdziemy w zakładce \"Settings -&gt; Security\" w panelu Digital Ocean</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/03/2021-03-04-190447_1353x386_scrot.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1353\" height=\"386\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/03/2021-03-04-190447_1353x386_scrot.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/2021-03-04-190447_1353x386_scrot.png 1000w, __GHOST_URL__/content/images/2021/03/2021-03-04-190447_1353x386_scrot.png 1353w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Wykonanie</p><pre><code> terraform plan</code></pre><p>Sprawdzi, czy nasza konfiguracja jest ok i pozwoli zobaczyć jak zmieni się architektura po wdrożeniu. W tym przypadku będzie to dodanie jednego serwera - dokładnie tak jak napisaliśmy w konfiguracji</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/03/2021-03-04-190739_957x755_scrot.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"957\" height=\"755\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/03/2021-03-04-190739_957x755_scrot.png 600w, __GHOST_URL__/content/images/2021/03/2021-03-04-190739_957x755_scrot.png 957w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Wdrożenie wykonamy wpisując</p><pre><code>terraform apply -auto-approve</code></pre><p>Wykonanie tej komendy trwało u mnie <code>47s</code>.</p><h1 id=\"przegl-d-wynik-w\">Przegląd wyników</h1><p>Aby zobaczyć co postawiliśmy wykonujemy polecenie:</p><pre><code> terraform show terraform.tfstate</code></pre><p>Zwraca ono dane na temat zasobów zarządzanych przez <code>terraform</code></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/03/2021-03-04-191308_966x505_scrot.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"966\" height=\"505\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/03/2021-03-04-191308_966x505_scrot.png 600w, __GHOST_URL__/content/images/2021/03/2021-03-04-191308_966x505_scrot.png 966w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Najbardziej interesujące jest dla nas <code>ip</code>. W tym przypadku <code>164.90.174.250</code>.</p><p>Na serwer loguję się komendą </p><pre><code>ssh -o \"StrictHostKeyChecking no\" root@164.90.174.250</code></pre><p>Jak widać działa, bo komenda zalogowała nas na serwer <code>web-1</code> jako <code>root</code>.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/03/2021-03-04-191554_965x446_scrot.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"965\" height=\"446\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/03/2021-03-04-191554_965x446_scrot.png 600w, __GHOST_URL__/content/images/2021/03/2021-03-04-191554_965x446_scrot.png 965w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Po powrocie do <code>localhost</code> poleceniem</p><pre><code>exit</code></pre><p>możemy usunąć wszystkie utworzone droplety komendą</p><pre><code> terraform destroy -auto-approve</code></pre><p>Należy o niej pamiętać po zakończonej pracy, szczególnie jeśli operujemy na dużej skali mocy obliczeniowej!</p>",
            "comment_id": "604118a88e39617ce723d8f3",
            "plaintext": "W scrapingu ważnym czynnikiem jest skala do jakiej możemy rozszerzyć tempo\npobierania i przetwarzania danych. Kiedy kilka lat temu pisałem swój pierwszy\nsystem, który równolegle zbierał dane używając kilkunastu serwerów, każdy z tych\nserwerów był przeze mnie \"wyklikany\" w panelu dostawcy.\n\nTeraz pokażę w jaki sposób rozstawić serwery z linii poleceń terraform. Dostawcą\nbędzie Digital Ocean, ponieważ w porównaniu ze swoją największą konkurencją ma\nbardzo korzystne (8-10 razy niższe) ceny transferu sieciowego. \n\nhttps://www.digitalocean.com/pricing/calculator/Prezentację przeprowadzimy z\nsystemu arch. \n\nInstalacja Terraform\nNie ma nic bardzej przyjemnego niż instlacja oprogramowania w arch. Aby cieszyć\nsię gotowym do pracy terraformem wystarczy komenda\n\nyay -S terraform\n\nPodłączenie dostawcy\nAby połączyć się z Digital Ocean potrzebujemy tokenu. Jeśli go nie posiadamy,\nznajdziemy w zakładce API w panelu przycisk \"Generate New Token\"\n\nToken warto zapisać w ~/.zshrc lub ~/.bashrc\n\nexport DIGITALOCEAN_TOKEN=xxxxxxxxxxxxxxxxxxxxxx\n\n\npo ponownym wykonaniu tego plik będzie on dostępny we wszystkich tworzonych\nprzez nas projektach.\n\nOficjalna dokumentacja pokazuje jak zrobić to przez zmienną do_token\n\nhttps://registry.terraform.io/providers/digitalocean/digitalocean/latest/docs\n\nale nie polecam tego sposobu, ponieważ wymusza on na nas dopisywanie argumentów \n-var do poleceń terraform a podejście prezentowane tutaj oszczędza nam ilość\nwpisywanych znaków.\n\nAby skonfigurować połączenie do Digital Ocean mając token w zmiennych\nśrodowiskowych tworzymy plik provider.tf i wpisujemy do niego:\n\nterraform {\n  required_providers {\n    digitalocean = {\n      source = \"digitalocean/digitalocean\"\n      version = \"2.5.1\"\n    }\n  }\n}\n\nprovider \"digitalocean\" {}\n\nA następnie wykonujemy komendę inicjalizacyjną\n\nterraform init\n\nRozstawianie serwerów\nKolejnym krokiem jest zaplanowanie i rozstawienie infrastruktury. W naszym\nprzypadku bedzie ona bardzo prosta. Powinna zawierać dokładnie jeden droplet z\nkluczami do wszystkich  inoyterów, którymi chcę się na niego logować.\n\nTworzymy kolejny plik. Nazwałem go master.tf\n\ndata \"digitalocean_ssh_key\" \"dell\" {\n  name = \"Daniel Laptop Dell\"\n}\ndata \"digitalocean_ssh_key\" \"yoga\" {\n  name = \"Daniel Lenovo Yoga\"\n}\ndata \"digitalocean_ssh_key\" \"hp\" {\n  name = \"Daniel Stacjonarny\"\n}\n# Create a web server\nresource \"digitalocean_droplet\" \"web\" {\n  image  = \"ubuntu-18-04-x64\"\n  name   = \"web-1\"\n  region = \"fra1\"\n  size   = \"s-1vcpu-1gb\"\n  ssh_keys = [\n    data.digitalocean_ssh_key.dell.id,\n    data.digitalocean_ssh_key.yoga.id,\n    data.digitalocean_ssh_key.hp.id\n  ]\n}\n\nSą to klucze, które znajdziemy w zakładce \"Settings -> Security\" w panelu\nDigital Ocean\n\nWykonanie\n\n terraform plan\n\nSprawdzi, czy nasza konfiguracja jest ok i pozwoli zobaczyć jak zmieni się\narchitektura po wdrożeniu. W tym przypadku będzie to dodanie jednego serwera -\ndokładnie tak jak napisaliśmy w konfiguracji\n\nWdrożenie wykonamy wpisując\n\nterraform apply -auto-approve\n\nWykonanie tej komendy trwało u mnie 47s.\n\nPrzegląd wyników\nAby zobaczyć co postawiliśmy wykonujemy polecenie:\n\n terraform show terraform.tfstate\n\nZwraca ono dane na temat zasobów zarządzanych przez terraform\n\nNajbardziej interesujące jest dla nas ip. W tym przypadku 164.90.174.250.\n\nNa serwer loguję się komendą \n\nssh -o \"StrictHostKeyChecking no\" root@164.90.174.250\n\nJak widać działa, bo komenda zalogowała nas na serwer web-1 jako root.\n\nPo powrocie do localhost poleceniem\n\nexit\n\nmożemy usunąć wszystkie utworzone droplety komendą\n\n terraform destroy -auto-approve\n\nNależy o niej pamiętać po zakończonej pracy, szczególnie jeśli operujemy na\ndużej skali mocy obliczeniowej!",
            "feature_image": "__GHOST_URL__/content/images/2021/04/image6-1.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-03-04T17:28:08.000Z",
            "updated_at": "2021-04-07T10:30:29.000Z",
            "published_at": "2021-03-04T18:19:11.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "6052116b8e39617ce723d9c8",
            "uuid": "e19a623f-b817-4987-807c-c61b7699747c",
            "title": "Form Data w Node JS",
            "slug": "form-data-w-node-js",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"node -v > .nvmrc\\nnpm init --yes\\nnpm i -g typescript\\nnpx tsc --init\\nnpm i axios node-fetch chalk @types/node-fetch\\ntouch app.ts \"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://stackoverflow.com/questions/47630163/axios-post-request-to-send-form-data\",\"metadata\":{\"url\":\"https://stackoverflow.com/questions/47630163/axios-post-request-to-send-form-data\",\"title\":\"axios post request to send form data\",\"description\":\"axios POST request is hitting the url on the controller but setting null values to my POJO class, when I go through developer tools in chrome, the payload contains data. What am I doing wrong? Axios\",\"author\":\"Srikanth Gowda\",\"publisher\":\"Stack Overflow\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded\",\"icon\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a\"}}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Wysyłanie żądań HTTP jest podstawową umiejętnością programisty webowego. W tym wpisie pokażemy jak za pomocą przeglądarki oraz node js wysyłać żądania typu \"],[0,[0],1,\"application/x-www-form-urlencoded\"],[0,[],0,\" znane też jako \"],[0,[0],1,\"form data\"],[0,[],0,\" za pomocą biblioteki axios.\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od utworzenia projektu w którym powstaną pliki \"]]],[3,\"ul\",[[[0,[],0,\"app.ts - wysyłka requesta z node js\"]],[[0,[],0,\"index.ts - wysyłka requesta z przeglądarki\"]],[[0,[],0,\"index.html\"]],[[0,[],0,\"catcher.ts - mikroserwis do przyjmowania i logowania danych o żądaniach http.\"]]]],[1,\"p\",[[0,[],0,\"Zaczniemy od backendu.\"]]],[1,\"h2\",[[0,[],0,\"Wysyłanie form data z node js\"]]],[1,\"p\",[[0,[],0,\"Inicjalizujemy projekt wykonując komendy:\"]]],[10,0],[1,\"p\",[[0,[],0,\"W \"],[0,[0],1,\"tsconfig.json\"],[0,[],0,\" wymieniamy \"],[0,[0],1,\"target\"],[0,[],0,\" na \"],[0,[0],1,\"ESNEXT\"],[0,[],0,\".\"]]],[1,\"p\",[]],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "html": "<p>Wysyłanie żądań HTTP jest podstawową umiejętnością programisty webowego. W tym wpisie pokażemy jak za pomocą przeglądarki oraz node js wysyłać żądania typu <code>application/x-www-form-urlencoded</code> znane też jako <code>form data</code> za pomocą biblioteki axios.</p><p>Zaczniemy od utworzenia projektu w którym powstaną pliki </p><ul><li>app.ts - wysyłka requesta z node js</li><li>index.ts - wysyłka requesta z przeglądarki</li><li>index.html</li><li>catcher.ts - mikroserwis do przyjmowania i logowania danych o żądaniach http.</li></ul><p>Zaczniemy od backendu.</p><h2 id=\"wysy-anie-form-data-z-node-js\">Wysyłanie form data z node js</h2><p>Inicjalizujemy projekt wykonując komendy:</p><pre><code>node -v &gt; .nvmrc\nnpm init --yes\nnpm i -g typescript\nnpx tsc --init\nnpm i axios node-fetch chalk @types/node-fetch\ntouch app.ts </code></pre><p>W <code>tsconfig.json</code> wymieniamy <code>target</code> na <code>ESNEXT</code>.</p><p></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://stackoverflow.com/questions/47630163/axios-post-request-to-send-form-data\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">axios post request to send form data</div><div class=\"kg-bookmark-description\">axios POST request is hitting the url on the controller but setting null values to my POJO class, when I go through developer tools in chrome, the payload contains data. What am I doing wrong? Axios</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v&#x3D;c78bd457575a\"><span class=\"kg-bookmark-author\">Stack Overflow</span><span class=\"kg-bookmark-publisher\">Srikanth Gowda</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v&#x3D;73d79a89bded\"></div></a></figure>",
            "comment_id": "6052116b8e39617ce723d9c8",
            "plaintext": "Wysyłanie żądań HTTP jest podstawową umiejętnością programisty webowego. W tym\nwpisie pokażemy jak za pomocą przeglądarki oraz node js wysyłać żądania typu \napplication/x-www-form-urlencoded znane też jako form data za pomocą biblioteki\naxios.\n\nZaczniemy od utworzenia projektu w którym powstaną pliki \n\n * app.ts - wysyłka requesta z node js\n * index.ts - wysyłka requesta z przeglądarki\n * index.html\n * catcher.ts - mikroserwis do przyjmowania i logowania danych o żądaniach http.\n\nZaczniemy od backendu.\n\nWysyłanie form data z node js\nInicjalizujemy projekt wykonując komendy:\n\nnode -v > .nvmrc\nnpm init --yes\nnpm i -g typescript\nnpx tsc --init\nnpm i axios node-fetch chalk @types/node-fetch\ntouch app.ts \n\nW tsconfig.json wymieniamy target na ESNEXT.\n\n\n\naxios post request to send form dataaxios POST request is hitting the url on\nthe\ncontroller but setting null values to my POJO class, when I go through\ndeveloper\ntools in chrome, the payload contains data. What am I doing wrong? AxiosStack\nOverflowSrikanth Gowda\n[https://stackoverflow.com/questions/47630163/axios-post-request-to-send-form-data]",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-03-17T14:25:47.000Z",
            "updated_at": "2021-03-18T12:32:13.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60705d372013ee207d135482",
            "uuid": "5d49ebe4-5e32-4350-8a60-c9ab5692acf4",
            "title": "Najlepsze metody web-scrapingu",
            "slug": "najlepsze-metody-web-skrapingu",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Zanim rozpoczniesz rozmowę o możliwościach, technologii i nowoczesnych metodach scrapingu stron internetowych, zadbaj o sformułowanie problemu.\"]]],[1,\"h2\",[[0,[],0,\"Sformułowanie problemu\"]]],[1,\"p\",[[0,[],0,\"Stała optymalizacja zasobów internetowych dla urządzeń mobilnych, rosnących szybkości internetowych, rozwiązania technologiczne na poziomie hardware i oprogramowania, a także projektantów wyszukujących w sieci Worldwide, takich jak widzisz ją dzisiaj. Mianowicie - kolorowe, kontrast, zatłoczone i absolutnie bezużyteczne (czasami szkodliwe) informacje. Są  to różne techniki i technologie w realizacji stron internetowych i jest głównym problemem, który należy rozwiązać podczas organizowania dostępu do danych.\"]]],[1,\"p\",[[0,[],0,\"Dostęp do treści docelowej można zorganizować w dwóch głównych kierunkach:\"]]],[1,\"p\",[[0,[],0,\"Korzystając z interfejsu API, gdy właściciele informacji przekazują go użytkownikom na podstawie osobistych odsetek - subskrypcji, wysyłek, programów partnerskich itp.\"]]],[1,\"p\",[[0,[],0,\"Bez użycia API - Urząd strony internetowej przez skrobanie (chyba że jest to przewidziane przez ich kod).\"]]],[1,\"p\",[[0,[],0,\"Pierwszy kierunek jest ograniczony tylko przez środki pieniężne, a konsument nie doświadcza trudności w zakresie realizacji technicznej. Dane uzyskane przez API są wyraźnie zorganizowane i znormalizowane. Na przykład w formatach XML lub JSON.\"]]],[1,\"p\",[[0,[],0,\"Drugim kierunkiem jest symulowanie przeglądarki - zasługuje na większą uwagę i jest rodzajem \\\"wyzwania\\\" dla deweloperów i matematyków. Automatyczne przetwarzanie tekstu przy użyciu sztucznej inteligencji, analizy semantycznej itp. - Wszystko to można nazwać kolosalnym przełomem technologicznym wymagającym rozwoju, świadomości i właściwej oceny.\"]]],[1,\"h3\",[[0,[],0,\"Ręczne kopiowanie zawartości \"]]],[1,\"p\",[[0,[],0,\"Najłatwiejszą metodą scrapingu jest ręczne wyszukiwanie żądanych informacji, a następnie kopiowanie i utrzymanie miejsca docelowego (lokalizację w dokumencie, publikując nasz własny zasób, umieszczenie w bazie danych itp.).\"]]],[1,\"p\",[[0,[],0,\"Ta metoda jest odpowiednia dla małych blogów lub drobnych sklepów z skąpym asortymentem tego samego rodzaju towarów.\"]]],[1,\"p\",[[0,[],0,\"Korzyści:\"]]],[3,\"ul\",[[[0,[],0,\"Wysokiej jakości treść i jego docelowa adaptacja dla potrzeb konsumenta.\"]],[[0,[],0,\"Wysoka prędkość wyszukiwania.\"]]]],[1,\"p\",[[0,[],0,\"Niedogodności:\"]]],[3,\"ul\",[[[0,[],0,\"Powtarzalna manualna praca droga w utrzymaniu\"]]]],[1,\"p\",[[0,[],0,\"Możliwości osoby są znacznie ograniczone do zasobów fizycznych, znajomość kula docelowej i banalnych umiejętności wyszukiwania online (nie każdy może skutecznie korzystać z narzędzi usług wyszukiwania).\"]]],[1,\"p\",[[0,[],0,\"Osoba podlega różnym wpływom zewnętrznym (psychologicznym, fizycznym itp.), A to niekorzystnie wpływa na stabilność swojej pracy i wartości jego usług.\"]]],[1,\"p\",[[0,[],0,\"Scraping do kilkuset jakościowych wyników dziennie.\"]]],[1,\"h3\",[[0,[],0,\"Wyrażenia regularne i wychwytywanie dopasowania w tekście\"]]],[1,\"p\",[[0,[],0,\"Bardzo prosta technika przetwarzania danych tekstowych, a jednocześnie potężna metoda wyodrębniania informacji z Internetu. Zwłaszcza w połączeniu z użyciem poleceń UNIX Capture (na przykład \\\"Curl\\\"). Wyrażenia regularne są obecne w wielu językach programowania (na przykład, implementujemy skrobanie internetowe za pomocą tej metody dla kilku projektów na temat Pythona i Ruby).\"]]],[1,\"p\",[[0,[],0,\"Przedstawiona metoda jest odpowiednia dla projektów, które są angażowane w automatyczne monitorowanie kilku źródeł informacji. Przypuśćmy, skrobanie poszczególnych fragmentów (nazwa produktu, jego koszty, numery telefonów i adresy e-mail itp.). W praktyce wdrażanie skrobaka dla jednej witryny może trwać około godziny. Prawda tylko wtedy, gdy zasób docelowy nie zawiera pułapek w formie renderowania JS.\"]]],[1,\"p\",[[0,[],0,\"Zalety:\"]]],[3,\"ul\",[[[0,[],0,\"Jeśli znasz już regularne wyrażenia co najmniej jednego języka programowania, wdrożenie niniejszej decyzji zajmie minimalny czas.\"]],[[0,[],0,\"Wyrażenia regularne umożliwiają szybkie odróżnienie dużej liczby niepotrzebnych drobnych \\\"niewyraźnych\\\" z korpusu wyniku, bez łamania głównej zawartości (na przykład, oczyścić pozostałości kodu HTML).\"]],[[0,[],0,\"Wyrażenia regularne są obsługiwane przez prawie wszystkie języki programowania. I co najważniejsze, ich składnia z języka do języka prawie nie zmienia się. Pozwala to wykonać bezbolesną migrację projektów w językach z większą wydajnością i jasnością Kodeksu (na przykład, z PHP na Ruby - ostatnio takich klientów stają się coraz bardziej).\"]]]],[1,\"p\",[[0,[],0,\"Niedogodności:\"]]],[3,\"ul\",[[[0,[],0,\"Wyrażenia regularne mogą zamienić się w układankę dla tych, którzy ich nie wykorzystali. W tym przypadku lepiej jest natychmiast skontaktować się z specjalistami. Z reguły pojawiają się problemy podczas integracji rozwiązań w jednym języku w innym lub podczas migracji projektów do innego języka programowania.\"]],[[0,[],0,\"Wyrażenia regularne są często bardzo złożone do czytania i analizy. Czasami oparte na specyfiki przetworzonych informacji są one nadmiernie rozciągane.\"]],[[0,[],0,\"Jeśli kod HTML został zmieniony na zasobach docelowym lub dodano nowy znacznik, najprawdopodobniej zostanie zmieniona i wyrażenie regularne (w przeciwnym razie istnieje duże ryzyko \\\"złamanej\\\" treści).\"]]]],[1,\"h3\",[[0,[],0,\"Zapytania HTTP (analiza kodu HTML)\"]]],[1,\"p\",[[0,[],0,\"Ta metoda umożliwia odbieranie stron dynamicznych i statycznych, wysyłając żądania HTTP do serwerów zdalnych. Wykorzystuje gniazda programowania i demontuje odebrane odpowiedzi z (jeśli to konieczne) wstępnie przygotowanych danych na pojemnikach docelowych (ich klas i identyfikator).\"]]],[1,\"p\",[[0,[],0,\"Narzędzie jest odpowiednie dla większości projektów. W realizacji jest nieco bardziej skompensowany, ale jest to kompensowane przez możliwość szybkiego uzyskania dużej ilości danych.\"]]],[1,\"p\",[[0,[],0,\"Korzyści:\"]]],[3,\"ul\",[[[0,[],0,\"Umożliwia uzyskanie oryginalnych stron w formie odpowiedzi HTTP.\"]],[[0,[],0,\"Ogromna liczba wyników ograniczona tylko przez zasoby serwera i szybkość Internetu.\"]]]],[1,\"p\",[[0,[],0,\"Niedogodności:\"]]],[3,\"ul\",[[[0,[],0,\"Wymaga przetwarzania otrzymanych odpowiedzi - wyniki mogą zawierać wiele zbędnych.\"]],[[0,[],0,\"Wiele witryn jest wyposażonych w ochronę przed podobnymi \\\"robotami\\\" (jako produkcji z sytuacji, powinieneś generować dodatkowe informacje o serwisie w nagłówku żądania HTTP, jednak nie wszystkie witryny można oszukać w ten sposób).\"]],[[0,[],0,\"Wysokie prawdopodobieństwo ma być zakazane przez administratora miejsca docelowego lub zautomatyzowanego systemu ochrony, gdy dziwne metodycznie powtarzające się \\\"odsetki\\\" pojawia się w zasobie. Praktyka pokazuje, że ilość i częstotliwość żądań może przekraczać możliwości ludzkie.\"]],[[0,[],0,\"Zdalny serwer może być wyłączony lub zajęty w momencie wysyłania żądania. W rezultacie pojawia się prawdopodobieństwo dużej liczby błędów limitujących.\"]]]],[1,\"h3\",[[0,[],0,\"Analiza struktury DOM generowanej dynamicznie\"]]],[1,\"p\",[[0,[],0,\"Dynamiczna zawartość jest jednym z problematycznych momentów skrobania internetowego. Jak sobie z tym poradzić? Aby go uzyskać, możesz użyć dowolnej pełnej przeglądarki, która odtwarza dynamiczną zawartość i skrypt po stronie klienta. Są gotowe darmowe wtyczki, które dają dobre wyniki. Istotnym ograniczeniem jest niska wydajność. Możemy uzyskiwać tylko jeden wynik w danym momencie. W rzeczywistości takie wtyczki rozwiązują wiele problemów i pozwalają zapomnieć o rzeczach takich jak ciasteczka, wyrażenia regularne, http itp.\"]]],[1,\"p\",[[0,[],0,\"Analiza struktury DOM opartej na skutkach ekranowych jest odpowiednia dla dużych i średnich projektów zainteresowanych zarówno jak iw ilości ekstrahowanych informacji. Wdrożenie automatyzacji tej metody jest dość złożone z technicznego punktu widzenia. Jednak nasz zespół udało się osiągnąć cel, a od projektu do projektu poprawia opracowaną funkcjonalność. Aby to zrobić, emulator przeglądarki został napisany i obsługiwacz \\\"wirtualny ekran\\\" z inteligentnym wyszukiwaniem węzłów w strukturze DOM.\"]]],[1,\"p\",[[0,[],0,\"Korzyści:\"]]],[3,\"ul\",[[[0,[],0,\"Uzyskać dynamiczną zawartość.\"]],[[0,[],0,\"Automatyzacja. Umożliwia uzyskanie wysokiej jakości treści w dużych ilościach.\"]],[[0,[],0,\"Możliwość wdrażania rozwiązań komercyjnych. Metoda pozwala łatwo cieszyć się wsparciem do rozwiązywania problemów z zakupionym / wynajmowanym oprogramowaniem.\"]]]],[1,\"p\",[[0,[],0,\"Niedogodności:\"]]],[3,\"ul\",[[[0,[],0,\"Złożoność i ładowanie serwera podczas automatyzacji sprawia, że ​​proces jest dość intensywny zasobów, zarówno w kosztach opracowywania, jak i serwera.\"]],[[0,[],0,\"Kompletność wdrażania. Dla osób niebędących specjalistami jest praktycznie niemożliwe, ponieważ Wymaga dokładnej znajomości zasobów sprzętowych, podstawy rozwoju sieci i doskonałego posiadania co najmniej jednego z języków programowania serwera.\"]],[[0,[],0,\"Większość wdrażania tej metody ma zastosowanie tylko na podstawie komercyjnej, a koszty takich produktów nie ma jeszcze tendencji do zmniejszenia.\"]]]],[1,\"h3\",[[0,[],0,\"Metody sztucznej inteligencji\"]]],[1,\"p\",[[0,[],0,\"Wyobraź sobie, że stoisz przed zadaniem scrapingu setek lub tysięcy witryn. Jednocześnie mają inny układ i napisane w różnych językach i ramach. W takiej sytuacji racjonalne środki zainwestują w rozwój złożonych systemów sztucznej inteligencji i / lub ontologii (ta metoda opiera się na teorii, że wszystkie witryny można podzielić na zajęcia i grupy o podobnej strukturze i zestawu technologii ).\"]]],[1,\"p\",[[0,[],0,\"Korzyści:\"]]],[3,\"ul\",[[[0,[],0,\"Po utworzeniu złożonego systemu pozwala uzyskać najwyższą możliwą zawartość z ogromnej liczby domen, nawet pomimo małych zmian na stronach (inteligentny system dostosuje możliwe niedokładności). Ocena jakości dla 150 tysięcy domen będzie średnio od 75% do 93% (weryfikowana na badaniach Jetrubia w realizowanym systemie).\"]],[[0,[],0,\"Metoda umożliwia normalizowanie wyniku uzyskanego ze wszystkich źródeł w strukturze bazy danych.\"]],[[0,[],0,\"Pomimo faktu, że taki system potrzebuje stałego wsparcia (na poziomie monitorowania), z możliwymi awariami, wymaga niewielkiej interwencji w kodzie\"]]]],[1,\"p\",[[0,[],0,\"Niedogodności:\"]]],[3,\"ul\",[[[0,[],0,\"Kompleksowa realizacja \\\"silnika\\\", wymagająca wysokiego poziomu wiedzy w matematyce, statystykach, sferze logiki rozmytej.\"]],[[0,[],0,\"Wysoki koszt rozwoju.\"]],[[0,[],0,\"Podobne koszty systemu wsparcia i szkolenia.\"]]]],[1,\"p\",[[0,[],0,\"Praktyka subskrypcji gotowych projektów komercyjnych. Odnosi się to do ograniczonej liczby żądań i ich wysokich kosztów (zauważamy, że twój własny rozwój szybko się opłaca).\"]]],[1,\"p\",[[0,[],0,\"Musisz podać moduły śledzenia błędów, serwerów ważności danych i serwerów proxy kopii zapasowych do możliwej witryny docelowej \\\"czarnej arkusza\\\".\"]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Zanim rozpoczniesz rozmowę o możliwościach, technologii i nowoczesnych metodach scrapingu stron internetowych, zadbaj o sformułowanie problemu.</p><h2 id=\"sformu%C5%82owanie-problemu\">Sformułowanie problemu</h2><p>Stała optymalizacja zasobów internetowych dla urządzeń mobilnych, rosnących szybkości internetowych, rozwiązania technologiczne na poziomie hardware i oprogramowania, a także projektantów wyszukujących w sieci Worldwide, takich jak widzisz ją dzisiaj. Mianowicie - kolorowe, kontrast, zatłoczone i absolutnie bezużyteczne (czasami szkodliwe) informacje. Są  to różne techniki i technologie w realizacji stron internetowych i jest głównym problemem, który należy rozwiązać podczas organizowania dostępu do danych.</p><p>Dostęp do treści docelowej można zorganizować w dwóch głównych kierunkach:</p><p>Korzystając z interfejsu API, gdy właściciele informacji przekazują go użytkownikom na podstawie osobistych odsetek - subskrypcji, wysyłek, programów partnerskich itp.</p><p>Bez użycia API - Urząd strony internetowej przez skrobanie (chyba że jest to przewidziane przez ich kod).</p><p>Pierwszy kierunek jest ograniczony tylko przez środki pieniężne, a konsument nie doświadcza trudności w zakresie realizacji technicznej. Dane uzyskane przez API są wyraźnie zorganizowane i znormalizowane. Na przykład w formatach XML lub JSON.</p><p>Drugim kierunkiem jest symulowanie przeglądarki - zasługuje na większą uwagę i jest rodzajem \"wyzwania\" dla deweloperów i matematyków. Automatyczne przetwarzanie tekstu przy użyciu sztucznej inteligencji, analizy semantycznej itp. - Wszystko to można nazwać kolosalnym przełomem technologicznym wymagającym rozwoju, świadomości i właściwej oceny.</p><h3 id=\"r%C4%99czne-kopiowanie-zawarto%C5%9Bci\">Ręczne kopiowanie zawartości </h3><p>Najłatwiejszą metodą scrapingu jest ręczne wyszukiwanie żądanych informacji, a następnie kopiowanie i utrzymanie miejsca docelowego (lokalizację w dokumencie, publikując nasz własny zasób, umieszczenie w bazie danych itp.).</p><p>Ta metoda jest odpowiednia dla małych blogów lub drobnych sklepów z skąpym asortymentem tego samego rodzaju towarów.</p><p>Korzyści:</p><ul><li>Wysokiej jakości treść i jego docelowa adaptacja dla potrzeb konsumenta.</li><li>Wysoka prędkość wyszukiwania.</li></ul><p>Niedogodności:</p><ul><li>Powtarzalna manualna praca droga w utrzymaniu</li></ul><p>Możliwości osoby są znacznie ograniczone do zasobów fizycznych, znajomość kula docelowej i banalnych umiejętności wyszukiwania online (nie każdy może skutecznie korzystać z narzędzi usług wyszukiwania).</p><p>Osoba podlega różnym wpływom zewnętrznym (psychologicznym, fizycznym itp.), A to niekorzystnie wpływa na stabilność swojej pracy i wartości jego usług.</p><p>Scraping do kilkuset jakościowych wyników dziennie.</p><h3 id=\"wyra%C5%BCenia-regularne-i-wychwytywanie-dopasowania-w-tek%C5%9Bcie\">Wyrażenia regularne i wychwytywanie dopasowania w tekście</h3><p>Bardzo prosta technika przetwarzania danych tekstowych, a jednocześnie potężna metoda wyodrębniania informacji z Internetu. Zwłaszcza w połączeniu z użyciem poleceń UNIX Capture (na przykład \"Curl\"). Wyrażenia regularne są obecne w wielu językach programowania (na przykład, implementujemy skrobanie internetowe za pomocą tej metody dla kilku projektów na temat Pythona i Ruby).</p><p>Przedstawiona metoda jest odpowiednia dla projektów, które są angażowane w automatyczne monitorowanie kilku źródeł informacji. Przypuśćmy, skrobanie poszczególnych fragmentów (nazwa produktu, jego koszty, numery telefonów i adresy e-mail itp.). W praktyce wdrażanie skrobaka dla jednej witryny może trwać około godziny. Prawda tylko wtedy, gdy zasób docelowy nie zawiera pułapek w formie renderowania JS.</p><p>Zalety:</p><ul><li>Jeśli znasz już regularne wyrażenia co najmniej jednego języka programowania, wdrożenie niniejszej decyzji zajmie minimalny czas.</li><li>Wyrażenia regularne umożliwiają szybkie odróżnienie dużej liczby niepotrzebnych drobnych \"niewyraźnych\" z korpusu wyniku, bez łamania głównej zawartości (na przykład, oczyścić pozostałości kodu HTML).</li><li>Wyrażenia regularne są obsługiwane przez prawie wszystkie języki programowania. I co najważniejsze, ich składnia z języka do języka prawie nie zmienia się. Pozwala to wykonać bezbolesną migrację projektów w językach z większą wydajnością i jasnością Kodeksu (na przykład, z PHP na Ruby - ostatnio takich klientów stają się coraz bardziej).</li></ul><p>Niedogodności:</p><ul><li>Wyrażenia regularne mogą zamienić się w układankę dla tych, którzy ich nie wykorzystali. W tym przypadku lepiej jest natychmiast skontaktować się z specjalistami. Z reguły pojawiają się problemy podczas integracji rozwiązań w jednym języku w innym lub podczas migracji projektów do innego języka programowania.</li><li>Wyrażenia regularne są często bardzo złożone do czytania i analizy. Czasami oparte na specyfiki przetworzonych informacji są one nadmiernie rozciągane.</li><li>Jeśli kod HTML został zmieniony na zasobach docelowym lub dodano nowy znacznik, najprawdopodobniej zostanie zmieniona i wyrażenie regularne (w przeciwnym razie istnieje duże ryzyko \"złamanej\" treści).</li></ul><h3 id=\"zapytania-http-analiza-kodu-html\">Zapytania HTTP (analiza kodu HTML)</h3><p>Ta metoda umożliwia odbieranie stron dynamicznych i statycznych, wysyłając żądania HTTP do serwerów zdalnych. Wykorzystuje gniazda programowania i demontuje odebrane odpowiedzi z (jeśli to konieczne) wstępnie przygotowanych danych na pojemnikach docelowych (ich klas i identyfikator).</p><p>Narzędzie jest odpowiednie dla większości projektów. W realizacji jest nieco bardziej skompensowany, ale jest to kompensowane przez możliwość szybkiego uzyskania dużej ilości danych.</p><p>Korzyści:</p><ul><li>Umożliwia uzyskanie oryginalnych stron w formie odpowiedzi HTTP.</li><li>Ogromna liczba wyników ograniczona tylko przez zasoby serwera i szybkość Internetu.</li></ul><p>Niedogodności:</p><ul><li>Wymaga przetwarzania otrzymanych odpowiedzi - wyniki mogą zawierać wiele zbędnych.</li><li>Wiele witryn jest wyposażonych w ochronę przed podobnymi \"robotami\" (jako produkcji z sytuacji, powinieneś generować dodatkowe informacje o serwisie w nagłówku żądania HTTP, jednak nie wszystkie witryny można oszukać w ten sposób).</li><li>Wysokie prawdopodobieństwo ma być zakazane przez administratora miejsca docelowego lub zautomatyzowanego systemu ochrony, gdy dziwne metodycznie powtarzające się \"odsetki\" pojawia się w zasobie. Praktyka pokazuje, że ilość i częstotliwość żądań może przekraczać możliwości ludzkie.</li><li>Zdalny serwer może być wyłączony lub zajęty w momencie wysyłania żądania. W rezultacie pojawia się prawdopodobieństwo dużej liczby błędów limitujących.</li></ul><h3 id=\"analiza-struktury-dom-generowanej-dynamicznie\">Analiza struktury DOM generowanej dynamicznie</h3><p>Dynamiczna zawartość jest jednym z problematycznych momentów skrobania internetowego. Jak sobie z tym poradzić? Aby go uzyskać, możesz użyć dowolnej pełnej przeglądarki, która odtwarza dynamiczną zawartość i skrypt po stronie klienta. Są gotowe darmowe wtyczki, które dają dobre wyniki. Istotnym ograniczeniem jest niska wydajność. Możemy uzyskiwać tylko jeden wynik w danym momencie. W rzeczywistości takie wtyczki rozwiązują wiele problemów i pozwalają zapomnieć o rzeczach takich jak ciasteczka, wyrażenia regularne, http itp.</p><p>Analiza struktury DOM opartej na skutkach ekranowych jest odpowiednia dla dużych i średnich projektów zainteresowanych zarówno jak iw ilości ekstrahowanych informacji. Wdrożenie automatyzacji tej metody jest dość złożone z technicznego punktu widzenia. Jednak nasz zespół udało się osiągnąć cel, a od projektu do projektu poprawia opracowaną funkcjonalność. Aby to zrobić, emulator przeglądarki został napisany i obsługiwacz \"wirtualny ekran\" z inteligentnym wyszukiwaniem węzłów w strukturze DOM.</p><p>Korzyści:</p><ul><li>Uzyskać dynamiczną zawartość.</li><li>Automatyzacja. Umożliwia uzyskanie wysokiej jakości treści w dużych ilościach.</li><li>Możliwość wdrażania rozwiązań komercyjnych. Metoda pozwala łatwo cieszyć się wsparciem do rozwiązywania problemów z zakupionym / wynajmowanym oprogramowaniem.</li></ul><p>Niedogodności:</p><ul><li>Złożoność i ładowanie serwera podczas automatyzacji sprawia, że ​​proces jest dość intensywny zasobów, zarówno w kosztach opracowywania, jak i serwera.</li><li>Kompletność wdrażania. Dla osób niebędących specjalistami jest praktycznie niemożliwe, ponieważ Wymaga dokładnej znajomości zasobów sprzętowych, podstawy rozwoju sieci i doskonałego posiadania co najmniej jednego z języków programowania serwera.</li><li>Większość wdrażania tej metody ma zastosowanie tylko na podstawie komercyjnej, a koszty takich produktów nie ma jeszcze tendencji do zmniejszenia.</li></ul><h3 id=\"metody-sztucznej-inteligencji\">Metody sztucznej inteligencji</h3><p>Wyobraź sobie, że stoisz przed zadaniem scrapingu setek lub tysięcy witryn. Jednocześnie mają inny układ i napisane w różnych językach i ramach. W takiej sytuacji racjonalne środki zainwestują w rozwój złożonych systemów sztucznej inteligencji i / lub ontologii (ta metoda opiera się na teorii, że wszystkie witryny można podzielić na zajęcia i grupy o podobnej strukturze i zestawu technologii ).</p><p>Korzyści:</p><ul><li>Po utworzeniu złożonego systemu pozwala uzyskać najwyższą możliwą zawartość z ogromnej liczby domen, nawet pomimo małych zmian na stronach (inteligentny system dostosuje możliwe niedokładności). Ocena jakości dla 150 tysięcy domen będzie średnio od 75% do 93% (weryfikowana na badaniach Jetrubia w realizowanym systemie).</li><li>Metoda umożliwia normalizowanie wyniku uzyskanego ze wszystkich źródeł w strukturze bazy danych.</li><li>Pomimo faktu, że taki system potrzebuje stałego wsparcia (na poziomie monitorowania), z możliwymi awariami, wymaga niewielkiej interwencji w kodzie</li></ul><p>Niedogodności:</p><ul><li>Kompleksowa realizacja \"silnika\", wymagająca wysokiego poziomu wiedzy w matematyce, statystykach, sferze logiki rozmytej.</li><li>Wysoki koszt rozwoju.</li><li>Podobne koszty systemu wsparcia i szkolenia.</li></ul><p>Praktyka subskrypcji gotowych projektów komercyjnych. Odnosi się to do ograniczonej liczby żądań i ich wysokich kosztów (zauważamy, że twój własny rozwój szybko się opłaca).</p><p>Musisz podać moduły śledzenia błędów, serwerów ważności danych i serwerów proxy kopii zapasowych do możliwej witryny docelowej \"czarnej arkusza\".</p>",
            "comment_id": "60705d372013ee207d135482",
            "plaintext": "Zanim rozpoczniesz rozmowę o możliwościach, technologii i nowoczesnych metodach\nscrapingu stron internetowych, zadbaj o sformułowanie problemu.\n\nSformułowanie problemu\nStała optymalizacja zasobów internetowych dla urządzeń mobilnych, rosnących\nszybkości internetowych, rozwiązania technologiczne na poziomie hardware i\noprogramowania, a także projektantów wyszukujących w sieci Worldwide, takich jak\nwidzisz ją dzisiaj. Mianowicie - kolorowe, kontrast, zatłoczone i absolutnie\nbezużyteczne (czasami szkodliwe) informacje. Są  to różne techniki i technologie\nw realizacji stron internetowych i jest głównym problemem, który należy\nrozwiązać podczas organizowania dostępu do danych.\n\nDostęp do treści docelowej można zorganizować w dwóch głównych kierunkach:\n\nKorzystając z interfejsu API, gdy właściciele informacji przekazują go\nużytkownikom na podstawie osobistych odsetek - subskrypcji, wysyłek, programów\npartnerskich itp.\n\nBez użycia API - Urząd strony internetowej przez skrobanie (chyba że jest to\nprzewidziane przez ich kod).\n\nPierwszy kierunek jest ograniczony tylko przez środki pieniężne, a konsument nie\ndoświadcza trudności w zakresie realizacji technicznej. Dane uzyskane przez API\nsą wyraźnie zorganizowane i znormalizowane. Na przykład w formatach XML lub\nJSON.\n\nDrugim kierunkiem jest symulowanie przeglądarki - zasługuje na większą uwagę i\njest rodzajem \"wyzwania\" dla deweloperów i matematyków. Automatyczne\nprzetwarzanie tekstu przy użyciu sztucznej inteligencji, analizy semantycznej\nitp. - Wszystko to można nazwać kolosalnym przełomem technologicznym wymagającym\nrozwoju, świadomości i właściwej oceny.\n\nRęczne kopiowanie zawartości \nNajłatwiejszą metodą scrapingu jest ręczne wyszukiwanie żądanych informacji, a\nnastępnie kopiowanie i utrzymanie miejsca docelowego (lokalizację w dokumencie,\npublikując nasz własny zasób, umieszczenie w bazie danych itp.).\n\nTa metoda jest odpowiednia dla małych blogów lub drobnych sklepów z skąpym\nasortymentem tego samego rodzaju towarów.\n\nKorzyści:\n\n * Wysokiej jakości treść i jego docelowa adaptacja dla potrzeb konsumenta.\n * Wysoka prędkość wyszukiwania.\n\nNiedogodności:\n\n * Powtarzalna manualna praca droga w utrzymaniu\n\nMożliwości osoby są znacznie ograniczone do zasobów fizycznych, znajomość kula\ndocelowej i banalnych umiejętności wyszukiwania online (nie każdy może\nskutecznie korzystać z narzędzi usług wyszukiwania).\n\nOsoba podlega różnym wpływom zewnętrznym (psychologicznym, fizycznym itp.), A to\nniekorzystnie wpływa na stabilność swojej pracy i wartości jego usług.\n\nScraping do kilkuset jakościowych wyników dziennie.\n\nWyrażenia regularne i wychwytywanie dopasowania w tekście\nBardzo prosta technika przetwarzania danych tekstowych, a jednocześnie potężna\nmetoda wyodrębniania informacji z Internetu. Zwłaszcza w połączeniu z użyciem\npoleceń UNIX Capture (na przykład \"Curl\"). Wyrażenia regularne są obecne w wielu\njęzykach programowania (na przykład, implementujemy skrobanie internetowe za\npomocą tej metody dla kilku projektów na temat Pythona i Ruby).\n\nPrzedstawiona metoda jest odpowiednia dla projektów, które są angażowane w\nautomatyczne monitorowanie kilku źródeł informacji. Przypuśćmy, skrobanie\nposzczególnych fragmentów (nazwa produktu, jego koszty, numery telefonów i\nadresy e-mail itp.). W praktyce wdrażanie skrobaka dla jednej witryny może trwać\nokoło godziny. Prawda tylko wtedy, gdy zasób docelowy nie zawiera pułapek w\nformie renderowania JS.\n\nZalety:\n\n * Jeśli znasz już regularne wyrażenia co najmniej jednego języka programowania,\n   wdrożenie niniejszej decyzji zajmie minimalny czas.\n * Wyrażenia regularne umożliwiają szybkie odróżnienie dużej liczby\n   niepotrzebnych drobnych \"niewyraźnych\" z korpusu wyniku, bez łamania głównej\n   zawartości (na przykład, oczyścić pozostałości kodu HTML).\n * Wyrażenia regularne są obsługiwane przez prawie wszystkie języki\n   programowania. I co najważniejsze, ich składnia z języka do języka prawie nie\n   zmienia się. Pozwala to wykonać bezbolesną migrację projektów w językach z\n   większą wydajnością i jasnością Kodeksu (na przykład, z PHP na Ruby -\n   ostatnio takich klientów stają się coraz bardziej).\n\nNiedogodności:\n\n * Wyrażenia regularne mogą zamienić się w układankę dla tych, którzy ich nie\n   wykorzystali. W tym przypadku lepiej jest natychmiast skontaktować się z\n   specjalistami. Z reguły pojawiają się problemy podczas integracji rozwiązań w\n   jednym języku w innym lub podczas migracji projektów do innego języka\n   programowania.\n * Wyrażenia regularne są często bardzo złożone do czytania i analizy. Czasami\n   oparte na specyfiki przetworzonych informacji są one nadmiernie rozciągane.\n * Jeśli kod HTML został zmieniony na zasobach docelowym lub dodano nowy\n   znacznik, najprawdopodobniej zostanie zmieniona i wyrażenie regularne (w\n   przeciwnym razie istnieje duże ryzyko \"złamanej\" treści).\n\nZapytania HTTP (analiza kodu HTML)\nTa metoda umożliwia odbieranie stron dynamicznych i statycznych, wysyłając\nżądania HTTP do serwerów zdalnych. Wykorzystuje gniazda programowania i\ndemontuje odebrane odpowiedzi z (jeśli to konieczne) wstępnie przygotowanych\ndanych na pojemnikach docelowych (ich klas i identyfikator).\n\nNarzędzie jest odpowiednie dla większości projektów. W realizacji jest nieco\nbardziej skompensowany, ale jest to kompensowane przez możliwość szybkiego\nuzyskania dużej ilości danych.\n\nKorzyści:\n\n * Umożliwia uzyskanie oryginalnych stron w formie odpowiedzi HTTP.\n * Ogromna liczba wyników ograniczona tylko przez zasoby serwera i szybkość\n   Internetu.\n\nNiedogodności:\n\n * Wymaga przetwarzania otrzymanych odpowiedzi - wyniki mogą zawierać wiele\n   zbędnych.\n * Wiele witryn jest wyposażonych w ochronę przed podobnymi \"robotami\" (jako\n   produkcji z sytuacji, powinieneś generować dodatkowe informacje o serwisie w\n   nagłówku żądania HTTP, jednak nie wszystkie witryny można oszukać w ten\n   sposób).\n * Wysokie prawdopodobieństwo ma być zakazane przez administratora miejsca\n   docelowego lub zautomatyzowanego systemu ochrony, gdy dziwne metodycznie\n   powtarzające się \"odsetki\" pojawia się w zasobie. Praktyka pokazuje, że ilość\n   i częstotliwość żądań może przekraczać możliwości ludzkie.\n * Zdalny serwer może być wyłączony lub zajęty w momencie wysyłania żądania. W\n   rezultacie pojawia się prawdopodobieństwo dużej liczby błędów limitujących.\n\nAnaliza struktury DOM generowanej dynamicznie\nDynamiczna zawartość jest jednym z problematycznych momentów skrobania\ninternetowego. Jak sobie z tym poradzić? Aby go uzyskać, możesz użyć dowolnej\npełnej przeglądarki, która odtwarza dynamiczną zawartość i skrypt po stronie\nklienta. Są gotowe darmowe wtyczki, które dają dobre wyniki. Istotnym\nograniczeniem jest niska wydajność. Możemy uzyskiwać tylko jeden wynik w danym\nmomencie. W rzeczywistości takie wtyczki rozwiązują wiele problemów i pozwalają\nzapomnieć o rzeczach takich jak ciasteczka, wyrażenia regularne, http itp.\n\nAnaliza struktury DOM opartej na skutkach ekranowych jest odpowiednia dla dużych\ni średnich projektów zainteresowanych zarówno jak iw ilości ekstrahowanych\ninformacji. Wdrożenie automatyzacji tej metody jest dość złożone z technicznego\npunktu widzenia. Jednak nasz zespół udało się osiągnąć cel, a od projektu do\nprojektu poprawia opracowaną funkcjonalność. Aby to zrobić, emulator\nprzeglądarki został napisany i obsługiwacz \"wirtualny ekran\" z inteligentnym\nwyszukiwaniem węzłów w strukturze DOM.\n\nKorzyści:\n\n * Uzyskać dynamiczną zawartość.\n * Automatyzacja. Umożliwia uzyskanie wysokiej jakości treści w dużych\n   ilościach.\n * Możliwość wdrażania rozwiązań komercyjnych. Metoda pozwala łatwo cieszyć się\n   wsparciem do rozwiązywania problemów z zakupionym / wynajmowanym\n   oprogramowaniem.\n\nNiedogodności:\n\n * Złożoność i ładowanie serwera podczas automatyzacji sprawia, że ​​proces jest\n   dość intensywny zasobów, zarówno w kosztach opracowywania, jak i serwera.\n * Kompletność wdrażania. Dla osób niebędących specjalistami jest praktycznie\n   niemożliwe, ponieważ Wymaga dokładnej znajomości zasobów sprzętowych,\n   podstawy rozwoju sieci i doskonałego posiadania co najmniej jednego z języków\n   programowania serwera.\n * Większość wdrażania tej metody ma zastosowanie tylko na podstawie\n   komercyjnej, a koszty takich produktów nie ma jeszcze tendencji do\n   zmniejszenia.\n\nMetody sztucznej inteligencji\nWyobraź sobie, że stoisz przed zadaniem scrapingu setek lub tysięcy witryn.\nJednocześnie mają inny układ i napisane w różnych językach i ramach. W takiej\nsytuacji racjonalne środki zainwestują w rozwój złożonych systemów sztucznej\ninteligencji i / lub ontologii (ta metoda opiera się na teorii, że wszystkie\nwitryny można podzielić na zajęcia i grupy o podobnej strukturze i zestawu\ntechnologii ).\n\nKorzyści:\n\n * Po utworzeniu złożonego systemu pozwala uzyskać najwyższą możliwą zawartość z\n   ogromnej liczby domen, nawet pomimo małych zmian na stronach (inteligentny\n   system dostosuje możliwe niedokładności). Ocena jakości dla 150 tysięcy domen\n   będzie średnio od 75% do 93% (weryfikowana na badaniach Jetrubia w\n   realizowanym systemie).\n * Metoda umożliwia normalizowanie wyniku uzyskanego ze wszystkich źródeł w\n   strukturze bazy danych.\n * Pomimo faktu, że taki system potrzebuje stałego wsparcia (na poziomie\n   monitorowania), z możliwymi awariami, wymaga niewielkiej interwencji w kodzie\n\nNiedogodności:\n\n * Kompleksowa realizacja \"silnika\", wymagająca wysokiego poziomu wiedzy w\n   matematyce, statystykach, sferze logiki rozmytej.\n * Wysoki koszt rozwoju.\n * Podobne koszty systemu wsparcia i szkolenia.\n\nPraktyka subskrypcji gotowych projektów komercyjnych. Odnosi się to do\nograniczonej liczby żądań i ich wysokich kosztów (zauważamy, że twój własny\nrozwój szybko się opłaca).\n\nMusisz podać moduły śledzenia błędów, serwerów ważności danych i serwerów proxy\nkopii zapasowych do możliwej witryny docelowej \"czarnej arkusza\".",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-09T13:57:11.000Z",
            "updated_at": "2021-04-09T19:48:53.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607c1b012fb35425592d0770",
            "uuid": "056b7f14-00f4-44e9-af3a-83e2b636a965",
            "title": "Ruby on Rails - szybkie wprowadzenie",
            "slug": "rails",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"curl -sSL https://get.rvm.io | bash -s stable --rails\",\"language\":\"bash\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://rvm.io/rvm/install\",\"metadata\":{\"url\":\"https://rvm.io/rvm/install\",\"title\":\"RVM: Ruby Version Manager - Installing RVM\",\"description\":null,\"author\":null,\"publisher\":\"Fastly\",\"thumbnail\":\"https://rvm.io/images/logo.png\",\"icon\":null}}],[\"code\",{\"code\":\"rails new weblog && cd weblog\",\"language\":\"bash\"}],[\"code\",{\"code\":\"rails generate scaffold post title:string body:text\",\"language\":\"bash\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-14-15-08.png\",\"width\":602,\"height\":601}],[\"code\",{\"code\":\"class CreatePosts < ActiveRecord::Migration[6.1]\\n  def change\\n    create_table :posts do |t|\\n      t.string :title\\n      t.text :body\\n\\n      t.timestamps\\n    end\\n  end\\nend\\n\",\"language\":\"ruby\"}],[\"code\",{\"code\":\"rails db:migrate\",\"language\":\"bash\"}],[\"hr\",{}],[\"hr\",{}],[\"code\",{\"code\":\"rails server\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-14-33-12.png\",\"width\":263,\"height\":154}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-14-37-18.png\",\"width\":633,\"height\":488}],[\"code\",{\"code\":\"http POST localhost:3000/posts.json title=\\\"Hej\\\" body=\\\"Ok\\\"\"}],[\"code\",{\"code\":\"Can't verify CSRF token authenticity.\"}],[\"code\",{\"code\":\"class ApplicationController < ActionController::Base\\n  protect_from_forgery with: :null_session\\nend\",\"language\":\"ruby\"}],[\"code\",{\"code\":\"http POST localhost:3000/posts.json title=ok\\n\"}],[\"code\",{\"code\":\"http POST localhost:3000/posts.json body=ok\\n\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-14-52-53.png\",\"width\":238,\"height\":62}],[\"code\",{\"code\":\"class Post < ApplicationRecord\\n  validates_presence_of :title\\nend\\n\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-19-14-41-18.png\",\"width\":507,\"height\":341}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-19-14-42-01.png\",\"width\":588,\"height\":370}],[\"code\",{\"code\":\"rails console\"}],[\"code\",{\"code\":\"Post.first\"}],[\"code\",{\"code\":\"Post.all\"}],[\"code\",{\"code\":\"Post.where(created_at: Date.yesterday..Date.tomorrow)\"}],[\"code\",{\"code\":\"Post.where(created_at: Date.yesterday..Date.tomorrow).to_sql\"}],[\"code\",{\"code\":\"Post.create! title: 'Hello', body: 'World'\\n\"}],[\"code\",{\"code\":\"rails generate resource comment post:references body:text\"}],[\"code\",{\"code\":\"rails generate\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://guides.rubyonrails.org/command_line.html#bin-rails-generate\",\"metadata\":{\"url\":\"https://guides.rubyonrails.org/command_line.html#bin-rails-generate\",\"title\":\"The Rails Command Line — Ruby on Rails Guides\",\"description\":\"The Rails Command LineAfter reading this guide, you will know: How to create a Rails application. How to generate models, controllers, database migrations, and unit tests. How to start a development server. How to experiment with objects through an interactive shell.\",\"author\":null,\"publisher\":\"Ruby on Rails Guides\",\"thumbnail\":\"https://avatars.githubusercontent.com/u/4223\",\"icon\":\"https://guides.rubyonrails.org/images/favicon.ico\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-15-09-56-1.png\",\"width\":644,\"height\":380}],[\"code\",{\"code\":\"class CreateComments < ActiveRecord::Migration[6.1]\\n  def change\\n    create_table :comments do |t|\\n      t.references :post, null: false, foreign_key: true\\n      t.text :body\\n\\n      t.timestamps\\n    end\\n  end\\nend\\n\",\"language\":\"ruby\"}],[\"code\",{\"code\":\"rails db:migrate\"}],[\"code\",{\"code\":\"Rails.application.routes.draw do\\n  resources :posts\\n  resources :comments\\nend\",\"language\":\"ruby\"}],[\"code\",{\"code\":\"Rails.application.routes.draw do\\n  resources :posts do\\n    resources :comments\\n  end\\nend\",\"language\":\"ruby\"}],[\"code\",{\"code\":\"rails routes\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-15-40-23-2.png\",\"width\":1262,\"height\":756}],[\"code\",{\"code\":\"class Comment < ApplicationRecord\\n  belongs_to :post\\nend\\n\"}],[\"code\",{\"code\":\"class Post < ApplicationRecord\\n  has_many :comments\\n  validates_presence_of :title\\nend\\n\"}],[\"code\",{\"code\":\"Post.second.comments.create! body: \\\"My first comment to second post\\\"\"}],[\"code\",{\"code\":\"<p><%= comment.body %> -- <%= comment.created_at.to_s(:long) %></p>\"}],[\"code\",{\"code\":\"<%= form_for([ @post, Comment.new], remote: true) do |form| %>\\n  Your comment: <br/>\\n  <%= form.text_area :body, size: '50x2' %><br/>\\n  <%= form.submit %>\\n<% end %>\"}],[\"code\",{\"code\":\"<hr>\\n\\n<h2>Comments (<span id=\\\"count\\\"><%= @post.comments.count %></span>)</h2>\\n\\n<div id=\\\"comments\\\">\\n   <%= render @post.comments %>\\n</div>\\n\\n<%= render 'comments/new', post: @post %>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-16-19-22-1.png\",\"width\":450,\"height\":288}],[\"code\",{\"code\":\"class CommentsController < ApplicationController\\n  before_action :set_post\\n\\n  def create\\n    @post.comments.create! comments_params\\n    redirect_to @post\\n  end\\n\\n  private\\n\\n  def set_post\\n    @post = Post.find(params[:post_id])\\n  end\\n\\n  def comments_params\\n    params.required(:comment).permit(:body)\\n  end\\n\\nend\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-09-47-58.png\",\"width\":517,\"height\":332}],[\"code\",{\"code\":\"redirect_to @post\"}],[\"code\",{\"code\":\"    respond_to do |format|\\n      if @post.save\\n        format.html { redirect_to @post, notice: \\\"Comment was successfully created.\\\" }\\n        format.json { render :show, status: :created, location: @post }\\n      else\\n        format.html { render :new, status: :unprocessable_entity }\\n        format.json { render json: @post.errors, status: :unprocessable_entity }\\n      end\\n    end\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-18-28-49-1.png\",\"width\":708,\"height\":476}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/rails/jbuilder\",\"metadata\":{\"url\":\"https://github.com/rails/jbuilder\",\"title\":\"rails/jbuilder\",\"description\":\"Jbuilder: generate JSON objects with a Builder-style DSL - rails/jbuilder\",\"author\":\"rails\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/9d3c523e683d19d728cc3cf514eeedf49593ddb0bea84432b4c012c57bea8189/rails/jbuilder\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"code\",{\"code\":\"json.partial! \\\"posts/post\\\", post: @post\\njson.comments @post.comments, :id, :body, :created_at\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-18-36-24-1.png\",\"width\":500,\"height\":339}],[\"code\",{\"code\":\"  def create\\n    comment = @post.comments.create! comments_params\\n\\n    respond_to do |format|\\n      if @post.save\\n        format.html { redirect_to @post, notice: \\\"Comment was successfully created.\\\" }\\n        format.json { render json: comment.to_json(include: [:post]) }\\n      else\\n        format.html { render :new, status: :unprocessable_entity }\\n        format.json { render json: @post.errors, status: :unprocessable_entity }\\n      end\\n    end\\n\\n  end\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-11-48-56.png\",\"width\":420,\"height\":276}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://dev.to/caicindy87/rendering-json-in-a-rails-api-25fd\",\"metadata\":{\"url\":\"https://dev.to/caicindy87/rendering-json-in-a-rails-api-25fd\",\"title\":\"Rendering JSON in a Rails API\",\"description\":\"To go over rendering JSON in a Rails API, I will use an example. Example: Models: doctor,...\",\"author\":\"Cindy\",\"publisher\":\"DEV Community\",\"thumbnail\":\"https://dev.to/social_previews/article/323041.png\",\"icon\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--t7tVouP9--/c_limit,f_png,fl_progressive,q_80,w_192/https://practicaldev-herokuapp-com.freetls.fastly.net/assets/devlogo-pwa-512.png\"}}],[\"code\",{\"code\":\"rails generate mailer comments submitted\"}],[\"code\",{\"code\":\"class CommentsMailer < ApplicationMailer\\n  def submitted(comment)\\n    @comment = comment\\n\\n    mail to: \\\"gustaw.daniel@gmail.com\\\", subject: 'New comment'\\n  end\\nend\"}],[\"code\",{\"code\":\"<h1>New comment on post: <%= @comment.post.title %></h1>\\n\\n<%= render @comment %>\"}],[\"code\",{\"code\":\"New comment on post: <%= @comment.post.title %>: <%= @comment.body %>\"}],[\"code\",{\"code\":\"CommentsMailer.submitted\"}],[\"code\",{\"code\":\"CommentsMailer.submitted Comment.first\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-19-17-35-1.png\",\"width\":532,\"height\":214}],[\"code\",{\"code\":\"CommentsMailer.submitted(comment).deliver_later\"}],[\"code\",{\"code\":\"class CommentsController < ApplicationController\\n  before_action :set_post\\n\\n  def create\\n    comment = @post.comments.create! comments_params\\n    CommentsMailer.submitted(comment).deliver_later\\n\\n    respond_to do |format|\\n      if @post.save\\n        format.html { redirect_to @post, notice: \\\"Comment was successfully created.\\\" }\\n        format.json { render json: comment.to_json(include: [:post]) }\\n      else\\n        format.html { render :new, status: :unprocessable_entity }\\n        format.json { render json: @post.errors, status: :unprocessable_entity }\\n      end\\n    end\\n\\n  end\\n\\n  private\\n\\n  def set_post\\n    @post = Post.find(params[:post_id])\\n  end\\n\\n  def comments_params\\n    params.required(:comment).permit(:body)\\n  end\\n\\nend\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-19-33-26-1.png\",\"width\":474,\"height\":651,\"cardWidth\":\"wide\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://guides.rubyonrails.org/action_mailer_basics.html\",\"metadata\":{\"url\":\"https://guides.rubyonrails.org/action_mailer_basics.html\",\"title\":\"Action Mailer Basics — Ruby on Rails Guides\",\"description\":\"Action Mailer BasicsThis guide provides you with all you need to get started in sending emails from and to your application, and many internals of Action Mailer. It also covers how to test your mailers.After reading this guide, you will know: How to send email within a Rails application. How to gene…\",\"author\":null,\"publisher\":\"Ruby on Rails Guides\",\"thumbnail\":\"https://avatars.githubusercontent.com/u/4223\",\"icon\":\"https://guides.rubyonrails.org/images/favicon.ico\"}}],[\"code\",{\"code\":\"rails generate channel comments\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-12-05-34.png\",\"width\":567,\"height\":139}],[\"code\",{\"code\":\"class CommentsChannel < ApplicationCable::Channel\\n  def subscribed\\n    # stream_from \\\"some_channel\\\"\\n  end\\n\\n  def unsubscribed\\n    # Any cleanup needed when channel is unsubscribed\\n  end\\nend\\n\",\"language\":\"ruby\"}],[\"code\",{\"code\":\"  def self.broadcast(comment)\\n    broadcast_to comment.post, comment:\\n      CommentsController.render(partial: 'comments/comment', locals: { comment: comment })\\n  end\"}],[\"code\",{\"code\":\"  def subscribed\\n    stream_for Post.last\\n  end\"}],[\"code\",{\"code\":\"CommentsChannel.broadcast(comment)\"}],[\"code\",{\"code\":\"    received(data) {\\n        const commentsElement = document.querySelector('#comments');\\n        const countElement = document.querySelector('#count');\\n\\n        if (commentsElement) {\\n            commentsElement.innerHTML += data.comment\\n        }\\n        if (countElement) {\\n            countElement.innerHTML = String(1 + parseInt(countElement.innerHTML))\\n        }\\n    }\"}],[\"embed\",{\"url\":\"https://youtu.be/cVoUsrTlTm4\",\"html\":\"<iframe width=\\\"200\\\" height=\\\"150\\\" src=\\\"https://www.youtube.com/embed/cVoUsrTlTm4?feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\",\"metadata\":{\"title\":\"Cable in Ruby on Rails\",\"author_name\":\"gustawdaniel\",\"author_url\":\"https://www.youtube.com/user/gustawdaniel\",\"height\":150,\"width\":200,\"version\":\"1.0\",\"provider_name\":\"YouTube\",\"provider_url\":\"https://www.youtube.com/\",\"thumbnail_height\":360,\"thumbnail_width\":480,\"thumbnail_url\":\"https://i.ytimg.com/vi/cVoUsrTlTm4/hqdefault.jpg\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.tutorialspoint.com/ruby-on-rails/index.htm\",\"metadata\":{\"url\":\"https://www.tutorialspoint.com/ruby-on-rails/index.htm\",\"title\":\"Ruby on Rails Tutorial - Tutorialspoint\",\"description\":\"Ruby on Rails Tutorial - Ruby on Rails is an extremely productive web application framework written in Ruby by David Heinemeier Hansson. This tutorial gives you a complete understanding\",\"author\":null,\"publisher\":\"Ruby on Rails Tutorial\",\"thumbnail\":\"https://www.tutorialspoint.com/videotutorials/images/loader.gif\",\"icon\":\"https://www.tutorialspoint.com/favicon.ico\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://rubyonrails.org/\",\"metadata\":{\"url\":\"https://rubyonrails.org\",\"title\":\"Ruby on Rails\",\"description\":\"A web-application framework that includes everything needed to create database-backed web applications according to the Model-View-Controller (MVC) pattern.\",\"author\":null,\"publisher\":\"Ruby on Rails\",\"thumbnail\":\"https://avatars.githubusercontent.com/u/4223\",\"icon\":null}}]],\"markups\":[[\"code\"],[\"a\",[\"href\",\"http://127.0.0.1:3000/posts\"]],[\"a\",[\"href\",\"http://localhost:3000/rails/mailers/comments_mailer/submitted\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"W roku 2019 przepisywałem pewien system medyczny z Rails na PHP, w 2021 z Rails na NodeJS. Być może ty też spotykasz się z systemami opartymi na Rails, które tracą utrzymanie. To wprowadzenie pomoże Ci szybko zapoznać się z podstawami tego frameworka.\"]]],[1,\"p\",[[0,[],0,\"Napiszemy w nim bloga całkowicie od zera. Zaznaczę, że nie znam dobrze ani Ruby ani Rails, więc zamiast obszernego wprowadzenia mamy tu odtworzenie mojego procesu uczenia się.\"]]],[1,\"p\",[[0,[],0,\"Założenia:\"]]],[3,\"ul\",[[[0,[],0,\"używamy linuxa (arch)\"]]]],[1,\"h2\",[[0,[],0,\"Postawienie aplikacji - CRUD\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od instalacji odpowiedniej wersji ruby.\"]]],[10,0],[1,\"p\",[[0,[0],1,\"rvm\"],[0,[],0,\" jest narzędziem analogicznym do \"],[0,[0],1,\"nvm\"],[0,[],0,\" - pozwala zarządzać wersją interpretera co jest wyjątkowo przydatne przy pracy z systemami, które używają różnych wersji interpreterów. Możesz o nim poczytać tu:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Tworzymy aplikację poleceniem\"]]],[10,2],[1,\"p\",[[0,[],0,\"Ta komenda zajmuje dużo czasu, ponieważ wymaga instalacji wszystkich paczek \"],[0,[0],1,\"gem\"],[0,[],0,\" i kompilacji \"],[0,[0],1,\"node-sass\"],[0,[],0,\" . \"]]],[1,\"p\",[[0,[],0,\"Następnym krokiem jest wygenerowanie automatycznie kodu do wykonywania operacji CRUD na poście. Posty będą miały tytuł i zawartość.\"]]],[10,3],[1,\"p\",[[0,[],0,\"Ta komenda powoduje wygenerowanie się sporej ilości plików:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Jednym z nich jest migracja na bazie danych, która zapisana w \"],[0,[0],1,\"db/migrate/20210418121400_create_posts.rb\"],[0,[],0,\" wygląda tak:\"]]],[10,5],[1,\"p\",[[0,[],0,\"Aby zsynchronizować bazę danych z wynikiem tej migracji wpisujemy\"]]],[10,6],[1,\"p\",[[0,[],0,\"Tu może się pojawić pytanie: \\\"Jaką bazę danych?\\\". W pliku \"],[0,[0],1,\"config/database.yml\"],[0,[],0,\" możemy zobaczyć konfigurację z której wynika, że domyślnie jest to \"],[0,[0],1,\"sqlite\"],[0,[],0,\". W pliku \"],[0,[0],1,\"db/schema.rb\"],[0,[],0,\" jest schemat bazy. \"]]],[10,7],[1,\"p\",[[0,[],0,\"To jest dobre miejsce na dygresję. Migrując systemy oparte na Ruby on Rails zastanawiałem się dlaczego środowisko produkcyjne ma \\\"sqlite\\\", myślałem, że ktoś celowo tak to skonfigurował. Okazuje się, że wystarczyło nie zmienić konfiguracji w tym pliku. Innym problemem, który zaprzątał mi głowę dwa lata temu, było pole \\\"updated_at\\\" w tabelach, które nie obsługiwały edycji. Widząc \\\"updated_at\\\" i nie mając dokumentacji myślałem, że istnieje proces edycji tych tabel, jednak to również jest wynik domyślnej konfiguracji \\\"rails\\\", który wszędzie wrzuca te kolumny.\"]]],[10,8],[1,\"p\",[[0,[],0,\"Żeby wystartować server używamy komendy\"]]],[10,9],[1,\"p\",[[0,[],0,\"Ogromną zaletą rails jest, że już teraz możemy korzystać z działającego CRUD pod linkiem \"]]],[1,\"p\",[[0,[1],1,\"http://127.0.0.1:3000/posts\"]]],[1,\"p\",[[0,[],0,\"Po wytworzeniu posta ręcznie dostajemy:\"]]],[10,10],[1,\"p\",[[0,[],0,\"Co jeszcze przyjemniejsze mamy też od razu \\\"api\\\" pod adresem \"],[0,[0],1,\"/posts.json\"]]],[10,11],[1,\"p\",[[0,[],0,\"Niestety próba utworzenia posta przez API \"]]],[10,12],[1,\"p\",[[0,[],0,\"kończy się błędem\"]]],[10,13],[1,\"p\",[[0,[],0,\"Żeby wyłączyć protekcję \\\"CSRF\\\" w pliku \"],[0,[0],1,\"app/controllers/application_controller.rb\"],[0,[],0,\" konfigurujemy opcję \"],[0,[0],1,\"protect_from_forgery\"],[0,[],0,\" \"]]],[10,14],[1,\"p\",[[0,[],0,\"Teraz zapis postów przez API działa. Zarówno \"]]],[10,15],[1,\"p\",[[0,[],0,\"jak i \"]]],[10,16],[1,\"p\",[[0,[],0,\"zapiszą swoje posty bez walidacji ich poprawności.\"]]],[10,17],[1,\"p\",[[0,[],0,\"Aby wymusić obecność parametru \"],[0,[0],1,\"title\"],[0,[],0,\" w poście, w pliku \"],[0,[0],1,\"app/models/post.rb\"],[0,[],0,\" dodajemy flagę \"],[0,[0],1,\"validates_presence_of\"]]],[10,18],[1,\"p\",[[0,[],0,\"Dzięki niej  niemożliwe będzie dodawanie postów bez tytułu zarówno na stronie\"]]],[10,19],[1,\"p\",[[0,[],0,\"jak i przez API\"]]],[10,20],[1,\"h2\",[[0,[],0,\"Debugowanie - Rails Console\"]]],[1,\"p\",[[0,[],0,\"Bardzo przydatnym narzędziem w pracy z Ruby on Rails jest konsola dostępna po wpisaniu polecenia:\"]]],[10,21],[1,\"p\",[[0,[],0,\"Pozwala ona na interaktywny dostęp do danych za pomocą języka Ruby i zdefiniowanych w Rails obiektów. Na przykład pierwszy post zobaczymy wpisując\"]]],[10,22],[1,\"p\",[[0,[],0,\"Żeby dostać wszystkie posty piszemy\"]]],[10,23],[1,\"p\",[[0,[],0,\"Posty utworzone od wczoraj do jutra dostaniemy pisząc\"]]],[10,24],[1,\"p\",[[0,[],0,\"Łatwo można przekształcić to do formy zapytania SQL dodając własność \"],[0,[0],1,\"to_sql\"],[0,[],0,\" na końcu\"]]],[10,25],[1,\"p\",[[0,[],0,\"Aby utworzyć nowy post piszemy \"]]],[10,26],[1,\"h2\",[[0,[],0,\"Relacje między tabelami\"]]],[1,\"p\",[[0,[],0,\"Typowym przykładem relacji względem postów są komentarze. Nie potrzebujemy dla nich takich samych kontrolerów i widoków jak dla postów, dlatego do generowania zamiast \"],[0,[0],1,\"scaffold\"],[0,[],0,\" użyjemy flagi \"],[0,[0],1,\"resource\"],[0,[],0,\".\"]]],[10,27],[1,\"p\",[[0,[],0,\"Pełną listę dostępnych generatorów zobaczymy wpisując polecenie:\"]]],[10,28],[1,\"p\",[[0,[],0,\"lub czytając dokumentację\"]]],[10,29],[1,\"p\",[[0,[],0,\"Tym czasem wrócimy do plików wygenerowanych dzięki opcji \"],[0,[0],1,\"resource\"],[0,[],0,\".\"]]],[10,30],[1,\"p\",[[0,[],0,\"Ponownie powstała tutaj migracja tym razem o zawartości:\"]]],[10,31],[1,\"p\",[[0,[],0,\"Aby ją wykonać wpisujemy\"]]],[10,32],[1,\"p\",[[0,[],0,\"Zajmijmy się teraz routingiem. Nie ma sensu nigdy pytać o wszystkie komentarze. Zawsze są one powiązane z postem, którego dotyczą. Zatem w pliku \"],[0,[0],1,\"config/routes.yml\"],[0,[],0,\" zastępujemy występujące obok siebie \"]]],[10,33],[1,\"p\",[[0,[],0,\"na konfigurację mówiącą, żeby komentarze były zagnieżdżone w poście\"]]],[10,34],[1,\"p\",[[0,[],0,\"Wyświetlenie routingu jest możliwe dzięki poleceniu:\"]]],[10,35],[10,36],[1,\"p\",[[0,[],0,\"Co do kierunku relacji, to w tym momencie komentarze należą do postów co opisano w pliku \"],[0,[0],1,\"app/models/comment.rb\"]]],[10,37],[1,\"p\",[[0,[],0,\"Ale posty nie mają oznaczonej relacji z komentarzami, co naprawimy dodając \"],[0,[0],1,\"has_many\"],[0,[],0,\" do \"],[0,[0],1,\"app/models/post.rb\"]]],[10,38],[1,\"p\",[[0,[],0,\"W konsoli możemy utworzyć teraz przykładowy komentarz\"]]],[10,39],[1,\"p\",[[0,[],0,\"Żeby wyświetlić komentarze i móc je dodawać napiszemy pomocnicze fragmenty widoków (partials). \"],[0,[0],1,\"app/views/comments/_comment.html.erb\"],[0,[],0,\" posłuży nam do wyświetlania jednego komentarza \"]]],[10,40],[1,\"p\",[[0,[],0,\"Natomiast \"],[0,[0],1,\"app/views/comments/_new.html.erb\"],[0,[],0,\" będzie formularzem do tworzenia komentarza\"]]],[10,41],[1,\"p\",[[0,[],0,\"Załączymy je w widoku pojedynczego postu dołączając do pliku \"],[0,[0],1,\"app/views/posts/shwo.html.erb\"],[0,[],0,\" kod\"]]],[10,42],[1,\"p\",[[0,[],0,\"Teraz nasz widok postu będzie wyglądała następująco\"]]],[10,43],[1,\"p\",[[0,[],0,\"Mimo, że wygląda jak gotowy do działania, to funkcja dodawania komentarzy wciąż nie jest dostępna. Przygotowaliśmy jedynie widok, ale brakuje logiki, która obsłużyła by zapisywanie komentarzy do bazy i łączenie ich z postami.\"]]],[1,\"p\",[[0,[],0,\"Aby ją dołączyć musimy obsłużyć tworzenie komentarzy w kontrolerze \"],[0,[0],1,\"app/controllers/comments_controller.rb\"],[0,[],0,\" \"]]],[10,44],[1,\"p\",[[0,[],0,\"Przyjrzyjmy mu się uważnie. Zaczyna się od opcji \"],[0,[0],1,\"before_action\"],[0,[],0,\", która ustawia post na podstawie parametru z adresu \"],[0,[0],1,\"url\"],[0,[],0,\". Następnie w \"],[0,[0],1,\"create\"],[0,[],0,\" używamy tego posta aby do niego utworzyć komentarz, jego parametry pochodzą z \"],[0,[0],1,\"comments_params\"],[0,[],0,\", które pobiera je z ciała żądania.\"]]],[1,\"p\",[[0,[],0,\"Następnie następuje przekierowanie do strony z postami. Na stronie działa to bardzo dobrze.\"]]],[10,45],[1,\"p\",[[0,[],0,\"Ale jeśli chcemy tworzyć posty z poziomu API. to za każdym razem będąc przekierowani do postu zobaczymy go bez komentarzy. Jeśli zastąpimy\"]]],[10,46],[1,\"p\",[[0,[],0,\"w kontrolerze przez instrukcje analogiczne jak dla posta\"]]],[10,47],[1,\"p\",[[0,[],0,\"dostaniemy błąd\"]]],[10,48],[1,\"p\",[[0,[],0,\"Jest tak dlatego, że teraz komentarze wymagają aby nadać im strukturę przy układaniu ich w plik JSON. Jest to rozwiązane dzięki fantastycznej bibliotece \"],[0,[0],1,\"jbuilder\"],[0,[],0,\".\"]]],[10,49],[1,\"p\",[[0,[],0,\"Tworząc plik \"],[0,[0],1,\"app/views/comments/show.json.jbuilder\"],[0,[],0,\" o treści\"]]],[10,50],[1,\"p\",[[0,[],0,\"skonfigurujemy serwer, aby po utworzeniu komentarza odpowiadał widokiem posta z listą wszystkich odpowiadających mu komentarzy. Jest to widok odpowiadający temu co widzimy w wersji HTML, choć nie zgodny z zasadami REST.\"]]],[10,51],[1,\"p\",[[0,[],0,\"Jeśli chcieli byśmy wyświetlić ten konkretny komentarz i możemy użyć składni\"]]],[10,52],[1,\"p\",[[0,[],0,\"w kontrolerze. Wtedy w widoku odpowiedzi zobaczymy komentarz wraz z postem.\"]]],[10,53],[1,\"p\",[[0,[],0,\"Więcej o formatowaniu można przeczytać tutaj:\"]]],[10,54],[1,\"h2\",[[0,[],0,\"Wysyłka e-maili\"]]],[1,\"p\",[[0,[],0,\"Bardzo częstą funkcją w serwisach internetowych jest wysyłanie e-maili w reakcji na jakieś zdarzenia. Zamiast pisać kod ponownie skorzystamy z generatora:\"]]],[10,55],[1,\"p\",[[0,[],0,\"Jest to e-mailer, który wysyła powitanie. Pierwszą rzeczą, jaką zrobimy będzie konfiguracja danych jakie będzie wstrzykiwał do szablonów. W pliku \"],[0,[0],1,\"comments_mailer.rb\"],[0,[],0,\" piszemy kod:\"]]],[10,56],[1,\"p\",[[0,[],0,\"W \"],[0,[0],1,\"app/views/comments_mailer\"],[0,[],0,\" mamy dwa pliki z szablonami. Dla widoku HTML jest to plik \"],[0,[0],1,\"submitted.html.erb\"],[0,[],0,\". Zmodyfikujemy go tak, żeby używając wcześniej zdefiniowanego partiala pokazywał nowy komentarz:\"]]],[10,57],[1,\"p\",[[0,[],0,\"W pliku \"],[0,[0],1,\"submitted.text.erb\"],[0,[],0,\" nie możemy użyć już \"],[0,[0],1,\"render\"],[0,[],0,\" dlatego uprościmy widok tekstowy do formy:\"]]],[10,58],[1,\"p\",[[0,[],0,\"Niesamowite w Rails jest to, że mamy gotowy widok do podglądu tych e-maili bez konieczności ich wysyłania. Aby z niego skorzystać musimy tylko wskazać komentarz, który wyświetlimy. W tym celu w pliku \"],[0,[0],1,\"test/mailers/previews/comments_mailer_preview.rb\"],[0,[],0,\" linię\"]]],[10,59],[1,\"p\",[[0,[],0,\"zmieniamy na\"]]],[10,60],[1,\"p\",[[0,[],0,\" Pod adresem\"]]],[1,\"p\",[[0,[2],1,\"http://localhost:3000/rails/mailers/comments_mailer/submitted\"]]],[1,\"p\",[[0,[],0,\"Możemy zobaczyć podgląd tego e-maila\"]]],[10,61],[1,\"p\",[[0,[],0,\"Nie możemy jednak oczekiwać, że ten e-mail będzie od razu wysyłany. Aby dołączyć jego wysyłanie musimy dodać linię\"]]],[10,62],[1,\"p\",[[0,[],0,\"w kontrolerze komentarzy. Cały kontroler powinien wyglądać teraz tak:\"]]],[10,63],[1,\"p\",[[0,[],0,\"Flaga \\\"deliver_later\\\" pozwala na załączenie wysyłki e-maila do wewnętrznej pętli Ruby on Rails, która wyśle go najszybciej jak to możliwe nie blokując jednocześnie wykonania reszty kodu. Utworzenie komentarza nadal nie wyśle e-maila na prawdziwą pocztę, ale w konsoli zobaczymy, że taka akcja była by podjęta gdyby wysyłka faktycznie była do końca skonfigurowana.\"]]],[10,64],[1,\"p\",[[0,[],0,\"Nie będziemy iść w tą stronę, ale jeśli chcesz dokończyć konfigurację to poczytaj o \"],[0,[0],1,\"smtp_settings\"],[0,[],0,\" i \"],[0,[0],1,\"delivery_method\"],[0,[],0,\" w dokumentacji:\"]]],[10,65],[1,\"p\",[[0,[],0,\"Teraz przejdziemy do komunikacji z serwerem w czasie rzeczywistym.\"]]],[1,\"h2\",[[0,[],0,\"Cable - komunikacja przez web socket\"]]],[1,\"p\",[[0,[],0,\"Aby używać komunikacji w czasie rzeczywistym potrzebujemy kanału. Wygenerujemy go poleceniem:\"]]],[10,66],[10,67],[1,\"p\",[[0,[],0,\"W pliku \"],[0,[0],1,\"app/channels/comments_channel.rb\"],[0,[],0,\" o zawartości:\"]]],[10,68],[1,\"p\",[[0,[],0,\"dodajemy metodę \"],[0,[0],1,\"broadcast\"]]],[10,69],[1,\"p\",[[0,[],0,\"zrobimy tu też uproszczenie polegające na tym, że subskrypcja będzie dotyczyła tylko ostatniego postu. Naszym celem jest pokazanie podstaw Rails, więc skupimy się na doprowadzenie do prezentacji mechanizmu kanałów, pomijając ten aspekt. W ramach tego uproszczenia piszemy\"]]],[10,70],[1,\"p\",[[0,[],0,\"Aby włączyć wysyłanie wiadomości do przeglądarki dodajemy linię\"]]],[10,71],[1,\"p\",[[0,[],0,\"za załączeniem e-mailera w kontrolerze komentarzy. \"]]],[1,\"p\",[[0,[],0,\"Do przeglądarki zostanie załączony plik z konfiguracją kanału \"],[0,[0],1,\"app/javascript/channels/comments_channel.js\"],[0,[],0,\". Ustawiamy w nim, że w reakcji na załączenie komentarza do publikacji (kanału) powinien być on dołączany na końcu wątku, a licznik komentarzy powinien podnosić się o 1:\"]]],[10,72],[1,\"p\",[[0,[],0,\"Efekt jest następujący:\"]]],[10,73],[1,\"p\",[[0,[],0,\"Do dalszej nauki polecam Ci materiały:\"]]],[10,74],[10,75],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>W roku 2019 przepisywałem pewien system medyczny z Rails na PHP, w 2021 z Rails na NodeJS. Być może ty też spotykasz się z systemami opartymi na Rails, które tracą utrzymanie. To wprowadzenie pomoże Ci szybko zapoznać się z podstawami tego frameworka.</p><p>Napiszemy w nim bloga całkowicie od zera. Zaznaczę, że nie znam dobrze ani Ruby ani Rails, więc zamiast obszernego wprowadzenia mamy tu odtworzenie mojego procesu uczenia się.</p><p>Założenia:</p><ul><li>używamy linuxa (arch)</li></ul><h2 id=\"postawienie-aplikacjicrud\">Postawienie aplikacji - CRUD</h2><p>Zaczniemy od instalacji odpowiedniej wersji ruby.</p><pre><code class=\"language-bash\">curl -sSL https://get.rvm.io | bash -s stable --rails</code></pre><p><code>rvm</code> jest narzędziem analogicznym do <code>nvm</code> - pozwala zarządzać wersją interpretera co jest wyjątkowo przydatne przy pracy z systemami, które używają różnych wersji interpreterów. Możesz o nim poczytać tu:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://rvm.io/rvm/install\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">RVM: Ruby Version Manager - Installing RVM</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">Fastly</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://rvm.io/images/logo.png\"></div></a></figure><p>Tworzymy aplikację poleceniem</p><pre><code class=\"language-bash\">rails new weblog &amp;&amp; cd weblog</code></pre><p>Ta komenda zajmuje dużo czasu, ponieważ wymaga instalacji wszystkich paczek <code>gem</code> i kompilacji <code>node-sass</code> . </p><p>Następnym krokiem jest wygenerowanie automatycznie kodu do wykonywania operacji CRUD na poście. Posty będą miały tytuł i zawartość.</p><pre><code class=\"language-bash\">rails generate scaffold post title:string body:text</code></pre><p>Ta komenda powoduje wygenerowanie się sporej ilości plików:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-14-15-08.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"602\" height=\"601\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-18-14-15-08.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-14-15-08.png 602w\"></figure><p>Jednym z nich jest migracja na bazie danych, która zapisana w <code>db/migrate/20210418121400_create_posts.rb</code> wygląda tak:</p><pre><code class=\"language-ruby\">class CreatePosts &lt; ActiveRecord::Migration[6.1]\n  def change\n    create_table :posts do |t|\n      t.string :title\n      t.text :body\n\n      t.timestamps\n    end\n  end\nend\n</code></pre><p>Aby zsynchronizować bazę danych z wynikiem tej migracji wpisujemy</p><pre><code class=\"language-bash\">rails db:migrate</code></pre><p>Tu może się pojawić pytanie: \"Jaką bazę danych?\". W pliku <code>config/database.yml</code> możemy zobaczyć konfigurację z której wynika, że domyślnie jest to <code>sqlite</code>. W pliku <code>db/schema.rb</code> jest schemat bazy. </p><hr><p>To jest dobre miejsce na dygresję. Migrując systemy oparte na Ruby on Rails zastanawiałem się dlaczego środowisko produkcyjne ma \"sqlite\", myślałem, że ktoś celowo tak to skonfigurował. Okazuje się, że wystarczyło nie zmienić konfiguracji w tym pliku. Innym problemem, który zaprzątał mi głowę dwa lata temu, było pole \"updated_at\" w tabelach, które nie obsługiwały edycji. Widząc \"updated_at\" i nie mając dokumentacji myślałem, że istnieje proces edycji tych tabel, jednak to również jest wynik domyślnej konfiguracji \"rails\", który wszędzie wrzuca te kolumny.</p><hr><p>Żeby wystartować server używamy komendy</p><pre><code>rails server</code></pre><p>Ogromną zaletą rails jest, że już teraz możemy korzystać z działającego CRUD pod linkiem </p><p><a href=\"http://127.0.0.1:3000/posts\">http://127.0.0.1:3000/posts</a></p><p>Po wytworzeniu posta ręcznie dostajemy:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-14-33-12.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"263\" height=\"154\"></figure><p>Co jeszcze przyjemniejsze mamy też od razu \"api\" pod adresem <code>/posts.json</code></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-14-37-18.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"633\" height=\"488\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-18-14-37-18.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-14-37-18.png 633w\"></figure><p>Niestety próba utworzenia posta przez API </p><pre><code>http POST localhost:3000/posts.json title=\"Hej\" body=\"Ok\"</code></pre><p>kończy się błędem</p><pre><code>Can't verify CSRF token authenticity.</code></pre><p>Żeby wyłączyć protekcję \"CSRF\" w pliku <code>app/controllers/application_controller.rb</code> konfigurujemy opcję <code>protect_from_forgery</code> </p><pre><code class=\"language-ruby\">class ApplicationController &lt; ActionController::Base\n  protect_from_forgery with: :null_session\nend</code></pre><p>Teraz zapis postów przez API działa. Zarówno </p><pre><code>http POST localhost:3000/posts.json title=ok\n</code></pre><p>jak i </p><pre><code>http POST localhost:3000/posts.json body=ok\n</code></pre><p>zapiszą swoje posty bez walidacji ich poprawności.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-14-52-53.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"238\" height=\"62\"></figure><p>Aby wymusić obecność parametru <code>title</code> w poście, w pliku <code>app/models/post.rb</code> dodajemy flagę <code>validates_presence_of</code></p><pre><code>class Post &lt; ApplicationRecord\n  validates_presence_of :title\nend\n</code></pre><p>Dzięki niej  niemożliwe będzie dodawanie postów bez tytułu zarówno na stronie</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-19-14-41-18.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"507\" height=\"341\"></figure><p>jak i przez API</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-19-14-42-01.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"588\" height=\"370\"></figure><h2 id=\"debugowanierails-console\">Debugowanie - Rails Console</h2><p>Bardzo przydatnym narzędziem w pracy z Ruby on Rails jest konsola dostępna po wpisaniu polecenia:</p><pre><code>rails console</code></pre><p>Pozwala ona na interaktywny dostęp do danych za pomocą języka Ruby i zdefiniowanych w Rails obiektów. Na przykład pierwszy post zobaczymy wpisując</p><pre><code>Post.first</code></pre><p>Żeby dostać wszystkie posty piszemy</p><pre><code>Post.all</code></pre><p>Posty utworzone od wczoraj do jutra dostaniemy pisząc</p><pre><code>Post.where(created_at: Date.yesterday..Date.tomorrow)</code></pre><p>Łatwo można przekształcić to do formy zapytania SQL dodając własność <code>to_sql</code> na końcu</p><pre><code>Post.where(created_at: Date.yesterday..Date.tomorrow).to_sql</code></pre><p>Aby utworzyć nowy post piszemy </p><pre><code>Post.create! title: 'Hello', body: 'World'\n</code></pre><h2 id=\"relacje-mi%C4%99dzy-tabelami\">Relacje między tabelami</h2><p>Typowym przykładem relacji względem postów są komentarze. Nie potrzebujemy dla nich takich samych kontrolerów i widoków jak dla postów, dlatego do generowania zamiast <code>scaffold</code> użyjemy flagi <code>resource</code>.</p><pre><code>rails generate resource comment post:references body:text</code></pre><p>Pełną listę dostępnych generatorów zobaczymy wpisując polecenie:</p><pre><code>rails generate</code></pre><p>lub czytając dokumentację</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://guides.rubyonrails.org/command_line.html#bin-rails-generate\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The Rails Command Line — Ruby on Rails Guides</div><div class=\"kg-bookmark-description\">The Rails Command LineAfter reading this guide, you will know: How to create a Rails application. How to generate models, controllers, database migrations, and unit tests. How to start a development server. How to experiment with objects through an interactive shell.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://guides.rubyonrails.org/images/favicon.ico\"><span class=\"kg-bookmark-author\">Ruby on Rails Guides</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://avatars.githubusercontent.com/u/4223\"></div></a></figure><p>Tym czasem wrócimy do plików wygenerowanych dzięki opcji <code>resource</code>.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-15-09-56-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"644\" height=\"380\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-18-15-09-56-1.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-15-09-56-1.png 644w\"></figure><p>Ponownie powstała tutaj migracja tym razem o zawartości:</p><pre><code class=\"language-ruby\">class CreateComments &lt; ActiveRecord::Migration[6.1]\n  def change\n    create_table :comments do |t|\n      t.references :post, null: false, foreign_key: true\n      t.text :body\n\n      t.timestamps\n    end\n  end\nend\n</code></pre><p>Aby ją wykonać wpisujemy</p><pre><code>rails db:migrate</code></pre><p>Zajmijmy się teraz routingiem. Nie ma sensu nigdy pytać o wszystkie komentarze. Zawsze są one powiązane z postem, którego dotyczą. Zatem w pliku <code>config/routes.yml</code> zastępujemy występujące obok siebie </p><pre><code class=\"language-ruby\">Rails.application.routes.draw do\n  resources :posts\n  resources :comments\nend</code></pre><p>na konfigurację mówiącą, żeby komentarze były zagnieżdżone w poście</p><pre><code class=\"language-ruby\">Rails.application.routes.draw do\n  resources :posts do\n    resources :comments\n  end\nend</code></pre><p>Wyświetlenie routingu jest możliwe dzięki poleceniu:</p><pre><code>rails routes</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-15-40-23-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1262\" height=\"756\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-18-15-40-23-2.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/Screenshot-from-2021-04-18-15-40-23-2.png 1000w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-15-40-23-2.png 1262w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Co do kierunku relacji, to w tym momencie komentarze należą do postów co opisano w pliku <code>app/models/comment.rb</code></p><pre><code>class Comment &lt; ApplicationRecord\n  belongs_to :post\nend\n</code></pre><p>Ale posty nie mają oznaczonej relacji z komentarzami, co naprawimy dodając <code>has_many</code> do <code>app/models/post.rb</code></p><pre><code>class Post &lt; ApplicationRecord\n  has_many :comments\n  validates_presence_of :title\nend\n</code></pre><p>W konsoli możemy utworzyć teraz przykładowy komentarz</p><pre><code>Post.second.comments.create! body: \"My first comment to second post\"</code></pre><p>Żeby wyświetlić komentarze i móc je dodawać napiszemy pomocnicze fragmenty widoków (partials). <code>app/views/comments/_comment.html.erb</code> posłuży nam do wyświetlania jednego komentarza </p><pre><code>&lt;p&gt;&lt;%= comment.body %&gt; -- &lt;%= comment.created_at.to_s(:long) %&gt;&lt;/p&gt;</code></pre><p>Natomiast <code>app/views/comments/_new.html.erb</code> będzie formularzem do tworzenia komentarza</p><pre><code>&lt;%= form_for([ @post, Comment.new], remote: true) do |form| %&gt;\n  Your comment: &lt;br/&gt;\n  &lt;%= form.text_area :body, size: '50x2' %&gt;&lt;br/&gt;\n  &lt;%= form.submit %&gt;\n&lt;% end %&gt;</code></pre><p>Załączymy je w widoku pojedynczego postu dołączając do pliku <code>app/views/posts/shwo.html.erb</code> kod</p><pre><code>&lt;hr&gt;\n\n&lt;h2&gt;Comments (&lt;span id=\"count\"&gt;&lt;%= @post.comments.count %&gt;&lt;/span&gt;)&lt;/h2&gt;\n\n&lt;div id=\"comments\"&gt;\n   &lt;%= render @post.comments %&gt;\n&lt;/div&gt;\n\n&lt;%= render 'comments/new', post: @post %&gt;</code></pre><p>Teraz nasz widok postu będzie wyglądała następująco</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-16-19-22-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"450\" height=\"288\"></figure><p>Mimo, że wygląda jak gotowy do działania, to funkcja dodawania komentarzy wciąż nie jest dostępna. Przygotowaliśmy jedynie widok, ale brakuje logiki, która obsłużyła by zapisywanie komentarzy do bazy i łączenie ich z postami.</p><p>Aby ją dołączyć musimy obsłużyć tworzenie komentarzy w kontrolerze <code>app/controllers/comments_controller.rb</code> </p><pre><code>class CommentsController &lt; ApplicationController\n  before_action :set_post\n\n  def create\n    @post.comments.create! comments_params\n    redirect_to @post\n  end\n\n  private\n\n  def set_post\n    @post = Post.find(params[:post_id])\n  end\n\n  def comments_params\n    params.required(:comment).permit(:body)\n  end\n\nend</code></pre><p>Przyjrzyjmy mu się uważnie. Zaczyna się od opcji <code>before_action</code>, która ustawia post na podstawie parametru z adresu <code>url</code>. Następnie w <code>create</code> używamy tego posta aby do niego utworzyć komentarz, jego parametry pochodzą z <code>comments_params</code>, które pobiera je z ciała żądania.</p><p>Następnie następuje przekierowanie do strony z postami. Na stronie działa to bardzo dobrze.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-09-47-58.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"517\" height=\"332\"></figure><p>Ale jeśli chcemy tworzyć posty z poziomu API. to za każdym razem będąc przekierowani do postu zobaczymy go bez komentarzy. Jeśli zastąpimy</p><pre><code>redirect_to @post</code></pre><p>w kontrolerze przez instrukcje analogiczne jak dla posta</p><pre><code>    respond_to do |format|\n      if @post.save\n        format.html { redirect_to @post, notice: \"Comment was successfully created.\" }\n        format.json { render :show, status: :created, location: @post }\n      else\n        format.html { render :new, status: :unprocessable_entity }\n        format.json { render json: @post.errors, status: :unprocessable_entity }\n      end\n    end</code></pre><p>dostaniemy błąd</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-18-28-49-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"708\" height=\"476\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-18-18-28-49-1.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-18-28-49-1.png 708w\"></figure><p>Jest tak dlatego, że teraz komentarze wymagają aby nadać im strukturę przy układaniu ich w plik JSON. Jest to rozwiązane dzięki fantastycznej bibliotece <code>jbuilder</code>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/rails/jbuilder\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">rails/jbuilder</div><div class=\"kg-bookmark-description\">Jbuilder: generate JSON objects with a Builder-style DSL - rails/jbuilder</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">rails</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/9d3c523e683d19d728cc3cf514eeedf49593ddb0bea84432b4c012c57bea8189/rails/jbuilder\"></div></a></figure><p>Tworząc plik <code>app/views/comments/show.json.jbuilder</code> o treści</p><pre><code>json.partial! \"posts/post\", post: @post\njson.comments @post.comments, :id, :body, :created_at</code></pre><p>skonfigurujemy serwer, aby po utworzeniu komentarza odpowiadał widokiem posta z listą wszystkich odpowiadających mu komentarzy. Jest to widok odpowiadający temu co widzimy w wersji HTML, choć nie zgodny z zasadami REST.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-18-36-24-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"339\"></figure><p>Jeśli chcieli byśmy wyświetlić ten konkretny komentarz i możemy użyć składni</p><pre><code>  def create\n    comment = @post.comments.create! comments_params\n\n    respond_to do |format|\n      if @post.save\n        format.html { redirect_to @post, notice: \"Comment was successfully created.\" }\n        format.json { render json: comment.to_json(include: [:post]) }\n      else\n        format.html { render :new, status: :unprocessable_entity }\n        format.json { render json: @post.errors, status: :unprocessable_entity }\n      end\n    end\n\n  end</code></pre><p>w kontrolerze. Wtedy w widoku odpowiedzi zobaczymy komentarz wraz z postem.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-11-48-56.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"420\" height=\"276\"></figure><p>Więcej o formatowaniu można przeczytać tutaj:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://dev.to/caicindy87/rendering-json-in-a-rails-api-25fd\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Rendering JSON in a Rails API</div><div class=\"kg-bookmark-description\">To go over rendering JSON in a Rails API, I will use an example. Example: Models: doctor,...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--t7tVouP9--/c_limit,f_png,fl_progressive,q_80,w_192/https://practicaldev-herokuapp-com.freetls.fastly.net/assets/devlogo-pwa-512.png\"><span class=\"kg-bookmark-author\">DEV Community</span><span class=\"kg-bookmark-publisher\">Cindy</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://dev.to/social_previews/article/323041.png\"></div></a></figure><h2 id=\"wysy%C5%82ka-e-maili\">Wysyłka e-maili</h2><p>Bardzo częstą funkcją w serwisach internetowych jest wysyłanie e-maili w reakcji na jakieś zdarzenia. Zamiast pisać kod ponownie skorzystamy z generatora:</p><pre><code>rails generate mailer comments submitted</code></pre><p>Jest to e-mailer, który wysyła powitanie. Pierwszą rzeczą, jaką zrobimy będzie konfiguracja danych jakie będzie wstrzykiwał do szablonów. W pliku <code>comments_mailer.rb</code> piszemy kod:</p><pre><code>class CommentsMailer &lt; ApplicationMailer\n  def submitted(comment)\n    @comment = comment\n\n    mail to: \"gustaw.daniel@gmail.com\", subject: 'New comment'\n  end\nend</code></pre><p>W <code>app/views/comments_mailer</code> mamy dwa pliki z szablonami. Dla widoku HTML jest to plik <code>submitted.html.erb</code>. Zmodyfikujemy go tak, żeby używając wcześniej zdefiniowanego partiala pokazywał nowy komentarz:</p><pre><code>&lt;h1&gt;New comment on post: &lt;%= @comment.post.title %&gt;&lt;/h1&gt;\n\n&lt;%= render @comment %&gt;</code></pre><p>W pliku <code>submitted.text.erb</code> nie możemy użyć już <code>render</code> dlatego uprościmy widok tekstowy do formy:</p><pre><code>New comment on post: &lt;%= @comment.post.title %&gt;: &lt;%= @comment.body %&gt;</code></pre><p>Niesamowite w Rails jest to, że mamy gotowy widok do podglądu tych e-maili bez konieczności ich wysyłania. Aby z niego skorzystać musimy tylko wskazać komentarz, który wyświetlimy. W tym celu w pliku <code>test/mailers/previews/comments_mailer_preview.rb</code> linię</p><pre><code>CommentsMailer.submitted</code></pre><p>zmieniamy na</p><pre><code>CommentsMailer.submitted Comment.first</code></pre><p> Pod adresem</p><p><a href=\"http://localhost:3000/rails/mailers/comments_mailer/submitted\">http://localhost:3000/rails/mailers/comments_mailer/submitted</a></p><p>Możemy zobaczyć podgląd tego e-maila</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-19-17-35-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"532\" height=\"214\"></figure><p>Nie możemy jednak oczekiwać, że ten e-mail będzie od razu wysyłany. Aby dołączyć jego wysyłanie musimy dodać linię</p><pre><code>CommentsMailer.submitted(comment).deliver_later</code></pre><p>w kontrolerze komentarzy. Cały kontroler powinien wyglądać teraz tak:</p><pre><code>class CommentsController &lt; ApplicationController\n  before_action :set_post\n\n  def create\n    comment = @post.comments.create! comments_params\n    CommentsMailer.submitted(comment).deliver_later\n\n    respond_to do |format|\n      if @post.save\n        format.html { redirect_to @post, notice: \"Comment was successfully created.\" }\n        format.json { render json: comment.to_json(include: [:post]) }\n      else\n        format.html { render :new, status: :unprocessable_entity }\n        format.json { render json: @post.errors, status: :unprocessable_entity }\n      end\n    end\n\n  end\n\n  private\n\n  def set_post\n    @post = Post.find(params[:post_id])\n  end\n\n  def comments_params\n    params.required(:comment).permit(:body)\n  end\n\nend</code></pre><p>Flaga \"deliver_later\" pozwala na załączenie wysyłki e-maila do wewnętrznej pętli Ruby on Rails, która wyśle go najszybciej jak to możliwe nie blokując jednocześnie wykonania reszty kodu. Utworzenie komentarza nadal nie wyśle e-maila na prawdziwą pocztę, ale w konsoli zobaczymy, że taka akcja była by podjęta gdyby wysyłka faktycznie była do końca skonfigurowana.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-18-19-33-26-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"474\" height=\"651\"></figure><p>Nie będziemy iść w tą stronę, ale jeśli chcesz dokończyć konfigurację to poczytaj o <code>smtp_settings</code> i <code>delivery_method</code> w dokumentacji:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://guides.rubyonrails.org/action_mailer_basics.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Action Mailer Basics — Ruby on Rails Guides</div><div class=\"kg-bookmark-description\">Action Mailer BasicsThis guide provides you with all you need to get started in sending emails from and to your application, and many internals of Action Mailer. It also covers how to test your mailers.After reading this guide, you will know: How to send email within a Rails application. How to gene…</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://guides.rubyonrails.org/images/favicon.ico\"><span class=\"kg-bookmark-author\">Ruby on Rails Guides</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://avatars.githubusercontent.com/u/4223\"></div></a></figure><p>Teraz przejdziemy do komunikacji z serwerem w czasie rzeczywistym.</p><h2 id=\"cablekomunikacja-przez-web-socket\">Cable - komunikacja przez web socket</h2><p>Aby używać komunikacji w czasie rzeczywistym potrzebujemy kanału. Wygenerujemy go poleceniem:</p><pre><code>rails generate channel comments</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-12-05-34.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"567\" height=\"139\"></figure><p>W pliku <code>app/channels/comments_channel.rb</code> o zawartości:</p><pre><code class=\"language-ruby\">class CommentsChannel &lt; ApplicationCable::Channel\n  def subscribed\n    # stream_from \"some_channel\"\n  end\n\n  def unsubscribed\n    # Any cleanup needed when channel is unsubscribed\n  end\nend\n</code></pre><p>dodajemy metodę <code>broadcast</code></p><pre><code>  def self.broadcast(comment)\n    broadcast_to comment.post, comment:\n      CommentsController.render(partial: 'comments/comment', locals: { comment: comment })\n  end</code></pre><p>zrobimy tu też uproszczenie polegające na tym, że subskrypcja będzie dotyczyła tylko ostatniego postu. Naszym celem jest pokazanie podstaw Rails, więc skupimy się na doprowadzenie do prezentacji mechanizmu kanałów, pomijając ten aspekt. W ramach tego uproszczenia piszemy</p><pre><code>  def subscribed\n    stream_for Post.last\n  end</code></pre><p>Aby włączyć wysyłanie wiadomości do przeglądarki dodajemy linię</p><pre><code>CommentsChannel.broadcast(comment)</code></pre><p>za załączeniem e-mailera w kontrolerze komentarzy. </p><p>Do przeglądarki zostanie załączony plik z konfiguracją kanału <code>app/javascript/channels/comments_channel.js</code>. Ustawiamy w nim, że w reakcji na załączenie komentarza do publikacji (kanału) powinien być on dołączany na końcu wątku, a licznik komentarzy powinien podnosić się o 1:</p><pre><code>    received(data) {\n        const commentsElement = document.querySelector('#comments');\n        const countElement = document.querySelector('#count');\n\n        if (commentsElement) {\n            commentsElement.innerHTML += data.comment\n        }\n        if (countElement) {\n            countElement.innerHTML = String(1 + parseInt(countElement.innerHTML))\n        }\n    }</code></pre><p>Efekt jest następujący:</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"150\" src=\"https://www.youtube.com/embed/cVoUsrTlTm4?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p>Do dalszej nauki polecam Ci materiały:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.tutorialspoint.com/ruby-on-rails/index.htm\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Ruby on Rails Tutorial - Tutorialspoint</div><div class=\"kg-bookmark-description\">Ruby on Rails Tutorial - Ruby on Rails is an extremely productive web application framework written in Ruby by David Heinemeier Hansson. This tutorial gives you a complete understanding</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.tutorialspoint.com/favicon.ico\"><span class=\"kg-bookmark-author\">Ruby on Rails Tutorial</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.tutorialspoint.com/videotutorials/images/loader.gif\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://rubyonrails.org/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Ruby on Rails</div><div class=\"kg-bookmark-description\">A web-application framework that includes everything needed to create database-backed web applications according to the Model-View-Controller (MVC) pattern.</div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">Ruby on Rails</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://avatars.githubusercontent.com/u/4223\"></div></a></figure>",
            "comment_id": "607c1b012fb35425592d0770",
            "plaintext": "W roku 2019 przepisywałem pewien system medyczny z Rails na PHP, w 2021 z Rails\nna NodeJS. Być może ty też spotykasz się z systemami opartymi na Rails, które\ntracą utrzymanie. To wprowadzenie pomoże Ci szybko zapoznać się z podstawami\ntego frameworka.\n\nNapiszemy w nim bloga całkowicie od zera. Zaznaczę, że nie znam dobrze ani Ruby\nani Rails, więc zamiast obszernego wprowadzenia mamy tu odtworzenie mojego\nprocesu uczenia się.\n\nZałożenia:\n\n * używamy linuxa (arch)\n\nPostawienie aplikacji - CRUD\nZaczniemy od instalacji odpowiedniej wersji ruby.\n\ncurl -sSL https://get.rvm.io | bash -s stable --rails\n\nrvm jest narzędziem analogicznym do nvm - pozwala zarządzać wersją interpretera\nco jest wyjątkowo przydatne przy pracy z systemami, które używają różnych wersji\ninterpreterów. Możesz o nim poczytać tu:\n\nRVM: Ruby Version Manager - Installing RVMFastly [https://rvm.io/rvm/install]\nTworzymy aplikację poleceniem\n\nrails new weblog && cd weblog\n\nTa komenda zajmuje dużo czasu, ponieważ wymaga instalacji wszystkich paczek gem \ni kompilacji node-sass . \n\nNastępnym krokiem jest wygenerowanie automatycznie kodu do wykonywania operacji\nCRUD na poście. Posty będą miały tytuł i zawartość.\n\nrails generate scaffold post title:string body:text\n\nTa komenda powoduje wygenerowanie się sporej ilości plików:\n\nJednym z nich jest migracja na bazie danych, która zapisana w \ndb/migrate/20210418121400_create_posts.rb wygląda tak:\n\nclass CreatePosts < ActiveRecord::Migration[6.1]\n  def change\n    create_table :posts do |t|\n      t.string :title\n      t.text :body\n\n      t.timestamps\n    end\n  end\nend\n\n\nAby zsynchronizować bazę danych z wynikiem tej migracji wpisujemy\n\nrails db:migrate\n\nTu może się pojawić pytanie: \"Jaką bazę danych?\". W pliku config/database.yml \nmożemy zobaczyć konfigurację z której wynika, że domyślnie jest to sqlite. W\npliku db/schema.rb jest schemat bazy. \n\n\n--------------------------------------------------------------------------------\n\nTo jest dobre miejsce na dygresję. Migrując systemy oparte na Ruby on Rails\nzastanawiałem się dlaczego środowisko produkcyjne ma \"sqlite\", myślałem, że ktoś\ncelowo tak to skonfigurował. Okazuje się, że wystarczyło nie zmienić\nkonfiguracji w tym pliku. Innym problemem, który zaprzątał mi głowę dwa lata\ntemu, było pole \"updated_at\" w tabelach, które nie obsługiwały edycji. Widząc\n\"updated_at\" i nie mając dokumentacji myślałem, że istnieje proces edycji tych\ntabel, jednak to również jest wynik domyślnej konfiguracji \"rails\", który\nwszędzie wrzuca te kolumny.\n\n\n--------------------------------------------------------------------------------\n\nŻeby wystartować server używamy komendy\n\nrails server\n\nOgromną zaletą rails jest, że już teraz możemy korzystać z działającego CRUD pod\nlinkiem \n\nhttp://127.0.0.1:3000/posts\n\nPo wytworzeniu posta ręcznie dostajemy:\n\nCo jeszcze przyjemniejsze mamy też od razu \"api\" pod adresem /posts.json\n\nNiestety próba utworzenia posta przez API \n\nhttp POST localhost:3000/posts.json title=\"Hej\" body=\"Ok\"\n\nkończy się błędem\n\nCan't verify CSRF token authenticity.\n\nŻeby wyłączyć protekcję \"CSRF\" w pliku app/controllers/application_controller.rb \nkonfigurujemy opcję protect_from_forgery \n\nclass ApplicationController < ActionController::Base\n  protect_from_forgery with: :null_session\nend\n\nTeraz zapis postów przez API działa. Zarówno \n\nhttp POST localhost:3000/posts.json title=ok\n\n\njak i \n\nhttp POST localhost:3000/posts.json body=ok\n\n\nzapiszą swoje posty bez walidacji ich poprawności.\n\nAby wymusić obecność parametru title w poście, w pliku app/models/post.rb \ndodajemy flagę validates_presence_of\n\nclass Post < ApplicationRecord\n  validates_presence_of :title\nend\n\n\nDzięki niej  niemożliwe będzie dodawanie postów bez tytułu zarówno na stronie\n\njak i przez API\n\nDebugowanie - Rails Console\nBardzo przydatnym narzędziem w pracy z Ruby on Rails jest konsola dostępna po\nwpisaniu polecenia:\n\nrails console\n\nPozwala ona na interaktywny dostęp do danych za pomocą języka Ruby i\nzdefiniowanych w Rails obiektów. Na przykład pierwszy post zobaczymy wpisując\n\nPost.first\n\nŻeby dostać wszystkie posty piszemy\n\nPost.all\n\nPosty utworzone od wczoraj do jutra dostaniemy pisząc\n\nPost.where(created_at: Date.yesterday..Date.tomorrow)\n\nŁatwo można przekształcić to do formy zapytania SQL dodając własność to_sql na\nkońcu\n\nPost.where(created_at: Date.yesterday..Date.tomorrow).to_sql\n\nAby utworzyć nowy post piszemy \n\nPost.create! title: 'Hello', body: 'World'\n\n\nRelacje między tabelami\nTypowym przykładem relacji względem postów są komentarze. Nie potrzebujemy dla\nnich takich samych kontrolerów i widoków jak dla postów, dlatego do generowania\nzamiast scaffold użyjemy flagi resource.\n\nrails generate resource comment post:references body:text\n\nPełną listę dostępnych generatorów zobaczymy wpisując polecenie:\n\nrails generate\n\nlub czytając dokumentację\n\nThe Rails Command Line — Ruby on Rails GuidesThe Rails Command LineAfter\nreading\nthis guide, you will know: How to create a Rails application. How to generate\nmodels, controllers, database migrations, and unit tests. How to start a\ndevelopment server. How to experiment with objects through an interactive\nshell.\nRuby on Rails Guides\n[https://guides.rubyonrails.org/command_line.html#bin-rails-generate]Tym czasem\nwrócimy do plików wygenerowanych dzięki opcji resource.\n\nPonownie powstała tutaj migracja tym razem o zawartości:\n\nclass CreateComments < ActiveRecord::Migration[6.1]\n  def change\n    create_table :comments do |t|\n      t.references :post, null: false, foreign_key: true\n      t.text :body\n\n      t.timestamps\n    end\n  end\nend\n\n\nAby ją wykonać wpisujemy\n\nrails db:migrate\n\nZajmijmy się teraz routingiem. Nie ma sensu nigdy pytać o wszystkie komentarze.\nZawsze są one powiązane z postem, którego dotyczą. Zatem w pliku \nconfig/routes.yml zastępujemy występujące obok siebie \n\nRails.application.routes.draw do\n  resources :posts\n  resources :comments\nend\n\nna konfigurację mówiącą, żeby komentarze były zagnieżdżone w poście\n\nRails.application.routes.draw do\n  resources :posts do\n    resources :comments\n  end\nend\n\nWyświetlenie routingu jest możliwe dzięki poleceniu:\n\nrails routes\n\nCo do kierunku relacji, to w tym momencie komentarze należą do postów co opisano\nw pliku app/models/comment.rb\n\nclass Comment < ApplicationRecord\n  belongs_to :post\nend\n\n\nAle posty nie mają oznaczonej relacji z komentarzami, co naprawimy dodając \nhas_many do app/models/post.rb\n\nclass Post < ApplicationRecord\n  has_many :comments\n  validates_presence_of :title\nend\n\n\nW konsoli możemy utworzyć teraz przykładowy komentarz\n\nPost.second.comments.create! body: \"My first comment to second post\"\n\nŻeby wyświetlić komentarze i móc je dodawać napiszemy pomocnicze fragmenty\nwidoków (partials). app/views/comments/_comment.html.erb posłuży nam do\nwyświetlania jednego komentarza \n\n<p><%= comment.body %> -- <%= comment.created_at.to_s(:long) %></p>\n\nNatomiast app/views/comments/_new.html.erb będzie formularzem do tworzenia\nkomentarza\n\n<%= form_for([ @post, Comment.new], remote: true) do |form| %>\n  Your comment: <br/>\n  <%= form.text_area :body, size: '50x2' %><br/>\n  <%= form.submit %>\n<% end %>\n\nZałączymy je w widoku pojedynczego postu dołączając do pliku \napp/views/posts/shwo.html.erb kod\n\n<hr>\n\n<h2>Comments (<span id=\"count\"><%= @post.comments.count %></span>)</h2>\n\n<div id=\"comments\">\n   <%= render @post.comments %>\n</div>\n\n<%= render 'comments/new', post: @post %>\n\nTeraz nasz widok postu będzie wyglądała następująco\n\nMimo, że wygląda jak gotowy do działania, to funkcja dodawania komentarzy wciąż\nnie jest dostępna. Przygotowaliśmy jedynie widok, ale brakuje logiki, która\nobsłużyła by zapisywanie komentarzy do bazy i łączenie ich z postami.\n\nAby ją dołączyć musimy obsłużyć tworzenie komentarzy w kontrolerze \napp/controllers/comments_controller.rb \n\nclass CommentsController < ApplicationController\n  before_action :set_post\n\n  def create\n    @post.comments.create! comments_params\n    redirect_to @post\n  end\n\n  private\n\n  def set_post\n    @post = Post.find(params[:post_id])\n  end\n\n  def comments_params\n    params.required(:comment).permit(:body)\n  end\n\nend\n\nPrzyjrzyjmy mu się uważnie. Zaczyna się od opcji before_action, która ustawia\npost na podstawie parametru z adresu url. Następnie w create używamy tego posta\naby do niego utworzyć komentarz, jego parametry pochodzą z comments_params,\nktóre pobiera je z ciała żądania.\n\nNastępnie następuje przekierowanie do strony z postami. Na stronie działa to\nbardzo dobrze.\n\nAle jeśli chcemy tworzyć posty z poziomu API. to za każdym razem będąc\nprzekierowani do postu zobaczymy go bez komentarzy. Jeśli zastąpimy\n\nredirect_to @post\n\nw kontrolerze przez instrukcje analogiczne jak dla posta\n\n    respond_to do |format|\n      if @post.save\n        format.html { redirect_to @post, notice: \"Comment was successfully created.\" }\n        format.json { render :show, status: :created, location: @post }\n      else\n        format.html { render :new, status: :unprocessable_entity }\n        format.json { render json: @post.errors, status: :unprocessable_entity }\n      end\n    end\n\ndostaniemy błąd\n\nJest tak dlatego, że teraz komentarze wymagają aby nadać im strukturę przy\nukładaniu ich w plik JSON. Jest to rozwiązane dzięki fantastycznej bibliotece \njbuilder.\n\nrails/jbuilderJbuilder: generate JSON objects with a Builder-style DSL -\nrails/jbuilderGitHubrails [https://github.com/rails/jbuilder]Tworząc plik app/views/comments/show.json.jbuilder o treści\n\njson.partial! \"posts/post\", post: @post\njson.comments @post.comments, :id, :body, :created_at\n\nskonfigurujemy serwer, aby po utworzeniu komentarza odpowiadał widokiem posta z\nlistą wszystkich odpowiadających mu komentarzy. Jest to widok odpowiadający temu\nco widzimy w wersji HTML, choć nie zgodny z zasadami REST.\n\nJeśli chcieli byśmy wyświetlić ten konkretny komentarz i możemy użyć składni\n\n  def create\n    comment = @post.comments.create! comments_params\n\n    respond_to do |format|\n      if @post.save\n        format.html { redirect_to @post, notice: \"Comment was successfully created.\" }\n        format.json { render json: comment.to_json(include: [:post]) }\n      else\n        format.html { render :new, status: :unprocessable_entity }\n        format.json { render json: @post.errors, status: :unprocessable_entity }\n      end\n    end\n\n  end\n\nw kontrolerze. Wtedy w widoku odpowiedzi zobaczymy komentarz wraz z postem.\n\nWięcej o formatowaniu można przeczytać tutaj:\n\nRendering JSON in a Rails APITo go over rendering JSON in a Rails API, I will\nuse an example. Example: Models: doctor,...DEV CommunityCindy\n[https://dev.to/caicindy87/rendering-json-in-a-rails-api-25fd]Wysyłka e-maili\nBardzo częstą funkcją w serwisach internetowych jest wysyłanie e-maili w reakcji\nna jakieś zdarzenia. Zamiast pisać kod ponownie skorzystamy z generatora:\n\nrails generate mailer comments submitted\n\nJest to e-mailer, który wysyła powitanie. Pierwszą rzeczą, jaką zrobimy będzie\nkonfiguracja danych jakie będzie wstrzykiwał do szablonów. W pliku \ncomments_mailer.rb piszemy kod:\n\nclass CommentsMailer < ApplicationMailer\n  def submitted(comment)\n    @comment = comment\n\n    mail to: \"gustaw.daniel@gmail.com\", subject: 'New comment'\n  end\nend\n\nW app/views/comments_mailer mamy dwa pliki z szablonami. Dla widoku HTML jest to\nplik submitted.html.erb. Zmodyfikujemy go tak, żeby używając wcześniej\nzdefiniowanego partiala pokazywał nowy komentarz:\n\n<h1>New comment on post: <%= @comment.post.title %></h1>\n\n<%= render @comment %>\n\nW pliku submitted.text.erb nie możemy użyć już render dlatego uprościmy widok\ntekstowy do formy:\n\nNew comment on post: <%= @comment.post.title %>: <%= @comment.body %>\n\nNiesamowite w Rails jest to, że mamy gotowy widok do podglądu tych e-maili bez\nkonieczności ich wysyłania. Aby z niego skorzystać musimy tylko wskazać\nkomentarz, który wyświetlimy. W tym celu w pliku \ntest/mailers/previews/comments_mailer_preview.rb linię\n\nCommentsMailer.submitted\n\nzmieniamy na\n\nCommentsMailer.submitted Comment.first\n\n Pod adresem\n\nhttp://localhost:3000/rails/mailers/comments_mailer/submitted\n\nMożemy zobaczyć podgląd tego e-maila\n\nNie możemy jednak oczekiwać, że ten e-mail będzie od razu wysyłany. Aby dołączyć\njego wysyłanie musimy dodać linię\n\nCommentsMailer.submitted(comment).deliver_later\n\nw kontrolerze komentarzy. Cały kontroler powinien wyglądać teraz tak:\n\nclass CommentsController < ApplicationController\n  before_action :set_post\n\n  def create\n    comment = @post.comments.create! comments_params\n    CommentsMailer.submitted(comment).deliver_later\n\n    respond_to do |format|\n      if @post.save\n        format.html { redirect_to @post, notice: \"Comment was successfully created.\" }\n        format.json { render json: comment.to_json(include: [:post]) }\n      else\n        format.html { render :new, status: :unprocessable_entity }\n        format.json { render json: @post.errors, status: :unprocessable_entity }\n      end\n    end\n\n  end\n\n  private\n\n  def set_post\n    @post = Post.find(params[:post_id])\n  end\n\n  def comments_params\n    params.required(:comment).permit(:body)\n  end\n\nend\n\nFlaga \"deliver_later\" pozwala na załączenie wysyłki e-maila do wewnętrznej pętli\nRuby on Rails, która wyśle go najszybciej jak to możliwe nie blokując\njednocześnie wykonania reszty kodu. Utworzenie komentarza nadal nie wyśle\ne-maila na prawdziwą pocztę, ale w konsoli zobaczymy, że taka akcja była by\npodjęta gdyby wysyłka faktycznie była do końca skonfigurowana.\n\nNie będziemy iść w tą stronę, ale jeśli chcesz dokończyć konfigurację to\npoczytaj o smtp_settings i delivery_method w dokumentacji:\n\nAction Mailer Basics — Ruby on Rails GuidesAction Mailer BasicsThis guide\nprovides you with all you need to get started in sending emails from and to\nyour\napplication, and many internals of Action Mailer. It also covers how to test\nyour mailers.After reading this guide, you will know: How to send email within\na\nRails application. How to gene…Ruby on Rails Guides\n[https://guides.rubyonrails.org/action_mailer_basics.html]Teraz przejdziemy do\nkomunikacji z serwerem w czasie rzeczywistym.\n\nCable - komunikacja przez web socket\nAby używać komunikacji w czasie rzeczywistym potrzebujemy kanału. Wygenerujemy\ngo poleceniem:\n\nrails generate channel comments\n\nW pliku app/channels/comments_channel.rb o zawartości:\n\nclass CommentsChannel < ApplicationCable::Channel\n  def subscribed\n    # stream_from \"some_channel\"\n  end\n\n  def unsubscribed\n    # Any cleanup needed when channel is unsubscribed\n  end\nend\n\n\ndodajemy metodę broadcast\n\n  def self.broadcast(comment)\n    broadcast_to comment.post, comment:\n      CommentsController.render(partial: 'comments/comment', locals: { comment: comment })\n  end\n\nzrobimy tu też uproszczenie polegające na tym, że subskrypcja będzie dotyczyła\ntylko ostatniego postu. Naszym celem jest pokazanie podstaw Rails, więc skupimy\nsię na doprowadzenie do prezentacji mechanizmu kanałów, pomijając ten aspekt. W\nramach tego uproszczenia piszemy\n\n  def subscribed\n    stream_for Post.last\n  end\n\nAby włączyć wysyłanie wiadomości do przeglądarki dodajemy linię\n\nCommentsChannel.broadcast(comment)\n\nza załączeniem e-mailera w kontrolerze komentarzy. \n\nDo przeglądarki zostanie załączony plik z konfiguracją kanału \napp/javascript/channels/comments_channel.js. Ustawiamy w nim, że w reakcji na\nzałączenie komentarza do publikacji (kanału) powinien być on dołączany na końcu\nwątku, a licznik komentarzy powinien podnosić się o 1:\n\n    received(data) {\n        const commentsElement = document.querySelector('#comments');\n        const countElement = document.querySelector('#count');\n\n        if (commentsElement) {\n            commentsElement.innerHTML += data.comment\n        }\n        if (countElement) {\n            countElement.innerHTML = String(1 + parseInt(countElement.innerHTML))\n        }\n    }\n\nEfekt jest następujący:\n\nDo dalszej nauki polecam Ci materiały:\n\nRuby on Rails Tutorial - TutorialspointRuby on Rails Tutorial - Ruby on Rails\nis\nan extremely productive web application framework written in Ruby by David\nHeinemeier Hansson. This tutorial gives you a complete understandingRuby on\nRails Tutorial [https://www.tutorialspoint.com/ruby-on-rails/index.htm]Ruby on\nRailsA web-application framework that includes everything needed to create\ndatabase-backed web applications according to the Model-View-Controller (MVC)\npattern.Ruby on Rails [https://rubyonrails.org/]",
            "feature_image": "__GHOST_URL__/content/images/2021/04/code_rails-374b9a344cbd0fff67ba7d6dd2fb7286.png",
            "featured": 1,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-18T11:41:53.000Z",
            "updated_at": "2021-04-20T12:18:38.000Z",
            "published_at": "2021-04-20T11:28:00.000Z",
            "custom_excerpt": "Wprowadzenie do Ruby on Rails prezentujące CRUD, relacje bazodanowe, mailera oraz komunikację przez web sockets.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607ebd292fb35425592d0860",
            "uuid": "eb639bb2-5fc8-43c7-9734-e1437fdf35f2",
            "title": "Scraping WordPress - 4300 wyroków sądów w sprawach frankowych bez linii kodu",
            "slug": "scraping-wordpressa",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-51-47.png\",\"width\":1745,\"height\":992,\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-55-32.png\",\"width\":1148,\"height\":755}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-57-19.png\",\"width\":1860,\"height\":1091}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://csvjson.com/json2csv\",\"metadata\":{\"url\":\"https://csvjson.com/json2csv\",\"title\":\"JSON to CSV - CSVJSON\",\"description\":\"Online tool for converting JSON to CSV or TSV. Convert JSON to Excel.\",\"author\":null,\"publisher\":\"CSVJSON\",\"thumbnail\":\"https://csvjson.com/img/logo-sponsor-flatfile.svg\",\"icon\":\"https://csvjson.com/img/favicon.ico\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-14-01-40.png\",\"width\":1814,\"height\":673}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-43-17.png\",\"width\":650,\"height\":238}]],\"markups\":[[\"a\",[\"href\",\"https://nawigator.bankowebezprawie.pl/pozwy-indywidualne/\"]],[\"code\"],[\"a\",[\"href\",\"https://datatables.net/\"]],[\"a\",[\"href\",\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/pc.json\"]],[\"a\",[\"href\",\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/pc.json.xlsx\"]],[\"a\",[\"href\",\"https://rejestr.io/krs/573742/stowarzyszenie-stop-bankowemu-bezprawiu\"]],[\"a\",[\"href\",\"https://www.bankowebezprawie.pl/darowizna/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Nie często się zdarza, żeby wykonanie usługi trwało krócej niż jej wycenienie, ale przy scrapingu tak może się stać. Scraping przypomina pod tym względem hacking, że w zależności od zabezpieczeń i skomplikowania systemu, z którego pobieramy dane, może on być banalnie prosty lub stanowić poważne wyzwanie.\"]]],[1,\"p\",[[0,[],0,\"W tym wpisie pokażę jak wykonałem usługę scrapingu zanim zdążyłem ją wycenić. Nie napisałem żadnej linii kodu, a całość zajęła mi kilka minut.\"]]],[1,\"h2\",[[0,[],0,\"Czego potrzebował klient:\"]]],[1,\"p\",[[0,[],0,\"Zapytanie dotyczyły bazy wyroków sądowych ze strony\"]]],[1,\"p\",[[0,[0],1,\"https://nawigator.bankowebezprawie.pl/pozwy-indywidualne/\"]]],[10,0],[1,\"p\",[[0,[],0,\"Dzięki wtyczce Wappalyzer możemy przeczytać, że to WordPress - antyczna technologia, która zwykle jest przyjazna dla scrapingu, bo jej wybór świadczy o braku funduszy na jakiekolwiek antyscrapingowe działania.\"]]],[1,\"p\",[[0,[],0,\"Tabela przeładowuje się w czasie rzeczywistym. Paginacja nie zmienia adresów url. Jest to typowe rozwiązanie dla paczki \"],[0,[1],1,\"datatable\"],[0,[],0,\" będącej wtyczką \"],[0,[1],1,\"jquery\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[2],1,\"https://datatables.net/\"]]],[1,\"p\",[[0,[],0,\" Na stronie tej wtyczki znajdziemy tą samą tabelę, tylko z odrobinę zmienionymi stylami:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Są to wystarczające poszlaki, by sądzić, że dane do tabeli są ładowane z jednej końcówki. Szybka analiza ruchu sieciowego nie pokazuje niczego ciekawego, ale pokazanie źródła strony już tak:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Reszta usługi polegała już tylko na zaznaczeniu tych kilu tysięcy linii tekstu i zapisaniu ich w pliku \"],[0,[1],1,\"json\"],[0,[],0,\". Potencjalnie dla wygody końcowego odbiorcy konwersja do \"],[0,[1],1,\"csv\"],[0,[],0,\" lub \"],[0,[1],1,\"xlsx\"],[0,[],0,\", na przykład na stronie\"]]],[10,3],[10,4],[1,\"p\",[[0,[],0,\"Linki do pobranych danych:\"]]],[1,\"p\",[[0,[3],1,\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/pc.json\"]]],[1,\"p\",[[0,[4],1,\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/pc.json.xlsx\"],[1,[],0,0]]],[1,\"p\",[[0,[],0,\"Na końcu zaznaczę, że mimo, że dostęp do tych danych jest darmowy, to ludzie pracujący nad ich strukturyzacją robią to w ramach wolontariatu aby realizować cel postawiony przez stowarzyszenie:\"]]],[1,\"blockquote\",[[0,[],0,\"B) gromadzenie informacji o nieuczciwych praktykach przedsiębiorcy i innych przypadkach naruszeń prawa przez te podmioty oraz opracowywanie i upublicznianie informacji, artykułów, raportów i opinii w tym zakresie\"]]],[1,\"p\",[[0,[5],1,\"https://rejestr.io/krs/573742/stowarzyszenie-stop-bankowemu-bezprawiu\"]]],[1,\"p\",[[0,[],0,\" Jeśli chcecie korzystać z ich pracy zachęcam Was do wsparcia ich na stronie\"]]],[1,\"p\",[[0,[6],1,\"https://www.bankowebezprawie.pl/darowizna/\"]]],[10,5],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Nie często się zdarza, żeby wykonanie usługi trwało krócej niż jej wycenienie, ale przy scrapingu tak może się stać. Scraping przypomina pod tym względem hacking, że w zależności od zabezpieczeń i skomplikowania systemu, z którego pobieramy dane, może on być banalnie prosty lub stanowić poważne wyzwanie.</p><p>W tym wpisie pokażę jak wykonałem usługę scrapingu zanim zdążyłem ją wycenić. Nie napisałem żadnej linii kodu, a całość zajęła mi kilka minut.</p><h2 id=\"czego-potrzebowa%C5%82-klient\">Czego potrzebował klient:</h2><p>Zapytanie dotyczyły bazy wyroków sądowych ze strony</p><p><a href=\"https://nawigator.bankowebezprawie.pl/pozwy-indywidualne/\">https://nawigator.bankowebezprawie.pl/pozwy-indywidualne/</a></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-51-47.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1745\" height=\"992\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-13-51-47.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/Screenshot-from-2021-04-20-13-51-47.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/04/Screenshot-from-2021-04-20-13-51-47.png 1600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-51-47.png 1745w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Dzięki wtyczce Wappalyzer możemy przeczytać, że to WordPress - antyczna technologia, która zwykle jest przyjazna dla scrapingu, bo jej wybór świadczy o braku funduszy na jakiekolwiek antyscrapingowe działania.</p><p>Tabela przeładowuje się w czasie rzeczywistym. Paginacja nie zmienia adresów url. Jest to typowe rozwiązanie dla paczki <code>datatable</code> będącej wtyczką <code>jquery</code>.</p><p><a href=\"https://datatables.net/\">https://datatables.net/</a></p><p> Na stronie tej wtyczki znajdziemy tą samą tabelę, tylko z odrobinę zmienionymi stylami:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-55-32.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1148\" height=\"755\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-13-55-32.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/Screenshot-from-2021-04-20-13-55-32.png 1000w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-55-32.png 1148w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Są to wystarczające poszlaki, by sądzić, że dane do tabeli są ładowane z jednej końcówki. Szybka analiza ruchu sieciowego nie pokazuje niczego ciekawego, ale pokazanie źródła strony już tak:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-57-19.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1860\" height=\"1091\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-13-57-19.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/Screenshot-from-2021-04-20-13-57-19.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/04/Screenshot-from-2021-04-20-13-57-19.png 1600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-57-19.png 1860w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Reszta usługi polegała już tylko na zaznaczeniu tych kilu tysięcy linii tekstu i zapisaniu ich w pliku <code>json</code>. Potencjalnie dla wygody końcowego odbiorcy konwersja do <code>csv</code> lub <code>xlsx</code>, na przykład na stronie</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://csvjson.com/json2csv\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">JSON to CSV - CSVJSON</div><div class=\"kg-bookmark-description\">Online tool for converting JSON to CSV or TSV. Convert JSON to Excel.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://csvjson.com/img/favicon.ico\"><span class=\"kg-bookmark-author\">CSVJSON</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://csvjson.com/img/logo-sponsor-flatfile.svg\"></div></a></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-14-01-40.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1814\" height=\"673\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-14-01-40.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/Screenshot-from-2021-04-20-14-01-40.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/04/Screenshot-from-2021-04-20-14-01-40.png 1600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-14-01-40.png 1814w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Linki do pobranych danych:</p><p><a href=\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/pc.json\">https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/pc.json</a></p><p><a href=\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/pc.json.xlsx\">https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/pc.json.xlsx</a><br></p><p>Na końcu zaznaczę, że mimo, że dostęp do tych danych jest darmowy, to ludzie pracujący nad ich strukturyzacją robią to w ramach wolontariatu aby realizować cel postawiony przez stowarzyszenie:</p><blockquote>B) gromadzenie informacji o nieuczciwych praktykach przedsiębiorcy i innych przypadkach naruszeń prawa przez te podmioty oraz opracowywanie i upublicznianie informacji, artykułów, raportów i opinii w tym zakresie</blockquote><p><a href=\"https://rejestr.io/krs/573742/stowarzyszenie-stop-bankowemu-bezprawiu\">https://rejestr.io/krs/573742/stowarzyszenie-stop-bankowemu-bezprawiu</a></p><p> Jeśli chcecie korzystać z ich pracy zachęcam Was do wsparcia ich na stronie</p><p><a href=\"https://www.bankowebezprawie.pl/darowizna/\">https://www.bankowebezprawie.pl/darowizna/</a></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-43-17.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"650\" height=\"238\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-20-13-43-17.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-13-43-17.png 650w\"></figure>",
            "comment_id": "607ebd292fb35425592d0860",
            "plaintext": "Nie często się zdarza, żeby wykonanie usługi trwało krócej niż jej wycenienie,\nale przy scrapingu tak może się stać. Scraping przypomina pod tym względem\nhacking, że w zależności od zabezpieczeń i skomplikowania systemu, z którego\npobieramy dane, może on być banalnie prosty lub stanowić poważne wyzwanie.\n\nW tym wpisie pokażę jak wykonałem usługę scrapingu zanim zdążyłem ją wycenić.\nNie napisałem żadnej linii kodu, a całość zajęła mi kilka minut.\n\nCzego potrzebował klient:\nZapytanie dotyczyły bazy wyroków sądowych ze strony\n\nhttps://nawigator.bankowebezprawie.pl/pozwy-indywidualne/\n\nDzięki wtyczce Wappalyzer możemy przeczytać, że to WordPress - antyczna\ntechnologia, która zwykle jest przyjazna dla scrapingu, bo jej wybór świadczy o\nbraku funduszy na jakiekolwiek antyscrapingowe działania.\n\nTabela przeładowuje się w czasie rzeczywistym. Paginacja nie zmienia adresów\nurl. Jest to typowe rozwiązanie dla paczki datatable będącej wtyczką jquery.\n\nhttps://datatables.net/\n\n Na stronie tej wtyczki znajdziemy tą samą tabelę, tylko z odrobinę zmienionymi\nstylami:\n\nSą to wystarczające poszlaki, by sądzić, że dane do tabeli są ładowane z jednej\nkońcówki. Szybka analiza ruchu sieciowego nie pokazuje niczego ciekawego, ale\npokazanie źródła strony już tak:\n\nReszta usługi polegała już tylko na zaznaczeniu tych kilu tysięcy linii tekstu i\nzapisaniu ich w pliku json. Potencjalnie dla wygody końcowego odbiorcy konwersja\ndo csv lub xlsx, na przykład na stronie\n\nJSON to CSV - CSVJSONOnline tool for converting JSON to CSV or TSV. Convert\nJSON\nto Excel.CSVJSON [https://csvjson.com/json2csv]Linki do pobranych danych:\n\nhttps://preciselab.fra1.digitaloceanspaces.com/blog/scraping/pc.json\n\nhttps://preciselab.fra1.digitaloceanspaces.com/blog/scraping/pc.json.xlsx\n\n\nNa końcu zaznaczę, że mimo, że dostęp do tych danych jest darmowy, to ludzie\npracujący nad ich strukturyzacją robią to w ramach wolontariatu aby realizować\ncel postawiony przez stowarzyszenie:\n\n> B) gromadzenie informacji o nieuczciwych praktykach przedsiębiorcy i innych\nprzypadkach naruszeń prawa przez te podmioty oraz opracowywanie i upublicznianie\ninformacji, artykułów, raportów i opinii w tym zakresie\nhttps://rejestr.io/krs/573742/stowarzyszenie-stop-bankowemu-bezprawiu\n\n Jeśli chcecie korzystać z ich pracy zachęcam Was do wsparcia ich na stronie\n\nhttps://www.bankowebezprawie.pl/darowizna/",
            "feature_image": "__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-14-10-23-1.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T11:38:17.000Z",
            "updated_at": "2021-04-20T12:18:07.000Z",
            "published_at": "2021-04-20T12:14:43.000Z",
            "custom_excerpt": "Nie często się zdarza, żeby wykonanie usługi trwało której, niż jej wycenienie, ale przy scrapingu może się tak stać. Zobacz jak łatwe może być pobranie danych, szczególnie z Wordpressa.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f1a3a2fb35425592d0a7a",
            "uuid": "ae27d1d3-b8a5-449f-9821-9bcd5311c65c",
            "title": "Wyciskamy dane z PDF jak sok z cytryny",
            "slug": "wyciskamy-dane-z-pdf-jak-sok-z-cytryny",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/convert-scanned-pdf-to-text.jpg\",\"width\":500,\"height\":353}],[\"code\",{\"code\":\"bilet pkp has:attachment -in:chats from:bilet.eic@intercity.pl to:me\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/gmail.png\",\"width\":1545,\"height\":916}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/text.png\",\"width\":829,\"height\":62}],[\"code\",{\"code\":\"sudo apt-get install poppler-utils\"}],[\"code\",{\"code\":\"pdftotext {PDF-file} {text-file}\"}],[\"code\",{\"code\":\"ls eic_*.pdf | xargs -i pdftotext \\\"{}\\\";\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/text2.png\",\"width\":836,\"height\":63}],[\"code\",{\"code\":\"ls eic_*.txt | xargs -i cat \\\"{}\\\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \\\"$1\\\\n\\\";}' | tr , . | paste -sd+ | bc\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/sum.png\",\"width\":832,\"height\":58}],[\"code\",{\"code\":\"BILET INTERNETOWYTANIOMIASTOWY\\n\\n\\\"PKP Intercity\\\"\\nSpółka Akcyjna\\n\\nOF: 503\\n\\nNORMAL. : 1\\nULG. :\\nX : X\\n\\nPrzewoźnik: PKP IC\\nA-Cena bazowa: 1xNormal\\n\\n¦ ¸\\n\\nOd/From\\n\\n27.09 05:50 Iława Gł.\\n*\\n*\\n*\\nPRZEZ: Działdowo * Nasielsk\\n\\nDo/To\\n\\n¦ ¸\\n\\nKL./CL.\\n\\nWarszawa C.\\n*\\n\\n27.09 07:50\\n*\\n*\\n\\n2\\n*\\n\\nSUMA PLN: 39,90 zł\\n519836278964\\n\\nNr transakcji:\\n\\nInformacje o podróży:\\nStacja\\nData Godzina\\nIława Gł.\\n27.09 05:50\\nWarszawa C.\\n27.09 07:50\\n\\n/Wagon K m\\nIC 5324\\n208\\n5\\n\\neIC67584344\\n\\nNr miejsca (o-okno ś-środek k-korytarz) Suma PLN\\n81 o\\n39,90 zł\\n1 m. do siedzenia; wagon bez przedziałów\\n\\nd9U\\nPodróżny:\\nPTU\\n8%\\n\\nSuma PLN Płatność: przelewem\\n39,90 Zapłacono i wystawiono dnia:\\n2018-09-26 09:01:20(52245592)\\n\\nOgółem PLN:\\n\\n39,90\\n\\nNiniejszy bilet internetowy nie jest fakturą VAT.\\nW związku z przeprowadzanymi modernizacjami sieci kolejowej, uprzejmie prosimy o\\ndokładne sprawdzanie rozkładu jazdy pociągów przed podróżą.\\n\\nData wydruku: 2018-09-26 09:01:57\\n\\n5324\\n\\nBilet internetowy jest biletem imiennym i jest ważny:\\na) wraz z dokumentem ze zdjęciem potwierdzającym tożsamość Podróżnego,\\nb) tylko w dniu, relacji, pociągu, wagonie i na miejsce na nim oznaczone.\\n\\nZwrotu należności za niewykorzystany bilet dokonuje się na podstawie wniosku\\nzłożonego przez płatnika w wyznaczonych przez 'PKP Intercity' S.A. punktach, z\\nwyjątkiem należności zwracanych automatycznie na zasadach określonych w\\nRegulaminie e-IC.\\n\\nDaniel Gustaw\\n\\nd9U\\n\\nInformacja o cenie\\nOpłata za przejazd:\\n\\n(P24) 7219\"}],[\"code\",{\"code\":\"$ cat eic_67584344.txt | perl -ne 'if(/SUMA PLN: (.*) zł/){print \\\"$1\\\\n\\\";}'\\n39,90\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/tr.png\",\"width\":835,\"height\":61}],[\"code\",{\"code\":\"$ ls eic_*.txt | xargs -i cat \\\"{}\\\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \\\"$1\\\\n\\\";}' | tr , .\\n39.90\\n63.00\\n15.14\\n55.00\\n60.00\\n186.00\\n70.56\\n89.40\\n139.00\\n68.11\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/paste.png\",\"width\":833,\"height\":56}],[\"code\",{\"code\":\"$ ls eic_*.txt | xargs -i cat \\\"{}\\\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \\\"$1\\\\n\\\";}' | tr , . | paste -sd+ | bc\\n786.11\"}],[\"code\",{\"code\":\"wget https://github.com/marianogappa/chart/releases/download/v3.0.0/chart_3.0.0_linux_amd64.tar.gz -O /tmp/chart.tar.gz\"}],[\"code\",{\"code\":\"tar -xvf /tmp/chart.tar.gz --directory /usr/local/bin\"}],[\"code\",{\"code\":\"ls eic_*.txt | xargs -i cat \\\"{}\\\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \\\"$1\\\\n\\\";}' | tr , . | cat -n | chart line\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/graph.png\",\"width\":1299,\"height\":665}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://calendly.com/gustaw-daniel\",\"metadata\":{\"url\":\"https://calendly.com/gustaw-daniel\",\"title\":\"Daniel Gustaw\",\"description\":\"Welcome to my scheduling page. Please follow the instructions to add an event to my calendar.\",\"author\":null,\"publisher\":\"Calendly\",\"thumbnail\":\"https://assets.calendly.com/assets/ogimage-a63bb2f442cd9e6345a5e4d7fe75393c6cfcc1ff29e48e858742d43573a8b02c.png?source=opengraph\",\"icon\":\"https://assets.calendly.com/assets/touch-icon-ipad-retina-7a95e0c775301f4c0a22002bdf0a95d3c2b9cbe95af29c64f9c9573bac1f01e4.png\"}}]],\"markups\":[[\"strong\"],[\"code\"],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Data_cleansing\"]],[\"a\",[\"href\",\"https://www.cyberciti.biz/faq/converter-pdf-files-to-text-format-command/\"]],[\"a\",[\"href\",\"https://stackoverflow.com/questions/33141207/what-is-the-working-of-this-command-ls-xargs-i-t-cp-1\"]],[\"a\",[\"href\",\"https://marianogappa.github.io/chart/\"]],[\"a\",[\"href\",\"https://www.geeksforgeeks.org/paste-command-in-linux-with-examples/\"]],[\"a\",[\"href\",\"https://www.rexegg.com/regex-perl-one-liners.html\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Dane są wszystkim co jest lub może być przetwarzane umysłowo lub komputerowo. Przy obróbce komputerowej niektóre formy ich zapisu są mniej lub bardziej wygodne. Na przykład PDF uznawany jest za formę wygodną dla człowieka, ale często nie doceniamy możliwości maszyn w automatyzacji procesów opartych o pliki PDF.\"]]],[1,\"p\",[[0,[],0,\"W tym wpisie pokarzemy jak pisząc naprawdę znikome ilości kodu można wygodnie wydobyć dane z plików PDF. Dla przykładu posłużymy się biletami kolejowymi ponieważ nie zawierają żadnych danych objętych tajemnicą, ale równie dobrze mogły to by być faktury, umowy czy pliki CV.\"]]],[10,0],[1,\"p\",[[1,[],0,0],[0,[0],1,\"Zdobycie danych\"]]],[1,\"p\",[[0,[],0,\"Przy każdym zakupie biletu z adresu \"],[0,[1],1,\"bilet.eic@intercity.pl\"],[0,[],0,\" wysyłany jest do mnie e-mail zawierający bilet. Łatwo mogę wyszukać te e-maile wybierając filtr w poczcie z której korzystam\"]]],[10,1],[1,\"p\",[[0,[],0,\"Oto widok jaki widzę po filtrowaniu:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Teraz wystarczyło pobrać pliki aby móc poddać je obróbce.\"]]],[1,\"p\",[[0,[],0,\"Wszystkie załączniki zapisałem na dysku twardym w katalogu ocr. Tak jak w każdym z wpisów na tym blogu dalsze operacje będą wykonywane na systemie Ubuntu.\"]]],[1,\"h2\",[[0,[0],1,\"Przetworzenie PDF do postaci tekstu\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od ustalenia początkowej zawartości katalogu. Jest wypełniony pikamy PDF.\"]]],[10,3],[1,\"p\",[[0,[],0,\"Dzięki narzędziu \"],[0,[1],1,\"pdftotext\"],[0,[],0,\" z pakietu \"],[0,[1],1,\"poppler-utils\"],[0,[],0,\" możemy wydobyć z plików PDF interesujące nas informacje w postaci czystego tekstu. Następującym poleceniem możemy zainstalować to narzędzie:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Aby go użyć korzystamy ze składni\"]]],[10,5],[1,\"p\",[[0,[],0,\"W naszym przypadku mamy wiele plików wejściowych i wyjściowych dlatego skorzystamy z \"],[0,[1],1,\"xargs\"],[0,[],0,\".\"]]],[10,6],[1,\"p\",[[0,[],0,\"Polecenie to składa się z dwóch części. W pierwszej listuję wszystkie pliki zaczynające się od \"],[0,[1],1,\"eic\"],[0,[],0,\" i kończące się na \"],[0,[1],1,\".pdf\"],[0,[],0,\". Następnie używając programu \"],[0,[1],1,\"xargs\"],[0,[],0,\" wynik przechwytywany jako strumień danych przekazuję linia po linii do polecenia \"],[0,[1],1,\"pdftotext\"],[0,[],0,\". Brak drugiego argumentu oznacza, że w moim przypadku powstały pliki tekstowe o takich samych nazwach jak pliki \"],[0,[1],1,\"pdf\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Łatwo sprawdzimy czy faktycznie istnieją dzięki poleceniu \"],[0,[1],1,\"ls\"]]],[10,7],[1,\"p\",[[0,[0],1,\"Strukturyzacja danych\"]]],[1,\"p\",[[0,[],0,\"Na początek zaczniemy od czegoś prostego. Załóżmy, że chcemy policzyć ile pieniędzy łącznie wydałem na bilety, ale nie będziemy sprawdzali tego na każdym bilecie po kolei ręcznie - od tego jest komputer. Poza tym gdy dostaniemy inny zestaw biletów ręczną robotę musieli byśmy powtarzać. Może Cię to zaskoczyć, ale aby wykonać to zadanie nie trzeba nawet edytora kodu i napisaliśmy to w jednej linii:\"]]],[10,8],[1,\"p\",[[0,[],0,\"Ta linia zwróciła \"],[0,[1],1,\"786.11\"],[0,[],0,\" czyli koszt wszystkich biletów.\"]]],[10,9],[1,\"p\",[[0,[],0,\"Wejdziemy teraz głębiej i zobaczmy co się za tym kryje. Wyświetlimy jeden z plików tekstowych poleceniem \"],[0,[1],1,\"cat eic_67584344.txt\"],[0,[],0,\":\"]]],[10,10],[1,\"p\",[[0,[],0,\"Pierwsze co się nasuwa to, że plik zawiera wszystkie informacje w formie nienaruszonej. Nie ma żadnych literówek, błędów, przestawień jakie typowe są dla systemów OCR wykonujących analogiczną pracę na skanach dokumentów. Cena \"],[0,[1],1,\"39,90 zł\"],[0,[],0,\" powtarza się tu w kilku liniach. Czasami występuje razem z \"],[0,[1],1,\"zł\"],[0,[],0,\", czasami nie, może się zdarzyć, że układ linii będzie inny jeśli na bilecie będzie jechało kilka osób. Szukamy najbardziej wiarygodnego wzorca. Jest nim \"],[0,[1],1,\"SUMA PLN: 39,90 zł\"],[0,[],0,\". Teraz chcemy wyłowić z tego pliku właśnie \"],[0,[1],1,\"39,90\"],[0,[],0,\". Posłuży nam do tego \"],[0,[1],1,\"perl\"],[0,[],0,\" - język stworzony przez lingwistę Larrego Walla właśnie w celu pracy z plikami tekstowymi.\"]]],[10,11],[1,\"p\",[[0,[],0,\"Polecenie to można wytłumaczyć następująco:\"]]],[3,\"ul\",[[[0,[],0,\"weź plik \"],[0,[1],1,\"eic_67584344.txt\"]],[[0,[],0,\"całą jego zawartość przekieruj do programu który napisaliśmy w \"],[0,[1],1,\"perl\"],[0,[],0,\" jako wejście\"]],[[0,[],0,\"program na każdej linii tekstu wykonuje to samo polecenie\"]],[[0,[],0,\"sprawdza czy tekst pasuje do wzorca zaczynającego się od \"],[0,[1],1,\"SUMA PLN:\"],[0,[],0,\" i kończącego na \"],[0,[1],1,\"zł\"],[0,[],0,\".\"]],[[0,[],0,\"jeśli tak, to wycina wartość między tymi ciągami znakowymi i ją zwraca\"]]]],[1,\"p\",[[0,[],0,\"Problem jaki mamy to polski \"],[0,[1],1,\",\"],[0,[],0,\" zamiast ogólnie stosowanej na świecie \"],[0,[1],1,\".\"],[0,[],0,\". Ten problem bardzo łatwo eliminujemy poleceniem \"],[0,[1],1,\"tr\"],[0,[],0,\" które zamienia swój pierwszy argument na drugi.\"]]],[10,12],[1,\"p\",[[0,[],0,\"Nie będziemy oczywiście powtarzać tych poleceń dla każdego pliku osobno. Zamiast tego ponownie wykorzystamy znany już \"],[0,[1],1,\"xargs\"]]],[10,13],[1,\"p\",[[0,[],0,\"Pozwolił nam na przeszukanie plików tekstowych za pomocą zdefiniowanych filtrów plik po pliku. Z ciekawszych rzeczy to wykorzystane \"],[0,[1],1,\"\\\"{}\\\"\"],[0,[],0,\" oznacza argument który wszedł do \"],[0,[1],1,\"xargs\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Zostało już tylko sumowanie, ale suma kolumn z pliku tekstowego to bułka z masłem w konsoli \"],[0,[1],1,\"bash\"],[0,[],0,\". W przypadku jednej kolumny nie trzeba nawet uruchamiać \"],[0,[1],1,\"awk\"],[0,[],0,\" - zaawansowanego programu do przetwarzania tekstów. Wystarczy nam \"],[0,[1],1,\"paste\"],[0,[],0,\" - program do łączenia plików i \"],[0,[1],1,\"bc\"],[0,[],0,\" prosty program do liczenia sum.\"]]],[1,\"p\",[[0,[],0,\"Za pomocą \"],[0,[1],1,\"paste\"],[0,[],0,\" z opcją \"],[0,[1],1,\"-s\"],[0,[],0,\" wykonamy transpozycję do jednej linii. Opcją \"],[0,[1],1,\"d\"],[0,[],0,\" ustawimy separator. Będzie nim oczywiście znak dodawania \"],[0,[1],1,\"+\"],[0,[],0,\". Wynik wygląda miej więcej tak:\"]]],[10,14],[1,\"p\",[[0,[],0,\"Ostatnia cegiełka \"],[0,[1],1,\"bc\"],[0,[],0,\" kończy zadanie, ale to było prezentowane na samym początku:\"]]],[10,15],[1,\"h2\",[[0,[0],1,\"Wizualizacja wyników\"]]],[1,\"p\",[[0,[],0,\"Ponieważ pliki ułożone są chronologicznie wyświetlimy łatwo będzie nam zobaczyć wykres kolejnych cen. W tym celu pobieramy \"],[0,[1],1,\"chart\"],[0,[],0,\" - paczkę napisaną w \"],[0,[1],1,\"go\"],[0,[],0,\" służącą do tworzenia wykresów.\"]]],[10,16],[1,\"p\",[[0,[],0,\"I rozpakowujemy\"]]],[10,17],[1,\"p\",[[0,[],0,\"Kolejna komenda, dodaje numery kolumn \"],[0,[1],1,\"cat -n\"],[0,[],0,\" i rysuje wykres\"]]],[10,18],[10,19],[1,\"p\",[[0,[],0,\"Podsumowując. Nie napracowaliśmy się tutaj za bardzo ale właśnie to było celem. Pokazanie jak jedną linią kodu można posumować ceny lub wyrysować wykres z danych, które pozornie są niedostępne, bo ich format nie jest tak oczywisty jak w przypadku uporządkowanych danych zapisanych w bazie o dobrze określonej strukturze.\"]]],[1,\"p\",[[0,[],0,\"Jeśli jesteś przedsiębiorcą i zainteresował Cię temat automatyzacji przetwarzania dokumentów umów się ze mną na darmową konsultację korzystając z linku\"]]],[10,20],[1,\"p\",[[0,[],0,\"Jeśli chcesz poszerzyć swoją wiedzę i zapoznać się z narzędziami z których korzystaliśmy linki do nich znajdziesz poniżej:\"]]],[1,\"p\",[[0,[],0,\"Czyszczenie danych\"]]],[1,\"p\",[[0,[2],1,\"https://en.wikipedia.org/wiki/Data_cleansing\"]]],[1,\"p\",[[0,[],0,\"Pdf to Text Converter\"]]],[1,\"p\",[[0,[3],1,\"https://www.cyberciti.biz/faq/converter-pdf-files-to-text-format-command/\"]]],[1,\"p\",[[0,[],0,\"Przykład zastosowania xargs\"]]],[1,\"p\",[[0,[4],1,\"https://stackoverflow.com/questions/33141207/what-is-the-working-of-this-command-ls-xargs-i-t-cp-1\"]]],[1,\"p\",[[0,[],0,\"Chart - narzędzie do rysowania wykresów\"]]],[1,\"p\",[[0,[5],1,\"https://marianogappa.github.io/chart/\"]]],[1,\"p\",[[0,[],0,\"Paste - komenda do łączenia plików\"]]],[1,\"p\",[[0,[6],1,\"https://www.geeksforgeeks.org/paste-command-in-linux-with-examples/\"]]],[1,\"p\",[[0,[],0,\"Przykładowe onelinery w Perlu\"]]],[1,\"p\",[[0,[7],1,\"https://www.rexegg.com/regex-perl-one-liners.html\"]]],[1,\"p\",[]],[1,\"p\",[]],[1,\"p\",[]],[1,\"p\",[]],[1,\"p\",[]],[1,\"p\",[]],[1,\"p\",[]],[1,\"p\",[[1,[],0,1]]],[1,\"p\",[[1,[],0,2]]],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Dane są wszystkim co jest lub może być przetwarzane umysłowo lub komputerowo. Przy obróbce komputerowej niektóre formy ich zapisu są mniej lub bardziej wygodne. Na przykład PDF uznawany jest za formę wygodną dla człowieka, ale często nie doceniamy możliwości maszyn w automatyzacji procesów opartych o pliki PDF.</p><p>W tym wpisie pokarzemy jak pisząc naprawdę znikome ilości kodu można wygodnie wydobyć dane z plików PDF. Dla przykładu posłużymy się biletami kolejowymi ponieważ nie zawierają żadnych danych objętych tajemnicą, ale równie dobrze mogły to by być faktury, umowy czy pliki CV.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/convert-scanned-pdf-to-text.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"353\"></figure><p><br><strong>Zdobycie danych</strong></p><p>Przy każdym zakupie biletu z adresu <code>bilet.eic@intercity.pl</code> wysyłany jest do mnie e-mail zawierający bilet. Łatwo mogę wyszukać te e-maile wybierając filtr w poczcie z której korzystam</p><pre><code>bilet pkp has:attachment -in:chats from:bilet.eic@intercity.pl to:me</code></pre><p>Oto widok jaki widzę po filtrowaniu:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/gmail.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1545\" height=\"916\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/gmail.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/gmail.png 1000w, __GHOST_URL__/content/images/2021/04/gmail.png 1545w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Teraz wystarczyło pobrać pliki aby móc poddać je obróbce.</p><p>Wszystkie załączniki zapisałem na dysku twardym w katalogu ocr. Tak jak w każdym z wpisów na tym blogu dalsze operacje będą wykonywane na systemie Ubuntu.</p><h2 id=\"przetworzenie-pdf-do-postaci-tekstu\"><strong>Przetworzenie PDF do postaci tekstu</strong></h2><p>Zaczniemy od ustalenia początkowej zawartości katalogu. Jest wypełniony pikamy PDF.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/text.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"829\" height=\"62\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/text.png 600w, __GHOST_URL__/content/images/2021/04/text.png 829w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Dzięki narzędziu <code>pdftotext</code> z pakietu <code>poppler-utils</code> możemy wydobyć z plików PDF interesujące nas informacje w postaci czystego tekstu. Następującym poleceniem możemy zainstalować to narzędzie:</p><pre><code>sudo apt-get install poppler-utils</code></pre><p>Aby go użyć korzystamy ze składni</p><pre><code>pdftotext {PDF-file} {text-file}</code></pre><p>W naszym przypadku mamy wiele plików wejściowych i wyjściowych dlatego skorzystamy z <code>xargs</code>.</p><pre><code>ls eic_*.pdf | xargs -i pdftotext \"{}\";</code></pre><p>Polecenie to składa się z dwóch części. W pierwszej listuję wszystkie pliki zaczynające się od <code>eic</code> i kończące się na <code>.pdf</code>. Następnie używając programu <code>xargs</code> wynik przechwytywany jako strumień danych przekazuję linia po linii do polecenia <code>pdftotext</code>. Brak drugiego argumentu oznacza, że w moim przypadku powstały pliki tekstowe o takich samych nazwach jak pliki <code>pdf</code>.</p><p>Łatwo sprawdzimy czy faktycznie istnieją dzięki poleceniu <code>ls</code></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/text2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"836\" height=\"63\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/text2.png 600w, __GHOST_URL__/content/images/2021/04/text2.png 836w\" sizes=\"(min-width: 720px) 720px\"></figure><p><strong>Strukturyzacja danych</strong></p><p>Na początek zaczniemy od czegoś prostego. Załóżmy, że chcemy policzyć ile pieniędzy łącznie wydałem na bilety, ale nie będziemy sprawdzali tego na każdym bilecie po kolei ręcznie - od tego jest komputer. Poza tym gdy dostaniemy inny zestaw biletów ręczną robotę musieli byśmy powtarzać. Może Cię to zaskoczyć, ale aby wykonać to zadanie nie trzeba nawet edytora kodu i napisaliśmy to w jednej linii:</p><pre><code>ls eic_*.txt | xargs -i cat \"{}\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \"$1\\n\";}' | tr , . | paste -sd+ | bc</code></pre><p>Ta linia zwróciła <code>786.11</code> czyli koszt wszystkich biletów.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/sum.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"832\" height=\"58\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/sum.png 600w, __GHOST_URL__/content/images/2021/04/sum.png 832w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Wejdziemy teraz głębiej i zobaczmy co się za tym kryje. Wyświetlimy jeden z plików tekstowych poleceniem <code>cat eic_67584344.txt</code>:</p><pre><code>BILET INTERNETOWYTANIOMIASTOWY\n\n\"PKP Intercity\"\nSpółka Akcyjna\n\nOF: 503\n\nNORMAL. : 1\nULG. :\nX : X\n\nPrzewoźnik: PKP IC\nA-Cena bazowa: 1xNormal\n\n¦ ¸\n\nOd/From\n\n27.09 05:50 Iława Gł.\n*\n*\n*\nPRZEZ: Działdowo * Nasielsk\n\nDo/To\n\n¦ ¸\n\nKL./CL.\n\nWarszawa C.\n*\n\n27.09 07:50\n*\n*\n\n2\n*\n\nSUMA PLN: 39,90 zł\n519836278964\n\nNr transakcji:\n\nInformacje o podróży:\nStacja\nData Godzina\nIława Gł.\n27.09 05:50\nWarszawa C.\n27.09 07:50\n\n/Wagon K m\nIC 5324\n208\n5\n\neIC67584344\n\nNr miejsca (o-okno ś-środek k-korytarz) Suma PLN\n81 o\n39,90 zł\n1 m. do siedzenia; wagon bez przedziałów\n\nd9U\nPodróżny:\nPTU\n8%\n\nSuma PLN Płatność: przelewem\n39,90 Zapłacono i wystawiono dnia:\n2018-09-26 09:01:20(52245592)\n\nOgółem PLN:\n\n39,90\n\nNiniejszy bilet internetowy nie jest fakturą VAT.\nW związku z przeprowadzanymi modernizacjami sieci kolejowej, uprzejmie prosimy o\ndokładne sprawdzanie rozkładu jazdy pociągów przed podróżą.\n\nData wydruku: 2018-09-26 09:01:57\n\n5324\n\nBilet internetowy jest biletem imiennym i jest ważny:\na) wraz z dokumentem ze zdjęciem potwierdzającym tożsamość Podróżnego,\nb) tylko w dniu, relacji, pociągu, wagonie i na miejsce na nim oznaczone.\n\nZwrotu należności za niewykorzystany bilet dokonuje się na podstawie wniosku\nzłożonego przez płatnika w wyznaczonych przez 'PKP Intercity' S.A. punktach, z\nwyjątkiem należności zwracanych automatycznie na zasadach określonych w\nRegulaminie e-IC.\n\nDaniel Gustaw\n\nd9U\n\nInformacja o cenie\nOpłata za przejazd:\n\n(P24) 7219</code></pre><p>Pierwsze co się nasuwa to, że plik zawiera wszystkie informacje w formie nienaruszonej. Nie ma żadnych literówek, błędów, przestawień jakie typowe są dla systemów OCR wykonujących analogiczną pracę na skanach dokumentów. Cena <code>39,90 zł</code> powtarza się tu w kilku liniach. Czasami występuje razem z <code>zł</code>, czasami nie, może się zdarzyć, że układ linii będzie inny jeśli na bilecie będzie jechało kilka osób. Szukamy najbardziej wiarygodnego wzorca. Jest nim <code>SUMA PLN: 39,90 zł</code>. Teraz chcemy wyłowić z tego pliku właśnie <code>39,90</code>. Posłuży nam do tego <code>perl</code> - język stworzony przez lingwistę Larrego Walla właśnie w celu pracy z plikami tekstowymi.</p><pre><code>$ cat eic_67584344.txt | perl -ne 'if(/SUMA PLN: (.*) zł/){print \"$1\\n\";}'\n39,90</code></pre><p>Polecenie to można wytłumaczyć następująco:</p><ul><li>weź plik <code>eic_67584344.txt</code></li><li>całą jego zawartość przekieruj do programu który napisaliśmy w <code>perl</code> jako wejście</li><li>program na każdej linii tekstu wykonuje to samo polecenie</li><li>sprawdza czy tekst pasuje do wzorca zaczynającego się od <code>SUMA PLN:</code> i kończącego na <code>zł</code>.</li><li>jeśli tak, to wycina wartość między tymi ciągami znakowymi i ją zwraca</li></ul><p>Problem jaki mamy to polski <code>,</code> zamiast ogólnie stosowanej na świecie <code>.</code>. Ten problem bardzo łatwo eliminujemy poleceniem <code>tr</code> które zamienia swój pierwszy argument na drugi.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/tr.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"835\" height=\"61\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/tr.png 600w, __GHOST_URL__/content/images/2021/04/tr.png 835w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Nie będziemy oczywiście powtarzać tych poleceń dla każdego pliku osobno. Zamiast tego ponownie wykorzystamy znany już <code>xargs</code></p><pre><code>$ ls eic_*.txt | xargs -i cat \"{}\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \"$1\\n\";}' | tr , .\n39.90\n63.00\n15.14\n55.00\n60.00\n186.00\n70.56\n89.40\n139.00\n68.11</code></pre><p>Pozwolił nam na przeszukanie plików tekstowych za pomocą zdefiniowanych filtrów plik po pliku. Z ciekawszych rzeczy to wykorzystane <code>\"{}\"</code> oznacza argument który wszedł do <code>xargs</code>.</p><p>Zostało już tylko sumowanie, ale suma kolumn z pliku tekstowego to bułka z masłem w konsoli <code>bash</code>. W przypadku jednej kolumny nie trzeba nawet uruchamiać <code>awk</code> - zaawansowanego programu do przetwarzania tekstów. Wystarczy nam <code>paste</code> - program do łączenia plików i <code>bc</code> prosty program do liczenia sum.</p><p>Za pomocą <code>paste</code> z opcją <code>-s</code> wykonamy transpozycję do jednej linii. Opcją <code>d</code> ustawimy separator. Będzie nim oczywiście znak dodawania <code>+</code>. Wynik wygląda miej więcej tak:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/paste.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"833\" height=\"56\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/paste.png 600w, __GHOST_URL__/content/images/2021/04/paste.png 833w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Ostatnia cegiełka <code>bc</code> kończy zadanie, ale to było prezentowane na samym początku:</p><pre><code>$ ls eic_*.txt | xargs -i cat \"{}\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \"$1\\n\";}' | tr , . | paste -sd+ | bc\n786.11</code></pre><h2 id=\"wizualizacja-wynik%C3%B3w\"><strong>Wizualizacja wyników</strong></h2><p>Ponieważ pliki ułożone są chronologicznie wyświetlimy łatwo będzie nam zobaczyć wykres kolejnych cen. W tym celu pobieramy <code>chart</code> - paczkę napisaną w <code>go</code> służącą do tworzenia wykresów.</p><pre><code>wget https://github.com/marianogappa/chart/releases/download/v3.0.0/chart_3.0.0_linux_amd64.tar.gz -O /tmp/chart.tar.gz</code></pre><p>I rozpakowujemy</p><pre><code>tar -xvf /tmp/chart.tar.gz --directory /usr/local/bin</code></pre><p>Kolejna komenda, dodaje numery kolumn <code>cat -n</code> i rysuje wykres</p><pre><code>ls eic_*.txt | xargs -i cat \"{}\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \"$1\\n\";}' | tr , . | cat -n | chart line</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/graph.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1299\" height=\"665\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/graph.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/graph.png 1000w, __GHOST_URL__/content/images/2021/04/graph.png 1299w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Podsumowując. Nie napracowaliśmy się tutaj za bardzo ale właśnie to było celem. Pokazanie jak jedną linią kodu można posumować ceny lub wyrysować wykres z danych, które pozornie są niedostępne, bo ich format nie jest tak oczywisty jak w przypadku uporządkowanych danych zapisanych w bazie o dobrze określonej strukturze.</p><p>Jeśli jesteś przedsiębiorcą i zainteresował Cię temat automatyzacji przetwarzania dokumentów umów się ze mną na darmową konsultację korzystając z linku</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://calendly.com/gustaw-daniel\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Daniel Gustaw</div><div class=\"kg-bookmark-description\">Welcome to my scheduling page. Please follow the instructions to add an event to my calendar.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets.calendly.com/assets/touch-icon-ipad-retina-7a95e0c775301f4c0a22002bdf0a95d3c2b9cbe95af29c64f9c9573bac1f01e4.png\"><span class=\"kg-bookmark-author\">Calendly</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets.calendly.com/assets/ogimage-a63bb2f442cd9e6345a5e4d7fe75393c6cfcc1ff29e48e858742d43573a8b02c.png?source&#x3D;opengraph\"></div></a></figure><p>Jeśli chcesz poszerzyć swoją wiedzę i zapoznać się z narzędziami z których korzystaliśmy linki do nich znajdziesz poniżej:</p><p>Czyszczenie danych</p><p><a href=\"https://en.wikipedia.org/wiki/Data_cleansing\">https://en.wikipedia.org/wiki/Data_cleansing</a></p><p>Pdf to Text Converter</p><p><a href=\"https://www.cyberciti.biz/faq/converter-pdf-files-to-text-format-command/\">https://www.cyberciti.biz/faq/converter-pdf-files-to-text-format-command/</a></p><p>Przykład zastosowania xargs</p><p><a href=\"https://stackoverflow.com/questions/33141207/what-is-the-working-of-this-command-ls-xargs-i-t-cp-1\">https://stackoverflow.com/questions/33141207/what-is-the-working-of-this-command-ls-xargs-i-t-cp-1</a></p><p>Chart - narzędzie do rysowania wykresów</p><p><a href=\"https://marianogappa.github.io/chart/\">https://marianogappa.github.io/chart/</a></p><p>Paste - komenda do łączenia plików</p><p><a href=\"https://www.geeksforgeeks.org/paste-command-in-linux-with-examples/\">https://www.geeksforgeeks.org/paste-command-in-linux-with-examples/</a></p><p>Przykładowe onelinery w Perlu</p><p><a href=\"https://www.rexegg.com/regex-perl-one-liners.html\">https://www.rexegg.com/regex-perl-one-liners.html</a></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><br></p><p><br></p><p></p>",
            "comment_id": "607f1a3a2fb35425592d0a7a",
            "plaintext": "Dane są wszystkim co jest lub może być przetwarzane umysłowo lub komputerowo.\nPrzy obróbce komputerowej niektóre formy ich zapisu są mniej lub bardziej\nwygodne. Na przykład PDF uznawany jest za formę wygodną dla człowieka, ale\nczęsto nie doceniamy możliwości maszyn w automatyzacji procesów opartych o pliki\nPDF.\n\nW tym wpisie pokarzemy jak pisząc naprawdę znikome ilości kodu można wygodnie\nwydobyć dane z plików PDF. Dla przykładu posłużymy się biletami kolejowymi\nponieważ nie zawierają żadnych danych objętych tajemnicą, ale równie dobrze\nmogły to by być faktury, umowy czy pliki CV.\n\n\nZdobycie danych\n\nPrzy każdym zakupie biletu z adresu bilet.eic@intercity.pl wysyłany jest do mnie\ne-mail zawierający bilet. Łatwo mogę wyszukać te e-maile wybierając filtr w\npoczcie z której korzystam\n\nbilet pkp has:attachment -in:chats from:bilet.eic@intercity.pl to:me\n\nOto widok jaki widzę po filtrowaniu:\n\nTeraz wystarczyło pobrać pliki aby móc poddać je obróbce.\n\nWszystkie załączniki zapisałem na dysku twardym w katalogu ocr. Tak jak w każdym\nz wpisów na tym blogu dalsze operacje będą wykonywane na systemie Ubuntu.\n\nPrzetworzenie PDF do postaci tekstu\nZaczniemy od ustalenia początkowej zawartości katalogu. Jest wypełniony pikamy\nPDF.\n\nDzięki narzędziu pdftotext z pakietu poppler-utils możemy wydobyć z plików PDF\ninteresujące nas informacje w postaci czystego tekstu. Następującym poleceniem\nmożemy zainstalować to narzędzie:\n\nsudo apt-get install poppler-utils\n\nAby go użyć korzystamy ze składni\n\npdftotext {PDF-file} {text-file}\n\nW naszym przypadku mamy wiele plików wejściowych i wyjściowych dlatego\nskorzystamy z xargs.\n\nls eic_*.pdf | xargs -i pdftotext \"{}\";\n\nPolecenie to składa się z dwóch części. W pierwszej listuję wszystkie pliki\nzaczynające się od eic i kończące się na .pdf. Następnie używając programu xargs \nwynik przechwytywany jako strumień danych przekazuję linia po linii do polecenia \npdftotext. Brak drugiego argumentu oznacza, że w moim przypadku powstały pliki\ntekstowe o takich samych nazwach jak pliki pdf.\n\nŁatwo sprawdzimy czy faktycznie istnieją dzięki poleceniu ls\n\nStrukturyzacja danych\n\nNa początek zaczniemy od czegoś prostego. Załóżmy, że chcemy policzyć ile\npieniędzy łącznie wydałem na bilety, ale nie będziemy sprawdzali tego na każdym\nbilecie po kolei ręcznie - od tego jest komputer. Poza tym gdy dostaniemy inny\nzestaw biletów ręczną robotę musieli byśmy powtarzać. Może Cię to zaskoczyć, ale\naby wykonać to zadanie nie trzeba nawet edytora kodu i napisaliśmy to w jednej\nlinii:\n\nls eic_*.txt | xargs -i cat \"{}\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \"$1\\n\";}' | tr , . | paste -sd+ | bc\n\nTa linia zwróciła 786.11 czyli koszt wszystkich biletów.\n\nWejdziemy teraz głębiej i zobaczmy co się za tym kryje. Wyświetlimy jeden z\nplików tekstowych poleceniem cat eic_67584344.txt:\n\nBILET INTERNETOWYTANIOMIASTOWY\n\n\"PKP Intercity\"\nSpółka Akcyjna\n\nOF: 503\n\nNORMAL. : 1\nULG. :\nX : X\n\nPrzewoźnik: PKP IC\nA-Cena bazowa: 1xNormal\n\n¦ ¸\n\nOd/From\n\n27.09 05:50 Iława Gł.\n*\n*\n*\nPRZEZ: Działdowo * Nasielsk\n\nDo/To\n\n¦ ¸\n\nKL./CL.\n\nWarszawa C.\n*\n\n27.09 07:50\n*\n*\n\n2\n*\n\nSUMA PLN: 39,90 zł\n519836278964\n\nNr transakcji:\n\nInformacje o podróży:\nStacja\nData Godzina\nIława Gł.\n27.09 05:50\nWarszawa C.\n27.09 07:50\n\n/Wagon K m\nIC 5324\n208\n5\n\neIC67584344\n\nNr miejsca (o-okno ś-środek k-korytarz) Suma PLN\n81 o\n39,90 zł\n1 m. do siedzenia; wagon bez przedziałów\n\nd9U\nPodróżny:\nPTU\n8%\n\nSuma PLN Płatność: przelewem\n39,90 Zapłacono i wystawiono dnia:\n2018-09-26 09:01:20(52245592)\n\nOgółem PLN:\n\n39,90\n\nNiniejszy bilet internetowy nie jest fakturą VAT.\nW związku z przeprowadzanymi modernizacjami sieci kolejowej, uprzejmie prosimy o\ndokładne sprawdzanie rozkładu jazdy pociągów przed podróżą.\n\nData wydruku: 2018-09-26 09:01:57\n\n5324\n\nBilet internetowy jest biletem imiennym i jest ważny:\na) wraz z dokumentem ze zdjęciem potwierdzającym tożsamość Podróżnego,\nb) tylko w dniu, relacji, pociągu, wagonie i na miejsce na nim oznaczone.\n\nZwrotu należności za niewykorzystany bilet dokonuje się na podstawie wniosku\nzłożonego przez płatnika w wyznaczonych przez 'PKP Intercity' S.A. punktach, z\nwyjątkiem należności zwracanych automatycznie na zasadach określonych w\nRegulaminie e-IC.\n\nDaniel Gustaw\n\nd9U\n\nInformacja o cenie\nOpłata za przejazd:\n\n(P24) 7219\n\nPierwsze co się nasuwa to, że plik zawiera wszystkie informacje w formie\nnienaruszonej. Nie ma żadnych literówek, błędów, przestawień jakie typowe są dla\nsystemów OCR wykonujących analogiczną pracę na skanach dokumentów. Cena 39,90 zł \npowtarza się tu w kilku liniach. Czasami występuje razem z zł, czasami nie, może\nsię zdarzyć, że układ linii będzie inny jeśli na bilecie będzie jechało kilka\nosób. Szukamy najbardziej wiarygodnego wzorca. Jest nim SUMA PLN: 39,90 zł.\nTeraz chcemy wyłowić z tego pliku właśnie 39,90. Posłuży nam do tego perl -\njęzyk stworzony przez lingwistę Larrego Walla właśnie w celu pracy z plikami\ntekstowymi.\n\n$ cat eic_67584344.txt | perl -ne 'if(/SUMA PLN: (.*) zł/){print \"$1\\n\";}'\n39,90\n\nPolecenie to można wytłumaczyć następująco:\n\n * weź plik eic_67584344.txt\n * całą jego zawartość przekieruj do programu który napisaliśmy w perl jako\n   wejście\n * program na każdej linii tekstu wykonuje to samo polecenie\n * sprawdza czy tekst pasuje do wzorca zaczynającego się od SUMA PLN: i\n   kończącego na zł.\n * jeśli tak, to wycina wartość między tymi ciągami znakowymi i ją zwraca\n\nProblem jaki mamy to polski , zamiast ogólnie stosowanej na świecie .. Ten\nproblem bardzo łatwo eliminujemy poleceniem tr które zamienia swój pierwszy\nargument na drugi.\n\nNie będziemy oczywiście powtarzać tych poleceń dla każdego pliku osobno. Zamiast\ntego ponownie wykorzystamy znany już xargs\n\n$ ls eic_*.txt | xargs -i cat \"{}\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \"$1\\n\";}' | tr , .\n39.90\n63.00\n15.14\n55.00\n60.00\n186.00\n70.56\n89.40\n139.00\n68.11\n\nPozwolił nam na przeszukanie plików tekstowych za pomocą zdefiniowanych filtrów\nplik po pliku. Z ciekawszych rzeczy to wykorzystane \"{}\" oznacza argument który\nwszedł do xargs.\n\nZostało już tylko sumowanie, ale suma kolumn z pliku tekstowego to bułka z\nmasłem w konsoli bash. W przypadku jednej kolumny nie trzeba nawet uruchamiać \nawk - zaawansowanego programu do przetwarzania tekstów. Wystarczy nam paste -\nprogram do łączenia plików i bc prosty program do liczenia sum.\n\nZa pomocą paste z opcją -s wykonamy transpozycję do jednej linii. Opcją d \nustawimy separator. Będzie nim oczywiście znak dodawania +. Wynik wygląda miej\nwięcej tak:\n\nOstatnia cegiełka bc kończy zadanie, ale to było prezentowane na samym początku:\n\n$ ls eic_*.txt | xargs -i cat \"{}\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \"$1\\n\";}' | tr , . | paste -sd+ | bc\n786.11\n\nWizualizacja wyników\nPonieważ pliki ułożone są chronologicznie wyświetlimy łatwo będzie nam zobaczyć\nwykres kolejnych cen. W tym celu pobieramy chart - paczkę napisaną w go służącą\ndo tworzenia wykresów.\n\nwget https://github.com/marianogappa/chart/releases/download/v3.0.0/chart_3.0.0_linux_amd64.tar.gz -O /tmp/chart.tar.gz\n\nI rozpakowujemy\n\ntar -xvf /tmp/chart.tar.gz --directory /usr/local/bin\n\nKolejna komenda, dodaje numery kolumn cat -n i rysuje wykres\n\nls eic_*.txt | xargs -i cat \"{}\" | perl -ne 'if(/SUMA PLN: (.*) zł/){print \"$1\\n\";}' | tr , . | cat -n | chart line\n\nPodsumowując. Nie napracowaliśmy się tutaj za bardzo ale właśnie to było celem.\nPokazanie jak jedną linią kodu można posumować ceny lub wyrysować wykres z\ndanych, które pozornie są niedostępne, bo ich format nie jest tak oczywisty jak\nw przypadku uporządkowanych danych zapisanych w bazie o dobrze określonej\nstrukturze.\n\nJeśli jesteś przedsiębiorcą i zainteresował Cię temat automatyzacji\nprzetwarzania dokumentów umów się ze mną na darmową konsultację korzystając z\nlinku\n\nDaniel GustawWelcome to my scheduling page. Please follow the instructions to\nadd an event to my calendar.Calendly [https://calendly.com/gustaw-daniel]Jeśli\nchcesz poszerzyć swoją wiedzę i zapoznać się z narzędziami z których\nkorzystaliśmy linki do nich znajdziesz poniżej:\n\nCzyszczenie danych\n\nhttps://en.wikipedia.org/wiki/Data_cleansing\n\nPdf to Text Converter\n\nhttps://www.cyberciti.biz/faq/converter-pdf-files-to-text-format-command/\n\nPrzykład zastosowania xargs\n\nhttps://stackoverflow.com/questions/33141207/what-is-the-working-of-this-command-ls-xargs-i-t-cp-1\n\nChart - narzędzie do rysowania wykresów\n\nhttps://marianogappa.github.io/chart/\n\nPaste - komenda do łączenia plików\n\nhttps://www.geeksforgeeks.org/paste-command-in-linux-with-examples/\n\nPrzykładowe onelinery w Perlu\n\nhttps://www.rexegg.com/regex-perl-one-liners.html",
            "feature_image": "__GHOST_URL__/content/images/2021/04/36C3-PDF-digital-signature-featured-1.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T18:15:22.000Z",
            "updated_at": "2021-04-20T18:45:26.000Z",
            "published_at": "2021-04-20T18:45:26.000Z",
            "custom_excerpt": "W tym wpisie pokarzemy jak pisząc naprawdę znikome ilości kodu można wygodnie wydobyć dane z plików PDF.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f216e2fb35425592d0af5",
            "uuid": "9d1e901f-193c-414e-87c5-b4b24cf4888d",
            "title": "W jaki sposób wojna o kompatybilność ukształtowała frontend?",
            "slug": "w-jaki-sposob-wojna-o-kompatybilnosc-uksztaltowala-frontend",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/cat.jpg\",\"width\":500,\"height\":338}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/width.jpeg\",\"width\":1920,\"height\":1080}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/trends.png\",\"width\":1150,\"height\":348}]],\"markups\":[[\"strong\"],[\"a\",[\"href\",\"https://www.eizo.pl/baza-wiedzy/od-displayport-po-d-sub-przeglad-zlaczy-wideo-w-monitorach-lcd/\"]],[\"a\",[\"href\",\"https://www.spidersweb.pl/2018/08/iphone-ladowarka-lightning.html\"]],[\"a\",[\"href\",\"http://itfocus.pl/dzial-it/storage/duze-dyski-duze-klopoty/\"]],[\"a\",[\"href\",\"http://www.tlumaczenia-angielski.info/w3c/history.html\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Problem niekompatybilnych wersji oprogramowania czy sprzętu prawdopodobnie nie raz przeszkadzał nam w codziennym życiu. Być może spotkałeś się z sytuacjami lub zauważyłeś:\"]]],[3,\"ul\",[[[0,[],0,\"jak pytając kogoś o ładowarkę do telefonu 10 lat temu trzeba było ustalać czy na pewno pasuje\"]],[[0,[],0,\"jak BIOS był wypierany przez UEFI bo nie wspierał startu systemów z dysków powyżej 2TB\"]],[[0,[],0,\"jaką stare gry z młodości sprawiały problemy na nowych systemach operacyjnych\"]],[[0,[],0,\"jak dwa portfele BTC potrafią dla tego samego seeda wyświetlać różne wartości stanu konta\"]]]],[1,\"p\",[[0,[],0,\"Być może jako przedsiębiorca mierzyłeś się już z problemem migrowania swojego systemu informatycznego, albo jako programista walczyłeś z błędami powodowanymi aktualizacją jakiejś paczki.\"]]],[10,0],[1,\"p\",[[0,[],0,\"Ten artykuł ma na celu pokazanie jak kompatybilność wsteczna wpływała na kierunek rozwoju technologii webowych.\"]]],[1,\"p\",[[0,[],0,\"Znajomość mechanizmów, które opiszę pomoże Ci łatwiej prognozować trendy w technologiach i optymalizować decyzje dotyczące tego w jaką technologię inwestować.\"]]],[1,\"p\",[[1,[],0,0],[0,[0],1,\"Wojna o kompatybilność ukształtowała dzisiejszy web.\"]]],[1,\"p\",[[0,[],0,\"Kwestia kompatybilności, to nie tylko problemy zwykłych ludzi, a sprawa wpływająca znacznie na kierunku rozwoju cywilizacji. To dzięki niej, lub przez jej brak pewne technologie mogą rosnąć, a inne są zapominane.\"]]],[1,\"p\",[[0,[],0,\"Za przykład niech posłuży nam historia rozwoju frontendu webowego, którą w bardzo skróconej wersji przybliżę. Był początek millenium. Twórcy przeglądarek toczyli krwawą walkę o klientów, których próbowali przyciągnąć coraz to nowszymi funkcjonalnościami. Pracowali nad nimi niezależnie i kiedy je publikowali programiści uczyli się wprowadzonych przez przeglądarki specyfikacji i coraz bardziej załamywali ręce.\"]]],[1,\"p\",[[0,[],0,\"Często dla każdej przeglądarki trzeba było pisać osobny kod do wykonania tego samego zadania. Niektóre zmieniały interfejs programistyczny nawet z wersji na wersję kilka razy! Pisząc kod programista zamiast zapytać o szerokość okna, sprawdzał na początku o to z jaką przeglądarką ma do czynienia, później dopiero w długiej liście warunków wykonywał odpowiednie komendy stosownie do przeglądarki jaką wykrył\"],[1,[],0,1]]],[10,1],[1,\"p\",[[0,[],0,\"W tych warunkach w 2005 pojawiła się biblioteka jQuery. Stanowiła ona warstwę pośredniczącą między programistami webowymi a przeglądarkami. Błyskawicznie zaczęła zdobywać popularność, bo choć obciążała przeglądarki, to dzięki niej programista pisał znacznie mnie kodu, a dodatkowo to ona przejmowała odpowiedzialność za obsługę starych przeglądarek. Wraz ze zdobywanie popularności wprowadzała nowatorskie rozwiązania jak niektóre selektory do wyszukiwania elementów na stronie, które dopiero później znalazły się na stałe w standardach. Do jQuery napisano niezliczoną liczbę wtyczek i w 2012 stała się technologią, którą poznawał każdy programista jeśli chciał pisać strony internetowe.\"]]],[1,\"p\",[[0,[],0,\"Wszyscy wiedzieli, że kod bez jQuery działa często znacznie szybciej, ale ogromny sukces jQuery pokazuje jak wielka nagroda czeka tego kto rozwiąże problem kompatybilności, który pojawia się zawsze w momencie dynamicznego budowania nowoczesnych technologii.\"]]],[1,\"p\",[[0,[],0,\"Popularność jQuery zaczęła przygasać dopiero kiedy stało się jasne, że twórcy przeglądarek dogadali się i uporządkowali proces wdrażania rekomendacji organizacji standaryzujących jak W3C. Ta organizacja powstała z kooperacji MIT i CERN przy poparciu DARPA i Komisji Europejskiej dba o to, żeby technologie webowe były kompatybilne i tworzy dokumentację dla twórców języków i przeglądarek. Budowa tego w przemyślany sposób pozwala obecnie na osiąganie znacznie trudniejszego celu - kompatybilności w przód. To znaczy, że standardy webowe projektowane są teraz tak, żeby ich późniejsze zmiany nie powodowały problemów w działaniu poprzednich wersji.\"]]],[1,\"p\",[[0,[],0,\"Jednak to nie koniec historii. Być może interesuje was, co się stało z technologiami webowymi po tym, jak jQuery przestawało powoli być już potrzebne.\"]]],[10,2],[1,\"p\",[[0,[],0,\"W 2013 roku zaczęło być głośno o frameworku Angular Js stworzonym 4 lata wcześniej przez Google. W tym samym momencie Facebook ogłosił powstanie Reacta. Oba narzędzia wdrażały deklaratywny paradygmat budowania interfejsów za pomocą bezstanowych komponentów. Krótko mówiąc, programista definiował warunki mówiące jak frontend ma działać, a komponenty przejmowały odpowiedzialność za warstwę wizualną pozostawiając więcej uwagi programisty do pracy nad logiką biznesową. W uproszczeniu: każde z sprawiało, że kod pisało się jeszcze szybciej niż w jQuery.\"]]],[1,\"p\",[[0,[],0,\"Angular Js zaczął jako ten pierwszy i miał przewagę. Sam pamiętam jak przecierałem oczy ze zdziwienia oglądając jak mój przyjaciel pierwszy raz pokazał mi aplikację napisaną w Angularze Js w 2015 roku. Wszystko wskazywało wtedy, że warto uczyć się bardziej Angulara Js niż Reacta.\"]]],[1,\"p\",[[0,[],0,\"W 2016 wydany został Angular 2.0, już bez Js. Początkowo miał być po prostu kolejną wersją Angular Js, ale decyzje projektowe sprawiły, że nie był on kompatybilny z pierwszą wersją Angulara Js. Od początku wzbudzało to duże kontrowersje. Podobnie jak fakt, że od tego momentu nowe wersje miały wychodzić co pół roku, a kompatybilność wsteczna miała być trzymana tylko dwie wersje wstecz.\"]]],[1,\"p\",[[0,[],0,\"Frameworki webowe szybko rosły, było ich coraz więcej i rok 2017 stał się rokiem hasła \\\"Jakiego nowego frameworka nauczę się dzisiaj?\\\". W szkole programowania w której wykładałem zadawano sobie pytanie: \\\"Jakiego frameworka mamy uczyć naszych kursantów?\\\". Jej założyciel postawił na Reacta. Kompatybilność wsteczna była znaczącym czynnikiem tej decyzji.\"]]],[1,\"p\",[[0,[],0,\"Łatwo domyślić się, że wielu twórców materiałów edukacyjnych chciało, żeby raz wytworzony kurs przynosił im korzyści dłużej. Wielu programistów chciało uczyć się narzędzia, które będzie działało w ten sam sposób za rok i przy którym aktualizacje nie będą podbijać kosztów utrzymania.\"]]],[1,\"p\",[[0,[],0,\"W roku 2017 - czyli rok po nadużyciu przez Angulara zaufania budowanego przez kompatybilność wsteczną React wyprzedził Angulara i już nigdy nie wypuścił tej przewagi.\"]]],[1,\"p\",[[0,[],0,\"Jaka lekcja płynie z tej historii? Że kompatybilność jest jednym z kluczowych czynników, które należy traktować poważnie analizując lub planując rozwój technologii.\"]]],[1,\"p\",[[0,[],0,\"Źródła do dalszej lektury:\"]]],[1,\"p\",[[0,[],0,\"Kompatybilność na przykładzie monitorów\"]]],[1,\"p\",[[0,[1],1,\"https://www.eizo.pl/baza-wiedzy/od-displayport-po-d-sub-przeglad-zlaczy-wideo-w-monitorach-lcd/\"]]],[1,\"p\",[[0,[],0,\"Komisja Europejska chce zmusić Apple do porzucenia Lightning w iPhone'ach\"]]],[1,\"p\",[[0,[2],1,\"https://www.spidersweb.pl/2018/08/iphone-ladowarka-lightning.html\"]]],[1,\"p\",[[0,[],0,\"Problemy z BIOS i dyskami\"]]],[1,\"p\",[[0,[3],1,\"http://itfocus.pl/dzial-it/storage/duze-dyski-duze-klopoty/\"]]],[1,\"p\",[[0,[],0,\"Historia W3C\"]]],[1,\"p\",[[0,[4],1,\"http://www.tlumaczenia-angielski.info/w3c/history.html\"]]],[1,\"p\",[[1,[],0,2]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Problem niekompatybilnych wersji oprogramowania czy sprzętu prawdopodobnie nie raz przeszkadzał nam w codziennym życiu. Być może spotkałeś się z sytuacjami lub zauważyłeś:</p><ul><li>jak pytając kogoś o ładowarkę do telefonu 10 lat temu trzeba było ustalać czy na pewno pasuje</li><li>jak BIOS był wypierany przez UEFI bo nie wspierał startu systemów z dysków powyżej 2TB</li><li>jaką stare gry z młodości sprawiały problemy na nowych systemach operacyjnych</li><li>jak dwa portfele BTC potrafią dla tego samego seeda wyświetlać różne wartości stanu konta</li></ul><p>Być może jako przedsiębiorca mierzyłeś się już z problemem migrowania swojego systemu informatycznego, albo jako programista walczyłeś z błędami powodowanymi aktualizacją jakiejś paczki.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/cat.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"338\"></figure><p>Ten artykuł ma na celu pokazanie jak kompatybilność wsteczna wpływała na kierunek rozwoju technologii webowych.</p><p>Znajomość mechanizmów, które opiszę pomoże Ci łatwiej prognozować trendy w technologiach i optymalizować decyzje dotyczące tego w jaką technologię inwestować.</p><p><br><strong>Wojna o kompatybilność ukształtowała dzisiejszy web.</strong></p><p>Kwestia kompatybilności, to nie tylko problemy zwykłych ludzi, a sprawa wpływająca znacznie na kierunku rozwoju cywilizacji. To dzięki niej, lub przez jej brak pewne technologie mogą rosnąć, a inne są zapominane.</p><p>Za przykład niech posłuży nam historia rozwoju frontendu webowego, którą w bardzo skróconej wersji przybliżę. Był początek millenium. Twórcy przeglądarek toczyli krwawą walkę o klientów, których próbowali przyciągnąć coraz to nowszymi funkcjonalnościami. Pracowali nad nimi niezależnie i kiedy je publikowali programiści uczyli się wprowadzonych przez przeglądarki specyfikacji i coraz bardziej załamywali ręce.</p><p>Często dla każdej przeglądarki trzeba było pisać osobny kod do wykonania tego samego zadania. Niektóre zmieniały interfejs programistyczny nawet z wersji na wersję kilka razy! Pisząc kod programista zamiast zapytać o szerokość okna, sprawdzał na początku o to z jaką przeglądarką ma do czynienia, później dopiero w długiej liście warunków wykonywał odpowiednie komendy stosownie do przeglądarki jaką wykrył<br></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/width.jpeg\" class=\"kg-image\" alt loading=\"lazy\" width=\"1920\" height=\"1080\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/width.jpeg 600w, __GHOST_URL__/content/images/size/w1000/2021/04/width.jpeg 1000w, __GHOST_URL__/content/images/size/w1600/2021/04/width.jpeg 1600w, __GHOST_URL__/content/images/2021/04/width.jpeg 1920w\" sizes=\"(min-width: 720px) 720px\"></figure><p>W tych warunkach w 2005 pojawiła się biblioteka jQuery. Stanowiła ona warstwę pośredniczącą między programistami webowymi a przeglądarkami. Błyskawicznie zaczęła zdobywać popularność, bo choć obciążała przeglądarki, to dzięki niej programista pisał znacznie mnie kodu, a dodatkowo to ona przejmowała odpowiedzialność za obsługę starych przeglądarek. Wraz ze zdobywanie popularności wprowadzała nowatorskie rozwiązania jak niektóre selektory do wyszukiwania elementów na stronie, które dopiero później znalazły się na stałe w standardach. Do jQuery napisano niezliczoną liczbę wtyczek i w 2012 stała się technologią, którą poznawał każdy programista jeśli chciał pisać strony internetowe.</p><p>Wszyscy wiedzieli, że kod bez jQuery działa często znacznie szybciej, ale ogromny sukces jQuery pokazuje jak wielka nagroda czeka tego kto rozwiąże problem kompatybilności, który pojawia się zawsze w momencie dynamicznego budowania nowoczesnych technologii.</p><p>Popularność jQuery zaczęła przygasać dopiero kiedy stało się jasne, że twórcy przeglądarek dogadali się i uporządkowali proces wdrażania rekomendacji organizacji standaryzujących jak W3C. Ta organizacja powstała z kooperacji MIT i CERN przy poparciu DARPA i Komisji Europejskiej dba o to, żeby technologie webowe były kompatybilne i tworzy dokumentację dla twórców języków i przeglądarek. Budowa tego w przemyślany sposób pozwala obecnie na osiąganie znacznie trudniejszego celu - kompatybilności w przód. To znaczy, że standardy webowe projektowane są teraz tak, żeby ich późniejsze zmiany nie powodowały problemów w działaniu poprzednich wersji.</p><p>Jednak to nie koniec historii. Być może interesuje was, co się stało z technologiami webowymi po tym, jak jQuery przestawało powoli być już potrzebne.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/trends.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1150\" height=\"348\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/trends.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/trends.png 1000w, __GHOST_URL__/content/images/2021/04/trends.png 1150w\" sizes=\"(min-width: 720px) 720px\"></figure><p>W 2013 roku zaczęło być głośno o frameworku Angular Js stworzonym 4 lata wcześniej przez Google. W tym samym momencie Facebook ogłosił powstanie Reacta. Oba narzędzia wdrażały deklaratywny paradygmat budowania interfejsów za pomocą bezstanowych komponentów. Krótko mówiąc, programista definiował warunki mówiące jak frontend ma działać, a komponenty przejmowały odpowiedzialność za warstwę wizualną pozostawiając więcej uwagi programisty do pracy nad logiką biznesową. W uproszczeniu: każde z sprawiało, że kod pisało się jeszcze szybciej niż w jQuery.</p><p>Angular Js zaczął jako ten pierwszy i miał przewagę. Sam pamiętam jak przecierałem oczy ze zdziwienia oglądając jak mój przyjaciel pierwszy raz pokazał mi aplikację napisaną w Angularze Js w 2015 roku. Wszystko wskazywało wtedy, że warto uczyć się bardziej Angulara Js niż Reacta.</p><p>W 2016 wydany został Angular 2.0, już bez Js. Początkowo miał być po prostu kolejną wersją Angular Js, ale decyzje projektowe sprawiły, że nie był on kompatybilny z pierwszą wersją Angulara Js. Od początku wzbudzało to duże kontrowersje. Podobnie jak fakt, że od tego momentu nowe wersje miały wychodzić co pół roku, a kompatybilność wsteczna miała być trzymana tylko dwie wersje wstecz.</p><p>Frameworki webowe szybko rosły, było ich coraz więcej i rok 2017 stał się rokiem hasła \"Jakiego nowego frameworka nauczę się dzisiaj?\". W szkole programowania w której wykładałem zadawano sobie pytanie: \"Jakiego frameworka mamy uczyć naszych kursantów?\". Jej założyciel postawił na Reacta. Kompatybilność wsteczna była znaczącym czynnikiem tej decyzji.</p><p>Łatwo domyślić się, że wielu twórców materiałów edukacyjnych chciało, żeby raz wytworzony kurs przynosił im korzyści dłużej. Wielu programistów chciało uczyć się narzędzia, które będzie działało w ten sam sposób za rok i przy którym aktualizacje nie będą podbijać kosztów utrzymania.</p><p>W roku 2017 - czyli rok po nadużyciu przez Angulara zaufania budowanego przez kompatybilność wsteczną React wyprzedził Angulara i już nigdy nie wypuścił tej przewagi.</p><p>Jaka lekcja płynie z tej historii? Że kompatybilność jest jednym z kluczowych czynników, które należy traktować poważnie analizując lub planując rozwój technologii.</p><p>Źródła do dalszej lektury:</p><p>Kompatybilność na przykładzie monitorów</p><p><a href=\"https://www.eizo.pl/baza-wiedzy/od-displayport-po-d-sub-przeglad-zlaczy-wideo-w-monitorach-lcd/\">https://www.eizo.pl/baza-wiedzy/od-displayport-po-d-sub-przeglad-zlaczy-wideo-w-monitorach-lcd/</a></p><p>Komisja Europejska chce zmusić Apple do porzucenia Lightning w iPhone'ach</p><p><a href=\"https://www.spidersweb.pl/2018/08/iphone-ladowarka-lightning.html\">https://www.spidersweb.pl/2018/08/iphone-ladowarka-lightning.html</a></p><p>Problemy z BIOS i dyskami</p><p><a href=\"http://itfocus.pl/dzial-it/storage/duze-dyski-duze-klopoty/\">http://itfocus.pl/dzial-it/storage/duze-dyski-duze-klopoty/</a></p><p>Historia W3C</p><p><a href=\"http://www.tlumaczenia-angielski.info/w3c/history.html\">http://www.tlumaczenia-angielski.info/w3c/history.html</a></p>",
            "comment_id": "607f216e2fb35425592d0af5",
            "plaintext": "Problem niekompatybilnych wersji oprogramowania czy sprzętu prawdopodobnie nie\nraz przeszkadzał nam w codziennym życiu. Być może spotkałeś się z sytuacjami lub\nzauważyłeś:\n\n * jak pytając kogoś o ładowarkę do telefonu 10 lat temu trzeba było ustalać czy\n   na pewno pasuje\n * jak BIOS był wypierany przez UEFI bo nie wspierał startu systemów z dysków\n   powyżej 2TB\n * jaką stare gry z młodości sprawiały problemy na nowych systemach operacyjnych\n * jak dwa portfele BTC potrafią dla tego samego seeda wyświetlać różne wartości\n   stanu konta\n\nByć może jako przedsiębiorca mierzyłeś się już z problemem migrowania swojego\nsystemu informatycznego, albo jako programista walczyłeś z błędami powodowanymi\naktualizacją jakiejś paczki.\n\nTen artykuł ma na celu pokazanie jak kompatybilność wsteczna wpływała na\nkierunek rozwoju technologii webowych.\n\nZnajomość mechanizmów, które opiszę pomoże Ci łatwiej prognozować trendy w\ntechnologiach i optymalizować decyzje dotyczące tego w jaką technologię\ninwestować.\n\n\nWojna o kompatybilność ukształtowała dzisiejszy web.\n\nKwestia kompatybilności, to nie tylko problemy zwykłych ludzi, a sprawa\nwpływająca znacznie na kierunku rozwoju cywilizacji. To dzięki niej, lub przez\njej brak pewne technologie mogą rosnąć, a inne są zapominane.\n\nZa przykład niech posłuży nam historia rozwoju frontendu webowego, którą w\nbardzo skróconej wersji przybliżę. Był początek millenium. Twórcy przeglądarek\ntoczyli krwawą walkę o klientów, których próbowali przyciągnąć coraz to nowszymi\nfunkcjonalnościami. Pracowali nad nimi niezależnie i kiedy je publikowali\nprogramiści uczyli się wprowadzonych przez przeglądarki specyfikacji i coraz\nbardziej załamywali ręce.\n\nCzęsto dla każdej przeglądarki trzeba było pisać osobny kod do wykonania tego\nsamego zadania. Niektóre zmieniały interfejs programistyczny nawet z wersji na\nwersję kilka razy! Pisząc kod programista zamiast zapytać o szerokość okna,\nsprawdzał na początku o to z jaką przeglądarką ma do czynienia, później dopiero\nw długiej liście warunków wykonywał odpowiednie komendy stosownie do\nprzeglądarki jaką wykrył\n\n\nW tych warunkach w 2005 pojawiła się biblioteka jQuery. Stanowiła ona warstwę\npośredniczącą między programistami webowymi a przeglądarkami. Błyskawicznie\nzaczęła zdobywać popularność, bo choć obciążała przeglądarki, to dzięki niej\nprogramista pisał znacznie mnie kodu, a dodatkowo to ona przejmowała\nodpowiedzialność za obsługę starych przeglądarek. Wraz ze zdobywanie\npopularności wprowadzała nowatorskie rozwiązania jak niektóre selektory do\nwyszukiwania elementów na stronie, które dopiero później znalazły się na stałe w\nstandardach. Do jQuery napisano niezliczoną liczbę wtyczek i w 2012 stała się\ntechnologią, którą poznawał każdy programista jeśli chciał pisać strony\ninternetowe.\n\nWszyscy wiedzieli, że kod bez jQuery działa często znacznie szybciej, ale\nogromny sukces jQuery pokazuje jak wielka nagroda czeka tego kto rozwiąże\nproblem kompatybilności, który pojawia się zawsze w momencie dynamicznego\nbudowania nowoczesnych technologii.\n\nPopularność jQuery zaczęła przygasać dopiero kiedy stało się jasne, że twórcy\nprzeglądarek dogadali się i uporządkowali proces wdrażania rekomendacji\norganizacji standaryzujących jak W3C. Ta organizacja powstała z kooperacji MIT i\nCERN przy poparciu DARPA i Komisji Europejskiej dba o to, żeby technologie\nwebowe były kompatybilne i tworzy dokumentację dla twórców języków i\nprzeglądarek. Budowa tego w przemyślany sposób pozwala obecnie na osiąganie\nznacznie trudniejszego celu - kompatybilności w przód. To znaczy, że standardy\nwebowe projektowane są teraz tak, żeby ich późniejsze zmiany nie powodowały\nproblemów w działaniu poprzednich wersji.\n\nJednak to nie koniec historii. Być może interesuje was, co się stało z\ntechnologiami webowymi po tym, jak jQuery przestawało powoli być już potrzebne.\n\nW 2013 roku zaczęło być głośno o frameworku Angular Js stworzonym 4 lata\nwcześniej przez Google. W tym samym momencie Facebook ogłosił powstanie Reacta.\nOba narzędzia wdrażały deklaratywny paradygmat budowania interfejsów za pomocą\nbezstanowych komponentów. Krótko mówiąc, programista definiował warunki mówiące\njak frontend ma działać, a komponenty przejmowały odpowiedzialność za warstwę\nwizualną pozostawiając więcej uwagi programisty do pracy nad logiką biznesową. W\nuproszczeniu: każde z sprawiało, że kod pisało się jeszcze szybciej niż w\njQuery.\n\nAngular Js zaczął jako ten pierwszy i miał przewagę. Sam pamiętam jak\nprzecierałem oczy ze zdziwienia oglądając jak mój przyjaciel pierwszy raz\npokazał mi aplikację napisaną w Angularze Js w 2015 roku. Wszystko wskazywało\nwtedy, że warto uczyć się bardziej Angulara Js niż Reacta.\n\nW 2016 wydany został Angular 2.0, już bez Js. Początkowo miał być po prostu\nkolejną wersją Angular Js, ale decyzje projektowe sprawiły, że nie był on\nkompatybilny z pierwszą wersją Angulara Js. Od początku wzbudzało to duże\nkontrowersje. Podobnie jak fakt, że od tego momentu nowe wersje miały wychodzić\nco pół roku, a kompatybilność wsteczna miała być trzymana tylko dwie wersje\nwstecz.\n\nFrameworki webowe szybko rosły, było ich coraz więcej i rok 2017 stał się rokiem\nhasła \"Jakiego nowego frameworka nauczę się dzisiaj?\". W szkole programowania w\nktórej wykładałem zadawano sobie pytanie: \"Jakiego frameworka mamy uczyć naszych\nkursantów?\". Jej założyciel postawił na Reacta. Kompatybilność wsteczna była\nznaczącym czynnikiem tej decyzji.\n\nŁatwo domyślić się, że wielu twórców materiałów edukacyjnych chciało, żeby raz\nwytworzony kurs przynosił im korzyści dłużej. Wielu programistów chciało uczyć\nsię narzędzia, które będzie działało w ten sam sposób za rok i przy którym\naktualizacje nie będą podbijać kosztów utrzymania.\n\nW roku 2017 - czyli rok po nadużyciu przez Angulara zaufania budowanego przez\nkompatybilność wsteczną React wyprzedził Angulara i już nigdy nie wypuścił tej\nprzewagi.\n\nJaka lekcja płynie z tej historii? Że kompatybilność jest jednym z kluczowych\nczynników, które należy traktować poważnie analizując lub planując rozwój\ntechnologii.\n\nŹródła do dalszej lektury:\n\nKompatybilność na przykładzie monitorów\n\nhttps://www.eizo.pl/baza-wiedzy/od-displayport-po-d-sub-przeglad-zlaczy-wideo-w-monitorach-lcd/\n\nKomisja Europejska chce zmusić Apple do porzucenia Lightning w iPhone'ach\n\nhttps://www.spidersweb.pl/2018/08/iphone-ladowarka-lightning.html\n\nProblemy z BIOS i dyskami\n\nhttp://itfocus.pl/dzial-it/storage/duze-dyski-duze-klopoty/\n\nHistoria W3C\n\nhttp://www.tlumaczenia-angielski.info/w3c/history.html",
            "feature_image": "__GHOST_URL__/content/images/2021/04/main.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T18:46:06.000Z",
            "updated_at": "2021-04-20T18:51:16.000Z",
            "published_at": "2021-04-20T18:51:16.000Z",
            "custom_excerpt": "Opisujemy jak porzucanie i dbanie o kompatybilność wsteczną wpływało na kierunek rozwoju technologii webowych.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f2d392fb35425592d0b22",
            "uuid": "449d68ef-3123-4c52-9d78-a6a850f6b996",
            "title": "Scraping Facebooka w 2021 roku",
            "slug": "scraping-facebooka-w-2021-roku",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Metoda stabilnych meta-selektorów opartych o stylowanie\\n\\nArtykuł ma na celu zapoznanie czytelnika z metodą na scaping portalu Facebooka po wprowadzeniu aktualizacji layoutu. Wymagana jest znajomość TypeScript lub JavaScript, oraz zasad działania selektorów CSS. Pokazujemy w nim zestaw narzędzi, które rozwiązują problem takiego budowania selektorów, aby były one stabilne na przykładzie scrapingu członków grupy.\\n\\nPo aferze Cambridge Analitica, po przesłuchaniach Zucka przed senatem USA, po wprowadzeniu RODO scraping danych w mediach społecznościowych staje się stopniowo coraz trudniejszy. Liderem we wprowadzaniu zabezpieczeń jest bezsprzecznie Facebook.\\n\\nPrzy zaledwie 2.3 miliarda kont aktywnych użytkowników rocznie usuwanych jest około 6 miliardów fakeowych kont. Co ciekawe przy takiej skali nie znam nikogo, kto mając prawdziwe konto skarżył by się na bezpodstawne banowanie. Tą fenomenalną precyzję zapewnia Facebookowi wykorzystanie 20 tysięcy współczynników, które sztuczna inteligencja wykorzystuje do umieszczania użytkowników na mapie poziomów ryzyka, że konto nie należy do prawdziwego człowieka. \\n\\nSerwis w miarę możliwości zbiera informacje o osobach, które nie mają kont, ale istnieją i mogły by je założyć. Potrafi też wykrywać zdjęcia generowane komputerowo dzięki artefaktom powstającym przy sztucznym tworzeniu zdjęć twarzy przy kącikach oczu. \\n\\nWszystkie te działania, służą dwóm podstawowym celom:\\n\\n- uodpornieniu sieci społecznościowej na zautomatyzowane, masowe umieszczenie treści\\n- zapobieganiu zautomatyzowanemu pobieraniu i przetwarzaniu danych dostępnych w serwisie\\n\\nSamemu wykrywaniu i banowaniu botów towarzyszą inne działania, jak na przykład obfuskacja kodu strony internetowej. Technika ta polega na zastępowaniu nazw i instrukcji zrozumiałych dla człowieka przez takie, które nie utrudniają czytanie i pracę z kodem źródłowym.\\n\\nPrzykładem czystego kodu, łatwego do zrozumienia dla programisty jest:\\n\\n```html\\n<form class=\\\"dismiss js-notice-dismiss\\\" action=\\\"/users/16663028/dismiss_notice?notice_name=org_newbie\\\" accept-charset=\\\"UTF-8\\\" method=\\\"post\\\"><input type=\\\"hidden\\\" name=\\\"_method\\\" value=\\\"delete\\\">\\n```\\n\\nPodczas gdy na Facebooku można się spodziewać raczej czegoś takiego:\\n\\n```html\\n<div class=\\\"rq0escxv l9j0dhe7 du4w35lb j83agx80 cbu4d94t pfnyh3mw d2edcug0 hv4rvrfc dati1w0a\\\"><div class=\\\"rq0escxv l9j0dhe7 du4w35lb j83agx80 cbu4d94t e5nlhep0 aodizinl\\\">\\n```\\n\\nW dostępnym jeszcze niedawno front-endzie Facebooka często można było natknąć się na atrybuty takie jak `data-testId`, które służyły do opierania o nie testów automatycznych interfejsu, ale nowy layout jest ich pozbawiony. Inżynierowie Facebooka musieli sobie zdawać sprawę z tego, że pomocne dla nich punkty zaczepienia były wykorzystywane przez twórców botów.\\n\\nTopologia drzewa DOM jest również bardziej płynna niż można by się spodziewać i budowanie długich opartych o nią selektorów typu:\\n\\n```\\ndiv > div > div > div > div > div > div > div:nth-child(2) span[dir=auto] > a:nth-child(1)\\n```\\n\\njest pracochłonnym i ryzykownym zadaniem.\\n\\n---\\n\\nMimo wielu trudności, twórca bota nadal nie jest na straconej pozycji. Front-end Facebooka nie jest rysowany na canvasie za pomocą webassmebly. Gdyby przepisano go na fluttera, problem był by naprawdę poważny. Jednak z taką obfuckacją, jaka jest stosowana na Facebooku można poradzić sobie dzięki następującej strategii.\\n\\n1. Patrzymy nie na nazwy klas tylko na ich znacznie - style, które są do nich przypisane\\n2. Pobieramy aktualny CSS strony Facebooka, którą przeglądamy i rozkładamy ją na mapę klas i ich styli\\n3. Budujemy nasze stabilne meta selektory za pomocą styli używając np.: `{display:block}` zamiast `.d-block`.\\n4. Konwertujemy stabilne meta selektory do formy poprawnych tymczasowych selektorów działających dla tej konkretnej strony\\n5. Wydobywamy interesujące nas dane już bez problemów jak za starych dobrych czasów\\n\\nNależy zaznaczyć, że niektóre style się powtarzają i znajdziemy wiele klas, które powodują takie samo stylowanie. Poniżej załączam histogram częstotliwości duplikacji styli dla selektorów w kodzie CSS Facebooka.\\n\\n| Liczba równoważnych klas | Częstość wystąpień |\\n| ------------------------ | ------------------ |\\n| 1                        | 6475               |\\n| 2                        | 304                |\\n| 3                        | 65                 |\\n| 4                        | 22                 |\\n| 5                        | 12                 |\\n| 6                        | 5                  |\\n| 7                        | 5                  |\\n| 8                        | 2                  |\\n| 10                       | 1                  |\\n| 15                       | 1                  |\\n| 19                       | 1                  |\\n| 21                       | 1                  |\\n| 25                       | 1                  |\\n\\nZaleca się korzystanie z tych, które się nie duplikują, ale obsługa pozostałych przypadków powoduje tylko podniesienie ilości możliwych kombinacji tymczasowych selektorów co nie wydaje się dużym kosztem, w szczególności jeśli zechcemy wykorzystać w naszych selektorach relacje między elementami drzewa DOM.\\n\\n---\\n\\nPrezentujemy teraz implementację tego konceptu w praktyce na przykładzie. Naszym celem jest ściągnięcie listy członków grupy.\\n\\n> https://www.facebook.com/groups/1590278311045624/members\\n\\n![](https://preciselab.fra1.digitaloceanspaces.com/blog/fb-scraping-in-2020/leads.png)\\n\\nNa liście osób szukamy ramek otaczających całe elementy listy oraz ramki otaczającej teksty. Wśród nich zależy nam na tych, które mają umiarkowaną liczbę klas. Jedna to za mało, bo selektor nie był by zbyt precyzyjny, 10 to dużo, bo mimo precyzji mógł by nie być wystarczająco stabilny. Przykładowy działający selektor kod strukturyzujący tą listę wygląda tak.\\n\\nMożemy zacząć od takiego kodu, który mapuje nam nazwę, kontekst, opis i awatar osoby w grupie\\n\\n```javascript\\n[...document.querySelectorAll('div.ue3kfks5.pw54ja7n.uo3d90p7.l82x9zwi.a8c37x1j')].map(e => ({\\n    name: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg div.nc684nl6>a').innerText, \\n    context: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(2)')?.innerText, \\n    description: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(3)')?.innerText, \\n    img: e.querySelector('image')?.getAttribute('xlink:href')\\n}))\\n```\\n\\nNiestety o ile u mnie ten kod zadziałał, to u Ciebie może być z nim problem, ponieważ jest duża szansa, że Facebook wprowadził aktualizację zmieniającą nazwy klas. Dlatego właśnie chcemy stworzy meta-selektor, który będzie niezmiennym źródłem budującym selektory takie jak ten w oparciu o plik CSS Facebooka.\\n\\nOznacza to, że żeby utrwalić nasz kod musimy zamienić klasy na przypisane im style. W tym celu szukamy w źródle strony linku do pierwszego pliku CSS:\\n\\n```scss\\nhttps://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug\\n```\\n\\n### TypeScript config\\n\\nNastępnie tworzymy plik `tsconfig.json` z zawartością\\n\\n```json\\n{\\n  \\\"compilerOptions\\\": {\\n    \\\"esModuleInterop\\\": true,\\n    \\\"target\\\": \\\"ES2020\\\",\\n    \\\"moduleResolution\\\": \\\"node\\\"\\n  }\\n}\\n```\\n\\nPierwsza własność - `esModuleInterop` pozwala nam na import zgodny ze specyfikacją modułów es6 bibliotek, które były modułami CommonJS. Np dzięki tej fladze możemy pisać:\\n\\n```typescript\\nimport fs from \\\"fs\\\";\\n```\\n\\nzamiast\\n\\n```typescript\\nimport * as fs from \\\"fs\\\";\\n```\\n\\nlub\\n\\n```typescript\\nconst fs = require(\\\"fs\\\");\\n```\\n\\nKolejna: `\\\"target\\\": \\\"ES2020\\\"` pozwala nam na używanie nowych elementów specyfikacji, na przykład bez tej linii nie mogli byśmy użyć mapy `Set` do eliminacji duplikatów.\\n\\nOstatnia: `\\\"moduleResolution\\\": \\\"node\\\"` pozwala na bardziej elastyczny import paczek w TypeScript i jest zalecana do większości projektów. U nas rozwiązała problem z importem paczki `axios`.\\n\\n### Zależności - Package.json\\n\\nKolejnym ważnym plikiem jest `package.json`, w naszym przypadku wygląda on tak:\\n\\n```json\\n{\\n  \\\"name\\\": \\\"fb-scraping-tools\\\",\\n  \\\"version\\\": \\\"1.0.0\\\",\\n  \\\"description\\\": \\\"Set of tools created to make scraping facebook easy.\\\",\\n  \\\"author\\\": \\\"Daniel Gustaw\\\",\\n  \\\"license\\\": \\\"WTFPL\\\",\\n  \\\"dependencies\\\": {\\n    \\\"axios\\\": \\\"^0.21.0\\\",\\n    \\\"md5\\\": \\\"^2.3.0\\\",\\n    \\\"ts-node\\\": \\\"^9.0.0\\\"\\n  },\\n  \\\"devDependencies\\\": {\\n    \\\"@types/md5\\\": \\\"^2.2.1\\\",\\n    \\\"@types/node\\\": \\\"^14.14.6\\\",\\n    \\\"typescript\\\": \\\"^4.0.5\\\"\\n  }\\n}\\n```\\n\\nWidzimy, że korzystamy tu z TypeScript, pobraliśmy kilka zestawów typów do podpowiadania składni, poza tym `axios` do wysyłania żądań http oraz `md5` do wyliczania sum kontrolnych z adresów `url`.\\n\\n### Dekompozycja styli Facebooka\\n\\nPrzejdziemy teraz do najciekawszej części, czyli rozkładu styli Facebooka na mapę klas i styli oraz odwrotną mapę przypisującą kolekcję selektorów określonym stylom.\\n\\nPlik `decompose_css_to_json.ts` zaczynamy od importu wymaganych paczek:\\n\\n```typescript\\nimport axios from \\\"axios\\\";\\nimport md5 from \\\"md5\\\";\\nimport fs from \\\"fs\\\";\\n```\\n\\nSą to proste paczki, które opisaliśmy już przy okazji omawiania pliku z zależnościami. Kolejnym krokiem będzie definiowanie wymaganych typów.\\n\\n```typescript\\ntype StringAccumulator = Record<string, string>\\ntype ArrayAccumulator = Record<string, string[]>\\n```\\n\\nTu nazwy mówią same za siebie, będą to typy w których nie znamy jeszcze kluczy, ale wiemy, że wartości są ciągami znakowymi, albo tablicami ciągów znakowych. Jest tak dlatego, że odwzorowanie styli do selektorów jest wielowartościowe.\\n\\nKolejnym krokiem jest nadanie programowi szkieletowej struktury:\\n\\n```typescript\\nconst CACHE_DIR = process.cwd() + `/.cache`;\\nconst url = `https://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug`;\\n\\nconst main = async (): Promise<void> => {\\n   // there will be placed source code of next part\\n};\\n\\nmain().catch(e => {\\n    console.error(e);\\n})\\n```\\n\\nW stałych definiujemy adres pliku ze stylami Facebooka oraz lokalizację katalogu z cache. Następny krok jest bardzo przewidywalny, chcemy zapisać zawartość pliku w cache, lub odczytać ją z cache jeśli już była zapisana wcześniej. Dzięki temu uniezależnimy działanie programu od tego, czy link nie wygaśnie w przyszłości i obniżymy szansę zbanowania za zbyt częste requesty. Jest to ważny element pracy w pisaniu programów tego typu.\\n\\n```typescript\\n    if (!fs.existsSync(CACHE_DIR)) {\\n        fs.mkdirSync(CACHE_DIR);\\n    }\\n\\n    const name = md5(url);\\n    const path = `${CACHE_DIR}/${name}.css`;\\n    let text = '';\\n    if (fs.existsSync(path)) {\\n        text = fs.readFileSync(path).toString()\\n    } else {\\n        const {data} = await axios.get(url);\\n        text = data;\\n        fs.writeFileSync(path, text);\\n    }\\n```\\n\\nMimo, że ważny, to nie odkrywczy i jedynym zadanie tego kodu jest przygotowanie zmiennych `path` z ścieżką do pliku `css` i `text` z jego zawartością.\\n\\nZnacznie ciekawszym fragmentem jest sam rozkład. Polega on na rozbiciu styli za pomocą wyrażeń regularnych, a następnie budowaniu jednocześnie dwóch map.\\n\\n```typescript\\n    const [styleToSelector, selectorToStyle]: [ArrayAccumulator, StringAccumulator] = text.match(/.*?\\\\{.*?\\\\}/g).reduce(\\n        (p: [ArrayAccumulator, StringAccumulator], n): [ArrayAccumulator, StringAccumulator] => {\\n            const [_, key, value]:string[] = n.match(/(.*?)\\\\{(.*?)\\\\}/);\\n\\n            const cleanKey = key.replace(/^\\\\}/,'')\\n\\n            return [\\n                {...p[0], [value]: [cleanKey, ...(p[0][value] || [])]},\\n                {...p[1], [cleanKey]: value}\\n            ];\\n        }, [{}, {}]\\n    );\\n```\\n\\nZmienna `cleanKey` wprowadzona została, żeby poradzić sobie z klasami, występującymi za znakiem `}}`, co w plikach `css` jest możliwe. Utrata tego znaku `}` z wartości nie zmienia niczego, ponieważ wartości i tak są dla nas tylko identyfikatorami, a nie fragmentami stylizacji, którą mieli byśmy gdziekolwiek implementować.\\n\\nNa końcu utrwalamy wyniki w plikach JSON.\\n\\n```typescript\\n    fs.writeFileSync(path.replace(/css$/, 'styleToSelector.json'), JSON.stringify(styleToSelector));\\n    fs.writeFileSync(path.replace(/css$/, 'selectorToStyle.json'), JSON.stringify(selectorToStyle));\\n```\\n\\nProgram włączamy komendą\\n\\n```bash\\nnpx ts-node decompose_css_to_json.ts\\n```\\n\\nNie drukuje on wyników, ale tworzy trzy pliki w ukrytym katalogu `.cache`. Czas wykonywania tego programu to około \\n\\n### Budowanie meta-selektorów na podstawie selektorów tymczasowych\\n\\nMeta-selektorem nazywam selektor, którym nazwy klas są zastąpione identyfikującymi je zasadami stylowania. Tworzenie meta-selektorów jest potrzebne, żeby kod, który tworzymy był stabilny. Punktem wyjściowym do jego stworzenia jest selektor napisany w konsoli przeglądarki.\\n\\nProgram nazwiemy `generate_meta_selectors.ts`. W standardowym layoucie skryptu mamy zmienną `input`. W niej zapisujemy działające zapytanie strukturyzujące wyświetlaną stronę Facebookową. Wykonanie go w konsoli przeglądarki powinno zwrócić tablicę z obiektami odpowiadającymi uczestnikom grupy Facebookowej.\\n\\n```typescript\\nimport md5 from \\\"md5\\\";\\nimport fs from \\\"fs\\\";\\n\\nconst input = `[...document.querySelectorAll('div.rq0escxv.l9j0dhe7.du4w35lb.j83agx80.cbu4d94t.pfnyh3mw.d2edcug0.aahdfvyu.tvmbv18p div.ue3kfks5.pw54ja7n.uo3d90p7.l82x9zwi.a8c37x1j:not([aria-busy])')].map(e => ({\\n    name: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg div.nc684nl6>a').innerText, \\n    link: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg div.nc684nl6>a').href, \\n    context: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(2)')?.innerText, \\n    description: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(3)')?.innerText, \\n    img: e.querySelector('image')?.getAttribute('xlink:href')\\n}))`;\\n\\nconst CACHE_DIR = process.cwd() + `/.cache`;\\nconst url = `https://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug`;\\n\\nconst main = async (): Promise<void> => {\\n\\t// there will be next part of presented program\\n};\\n\\nmain().catch(e => {\\n    console.error(e);\\n})\\n```\\n\\nTeraz aby przetworzyć losowe klasy w selektorach na stabilne meta-selektory pobieramy zawartość pliku z mapą selektorów\\n\\n```typescript\\n    const name = md5(url);\\n    const path = `${CACHE_DIR}/${name}.selectorToStyle.json`;\\n    const selectorToStyle = JSON.parse(fs.readFileSync(path).toString())\\n```\\n\\nTworzymy tablicę klas w dwóch krokach - pobierając ciągi w cudzysłowach, a następnie wycinając z nich ośmioznakowe ciągi cyfr i liter poprzedzone kropką\\n\\n```typescript\\n    const classes = [...new Set(input.match(/'.*?'/g).join('').match(/\\\\.\\\\w{8}/g))];\\n```\\n\\nNa podstawie tych klas oraz dzięki mapie pobranej do zmiennej `selectorToStyle` możemy wytworzyć tablicę podstawień\\n\\n```typescript\\n    const replaces: [string, string][] = classes.map(c => [c, `{${selectorToStyle[c]}}`]);\\n```\\n\\nWartość tej zmiennej wyniosła w naszym przykładzie\\n\\n```json\\n[\\n  [ '.rq0escxv', '{box-sizing:border-box}' ],\\n  [ '.l9j0dhe7', '{position:relative}' ],\\n  [ '.du4w35lb', '{z-index:0}' ],\\n  [ '.j83agx80', '{display:flex}' ],\\n  [ '.cbu4d94t', '{flex-direction:column}' ],\\n  [ '.pfnyh3mw', '{flex-shrink:0}' ],\\n  [ '.d2edcug0', '{max-width:100%}' ],\\n  [ '.aahdfvyu', '{margin-top:4px}' ],\\n  [ '.tvmbv18p', '{margin-bottom:4px}' ],\\n  [ '.ue3kfks5', '{border-top-left-radius:8px}' ],\\n  [ '.pw54ja7n', '{border-top-right-radius:8px}' ],\\n  [ '.uo3d90p7', '{border-bottom-right-radius:8px}' ],\\n  [ '.l82x9zwi', '{border-bottom-left-radius:8px}' ],\\n  [ '.a8c37x1j', '{display:block}' ],\\n  [ '.ew0dbk1b', '{margin-bottom:-5px}' ],\\n  [ '.irj2b8pg', '{margin-top:-5px}' ],\\n  [ '.nc684nl6', '{display:inline}' ]\\n]\\n```\\n\\nNa końcu dokonujemy podmienienia klas na identyfikatory przypisane stylom\\n\\n```typescript\\n    let out = input;\\n\\n    replaces.forEach(r => {\\n        out = out.replace(new RegExp(r[0], 'g'), r[1])\\n    })\\n    console.log(out);\\n```\\n\\nWidzimy naprawdę proste podstawienie dzięki temu, że każda klasa zawsze ma selektor w postaci stylu. To założenie potencjalnie mogło by nie być prawdą, ale Facebook stosuje skrypty minifikujące, które oczyszczają HTML z klas pozbawionych znaczenia.\\n\\nFinalnie wynikiem działania tego programu włączonego komendą\\n\\n```bash\\n npx ts-node generate_meta_selectors.ts\\n```\\n\\njest tekst meta-selektora\\n\\n```javascript\\n[...document.querySelectorAll('div{box-sizing:border-box}{position:relative}{z-index:0}{display:flex}{flex-direction:column}{flex-shrink:0}{max-width:100%}{margin-top:4px}{margin-bottom:4px} div{border-top-left-radius:8px}{border-top-right-radius:8px}{border-bottom-right-radius:8px}{border-bottom-left-radius:8px}{display:block}:not([aria-busy])')].map(e => ({\\n    name: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}>a').innerText, \\n    link: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}>a').href, \\n    context: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(2)')?.innerText, \\n    description: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(3)')?.innerText, \\n    img: e.querySelector('image')?.getAttribute('xlink:href')\\n}))\\n```\\n\\nTak jak zapowiadałem, zamiast klas są tu ich znaczenia. Nazwy klas się zmieniają, ale znaczenia zostają. Teraz nadszedł czas, żeby zapisać ten meta-selektor jako stały element naszego programu np wbudowując go do wtyczki, która wykona go w stosownym momencie na stronie Facebooka. Na przykład kiedy strona zostanie zescrolowana do końca i interwał\\n\\n```javascript\\ni = setInterval(() => window.scrollTo(0,document.body.scrollHeight), 1000);\\n```\\n\\n przestanie podnosić wartość `document.body.scrollHeight`, \\n\\nNie możemy jednak tego kodu wykonać bezpośrednio, bo zawiera on selektory nie będące poprawnymi selektorami. Aby móc go wykonać musimy tą operację odwrócić. Do tego potrzebujemy oddzielnego skryptu.\\n\\n### Odzyskanie prawdziwych i aktualnych selektorów dzięki meta-selektorom\\n\\nTworzymy plik `generate_temp_selector.ts`. Przyzwyczajeni do tego jak tego typu pliki wyglądają łatwo odnajdziemy się w części otaczającej ciało funkcji `main`.\\n\\n```typescript\\nimport md5 from \\\"md5\\\";\\nimport fs from \\\"fs\\\";\\n\\nconst metaSelector = `[...document.querySelectorAll('div{box-sizing:border-box}{position:relative}{z-index:0}{display:flex}{flex-direction:column}{flex-shrink:0}{max-width:100%}{margin-top:4px}{margin-bottom:4px} div{border-top-left-radius:8px}{border-top-right-radius:8px}{border-bottom-right-radius:8px}{border-bottom-left-radius:8px}{display:block}:not([aria-busy])')].map(e => ({\\n    name: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}>a').innerText, \\n    link: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}>a').href,\\n    context: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(2)')?.innerText, \\n    description: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(3)')?.innerText, \\n    img: e.querySelector('image')?.getAttribute('xlink:href')\\n}))`;\\n\\n\\nconst CACHE_DIR = process.cwd() + `/.cache`;\\nconst url = `https://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug`;\\n\\nconst main = async (): Promise<void> => {\\n\\n};\\n\\nmain().catch(e => {\\n    console.error(e);\\n})\\n```\\n\\nDane wejściowe do programu to ponownie `url` oraz ciąg znakowy, tym razem nazwany `metaSelector`. Celem funkcji `main` jest wydrukowanie na ekranie selektora używając drugiej mapy - tej przeprowadzającej style na selektory. \\n\\n```typescript\\n    const name = md5(url);\\n    const path = `${CACHE_DIR}/${name}.styleToSelector.json`;\\n    const styleToSelector = JSON.parse(fs.readFileSync(path).toString())\\n\\n    const selectors = [...new Set(metaSelector.match(/'.*?'/g).join('').match(/\\\\{.*?\\\\}/g))];\\n```\\n\\nZaczynamy tak jak ostatnio, ale tym razem szukamy selektorów, więc stosujemy odrobinę inny wyrażenia regularne i drugą z wygenerowanych map. Również tu chcemy stworzy listę zastąpień, ale różni się ona typem od tej stosowanej w poprzednim programie.\\n\\n```typescript\\n    const replaces: [string, string[]][] = selectors.map(c => {\\n        const key = c.replace(/^\\\\{/, '').replace(/\\\\}$/, '');\\n        return [\\n            c,\\n            styleToSelector[key].filter((c: string) => /^\\\\.\\\\w{8}$/.test(c))\\n        ]\\n    });\\n```\\n\\nPrzykładowa wartość tej zmiennej to:\\n\\n```json\\n[\\n  [ '{box-sizing:border-box}', [ '.ibamfamh', '.rq0escxv' ] ],\\n  [ '{position:relative}', [ '.jfde6mfb', '.l9j0dhe7' ] ],\\n  [ '{z-index:0}', [ '.du4w35lb' ] ],\\n  [ '{display:flex}', [ '.mmelxcy8', '.j83agx80' ] ],\\n  [ '{flex-direction:column}', [ '.pawmy52i', '.cbu4d94t' ] ],\\n  [ '{flex-shrink:0}', [ '.n0kn69sm', '.pfnyh3mw' ] ],\\n  [ '{max-width:100%}', [ '.d2edcug0' ] ],\\n  [ '{margin-top:4px}', [ '.aahdfvyu' ] ],\\n  [ '{margin-bottom:4px}', [ '.tvmbv18p' ] ],\\n  [ '{border-top-left-radius:8px}', [ '.ue3kfks5' ] ],\\n  [ '{border-top-right-radius:8px}', [ '.pw54ja7n' ] ],\\n  [ '{border-bottom-right-radius:8px}', [ '.uo3d90p7' ] ],\\n  [ '{border-bottom-left-radius:8px}', [ '.l82x9zwi' ] ],\\n  [ '{display:block}', [ '.a7hnopfp', '.a8c37x1j' ] ],\\n  [ '{margin-bottom:-5px}', [ '.ew0dbk1b' ] ],\\n  [ '{margin-top:-5px}', [ '.irj2b8pg' ] ],\\n  [ '{display:inline}', [ '.nc684nl6' ] ]\\n]\\n```\\n\\nNiestety ze względu na wielowartościowość tego przekształcenia nie możemy użyć podmiany tak prostej jak ostatnio. Tym razem decydujemy się na kompromisy i piszemy kod, który usunie wszystkie wielowartościowe klasy. Możemy się z tym pogodzić ponieważ jak wskazaliśmy na początku, stanowią one nieznaczny procent wszystkich selektorów, jakie są stosowane.\\n\\n```typescript\\nlet out = metaSelector;\\n\\nreplaces.forEach(r => {\\n    out = out.replace(new RegExp(r[0], 'g'), r[1].length === 1 ? r[1][0] : '')\\n})\\nconsole.log(out);\\n```\\n\\nPo wykonaniu programu komendą\\n\\n```\\nnpx ts-node generate_temp_selector.ts\\n```\\n\\ndostaniemy gotowy do użycia kod strukturyzujący listę osób z grupy Facebooka:\\n\\n```javascript\\n[...document.querySelectorAll('div.du4w35lb.d2edcug0.aahdfvyu.tvmbv18p div.ue3kfks5.pw54ja7n.uo3d90p7.l82x9zwi:not([aria-busy])')].map(e => ({\\n    name: e.querySelector('.ew0dbk1b.irj2b8pg div.nc684nl6>a').innerText, \\n    link: e.querySelector('.ew0dbk1b.irj2b8pg div.nc684nl6>a').href,\\n    context: e.querySelector('.ew0dbk1b.irj2b8pg :nth-child(2)')?.innerText, \\n    description: e.querySelector('.ew0dbk1b.irj2b8pg :nth-child(3)')?.innerText, \\n    img: e.querySelector('image')?.getAttribute('xlink:href')\\n}))\\n```\\n\\n### Analiza wyników\\n\\nDługość nowego selektora to 513 znaków w porównaniu z 639 dla selektora wejściowego, ale działa on świetnie. Dla grupy, którą analizowaliśmy mającej 4576 osób procedura automatycznego scrollingu w dół zajęła 90 minut.\\n\\n![Szbybkość pozyskiwania leadów](https://preciselab.fra1.digitaloceanspaces.com/blog/fb-scraping-in-2020/lead-time.svg)\\n\\nJSON z danymi ważył 2.1 MB. Po konwersji do formatu CSV komendą:\\n\\n```bash\\njq -r '.[] | ([.name,.context,.description,.link,.img] | @csv)' .cache/crypto.json > .cache/crypto.csv\\n```\\n\\npowstały `.csv` miał 1.9 MB. Blisko połowa tych danych to adresy obrazków profilowych, które są dość długie, ale raczej działają od kilku godzin do kilku dni po pobraniu, nie dłużej, dlatego zalecam dodanie ich do kolejki pobierania przez osobny proces, jeśli chcemy je gromadzić. Łatwo możemy sprawdzić to dzięki utworzeniu pliku, który by ich nie posiadał:\\n\\n```bash\\njq '.[] | {name:.name,context:.context,description:.description,link:.link}' .cache/crypto.json > .cache/crypto-no-img.json\\n```\\n\\nI sprawdzeniu rozmiaru tak powstałego pliku\\n\\n```bash\\ndu -ha .cache\\n332K    .cache/f3579000ff0b02d47dec7a17d043e454.selectorToStyle.json\\n360K    .cache/f3579000ff0b02d47dec7a17d043e454.styleToSelector.json\\n2.1M    .cache/crypto.json\\n1016K   .cache/crypto-no-img.json\\n336K    .cache/f3579000ff0b02d47dec7a17d043e454.css\\n1.9M    .cache/crypto.csv\\n6.0M    .cache\\n```\\n\\nTe awatary same ważą 2.19 KiB i mają rozmiar 60x60 px. Łatwo można sprawdzić jaki był rozmiaru udział różnych typów danych w scrapingu:\\n\\n![Procentowy udział typów danych w objętości scrapingu](https://preciselab.fra1.digitaloceanspaces.com/blog/fb-scraping-in-2020/data-volume.svg)\\n\\nNależy zaznaczyć, że ze względu na realny rozmiar drzewa dom, w Facebooku, można szacować, że przeglądarka musiała wybudować kilkaset MB, żebyśmy mogli pobrać te dane. Przez cały czas scrolowania (90 minut) przeglądarka zużywała 100% rdzenia o taktowaniu 2GHz.\\n\\n### Rekomendacja dla programistów Facebooka\\n\\nPrzepiszcie serwis na flutter, to scraping stanie się o całe rzędy wielkości droższy i praktycznie nieopłacalny w wielu przypadkach. Innym prostszym rozwiązaniem było by podniesienie ilości różnych klas mających ten sam styl i miksowanie ich za pomocą randomizerów, które powodowały by losowe wypadanie danych z selektorów opartych o te klasy. Owszem, pliki CSS były by cięższe, ale było by to mocne uderzenie w prezentowaną przeze mnie metodę. \\n\\n### Rekomendacja dla tych, którzy scrapują\\n\\nWyścig zbrojeń w zakresie scrapingu wchodzi w coraz ciekawszą fazę. Automatyzacja jest wciąż częściowo możliwa, ale jej rozszerzanie wymaga coraz wyższych nakładów oraz badań nad odwzorowywaniem zachowań naturalnych dla użytkowników, tak aby pisane przez nas skrypty pozostawały nie wykryte mimo coraz bardziej wyrafinowanych metod ich detekcji. \\n\\nMoim zdaniem na kontach przeznaczonych do scrapingu warto  prowadzić normalne aktywności wykorzystując realne osoby przynajmniej w takim stopniu, aby generując taką naturalną aktywność przeplataną pracą bota można było obniżyć ryzyko klasyfikacji jako bot i uniknąć captha oraz banowania konta.\\n\\nNależy pamiętać, że takie zbieranie danych jest niezgodne z regulaminem Facebooka, który mówi, że potrzebujemy na to pisemnej zgody.\\n\\nhttps://www.facebook.com/apps/site_scraping_tos_terms.php\\n\\nA ponieważ to są dane osobowe przetwarzane bez zgody właścicieli to w pewnych częściach świata jest to niezgodne z regulacjami takimi jak europejskie GDPR znane w Polsce jako RODO. \\n\\n### Źródła\\n\\nhttp://www.proto.pl/aktualnosci/liczba-uzytkownikow-facebooka-zwieksza-sie-mimo-skandali\\n\\nhttps://www.wired.com/story/facebook-removes-accounts-ai-generated-photos/\\n\\nhttps://stackoverflow.com/questions/56238356/understanding-esmoduleinterop-in-tsconfig-file\\n\\nhttps://www.typescriptlang.org/docs/handbook/module-resolution.html\\n\\nhttps://about.fb.com/news/2020/10/taking-legal-action-against-data-scraping/\\n\\nhttps://www.octoparse.com/blog/5-things-you-need-to-know-before-scraping-data-from-facebook\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"metoda-stabilnych-meta-selektor%C3%B3w-opartych-o-stylowanie\">Metoda stabilnych meta-selektorów opartych o stylowanie</h2>\n<p>Artykuł ma na celu zapoznanie czytelnika z metodą na scaping portalu Facebooka po wprowadzeniu aktualizacji layoutu. Wymagana jest znajomość TypeScript lub JavaScript, oraz zasad działania selektorów CSS. Pokazujemy w nim zestaw narzędzi, które rozwiązują problem takiego budowania selektorów, aby były one stabilne na przykładzie scrapingu członków grupy.</p>\n<p>Po aferze Cambridge Analitica, po przesłuchaniach Zucka przed senatem USA, po wprowadzeniu RODO scraping danych w mediach społecznościowych staje się stopniowo coraz trudniejszy. Liderem we wprowadzaniu zabezpieczeń jest bezsprzecznie Facebook.</p>\n<p>Przy zaledwie 2.3 miliarda kont aktywnych użytkowników rocznie usuwanych jest około 6 miliardów fakeowych kont. Co ciekawe przy takiej skali nie znam nikogo, kto mając prawdziwe konto skarżył by się na bezpodstawne banowanie. Tą fenomenalną precyzję zapewnia Facebookowi wykorzystanie 20 tysięcy współczynników, które sztuczna inteligencja wykorzystuje do umieszczania użytkowników na mapie poziomów ryzyka, że konto nie należy do prawdziwego człowieka.</p>\n<p>Serwis w miarę możliwości zbiera informacje o osobach, które nie mają kont, ale istnieją i mogły by je założyć. Potrafi też wykrywać zdjęcia generowane komputerowo dzięki artefaktom powstającym przy sztucznym tworzeniu zdjęć twarzy przy kącikach oczu.</p>\n<p>Wszystkie te działania, służą dwóm podstawowym celom:</p>\n<ul>\n<li>uodpornieniu sieci społecznościowej na zautomatyzowane, masowe umieszczenie treści</li>\n<li>zapobieganiu zautomatyzowanemu pobieraniu i przetwarzaniu danych dostępnych w serwisie</li>\n</ul>\n<p>Samemu wykrywaniu i banowaniu botów towarzyszą inne działania, jak na przykład obfuskacja kodu strony internetowej. Technika ta polega na zastępowaniu nazw i instrukcji zrozumiałych dla człowieka przez takie, które nie utrudniają czytanie i pracę z kodem źródłowym.</p>\n<p>Przykładem czystego kodu, łatwego do zrozumienia dla programisty jest:</p>\n<pre><code class=\"language-html\">&lt;form class=&quot;dismiss js-notice-dismiss&quot; action=&quot;/users/16663028/dismiss_notice?notice_name=org_newbie&quot; accept-charset=&quot;UTF-8&quot; method=&quot;post&quot;&gt;&lt;input type=&quot;hidden&quot; name=&quot;_method&quot; value=&quot;delete&quot;&gt;\n</code></pre>\n<p>Podczas gdy na Facebooku można się spodziewać raczej czegoś takiego:</p>\n<pre><code class=\"language-html\">&lt;div class=&quot;rq0escxv l9j0dhe7 du4w35lb j83agx80 cbu4d94t pfnyh3mw d2edcug0 hv4rvrfc dati1w0a&quot;&gt;&lt;div class=&quot;rq0escxv l9j0dhe7 du4w35lb j83agx80 cbu4d94t e5nlhep0 aodizinl&quot;&gt;\n</code></pre>\n<p>W dostępnym jeszcze niedawno front-endzie Facebooka często można było natknąć się na atrybuty takie jak <code>data-testId</code>, które służyły do opierania o nie testów automatycznych interfejsu, ale nowy layout jest ich pozbawiony. Inżynierowie Facebooka musieli sobie zdawać sprawę z tego, że pomocne dla nich punkty zaczepienia były wykorzystywane przez twórców botów.</p>\n<p>Topologia drzewa DOM jest również bardziej płynna niż można by się spodziewać i budowanie długich opartych o nią selektorów typu:</p>\n<pre><code>div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div:nth-child(2) span[dir=auto] &gt; a:nth-child(1)\n</code></pre>\n<p>jest pracochłonnym i ryzykownym zadaniem.</p>\n<hr>\n<p>Mimo wielu trudności, twórca bota nadal nie jest na straconej pozycji. Front-end Facebooka nie jest rysowany na canvasie za pomocą webassmebly. Gdyby przepisano go na fluttera, problem był by naprawdę poważny. Jednak z taką obfuckacją, jaka jest stosowana na Facebooku można poradzić sobie dzięki następującej strategii.</p>\n<ol>\n<li>Patrzymy nie na nazwy klas tylko na ich znacznie - style, które są do nich przypisane</li>\n<li>Pobieramy aktualny CSS strony Facebooka, którą przeglądamy i rozkładamy ją na mapę klas i ich styli</li>\n<li>Budujemy nasze stabilne meta selektory za pomocą styli używając np.: <code>{display:block}</code> zamiast <code>.d-block</code>.</li>\n<li>Konwertujemy stabilne meta selektory do formy poprawnych tymczasowych selektorów działających dla tej konkretnej strony</li>\n<li>Wydobywamy interesujące nas dane już bez problemów jak za starych dobrych czasów</li>\n</ol>\n<p>Należy zaznaczyć, że niektóre style się powtarzają i znajdziemy wiele klas, które powodują takie samo stylowanie. Poniżej załączam histogram częstotliwości duplikacji styli dla selektorów w kodzie CSS Facebooka.</p>\n<table>\n<thead>\n<tr>\n<th>Liczba równoważnych klas</th>\n<th>Częstość wystąpień</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>6475</td>\n</tr>\n<tr>\n<td>2</td>\n<td>304</td>\n</tr>\n<tr>\n<td>3</td>\n<td>65</td>\n</tr>\n<tr>\n<td>4</td>\n<td>22</td>\n</tr>\n<tr>\n<td>5</td>\n<td>12</td>\n</tr>\n<tr>\n<td>6</td>\n<td>5</td>\n</tr>\n<tr>\n<td>7</td>\n<td>5</td>\n</tr>\n<tr>\n<td>8</td>\n<td>2</td>\n</tr>\n<tr>\n<td>10</td>\n<td>1</td>\n</tr>\n<tr>\n<td>15</td>\n<td>1</td>\n</tr>\n<tr>\n<td>19</td>\n<td>1</td>\n</tr>\n<tr>\n<td>21</td>\n<td>1</td>\n</tr>\n<tr>\n<td>25</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n<p>Zaleca się korzystanie z tych, które się nie duplikują, ale obsługa pozostałych przypadków powoduje tylko podniesienie ilości możliwych kombinacji tymczasowych selektorów co nie wydaje się dużym kosztem, w szczególności jeśli zechcemy wykorzystać w naszych selektorach relacje między elementami drzewa DOM.</p>\n<hr>\n<p>Prezentujemy teraz implementację tego konceptu w praktyce na przykładzie. Naszym celem jest ściągnięcie listy członków grupy.</p>\n<blockquote>\n<p><a href=\"https://www.facebook.com/groups/1590278311045624/members\">https://www.facebook.com/groups/1590278311045624/members</a></p>\n</blockquote>\n<p><img src=\"https://preciselab.fra1.digitaloceanspaces.com/blog/fb-scraping-in-2020/leads.png\" alt=\"\" loading=\"lazy\"></p>\n<p>Na liście osób szukamy ramek otaczających całe elementy listy oraz ramki otaczającej teksty. Wśród nich zależy nam na tych, które mają umiarkowaną liczbę klas. Jedna to za mało, bo selektor nie był by zbyt precyzyjny, 10 to dużo, bo mimo precyzji mógł by nie być wystarczająco stabilny. Przykładowy działający selektor kod strukturyzujący tą listę wygląda tak.</p>\n<p>Możemy zacząć od takiego kodu, który mapuje nam nazwę, kontekst, opis i awatar osoby w grupie</p>\n<pre><code class=\"language-javascript\">[...document.querySelectorAll('div.ue3kfks5.pw54ja7n.uo3d90p7.l82x9zwi.a8c37x1j')].map(e =&gt; ({\n    name: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg div.nc684nl6&gt;a').innerText, \n    context: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(2)')?.innerText, \n    description: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(3)')?.innerText, \n    img: e.querySelector('image')?.getAttribute('xlink:href')\n}))\n</code></pre>\n<p>Niestety o ile u mnie ten kod zadziałał, to u Ciebie może być z nim problem, ponieważ jest duża szansa, że Facebook wprowadził aktualizację zmieniającą nazwy klas. Dlatego właśnie chcemy stworzy meta-selektor, który będzie niezmiennym źródłem budującym selektory takie jak ten w oparciu o plik CSS Facebooka.</p>\n<p>Oznacza to, że żeby utrwalić nasz kod musimy zamienić klasy na przypisane im style. W tym celu szukamy w źródle strony linku do pierwszego pliku CSS:</p>\n<pre><code class=\"language-scss\">https://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug\n</code></pre>\n<h3 id=\"typescript-config\">TypeScript config</h3>\n<p>Następnie tworzymy plik <code>tsconfig.json</code> z zawartością</p>\n<pre><code class=\"language-json\">{\n  &quot;compilerOptions&quot;: {\n    &quot;esModuleInterop&quot;: true,\n    &quot;target&quot;: &quot;ES2020&quot;,\n    &quot;moduleResolution&quot;: &quot;node&quot;\n  }\n}\n</code></pre>\n<p>Pierwsza własność - <code>esModuleInterop</code> pozwala nam na import zgodny ze specyfikacją modułów es6 bibliotek, które były modułami CommonJS. Np dzięki tej fladze możemy pisać:</p>\n<pre><code class=\"language-typescript\">import fs from &quot;fs&quot;;\n</code></pre>\n<p>zamiast</p>\n<pre><code class=\"language-typescript\">import * as fs from &quot;fs&quot;;\n</code></pre>\n<p>lub</p>\n<pre><code class=\"language-typescript\">const fs = require(&quot;fs&quot;);\n</code></pre>\n<p>Kolejna: <code>&quot;target&quot;: &quot;ES2020&quot;</code> pozwala nam na używanie nowych elementów specyfikacji, na przykład bez tej linii nie mogli byśmy użyć mapy <code>Set</code> do eliminacji duplikatów.</p>\n<p>Ostatnia: <code>&quot;moduleResolution&quot;: &quot;node&quot;</code> pozwala na bardziej elastyczny import paczek w TypeScript i jest zalecana do większości projektów. U nas rozwiązała problem z importem paczki <code>axios</code>.</p>\n<h3 id=\"zale%C5%BCno%C5%9Bcipackagejson\">Zależności - Package.json</h3>\n<p>Kolejnym ważnym plikiem jest <code>package.json</code>, w naszym przypadku wygląda on tak:</p>\n<pre><code class=\"language-json\">{\n  &quot;name&quot;: &quot;fb-scraping-tools&quot;,\n  &quot;version&quot;: &quot;1.0.0&quot;,\n  &quot;description&quot;: &quot;Set of tools created to make scraping facebook easy.&quot;,\n  &quot;author&quot;: &quot;Daniel Gustaw&quot;,\n  &quot;license&quot;: &quot;WTFPL&quot;,\n  &quot;dependencies&quot;: {\n    &quot;axios&quot;: &quot;^0.21.0&quot;,\n    &quot;md5&quot;: &quot;^2.3.0&quot;,\n    &quot;ts-node&quot;: &quot;^9.0.0&quot;\n  },\n  &quot;devDependencies&quot;: {\n    &quot;@types/md5&quot;: &quot;^2.2.1&quot;,\n    &quot;@types/node&quot;: &quot;^14.14.6&quot;,\n    &quot;typescript&quot;: &quot;^4.0.5&quot;\n  }\n}\n</code></pre>\n<p>Widzimy, że korzystamy tu z TypeScript, pobraliśmy kilka zestawów typów do podpowiadania składni, poza tym <code>axios</code> do wysyłania żądań http oraz <code>md5</code> do wyliczania sum kontrolnych z adresów <code>url</code>.</p>\n<h3 id=\"dekompozycja-styli-facebooka\">Dekompozycja styli Facebooka</h3>\n<p>Przejdziemy teraz do najciekawszej części, czyli rozkładu styli Facebooka na mapę klas i styli oraz odwrotną mapę przypisującą kolekcję selektorów określonym stylom.</p>\n<p>Plik <code>decompose_css_to_json.ts</code> zaczynamy od importu wymaganych paczek:</p>\n<pre><code class=\"language-typescript\">import axios from &quot;axios&quot;;\nimport md5 from &quot;md5&quot;;\nimport fs from &quot;fs&quot;;\n</code></pre>\n<p>Są to proste paczki, które opisaliśmy już przy okazji omawiania pliku z zależnościami. Kolejnym krokiem będzie definiowanie wymaganych typów.</p>\n<pre><code class=\"language-typescript\">type StringAccumulator = Record&lt;string, string&gt;\ntype ArrayAccumulator = Record&lt;string, string[]&gt;\n</code></pre>\n<p>Tu nazwy mówią same za siebie, będą to typy w których nie znamy jeszcze kluczy, ale wiemy, że wartości są ciągami znakowymi, albo tablicami ciągów znakowych. Jest tak dlatego, że odwzorowanie styli do selektorów jest wielowartościowe.</p>\n<p>Kolejnym krokiem jest nadanie programowi szkieletowej struktury:</p>\n<pre><code class=\"language-typescript\">const CACHE_DIR = process.cwd() + `/.cache`;\nconst url = `https://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug`;\n\nconst main = async (): Promise&lt;void&gt; =&gt; {\n   // there will be placed source code of next part\n};\n\nmain().catch(e =&gt; {\n    console.error(e);\n})\n</code></pre>\n<p>W stałych definiujemy adres pliku ze stylami Facebooka oraz lokalizację katalogu z cache. Następny krok jest bardzo przewidywalny, chcemy zapisać zawartość pliku w cache, lub odczytać ją z cache jeśli już była zapisana wcześniej. Dzięki temu uniezależnimy działanie programu od tego, czy link nie wygaśnie w przyszłości i obniżymy szansę zbanowania za zbyt częste requesty. Jest to ważny element pracy w pisaniu programów tego typu.</p>\n<pre><code class=\"language-typescript\">    if (!fs.existsSync(CACHE_DIR)) {\n        fs.mkdirSync(CACHE_DIR);\n    }\n\n    const name = md5(url);\n    const path = `${CACHE_DIR}/${name}.css`;\n    let text = '';\n    if (fs.existsSync(path)) {\n        text = fs.readFileSync(path).toString()\n    } else {\n        const {data} = await axios.get(url);\n        text = data;\n        fs.writeFileSync(path, text);\n    }\n</code></pre>\n<p>Mimo, że ważny, to nie odkrywczy i jedynym zadanie tego kodu jest przygotowanie zmiennych <code>path</code> z ścieżką do pliku <code>css</code> i <code>text</code> z jego zawartością.</p>\n<p>Znacznie ciekawszym fragmentem jest sam rozkład. Polega on na rozbiciu styli za pomocą wyrażeń regularnych, a następnie budowaniu jednocześnie dwóch map.</p>\n<pre><code class=\"language-typescript\">    const [styleToSelector, selectorToStyle]: [ArrayAccumulator, StringAccumulator] = text.match(/.*?\\{.*?\\}/g).reduce(\n        (p: [ArrayAccumulator, StringAccumulator], n): [ArrayAccumulator, StringAccumulator] =&gt; {\n            const [_, key, value]:string[] = n.match(/(.*?)\\{(.*?)\\}/);\n\n            const cleanKey = key.replace(/^\\}/,'')\n\n            return [\n                {...p[0], [value]: [cleanKey, ...(p[0][value] || [])]},\n                {...p[1], [cleanKey]: value}\n            ];\n        }, [{}, {}]\n    );\n</code></pre>\n<p>Zmienna <code>cleanKey</code> wprowadzona została, żeby poradzić sobie z klasami, występującymi za znakiem <code>}}</code>, co w plikach <code>css</code> jest możliwe. Utrata tego znaku <code>}</code> z wartości nie zmienia niczego, ponieważ wartości i tak są dla nas tylko identyfikatorami, a nie fragmentami stylizacji, którą mieli byśmy gdziekolwiek implementować.</p>\n<p>Na końcu utrwalamy wyniki w plikach JSON.</p>\n<pre><code class=\"language-typescript\">    fs.writeFileSync(path.replace(/css$/, 'styleToSelector.json'), JSON.stringify(styleToSelector));\n    fs.writeFileSync(path.replace(/css$/, 'selectorToStyle.json'), JSON.stringify(selectorToStyle));\n</code></pre>\n<p>Program włączamy komendą</p>\n<pre><code class=\"language-bash\">npx ts-node decompose_css_to_json.ts\n</code></pre>\n<p>Nie drukuje on wyników, ale tworzy trzy pliki w ukrytym katalogu <code>.cache</code>. Czas wykonywania tego programu to około</p>\n<h3 id=\"budowanie-meta-selektor%C3%B3w-na-podstawie-selektor%C3%B3w-tymczasowych\">Budowanie meta-selektorów na podstawie selektorów tymczasowych</h3>\n<p>Meta-selektorem nazywam selektor, którym nazwy klas są zastąpione identyfikującymi je zasadami stylowania. Tworzenie meta-selektorów jest potrzebne, żeby kod, który tworzymy był stabilny. Punktem wyjściowym do jego stworzenia jest selektor napisany w konsoli przeglądarki.</p>\n<p>Program nazwiemy <code>generate_meta_selectors.ts</code>. W standardowym layoucie skryptu mamy zmienną <code>input</code>. W niej zapisujemy działające zapytanie strukturyzujące wyświetlaną stronę Facebookową. Wykonanie go w konsoli przeglądarki powinno zwrócić tablicę z obiektami odpowiadającymi uczestnikom grupy Facebookowej.</p>\n<pre><code class=\"language-typescript\">import md5 from &quot;md5&quot;;\nimport fs from &quot;fs&quot;;\n\nconst input = `[...document.querySelectorAll('div.rq0escxv.l9j0dhe7.du4w35lb.j83agx80.cbu4d94t.pfnyh3mw.d2edcug0.aahdfvyu.tvmbv18p div.ue3kfks5.pw54ja7n.uo3d90p7.l82x9zwi.a8c37x1j:not([aria-busy])')].map(e =&gt; ({\n    name: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg div.nc684nl6&gt;a').innerText, \n    link: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg div.nc684nl6&gt;a').href, \n    context: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(2)')?.innerText, \n    description: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(3)')?.innerText, \n    img: e.querySelector('image')?.getAttribute('xlink:href')\n}))`;\n\nconst CACHE_DIR = process.cwd() + `/.cache`;\nconst url = `https://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug`;\n\nconst main = async (): Promise&lt;void&gt; =&gt; {\n\t// there will be next part of presented program\n};\n\nmain().catch(e =&gt; {\n    console.error(e);\n})\n</code></pre>\n<p>Teraz aby przetworzyć losowe klasy w selektorach na stabilne meta-selektory pobieramy zawartość pliku z mapą selektorów</p>\n<pre><code class=\"language-typescript\">    const name = md5(url);\n    const path = `${CACHE_DIR}/${name}.selectorToStyle.json`;\n    const selectorToStyle = JSON.parse(fs.readFileSync(path).toString())\n</code></pre>\n<p>Tworzymy tablicę klas w dwóch krokach - pobierając ciągi w cudzysłowach, a następnie wycinając z nich ośmioznakowe ciągi cyfr i liter poprzedzone kropką</p>\n<pre><code class=\"language-typescript\">    const classes = [...new Set(input.match(/'.*?'/g).join('').match(/\\.\\w{8}/g))];\n</code></pre>\n<p>Na podstawie tych klas oraz dzięki mapie pobranej do zmiennej <code>selectorToStyle</code> możemy wytworzyć tablicę podstawień</p>\n<pre><code class=\"language-typescript\">    const replaces: [string, string][] = classes.map(c =&gt; [c, `{${selectorToStyle[c]}}`]);\n</code></pre>\n<p>Wartość tej zmiennej wyniosła w naszym przykładzie</p>\n<pre><code class=\"language-json\">[\n  [ '.rq0escxv', '{box-sizing:border-box}' ],\n  [ '.l9j0dhe7', '{position:relative}' ],\n  [ '.du4w35lb', '{z-index:0}' ],\n  [ '.j83agx80', '{display:flex}' ],\n  [ '.cbu4d94t', '{flex-direction:column}' ],\n  [ '.pfnyh3mw', '{flex-shrink:0}' ],\n  [ '.d2edcug0', '{max-width:100%}' ],\n  [ '.aahdfvyu', '{margin-top:4px}' ],\n  [ '.tvmbv18p', '{margin-bottom:4px}' ],\n  [ '.ue3kfks5', '{border-top-left-radius:8px}' ],\n  [ '.pw54ja7n', '{border-top-right-radius:8px}' ],\n  [ '.uo3d90p7', '{border-bottom-right-radius:8px}' ],\n  [ '.l82x9zwi', '{border-bottom-left-radius:8px}' ],\n  [ '.a8c37x1j', '{display:block}' ],\n  [ '.ew0dbk1b', '{margin-bottom:-5px}' ],\n  [ '.irj2b8pg', '{margin-top:-5px}' ],\n  [ '.nc684nl6', '{display:inline}' ]\n]\n</code></pre>\n<p>Na końcu dokonujemy podmienienia klas na identyfikatory przypisane stylom</p>\n<pre><code class=\"language-typescript\">    let out = input;\n\n    replaces.forEach(r =&gt; {\n        out = out.replace(new RegExp(r[0], 'g'), r[1])\n    })\n    console.log(out);\n</code></pre>\n<p>Widzimy naprawdę proste podstawienie dzięki temu, że każda klasa zawsze ma selektor w postaci stylu. To założenie potencjalnie mogło by nie być prawdą, ale Facebook stosuje skrypty minifikujące, które oczyszczają HTML z klas pozbawionych znaczenia.</p>\n<p>Finalnie wynikiem działania tego programu włączonego komendą</p>\n<pre><code class=\"language-bash\"> npx ts-node generate_meta_selectors.ts\n</code></pre>\n<p>jest tekst meta-selektora</p>\n<pre><code class=\"language-javascript\">[...document.querySelectorAll('div{box-sizing:border-box}{position:relative}{z-index:0}{display:flex}{flex-direction:column}{flex-shrink:0}{max-width:100%}{margin-top:4px}{margin-bottom:4px} div{border-top-left-radius:8px}{border-top-right-radius:8px}{border-bottom-right-radius:8px}{border-bottom-left-radius:8px}{display:block}:not([aria-busy])')].map(e =&gt; ({\n    name: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}&gt;a').innerText, \n    link: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}&gt;a').href, \n    context: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(2)')?.innerText, \n    description: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(3)')?.innerText, \n    img: e.querySelector('image')?.getAttribute('xlink:href')\n}))\n</code></pre>\n<p>Tak jak zapowiadałem, zamiast klas są tu ich znaczenia. Nazwy klas się zmieniają, ale znaczenia zostają. Teraz nadszedł czas, żeby zapisać ten meta-selektor jako stały element naszego programu np wbudowując go do wtyczki, która wykona go w stosownym momencie na stronie Facebooka. Na przykład kiedy strona zostanie zescrolowana do końca i interwał</p>\n<pre><code class=\"language-javascript\">i = setInterval(() =&gt; window.scrollTo(0,document.body.scrollHeight), 1000);\n</code></pre>\n<p>przestanie podnosić wartość <code>document.body.scrollHeight</code>,</p>\n<p>Nie możemy jednak tego kodu wykonać bezpośrednio, bo zawiera on selektory nie będące poprawnymi selektorami. Aby móc go wykonać musimy tą operację odwrócić. Do tego potrzebujemy oddzielnego skryptu.</p>\n<h3 id=\"odzyskanie-prawdziwych-i-aktualnych-selektor%C3%B3w-dzi%C4%99ki-meta-selektorom\">Odzyskanie prawdziwych i aktualnych selektorów dzięki meta-selektorom</h3>\n<p>Tworzymy plik <code>generate_temp_selector.ts</code>. Przyzwyczajeni do tego jak tego typu pliki wyglądają łatwo odnajdziemy się w części otaczającej ciało funkcji <code>main</code>.</p>\n<pre><code class=\"language-typescript\">import md5 from &quot;md5&quot;;\nimport fs from &quot;fs&quot;;\n\nconst metaSelector = `[...document.querySelectorAll('div{box-sizing:border-box}{position:relative}{z-index:0}{display:flex}{flex-direction:column}{flex-shrink:0}{max-width:100%}{margin-top:4px}{margin-bottom:4px} div{border-top-left-radius:8px}{border-top-right-radius:8px}{border-bottom-right-radius:8px}{border-bottom-left-radius:8px}{display:block}:not([aria-busy])')].map(e =&gt; ({\n    name: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}&gt;a').innerText, \n    link: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}&gt;a').href,\n    context: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(2)')?.innerText, \n    description: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(3)')?.innerText, \n    img: e.querySelector('image')?.getAttribute('xlink:href')\n}))`;\n\n\nconst CACHE_DIR = process.cwd() + `/.cache`;\nconst url = `https://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug`;\n\nconst main = async (): Promise&lt;void&gt; =&gt; {\n\n};\n\nmain().catch(e =&gt; {\n    console.error(e);\n})\n</code></pre>\n<p>Dane wejściowe do programu to ponownie <code>url</code> oraz ciąg znakowy, tym razem nazwany <code>metaSelector</code>. Celem funkcji <code>main</code> jest wydrukowanie na ekranie selektora używając drugiej mapy - tej przeprowadzającej style na selektory.</p>\n<pre><code class=\"language-typescript\">    const name = md5(url);\n    const path = `${CACHE_DIR}/${name}.styleToSelector.json`;\n    const styleToSelector = JSON.parse(fs.readFileSync(path).toString())\n\n    const selectors = [...new Set(metaSelector.match(/'.*?'/g).join('').match(/\\{.*?\\}/g))];\n</code></pre>\n<p>Zaczynamy tak jak ostatnio, ale tym razem szukamy selektorów, więc stosujemy odrobinę inny wyrażenia regularne i drugą z wygenerowanych map. Również tu chcemy stworzy listę zastąpień, ale różni się ona typem od tej stosowanej w poprzednim programie.</p>\n<pre><code class=\"language-typescript\">    const replaces: [string, string[]][] = selectors.map(c =&gt; {\n        const key = c.replace(/^\\{/, '').replace(/\\}$/, '');\n        return [\n            c,\n            styleToSelector[key].filter((c: string) =&gt; /^\\.\\w{8}$/.test(c))\n        ]\n    });\n</code></pre>\n<p>Przykładowa wartość tej zmiennej to:</p>\n<pre><code class=\"language-json\">[\n  [ '{box-sizing:border-box}', [ '.ibamfamh', '.rq0escxv' ] ],\n  [ '{position:relative}', [ '.jfde6mfb', '.l9j0dhe7' ] ],\n  [ '{z-index:0}', [ '.du4w35lb' ] ],\n  [ '{display:flex}', [ '.mmelxcy8', '.j83agx80' ] ],\n  [ '{flex-direction:column}', [ '.pawmy52i', '.cbu4d94t' ] ],\n  [ '{flex-shrink:0}', [ '.n0kn69sm', '.pfnyh3mw' ] ],\n  [ '{max-width:100%}', [ '.d2edcug0' ] ],\n  [ '{margin-top:4px}', [ '.aahdfvyu' ] ],\n  [ '{margin-bottom:4px}', [ '.tvmbv18p' ] ],\n  [ '{border-top-left-radius:8px}', [ '.ue3kfks5' ] ],\n  [ '{border-top-right-radius:8px}', [ '.pw54ja7n' ] ],\n  [ '{border-bottom-right-radius:8px}', [ '.uo3d90p7' ] ],\n  [ '{border-bottom-left-radius:8px}', [ '.l82x9zwi' ] ],\n  [ '{display:block}', [ '.a7hnopfp', '.a8c37x1j' ] ],\n  [ '{margin-bottom:-5px}', [ '.ew0dbk1b' ] ],\n  [ '{margin-top:-5px}', [ '.irj2b8pg' ] ],\n  [ '{display:inline}', [ '.nc684nl6' ] ]\n]\n</code></pre>\n<p>Niestety ze względu na wielowartościowość tego przekształcenia nie możemy użyć podmiany tak prostej jak ostatnio. Tym razem decydujemy się na kompromisy i piszemy kod, który usunie wszystkie wielowartościowe klasy. Możemy się z tym pogodzić ponieważ jak wskazaliśmy na początku, stanowią one nieznaczny procent wszystkich selektorów, jakie są stosowane.</p>\n<pre><code class=\"language-typescript\">let out = metaSelector;\n\nreplaces.forEach(r =&gt; {\n    out = out.replace(new RegExp(r[0], 'g'), r[1].length === 1 ? r[1][0] : '')\n})\nconsole.log(out);\n</code></pre>\n<p>Po wykonaniu programu komendą</p>\n<pre><code>npx ts-node generate_temp_selector.ts\n</code></pre>\n<p>dostaniemy gotowy do użycia kod strukturyzujący listę osób z grupy Facebooka:</p>\n<pre><code class=\"language-javascript\">[...document.querySelectorAll('div.du4w35lb.d2edcug0.aahdfvyu.tvmbv18p div.ue3kfks5.pw54ja7n.uo3d90p7.l82x9zwi:not([aria-busy])')].map(e =&gt; ({\n    name: e.querySelector('.ew0dbk1b.irj2b8pg div.nc684nl6&gt;a').innerText, \n    link: e.querySelector('.ew0dbk1b.irj2b8pg div.nc684nl6&gt;a').href,\n    context: e.querySelector('.ew0dbk1b.irj2b8pg :nth-child(2)')?.innerText, \n    description: e.querySelector('.ew0dbk1b.irj2b8pg :nth-child(3)')?.innerText, \n    img: e.querySelector('image')?.getAttribute('xlink:href')\n}))\n</code></pre>\n<h3 id=\"analiza-wynik%C3%B3w\">Analiza wyników</h3>\n<p>Długość nowego selektora to 513 znaków w porównaniu z 639 dla selektora wejściowego, ale działa on świetnie. Dla grupy, którą analizowaliśmy mającej 4576 osób procedura automatycznego scrollingu w dół zajęła 90 minut.</p>\n<p><img src=\"https://preciselab.fra1.digitaloceanspaces.com/blog/fb-scraping-in-2020/lead-time.svg\" alt=\"Szbybkość pozyskiwania leadów\" loading=\"lazy\"></p>\n<p>JSON z danymi ważył 2.1 MB. Po konwersji do formatu CSV komendą:</p>\n<pre><code class=\"language-bash\">jq -r '.[] | ([.name,.context,.description,.link,.img] | @csv)' .cache/crypto.json &gt; .cache/crypto.csv\n</code></pre>\n<p>powstały <code>.csv</code> miał 1.9 MB. Blisko połowa tych danych to adresy obrazków profilowych, które są dość długie, ale raczej działają od kilku godzin do kilku dni po pobraniu, nie dłużej, dlatego zalecam dodanie ich do kolejki pobierania przez osobny proces, jeśli chcemy je gromadzić. Łatwo możemy sprawdzić to dzięki utworzeniu pliku, który by ich nie posiadał:</p>\n<pre><code class=\"language-bash\">jq '.[] | {name:.name,context:.context,description:.description,link:.link}' .cache/crypto.json &gt; .cache/crypto-no-img.json\n</code></pre>\n<p>I sprawdzeniu rozmiaru tak powstałego pliku</p>\n<pre><code class=\"language-bash\">du -ha .cache\n332K    .cache/f3579000ff0b02d47dec7a17d043e454.selectorToStyle.json\n360K    .cache/f3579000ff0b02d47dec7a17d043e454.styleToSelector.json\n2.1M    .cache/crypto.json\n1016K   .cache/crypto-no-img.json\n336K    .cache/f3579000ff0b02d47dec7a17d043e454.css\n1.9M    .cache/crypto.csv\n6.0M    .cache\n</code></pre>\n<p>Te awatary same ważą 2.19 KiB i mają rozmiar 60x60 px. Łatwo można sprawdzić jaki był rozmiaru udział różnych typów danych w scrapingu:</p>\n<p><img src=\"https://preciselab.fra1.digitaloceanspaces.com/blog/fb-scraping-in-2020/data-volume.svg\" alt=\"Procentowy udział typów danych w objętości scrapingu\" loading=\"lazy\"></p>\n<p>Należy zaznaczyć, że ze względu na realny rozmiar drzewa dom, w Facebooku, można szacować, że przeglądarka musiała wybudować kilkaset MB, żebyśmy mogli pobrać te dane. Przez cały czas scrolowania (90 minut) przeglądarka zużywała 100% rdzenia o taktowaniu 2GHz.</p>\n<h3 id=\"rekomendacja-dla-programist%C3%B3w-facebooka\">Rekomendacja dla programistów Facebooka</h3>\n<p>Przepiszcie serwis na flutter, to scraping stanie się o całe rzędy wielkości droższy i praktycznie nieopłacalny w wielu przypadkach. Innym prostszym rozwiązaniem było by podniesienie ilości różnych klas mających ten sam styl i miksowanie ich za pomocą randomizerów, które powodowały by losowe wypadanie danych z selektorów opartych o te klasy. Owszem, pliki CSS były by cięższe, ale było by to mocne uderzenie w prezentowaną przeze mnie metodę.</p>\n<h3 id=\"rekomendacja-dla-tych-kt%C3%B3rzy-scrapuj%C4%85\">Rekomendacja dla tych, którzy scrapują</h3>\n<p>Wyścig zbrojeń w zakresie scrapingu wchodzi w coraz ciekawszą fazę. Automatyzacja jest wciąż częściowo możliwa, ale jej rozszerzanie wymaga coraz wyższych nakładów oraz badań nad odwzorowywaniem zachowań naturalnych dla użytkowników, tak aby pisane przez nas skrypty pozostawały nie wykryte mimo coraz bardziej wyrafinowanych metod ich detekcji.</p>\n<p>Moim zdaniem na kontach przeznaczonych do scrapingu warto  prowadzić normalne aktywności wykorzystując realne osoby przynajmniej w takim stopniu, aby generując taką naturalną aktywność przeplataną pracą bota można było obniżyć ryzyko klasyfikacji jako bot i uniknąć captha oraz banowania konta.</p>\n<p>Należy pamiętać, że takie zbieranie danych jest niezgodne z regulaminem Facebooka, który mówi, że potrzebujemy na to pisemnej zgody.</p>\n<p><a href=\"https://www.facebook.com/apps/site_scraping_tos_terms.php\">https://www.facebook.com/apps/site_scraping_tos_terms.php</a></p>\n<p>A ponieważ to są dane osobowe przetwarzane bez zgody właścicieli to w pewnych częściach świata jest to niezgodne z regulacjami takimi jak europejskie GDPR znane w Polsce jako RODO.</p>\n<h3 id=\"%C5%BAr%C3%B3d%C5%82a\">Źródła</h3>\n<p><a href=\"http://www.proto.pl/aktualnosci/liczba-uzytkownikow-facebooka-zwieksza-sie-mimo-skandali\">http://www.proto.pl/aktualnosci/liczba-uzytkownikow-facebooka-zwieksza-sie-mimo-skandali</a></p>\n<p><a href=\"https://www.wired.com/story/facebook-removes-accounts-ai-generated-photos/\">https://www.wired.com/story/facebook-removes-accounts-ai-generated-photos/</a></p>\n<p><a href=\"https://stackoverflow.com/questions/56238356/understanding-esmoduleinterop-in-tsconfig-file\">https://stackoverflow.com/questions/56238356/understanding-esmoduleinterop-in-tsconfig-file</a></p>\n<p><a href=\"https://www.typescriptlang.org/docs/handbook/module-resolution.html\">https://www.typescriptlang.org/docs/handbook/module-resolution.html</a></p>\n<p><a href=\"https://about.fb.com/news/2020/10/taking-legal-action-against-data-scraping/\">https://about.fb.com/news/2020/10/taking-legal-action-against-data-scraping/</a></p>\n<p><a href=\"https://www.octoparse.com/blog/5-things-you-need-to-know-before-scraping-data-from-facebook\">https://www.octoparse.com/blog/5-things-you-need-to-know-before-scraping-data-from-facebook</a></p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f2d392fb35425592d0b22",
            "plaintext": "Metoda stabilnych meta-selektorów opartych o stylowanie\nArtykuł ma na celu zapoznanie czytelnika z metodą na scaping portalu Facebooka\npo wprowadzeniu aktualizacji layoutu. Wymagana jest znajomość TypeScript lub\nJavaScript, oraz zasad działania selektorów CSS. Pokazujemy w nim zestaw\nnarzędzi, które rozwiązują problem takiego budowania selektorów, aby były one\nstabilne na przykładzie scrapingu członków grupy.\n\nPo aferze Cambridge Analitica, po przesłuchaniach Zucka przed senatem USA, po\nwprowadzeniu RODO scraping danych w mediach społecznościowych staje się\nstopniowo coraz trudniejszy. Liderem we wprowadzaniu zabezpieczeń jest\nbezsprzecznie Facebook.\n\nPrzy zaledwie 2.3 miliarda kont aktywnych użytkowników rocznie usuwanych jest\nokoło 6 miliardów fakeowych kont. Co ciekawe przy takiej skali nie znam nikogo,\nkto mając prawdziwe konto skarżył by się na bezpodstawne banowanie. Tą\nfenomenalną precyzję zapewnia Facebookowi wykorzystanie 20 tysięcy\nwspółczynników, które sztuczna inteligencja wykorzystuje do umieszczania\nużytkowników na mapie poziomów ryzyka, że konto nie należy do prawdziwego\nczłowieka.\n\nSerwis w miarę możliwości zbiera informacje o osobach, które nie mają kont, ale\nistnieją i mogły by je założyć. Potrafi też wykrywać zdjęcia generowane\nkomputerowo dzięki artefaktom powstającym przy sztucznym tworzeniu zdjęć twarzy\nprzy kącikach oczu.\n\nWszystkie te działania, służą dwóm podstawowym celom:\n\n * uodpornieniu sieci społecznościowej na zautomatyzowane, masowe umieszczenie\n   treści\n * zapobieganiu zautomatyzowanemu pobieraniu i przetwarzaniu danych dostępnych w\n   serwisie\n\nSamemu wykrywaniu i banowaniu botów towarzyszą inne działania, jak na przykład\nobfuskacja kodu strony internetowej. Technika ta polega na zastępowaniu nazw i\ninstrukcji zrozumiałych dla człowieka przez takie, które nie utrudniają czytanie\ni pracę z kodem źródłowym.\n\nPrzykładem czystego kodu, łatwego do zrozumienia dla programisty jest:\n\n<form class=\"dismiss js-notice-dismiss\" action=\"/users/16663028/dismiss_notice?notice_name=org_newbie\" accept-charset=\"UTF-8\" method=\"post\"><input type=\"hidden\" name=\"_method\" value=\"delete\">\n\n\nPodczas gdy na Facebooku można się spodziewać raczej czegoś takiego:\n\n<div class=\"rq0escxv l9j0dhe7 du4w35lb j83agx80 cbu4d94t pfnyh3mw d2edcug0 hv4rvrfc dati1w0a\"><div class=\"rq0escxv l9j0dhe7 du4w35lb j83agx80 cbu4d94t e5nlhep0 aodizinl\">\n\n\nW dostępnym jeszcze niedawno front-endzie Facebooka często można było natknąć\nsię na atrybuty takie jak data-testId, które służyły do opierania o nie testów\nautomatycznych interfejsu, ale nowy layout jest ich pozbawiony. Inżynierowie\nFacebooka musieli sobie zdawać sprawę z tego, że pomocne dla nich punkty\nzaczepienia były wykorzystywane przez twórców botów.\n\nTopologia drzewa DOM jest również bardziej płynna niż można by się spodziewać i\nbudowanie długich opartych o nią selektorów typu:\n\ndiv > div > div > div > div > div > div > div:nth-child(2) span[dir=auto] > a:nth-child(1)\n\n\njest pracochłonnym i ryzykownym zadaniem.\n\n\n--------------------------------------------------------------------------------\n\nMimo wielu trudności, twórca bota nadal nie jest na straconej pozycji. Front-end\nFacebooka nie jest rysowany na canvasie za pomocą webassmebly. Gdyby przepisano\ngo na fluttera, problem był by naprawdę poważny. Jednak z taką obfuckacją, jaka\njest stosowana na Facebooku można poradzić sobie dzięki następującej strategii.\n\n 1. Patrzymy nie na nazwy klas tylko na ich znacznie - style, które są do nich\n    przypisane\n 2. Pobieramy aktualny CSS strony Facebooka, którą przeglądamy i rozkładamy ją\n    na mapę klas i ich styli\n 3. Budujemy nasze stabilne meta selektory za pomocą styli używając np.: \n    {display:block} zamiast .d-block.\n 4. Konwertujemy stabilne meta selektory do formy poprawnych tymczasowych\n    selektorów działających dla tej konkretnej strony\n 5. Wydobywamy interesujące nas dane już bez problemów jak za starych dobrych\n    czasów\n\nNależy zaznaczyć, że niektóre style się powtarzają i znajdziemy wiele klas,\nktóre powodują takie samo stylowanie. Poniżej załączam histogram częstotliwości\nduplikacji styli dla selektorów w kodzie CSS Facebooka.\n\nLiczba równoważnych klasCzęstość wystąpień16475230436542251265758210115119121125\n1Zaleca się korzystanie z tych, które się nie duplikują, ale obsługa pozostałych\nprzypadków powoduje tylko podniesienie ilości możliwych kombinacji tymczasowych\nselektorów co nie wydaje się dużym kosztem, w szczególności jeśli zechcemy\nwykorzystać w naszych selektorach relacje między elementami drzewa DOM.\n\n\n--------------------------------------------------------------------------------\n\nPrezentujemy teraz implementację tego konceptu w praktyce na przykładzie. Naszym\ncelem jest ściągnięcie listy członków grupy.\n\n> https://www.facebook.com/groups/1590278311045624/members\n\n\n\n\nNa liście osób szukamy ramek otaczających całe elementy listy oraz ramki\notaczającej teksty. Wśród nich zależy nam na tych, które mają umiarkowaną liczbę\nklas. Jedna to za mało, bo selektor nie był by zbyt precyzyjny, 10 to dużo, bo\nmimo precyzji mógł by nie być wystarczająco stabilny. Przykładowy działający\nselektor kod strukturyzujący tą listę wygląda tak.\n\nMożemy zacząć od takiego kodu, który mapuje nam nazwę, kontekst, opis i awatar\nosoby w grupie\n\n[...document.querySelectorAll('div.ue3kfks5.pw54ja7n.uo3d90p7.l82x9zwi.a8c37x1j')].map(e => ({\n    name: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg div.nc684nl6>a').innerText, \n    context: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(2)')?.innerText, \n    description: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(3)')?.innerText, \n    img: e.querySelector('image')?.getAttribute('xlink:href')\n}))\n\n\nNiestety o ile u mnie ten kod zadziałał, to u Ciebie może być z nim problem,\nponieważ jest duża szansa, że Facebook wprowadził aktualizację zmieniającą nazwy\nklas. Dlatego właśnie chcemy stworzy meta-selektor, który będzie niezmiennym\nźródłem budującym selektory takie jak ten w oparciu o plik CSS Facebooka.\n\nOznacza to, że żeby utrwalić nasz kod musimy zamienić klasy na przypisane im\nstyle. W tym celu szukamy w źródle strony linku do pierwszego pliku CSS:\n\nhttps://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug\n\n\nTypeScript config\nNastępnie tworzymy plik tsconfig.json z zawartością\n\n{\n  \"compilerOptions\": {\n    \"esModuleInterop\": true,\n    \"target\": \"ES2020\",\n    \"moduleResolution\": \"node\"\n  }\n}\n\n\nPierwsza własność - esModuleInterop pozwala nam na import zgodny ze specyfikacją\nmodułów es6 bibliotek, które były modułami CommonJS. Np dzięki tej fladze możemy\npisać:\n\nimport fs from \"fs\";\n\n\nzamiast\n\nimport * as fs from \"fs\";\n\n\nlub\n\nconst fs = require(\"fs\");\n\n\nKolejna: \"target\": \"ES2020\" pozwala nam na używanie nowych elementów\nspecyfikacji, na przykład bez tej linii nie mogli byśmy użyć mapy Set do\neliminacji duplikatów.\n\nOstatnia: \"moduleResolution\": \"node\" pozwala na bardziej elastyczny import\npaczek w TypeScript i jest zalecana do większości projektów. U nas rozwiązała\nproblem z importem paczki axios.\n\nZależności - Package.json\nKolejnym ważnym plikiem jest package.json, w naszym przypadku wygląda on tak:\n\n{\n  \"name\": \"fb-scraping-tools\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Set of tools created to make scraping facebook easy.\",\n  \"author\": \"Daniel Gustaw\",\n  \"license\": \"WTFPL\",\n  \"dependencies\": {\n    \"axios\": \"^0.21.0\",\n    \"md5\": \"^2.3.0\",\n    \"ts-node\": \"^9.0.0\"\n  },\n  \"devDependencies\": {\n    \"@types/md5\": \"^2.2.1\",\n    \"@types/node\": \"^14.14.6\",\n    \"typescript\": \"^4.0.5\"\n  }\n}\n\n\nWidzimy, że korzystamy tu z TypeScript, pobraliśmy kilka zestawów typów do\npodpowiadania składni, poza tym axios do wysyłania żądań http oraz md5 do\nwyliczania sum kontrolnych z adresów url.\n\nDekompozycja styli Facebooka\nPrzejdziemy teraz do najciekawszej części, czyli rozkładu styli Facebooka na\nmapę klas i styli oraz odwrotną mapę przypisującą kolekcję selektorów określonym\nstylom.\n\nPlik decompose_css_to_json.ts zaczynamy od importu wymaganych paczek:\n\nimport axios from \"axios\";\nimport md5 from \"md5\";\nimport fs from \"fs\";\n\n\nSą to proste paczki, które opisaliśmy już przy okazji omawiania pliku z\nzależnościami. Kolejnym krokiem będzie definiowanie wymaganych typów.\n\ntype StringAccumulator = Record<string, string>\ntype ArrayAccumulator = Record<string, string[]>\n\n\nTu nazwy mówią same za siebie, będą to typy w których nie znamy jeszcze kluczy,\nale wiemy, że wartości są ciągami znakowymi, albo tablicami ciągów znakowych.\nJest tak dlatego, że odwzorowanie styli do selektorów jest wielowartościowe.\n\nKolejnym krokiem jest nadanie programowi szkieletowej struktury:\n\nconst CACHE_DIR = process.cwd() + `/.cache`;\nconst url = `https://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug`;\n\nconst main = async (): Promise<void> => {\n   // there will be placed source code of next part\n};\n\nmain().catch(e => {\n    console.error(e);\n})\n\n\nW stałych definiujemy adres pliku ze stylami Facebooka oraz lokalizację katalogu\nz cache. Następny krok jest bardzo przewidywalny, chcemy zapisać zawartość pliku\nw cache, lub odczytać ją z cache jeśli już była zapisana wcześniej. Dzięki temu\nuniezależnimy działanie programu od tego, czy link nie wygaśnie w przyszłości i\nobniżymy szansę zbanowania za zbyt częste requesty. Jest to ważny element pracy\nw pisaniu programów tego typu.\n\n    if (!fs.existsSync(CACHE_DIR)) {\n        fs.mkdirSync(CACHE_DIR);\n    }\n\n    const name = md5(url);\n    const path = `${CACHE_DIR}/${name}.css`;\n    let text = '';\n    if (fs.existsSync(path)) {\n        text = fs.readFileSync(path).toString()\n    } else {\n        const {data} = await axios.get(url);\n        text = data;\n        fs.writeFileSync(path, text);\n    }\n\n\nMimo, że ważny, to nie odkrywczy i jedynym zadanie tego kodu jest przygotowanie\nzmiennych path z ścieżką do pliku css i text z jego zawartością.\n\nZnacznie ciekawszym fragmentem jest sam rozkład. Polega on na rozbiciu styli za\npomocą wyrażeń regularnych, a następnie budowaniu jednocześnie dwóch map.\n\n    const [styleToSelector, selectorToStyle]: [ArrayAccumulator, StringAccumulator] = text.match(/.*?\\{.*?\\}/g).reduce(\n        (p: [ArrayAccumulator, StringAccumulator], n): [ArrayAccumulator, StringAccumulator] => {\n            const [_, key, value]:string[] = n.match(/(.*?)\\{(.*?)\\}/);\n\n            const cleanKey = key.replace(/^\\}/,'')\n\n            return [\n                {...p[0], [value]: [cleanKey, ...(p[0][value] || [])]},\n                {...p[1], [cleanKey]: value}\n            ];\n        }, [{}, {}]\n    );\n\n\nZmienna cleanKey wprowadzona została, żeby poradzić sobie z klasami,\nwystępującymi za znakiem }}, co w plikach css jest możliwe. Utrata tego znaku } \nz wartości nie zmienia niczego, ponieważ wartości i tak są dla nas tylko\nidentyfikatorami, a nie fragmentami stylizacji, którą mieli byśmy gdziekolwiek\nimplementować.\n\nNa końcu utrwalamy wyniki w plikach JSON.\n\n    fs.writeFileSync(path.replace(/css$/, 'styleToSelector.json'), JSON.stringify(styleToSelector));\n    fs.writeFileSync(path.replace(/css$/, 'selectorToStyle.json'), JSON.stringify(selectorToStyle));\n\n\nProgram włączamy komendą\n\nnpx ts-node decompose_css_to_json.ts\n\n\nNie drukuje on wyników, ale tworzy trzy pliki w ukrytym katalogu .cache. Czas\nwykonywania tego programu to około\n\nBudowanie meta-selektorów na podstawie selektorów tymczasowych\nMeta-selektorem nazywam selektor, którym nazwy klas są zastąpione\nidentyfikującymi je zasadami stylowania. Tworzenie meta-selektorów jest\npotrzebne, żeby kod, który tworzymy był stabilny. Punktem wyjściowym do jego\nstworzenia jest selektor napisany w konsoli przeglądarki.\n\nProgram nazwiemy generate_meta_selectors.ts. W standardowym layoucie skryptu\nmamy zmienną input. W niej zapisujemy działające zapytanie strukturyzujące\nwyświetlaną stronę Facebookową. Wykonanie go w konsoli przeglądarki powinno\nzwrócić tablicę z obiektami odpowiadającymi uczestnikom grupy Facebookowej.\n\nimport md5 from \"md5\";\nimport fs from \"fs\";\n\nconst input = `[...document.querySelectorAll('div.rq0escxv.l9j0dhe7.du4w35lb.j83agx80.cbu4d94t.pfnyh3mw.d2edcug0.aahdfvyu.tvmbv18p div.ue3kfks5.pw54ja7n.uo3d90p7.l82x9zwi.a8c37x1j:not([aria-busy])')].map(e => ({\n    name: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg div.nc684nl6>a').innerText, \n    link: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg div.nc684nl6>a').href, \n    context: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(2)')?.innerText, \n    description: e.querySelector('.j83agx80.cbu4d94t.ew0dbk1b.irj2b8pg :nth-child(3)')?.innerText, \n    img: e.querySelector('image')?.getAttribute('xlink:href')\n}))`;\n\nconst CACHE_DIR = process.cwd() + `/.cache`;\nconst url = `https://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug`;\n\nconst main = async (): Promise<void> => {\n\t// there will be next part of presented program\n};\n\nmain().catch(e => {\n    console.error(e);\n})\n\n\nTeraz aby przetworzyć losowe klasy w selektorach na stabilne meta-selektory\npobieramy zawartość pliku z mapą selektorów\n\n    const name = md5(url);\n    const path = `${CACHE_DIR}/${name}.selectorToStyle.json`;\n    const selectorToStyle = JSON.parse(fs.readFileSync(path).toString())\n\n\nTworzymy tablicę klas w dwóch krokach - pobierając ciągi w cudzysłowach, a\nnastępnie wycinając z nich ośmioznakowe ciągi cyfr i liter poprzedzone kropką\n\n    const classes = [...new Set(input.match(/'.*?'/g).join('').match(/\\.\\w{8}/g))];\n\n\nNa podstawie tych klas oraz dzięki mapie pobranej do zmiennej selectorToStyle \nmożemy wytworzyć tablicę podstawień\n\n    const replaces: [string, string][] = classes.map(c => [c, `{${selectorToStyle[c]}}`]);\n\n\nWartość tej zmiennej wyniosła w naszym przykładzie\n\n[\n  [ '.rq0escxv', '{box-sizing:border-box}' ],\n  [ '.l9j0dhe7', '{position:relative}' ],\n  [ '.du4w35lb', '{z-index:0}' ],\n  [ '.j83agx80', '{display:flex}' ],\n  [ '.cbu4d94t', '{flex-direction:column}' ],\n  [ '.pfnyh3mw', '{flex-shrink:0}' ],\n  [ '.d2edcug0', '{max-width:100%}' ],\n  [ '.aahdfvyu', '{margin-top:4px}' ],\n  [ '.tvmbv18p', '{margin-bottom:4px}' ],\n  [ '.ue3kfks5', '{border-top-left-radius:8px}' ],\n  [ '.pw54ja7n', '{border-top-right-radius:8px}' ],\n  [ '.uo3d90p7', '{border-bottom-right-radius:8px}' ],\n  [ '.l82x9zwi', '{border-bottom-left-radius:8px}' ],\n  [ '.a8c37x1j', '{display:block}' ],\n  [ '.ew0dbk1b', '{margin-bottom:-5px}' ],\n  [ '.irj2b8pg', '{margin-top:-5px}' ],\n  [ '.nc684nl6', '{display:inline}' ]\n]\n\n\nNa końcu dokonujemy podmienienia klas na identyfikatory przypisane stylom\n\n    let out = input;\n\n    replaces.forEach(r => {\n        out = out.replace(new RegExp(r[0], 'g'), r[1])\n    })\n    console.log(out);\n\n\nWidzimy naprawdę proste podstawienie dzięki temu, że każda klasa zawsze ma\nselektor w postaci stylu. To założenie potencjalnie mogło by nie być prawdą, ale\nFacebook stosuje skrypty minifikujące, które oczyszczają HTML z klas\npozbawionych znaczenia.\n\nFinalnie wynikiem działania tego programu włączonego komendą\n\n npx ts-node generate_meta_selectors.ts\n\n\njest tekst meta-selektora\n\n[...document.querySelectorAll('div{box-sizing:border-box}{position:relative}{z-index:0}{display:flex}{flex-direction:column}{flex-shrink:0}{max-width:100%}{margin-top:4px}{margin-bottom:4px} div{border-top-left-radius:8px}{border-top-right-radius:8px}{border-bottom-right-radius:8px}{border-bottom-left-radius:8px}{display:block}:not([aria-busy])')].map(e => ({\n    name: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}>a').innerText, \n    link: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}>a').href, \n    context: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(2)')?.innerText, \n    description: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(3)')?.innerText, \n    img: e.querySelector('image')?.getAttribute('xlink:href')\n}))\n\n\nTak jak zapowiadałem, zamiast klas są tu ich znaczenia. Nazwy klas się\nzmieniają, ale znaczenia zostają. Teraz nadszedł czas, żeby zapisać ten\nmeta-selektor jako stały element naszego programu np wbudowując go do wtyczki,\nktóra wykona go w stosownym momencie na stronie Facebooka. Na przykład kiedy\nstrona zostanie zescrolowana do końca i interwał\n\ni = setInterval(() => window.scrollTo(0,document.body.scrollHeight), 1000);\n\n\nprzestanie podnosić wartość document.body.scrollHeight,\n\nNie możemy jednak tego kodu wykonać bezpośrednio, bo zawiera on selektory nie\nbędące poprawnymi selektorami. Aby móc go wykonać musimy tą operację odwrócić.\nDo tego potrzebujemy oddzielnego skryptu.\n\nOdzyskanie prawdziwych i aktualnych selektorów dzięki meta-selektorom\nTworzymy plik generate_temp_selector.ts. Przyzwyczajeni do tego jak tego typu\npliki wyglądają łatwo odnajdziemy się w części otaczającej ciało funkcji main.\n\nimport md5 from \"md5\";\nimport fs from \"fs\";\n\nconst metaSelector = `[...document.querySelectorAll('div{box-sizing:border-box}{position:relative}{z-index:0}{display:flex}{flex-direction:column}{flex-shrink:0}{max-width:100%}{margin-top:4px}{margin-bottom:4px} div{border-top-left-radius:8px}{border-top-right-radius:8px}{border-bottom-right-radius:8px}{border-bottom-left-radius:8px}{display:block}:not([aria-busy])')].map(e => ({\n    name: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}>a').innerText, \n    link: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} div{display:inline}>a').href,\n    context: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(2)')?.innerText, \n    description: e.querySelector('{display:flex}{flex-direction:column}{margin-bottom:-5px}{margin-top:-5px} :nth-child(3)')?.innerText, \n    img: e.querySelector('image')?.getAttribute('xlink:href')\n}))`;\n\n\nconst CACHE_DIR = process.cwd() + `/.cache`;\nconst url = `https://static.xx.fbcdn.net/rsrc.php/v3/yQ/l/0,cross/ArGQFhpa-mYIQaebMcDHPHgi1H0oF0i_rK0T6c_KgOBbWpC6CZY50c0PwrzoCWCCooTDwUJHUy3C2.css?_nc_x=JKmcfy-J-Ug`;\n\nconst main = async (): Promise<void> => {\n\n};\n\nmain().catch(e => {\n    console.error(e);\n})\n\n\nDane wejściowe do programu to ponownie url oraz ciąg znakowy, tym razem nazwany \nmetaSelector. Celem funkcji main jest wydrukowanie na ekranie selektora używając\ndrugiej mapy - tej przeprowadzającej style na selektory.\n\n    const name = md5(url);\n    const path = `${CACHE_DIR}/${name}.styleToSelector.json`;\n    const styleToSelector = JSON.parse(fs.readFileSync(path).toString())\n\n    const selectors = [...new Set(metaSelector.match(/'.*?'/g).join('').match(/\\{.*?\\}/g))];\n\n\nZaczynamy tak jak ostatnio, ale tym razem szukamy selektorów, więc stosujemy\nodrobinę inny wyrażenia regularne i drugą z wygenerowanych map. Również tu\nchcemy stworzy listę zastąpień, ale różni się ona typem od tej stosowanej w\npoprzednim programie.\n\n    const replaces: [string, string[]][] = selectors.map(c => {\n        const key = c.replace(/^\\{/, '').replace(/\\}$/, '');\n        return [\n            c,\n            styleToSelector[key].filter((c: string) => /^\\.\\w{8}$/.test(c))\n        ]\n    });\n\n\nPrzykładowa wartość tej zmiennej to:\n\n[\n  [ '{box-sizing:border-box}', [ '.ibamfamh', '.rq0escxv' ] ],\n  [ '{position:relative}', [ '.jfde6mfb', '.l9j0dhe7' ] ],\n  [ '{z-index:0}', [ '.du4w35lb' ] ],\n  [ '{display:flex}', [ '.mmelxcy8', '.j83agx80' ] ],\n  [ '{flex-direction:column}', [ '.pawmy52i', '.cbu4d94t' ] ],\n  [ '{flex-shrink:0}', [ '.n0kn69sm', '.pfnyh3mw' ] ],\n  [ '{max-width:100%}', [ '.d2edcug0' ] ],\n  [ '{margin-top:4px}', [ '.aahdfvyu' ] ],\n  [ '{margin-bottom:4px}', [ '.tvmbv18p' ] ],\n  [ '{border-top-left-radius:8px}', [ '.ue3kfks5' ] ],\n  [ '{border-top-right-radius:8px}', [ '.pw54ja7n' ] ],\n  [ '{border-bottom-right-radius:8px}', [ '.uo3d90p7' ] ],\n  [ '{border-bottom-left-radius:8px}', [ '.l82x9zwi' ] ],\n  [ '{display:block}', [ '.a7hnopfp', '.a8c37x1j' ] ],\n  [ '{margin-bottom:-5px}', [ '.ew0dbk1b' ] ],\n  [ '{margin-top:-5px}', [ '.irj2b8pg' ] ],\n  [ '{display:inline}', [ '.nc684nl6' ] ]\n]\n\n\nNiestety ze względu na wielowartościowość tego przekształcenia nie możemy użyć\npodmiany tak prostej jak ostatnio. Tym razem decydujemy się na kompromisy i\npiszemy kod, który usunie wszystkie wielowartościowe klasy. Możemy się z tym\npogodzić ponieważ jak wskazaliśmy na początku, stanowią one nieznaczny procent\nwszystkich selektorów, jakie są stosowane.\n\nlet out = metaSelector;\n\nreplaces.forEach(r => {\n    out = out.replace(new RegExp(r[0], 'g'), r[1].length === 1 ? r[1][0] : '')\n})\nconsole.log(out);\n\n\nPo wykonaniu programu komendą\n\nnpx ts-node generate_temp_selector.ts\n\n\ndostaniemy gotowy do użycia kod strukturyzujący listę osób z grupy Facebooka:\n\n[...document.querySelectorAll('div.du4w35lb.d2edcug0.aahdfvyu.tvmbv18p div.ue3kfks5.pw54ja7n.uo3d90p7.l82x9zwi:not([aria-busy])')].map(e => ({\n    name: e.querySelector('.ew0dbk1b.irj2b8pg div.nc684nl6>a').innerText, \n    link: e.querySelector('.ew0dbk1b.irj2b8pg div.nc684nl6>a').href,\n    context: e.querySelector('.ew0dbk1b.irj2b8pg :nth-child(2)')?.innerText, \n    description: e.querySelector('.ew0dbk1b.irj2b8pg :nth-child(3)')?.innerText, \n    img: e.querySelector('image')?.getAttribute('xlink:href')\n}))\n\n\nAnaliza wyników\nDługość nowego selektora to 513 znaków w porównaniu z 639 dla selektora\nwejściowego, ale działa on świetnie. Dla grupy, którą analizowaliśmy mającej\n4576 osób procedura automatycznego scrollingu w dół zajęła 90 minut.\n\n\n\nJSON z danymi ważył 2.1 MB. Po konwersji do formatu CSV komendą:\n\njq -r '.[] | ([.name,.context,.description,.link,.img] | @csv)' .cache/crypto.json > .cache/crypto.csv\n\n\npowstały .csv miał 1.9 MB. Blisko połowa tych danych to adresy obrazków\nprofilowych, które są dość długie, ale raczej działają od kilku godzin do kilku\ndni po pobraniu, nie dłużej, dlatego zalecam dodanie ich do kolejki pobierania\nprzez osobny proces, jeśli chcemy je gromadzić. Łatwo możemy sprawdzić to dzięki\nutworzeniu pliku, który by ich nie posiadał:\n\njq '.[] | {name:.name,context:.context,description:.description,link:.link}' .cache/crypto.json > .cache/crypto-no-img.json\n\n\nI sprawdzeniu rozmiaru tak powstałego pliku\n\ndu -ha .cache\n332K    .cache/f3579000ff0b02d47dec7a17d043e454.selectorToStyle.json\n360K    .cache/f3579000ff0b02d47dec7a17d043e454.styleToSelector.json\n2.1M    .cache/crypto.json\n1016K   .cache/crypto-no-img.json\n336K    .cache/f3579000ff0b02d47dec7a17d043e454.css\n1.9M    .cache/crypto.csv\n6.0M    .cache\n\n\nTe awatary same ważą 2.19 KiB i mają rozmiar 60x60 px. Łatwo można sprawdzić\njaki był rozmiaru udział różnych typów danych w scrapingu:\n\n\n\nNależy zaznaczyć, że ze względu na realny rozmiar drzewa dom, w Facebooku, można\nszacować, że przeglądarka musiała wybudować kilkaset MB, żebyśmy mogli pobrać te\ndane. Przez cały czas scrolowania (90 minut) przeglądarka zużywała 100% rdzenia\no taktowaniu 2GHz.\n\nRekomendacja dla programistów Facebooka\nPrzepiszcie serwis na flutter, to scraping stanie się o całe rzędy wielkości\ndroższy i praktycznie nieopłacalny w wielu przypadkach. Innym prostszym\nrozwiązaniem było by podniesienie ilości różnych klas mających ten sam styl i\nmiksowanie ich za pomocą randomizerów, które powodowały by losowe wypadanie\ndanych z selektorów opartych o te klasy. Owszem, pliki CSS były by cięższe, ale\nbyło by to mocne uderzenie w prezentowaną przeze mnie metodę.\n\nRekomendacja dla tych, którzy scrapują\nWyścig zbrojeń w zakresie scrapingu wchodzi w coraz ciekawszą fazę.\nAutomatyzacja jest wciąż częściowo możliwa, ale jej rozszerzanie wymaga coraz\nwyższych nakładów oraz badań nad odwzorowywaniem zachowań naturalnych dla\nużytkowników, tak aby pisane przez nas skrypty pozostawały nie wykryte mimo\ncoraz bardziej wyrafinowanych metod ich detekcji.\n\nMoim zdaniem na kontach przeznaczonych do scrapingu warto prowadzić normalne\naktywności wykorzystując realne osoby przynajmniej w takim stopniu, aby\ngenerując taką naturalną aktywność przeplataną pracą bota można było obniżyć\nryzyko klasyfikacji jako bot i uniknąć captha oraz banowania konta.\n\nNależy pamiętać, że takie zbieranie danych jest niezgodne z regulaminem\nFacebooka, który mówi, że potrzebujemy na to pisemnej zgody.\n\nhttps://www.facebook.com/apps/site_scraping_tos_terms.php\n\nA ponieważ to są dane osobowe przetwarzane bez zgody właścicieli to w pewnych\nczęściach świata jest to niezgodne z regulacjami takimi jak europejskie GDPR\nznane w Polsce jako RODO.\n\nŹródła\nhttp://www.proto.pl/aktualnosci/liczba-uzytkownikow-facebooka-zwieksza-sie-mimo-skandali\n\nhttps://www.wired.com/story/facebook-removes-accounts-ai-generated-photos/\n\nhttps://stackoverflow.com/questions/56238356/understanding-esmoduleinterop-in-tsconfig-file\n\nhttps://www.typescriptlang.org/docs/handbook/module-resolution.html\n\nhttps://about.fb.com/news/2020/10/taking-legal-action-against-data-scraping/\n\nhttps://www.octoparse.com/blog/5-things-you-need-to-know-before-scraping-data-from-facebook",
            "feature_image": "__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-20-21-44-14.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T19:36:25.000Z",
            "updated_at": "2021-04-24T11:23:36.000Z",
            "published_at": "2021-04-23T19:49:00.000Z",
            "custom_excerpt": "Artykuł ma na celu zapoznanie czytelnika z metodą na scaping portalu Facebooka po wprowadzeniu aktualizacji layoutu.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f31a42fb35425592d0b2e",
            "uuid": "3d1e999f-3ab2-4bf6-810b-96101cb69a0b",
            "title": "Logowanie danych w MySql, Ajax i Behat",
            "slug": "logowanie-danych-w-mysql-ajax-i-behat",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Opis projektu\\n\\nJest to projekt, który pisałem ucząc się używania bazy danych w PHP. Kilka dni temu odświeżyłem go, dopisałem testy i postanowiłem udostępnić.\\n\\nZ artykułu dowiesz się jak **centralizować konfigurację** projektu, **logować zdarzenia na stronie do bazy** danych, **testować stronę** wykorzystując selenium.\\n\\nSkład kodu źródłowego to:\\n\\n```\\nPHP 43.2% Perl 19.8% HTML 19.6% Cucumber 7.4% JavaScript 6.5% CSS 3.5%\\n```\\n\\nPo napisaniu projekt będzie wyglądał tak:\"}],[\"html\",{\"html\":\"<video src=\\\"https://www.dropbox.com/s/tkixyejx8d20gvp/1.mp4?dl=1\\\" controls></video>\"}],[\"markdown\",{\"markdown\":\"## Instalacja\\n\\n**Uwaga! Zanim włączysz install.pl upewnij się, że nie masz bazy o nazwie calc, zanim włączysz install.sh upewnij się, że nie masz chrome w sources.list. Skrypy instalacyjne w perlu i bashu nie są długie, zapoznaj się z nimi przed uruchomieniem.**\\n\\nInstalację projektu zalecam przeprowadzić na maszynie wirtualnej, np.: `Lubuntu`.\\n\\nAby zainstalować projekt należy pobrać repozytorium (w lokacji, w której nie ma katalogu `calc`)\\n\\n```\\ngit clone https://github.com/gustawdaniel/calc\\n```\\n\\nPrzejść do katalogu `calc` i zainstalować potrzebne oprogramowanie. Przed instalacją przejrzyj plik `install.sh` i wykomentuj dodawanie repozytorium chrome jeśli masz je już zainstalowane.\\n\\n```\\ncd calc && bash install.sh\\n```\\n\\nSprawdź swoje parametry połączenia z bazą danych `mysql`. Jeśli podczas instalacji klikałeś tylko `enter` i nie miałeś wcześniej zainstalowanego pakietu `mysql-server` możesz zostawić domyślne. W przeciwnym wypadku wpisz poprawne wartości do pliku `config/parameters.yml` i usuń go z repozytorium.\\n\\n```\\ngit rm --cached config/parameters.yml\\n```\\n\\nAby zainstalować bazę danych i włączyć serwer php wpisz komendę\\n\\n```\\nperl install.pl\\n```\\n\\nW nowym terminalu (`ctrl+n`) włącz serwer selenium\\n\\n```\\nselenium-standalone start\\n```\\n\\nW kolejnym możesz włączyć testy:\\n\\n```\\nvendor/bin/behat\\n```\\n\\nMożesz również normalnie korzystać ze strony, która wystawiona jest na porcie 9000\\n\\n```\\nfirefox localhost:9000\\n```\\n\\nJeśli masz domyślne parametry łączenia z bazą, to, żeby zobaczyć zawartość bazy danych wpisz\\n\\n```\\nsudo mysql -u root\\nuse calc;\\nselect * from log;\\n\\n```\\n\\n## Struktura bazy\\n\\nZwykle zaczynam projekt od bazy danych. Jej instalację umieściłem w pliku `sql/main.sql`.\\n\\n> sql/main.sql\\n\\n```sql\\nDROP   DATABASE IF     EXISTS database_name;\\nCREATE DATABASE IF NOT EXISTS database_name\\n    DEFAULT CHARACTER SET = 'utf8'\\n    DEFAULT COLLATE 'utf8_unicode_ci';\\n\\nUSE database_name;\\n\\nCREATE TABLE log\\n(\\n    id      \\t  BIGINT UNSIGNED    \\t\\tNOT NULL AUTO_INCREMENT PRIMARY KEY,\\n    time   \\t\\t  DATETIME           \\t\\tNOT NULL,\\n    a      \\t\\t  DOUBLE\\t\\t\\t\\t\\t,\\n    b      \\t\\t  DOUBLE\\t\\t\\t\\t\\t,\\n    button  \\t  ENUM('sum', 'diff')       ,\\n    useragent\\t  VARCHAR(255)\\n);\\n\\n```\\n\\nIstotne jest, że nazwa bazy, jaką stworzymy to nie `database_name` lecz nazwa podana później w pliku konfiguracyjnym. Zastąpi ona tą nazwę dzięki zastosowaniu języka perl, który \\\"skompiluje\\\" ten skrypt do wykonywalnej postaci. O tym będzie kolejny rozdział.\\n\\n## Konfiguracja\\n\\nBardzo dobrym nawykiem, który wyniosłem z pracy z Symfony jest trzymanie parametrów dotyczących połączenia z bazą danych poza kodem projektu. Jeszcze lepszym jest rozdzielenie parametrów prywatnych (które mogą zawierać loginy i hasła ze środowiska produkcyjnego - nie trzymanych w repozytorium), od domyślnych.\\n\\nW tym przykładzie stosujemy jedynie domyślne parametry. Umieścimy je w pliku `parameters.yml` w katalogu `config`.\\n\\n> config/parameters.yml\\n\\n```yml\\nconfig:\\n    host: 'localhost'\\n    user: 'root'\\n    pass: ''\\n    base: 'calc'\\n    port: '3306'\\n\\n```\\n\\nBędziemy się do nich odnosić w instalatorze napisanym w perlu oraz w klasie odpowiadającej za zapis do bazy danych w PHP.\\n\\n### Konfiguracja w Perlu\\n\\nNapiszemy dwa skrypty - do tworzenia, oraz do resetowania bazy. Do odczytywania pliku `parameters.yml` wykorzystamy bibliotekę `YAML::Tiny`. Poniższy skrypt kolejno:\\n\\nOdczytuje plik z parametrami do zmiennej `$yaml`.\\nZapisuje wszystkie parametry do odpowiednich zmiennych.\\n\\n> install.pl\\n\\n```perl\\n#!/bin/perl\\n\\nuse YAML::Tiny;\\n\\nuse strict;\\nuse warnings;\\n\\n#\\n#       Config:\\n#\\n\\n    my $yaml = YAML::Tiny->read( 'config/parameters.yml' );\\n    my $baseName  = $yaml->[0]->{config}->{base};\\n    my $user  = $yaml->[0]->{config}->{user};\\n    my $pass  = $yaml->[0]->{config}->{pass};\\n    my $host  = $yaml->[0]->{config}->{host};\\n    my $port  = $yaml->[0]->{config}->{port};\\n\\n```\\n\\nTworzy zmienne z ustawieniami katalogów. (Instrukcje tworzące bazę znajdują się w pliku `main.sql`.)\\n\\n```perl\\n#\\n#       Catalogs structure:\\n#\\n\\n    my $build = \\\"build/\\\";\\n    my $sql = \\\"sql/\\\";\\n    my $mainSQL = \\\"main.sql\\\";\\n\\n\\n```\\n\\nOtwiera plik z kodem `sql` i zapisuje treść do zmiennej `$content`.\\n\\n```perl\\n#\\n#       Script:\\n#\\n\\n\\n#-----------------------------------------    Database   -------------#\\n\\n#       Prepare catalog\\n    system('mkdir -p '.$build);\\n\\n#       Read file with mysql\\n    my $content;\\n    open(my $fh, '<', $sql.$mainSQL) or die \\\"cannot open file\\\";\\n    {\\n        local $/;\\n        $content = <$fh>;\\n    }\\n    close($fh);\\n\\n```\\n\\nZamienia każde wystąpienie ciągu `database_name` na nazwę z pliku `parameters.yml` i zapisuje.\\n\\n```perl\\n#       Replace database name by name from config\\n    $content =~ s/database_name/$baseName/g;\\n\\n#       Save file with correct db name\\n    open($fh, '>', $build.$mainSQL) or die \\\"Could not open file' $!\\\";\\n    {\\n        print $fh $content;\\n    }\\n    close $fh;\\n\\n```\\n\\nNadaje domyślnemu użytkownikowi prawo otwierania bazy jako root, tworzy bazę i włącza serwer `php`.\\n\\n```perl\\n#       Execute file\\n    my $passSting = ($pass eq \\\"\\\") ? \\\"\\\" : \\\" -p \\\".$pass;\\n    system('sudo mysql -h '.$host.' -P '.$port.' -u '.$user.$passSting.' < '.$build.$mainSQL);\\n\\n#       Start server\\n    system('cd web && php -S localhost:9000');\\n\\n\\n```\\n\\n### Konfiguracja w PHP\\n\\nDo obsługi pliku konfiguracyjnego w `php` zastosujemy bibliotekę `\\\"mustangostang/spyc\\\": \\\"^0.6.1\\\"`. Będzie ona wykorzystana jedynie przy łączeniu się z bazą - w pliku `php/DataBase.php`.\\n\\n> php/DataBase.php\\n\\n```php\\n<?php\\n\\nrequire_once __DIR__.\\\"/../vendor/mustangostang/spyc/Spyc.php\\\";\\n\\nclass DataBase\\n{\\n\\n\\t...\\n\\n\\t\\t// config from yml\\n\\t\\t$config = Spyc::YAMLLoad(__DIR__.\\\"/../config/parameters.yml\\\")[\\\"config\\\"];\\n\\n\\t\\t// connecting\\n\\t\\t$mysqli = @new mysqli($config[\\\"host\\\"], $config[\\\"user\\\"], $config[\\\"pass\\\"], $config[\\\"base\\\"], $config[\\\"port\\\"]);\\n\\n\\t...\\n\\n```\\n\\nW do zmiennej `$config` zapisywana jest tablica z parametrami do połączenia z bazą. Zasada działania jest taka sama, jak w poprzednim skrypcie.\\n\\n## Logowanie danych w bazie\\n\\nW paragrafie dotyczącym struktury bazy pokazaliśmy jakie rekordy zawiera jedyna tabela jaką mamy - `log`. Są to `id`, `time`, `a`, `b`, `button` i `useragent`. `a` i `b` odpowiadają liczbom wpisanym przez użytkownika. `button` jest akcją którą wybrał `sum` dla sumy lub `diff` dla różnicy. `useragent` to dane dotyczące przeglądarki.\\n\\nOdwzorujemy teraz rekord bazy danych w `php` jako obiekt. W tym celu tworzymy klasę `Log` w pliku `php/Log.php`\\n\\n> php/Log.php\\n\\n```php\\n<?php\\n\\nclass Log\\n{\\n    private $a;\\n    private $b;\\n    private $action;\\n    private $agent;\\n\\n    /**\\n     * @return mixed\\n     */\\n    public function getC()\\n    {\\n        if($this->action==\\\"sum\\\"){\\n            return $this->a + $this->b;\\n        } elseif ($this->action==\\\"diff\\\") {\\n            return $this->a - $this->b;\\n        } else {\\n            return null;\\n        }\\n    }\\n\\n   ...\\n}\\n\\n```\\n\\nZawiera ona wszystkie pola z tabeli poza identyfikatorem i czasem, które nadawane są podczas zapisu do bazy. Przez trzy kropki oznaczyłem wszystkie gettery i settery dla własności klasy. W większości IDE można je wygenerować automatycznie, np.: w `PhpStorm` wybierając `code->Generate...`. Metoda `getC` pozwala wyliczyć wartość sumy lub różnicy po stronie serwera, co wykorzystane jest później w interfejsie `API`.\\n\\nTeraz możemy przedstawić w całości wspomnianą wcześniej klasę `DataBase`, która służyła do zapisu danych otrzymanych ze strony do bazy.\\n\\n> php/DataBase.php\\n\\n```php\\n<?php\\n\\nrequire_once __DIR__.\\\"/Log.php\\\";\\nrequire_once __DIR__.\\\"/../vendor/mustangostang/spyc/Spyc.php\\\";\\n\\nclass DataBase\\n{\\n\\tfunction save(Log $log){\\n\\n\\t\\t$a = $log->getA();\\n\\t\\t$b = $log->getB();\\n\\t\\t$s = $log->getAction();\\n\\t\\t$u = $log->getAgent();\\n\\n\\t\\t// config from yml\\n\\t\\t$config = Spyc::YAMLLoad(__DIR__.\\\"/../config/parameters.yml\\\")[\\\"config\\\"];\\n\\n\\t\\t// connecting\\n\\t\\t$mysqli = @new mysqli($config[\\\"host\\\"], $config[\\\"user\\\"], $config[\\\"pass\\\"], $config[\\\"base\\\"], $config[\\\"port\\\"]);\\n\\n\\t\\t// test of connecting\\n\\t\\tif ($mysqli -> connect_errno)\\n\\t\\t{\\n\\t\\t\\t$code = $mysqli -> connect_errno;\\n\\t\\t\\t$mess = $mysqli -> connect_error;\\n\\t\\t\\tdie(\\\"Failed to connect to MySQL: ($code) $mess\\\\n\\\");\\n\\t\\t}\\n\\n\\t\\t// definition of query\\n\\t\\t$query  = 'INSERT INTO log VALUES(NULL,NOW(),?,?,?,?);';\\n\\n\\t\\t// preparing\\n\\t\\t$stmt = @$mysqli -> prepare($query);\\n\\n\\t\\t// test of preparing\\n\\t\\tif(!$stmt)\\n\\t\\t{\\n\\t\\t\\t$code = $mysqli -> errno;\\n\\t\\t\\t$mess = $mysqli -> error;\\n\\t\\t\\t$mysqli -> close();\\n\\t\\t\\tdie(\\\"Failed to prepare statement: ($code) $mess\\\\n\\\");\\n\\t\\t}\\n\\n\\t\\t// binding\\n\\t\\t$bind = @$stmt -> bind_param(\\\"ddss\\\", $a, $b, $s, $u);\\n\\n\\t\\t// test of binding\\n\\t\\tif(!$bind)\\n\\t\\t{\\n\\t\\t\\t$stmt   -> close();\\n\\t\\t\\t$mysqli -> close();\\n\\t\\t\\tdie(\\\"Failed to bind param.\\\\n\\\");\\n\\t\\t}\\n\\n\\t\\t// executing query\\n\\t\\t$exec = @$stmt -> execute();\\n\\n\\t\\t// checking fails\\n\\t\\tif(!$exec)\\n\\t\\t{\\n\\t\\t\\t$stmt   -> close();\\n\\t\\t\\t$mysqli -> close();\\n\\t\\t\\tdie(\\\"Failed to execute prepare statement.\\\\n\\\");\\n\\t\\t}\\n\\n\\t\\t// clearing and disconnecting\\n\\t\\t$stmt   -> close();\\n\\t\\t$mysqli -> close();\\n\\t}\\n}\\n\\n```\\n\\nKlasa ta nie ma własności, ma za to jedną metodę - `save`. Ta metoda pobiera obiekt `Log` i wykonuje logowanie do bazy danych wszystkich własności tego obiektu, przy czym dodaje jeszcze czas. Najciekawsza część tej klasy - pobieranie konfiguracji była omówiona wcześniej. Reszta jest po prostu w zwykłym zapisem do bazy.\\n\\nTo były klasy, teraz czas na skrypt wejściowy back-endu naszej aplikacji. Znajduje się w pliku `web/api.php` i odpowiada za poprawne przechwycenie żądania, pobranie parametrów, przekazanie ich bazie i oddanie odpowiedzi zawierającej wynik działania.\\n\\n```php\\n<?php\\n\\n// error display\\n//ini_set('display_errors', 1);\\n//ini_set('display_startup_errors', 1);\\n//error_reporting(E_ALL);\\n\\nrequire_once __DIR__.\\\"/../php/Log.php\\\";\\nrequire_once __DIR__.\\\"/../php/DataBase.php\\\";\\n\\n// routing\\nif($_SERVER['REQUEST_METHOD']==\\\"POST\\\"\\n    && parse_url($_SERVER[\\\"REQUEST_URI\\\"])[\\\"path\\\"]==\\\"/api.php/action\\\"){\\n\\n    // get data from request\\n    $log = new Log();\\n    $log->setA($_POST[\\\"a\\\"]);\\n    $log->setB($_POST[\\\"b\\\"]);\\n    $log->setAction($_POST[\\\"action\\\"]);\\n    $log->setAgent($_SERVER['HTTP_USER_AGENT']);\\n\\n    // connect to db and save data\\n    $db = new DataBase();\\n    $db->save($log);\\n\\n    // send response\\n    header('Content-type: application/json');\\n    echo json_encode([\\n        \\\"a\\\"=>$log->getA(),\\n        \\\"b\\\"=>$log->getB(),\\n        \\\"c\\\"=>$log->getC(),\\n        \\\"action\\\"=>$log->getAction()\\n    ]);\\n}\\n\\n```\\n\\n### Testowanie Api przez httpie\\n\\nMożemy przetestować nasze `api` wykorzystując `httpie`. Komenda\\n\\n```\\nhttp -fv 127.0.0.1:9000/api.php/action a=1 b=2 action=\\\"sum\\\"\\n\\n```\\n\\npowinna wyprodukować następujący output:\\n\\n```http\\nPOST /api.php/action HTTP/1.1\\nAccept: */*\\nAccept-Encoding: gzip, deflate\\nConnection: keep-alive\\nContent-Length: 18\\nContent-Type: application/x-www-form-urlencoded; charset=utf-8\\nHost: 127.0.0.1:9000\\nUser-Agent: HTTPie/0.9.2\\n\\na=1&b=2&action=sum\\n\\nHTTP/1.1 200 OK\\nConnection: close\\nContent-type: application/json\\nHost: 127.0.0.1:9000\\nX-Powered-By: PHP/7.0.8-0ubuntu0.16.04.3\\n\\n{\\n    \\\"a\\\": \\\"1\\\",\\n    \\\"action\\\": \\\"sum\\\",\\n    \\\"b\\\": \\\"2\\\",\\n    \\\"c\\\": 3\\n}\\n\\n```\\n\\n## AJAX\\n\\nKiedy mamy gotową bazę oraz skrypty do jej obsługiwania, nic nie stoi na przeszkodzie dokończenia projektu przez napisanie frontu. Zakładamy, że instalacja przebiegła pomyślnie i `bower` zainstalował potrzebne paczki - to znaczy `\\\"bootstrap\\\": \\\"v4.0.0-alpha.5\\\"` w katalogu `web`. Ponieważ `jQuery` jest zależnością dla `Bootstrapa` możemy z niej skorzystać przy tworzeniu skryptów.\\n\\nNasz front składa się z trzech plików: `web/index.html`, `web/css/style.css` i `web/js/site.js`. Oto one:\\n\\n> web/index.html\\n\\n```html\\n<!DOCTYPE html>\\n<html lang=\\\"en\\\">\\n  <head>\\n    <meta charset=\\\"utf-8\\\">\\n    <meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1\\\">\\n    <title>Php calculator logging requests into database.</title>\\n\\n    <link rel=\\\"stylesheet\\\" href=\\\"bower_components/bootstrap/dist/css/bootstrap.min.css\\\">\\n    <link href=\\\"https://fonts.googleapis.com/css?family=Lato:300\\\" rel=\\\"stylesheet\\\">\\n    <link rel=\\\"stylesheet\\\" href=\\\"css/style.css\\\">\\n  </head>\\n  <body>\\n\\n    <section>\\n      <div class=\\\"container\\\">\\n        <div class=\\\"row\\\">\\n          <div class=\\\"offset-md-3 col-md-6\\\">\\n            <div class=\\\"card text-xs-center\\\">\\n              <div class=\\\"card-header\\\">\\n                Set two numbers and chose calculation\\n              </div>\\n              <div class=\\\"card-block\\\">\\n                <div class=\\\"form-group\\\">\\n                  <input id=\\\"a\\\" type=\\\"number\\\" step=\\\"any\\\" class=\\\"form-control\\\">\\n                </div>\\n                <div class=\\\"form-group\\\">\\n                  <input id=\\\"b\\\" type=\\\"number\\\" step=\\\"any\\\" class=\\\"form-control\\\">\\n                </div>\\n\\n                <div class=\\\"form-group row submit-area\\\">\\n                  <div class=\\\"col-xs-6\\\">\\n                    <input class=\\\"btn btn-lg btn-block hidden-xs-down btn-primary\\\" type=\\\"submit\\\" value='Sum' name=\\\"sum\\\">\\n                    <input class=\\\"btn btn-lg btn-block hidden-sm-up btn-primary\\\" type=\\\"submit\\\" value='+' name=\\\"sum\\\">\\n                  </div>\\n                  <div class=\\\"col-xs-6\\\">\\n                    <input class=\\\"btn btn-lg btn-block hidden-xs-down btn-danger\\\" type=\\\"submit\\\" value='Difference' name=\\\"diff\\\">\\n                    <input class=\\\"btn btn-lg btn-block hidden-sm-up btn-danger\\\" type=\\\"submit\\\" value='-' name=\\\"diff\\\">\\n                  </div>\\n                </div>\\n                <div class=\\\"form-group\\\">\\n                  <input id=\\\"c\\\" type=\\\"text\\\" readonly step=\\\"any\\\" class=\\\"form-control\\\">\\n                </div>\\n\\n              </div>\\n              </div>\\n            </div>\\n          </div>\\n        </div>\\n      </div>\\n    </section>\\n\\n\\n    <nav class=\\\"navbar navbar-fixed-bottom navbar-light bg-faded\\\">\\n      <a class=\\\"navbar-brand\\\" href=\\\"README.html\\\">Documentation</a>\\n      <a class=\\\"navbar-brand float-xs-right\\\" href=\\\"http://gustawdaniel.pl\\\">Daniel Gustaw</a>\\n    </nav>\\n\\n    <script src=\\\"bower_components/jquery/dist/jquery.min.js\\\"></script>\\n    <script src=\\\"js/site.js\\\"></script>\\n  </body>\\n</html>\\n\\n```\\n\\nStandardowy plik html. To co jest w nim ciekawego, to wykorzystanie klasy `card` z `bootstrap 4` oraz zmiana napisów na przyciskach z pełnych nazw na znaki `+` i `-` przy małych szerokościach ekranu.\\n\\nJeszcze prostsze są style naszej strony.\\n\\n> web/css/style.css\\n\\n```css\\nbody {\\n    font-family: 'Lato', 'SansSerif', serif;\\n}\\n\\nsection {\\n    margin-top: 20vh;\\n}\\n\\n```\\n\\nJest to zasługa Bootstrapa który naprawdę dużo potrafi odwzorować tak, jak bym oczekiwał. Jedyne czego potrzebujemy to margines pionowy i czcionka.\\n\\nNajciekawsza część to JavaScript:\\n\\n> web/js/site.js\\n\\n```js\\n(function () {\\n\\n    var submitArea = document.getElementsByClassName(\\\"submit-area\\\")[0];\\n    var card = document.getElementsByClassName(\\\"card\\\")[0];\\n    var a = document.getElementById(\\\"a\\\");\\n    var b = document.getElementById(\\\"b\\\");\\n    var c = document.getElementById(\\\"c\\\");\\n\\n    function round(value,dec=5) {\\n        return 1*(Math.round(value+\\\"e+\\\"+dec)+\\\"e-\\\"+dec);\\n    }\\n\\n    submitArea.addEventListener('click',function (e) {\\n        if(e.target.name=='sum') {\\n            c.value = round((a.value*1) + (b.value*1));\\n        } else if(e.target.name=='diff') {\\n            c.value = a.value - b.value;\\n        }\\n\\n        $.post(\\\"api.php/action\\\", {a: a.value, b: b.value, c: c.value, action: e.target.getAttribute('name')}, function (data) {\\n            console.log(data);\\n        })\\n    });\\n\\n})();\\n\\n```\\n\\nCały zawarty jest w funkcji anonimowej, co zapewnia enkapsulację - nie mieszamy naszych zmiennych z globalnymi. Struktura skryptu jest następująca. Najpierw definiujemy zmienne powiązane z elementami htmla, później umieszczamy funkcje pomocnicze - u nas `round`, na koniec definiujemy listener.\\n\\nFunkcja `round` pozwala na zaokrąglanie obliczeń w JavaScript. Domyślna funkcja round z obiektu `Math` zawsze zaokrągla do liczb całkowitych. Wartość domyślna liczby miejsc po przecinku definiowana przez znak `=` jest stosunkowo nowym rozwiązaniem w JavaScript. Wnętrze funkcji pełnymi garściami czerpie z dynamicznego typowania i notacji naukowej do przedstawiania liczb w tym języku.\\n\\nZauważ, że ponieważ przyciski do liczenia sumy i różnycy występują podwójnie (ze względu na responsywność aplikacji), dopiero wewnątrz listenera musimy określić który z nich został wybrany. Jeśli jest to suma, mnożymy nasze wartości przez 1, aby znak `+` oznaczał dodawanie, a nie konkatenację.\\n\\nNatychmiast po zidentyfikowaniu, który przycisk został wybrany, następuje aktualizacja wyniku. Dopiero wtedy wysyłane jest żadnie `POST` co dzięki `jQuery` jest wyjątkowo proste. Takie rozwiązanie ma zalety i wady. Zaletą jest szybkość, użytkownik nie musi czekać naodpowiedź z serwera. Wadą jest duplikacja logiki odpowiedzialnej za wykonywanie obliczeń. Nie trudno domyślić się, że z powodu innych zaokrągleń wyniki przekazywane w odpowiedzi `API` będą mogły różnić się od tych wyświetlanych na stronie.\\n\\n## Behat i Selenium\\n\\n**Behat** jest narzędziem do pisania behawioralnych testów automatycznych. Jest to najbardziej naturalny dla człowieka sposób testowania oparty o historie, które mogą się wydażyć podczas korzystania z aplikacji. **Selenium** to serwer pozwalający symulować przeglądarkę, wyposażony w programistyczne API. Łącząc te dwa narzędzia otrzymujemy możliwość pisania czegoś w rodzaju bota odwiedzającego naszą stronę i wykonującego określone akcje. To właśnie użycie tego narzędzia widziałeś w video na początku wpisu.\\n\\nDzięki poleceniu `vendor/bin/behat --init` behat generuje domyślny plik `features/bootstrap/FeatureContext.php`. Rozszerzymy tą klasę dodając do niej `MinkContext`. Jest to zbiór tłumaczeń między naturalnym językiem `Gherkin` a akcjami wykonywanymi przed drivery przeglądarki takie jak `selenium`.\\n\\nNapisałem o `Gerkinie`, że jest językiem naturalnym. W [oficjalnej dokumentacji](https://github.com/cucumber/cucumber/wiki/Gherkin) jest przedstawiany następująco:\\n\\n> Gherkin is the language that Cucumber understands. It is a Business Readable, Domain Specific Language that lets you describe software’s behaviour without detailing how that behaviour is implemented.\\n\\nPoza tym rozszerzeniem dodamy kilka funkcji, których brakuje w `MinkConext`\\n\\n> features/bootstrap/FeatureContext.php\\n\\n```php\\n<?php\\n\\nuse Behat\\\\Behat\\\\Context\\\\Context;\\nuse Behat\\\\Gherkin\\\\Node\\\\PyStringNode;\\nuse Behat\\\\Gherkin\\\\Node\\\\TableNode;\\nuse Behat\\\\MinkExtension\\\\Context\\\\MinkContext;\\n\\n/**\\n * Defines application features from the specific context.\\n */\\nclass FeatureContext extends MinkContext implements Context\\n{\\n    /**\\n     * Initializes context.\\n     *\\n     * Every scenario gets its own context instance.\\n     * You can also pass arbitrary arguments to the\\n     * context constructor through behat.yml.\\n     */\\n    public function __construct()\\n    {\\n    }\\n\\n    /**\\n     * @param String $field\\n     * @param String $value\\n     * @Given I set :field as :value\\n     */\\n    public function iSetAs($field, $value)\\n    {\\n        $javascript = 'document.getElementById(\\\"'.$field.'\\\").value='.$value;\\n        $this->getSession()->executeScript($javascript);\\n    }\\n\\n    /**\\n     * @Then Result should be :value\\n     */\\n    public function resultShouldBe($value)\\n    {\\n        $javascript = 'document.getElementById(\\\"c\\\").value';\\n        $realResult = $this->getSession()->evaluateScript($javascript);\\n\\n        if ( $value !== $realResult) {\\n            throw new Exception(\\n                \\\"Actual result is:\\\\n\\\" . $realResult\\n            );\\n        }\\n    }\\n\\n    /**\\n     * @param String $number\\n     * @When I wait :number ms\\n     */\\n    public function iWaitMs($number)\\n    {\\n        $this->getSession()->wait($number);\\n    }\\n\\n    /**\\n     * @param String $number\\n     * @When I wait :number ms for jQuery\\n     */\\n    public function iWaitMsForJQuery($number)\\n    {\\n        $this->getSession()->wait($number, '(0 === jQuery.active)');\\n    }\\n}\\n\\n```\\n\\nTe funkcje to ustawianie wartości pola, kiedy nie znajduje się ono w formulażu, sprawdzanie poprawności wyniku i czekanie: zwykłe, oraz pozwalające nie czekać dłużej jeśli wszystkie requesty zostały wykonane.\\n\\nMając przygotowany kontekst możemy przyjrzeć się zawartości pliku opisującego testy\\n\\n> features/calculation.feature\\n\\n```gherkin\\nFeature: Executing calculations on the website\\n  In order to calculate sum or difference\\n  As an web browser\\n  I want to see result after pressing button\\n\\n  @javascript\\n  Scenario Outline: Action on two numbers\\n    Given I am on the homepage\\n    And I set \\\"a\\\" as <a>\\n    And I set \\\"b\\\" as <b>\\n    When I press \\\"<action>\\\"\\n    And I wait 1000 ms for jQuery\\n    Then Result should be <result>\\n\\n    Examples:\\n      | a      | b       | action | result |\\n      | 1      | 2       | sum    | 3      |\\n      | 3      | 6       | sum    | 9      |\\n      | 100    | 2000    | sum    | 2100   |\\n      | -1.5   | -3.1    | sum    | -4.6   |\\n      | 1.9990 | -0.0090 | sum    | 1.99   |\\n      | 1      | 2       | diff   | -1     |\\n      | -1     | -2      | diff   | 1      |\\n      | 1.001  | 2.001   | diff   | -1     |\\n      | 0.993  | 9.33    | diff   | -8.337 |\\n      | 12     | -12     | diff   | 24     |\\n\\n\\n```\\n\\nZawiera on scenariusz składający się z 6 kroków powtórzyny w 10 konfiguracjach. Te kroki to typowe wykonywanie obliczeń na stronie - ustawienie, `a`, `b` wybranie przycisku, czekanie na rezultat i sprawdzenie jego poprawności.\\n\\nŻeby wszystko zadziałało poprawnie brakuje jeszcze pliku konfiguracyjnego `behata`. Jest to `behat.yml`.\\n\\n> behat.yml\\n\\n```yml\\ndefault:\\n  extensions:\\n    Behat\\\\MinkExtension:\\n      browser_name: chrome\\n      base_url:  'http://localhost:9000'\\n      sessions:\\n        default:\\n          goutte: ~\\n        selenium:\\n          selenium2: ~\\n\\n```\\n\\nTo już wszystko. Jeśli prześledziłeś kod aż do tego momentu, znasz ten projekt na wylot. Mam nadzieję, że czegoś się nauczyłeś, a jeśli widzisz miejsca, gdzie mógł bym coś poprawić, śmiało daj mi znać. Będę wdzięczny za wszystkie konstruktywne uwagi.\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"opis-projektu\">Opis projektu</h2>\n<p>Jest to projekt, który pisałem ucząc się używania bazy danych w PHP. Kilka dni temu odświeżyłem go, dopisałem testy i postanowiłem udostępnić.</p>\n<p>Z artykułu dowiesz się jak <strong>centralizować konfigurację</strong> projektu, <strong>logować zdarzenia na stronie do bazy</strong> danych, <strong>testować stronę</strong> wykorzystując selenium.</p>\n<p>Skład kodu źródłowego to:</p>\n<pre><code>PHP 43.2% Perl 19.8% HTML 19.6% Cucumber 7.4% JavaScript 6.5% CSS 3.5%\n</code></pre>\n<p>Po napisaniu projekt będzie wyglądał tak:</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: html--><video src=\"https://www.dropbox.com/s/tkixyejx8d20gvp/1.mp4?dl=1\" controls></video><!--kg-card-end: html--><!--kg-card-begin: markdown--><h2 id=\"instalacja\">Instalacja</h2>\n<p><strong>Uwaga! Zanim włączysz install.pl upewnij się, że nie masz bazy o nazwie calc, zanim włączysz install.sh upewnij się, że nie masz chrome w sources.list. Skrypy instalacyjne w perlu i bashu nie są długie, zapoznaj się z nimi przed uruchomieniem.</strong></p>\n<p>Instalację projektu zalecam przeprowadzić na maszynie wirtualnej, np.: <code>Lubuntu</code>.</p>\n<p>Aby zainstalować projekt należy pobrać repozytorium (w lokacji, w której nie ma katalogu <code>calc</code>)</p>\n<pre><code>git clone https://github.com/gustawdaniel/calc\n</code></pre>\n<p>Przejść do katalogu <code>calc</code> i zainstalować potrzebne oprogramowanie. Przed instalacją przejrzyj plik <code>install.sh</code> i wykomentuj dodawanie repozytorium chrome jeśli masz je już zainstalowane.</p>\n<pre><code>cd calc &amp;&amp; bash install.sh\n</code></pre>\n<p>Sprawdź swoje parametry połączenia z bazą danych <code>mysql</code>. Jeśli podczas instalacji klikałeś tylko <code>enter</code> i nie miałeś wcześniej zainstalowanego pakietu <code>mysql-server</code> możesz zostawić domyślne. W przeciwnym wypadku wpisz poprawne wartości do pliku <code>config/parameters.yml</code> i usuń go z repozytorium.</p>\n<pre><code>git rm --cached config/parameters.yml\n</code></pre>\n<p>Aby zainstalować bazę danych i włączyć serwer php wpisz komendę</p>\n<pre><code>perl install.pl\n</code></pre>\n<p>W nowym terminalu (<code>ctrl+n</code>) włącz serwer selenium</p>\n<pre><code>selenium-standalone start\n</code></pre>\n<p>W kolejnym możesz włączyć testy:</p>\n<pre><code>vendor/bin/behat\n</code></pre>\n<p>Możesz również normalnie korzystać ze strony, która wystawiona jest na porcie 9000</p>\n<pre><code>firefox localhost:9000\n</code></pre>\n<p>Jeśli masz domyślne parametry łączenia z bazą, to, żeby zobaczyć zawartość bazy danych wpisz</p>\n<pre><code>sudo mysql -u root\nuse calc;\nselect * from log;\n\n</code></pre>\n<h2 id=\"struktura-bazy\">Struktura bazy</h2>\n<p>Zwykle zaczynam projekt od bazy danych. Jej instalację umieściłem w pliku <code>sql/main.sql</code>.</p>\n<blockquote>\n<p>sql/main.sql</p>\n</blockquote>\n<pre><code class=\"language-sql\">DROP   DATABASE IF     EXISTS database_name;\nCREATE DATABASE IF NOT EXISTS database_name\n    DEFAULT CHARACTER SET = 'utf8'\n    DEFAULT COLLATE 'utf8_unicode_ci';\n\nUSE database_name;\n\nCREATE TABLE log\n(\n    id      \t  BIGINT UNSIGNED    \t\tNOT NULL AUTO_INCREMENT PRIMARY KEY,\n    time   \t\t  DATETIME           \t\tNOT NULL,\n    a      \t\t  DOUBLE\t\t\t\t\t,\n    b      \t\t  DOUBLE\t\t\t\t\t,\n    button  \t  ENUM('sum', 'diff')       ,\n    useragent\t  VARCHAR(255)\n);\n\n</code></pre>\n<p>Istotne jest, że nazwa bazy, jaką stworzymy to nie <code>database_name</code> lecz nazwa podana później w pliku konfiguracyjnym. Zastąpi ona tą nazwę dzięki zastosowaniu języka perl, który &quot;skompiluje&quot; ten skrypt do wykonywalnej postaci. O tym będzie kolejny rozdział.</p>\n<h2 id=\"konfiguracja\">Konfiguracja</h2>\n<p>Bardzo dobrym nawykiem, który wyniosłem z pracy z Symfony jest trzymanie parametrów dotyczących połączenia z bazą danych poza kodem projektu. Jeszcze lepszym jest rozdzielenie parametrów prywatnych (które mogą zawierać loginy i hasła ze środowiska produkcyjnego - nie trzymanych w repozytorium), od domyślnych.</p>\n<p>W tym przykładzie stosujemy jedynie domyślne parametry. Umieścimy je w pliku <code>parameters.yml</code> w katalogu <code>config</code>.</p>\n<blockquote>\n<p>config/parameters.yml</p>\n</blockquote>\n<pre><code class=\"language-yml\">config:\n    host: 'localhost'\n    user: 'root'\n    pass: ''\n    base: 'calc'\n    port: '3306'\n\n</code></pre>\n<p>Będziemy się do nich odnosić w instalatorze napisanym w perlu oraz w klasie odpowiadającej za zapis do bazy danych w PHP.</p>\n<h3 id=\"konfiguracja-w-perlu\">Konfiguracja w Perlu</h3>\n<p>Napiszemy dwa skrypty - do tworzenia, oraz do resetowania bazy. Do odczytywania pliku <code>parameters.yml</code> wykorzystamy bibliotekę <code>YAML::Tiny</code>. Poniższy skrypt kolejno:</p>\n<p>Odczytuje plik z parametrami do zmiennej <code>$yaml</code>.<br>\nZapisuje wszystkie parametry do odpowiednich zmiennych.</p>\n<blockquote>\n<p>install.pl</p>\n</blockquote>\n<pre><code class=\"language-perl\">#!/bin/perl\n\nuse YAML::Tiny;\n\nuse strict;\nuse warnings;\n\n#\n#       Config:\n#\n\n    my $yaml = YAML::Tiny-&gt;read( 'config/parameters.yml' );\n    my $baseName  = $yaml-&gt;[0]-&gt;{config}-&gt;{base};\n    my $user  = $yaml-&gt;[0]-&gt;{config}-&gt;{user};\n    my $pass  = $yaml-&gt;[0]-&gt;{config}-&gt;{pass};\n    my $host  = $yaml-&gt;[0]-&gt;{config}-&gt;{host};\n    my $port  = $yaml-&gt;[0]-&gt;{config}-&gt;{port};\n\n</code></pre>\n<p>Tworzy zmienne z ustawieniami katalogów. (Instrukcje tworzące bazę znajdują się w pliku <code>main.sql</code>.)</p>\n<pre><code class=\"language-perl\">#\n#       Catalogs structure:\n#\n\n    my $build = &quot;build/&quot;;\n    my $sql = &quot;sql/&quot;;\n    my $mainSQL = &quot;main.sql&quot;;\n\n\n</code></pre>\n<p>Otwiera plik z kodem <code>sql</code> i zapisuje treść do zmiennej <code>$content</code>.</p>\n<pre><code class=\"language-perl\">#\n#       Script:\n#\n\n\n#-----------------------------------------    Database   -------------#\n\n#       Prepare catalog\n    system('mkdir -p '.$build);\n\n#       Read file with mysql\n    my $content;\n    open(my $fh, '&lt;', $sql.$mainSQL) or die &quot;cannot open file&quot;;\n    {\n        local $/;\n        $content = &lt;$fh&gt;;\n    }\n    close($fh);\n\n</code></pre>\n<p>Zamienia każde wystąpienie ciągu <code>database_name</code> na nazwę z pliku <code>parameters.yml</code> i zapisuje.</p>\n<pre><code class=\"language-perl\">#       Replace database name by name from config\n    $content =~ s/database_name/$baseName/g;\n\n#       Save file with correct db name\n    open($fh, '&gt;', $build.$mainSQL) or die &quot;Could not open file' $!&quot;;\n    {\n        print $fh $content;\n    }\n    close $fh;\n\n</code></pre>\n<p>Nadaje domyślnemu użytkownikowi prawo otwierania bazy jako root, tworzy bazę i włącza serwer <code>php</code>.</p>\n<pre><code class=\"language-perl\">#       Execute file\n    my $passSting = ($pass eq &quot;&quot;) ? &quot;&quot; : &quot; -p &quot;.$pass;\n    system('sudo mysql -h '.$host.' -P '.$port.' -u '.$user.$passSting.' &lt; '.$build.$mainSQL);\n\n#       Start server\n    system('cd web &amp;&amp; php -S localhost:9000');\n\n\n</code></pre>\n<h3 id=\"konfiguracja-w-php\">Konfiguracja w PHP</h3>\n<p>Do obsługi pliku konfiguracyjnego w <code>php</code> zastosujemy bibliotekę <code>&quot;mustangostang/spyc&quot;: &quot;^0.6.1&quot;</code>. Będzie ona wykorzystana jedynie przy łączeniu się z bazą - w pliku <code>php/DataBase.php</code>.</p>\n<blockquote>\n<p>php/DataBase.php</p>\n</blockquote>\n<pre><code class=\"language-php\">&lt;?php\n\nrequire_once __DIR__.&quot;/../vendor/mustangostang/spyc/Spyc.php&quot;;\n\nclass DataBase\n{\n\n\t...\n\n\t\t// config from yml\n\t\t$config = Spyc::YAMLLoad(__DIR__.&quot;/../config/parameters.yml&quot;)[&quot;config&quot;];\n\n\t\t// connecting\n\t\t$mysqli = @new mysqli($config[&quot;host&quot;], $config[&quot;user&quot;], $config[&quot;pass&quot;], $config[&quot;base&quot;], $config[&quot;port&quot;]);\n\n\t...\n\n</code></pre>\n<p>W do zmiennej <code>$config</code> zapisywana jest tablica z parametrami do połączenia z bazą. Zasada działania jest taka sama, jak w poprzednim skrypcie.</p>\n<h2 id=\"logowanie-danych-w-bazie\">Logowanie danych w bazie</h2>\n<p>W paragrafie dotyczącym struktury bazy pokazaliśmy jakie rekordy zawiera jedyna tabela jaką mamy - <code>log</code>. Są to <code>id</code>, <code>time</code>, <code>a</code>, <code>b</code>, <code>button</code> i <code>useragent</code>. <code>a</code> i <code>b</code> odpowiadają liczbom wpisanym przez użytkownika. <code>button</code> jest akcją którą wybrał <code>sum</code> dla sumy lub <code>diff</code> dla różnicy. <code>useragent</code> to dane dotyczące przeglądarki.</p>\n<p>Odwzorujemy teraz rekord bazy danych w <code>php</code> jako obiekt. W tym celu tworzymy klasę <code>Log</code> w pliku <code>php/Log.php</code></p>\n<blockquote>\n<p>php/Log.php</p>\n</blockquote>\n<pre><code class=\"language-php\">&lt;?php\n\nclass Log\n{\n    private $a;\n    private $b;\n    private $action;\n    private $agent;\n\n    /**\n     * @return mixed\n     */\n    public function getC()\n    {\n        if($this-&gt;action==&quot;sum&quot;){\n            return $this-&gt;a + $this-&gt;b;\n        } elseif ($this-&gt;action==&quot;diff&quot;) {\n            return $this-&gt;a - $this-&gt;b;\n        } else {\n            return null;\n        }\n    }\n\n   ...\n}\n\n</code></pre>\n<p>Zawiera ona wszystkie pola z tabeli poza identyfikatorem i czasem, które nadawane są podczas zapisu do bazy. Przez trzy kropki oznaczyłem wszystkie gettery i settery dla własności klasy. W większości IDE można je wygenerować automatycznie, np.: w <code>PhpStorm</code> wybierając <code>code-&gt;Generate...</code>. Metoda <code>getC</code> pozwala wyliczyć wartość sumy lub różnicy po stronie serwera, co wykorzystane jest później w interfejsie <code>API</code>.</p>\n<p>Teraz możemy przedstawić w całości wspomnianą wcześniej klasę <code>DataBase</code>, która służyła do zapisu danych otrzymanych ze strony do bazy.</p>\n<blockquote>\n<p>php/DataBase.php</p>\n</blockquote>\n<pre><code class=\"language-php\">&lt;?php\n\nrequire_once __DIR__.&quot;/Log.php&quot;;\nrequire_once __DIR__.&quot;/../vendor/mustangostang/spyc/Spyc.php&quot;;\n\nclass DataBase\n{\n\tfunction save(Log $log){\n\n\t\t$a = $log-&gt;getA();\n\t\t$b = $log-&gt;getB();\n\t\t$s = $log-&gt;getAction();\n\t\t$u = $log-&gt;getAgent();\n\n\t\t// config from yml\n\t\t$config = Spyc::YAMLLoad(__DIR__.&quot;/../config/parameters.yml&quot;)[&quot;config&quot;];\n\n\t\t// connecting\n\t\t$mysqli = @new mysqli($config[&quot;host&quot;], $config[&quot;user&quot;], $config[&quot;pass&quot;], $config[&quot;base&quot;], $config[&quot;port&quot;]);\n\n\t\t// test of connecting\n\t\tif ($mysqli -&gt; connect_errno)\n\t\t{\n\t\t\t$code = $mysqli -&gt; connect_errno;\n\t\t\t$mess = $mysqli -&gt; connect_error;\n\t\t\tdie(&quot;Failed to connect to MySQL: ($code) $mess\\n&quot;);\n\t\t}\n\n\t\t// definition of query\n\t\t$query  = 'INSERT INTO log VALUES(NULL,NOW(),?,?,?,?);';\n\n\t\t// preparing\n\t\t$stmt = @$mysqli -&gt; prepare($query);\n\n\t\t// test of preparing\n\t\tif(!$stmt)\n\t\t{\n\t\t\t$code = $mysqli -&gt; errno;\n\t\t\t$mess = $mysqli -&gt; error;\n\t\t\t$mysqli -&gt; close();\n\t\t\tdie(&quot;Failed to prepare statement: ($code) $mess\\n&quot;);\n\t\t}\n\n\t\t// binding\n\t\t$bind = @$stmt -&gt; bind_param(&quot;ddss&quot;, $a, $b, $s, $u);\n\n\t\t// test of binding\n\t\tif(!$bind)\n\t\t{\n\t\t\t$stmt   -&gt; close();\n\t\t\t$mysqli -&gt; close();\n\t\t\tdie(&quot;Failed to bind param.\\n&quot;);\n\t\t}\n\n\t\t// executing query\n\t\t$exec = @$stmt -&gt; execute();\n\n\t\t// checking fails\n\t\tif(!$exec)\n\t\t{\n\t\t\t$stmt   -&gt; close();\n\t\t\t$mysqli -&gt; close();\n\t\t\tdie(&quot;Failed to execute prepare statement.\\n&quot;);\n\t\t}\n\n\t\t// clearing and disconnecting\n\t\t$stmt   -&gt; close();\n\t\t$mysqli -&gt; close();\n\t}\n}\n\n</code></pre>\n<p>Klasa ta nie ma własności, ma za to jedną metodę - <code>save</code>. Ta metoda pobiera obiekt <code>Log</code> i wykonuje logowanie do bazy danych wszystkich własności tego obiektu, przy czym dodaje jeszcze czas. Najciekawsza część tej klasy - pobieranie konfiguracji była omówiona wcześniej. Reszta jest po prostu w zwykłym zapisem do bazy.</p>\n<p>To były klasy, teraz czas na skrypt wejściowy back-endu naszej aplikacji. Znajduje się w pliku <code>web/api.php</code> i odpowiada za poprawne przechwycenie żądania, pobranie parametrów, przekazanie ich bazie i oddanie odpowiedzi zawierającej wynik działania.</p>\n<pre><code class=\"language-php\">&lt;?php\n\n// error display\n//ini_set('display_errors', 1);\n//ini_set('display_startup_errors', 1);\n//error_reporting(E_ALL);\n\nrequire_once __DIR__.&quot;/../php/Log.php&quot;;\nrequire_once __DIR__.&quot;/../php/DataBase.php&quot;;\n\n// routing\nif($_SERVER['REQUEST_METHOD']==&quot;POST&quot;\n    &amp;&amp; parse_url($_SERVER[&quot;REQUEST_URI&quot;])[&quot;path&quot;]==&quot;/api.php/action&quot;){\n\n    // get data from request\n    $log = new Log();\n    $log-&gt;setA($_POST[&quot;a&quot;]);\n    $log-&gt;setB($_POST[&quot;b&quot;]);\n    $log-&gt;setAction($_POST[&quot;action&quot;]);\n    $log-&gt;setAgent($_SERVER['HTTP_USER_AGENT']);\n\n    // connect to db and save data\n    $db = new DataBase();\n    $db-&gt;save($log);\n\n    // send response\n    header('Content-type: application/json');\n    echo json_encode([\n        &quot;a&quot;=&gt;$log-&gt;getA(),\n        &quot;b&quot;=&gt;$log-&gt;getB(),\n        &quot;c&quot;=&gt;$log-&gt;getC(),\n        &quot;action&quot;=&gt;$log-&gt;getAction()\n    ]);\n}\n\n</code></pre>\n<h3 id=\"testowanie-api-przez-httpie\">Testowanie Api przez httpie</h3>\n<p>Możemy przetestować nasze <code>api</code> wykorzystując <code>httpie</code>. Komenda</p>\n<pre><code>http -fv 127.0.0.1:9000/api.php/action a=1 b=2 action=&quot;sum&quot;\n\n</code></pre>\n<p>powinna wyprodukować następujący output:</p>\n<pre><code class=\"language-http\">POST /api.php/action HTTP/1.1\nAccept: */*\nAccept-Encoding: gzip, deflate\nConnection: keep-alive\nContent-Length: 18\nContent-Type: application/x-www-form-urlencoded; charset=utf-8\nHost: 127.0.0.1:9000\nUser-Agent: HTTPie/0.9.2\n\na=1&amp;b=2&amp;action=sum\n\nHTTP/1.1 200 OK\nConnection: close\nContent-type: application/json\nHost: 127.0.0.1:9000\nX-Powered-By: PHP/7.0.8-0ubuntu0.16.04.3\n\n{\n    &quot;a&quot;: &quot;1&quot;,\n    &quot;action&quot;: &quot;sum&quot;,\n    &quot;b&quot;: &quot;2&quot;,\n    &quot;c&quot;: 3\n}\n\n</code></pre>\n<h2 id=\"ajax\">AJAX</h2>\n<p>Kiedy mamy gotową bazę oraz skrypty do jej obsługiwania, nic nie stoi na przeszkodzie dokończenia projektu przez napisanie frontu. Zakładamy, że instalacja przebiegła pomyślnie i <code>bower</code> zainstalował potrzebne paczki - to znaczy <code>&quot;bootstrap&quot;: &quot;v4.0.0-alpha.5&quot;</code> w katalogu <code>web</code>. Ponieważ <code>jQuery</code> jest zależnością dla <code>Bootstrapa</code> możemy z niej skorzystać przy tworzeniu skryptów.</p>\n<p>Nasz front składa się z trzech plików: <code>web/index.html</code>, <code>web/css/style.css</code> i <code>web/js/site.js</code>. Oto one:</p>\n<blockquote>\n<p>web/index.html</p>\n</blockquote>\n<pre><code class=\"language-html\">&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n  &lt;head&gt;\n    &lt;meta charset=&quot;utf-8&quot;&gt;\n    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt;\n    &lt;title&gt;Php calculator logging requests into database.&lt;/title&gt;\n\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;bower_components/bootstrap/dist/css/bootstrap.min.css&quot;&gt;\n    &lt;link href=&quot;https://fonts.googleapis.com/css?family=Lato:300&quot; rel=&quot;stylesheet&quot;&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;css/style.css&quot;&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n\n    &lt;section&gt;\n      &lt;div class=&quot;container&quot;&gt;\n        &lt;div class=&quot;row&quot;&gt;\n          &lt;div class=&quot;offset-md-3 col-md-6&quot;&gt;\n            &lt;div class=&quot;card text-xs-center&quot;&gt;\n              &lt;div class=&quot;card-header&quot;&gt;\n                Set two numbers and chose calculation\n              &lt;/div&gt;\n              &lt;div class=&quot;card-block&quot;&gt;\n                &lt;div class=&quot;form-group&quot;&gt;\n                  &lt;input id=&quot;a&quot; type=&quot;number&quot; step=&quot;any&quot; class=&quot;form-control&quot;&gt;\n                &lt;/div&gt;\n                &lt;div class=&quot;form-group&quot;&gt;\n                  &lt;input id=&quot;b&quot; type=&quot;number&quot; step=&quot;any&quot; class=&quot;form-control&quot;&gt;\n                &lt;/div&gt;\n\n                &lt;div class=&quot;form-group row submit-area&quot;&gt;\n                  &lt;div class=&quot;col-xs-6&quot;&gt;\n                    &lt;input class=&quot;btn btn-lg btn-block hidden-xs-down btn-primary&quot; type=&quot;submit&quot; value='Sum' name=&quot;sum&quot;&gt;\n                    &lt;input class=&quot;btn btn-lg btn-block hidden-sm-up btn-primary&quot; type=&quot;submit&quot; value='+' name=&quot;sum&quot;&gt;\n                  &lt;/div&gt;\n                  &lt;div class=&quot;col-xs-6&quot;&gt;\n                    &lt;input class=&quot;btn btn-lg btn-block hidden-xs-down btn-danger&quot; type=&quot;submit&quot; value='Difference' name=&quot;diff&quot;&gt;\n                    &lt;input class=&quot;btn btn-lg btn-block hidden-sm-up btn-danger&quot; type=&quot;submit&quot; value='-' name=&quot;diff&quot;&gt;\n                  &lt;/div&gt;\n                &lt;/div&gt;\n                &lt;div class=&quot;form-group&quot;&gt;\n                  &lt;input id=&quot;c&quot; type=&quot;text&quot; readonly step=&quot;any&quot; class=&quot;form-control&quot;&gt;\n                &lt;/div&gt;\n\n              &lt;/div&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/section&gt;\n\n\n    &lt;nav class=&quot;navbar navbar-fixed-bottom navbar-light bg-faded&quot;&gt;\n      &lt;a class=&quot;navbar-brand&quot; href=&quot;README.html&quot;&gt;Documentation&lt;/a&gt;\n      &lt;a class=&quot;navbar-brand float-xs-right&quot; href=&quot;http://gustawdaniel.pl&quot;&gt;Daniel Gustaw&lt;/a&gt;\n    &lt;/nav&gt;\n\n    &lt;script src=&quot;bower_components/jquery/dist/jquery.min.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;js/site.js&quot;&gt;&lt;/script&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\n</code></pre>\n<p>Standardowy plik html. To co jest w nim ciekawego, to wykorzystanie klasy <code>card</code> z <code>bootstrap 4</code> oraz zmiana napisów na przyciskach z pełnych nazw na znaki <code>+</code> i <code>-</code> przy małych szerokościach ekranu.</p>\n<p>Jeszcze prostsze są style naszej strony.</p>\n<blockquote>\n<p>web/css/style.css</p>\n</blockquote>\n<pre><code class=\"language-css\">body {\n    font-family: 'Lato', 'SansSerif', serif;\n}\n\nsection {\n    margin-top: 20vh;\n}\n\n</code></pre>\n<p>Jest to zasługa Bootstrapa który naprawdę dużo potrafi odwzorować tak, jak bym oczekiwał. Jedyne czego potrzebujemy to margines pionowy i czcionka.</p>\n<p>Najciekawsza część to JavaScript:</p>\n<blockquote>\n<p>web/js/site.js</p>\n</blockquote>\n<pre><code class=\"language-js\">(function () {\n\n    var submitArea = document.getElementsByClassName(&quot;submit-area&quot;)[0];\n    var card = document.getElementsByClassName(&quot;card&quot;)[0];\n    var a = document.getElementById(&quot;a&quot;);\n    var b = document.getElementById(&quot;b&quot;);\n    var c = document.getElementById(&quot;c&quot;);\n\n    function round(value,dec=5) {\n        return 1*(Math.round(value+&quot;e+&quot;+dec)+&quot;e-&quot;+dec);\n    }\n\n    submitArea.addEventListener('click',function (e) {\n        if(e.target.name=='sum') {\n            c.value = round((a.value*1) + (b.value*1));\n        } else if(e.target.name=='diff') {\n            c.value = a.value - b.value;\n        }\n\n        $.post(&quot;api.php/action&quot;, {a: a.value, b: b.value, c: c.value, action: e.target.getAttribute('name')}, function (data) {\n            console.log(data);\n        })\n    });\n\n})();\n\n</code></pre>\n<p>Cały zawarty jest w funkcji anonimowej, co zapewnia enkapsulację - nie mieszamy naszych zmiennych z globalnymi. Struktura skryptu jest następująca. Najpierw definiujemy zmienne powiązane z elementami htmla, później umieszczamy funkcje pomocnicze - u nas <code>round</code>, na koniec definiujemy listener.</p>\n<p>Funkcja <code>round</code> pozwala na zaokrąglanie obliczeń w JavaScript. Domyślna funkcja round z obiektu <code>Math</code> zawsze zaokrągla do liczb całkowitych. Wartość domyślna liczby miejsc po przecinku definiowana przez znak <code>=</code> jest stosunkowo nowym rozwiązaniem w JavaScript. Wnętrze funkcji pełnymi garściami czerpie z dynamicznego typowania i notacji naukowej do przedstawiania liczb w tym języku.</p>\n<p>Zauważ, że ponieważ przyciski do liczenia sumy i różnycy występują podwójnie (ze względu na responsywność aplikacji), dopiero wewnątrz listenera musimy określić który z nich został wybrany. Jeśli jest to suma, mnożymy nasze wartości przez 1, aby znak <code>+</code> oznaczał dodawanie, a nie konkatenację.</p>\n<p>Natychmiast po zidentyfikowaniu, który przycisk został wybrany, następuje aktualizacja wyniku. Dopiero wtedy wysyłane jest żadnie <code>POST</code> co dzięki <code>jQuery</code> jest wyjątkowo proste. Takie rozwiązanie ma zalety i wady. Zaletą jest szybkość, użytkownik nie musi czekać naodpowiedź z serwera. Wadą jest duplikacja logiki odpowiedzialnej za wykonywanie obliczeń. Nie trudno domyślić się, że z powodu innych zaokrągleń wyniki przekazywane w odpowiedzi <code>API</code> będą mogły różnić się od tych wyświetlanych na stronie.</p>\n<h2 id=\"behat-i-selenium\">Behat i Selenium</h2>\n<p><strong>Behat</strong> jest narzędziem do pisania behawioralnych testów automatycznych. Jest to najbardziej naturalny dla człowieka sposób testowania oparty o historie, które mogą się wydażyć podczas korzystania z aplikacji. <strong>Selenium</strong> to serwer pozwalający symulować przeglądarkę, wyposażony w programistyczne API. Łącząc te dwa narzędzia otrzymujemy możliwość pisania czegoś w rodzaju bota odwiedzającego naszą stronę i wykonującego określone akcje. To właśnie użycie tego narzędzia widziałeś w video na początku wpisu.</p>\n<p>Dzięki poleceniu <code>vendor/bin/behat --init</code> behat generuje domyślny plik <code>features/bootstrap/FeatureContext.php</code>. Rozszerzymy tą klasę dodając do niej <code>MinkContext</code>. Jest to zbiór tłumaczeń między naturalnym językiem <code>Gherkin</code> a akcjami wykonywanymi przed drivery przeglądarki takie jak <code>selenium</code>.</p>\n<p>Napisałem o <code>Gerkinie</code>, że jest językiem naturalnym. W <a href=\"https://github.com/cucumber/cucumber/wiki/Gherkin\">oficjalnej dokumentacji</a> jest przedstawiany następująco:</p>\n<blockquote>\n<p>Gherkin is the language that Cucumber understands. It is a Business Readable, Domain Specific Language that lets you describe software’s behaviour without detailing how that behaviour is implemented.</p>\n</blockquote>\n<p>Poza tym rozszerzeniem dodamy kilka funkcji, których brakuje w <code>MinkConext</code></p>\n<blockquote>\n<p>features/bootstrap/FeatureContext.php</p>\n</blockquote>\n<pre><code class=\"language-php\">&lt;?php\n\nuse Behat\\Behat\\Context\\Context;\nuse Behat\\Gherkin\\Node\\PyStringNode;\nuse Behat\\Gherkin\\Node\\TableNode;\nuse Behat\\MinkExtension\\Context\\MinkContext;\n\n/**\n * Defines application features from the specific context.\n */\nclass FeatureContext extends MinkContext implements Context\n{\n    /**\n     * Initializes context.\n     *\n     * Every scenario gets its own context instance.\n     * You can also pass arbitrary arguments to the\n     * context constructor through behat.yml.\n     */\n    public function __construct()\n    {\n    }\n\n    /**\n     * @param String $field\n     * @param String $value\n     * @Given I set :field as :value\n     */\n    public function iSetAs($field, $value)\n    {\n        $javascript = 'document.getElementById(&quot;'.$field.'&quot;).value='.$value;\n        $this-&gt;getSession()-&gt;executeScript($javascript);\n    }\n\n    /**\n     * @Then Result should be :value\n     */\n    public function resultShouldBe($value)\n    {\n        $javascript = 'document.getElementById(&quot;c&quot;).value';\n        $realResult = $this-&gt;getSession()-&gt;evaluateScript($javascript);\n\n        if ( $value !== $realResult) {\n            throw new Exception(\n                &quot;Actual result is:\\n&quot; . $realResult\n            );\n        }\n    }\n\n    /**\n     * @param String $number\n     * @When I wait :number ms\n     */\n    public function iWaitMs($number)\n    {\n        $this-&gt;getSession()-&gt;wait($number);\n    }\n\n    /**\n     * @param String $number\n     * @When I wait :number ms for jQuery\n     */\n    public function iWaitMsForJQuery($number)\n    {\n        $this-&gt;getSession()-&gt;wait($number, '(0 === jQuery.active)');\n    }\n}\n\n</code></pre>\n<p>Te funkcje to ustawianie wartości pola, kiedy nie znajduje się ono w formulażu, sprawdzanie poprawności wyniku i czekanie: zwykłe, oraz pozwalające nie czekać dłużej jeśli wszystkie requesty zostały wykonane.</p>\n<p>Mając przygotowany kontekst możemy przyjrzeć się zawartości pliku opisującego testy</p>\n<blockquote>\n<p>features/calculation.feature</p>\n</blockquote>\n<pre><code class=\"language-gherkin\">Feature: Executing calculations on the website\n  In order to calculate sum or difference\n  As an web browser\n  I want to see result after pressing button\n\n  @javascript\n  Scenario Outline: Action on two numbers\n    Given I am on the homepage\n    And I set &quot;a&quot; as &lt;a&gt;\n    And I set &quot;b&quot; as &lt;b&gt;\n    When I press &quot;&lt;action&gt;&quot;\n    And I wait 1000 ms for jQuery\n    Then Result should be &lt;result&gt;\n\n    Examples:\n      | a      | b       | action | result |\n      | 1      | 2       | sum    | 3      |\n      | 3      | 6       | sum    | 9      |\n      | 100    | 2000    | sum    | 2100   |\n      | -1.5   | -3.1    | sum    | -4.6   |\n      | 1.9990 | -0.0090 | sum    | 1.99   |\n      | 1      | 2       | diff   | -1     |\n      | -1     | -2      | diff   | 1      |\n      | 1.001  | 2.001   | diff   | -1     |\n      | 0.993  | 9.33    | diff   | -8.337 |\n      | 12     | -12     | diff   | 24     |\n\n\n</code></pre>\n<p>Zawiera on scenariusz składający się z 6 kroków powtórzyny w 10 konfiguracjach. Te kroki to typowe wykonywanie obliczeń na stronie - ustawienie, <code>a</code>, <code>b</code> wybranie przycisku, czekanie na rezultat i sprawdzenie jego poprawności.</p>\n<p>Żeby wszystko zadziałało poprawnie brakuje jeszcze pliku konfiguracyjnego <code>behata</code>. Jest to <code>behat.yml</code>.</p>\n<blockquote>\n<p>behat.yml</p>\n</blockquote>\n<pre><code class=\"language-yml\">default:\n  extensions:\n    Behat\\MinkExtension:\n      browser_name: chrome\n      base_url:  'http://localhost:9000'\n      sessions:\n        default:\n          goutte: ~\n        selenium:\n          selenium2: ~\n\n</code></pre>\n<p>To już wszystko. Jeśli prześledziłeś kod aż do tego momentu, znasz ten projekt na wylot. Mam nadzieję, że czegoś się nauczyłeś, a jeśli widzisz miejsca, gdzie mógł bym coś poprawić, śmiało daj mi znać. Będę wdzięczny za wszystkie konstruktywne uwagi.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f31a42fb35425592d0b2e",
            "plaintext": "Opis projektu\nJest to projekt, który pisałem ucząc się używania bazy danych w PHP. Kilka dni\ntemu odświeżyłem go, dopisałem testy i postanowiłem udostępnić.\n\nZ artykułu dowiesz się jak centralizować konfigurację projektu, logować\nzdarzenia na stronie do bazy danych, testować stronę wykorzystując selenium.\n\nSkład kodu źródłowego to:\n\nPHP 43.2% Perl 19.8% HTML 19.6% Cucumber 7.4% JavaScript 6.5% CSS 3.5%\n\n\nPo napisaniu projekt będzie wyglądał tak:\n\nInstalacja\nUwaga! Zanim włączysz install.pl upewnij się, że nie masz bazy o nazwie calc,\nzanim włączysz install.sh upewnij się, że nie masz chrome w sources.list. Skrypy\ninstalacyjne w perlu i bashu nie są długie, zapoznaj się z nimi przed\nuruchomieniem.\n\nInstalację projektu zalecam przeprowadzić na maszynie wirtualnej, np.: Lubuntu.\n\nAby zainstalować projekt należy pobrać repozytorium (w lokacji, w której nie ma\nkatalogu calc)\n\ngit clone https://github.com/gustawdaniel/calc\n\n\nPrzejść do katalogu calc i zainstalować potrzebne oprogramowanie. Przed\ninstalacją przejrzyj plik install.sh i wykomentuj dodawanie repozytorium chrome\njeśli masz je już zainstalowane.\n\ncd calc && bash install.sh\n\n\nSprawdź swoje parametry połączenia z bazą danych mysql. Jeśli podczas instalacji\nklikałeś tylko enter i nie miałeś wcześniej zainstalowanego pakietu mysql-server \nmożesz zostawić domyślne. W przeciwnym wypadku wpisz poprawne wartości do pliku \nconfig/parameters.yml i usuń go z repozytorium.\n\ngit rm --cached config/parameters.yml\n\n\nAby zainstalować bazę danych i włączyć serwer php wpisz komendę\n\nperl install.pl\n\n\nW nowym terminalu (ctrl+n) włącz serwer selenium\n\nselenium-standalone start\n\n\nW kolejnym możesz włączyć testy:\n\nvendor/bin/behat\n\n\nMożesz również normalnie korzystać ze strony, która wystawiona jest na porcie\n9000\n\nfirefox localhost:9000\n\n\nJeśli masz domyślne parametry łączenia z bazą, to, żeby zobaczyć zawartość bazy\ndanych wpisz\n\nsudo mysql -u root\nuse calc;\nselect * from log;\n\n\n\nStruktura bazy\nZwykle zaczynam projekt od bazy danych. Jej instalację umieściłem w pliku \nsql/main.sql.\n\n> sql/main.sql\n\n\nDROP   DATABASE IF     EXISTS database_name;\nCREATE DATABASE IF NOT EXISTS database_name\n    DEFAULT CHARACTER SET = 'utf8'\n    DEFAULT COLLATE 'utf8_unicode_ci';\n\nUSE database_name;\n\nCREATE TABLE log\n(\n    id      \t  BIGINT UNSIGNED    \t\tNOT NULL AUTO_INCREMENT PRIMARY KEY,\n    time   \t\t  DATETIME           \t\tNOT NULL,\n    a      \t\t  DOUBLE\t\t\t\t\t,\n    b      \t\t  DOUBLE\t\t\t\t\t,\n    button  \t  ENUM('sum', 'diff')       ,\n    useragent\t  VARCHAR(255)\n);\n\n\n\nIstotne jest, że nazwa bazy, jaką stworzymy to nie database_name lecz nazwa\npodana później w pliku konfiguracyjnym. Zastąpi ona tą nazwę dzięki zastosowaniu\njęzyka perl, który \"skompiluje\" ten skrypt do wykonywalnej postaci. O tym będzie\nkolejny rozdział.\n\nKonfiguracja\nBardzo dobrym nawykiem, który wyniosłem z pracy z Symfony jest trzymanie\nparametrów dotyczących połączenia z bazą danych poza kodem projektu. Jeszcze\nlepszym jest rozdzielenie parametrów prywatnych (które mogą zawierać loginy i\nhasła ze środowiska produkcyjnego - nie trzymanych w repozytorium), od\ndomyślnych.\n\nW tym przykładzie stosujemy jedynie domyślne parametry. Umieścimy je w pliku \nparameters.yml w katalogu config.\n\n> config/parameters.yml\n\n\nconfig:\n    host: 'localhost'\n    user: 'root'\n    pass: ''\n    base: 'calc'\n    port: '3306'\n\n\n\nBędziemy się do nich odnosić w instalatorze napisanym w perlu oraz w klasie\nodpowiadającej za zapis do bazy danych w PHP.\n\nKonfiguracja w Perlu\nNapiszemy dwa skrypty - do tworzenia, oraz do resetowania bazy. Do odczytywania\npliku parameters.yml wykorzystamy bibliotekę YAML::Tiny. Poniższy skrypt\nkolejno:\n\nOdczytuje plik z parametrami do zmiennej $yaml.\nZapisuje wszystkie parametry do odpowiednich zmiennych.\n\n> install.pl\n\n\n#!/bin/perl\n\nuse YAML::Tiny;\n\nuse strict;\nuse warnings;\n\n#\n#       Config:\n#\n\n    my $yaml = YAML::Tiny->read( 'config/parameters.yml' );\n    my $baseName  = $yaml->[0]->{config}->{base};\n    my $user  = $yaml->[0]->{config}->{user};\n    my $pass  = $yaml->[0]->{config}->{pass};\n    my $host  = $yaml->[0]->{config}->{host};\n    my $port  = $yaml->[0]->{config}->{port};\n\n\n\nTworzy zmienne z ustawieniami katalogów. (Instrukcje tworzące bazę znajdują się\nw pliku main.sql.)\n\n#\n#       Catalogs structure:\n#\n\n    my $build = \"build/\";\n    my $sql = \"sql/\";\n    my $mainSQL = \"main.sql\";\n\n\n\n\nOtwiera plik z kodem sql i zapisuje treść do zmiennej $content.\n\n#\n#       Script:\n#\n\n\n#-----------------------------------------    Database   -------------#\n\n#       Prepare catalog\n    system('mkdir -p '.$build);\n\n#       Read file with mysql\n    my $content;\n    open(my $fh, '<', $sql.$mainSQL) or die \"cannot open file\";\n    {\n        local $/;\n        $content = <$fh>;\n    }\n    close($fh);\n\n\n\nZamienia każde wystąpienie ciągu database_name na nazwę z pliku parameters.yml i\nzapisuje.\n\n#       Replace database name by name from config\n    $content =~ s/database_name/$baseName/g;\n\n#       Save file with correct db name\n    open($fh, '>', $build.$mainSQL) or die \"Could not open file' $!\";\n    {\n        print $fh $content;\n    }\n    close $fh;\n\n\n\nNadaje domyślnemu użytkownikowi prawo otwierania bazy jako root, tworzy bazę i\nwłącza serwer php.\n\n#       Execute file\n    my $passSting = ($pass eq \"\") ? \"\" : \" -p \".$pass;\n    system('sudo mysql -h '.$host.' -P '.$port.' -u '.$user.$passSting.' < '.$build.$mainSQL);\n\n#       Start server\n    system('cd web && php -S localhost:9000');\n\n\n\n\nKonfiguracja w PHP\nDo obsługi pliku konfiguracyjnego w php zastosujemy bibliotekę \n\"mustangostang/spyc\": \"^0.6.1\". Będzie ona wykorzystana jedynie przy łączeniu\nsię z bazą - w pliku php/DataBase.php.\n\n> php/DataBase.php\n\n\n<?php\n\nrequire_once __DIR__.\"/../vendor/mustangostang/spyc/Spyc.php\";\n\nclass DataBase\n{\n\n\t...\n\n\t\t// config from yml\n\t\t$config = Spyc::YAMLLoad(__DIR__.\"/../config/parameters.yml\")[\"config\"];\n\n\t\t// connecting\n\t\t$mysqli = @new mysqli($config[\"host\"], $config[\"user\"], $config[\"pass\"], $config[\"base\"], $config[\"port\"]);\n\n\t...\n\n\n\nW do zmiennej $config zapisywana jest tablica z parametrami do połączenia z\nbazą. Zasada działania jest taka sama, jak w poprzednim skrypcie.\n\nLogowanie danych w bazie\nW paragrafie dotyczącym struktury bazy pokazaliśmy jakie rekordy zawiera jedyna\ntabela jaką mamy - log. Są to id, time, a, b, button i useragent. a i b \nodpowiadają liczbom wpisanym przez użytkownika. button jest akcją którą wybrał \nsum dla sumy lub diff dla różnicy. useragent to dane dotyczące przeglądarki.\n\nOdwzorujemy teraz rekord bazy danych w php jako obiekt. W tym celu tworzymy\nklasę Log w pliku php/Log.php\n\n> php/Log.php\n\n\n<?php\n\nclass Log\n{\n    private $a;\n    private $b;\n    private $action;\n    private $agent;\n\n    /**\n     * @return mixed\n     */\n    public function getC()\n    {\n        if($this->action==\"sum\"){\n            return $this->a + $this->b;\n        } elseif ($this->action==\"diff\") {\n            return $this->a - $this->b;\n        } else {\n            return null;\n        }\n    }\n\n   ...\n}\n\n\n\nZawiera ona wszystkie pola z tabeli poza identyfikatorem i czasem, które\nnadawane są podczas zapisu do bazy. Przez trzy kropki oznaczyłem wszystkie\ngettery i settery dla własności klasy. W większości IDE można je wygenerować\nautomatycznie, np.: w PhpStorm wybierając code->Generate.... Metoda getC pozwala\nwyliczyć wartość sumy lub różnicy po stronie serwera, co wykorzystane jest\npóźniej w interfejsie API.\n\nTeraz możemy przedstawić w całości wspomnianą wcześniej klasę DataBase, która\nsłużyła do zapisu danych otrzymanych ze strony do bazy.\n\n> php/DataBase.php\n\n\n<?php\n\nrequire_once __DIR__.\"/Log.php\";\nrequire_once __DIR__.\"/../vendor/mustangostang/spyc/Spyc.php\";\n\nclass DataBase\n{\n\tfunction save(Log $log){\n\n\t\t$a = $log->getA();\n\t\t$b = $log->getB();\n\t\t$s = $log->getAction();\n\t\t$u = $log->getAgent();\n\n\t\t// config from yml\n\t\t$config = Spyc::YAMLLoad(__DIR__.\"/../config/parameters.yml\")[\"config\"];\n\n\t\t// connecting\n\t\t$mysqli = @new mysqli($config[\"host\"], $config[\"user\"], $config[\"pass\"], $config[\"base\"], $config[\"port\"]);\n\n\t\t// test of connecting\n\t\tif ($mysqli -> connect_errno)\n\t\t{\n\t\t\t$code = $mysqli -> connect_errno;\n\t\t\t$mess = $mysqli -> connect_error;\n\t\t\tdie(\"Failed to connect to MySQL: ($code) $mess\\n\");\n\t\t}\n\n\t\t// definition of query\n\t\t$query  = 'INSERT INTO log VALUES(NULL,NOW(),?,?,?,?);';\n\n\t\t// preparing\n\t\t$stmt = @$mysqli -> prepare($query);\n\n\t\t// test of preparing\n\t\tif(!$stmt)\n\t\t{\n\t\t\t$code = $mysqli -> errno;\n\t\t\t$mess = $mysqli -> error;\n\t\t\t$mysqli -> close();\n\t\t\tdie(\"Failed to prepare statement: ($code) $mess\\n\");\n\t\t}\n\n\t\t// binding\n\t\t$bind = @$stmt -> bind_param(\"ddss\", $a, $b, $s, $u);\n\n\t\t// test of binding\n\t\tif(!$bind)\n\t\t{\n\t\t\t$stmt   -> close();\n\t\t\t$mysqli -> close();\n\t\t\tdie(\"Failed to bind param.\\n\");\n\t\t}\n\n\t\t// executing query\n\t\t$exec = @$stmt -> execute();\n\n\t\t// checking fails\n\t\tif(!$exec)\n\t\t{\n\t\t\t$stmt   -> close();\n\t\t\t$mysqli -> close();\n\t\t\tdie(\"Failed to execute prepare statement.\\n\");\n\t\t}\n\n\t\t// clearing and disconnecting\n\t\t$stmt   -> close();\n\t\t$mysqli -> close();\n\t}\n}\n\n\n\nKlasa ta nie ma własności, ma za to jedną metodę - save. Ta metoda pobiera\nobiekt Log i wykonuje logowanie do bazy danych wszystkich własności tego\nobiektu, przy czym dodaje jeszcze czas. Najciekawsza część tej klasy -\npobieranie konfiguracji była omówiona wcześniej. Reszta jest po prostu w zwykłym\nzapisem do bazy.\n\nTo były klasy, teraz czas na skrypt wejściowy back-endu naszej aplikacji.\nZnajduje się w pliku web/api.php i odpowiada za poprawne przechwycenie żądania,\npobranie parametrów, przekazanie ich bazie i oddanie odpowiedzi zawierającej\nwynik działania.\n\n<?php\n\n// error display\n//ini_set('display_errors', 1);\n//ini_set('display_startup_errors', 1);\n//error_reporting(E_ALL);\n\nrequire_once __DIR__.\"/../php/Log.php\";\nrequire_once __DIR__.\"/../php/DataBase.php\";\n\n// routing\nif($_SERVER['REQUEST_METHOD']==\"POST\"\n    && parse_url($_SERVER[\"REQUEST_URI\"])[\"path\"]==\"/api.php/action\"){\n\n    // get data from request\n    $log = new Log();\n    $log->setA($_POST[\"a\"]);\n    $log->setB($_POST[\"b\"]);\n    $log->setAction($_POST[\"action\"]);\n    $log->setAgent($_SERVER['HTTP_USER_AGENT']);\n\n    // connect to db and save data\n    $db = new DataBase();\n    $db->save($log);\n\n    // send response\n    header('Content-type: application/json');\n    echo json_encode([\n        \"a\"=>$log->getA(),\n        \"b\"=>$log->getB(),\n        \"c\"=>$log->getC(),\n        \"action\"=>$log->getAction()\n    ]);\n}\n\n\n\nTestowanie Api przez httpie\nMożemy przetestować nasze api wykorzystując httpie. Komenda\n\nhttp -fv 127.0.0.1:9000/api.php/action a=1 b=2 action=\"sum\"\n\n\n\npowinna wyprodukować następujący output:\n\nPOST /api.php/action HTTP/1.1\nAccept: */*\nAccept-Encoding: gzip, deflate\nConnection: keep-alive\nContent-Length: 18\nContent-Type: application/x-www-form-urlencoded; charset=utf-8\nHost: 127.0.0.1:9000\nUser-Agent: HTTPie/0.9.2\n\na=1&b=2&action=sum\n\nHTTP/1.1 200 OK\nConnection: close\nContent-type: application/json\nHost: 127.0.0.1:9000\nX-Powered-By: PHP/7.0.8-0ubuntu0.16.04.3\n\n{\n    \"a\": \"1\",\n    \"action\": \"sum\",\n    \"b\": \"2\",\n    \"c\": 3\n}\n\n\n\nAJAX\nKiedy mamy gotową bazę oraz skrypty do jej obsługiwania, nic nie stoi na\nprzeszkodzie dokończenia projektu przez napisanie frontu. Zakładamy, że\ninstalacja przebiegła pomyślnie i bower zainstalował potrzebne paczki - to\nznaczy \"bootstrap\": \"v4.0.0-alpha.5\" w katalogu web. Ponieważ jQuery jest\nzależnością dla Bootstrapa możemy z niej skorzystać przy tworzeniu skryptów.\n\nNasz front składa się z trzech plików: web/index.html, web/css/style.css i \nweb/js/site.js. Oto one:\n\n> web/index.html\n\n\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n    <title>Php calculator logging requests into database.</title>\n\n    <link rel=\"stylesheet\" href=\"bower_components/bootstrap/dist/css/bootstrap.min.css\">\n    <link href=\"https://fonts.googleapis.com/css?family=Lato:300\" rel=\"stylesheet\">\n    <link rel=\"stylesheet\" href=\"css/style.css\">\n  </head>\n  <body>\n\n    <section>\n      <div class=\"container\">\n        <div class=\"row\">\n          <div class=\"offset-md-3 col-md-6\">\n            <div class=\"card text-xs-center\">\n              <div class=\"card-header\">\n                Set two numbers and chose calculation\n              </div>\n              <div class=\"card-block\">\n                <div class=\"form-group\">\n                  <input id=\"a\" type=\"number\" step=\"any\" class=\"form-control\">\n                </div>\n                <div class=\"form-group\">\n                  <input id=\"b\" type=\"number\" step=\"any\" class=\"form-control\">\n                </div>\n\n                <div class=\"form-group row submit-area\">\n                  <div class=\"col-xs-6\">\n                    <input class=\"btn btn-lg btn-block hidden-xs-down btn-primary\" type=\"submit\" value='Sum' name=\"sum\">\n                    <input class=\"btn btn-lg btn-block hidden-sm-up btn-primary\" type=\"submit\" value='+' name=\"sum\">\n                  </div>\n                  <div class=\"col-xs-6\">\n                    <input class=\"btn btn-lg btn-block hidden-xs-down btn-danger\" type=\"submit\" value='Difference' name=\"diff\">\n                    <input class=\"btn btn-lg btn-block hidden-sm-up btn-danger\" type=\"submit\" value='-' name=\"diff\">\n                  </div>\n                </div>\n                <div class=\"form-group\">\n                  <input id=\"c\" type=\"text\" readonly step=\"any\" class=\"form-control\">\n                </div>\n\n              </div>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n    </section>\n\n\n    <nav class=\"navbar navbar-fixed-bottom navbar-light bg-faded\">\n      <a class=\"navbar-brand\" href=\"README.html\">Documentation</a>\n      <a class=\"navbar-brand float-xs-right\" href=\"http://gustawdaniel.pl\">Daniel Gustaw</a>\n    </nav>\n\n    <script src=\"bower_components/jquery/dist/jquery.min.js\"></script>\n    <script src=\"js/site.js\"></script>\n  </body>\n</html>\n\n\n\nStandardowy plik html. To co jest w nim ciekawego, to wykorzystanie klasy card z \nbootstrap 4 oraz zmiana napisów na przyciskach z pełnych nazw na znaki + i - \nprzy małych szerokościach ekranu.\n\nJeszcze prostsze są style naszej strony.\n\n> web/css/style.css\n\n\nbody {\n    font-family: 'Lato', 'SansSerif', serif;\n}\n\nsection {\n    margin-top: 20vh;\n}\n\n\n\nJest to zasługa Bootstrapa który naprawdę dużo potrafi odwzorować tak, jak bym\noczekiwał. Jedyne czego potrzebujemy to margines pionowy i czcionka.\n\nNajciekawsza część to JavaScript:\n\n> web/js/site.js\n\n\n(function () {\n\n    var submitArea = document.getElementsByClassName(\"submit-area\")[0];\n    var card = document.getElementsByClassName(\"card\")[0];\n    var a = document.getElementById(\"a\");\n    var b = document.getElementById(\"b\");\n    var c = document.getElementById(\"c\");\n\n    function round(value,dec=5) {\n        return 1*(Math.round(value+\"e+\"+dec)+\"e-\"+dec);\n    }\n\n    submitArea.addEventListener('click',function (e) {\n        if(e.target.name=='sum') {\n            c.value = round((a.value*1) + (b.value*1));\n        } else if(e.target.name=='diff') {\n            c.value = a.value - b.value;\n        }\n\n        $.post(\"api.php/action\", {a: a.value, b: b.value, c: c.value, action: e.target.getAttribute('name')}, function (data) {\n            console.log(data);\n        })\n    });\n\n})();\n\n\n\nCały zawarty jest w funkcji anonimowej, co zapewnia enkapsulację - nie mieszamy\nnaszych zmiennych z globalnymi. Struktura skryptu jest następująca. Najpierw\ndefiniujemy zmienne powiązane z elementami htmla, później umieszczamy funkcje\npomocnicze - u nas round, na koniec definiujemy listener.\n\nFunkcja round pozwala na zaokrąglanie obliczeń w JavaScript. Domyślna funkcja\nround z obiektu Math zawsze zaokrągla do liczb całkowitych. Wartość domyślna\nliczby miejsc po przecinku definiowana przez znak = jest stosunkowo nowym\nrozwiązaniem w JavaScript. Wnętrze funkcji pełnymi garściami czerpie z\ndynamicznego typowania i notacji naukowej do przedstawiania liczb w tym języku.\n\nZauważ, że ponieważ przyciski do liczenia sumy i różnycy występują podwójnie (ze\nwzględu na responsywność aplikacji), dopiero wewnątrz listenera musimy określić\nktóry z nich został wybrany. Jeśli jest to suma, mnożymy nasze wartości przez 1,\naby znak + oznaczał dodawanie, a nie konkatenację.\n\nNatychmiast po zidentyfikowaniu, który przycisk został wybrany, następuje\naktualizacja wyniku. Dopiero wtedy wysyłane jest żadnie POST co dzięki jQuery \njest wyjątkowo proste. Takie rozwiązanie ma zalety i wady. Zaletą jest szybkość,\nużytkownik nie musi czekać naodpowiedź z serwera. Wadą jest duplikacja logiki\nodpowiedzialnej za wykonywanie obliczeń. Nie trudno domyślić się, że z powodu\ninnych zaokrągleń wyniki przekazywane w odpowiedzi API będą mogły różnić się od\ntych wyświetlanych na stronie.\n\nBehat i Selenium\nBehat jest narzędziem do pisania behawioralnych testów automatycznych. Jest to\nnajbardziej naturalny dla człowieka sposób testowania oparty o historie, które\nmogą się wydażyć podczas korzystania z aplikacji. Selenium to serwer pozwalający\nsymulować przeglądarkę, wyposażony w programistyczne API. Łącząc te dwa\nnarzędzia otrzymujemy możliwość pisania czegoś w rodzaju bota odwiedzającego\nnaszą stronę i wykonującego określone akcje. To właśnie użycie tego narzędzia\nwidziałeś w video na początku wpisu.\n\nDzięki poleceniu vendor/bin/behat --init behat generuje domyślny plik \nfeatures/bootstrap/FeatureContext.php. Rozszerzymy tą klasę dodając do niej \nMinkContext. Jest to zbiór tłumaczeń między naturalnym językiem Gherkin a\nakcjami wykonywanymi przed drivery przeglądarki takie jak selenium.\n\nNapisałem o Gerkinie, że jest językiem naturalnym. W oficjalnej dokumentacji\n[https://github.com/cucumber/cucumber/wiki/Gherkin] jest przedstawiany\nnastępująco:\n\n> Gherkin is the language that Cucumber understands. It is a Business Readable,\nDomain Specific Language that lets you describe software’s behaviour without\ndetailing how that behaviour is implemented.\n\n\nPoza tym rozszerzeniem dodamy kilka funkcji, których brakuje w MinkConext\n\n> features/bootstrap/FeatureContext.php\n\n\n<?php\n\nuse Behat\\Behat\\Context\\Context;\nuse Behat\\Gherkin\\Node\\PyStringNode;\nuse Behat\\Gherkin\\Node\\TableNode;\nuse Behat\\MinkExtension\\Context\\MinkContext;\n\n/**\n * Defines application features from the specific context.\n */\nclass FeatureContext extends MinkContext implements Context\n{\n    /**\n     * Initializes context.\n     *\n     * Every scenario gets its own context instance.\n     * You can also pass arbitrary arguments to the\n     * context constructor through behat.yml.\n     */\n    public function __construct()\n    {\n    }\n\n    /**\n     * @param String $field\n     * @param String $value\n     * @Given I set :field as :value\n     */\n    public function iSetAs($field, $value)\n    {\n        $javascript = 'document.getElementById(\"'.$field.'\").value='.$value;\n        $this->getSession()->executeScript($javascript);\n    }\n\n    /**\n     * @Then Result should be :value\n     */\n    public function resultShouldBe($value)\n    {\n        $javascript = 'document.getElementById(\"c\").value';\n        $realResult = $this->getSession()->evaluateScript($javascript);\n\n        if ( $value !== $realResult) {\n            throw new Exception(\n                \"Actual result is:\\n\" . $realResult\n            );\n        }\n    }\n\n    /**\n     * @param String $number\n     * @When I wait :number ms\n     */\n    public function iWaitMs($number)\n    {\n        $this->getSession()->wait($number);\n    }\n\n    /**\n     * @param String $number\n     * @When I wait :number ms for jQuery\n     */\n    public function iWaitMsForJQuery($number)\n    {\n        $this->getSession()->wait($number, '(0 === jQuery.active)');\n    }\n}\n\n\n\nTe funkcje to ustawianie wartości pola, kiedy nie znajduje się ono w formulażu,\nsprawdzanie poprawności wyniku i czekanie: zwykłe, oraz pozwalające nie czekać\ndłużej jeśli wszystkie requesty zostały wykonane.\n\nMając przygotowany kontekst możemy przyjrzeć się zawartości pliku opisującego\ntesty\n\n> features/calculation.feature\n\n\nFeature: Executing calculations on the website\n  In order to calculate sum or difference\n  As an web browser\n  I want to see result after pressing button\n\n  @javascript\n  Scenario Outline: Action on two numbers\n    Given I am on the homepage\n    And I set \"a\" as <a>\n    And I set \"b\" as <b>\n    When I press \"<action>\"\n    And I wait 1000 ms for jQuery\n    Then Result should be <result>\n\n    Examples:\n      | a      | b       | action | result |\n      | 1      | 2       | sum    | 3      |\n      | 3      | 6       | sum    | 9      |\n      | 100    | 2000    | sum    | 2100   |\n      | -1.5   | -3.1    | sum    | -4.6   |\n      | 1.9990 | -0.0090 | sum    | 1.99   |\n      | 1      | 2       | diff   | -1     |\n      | -1     | -2      | diff   | 1      |\n      | 1.001  | 2.001   | diff   | -1     |\n      | 0.993  | 9.33    | diff   | -8.337 |\n      | 12     | -12     | diff   | 24     |\n\n\n\n\nZawiera on scenariusz składający się z 6 kroków powtórzyny w 10 konfiguracjach.\nTe kroki to typowe wykonywanie obliczeń na stronie - ustawienie, a, b wybranie\nprzycisku, czekanie na rezultat i sprawdzenie jego poprawności.\n\nŻeby wszystko zadziałało poprawnie brakuje jeszcze pliku konfiguracyjnego behata\n. Jest to behat.yml.\n\n> behat.yml\n\n\ndefault:\n  extensions:\n    Behat\\MinkExtension:\n      browser_name: chrome\n      base_url:  'http://localhost:9000'\n      sessions:\n        default:\n          goutte: ~\n        selenium:\n          selenium2: ~\n\n\n\nTo już wszystko. Jeśli prześledziłeś kod aż do tego momentu, znasz ten projekt\nna wylot. Mam nadzieję, że czegoś się nauczyłeś, a jeśli widzisz miejsca, gdzie\nmógł bym coś poprawić, śmiało daj mi znać. Będę wdzięczny za wszystkie\nkonstruktywne uwagi.",
            "feature_image": "__GHOST_URL__/content/images/2021/04/failedassertion.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T19:55:16.000Z",
            "updated_at": "2021-06-21T16:39:24.000Z",
            "published_at": "2021-04-26T20:03:00.000Z",
            "custom_excerpt": "Napiszemy prostą aplikację webową - kalkulator. Na jego przykładzie pokażemy jak skonfigurować selenium z behatem i wykonać na nim testy automatyczne.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f32492fb35425592d0b3e",
            "uuid": "d533f8db-9ac3-459d-969d-1b0b0deb7211",
            "title": "Wizualizacja dynamicznej sieci korelacyjnej.",
            "slug": "wizualizacja-dynamicznej-sieci-korelacyjnej",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Opis projektu\\n\\nPython jest językiem w którym można pisać nie znając go. Mimo, że nie znam Pythona napisałem w nim skrypt do obsługi serwera ubigraph - oprogramowania pozwalającego wizualizować grafy.\\n\\nProjekt powstał we wrześniu 2015 roku, zanim `ubigraph` [przestał być wspierany :(](https://twitter.com/SadieSv/status/716044022129659904). Mimo tego, że strona projektu nie jest dostępna, oprogramowanie napisane w oparciu o serwer `ubigraph` wciąż działa a sam plik z serwerem został dołączony do repozytorium.\\n\\nDzięki przeczytaniu tego artykułu zapoznasz się narzędziem do odczytu plików **json w bashu**, dowiesz się jak **definiować klasy i operować na tablicach w pythonie**, oraz zobaczysz jak bardzo pakiet **numpy** upraszcza obliczenia.\\n\\nSkład kodu źródłowego to:\\n\\n```\\nPython 90.1% Shell 9.9%\\n```\\n\\nPo napisaniu projekt będzie wyglądał tak:\"}],[\"embed\",{\"url\":\"https://www.youtube.com/watch?v=vGGNDG-0W6M\",\"html\":\"<iframe width=\\\"200\\\" height=\\\"113\\\" src=\\\"https://www.youtube.com/embed/vGGNDG-0W6M?feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\",\"metadata\":{\"title\":\"Dynamiczna sieć korelacyjna kilku spółek.\",\"author_name\":\"gustawdaniel\",\"author_url\":\"https://www.youtube.com/user/gustawdaniel\",\"height\":113,\"width\":200,\"version\":\"1.0\",\"provider_name\":\"YouTube\",\"provider_url\":\"https://www.youtube.com/\",\"thumbnail_height\":360,\"thumbnail_width\":480,\"thumbnail_url\":\"https://i.ytimg.com/vi/vGGNDG-0W6M/hqdefault.jpg\"}}],[\"markdown\",{\"markdown\":\"### Instalacja\\n\\nAby zainstalować projekt należy pobrać repozytorium\\n\\n```\\ngit clone https://github.com/gustawdaniel/dynamic_network_correaltion.git\\n```\\n\\nPrzejść do katalogu `dynamic_network_correaltion` i zainstalować projekt skryptem `install.sh`.\\n\\n```\\ncd dynamic_network_correaltion && bash install.sh\\n```\\n\\nPowinieneś zobaczyć nowe czarne okno o tytule `Ubigraph`. W nowym terminalu (`ctrl+n`) włącz skrypt `visualise.py`.\\n\\n```\\npython visualise.py\\n```\\n\\nKolejno wybieraj następujące opcje:\\n\\n```\\ntest ENTER ENTER ENTER ENTER ENTER\\n```\\n\\nW oknie `Ubigraph` powinieneś zobaczyć wizualizację dynamicznej sieci korelacyjnej.\\n\\n## Konfiguracja\\n\\nW tym rozdziale omówione są wszystkie kroki instalacji poza instalacją zależności.\\n\\nZaczniemy od pobrania danych z archiwum domu maklerskiego [bossa](http://bossa.pl). W ich [publicznym archiwum](http://bossa.pl/pub/) znajdują się pliki z notowaniami w formacie `mst` (odmiana `csv`) spakowane w archiwa `zip`. Wszystkie adresy interesujących nas plików zaczynają się od `http://bossa.pl/pub/`, ale mają różne końcówki. Zapisałem je w pliku konfiguracyjnym.\\n\\n> config/wget_data_config.json\\n\\n```json\\n{\\n  \\\"uri1\\\": \\\"http://bossa.pl/pub/\\\",\\n  \\\"data\\\": [\\n    {\\n      \\\"uri2\\\": \\\"metastock/mstock/mstall.zip\\\"\\n    },{\\n      \\\"uri2\\\": \\\"ciagle/mstock/mstcgl.zip\\\"\\n    },{\\n      \\\"uri2\\\": \\\"futures/mstock/mstfut.zip\\\"\\n    },{\\n      \\\"uri2\\\": \\\"newconnect/mstock/mstncn.zip\\\"\\n    },{\\n      \\\"uri2\\\": \\\"jednolity/f2/mstock/mstf2.zip\\\"\\n    },{\\n      \\\"uri2\\\": \\\"ciagle/mstock/mstobl.zip\\\"\\n    },{\\n      \\\"uri2\\\": \\\"indzagr/mstock/mstzgr.zip\\\"\\n    },{\\n      \\\"uri2\\\": \\\"waluty/mstock/mstnbp.zip\\\"\\n    },{\\n      \\\"uri2\\\": \\\"fundinwest/mstock/mstfun.zip\\\"\\n    },{\\n      \\\"uri2\\\": \\\"ofe/mstock/mstofe.zip\\\"\\n    },{\\n      \\\"uri2\\\": \\\"forex/mstock/mstfx.zip\\\"\\n    }\\n  ]\\n}\\n```\\n\\n### Pobranie archiwów (json w bashu)\\n\\nNaszym celem jest pobranie wszystkich plików o adresach składających się z `\\\"url1\\\".\\\"url2\\\"`. Będzie za to odpowiedzialny program `jq`, który pozwala na wydobywanie z pliku `json` wartości dla podanych kluczy. Przyjrzyjmy się pierwszej części skryptu do pobierania notowań:\\n\\n> wget_data.sh\\n\\n```bash\\n#!/bin/bash\\n\\n#\\n#   Definitions\\n#\\n\\n# catalogs structure\\nCONF=\\\"config/wget_data_config.json\\\";\\nRAW=\\\"raw\\\";\\n\\n# method allowing get data from config file\\nfunction getFromConf {\\n    echo $(cat $CONF | jq -r $1);\\n}\\n\\n# variables constant for all script\\nLINES=$(grep \\\\\\\"uri2\\\\\\\": $CONF | wc -l);\\nURI1=$(getFromConf '.uri1');\\n```\\n\\nZmienne `CONF` i `RAW` są jedynie statycznymi ścieżkami do pliku z konfiguracją oraz katalogu, gdzie dane mają zostać zapisane. Zmienna `LINES` pobiera ilość wystąpień ciągu `\\\"uri2\\\":` w pliku `json` co odpowiada liczbie linków które chcemy pobrać.\\n\\nFunkcja `getFromConf` pobiera z pliku konfiguracyjnego klucz określony w pierwszym parametrze z jakim ją wywołamy. Jej pierwsze zastosowanie widać przy definiowaniu zmiennej `URI1`. Przed nazwą klucza występuje kropka, a całość jest w pojedynczych cudzysłowach. To wystarczy. Kolejna część skryptu to pętla po liniach które zliczyliśmy.\\n\\n```bash\\n#\\n#   Script\\n#\\n\\n#clear raw catalog\\nrm $RAW/*\\n\\n# iterate over all lines\\nfor i in `seq 1 $LINES`\\ndo\\n    # downloading data from links from config\\n    wget $URI1$(getFromConf '.data['$i-1'].uri2') -P $RAW\\ndone\\n```\\n\\nPo wyczyszczeniu katalogu `raw` z dotychczasowej zawartości pętla pobiera linki do katalogu `raw`. Interesujący jest sposób w jaki w bashu przeprowadza się konkatenację - wystarczy postawić zmienne obok siebie. Tym razem klucz po którym wyszukujemy - `'.data['$i-1'].uri2'` jest bardziej skomplikowany, ale w pełni odpowiada naturalnej intuicji dotyczącej wyszukiwania w strukturze `json`.\\n\\n### Rozpakowywanie archiwów\\n\\nRozpakowanie archiwów sprowadza się do iterowania po katalogu `raw`. Standardowo definiujemy strukturę katalogów w zmiennych, czyścimy katalog `build`, i we wspomnianej pętli odczytujemy nazwę bez ścieżki i rozszerzenia, tworzymy katalog z taką nazwą, rozpakowujemy tam archiwum.\\n\\n> build_data.sh\\n\\n```bash\\n#!/usr/bin/env bash\\n\\n# catalogs structure\\nRAW=raw;\\nBUILD=build;\\n\\n# clear build for idempotency\\nrm -rf $BUILD/*;\\n\\n# loop over archives in raw\\nfor FILE in $RAW/*.zip\\ndo\\n#    create directory in build and unzip there file from raw\\n    NAME=$(basename $FILE .zip);\\n    echo $NAME;\\n    mkdir -p $BUILD/$NAME;\\n    unzip -q $FILE -d $BUILD/$NAME;\\ndone\\n\\n```\\n\\nOpcja `-q` w komendzie `unzip` pozwala ją wyciszyć.\\n\\n### Przygotowanie katalogu testowego\\n\\nJeśli spojrzymy na plik `install.sh` to poza instalacją zależności i przygotowaniem danych jest tam również przygotowanie testów.\\n\\n> install.sh\\n\\n```bash\\n# prepare test\\nmkdir -p test\\nrm -rf test/*\\ncp build/mstcgl/[A-D][A-D][A-D]* test/\\n\\n```\\n\\nTa komenda służy do wybrania notowań kilku przykładowych spółek i zapisania ich w katalogu `test`. Pozwala to na uproszczenie procedury włączania programu. W jego interfejsie wystarczy wskazać nazwę katalogu `test` aby pobrał on wszystkie pliki stamtąd. Jeśli chcesz zobaczyć wykresy dla innych spółek, zalecana jest właśnie taka metoda postępowania:\\n\\n1. Tworzymy katalog\\n2. Kopiujemy do niego wybrane pliki `mst`\\n3. Przy włączaniu wizualizacji podajemy nazwę tego katalogu i dwa razy `ENTER`.\\n\\n## Skrypt wykonujący wizualizację\\n\\nOmówimy teraz wszystkie części skryptu odpowiedzialnego z wizualizację sieci korelacyjnej. Zaczniemy od importów i nawiązanie połączenia z serwerem.\\n\\n> visualise.py\\n\\n```py\\n# -*- coding: utf-8 -*-\\n\\nimport os  # for loading files\\nimport datetime  # for time operations\\nimport numpy  # for calculation correlation\\n\\nimport xmlrpclib  # for visualise by ubigraph\\nimport time  # for waiting between steps\\n\\n#  connect to server displaying image\\nserver_url = 'http://127.0.0.1:20738/RPC2'\\nserver = xmlrpclib.Server(server_url)\\nG = server.ubigraph\\n\\nG.clear()  # clear image before start\\n\\n```\\n\\nŁadowane paczki pozwalają nam operować na plikach, czasie, wykonywać obliczenia, łączyć się z serwerem `ubigraph` oraz zatrzymywać program na określoną jednostkę czasu. Po załadowaniu paczek następuje nawiązanie połączenia z serwerem i wyczyszczenie jego okna.\\n\\n### Klasy\\n\\nNastępną częścią skryptu jest klasa z konfiguracją.\\n\\n```py\\n##################################################################\\n#                          Configuration                         #\\n##################################################################\\n\\nclass Config:\\n    def __init__(self):\\n        self.state = 1\\n\\n    # weights of open, highest, lowest and close price for calculating correlation\\n    op = 0.25\\n    hi = 0.25\\n    lo = 0.25\\n    cl = 0.25\\n\\n    free_mem = 1  # option for free memory\\n\\n    sleep = 0.001  # time of sleeping between steps\\n    memory = 100  # How many days before actual data should be taken in correlation?\\n    # boundary = 0 #\\n    boundary = 0.7  # correlation boundary between showed and hidden connection in graph\\n\\n\\nconfig = Config()\\n\\n```\\n\\nNie ma ona żadnej metody, a zmienne w niej przechowywane są publiczne. Służy więc ona jedynie jako kontener na te wartości, aby nie zaśmiecać globalnej przestrzeni nazw. Zmienne `op`, `hi`, `lo`, `cl` są to wagi z jakimi ceny otwarcia, najwyższa, najniższa i zamknięcia dla danego instrumentu w konkretnym dniu wchodzą do obliczania korelacji. Ustawienie ich na `0.25` oznacza liczenie zwykłej średniej. Jeśli chcieli byśmy, aby korelacja liczona była tylko dla cen zamknięcia powinniśmy ustawić wszystkie oprócz `cl` na `0`, a `cl` na `1`.\\n\\nZmienna `free_mem` posłuży nam później jako znacznik przy zwalnianiu pamięci. `sleep` jest to czas oczekiwania między kolejnymi iteracjami podany w sekundach. Iteracje oznaczają przechodzenie o 1 dzień w historii. W zmiennej `memory` trzymany jest zakres dni jakie mają być brane do obliczania korelacji, są to zawsze dni przed dniem dla którego obliczamy korelację. Ostatnia zmienna - `boundary` - jest wartością graniczną korelacji dla której połączenia są dodawane lub usuwane. Jeśli korelacje będzie wyższa niż wartość tej zmiennej, to podczas wizualizacji pojawi się połączenia, jeśli niższa, to zniknie.\\n\\nTa klasa była jedynie odpowiednikiem struktury w `Pascalu`. Teraz czas na bardziej \\\"obiektową\\\" klasę.\\n\\n```py\\n##################################################################\\n#                          Definitions                           #\\n##################################################################\\n\\nclass Company:\\n    \\\"\\\"\\\"Company contains info about company needed to calculations\\\"\\\"\\\"\\n\\n    def __init__(self, filename):\\n        self.filename = filename\\n        self.dates = []\\n        self.prices = []\\n\\n        self.prices_evryday = []  # table used instead dates and prices after assigning time of simulation\\n\\n        self.vertex_id = Company.vertex_id\\n        Company.vertex_id += 1\\n\\n    vertex_id = 0\\n    min_date = 0\\n    max_date = 0\\n    name = ''\\n\\n    def debug_print(self):\\n        print \\\"name: \\\", self.name\\n        print \\\"filename: \\\", self.filename\\n        print \\\"vertex: \\\", self.vertex_id\\n        print \\\"min_date: \\\", self.min_date\\n        print \\\"max_date: \\\", self.max_date\\n        print \\\"max price: \\\", max(self.prices)\\n        print \\\"min price: \\\", min(self.prices)\\n\\n    def in_range(self, date):  # czy date jest w zakresie\\n        if self.min_date < date < self.max_date:\\n            return 1\\n        else:\\n            return 0\\n\\n```\\n\\nKlasa `Company` zawiera informacje o firmie potrzebne do obliczeń. Dokładnie tak jak sama o sobie mówi. Jej konstruktor przyjmuje nazwę pliku i automatycznie inkrementuje swoje `vertex_id`. Jej pierwsza metoda służy do wyświetlania informacji o klasie. Nie jest przydatna dla użytkownika, ale świetnie sprawdza się podczas pisania kodu. Druga metoda `in_range` sprawdza czy dana spółka jest notowana w czasie określonym w jej argumencie. Będzie to często wykorzystywane ze względu na to, że radzenie sobie z lukami w danych wejściowych stanowią dużą część tego kodu.\\n\\n### Interfejs i przygotowanie danych\\n\\nPo definicji klas możemy przejść do interfejsu użytkownika.\\n\\n```py\\n        ##################################################################\\n        #                          Interface                             #\\n        ##################################################################\\n\\nprint \\\"Select files with input data\\\"\\n\\ni = 1\\npaths = []\\nwhile 1:\\n    path = raw_input(\\\"Get path to files \\\" + str(i) + \\\", or ENTER to finish: \\\")\\n    if len(path) == 0:\\n        break\\n    i += 1\\n    paths.append(path)\\n    print path, len(path), paths\\n\\nif len(paths) == 0:  # if error\\n    print \\\"\\\\nYou do not chosen enough number of files.\\\\nRead docs or contact with author: gustaw.daniel@gmial.com.\\\\n\\\"\\n    exit()\\n\\ndirectory = ''\\nif len(paths) == 1:  # catalog\\n    directory = paths[0]\\n    print \\\"Loading from catalog :\\\" + str(directory)\\n    paths = os.listdir(directory)  # names of files\\n\\nelse:\\n    print \\\"Loading given files:\\\"\\n\\n```\\n\\nInterfejs jest trochę wymieszany z logiką i jestem pewien, że dało by się napisać to ładniej, ale jak wspomniałem - nie umiem Pythona, więc jeśli w tym miejscu masz jakieś uwagi, albo pomysły, jak lepiej można by to napisać, podziel się tym w komentarzu.\\n\\nGeneralnie celem tego kawałka kodu było udostępnienie użytkownikowi możliwości wybrania katalogu, bądź listy poszczególnych plików, jednak ta druga opcja okazała się mało praktyczna, bo wygodniej było przygotować katalog i wpisać jego nazwę, niż wprowadzać nazwy ręcznie. W tym momencie jest to jedyna zalecana forma wprowadzania plików do programu.\\n\\n```py\\n##################################################################\\n#                     Loading list of files                      #\\n##################################################################\\n\\ncompanies = []  # empty list of companies\\n\\nfiles_content = []  # empty content of files\\nfor path in paths:  # for any path\\n    files_content.append(open(str(directory) + '/' + str(path), 'r').readlines())\\n    company = Company(path)  # create company\\n    companies.append(company)  # append to companies list\\n    print paths.index(path), path\\n\\nprint \\\"Processing files\\\"\\n\\n```\\n\\nKiedy użytkownik określi jakie pliki mają być wczytane, następuje ładowanie ich zawartości za pomocą funkcji `open` i jej metody `readlines`. Dla każdej ścieżki do pliku tworzona jest instancja `Company` i dołączana to tablicy z firmami (lub bardziej ogólnie instrumentami finansowymi).  \\n\\nJeśli byśmy przyjrzeli się strukturze pliku `mst` to jest ona następująca:\\n\\n```csv\\n<TICKER>,<DTYYYYMMDD>,<OPEN>,<HIGH>,<LOW>,<CLOSE>,<VOL>\\n01CYBATON,20080415,4.48,4.48,3.76,4.08,13220\\n01CYBATON,20080416,4.24,4.24,3.84,4.16,1120\\n01CYBATON,20080417,4.08,4.40,4.08,4.08,7600\\n           ...\\n\\n```\\n\\nPonieważ nagłówki nie są nam potrzebne przy obliczeniach odcinamy je z każdej tablicy zawierającej line `file_content`.\\n\\n```py\\nprint \\\"Cutting headers\\\"\\n\\nfor file_content in files_content:  # removing headers\\n    file_content.pop(0)\\n\\n```\\n\\nNadal jednak występuje tam duży nadmiar danych. Przede wszystkim nazwy spółki się powtarzają, daty są w trudnym do przetwarzania formacie, volumeny wcale nie są nam potrzebne, a zamiast cen otwarcia, najwyższej, najniższej i zamknięcia potrzebujemy jednej ceny z której będzie liczona korelacja.\\n\\nŻeby pozbyć się tych danych tworzymy dwie tablice - z datami i cenami.\\n\\n```py\\ndate = []\\nprice = []\\n\\nmin_date = 99999999999  # searching min and max date common for companies\\nmax_date = 0\\n\\nepoch = datetime.datetime.utcfromtimestamp(0)\\n\\n```\\n\\nZmienne `max_date` i `min_date` pozwolą nam wybrać ograniczenia zakresu dat w jakich możemy wizualizować. Od razu wspomnę o ograniczeniach. Wizualizacja nie może kończyć się przed 1 stycznia 1970 ponieważ ten dzień jest początkiem odliczania czasu w sekundach w systemach uniksowych. No i nie może zaczynać się za `min_date` dni. Nie jest to eleganckie rozwiązanie, ale z praktycznego punktu widzenia to ponad 200 tysięcy lat, więc mimo, że nie jest ładne, działa dobrze.\\n\\n```py\\n##################################################################\\n#           Loading files to memory                              #\\n##################################################################\\n\\nprint \\\"Saving content\\\"\\n\\nfor i in range(0, len(files_content)):  # for any file\\n    for line in files_content[i]:  # get line\\n        l = line.rstrip().split(',')  # split by coma\\n        date.append((datetime.datetime.strptime(l[1], \\\"%Y%m%d\\\").date() - epoch.date()).days)\\n        # append date in days form epoch to date array\\n        price.append(round(\\n            float(l[2]) * config.op +\\n            float(l[3]) * config.hi +\\n            float(l[4]) * config.lo +\\n            float(l[5]) * config.cl, 4))\\n        # and price as mean with proper weights to price array\\n    min_date = min(min_date, date[0])  # if there was no date before this one, set this date there\\n    max_date = max(max_date, date[-1])  # and in similar way set latest date\\n\\n    companies[i].name = l[0]\\n    companies[i].dates = date\\n    companies[i].prices = price\\n    companies[i].min_date = date[0]\\n    companies[i].max_date = date[-1]\\n\\n    date = []\\n    price = []\\n    print i + 1, \\\"/\\\", len(files_content)\\n\\nif config.free_mem:\\n    files_content = []\\n\\n```\\n\\nTen kawałek kodu odpowiada za wyłuskanie jednej ceny zamiast czterech i konwersję daty na datę w dniach od 1 stycznia 1970. Tablice z tymi tylko wartościami zapisywane są do zmiennych tymczasowych `price` i `date`, a później do tablicy klas `Company`. Przy tej okazji oblizane są początkowa i końcowa data dla każdej ze spółek oraz najszerszy możliwy zakres dat zapisywany jest w `min_date` i `max_date`. Domyślnie na końcu tej operacji czyścimy pamięć ze zmiennej `files_content`.\\n\\nPrzyszedł czas na ostatni kawałek interakcji z użytkownikiem. Określił on już pliki wejściowe. Program zbadał i przetworzył ich zawartość. Nadszedł czas, żeby użytkownik zdecydował, jaki okres historyczny chce obserwować.\\n\\n```py\\n##################################################################\\n#           Selecting time of simulation                         #\\n##################################################################\\n\\nprint \\\"Selecting time of visualisation: \\\"\\nprint \\\"Time given is in days from 01.01.1970\\\"\\nprint \\\"Company name         start of date      end of data\\\"\\nmin_max = max_date\\nmax_min = min_date\\nfor company in companies:\\n    min_max = min(min_max, company.max_date)\\n    max_min = max(max_min, company.min_date)\\n    print repr(company.name).ljust(25), repr(company.min_date).ljust(20), repr(company.max_date).ljust(20)\\nprint \\\"Union (at least one company on stock): \\\", min_date, max_date\\nprint \\\"Intersection (all companies on stock): \\\", max_min, min_max\\n\\nmin_user = raw_input(\\\"Set first day of simulation, ENTER - Intersection: \\\")\\nif len(min_user) == 0:\\n    min_user = max_min\\nelse:\\n    min_user = int(min_user)\\nmax_user = raw_input(\\\"Set last day of simulation, ENTER - Intersection: \\\")\\nif len(max_user) == 0:\\n    max_user = min_max\\nelse:\\n    max_user = int(max_user)\\nmemory = raw_input(\\\"Set range of calculating correlation, ENTER - 100: \\\")\\nif len(memory) == 0:\\n    memory = config.memory\\nelse:\\n    memory = int(memory)\\n\\n```\\n\\nPo wyjaśnieniu użytkownikowi jednostek w jakich podawane są daty, skrypt oblicza sumę i iloczyn mnogościowy wszystkich przedziałów czasowych, jakie odpowiadają czasom notowania wprowadzonych spółek. Domyślnie symulacja następuje dla okresu w którym wszystkie spółki są notowane jednocześnie, ale użytkownik ma możliwość samodzielnego decydowania o tym okresie. Ostatnią zmienną o jaką pytamy użytkownika jest zakres czasu w jakim korelacja będzie obliczana.\\n\\nPozostały jeszcze parametry jakie jak graniczna wartość korelacji między pojawianiem się a znikaniem połączeń, czas czekania między kolejnymi krokami. Aby nie czynić interfejsu zbyt męczącym (i tak domyślnie klikamy enter aż 5 razy) pozostawiłem te wartości jako domyślne. Kod skryptu jest jawny, więc osoba zainteresowana łatwo sobie może je zmienić.\\n\\n### Obliczanie interpolacji i korelacji cen\\n\\nPrzejdźmy teraz do obliczeń.\\n\\n```py\\n##################################################################\\n#                    Interpolation of prices                     #\\n##################################################################\\n\\nprint \\\"Prices are interpolated\\\"\\n\\n# print \\\"min memm, max \\\",min_user, memory, max_user\\n\\nfor company in companies:\\n    for date in range(min_user - memory, max_user):\\n        if company.in_range(date):\\n            price = round(numpy.interp(date, company.dates, company.prices), 4)\\n        else:\\n            price = 0\\n        company.prices_evryday.append(price)\\n    print repr(company.vertex_id + 1).ljust(3), \\\"/\\\", repr(Company.vertex_id).ljust(6), repr(company.name).ljust(20)\\n    if config.free_mem:  # free memory\\n        company.dates = []\\n        company.prices = []\\n\\n```\\n\\nKolejny problem do pokonania, to brak ciągłości notować. Są dni, kiedy giełada jest zamknięta. Żeby sobie z tym poradzić w klasie `Company` oprócz tablicy `prices` jest też tablica `prices_everyday`. Do niej wpisywane są ceny interpolowane ze wszystkich cen i wszystkich dat. Jeśli firma nie jest notowana, do tablicy `prices_everyday` zapisywane jest `0`. W ten sposób radzimy sobie z nierówną długością okresów notowań w danych wejściowych. Po wykonaniu tej operacji tablice z danymi i cenami nie są już potrzebne. Możemy je śmiało usunąć. Jeśli z jakichś powodów nie chcieli byśmy tego robić możemy ustawić parametr `free_mem` na `0`. Domyślnie jednak czyścimy pamięć z tych danych.\\n\\nMając dane w formie wygodnej do przeprowadzania obliczeń możemy wyliczyć korelacje. Tak jak przy interpolacji, pomoże nam pakiet **numpy**.\\n\\n```py\\n##################################################################\\n#                    Calculation of correlations                 #\\n##################################################################\\n\\nprint \\\"Calculating of correlation\\\"\\n\\ncorr = []\\nline = []\\ncorrelations = []  # Huge layer matrix with any correlations,\\n\\nnumpy.seterr(divide='ignore', invalid='ignore')  # ignoring of warnings that we get\\n# calculating correlation on identical lists\\n\\nfor date in range(0, max_user - min_user):\\n    corr = numpy.corrcoef([company.prices_evryday[date:date + memory] for company in companies])\\n    correlations.append(corr)\\n\\n```\\n\\nWarto zauważyć, że tablica `company.prices_everyday` zaczyna się w chwili czasu `min_user - memory`, to znaczy `memory` dni wcześniej niż przebiega symulacjia. Z tego względu pętla do obliczania korelacji zaczyna się od `0` a kończy na `max_user-min_user` czyli `memory` indeksów przed skończeniem tablicy `company.prices_everyday`. Dla każdego kroku pętli obliczamy korelacje od indeksu bierzącego do wyprzedzającgo go o wartość `memory`.\\n\\nWewnątrz argumentu funkcji obliczającej korelację iterujemy po wszystkich firmach. Należy przyznać, że skaładnia `pythona` jest tu bardzo zwięzła, pozostając jednocześnie całkiem czytelną.\\n\\nProduktem tego kroku jest warstwowa macież korelacji, do którj będziemy się odwoływać do końca programu.\\n\\n### Obsługa serwera Unigraph\\n\\nNa tym w zasadzie kończą się obliczenia i następne fragmenty kodu będą związane z obsługą `unigraph`.\\n\\n```py\\n##################################################################\\n#                  Creating matrix of connections                #\\n##################################################################\\n\\nprint \\\"Initialisation of matrix of connection\\\"\\n\\ne = [[0 for x in range(Company.vertex_id)] for y in range(Company.vertex_id)]  # matrix of connections\\n\\n```\\n\\nNa początku inicjalizujemy pustą macież połączeń reprezentujących występowanie lub brak korelacji między notowaniami instrumentów finansowych.\\n\\n```py\\n##################################################################\\n#              Creation of initial vertexes                      #\\n##################################################################\\n\\n\\nfor ind in range(0, Company.vertex_id):\\n    if companies[ind].prices_evryday[0] != 0:\\n        G.new_vertex_w_id(ind)\\n        G.set_vertex_attribute(ind, 'label', companies[ind].name)\\n\\n```\\n\\nTworzymy wierzchołki dla firm notowanych od początku i nadajemy im nazwy firma jako opisy.\\n\\n```py\\n##################################################################\\n#              Creation initial connections                      #\\n##################################################################\\n\\nfor ind1 in range(0, Company.vertex_id):\\n    for ind2 in range(ind1 + 1, Company.vertex_id):\\n        if correlations[0][ind1][ind2] >= config.boundary:\\n            e[ind1][ind2] = G.new_edge(ind1, ind2)\\n\\n```\\n\\nIterujemy po trójkątnej macieży połączeń między firmami dodając połaczenia jeśli początkowe korelacje przekraczają graniczną wartoś ustaloną w konfiguracji. I na końcu przeprowadzamy symulację:\\n\\n```py\\n##################################################################\\n#      Visualization of dynamic correlation network              #\\n##################################################################\\n\\n# for any time\\nfor x in range(1, len(correlations)):\\n    # for any company\\n    for ind1 in range(0, Company.vertex_id):\\n        # if company starts be noted, create them\\n        if companies[ind1].prices_evryday[x - 1] == 0 and companies[ind1].prices_evryday[x] != 0:\\n            G.new_vertex_w_id(ind1)\\n            G.set_vertex_attribute(ind1, 'label', companies[ind1].name)\\n            print x, \\\" (a):v \\\", ind1\\n        # for any company with index higher than last one\\n        for ind2 in range(ind1 + 1, Company.vertex_id):\\n            # if connection occurs, add this\\n            if correlations[x - 1][ind1][ind2] < config.boundary <= correlations[x][ind1][ind2]:\\n                e[ind1][ind2] = G.new_edge(ind1, ind2)\\n                print x, \\\" (a):e \\\", ind1, ind2\\n            # if connection vanishes, delete this\\n            if correlations[x - 1][ind1][ind2] >= config.boundary > correlations[x][ind1][ind2]:\\n                G.remove_edge(e[ind1][ind2])\\n                print x, \\\" (r):e \\\", ind1, ind2\\n            time.sleep(config.sleep)\\n        if companies[ind1].prices_evryday[x - 1] != 0 and companies[ind1].prices_evryday[x] == 0:\\n            G.remove_vertex(ind1)\\n            print x, \\\" (r):v \\\", ind1\\n\\n```\\n\\nMimo, że to tu wykonuje się najważniejsza część kodu, zajmuje on stosunkowo mało miejsca. W tej pętli iterującej po dniach (a właściwie indeksach, które przypisaliśmy dniom) wykonywana jest pęta po wszystkich firmach. W niej sprawdzamy, czy firma zaczyna być notowana i jeśli tak, dodajemy ją do wizualizacji. Ponownie zagnieżdżamy pętlę po firmach dbając o unikanie powtórzeń. Jeśli korelacja przekroczyła granicę schodząc w dół - usówamy połączenie, jeśliw górę dodajemy. Czekamy chwilę, żeby użytkownik nacieszył oko. Na koniec jeśli firma skończyła notowanie na giełdzie usówamy jej wierzchołek.\\n\\n## Podsumowanie\\n\\nTo wszystko. Wisienka na torcie okazła się być kilkoma linijkami gęstego kodu w porównaniu do setek linii, które walczyły o to by poznać intencje użytkownika i z danych wejściowych wyłuskać struturę wygodną do przeprowadzenia obliczeń.\\n\\nJest to niestety poważny problem całej branży analizy danych. W wielu przypadkach dane wejściowe są na tyle nie wygodne, że ich przekształcenie do porządanej postaci kosztuje nas więcej wysiłku niż samo wykonanie ich analizy.\\n\\nJednak sytuacja się polepsza. Coraz cześciej spotykane `API`, oraz wzrost popularności formatu `json` który wypiera powoli `xml` i `csv` są krokami w dobrym kierunku i ułatwiają pracę z danymi.\\n\\n![popularność json, xml, csv](http://i.imgur.com/OyhoigO.png)\\n\\nJak zawsze zachęcam do komentowania, wyrażania wątpliwości i zadawania pytań.\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"opis-projektu\">Opis projektu</h2>\n<p>Python jest językiem w którym można pisać nie znając go. Mimo, że nie znam Pythona napisałem w nim skrypt do obsługi serwera ubigraph - oprogramowania pozwalającego wizualizować grafy.</p>\n<p>Projekt powstał we wrześniu 2015 roku, zanim <code>ubigraph</code> <a href=\"https://twitter.com/SadieSv/status/716044022129659904\">przestał być wspierany :(</a>. Mimo tego, że strona projektu nie jest dostępna, oprogramowanie napisane w oparciu o serwer <code>ubigraph</code> wciąż działa a sam plik z serwerem został dołączony do repozytorium.</p>\n<p>Dzięki przeczytaniu tego artykułu zapoznasz się narzędziem do odczytu plików <strong>json w bashu</strong>, dowiesz się jak <strong>definiować klasy i operować na tablicach w pythonie</strong>, oraz zobaczysz jak bardzo pakiet <strong>numpy</strong> upraszcza obliczenia.</p>\n<p>Skład kodu źródłowego to:</p>\n<pre><code>Python 90.1% Shell 9.9%\n</code></pre>\n<p>Po napisaniu projekt będzie wyglądał tak:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/vGGNDG-0W6M?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><!--kg-card-begin: markdown--><h3 id=\"instalacja\">Instalacja</h3>\n<p>Aby zainstalować projekt należy pobrać repozytorium</p>\n<pre><code>git clone https://github.com/gustawdaniel/dynamic_network_correaltion.git\n</code></pre>\n<p>Przejść do katalogu <code>dynamic_network_correaltion</code> i zainstalować projekt skryptem <code>install.sh</code>.</p>\n<pre><code>cd dynamic_network_correaltion &amp;&amp; bash install.sh\n</code></pre>\n<p>Powinieneś zobaczyć nowe czarne okno o tytule <code>Ubigraph</code>. W nowym terminalu (<code>ctrl+n</code>) włącz skrypt <code>visualise.py</code>.</p>\n<pre><code>python visualise.py\n</code></pre>\n<p>Kolejno wybieraj następujące opcje:</p>\n<pre><code>test ENTER ENTER ENTER ENTER ENTER\n</code></pre>\n<p>W oknie <code>Ubigraph</code> powinieneś zobaczyć wizualizację dynamicznej sieci korelacyjnej.</p>\n<h2 id=\"konfiguracja\">Konfiguracja</h2>\n<p>W tym rozdziale omówione są wszystkie kroki instalacji poza instalacją zależności.</p>\n<p>Zaczniemy od pobrania danych z archiwum domu maklerskiego <a href=\"http://bossa.pl\">bossa</a>. W ich <a href=\"http://bossa.pl/pub/\">publicznym archiwum</a> znajdują się pliki z notowaniami w formacie <code>mst</code> (odmiana <code>csv</code>) spakowane w archiwa <code>zip</code>. Wszystkie adresy interesujących nas plików zaczynają się od <code>http://bossa.pl/pub/</code>, ale mają różne końcówki. Zapisałem je w pliku konfiguracyjnym.</p>\n<blockquote>\n<p>config/wget_data_config.json</p>\n</blockquote>\n<pre><code class=\"language-json\">{\n  &quot;uri1&quot;: &quot;http://bossa.pl/pub/&quot;,\n  &quot;data&quot;: [\n    {\n      &quot;uri2&quot;: &quot;metastock/mstock/mstall.zip&quot;\n    },{\n      &quot;uri2&quot;: &quot;ciagle/mstock/mstcgl.zip&quot;\n    },{\n      &quot;uri2&quot;: &quot;futures/mstock/mstfut.zip&quot;\n    },{\n      &quot;uri2&quot;: &quot;newconnect/mstock/mstncn.zip&quot;\n    },{\n      &quot;uri2&quot;: &quot;jednolity/f2/mstock/mstf2.zip&quot;\n    },{\n      &quot;uri2&quot;: &quot;ciagle/mstock/mstobl.zip&quot;\n    },{\n      &quot;uri2&quot;: &quot;indzagr/mstock/mstzgr.zip&quot;\n    },{\n      &quot;uri2&quot;: &quot;waluty/mstock/mstnbp.zip&quot;\n    },{\n      &quot;uri2&quot;: &quot;fundinwest/mstock/mstfun.zip&quot;\n    },{\n      &quot;uri2&quot;: &quot;ofe/mstock/mstofe.zip&quot;\n    },{\n      &quot;uri2&quot;: &quot;forex/mstock/mstfx.zip&quot;\n    }\n  ]\n}\n</code></pre>\n<h3 id=\"pobranie-archiw%C3%B3w-json-w-bashu\">Pobranie archiwów (json w bashu)</h3>\n<p>Naszym celem jest pobranie wszystkich plików o adresach składających się z <code>&quot;url1&quot;.&quot;url2&quot;</code>. Będzie za to odpowiedzialny program <code>jq</code>, który pozwala na wydobywanie z pliku <code>json</code> wartości dla podanych kluczy. Przyjrzyjmy się pierwszej części skryptu do pobierania notowań:</p>\n<blockquote>\n<p>wget_data.sh</p>\n</blockquote>\n<pre><code class=\"language-bash\">#!/bin/bash\n\n#\n#   Definitions\n#\n\n# catalogs structure\nCONF=&quot;config/wget_data_config.json&quot;;\nRAW=&quot;raw&quot;;\n\n# method allowing get data from config file\nfunction getFromConf {\n    echo $(cat $CONF | jq -r $1);\n}\n\n# variables constant for all script\nLINES=$(grep \\&quot;uri2\\&quot;: $CONF | wc -l);\nURI1=$(getFromConf '.uri1');\n</code></pre>\n<p>Zmienne <code>CONF</code> i <code>RAW</code> są jedynie statycznymi ścieżkami do pliku z konfiguracją oraz katalogu, gdzie dane mają zostać zapisane. Zmienna <code>LINES</code> pobiera ilość wystąpień ciągu <code>&quot;uri2&quot;:</code> w pliku <code>json</code> co odpowiada liczbie linków które chcemy pobrać.</p>\n<p>Funkcja <code>getFromConf</code> pobiera z pliku konfiguracyjnego klucz określony w pierwszym parametrze z jakim ją wywołamy. Jej pierwsze zastosowanie widać przy definiowaniu zmiennej <code>URI1</code>. Przed nazwą klucza występuje kropka, a całość jest w pojedynczych cudzysłowach. To wystarczy. Kolejna część skryptu to pętla po liniach które zliczyliśmy.</p>\n<pre><code class=\"language-bash\">#\n#   Script\n#\n\n#clear raw catalog\nrm $RAW/*\n\n# iterate over all lines\nfor i in `seq 1 $LINES`\ndo\n    # downloading data from links from config\n    wget $URI1$(getFromConf '.data['$i-1'].uri2') -P $RAW\ndone\n</code></pre>\n<p>Po wyczyszczeniu katalogu <code>raw</code> z dotychczasowej zawartości pętla pobiera linki do katalogu <code>raw</code>. Interesujący jest sposób w jaki w bashu przeprowadza się konkatenację - wystarczy postawić zmienne obok siebie. Tym razem klucz po którym wyszukujemy - <code>'.data['$i-1'].uri2'</code> jest bardziej skomplikowany, ale w pełni odpowiada naturalnej intuicji dotyczącej wyszukiwania w strukturze <code>json</code>.</p>\n<h3 id=\"rozpakowywanie-archiw%C3%B3w\">Rozpakowywanie archiwów</h3>\n<p>Rozpakowanie archiwów sprowadza się do iterowania po katalogu <code>raw</code>. Standardowo definiujemy strukturę katalogów w zmiennych, czyścimy katalog <code>build</code>, i we wspomnianej pętli odczytujemy nazwę bez ścieżki i rozszerzenia, tworzymy katalog z taką nazwą, rozpakowujemy tam archiwum.</p>\n<blockquote>\n<p>build_data.sh</p>\n</blockquote>\n<pre><code class=\"language-bash\">#!/usr/bin/env bash\n\n# catalogs structure\nRAW=raw;\nBUILD=build;\n\n# clear build for idempotency\nrm -rf $BUILD/*;\n\n# loop over archives in raw\nfor FILE in $RAW/*.zip\ndo\n#    create directory in build and unzip there file from raw\n    NAME=$(basename $FILE .zip);\n    echo $NAME;\n    mkdir -p $BUILD/$NAME;\n    unzip -q $FILE -d $BUILD/$NAME;\ndone\n\n</code></pre>\n<p>Opcja <code>-q</code> w komendzie <code>unzip</code> pozwala ją wyciszyć.</p>\n<h3 id=\"przygotowanie-katalogu-testowego\">Przygotowanie katalogu testowego</h3>\n<p>Jeśli spojrzymy na plik <code>install.sh</code> to poza instalacją zależności i przygotowaniem danych jest tam również przygotowanie testów.</p>\n<blockquote>\n<p>install.sh</p>\n</blockquote>\n<pre><code class=\"language-bash\"># prepare test\nmkdir -p test\nrm -rf test/*\ncp build/mstcgl/[A-D][A-D][A-D]* test/\n\n</code></pre>\n<p>Ta komenda służy do wybrania notowań kilku przykładowych spółek i zapisania ich w katalogu <code>test</code>. Pozwala to na uproszczenie procedury włączania programu. W jego interfejsie wystarczy wskazać nazwę katalogu <code>test</code> aby pobrał on wszystkie pliki stamtąd. Jeśli chcesz zobaczyć wykresy dla innych spółek, zalecana jest właśnie taka metoda postępowania:</p>\n<ol>\n<li>Tworzymy katalog</li>\n<li>Kopiujemy do niego wybrane pliki <code>mst</code></li>\n<li>Przy włączaniu wizualizacji podajemy nazwę tego katalogu i dwa razy <code>ENTER</code>.</li>\n</ol>\n<h2 id=\"skrypt-wykonuj%C4%85cy-wizualizacj%C4%99\">Skrypt wykonujący wizualizację</h2>\n<p>Omówimy teraz wszystkie części skryptu odpowiedzialnego z wizualizację sieci korelacyjnej. Zaczniemy od importów i nawiązanie połączenia z serwerem.</p>\n<blockquote>\n<p>visualise.py</p>\n</blockquote>\n<pre><code class=\"language-py\"># -*- coding: utf-8 -*-\n\nimport os  # for loading files\nimport datetime  # for time operations\nimport numpy  # for calculation correlation\n\nimport xmlrpclib  # for visualise by ubigraph\nimport time  # for waiting between steps\n\n#  connect to server displaying image\nserver_url = 'http://127.0.0.1:20738/RPC2'\nserver = xmlrpclib.Server(server_url)\nG = server.ubigraph\n\nG.clear()  # clear image before start\n\n</code></pre>\n<p>Ładowane paczki pozwalają nam operować na plikach, czasie, wykonywać obliczenia, łączyć się z serwerem <code>ubigraph</code> oraz zatrzymywać program na określoną jednostkę czasu. Po załadowaniu paczek następuje nawiązanie połączenia z serwerem i wyczyszczenie jego okna.</p>\n<h3 id=\"klasy\">Klasy</h3>\n<p>Następną częścią skryptu jest klasa z konfiguracją.</p>\n<pre><code class=\"language-py\">##################################################################\n#                          Configuration                         #\n##################################################################\n\nclass Config:\n    def __init__(self):\n        self.state = 1\n\n    # weights of open, highest, lowest and close price for calculating correlation\n    op = 0.25\n    hi = 0.25\n    lo = 0.25\n    cl = 0.25\n\n    free_mem = 1  # option for free memory\n\n    sleep = 0.001  # time of sleeping between steps\n    memory = 100  # How many days before actual data should be taken in correlation?\n    # boundary = 0 #\n    boundary = 0.7  # correlation boundary between showed and hidden connection in graph\n\n\nconfig = Config()\n\n</code></pre>\n<p>Nie ma ona żadnej metody, a zmienne w niej przechowywane są publiczne. Służy więc ona jedynie jako kontener na te wartości, aby nie zaśmiecać globalnej przestrzeni nazw. Zmienne <code>op</code>, <code>hi</code>, <code>lo</code>, <code>cl</code> są to wagi z jakimi ceny otwarcia, najwyższa, najniższa i zamknięcia dla danego instrumentu w konkretnym dniu wchodzą do obliczania korelacji. Ustawienie ich na <code>0.25</code> oznacza liczenie zwykłej średniej. Jeśli chcieli byśmy, aby korelacja liczona była tylko dla cen zamknięcia powinniśmy ustawić wszystkie oprócz <code>cl</code> na <code>0</code>, a <code>cl</code> na <code>1</code>.</p>\n<p>Zmienna <code>free_mem</code> posłuży nam później jako znacznik przy zwalnianiu pamięci. <code>sleep</code> jest to czas oczekiwania między kolejnymi iteracjami podany w sekundach. Iteracje oznaczają przechodzenie o 1 dzień w historii. W zmiennej <code>memory</code> trzymany jest zakres dni jakie mają być brane do obliczania korelacji, są to zawsze dni przed dniem dla którego obliczamy korelację. Ostatnia zmienna - <code>boundary</code> - jest wartością graniczną korelacji dla której połączenia są dodawane lub usuwane. Jeśli korelacje będzie wyższa niż wartość tej zmiennej, to podczas wizualizacji pojawi się połączenia, jeśli niższa, to zniknie.</p>\n<p>Ta klasa była jedynie odpowiednikiem struktury w <code>Pascalu</code>. Teraz czas na bardziej &quot;obiektową&quot; klasę.</p>\n<pre><code class=\"language-py\">##################################################################\n#                          Definitions                           #\n##################################################################\n\nclass Company:\n    &quot;&quot;&quot;Company contains info about company needed to calculations&quot;&quot;&quot;\n\n    def __init__(self, filename):\n        self.filename = filename\n        self.dates = []\n        self.prices = []\n\n        self.prices_evryday = []  # table used instead dates and prices after assigning time of simulation\n\n        self.vertex_id = Company.vertex_id\n        Company.vertex_id += 1\n\n    vertex_id = 0\n    min_date = 0\n    max_date = 0\n    name = ''\n\n    def debug_print(self):\n        print &quot;name: &quot;, self.name\n        print &quot;filename: &quot;, self.filename\n        print &quot;vertex: &quot;, self.vertex_id\n        print &quot;min_date: &quot;, self.min_date\n        print &quot;max_date: &quot;, self.max_date\n        print &quot;max price: &quot;, max(self.prices)\n        print &quot;min price: &quot;, min(self.prices)\n\n    def in_range(self, date):  # czy date jest w zakresie\n        if self.min_date &lt; date &lt; self.max_date:\n            return 1\n        else:\n            return 0\n\n</code></pre>\n<p>Klasa <code>Company</code> zawiera informacje o firmie potrzebne do obliczeń. Dokładnie tak jak sama o sobie mówi. Jej konstruktor przyjmuje nazwę pliku i automatycznie inkrementuje swoje <code>vertex_id</code>. Jej pierwsza metoda służy do wyświetlania informacji o klasie. Nie jest przydatna dla użytkownika, ale świetnie sprawdza się podczas pisania kodu. Druga metoda <code>in_range</code> sprawdza czy dana spółka jest notowana w czasie określonym w jej argumencie. Będzie to często wykorzystywane ze względu na to, że radzenie sobie z lukami w danych wejściowych stanowią dużą część tego kodu.</p>\n<h3 id=\"interfejs-i-przygotowanie-danych\">Interfejs i przygotowanie danych</h3>\n<p>Po definicji klas możemy przejść do interfejsu użytkownika.</p>\n<pre><code class=\"language-py\">        ##################################################################\n        #                          Interface                             #\n        ##################################################################\n\nprint &quot;Select files with input data&quot;\n\ni = 1\npaths = []\nwhile 1:\n    path = raw_input(&quot;Get path to files &quot; + str(i) + &quot;, or ENTER to finish: &quot;)\n    if len(path) == 0:\n        break\n    i += 1\n    paths.append(path)\n    print path, len(path), paths\n\nif len(paths) == 0:  # if error\n    print &quot;\\nYou do not chosen enough number of files.\\nRead docs or contact with author: gustaw.daniel@gmial.com.\\n&quot;\n    exit()\n\ndirectory = ''\nif len(paths) == 1:  # catalog\n    directory = paths[0]\n    print &quot;Loading from catalog :&quot; + str(directory)\n    paths = os.listdir(directory)  # names of files\n\nelse:\n    print &quot;Loading given files:&quot;\n\n</code></pre>\n<p>Interfejs jest trochę wymieszany z logiką i jestem pewien, że dało by się napisać to ładniej, ale jak wspomniałem - nie umiem Pythona, więc jeśli w tym miejscu masz jakieś uwagi, albo pomysły, jak lepiej można by to napisać, podziel się tym w komentarzu.</p>\n<p>Generalnie celem tego kawałka kodu było udostępnienie użytkownikowi możliwości wybrania katalogu, bądź listy poszczególnych plików, jednak ta druga opcja okazała się mało praktyczna, bo wygodniej było przygotować katalog i wpisać jego nazwę, niż wprowadzać nazwy ręcznie. W tym momencie jest to jedyna zalecana forma wprowadzania plików do programu.</p>\n<pre><code class=\"language-py\">##################################################################\n#                     Loading list of files                      #\n##################################################################\n\ncompanies = []  # empty list of companies\n\nfiles_content = []  # empty content of files\nfor path in paths:  # for any path\n    files_content.append(open(str(directory) + '/' + str(path), 'r').readlines())\n    company = Company(path)  # create company\n    companies.append(company)  # append to companies list\n    print paths.index(path), path\n\nprint &quot;Processing files&quot;\n\n</code></pre>\n<p>Kiedy użytkownik określi jakie pliki mają być wczytane, następuje ładowanie ich zawartości za pomocą funkcji <code>open</code> i jej metody <code>readlines</code>. Dla każdej ścieżki do pliku tworzona jest instancja <code>Company</code> i dołączana to tablicy z firmami (lub bardziej ogólnie instrumentami finansowymi).</p>\n<p>Jeśli byśmy przyjrzeli się strukturze pliku <code>mst</code> to jest ona następująca:</p>\n<pre><code class=\"language-csv\">&lt;TICKER&gt;,&lt;DTYYYYMMDD&gt;,&lt;OPEN&gt;,&lt;HIGH&gt;,&lt;LOW&gt;,&lt;CLOSE&gt;,&lt;VOL&gt;\n01CYBATON,20080415,4.48,4.48,3.76,4.08,13220\n01CYBATON,20080416,4.24,4.24,3.84,4.16,1120\n01CYBATON,20080417,4.08,4.40,4.08,4.08,7600\n           ...\n\n</code></pre>\n<p>Ponieważ nagłówki nie są nam potrzebne przy obliczeniach odcinamy je z każdej tablicy zawierającej line <code>file_content</code>.</p>\n<pre><code class=\"language-py\">print &quot;Cutting headers&quot;\n\nfor file_content in files_content:  # removing headers\n    file_content.pop(0)\n\n</code></pre>\n<p>Nadal jednak występuje tam duży nadmiar danych. Przede wszystkim nazwy spółki się powtarzają, daty są w trudnym do przetwarzania formacie, volumeny wcale nie są nam potrzebne, a zamiast cen otwarcia, najwyższej, najniższej i zamknięcia potrzebujemy jednej ceny z której będzie liczona korelacja.</p>\n<p>Żeby pozbyć się tych danych tworzymy dwie tablice - z datami i cenami.</p>\n<pre><code class=\"language-py\">date = []\nprice = []\n\nmin_date = 99999999999  # searching min and max date common for companies\nmax_date = 0\n\nepoch = datetime.datetime.utcfromtimestamp(0)\n\n</code></pre>\n<p>Zmienne <code>max_date</code> i <code>min_date</code> pozwolą nam wybrać ograniczenia zakresu dat w jakich możemy wizualizować. Od razu wspomnę o ograniczeniach. Wizualizacja nie może kończyć się przed 1 stycznia 1970 ponieważ ten dzień jest początkiem odliczania czasu w sekundach w systemach uniksowych. No i nie może zaczynać się za <code>min_date</code> dni. Nie jest to eleganckie rozwiązanie, ale z praktycznego punktu widzenia to ponad 200 tysięcy lat, więc mimo, że nie jest ładne, działa dobrze.</p>\n<pre><code class=\"language-py\">##################################################################\n#           Loading files to memory                              #\n##################################################################\n\nprint &quot;Saving content&quot;\n\nfor i in range(0, len(files_content)):  # for any file\n    for line in files_content[i]:  # get line\n        l = line.rstrip().split(',')  # split by coma\n        date.append((datetime.datetime.strptime(l[1], &quot;%Y%m%d&quot;).date() - epoch.date()).days)\n        # append date in days form epoch to date array\n        price.append(round(\n            float(l[2]) * config.op +\n            float(l[3]) * config.hi +\n            float(l[4]) * config.lo +\n            float(l[5]) * config.cl, 4))\n        # and price as mean with proper weights to price array\n    min_date = min(min_date, date[0])  # if there was no date before this one, set this date there\n    max_date = max(max_date, date[-1])  # and in similar way set latest date\n\n    companies[i].name = l[0]\n    companies[i].dates = date\n    companies[i].prices = price\n    companies[i].min_date = date[0]\n    companies[i].max_date = date[-1]\n\n    date = []\n    price = []\n    print i + 1, &quot;/&quot;, len(files_content)\n\nif config.free_mem:\n    files_content = []\n\n</code></pre>\n<p>Ten kawałek kodu odpowiada za wyłuskanie jednej ceny zamiast czterech i konwersję daty na datę w dniach od 1 stycznia 1970. Tablice z tymi tylko wartościami zapisywane są do zmiennych tymczasowych <code>price</code> i <code>date</code>, a później do tablicy klas <code>Company</code>. Przy tej okazji oblizane są początkowa i końcowa data dla każdej ze spółek oraz najszerszy możliwy zakres dat zapisywany jest w <code>min_date</code> i <code>max_date</code>. Domyślnie na końcu tej operacji czyścimy pamięć ze zmiennej <code>files_content</code>.</p>\n<p>Przyszedł czas na ostatni kawałek interakcji z użytkownikiem. Określił on już pliki wejściowe. Program zbadał i przetworzył ich zawartość. Nadszedł czas, żeby użytkownik zdecydował, jaki okres historyczny chce obserwować.</p>\n<pre><code class=\"language-py\">##################################################################\n#           Selecting time of simulation                         #\n##################################################################\n\nprint &quot;Selecting time of visualisation: &quot;\nprint &quot;Time given is in days from 01.01.1970&quot;\nprint &quot;Company name         start of date      end of data&quot;\nmin_max = max_date\nmax_min = min_date\nfor company in companies:\n    min_max = min(min_max, company.max_date)\n    max_min = max(max_min, company.min_date)\n    print repr(company.name).ljust(25), repr(company.min_date).ljust(20), repr(company.max_date).ljust(20)\nprint &quot;Union (at least one company on stock): &quot;, min_date, max_date\nprint &quot;Intersection (all companies on stock): &quot;, max_min, min_max\n\nmin_user = raw_input(&quot;Set first day of simulation, ENTER - Intersection: &quot;)\nif len(min_user) == 0:\n    min_user = max_min\nelse:\n    min_user = int(min_user)\nmax_user = raw_input(&quot;Set last day of simulation, ENTER - Intersection: &quot;)\nif len(max_user) == 0:\n    max_user = min_max\nelse:\n    max_user = int(max_user)\nmemory = raw_input(&quot;Set range of calculating correlation, ENTER - 100: &quot;)\nif len(memory) == 0:\n    memory = config.memory\nelse:\n    memory = int(memory)\n\n</code></pre>\n<p>Po wyjaśnieniu użytkownikowi jednostek w jakich podawane są daty, skrypt oblicza sumę i iloczyn mnogościowy wszystkich przedziałów czasowych, jakie odpowiadają czasom notowania wprowadzonych spółek. Domyślnie symulacja następuje dla okresu w którym wszystkie spółki są notowane jednocześnie, ale użytkownik ma możliwość samodzielnego decydowania o tym okresie. Ostatnią zmienną o jaką pytamy użytkownika jest zakres czasu w jakim korelacja będzie obliczana.</p>\n<p>Pozostały jeszcze parametry jakie jak graniczna wartość korelacji między pojawianiem się a znikaniem połączeń, czas czekania między kolejnymi krokami. Aby nie czynić interfejsu zbyt męczącym (i tak domyślnie klikamy enter aż 5 razy) pozostawiłem te wartości jako domyślne. Kod skryptu jest jawny, więc osoba zainteresowana łatwo sobie może je zmienić.</p>\n<h3 id=\"obliczanie-interpolacji-i-korelacji-cen\">Obliczanie interpolacji i korelacji cen</h3>\n<p>Przejdźmy teraz do obliczeń.</p>\n<pre><code class=\"language-py\">##################################################################\n#                    Interpolation of prices                     #\n##################################################################\n\nprint &quot;Prices are interpolated&quot;\n\n# print &quot;min memm, max &quot;,min_user, memory, max_user\n\nfor company in companies:\n    for date in range(min_user - memory, max_user):\n        if company.in_range(date):\n            price = round(numpy.interp(date, company.dates, company.prices), 4)\n        else:\n            price = 0\n        company.prices_evryday.append(price)\n    print repr(company.vertex_id + 1).ljust(3), &quot;/&quot;, repr(Company.vertex_id).ljust(6), repr(company.name).ljust(20)\n    if config.free_mem:  # free memory\n        company.dates = []\n        company.prices = []\n\n</code></pre>\n<p>Kolejny problem do pokonania, to brak ciągłości notować. Są dni, kiedy giełada jest zamknięta. Żeby sobie z tym poradzić w klasie <code>Company</code> oprócz tablicy <code>prices</code> jest też tablica <code>prices_everyday</code>. Do niej wpisywane są ceny interpolowane ze wszystkich cen i wszystkich dat. Jeśli firma nie jest notowana, do tablicy <code>prices_everyday</code> zapisywane jest <code>0</code>. W ten sposób radzimy sobie z nierówną długością okresów notowań w danych wejściowych. Po wykonaniu tej operacji tablice z danymi i cenami nie są już potrzebne. Możemy je śmiało usunąć. Jeśli z jakichś powodów nie chcieli byśmy tego robić możemy ustawić parametr <code>free_mem</code> na <code>0</code>. Domyślnie jednak czyścimy pamięć z tych danych.</p>\n<p>Mając dane w formie wygodnej do przeprowadzania obliczeń możemy wyliczyć korelacje. Tak jak przy interpolacji, pomoże nam pakiet <strong>numpy</strong>.</p>\n<pre><code class=\"language-py\">##################################################################\n#                    Calculation of correlations                 #\n##################################################################\n\nprint &quot;Calculating of correlation&quot;\n\ncorr = []\nline = []\ncorrelations = []  # Huge layer matrix with any correlations,\n\nnumpy.seterr(divide='ignore', invalid='ignore')  # ignoring of warnings that we get\n# calculating correlation on identical lists\n\nfor date in range(0, max_user - min_user):\n    corr = numpy.corrcoef([company.prices_evryday[date:date + memory] for company in companies])\n    correlations.append(corr)\n\n</code></pre>\n<p>Warto zauważyć, że tablica <code>company.prices_everyday</code> zaczyna się w chwili czasu <code>min_user - memory</code>, to znaczy <code>memory</code> dni wcześniej niż przebiega symulacjia. Z tego względu pętla do obliczania korelacji zaczyna się od <code>0</code> a kończy na <code>max_user-min_user</code> czyli <code>memory</code> indeksów przed skończeniem tablicy <code>company.prices_everyday</code>. Dla każdego kroku pętli obliczamy korelacje od indeksu bierzącego do wyprzedzającgo go o wartość <code>memory</code>.</p>\n<p>Wewnątrz argumentu funkcji obliczającej korelację iterujemy po wszystkich firmach. Należy przyznać, że skaładnia <code>pythona</code> jest tu bardzo zwięzła, pozostając jednocześnie całkiem czytelną.</p>\n<p>Produktem tego kroku jest warstwowa macież korelacji, do którj będziemy się odwoływać do końca programu.</p>\n<h3 id=\"obs%C5%82uga-serwera-unigraph\">Obsługa serwera Unigraph</h3>\n<p>Na tym w zasadzie kończą się obliczenia i następne fragmenty kodu będą związane z obsługą <code>unigraph</code>.</p>\n<pre><code class=\"language-py\">##################################################################\n#                  Creating matrix of connections                #\n##################################################################\n\nprint &quot;Initialisation of matrix of connection&quot;\n\ne = [[0 for x in range(Company.vertex_id)] for y in range(Company.vertex_id)]  # matrix of connections\n\n</code></pre>\n<p>Na początku inicjalizujemy pustą macież połączeń reprezentujących występowanie lub brak korelacji między notowaniami instrumentów finansowych.</p>\n<pre><code class=\"language-py\">##################################################################\n#              Creation of initial vertexes                      #\n##################################################################\n\n\nfor ind in range(0, Company.vertex_id):\n    if companies[ind].prices_evryday[0] != 0:\n        G.new_vertex_w_id(ind)\n        G.set_vertex_attribute(ind, 'label', companies[ind].name)\n\n</code></pre>\n<p>Tworzymy wierzchołki dla firm notowanych od początku i nadajemy im nazwy firma jako opisy.</p>\n<pre><code class=\"language-py\">##################################################################\n#              Creation initial connections                      #\n##################################################################\n\nfor ind1 in range(0, Company.vertex_id):\n    for ind2 in range(ind1 + 1, Company.vertex_id):\n        if correlations[0][ind1][ind2] &gt;= config.boundary:\n            e[ind1][ind2] = G.new_edge(ind1, ind2)\n\n</code></pre>\n<p>Iterujemy po trójkątnej macieży połączeń między firmami dodając połaczenia jeśli początkowe korelacje przekraczają graniczną wartoś ustaloną w konfiguracji. I na końcu przeprowadzamy symulację:</p>\n<pre><code class=\"language-py\">##################################################################\n#      Visualization of dynamic correlation network              #\n##################################################################\n\n# for any time\nfor x in range(1, len(correlations)):\n    # for any company\n    for ind1 in range(0, Company.vertex_id):\n        # if company starts be noted, create them\n        if companies[ind1].prices_evryday[x - 1] == 0 and companies[ind1].prices_evryday[x] != 0:\n            G.new_vertex_w_id(ind1)\n            G.set_vertex_attribute(ind1, 'label', companies[ind1].name)\n            print x, &quot; (a):v &quot;, ind1\n        # for any company with index higher than last one\n        for ind2 in range(ind1 + 1, Company.vertex_id):\n            # if connection occurs, add this\n            if correlations[x - 1][ind1][ind2] &lt; config.boundary &lt;= correlations[x][ind1][ind2]:\n                e[ind1][ind2] = G.new_edge(ind1, ind2)\n                print x, &quot; (a):e &quot;, ind1, ind2\n            # if connection vanishes, delete this\n            if correlations[x - 1][ind1][ind2] &gt;= config.boundary &gt; correlations[x][ind1][ind2]:\n                G.remove_edge(e[ind1][ind2])\n                print x, &quot; (r):e &quot;, ind1, ind2\n            time.sleep(config.sleep)\n        if companies[ind1].prices_evryday[x - 1] != 0 and companies[ind1].prices_evryday[x] == 0:\n            G.remove_vertex(ind1)\n            print x, &quot; (r):v &quot;, ind1\n\n</code></pre>\n<p>Mimo, że to tu wykonuje się najważniejsza część kodu, zajmuje on stosunkowo mało miejsca. W tej pętli iterującej po dniach (a właściwie indeksach, które przypisaliśmy dniom) wykonywana jest pęta po wszystkich firmach. W niej sprawdzamy, czy firma zaczyna być notowana i jeśli tak, dodajemy ją do wizualizacji. Ponownie zagnieżdżamy pętlę po firmach dbając o unikanie powtórzeń. Jeśli korelacja przekroczyła granicę schodząc w dół - usówamy połączenie, jeśliw górę dodajemy. Czekamy chwilę, żeby użytkownik nacieszył oko. Na koniec jeśli firma skończyła notowanie na giełdzie usówamy jej wierzchołek.</p>\n<h2 id=\"podsumowanie\">Podsumowanie</h2>\n<p>To wszystko. Wisienka na torcie okazła się być kilkoma linijkami gęstego kodu w porównaniu do setek linii, które walczyły o to by poznać intencje użytkownika i z danych wejściowych wyłuskać struturę wygodną do przeprowadzenia obliczeń.</p>\n<p>Jest to niestety poważny problem całej branży analizy danych. W wielu przypadkach dane wejściowe są na tyle nie wygodne, że ich przekształcenie do porządanej postaci kosztuje nas więcej wysiłku niż samo wykonanie ich analizy.</p>\n<p>Jednak sytuacja się polepsza. Coraz cześciej spotykane <code>API</code>, oraz wzrost popularności formatu <code>json</code> który wypiera powoli <code>xml</code> i <code>csv</code> są krokami w dobrym kierunku i ułatwiają pracę z danymi.</p>\n<p><img src=\"http://i.imgur.com/OyhoigO.png\" alt=\"popularność json, xml, csv\" loading=\"lazy\"></p>\n<p>Jak zawsze zachęcam do komentowania, wyrażania wątpliwości i zadawania pytań.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f32492fb35425592d0b3e",
            "plaintext": "Opis projektu\nPython jest językiem w którym można pisać nie znając go. Mimo, że nie znam\nPythona napisałem w nim skrypt do obsługi serwera ubigraph - oprogramowania\npozwalającego wizualizować grafy.\n\nProjekt powstał we wrześniu 2015 roku, zanim ubigraph przestał być wspierany :(\n[https://twitter.com/SadieSv/status/716044022129659904]. Mimo tego, że strona\nprojektu nie jest dostępna, oprogramowanie napisane w oparciu o serwer ubigraph \nwciąż działa a sam plik z serwerem został dołączony do repozytorium.\n\nDzięki przeczytaniu tego artykułu zapoznasz się narzędziem do odczytu plików \njson w bashu, dowiesz się jak definiować klasy i operować na tablicach w\npythonie, oraz zobaczysz jak bardzo pakiet numpy upraszcza obliczenia.\n\nSkład kodu źródłowego to:\n\nPython 90.1% Shell 9.9%\n\n\nPo napisaniu projekt będzie wyglądał tak:\n\nInstalacja\nAby zainstalować projekt należy pobrać repozytorium\n\ngit clone https://github.com/gustawdaniel/dynamic_network_correaltion.git\n\n\nPrzejść do katalogu dynamic_network_correaltion i zainstalować projekt skryptem \ninstall.sh.\n\ncd dynamic_network_correaltion && bash install.sh\n\n\nPowinieneś zobaczyć nowe czarne okno o tytule Ubigraph. W nowym terminalu (\nctrl+n) włącz skrypt visualise.py.\n\npython visualise.py\n\n\nKolejno wybieraj następujące opcje:\n\ntest ENTER ENTER ENTER ENTER ENTER\n\n\nW oknie Ubigraph powinieneś zobaczyć wizualizację dynamicznej sieci\nkorelacyjnej.\n\nKonfiguracja\nW tym rozdziale omówione są wszystkie kroki instalacji poza instalacją\nzależności.\n\nZaczniemy od pobrania danych z archiwum domu maklerskiego bossa\n[http://bossa.pl]. W ich publicznym archiwum [http://bossa.pl/pub/] znajdują się\npliki z notowaniami w formacie mst (odmiana csv) spakowane w archiwa zip.\nWszystkie adresy interesujących nas plików zaczynają się od http://bossa.pl/pub/\n, ale mają różne końcówki. Zapisałem je w pliku konfiguracyjnym.\n\n> config/wget_data_config.json\n\n\n{\n  \"uri1\": \"http://bossa.pl/pub/\",\n  \"data\": [\n    {\n      \"uri2\": \"metastock/mstock/mstall.zip\"\n    },{\n      \"uri2\": \"ciagle/mstock/mstcgl.zip\"\n    },{\n      \"uri2\": \"futures/mstock/mstfut.zip\"\n    },{\n      \"uri2\": \"newconnect/mstock/mstncn.zip\"\n    },{\n      \"uri2\": \"jednolity/f2/mstock/mstf2.zip\"\n    },{\n      \"uri2\": \"ciagle/mstock/mstobl.zip\"\n    },{\n      \"uri2\": \"indzagr/mstock/mstzgr.zip\"\n    },{\n      \"uri2\": \"waluty/mstock/mstnbp.zip\"\n    },{\n      \"uri2\": \"fundinwest/mstock/mstfun.zip\"\n    },{\n      \"uri2\": \"ofe/mstock/mstofe.zip\"\n    },{\n      \"uri2\": \"forex/mstock/mstfx.zip\"\n    }\n  ]\n}\n\n\nPobranie archiwów (json w bashu)\nNaszym celem jest pobranie wszystkich plików o adresach składających się z \n\"url1\".\"url2\". Będzie za to odpowiedzialny program jq, który pozwala na\nwydobywanie z pliku json wartości dla podanych kluczy. Przyjrzyjmy się pierwszej\nczęści skryptu do pobierania notowań:\n\n> wget_data.sh\n\n\n#!/bin/bash\n\n#\n#   Definitions\n#\n\n# catalogs structure\nCONF=\"config/wget_data_config.json\";\nRAW=\"raw\";\n\n# method allowing get data from config file\nfunction getFromConf {\n    echo $(cat $CONF | jq -r $1);\n}\n\n# variables constant for all script\nLINES=$(grep \\\"uri2\\\": $CONF | wc -l);\nURI1=$(getFromConf '.uri1');\n\n\nZmienne CONF i RAW są jedynie statycznymi ścieżkami do pliku z konfiguracją oraz\nkatalogu, gdzie dane mają zostać zapisane. Zmienna LINES pobiera ilość wystąpień\nciągu \"uri2\": w pliku json co odpowiada liczbie linków które chcemy pobrać.\n\nFunkcja getFromConf pobiera z pliku konfiguracyjnego klucz określony w pierwszym\nparametrze z jakim ją wywołamy. Jej pierwsze zastosowanie widać przy\ndefiniowaniu zmiennej URI1. Przed nazwą klucza występuje kropka, a całość jest w\npojedynczych cudzysłowach. To wystarczy. Kolejna część skryptu to pętla po\nliniach które zliczyliśmy.\n\n#\n#   Script\n#\n\n#clear raw catalog\nrm $RAW/*\n\n# iterate over all lines\nfor i in `seq 1 $LINES`\ndo\n    # downloading data from links from config\n    wget $URI1$(getFromConf '.data['$i-1'].uri2') -P $RAW\ndone\n\n\nPo wyczyszczeniu katalogu raw z dotychczasowej zawartości pętla pobiera linki do\nkatalogu raw. Interesujący jest sposób w jaki w bashu przeprowadza się\nkonkatenację - wystarczy postawić zmienne obok siebie. Tym razem klucz po którym\nwyszukujemy - '.data['$i-1'].uri2' jest bardziej skomplikowany, ale w pełni\nodpowiada naturalnej intuicji dotyczącej wyszukiwania w strukturze json.\n\nRozpakowywanie archiwów\nRozpakowanie archiwów sprowadza się do iterowania po katalogu raw. Standardowo\ndefiniujemy strukturę katalogów w zmiennych, czyścimy katalog build, i we\nwspomnianej pętli odczytujemy nazwę bez ścieżki i rozszerzenia, tworzymy katalog\nz taką nazwą, rozpakowujemy tam archiwum.\n\n> build_data.sh\n\n\n#!/usr/bin/env bash\n\n# catalogs structure\nRAW=raw;\nBUILD=build;\n\n# clear build for idempotency\nrm -rf $BUILD/*;\n\n# loop over archives in raw\nfor FILE in $RAW/*.zip\ndo\n#    create directory in build and unzip there file from raw\n    NAME=$(basename $FILE .zip);\n    echo $NAME;\n    mkdir -p $BUILD/$NAME;\n    unzip -q $FILE -d $BUILD/$NAME;\ndone\n\n\n\nOpcja -q w komendzie unzip pozwala ją wyciszyć.\n\nPrzygotowanie katalogu testowego\nJeśli spojrzymy na plik install.sh to poza instalacją zależności i\nprzygotowaniem danych jest tam również przygotowanie testów.\n\n> install.sh\n\n\n# prepare test\nmkdir -p test\nrm -rf test/*\ncp build/mstcgl/[A-D][A-D][A-D]* test/\n\n\n\nTa komenda służy do wybrania notowań kilku przykładowych spółek i zapisania ich\nw katalogu test. Pozwala to na uproszczenie procedury włączania programu. W jego\ninterfejsie wystarczy wskazać nazwę katalogu test aby pobrał on wszystkie pliki\nstamtąd. Jeśli chcesz zobaczyć wykresy dla innych spółek, zalecana jest właśnie\ntaka metoda postępowania:\n\n 1. Tworzymy katalog\n 2. Kopiujemy do niego wybrane pliki mst\n 3. Przy włączaniu wizualizacji podajemy nazwę tego katalogu i dwa razy ENTER.\n\nSkrypt wykonujący wizualizację\nOmówimy teraz wszystkie części skryptu odpowiedzialnego z wizualizację sieci\nkorelacyjnej. Zaczniemy od importów i nawiązanie połączenia z serwerem.\n\n> visualise.py\n\n\n# -*- coding: utf-8 -*-\n\nimport os  # for loading files\nimport datetime  # for time operations\nimport numpy  # for calculation correlation\n\nimport xmlrpclib  # for visualise by ubigraph\nimport time  # for waiting between steps\n\n#  connect to server displaying image\nserver_url = 'http://127.0.0.1:20738/RPC2'\nserver = xmlrpclib.Server(server_url)\nG = server.ubigraph\n\nG.clear()  # clear image before start\n\n\n\nŁadowane paczki pozwalają nam operować na plikach, czasie, wykonywać obliczenia,\nłączyć się z serwerem ubigraph oraz zatrzymywać program na określoną jednostkę\nczasu. Po załadowaniu paczek następuje nawiązanie połączenia z serwerem i\nwyczyszczenie jego okna.\n\nKlasy\nNastępną częścią skryptu jest klasa z konfiguracją.\n\n##################################################################\n#                          Configuration                         #\n##################################################################\n\nclass Config:\n    def __init__(self):\n        self.state = 1\n\n    # weights of open, highest, lowest and close price for calculating correlation\n    op = 0.25\n    hi = 0.25\n    lo = 0.25\n    cl = 0.25\n\n    free_mem = 1  # option for free memory\n\n    sleep = 0.001  # time of sleeping between steps\n    memory = 100  # How many days before actual data should be taken in correlation?\n    # boundary = 0 #\n    boundary = 0.7  # correlation boundary between showed and hidden connection in graph\n\n\nconfig = Config()\n\n\n\nNie ma ona żadnej metody, a zmienne w niej przechowywane są publiczne. Służy\nwięc ona jedynie jako kontener na te wartości, aby nie zaśmiecać globalnej\nprzestrzeni nazw. Zmienne op, hi, lo, cl są to wagi z jakimi ceny otwarcia,\nnajwyższa, najniższa i zamknięcia dla danego instrumentu w konkretnym dniu\nwchodzą do obliczania korelacji. Ustawienie ich na 0.25 oznacza liczenie zwykłej\nśredniej. Jeśli chcieli byśmy, aby korelacja liczona była tylko dla cen\nzamknięcia powinniśmy ustawić wszystkie oprócz cl na 0, a cl na 1.\n\nZmienna free_mem posłuży nam później jako znacznik przy zwalnianiu pamięci. \nsleep jest to czas oczekiwania między kolejnymi iteracjami podany w sekundach.\nIteracje oznaczają przechodzenie o 1 dzień w historii. W zmiennej memory \ntrzymany jest zakres dni jakie mają być brane do obliczania korelacji, są to\nzawsze dni przed dniem dla którego obliczamy korelację. Ostatnia zmienna - \nboundary - jest wartością graniczną korelacji dla której połączenia są dodawane\nlub usuwane. Jeśli korelacje będzie wyższa niż wartość tej zmiennej, to podczas\nwizualizacji pojawi się połączenia, jeśli niższa, to zniknie.\n\nTa klasa była jedynie odpowiednikiem struktury w Pascalu. Teraz czas na bardziej\n\"obiektową\" klasę.\n\n##################################################################\n#                          Definitions                           #\n##################################################################\n\nclass Company:\n    \"\"\"Company contains info about company needed to calculations\"\"\"\n\n    def __init__(self, filename):\n        self.filename = filename\n        self.dates = []\n        self.prices = []\n\n        self.prices_evryday = []  # table used instead dates and prices after assigning time of simulation\n\n        self.vertex_id = Company.vertex_id\n        Company.vertex_id += 1\n\n    vertex_id = 0\n    min_date = 0\n    max_date = 0\n    name = ''\n\n    def debug_print(self):\n        print \"name: \", self.name\n        print \"filename: \", self.filename\n        print \"vertex: \", self.vertex_id\n        print \"min_date: \", self.min_date\n        print \"max_date: \", self.max_date\n        print \"max price: \", max(self.prices)\n        print \"min price: \", min(self.prices)\n\n    def in_range(self, date):  # czy date jest w zakresie\n        if self.min_date < date < self.max_date:\n            return 1\n        else:\n            return 0\n\n\n\nKlasa Company zawiera informacje o firmie potrzebne do obliczeń. Dokładnie tak\njak sama o sobie mówi. Jej konstruktor przyjmuje nazwę pliku i automatycznie\ninkrementuje swoje vertex_id. Jej pierwsza metoda służy do wyświetlania\ninformacji o klasie. Nie jest przydatna dla użytkownika, ale świetnie sprawdza\nsię podczas pisania kodu. Druga metoda in_range sprawdza czy dana spółka jest\nnotowana w czasie określonym w jej argumencie. Będzie to często wykorzystywane\nze względu na to, że radzenie sobie z lukami w danych wejściowych stanowią dużą\nczęść tego kodu.\n\nInterfejs i przygotowanie danych\nPo definicji klas możemy przejść do interfejsu użytkownika.\n\n        ##################################################################\n        #                          Interface                             #\n        ##################################################################\n\nprint \"Select files with input data\"\n\ni = 1\npaths = []\nwhile 1:\n    path = raw_input(\"Get path to files \" + str(i) + \", or ENTER to finish: \")\n    if len(path) == 0:\n        break\n    i += 1\n    paths.append(path)\n    print path, len(path), paths\n\nif len(paths) == 0:  # if error\n    print \"\\nYou do not chosen enough number of files.\\nRead docs or contact with author: gustaw.daniel@gmial.com.\\n\"\n    exit()\n\ndirectory = ''\nif len(paths) == 1:  # catalog\n    directory = paths[0]\n    print \"Loading from catalog :\" + str(directory)\n    paths = os.listdir(directory)  # names of files\n\nelse:\n    print \"Loading given files:\"\n\n\n\nInterfejs jest trochę wymieszany z logiką i jestem pewien, że dało by się\nnapisać to ładniej, ale jak wspomniałem - nie umiem Pythona, więc jeśli w tym\nmiejscu masz jakieś uwagi, albo pomysły, jak lepiej można by to napisać, podziel\nsię tym w komentarzu.\n\nGeneralnie celem tego kawałka kodu było udostępnienie użytkownikowi możliwości\nwybrania katalogu, bądź listy poszczególnych plików, jednak ta druga opcja\nokazała się mało praktyczna, bo wygodniej było przygotować katalog i wpisać jego\nnazwę, niż wprowadzać nazwy ręcznie. W tym momencie jest to jedyna zalecana\nforma wprowadzania plików do programu.\n\n##################################################################\n#                     Loading list of files                      #\n##################################################################\n\ncompanies = []  # empty list of companies\n\nfiles_content = []  # empty content of files\nfor path in paths:  # for any path\n    files_content.append(open(str(directory) + '/' + str(path), 'r').readlines())\n    company = Company(path)  # create company\n    companies.append(company)  # append to companies list\n    print paths.index(path), path\n\nprint \"Processing files\"\n\n\n\nKiedy użytkownik określi jakie pliki mają być wczytane, następuje ładowanie ich\nzawartości za pomocą funkcji open i jej metody readlines. Dla każdej ścieżki do\npliku tworzona jest instancja Company i dołączana to tablicy z firmami (lub\nbardziej ogólnie instrumentami finansowymi).\n\nJeśli byśmy przyjrzeli się strukturze pliku mst to jest ona następująca:\n\n<TICKER>,<DTYYYYMMDD>,<OPEN>,<HIGH>,<LOW>,<CLOSE>,<VOL>\n01CYBATON,20080415,4.48,4.48,3.76,4.08,13220\n01CYBATON,20080416,4.24,4.24,3.84,4.16,1120\n01CYBATON,20080417,4.08,4.40,4.08,4.08,7600\n           ...\n\n\n\nPonieważ nagłówki nie są nam potrzebne przy obliczeniach odcinamy je z każdej\ntablicy zawierającej line file_content.\n\nprint \"Cutting headers\"\n\nfor file_content in files_content:  # removing headers\n    file_content.pop(0)\n\n\n\nNadal jednak występuje tam duży nadmiar danych. Przede wszystkim nazwy spółki\nsię powtarzają, daty są w trudnym do przetwarzania formacie, volumeny wcale nie\nsą nam potrzebne, a zamiast cen otwarcia, najwyższej, najniższej i zamknięcia\npotrzebujemy jednej ceny z której będzie liczona korelacja.\n\nŻeby pozbyć się tych danych tworzymy dwie tablice - z datami i cenami.\n\ndate = []\nprice = []\n\nmin_date = 99999999999  # searching min and max date common for companies\nmax_date = 0\n\nepoch = datetime.datetime.utcfromtimestamp(0)\n\n\n\nZmienne max_date i min_date pozwolą nam wybrać ograniczenia zakresu dat w jakich\nmożemy wizualizować. Od razu wspomnę o ograniczeniach. Wizualizacja nie może\nkończyć się przed 1 stycznia 1970 ponieważ ten dzień jest początkiem odliczania\nczasu w sekundach w systemach uniksowych. No i nie może zaczynać się za min_date \ndni. Nie jest to eleganckie rozwiązanie, ale z praktycznego punktu widzenia to\nponad 200 tysięcy lat, więc mimo, że nie jest ładne, działa dobrze.\n\n##################################################################\n#           Loading files to memory                              #\n##################################################################\n\nprint \"Saving content\"\n\nfor i in range(0, len(files_content)):  # for any file\n    for line in files_content[i]:  # get line\n        l = line.rstrip().split(',')  # split by coma\n        date.append((datetime.datetime.strptime(l[1], \"%Y%m%d\").date() - epoch.date()).days)\n        # append date in days form epoch to date array\n        price.append(round(\n            float(l[2]) * config.op +\n            float(l[3]) * config.hi +\n            float(l[4]) * config.lo +\n            float(l[5]) * config.cl, 4))\n        # and price as mean with proper weights to price array\n    min_date = min(min_date, date[0])  # if there was no date before this one, set this date there\n    max_date = max(max_date, date[-1])  # and in similar way set latest date\n\n    companies[i].name = l[0]\n    companies[i].dates = date\n    companies[i].prices = price\n    companies[i].min_date = date[0]\n    companies[i].max_date = date[-1]\n\n    date = []\n    price = []\n    print i + 1, \"/\", len(files_content)\n\nif config.free_mem:\n    files_content = []\n\n\n\nTen kawałek kodu odpowiada za wyłuskanie jednej ceny zamiast czterech i\nkonwersję daty na datę w dniach od 1 stycznia 1970. Tablice z tymi tylko\nwartościami zapisywane są do zmiennych tymczasowych price i date, a później do\ntablicy klas Company. Przy tej okazji oblizane są początkowa i końcowa data dla\nkażdej ze spółek oraz najszerszy możliwy zakres dat zapisywany jest w min_date i \nmax_date. Domyślnie na końcu tej operacji czyścimy pamięć ze zmiennej \nfiles_content.\n\nPrzyszedł czas na ostatni kawałek interakcji z użytkownikiem. Określił on już\npliki wejściowe. Program zbadał i przetworzył ich zawartość. Nadszedł czas, żeby\nużytkownik zdecydował, jaki okres historyczny chce obserwować.\n\n##################################################################\n#           Selecting time of simulation                         #\n##################################################################\n\nprint \"Selecting time of visualisation: \"\nprint \"Time given is in days from 01.01.1970\"\nprint \"Company name         start of date      end of data\"\nmin_max = max_date\nmax_min = min_date\nfor company in companies:\n    min_max = min(min_max, company.max_date)\n    max_min = max(max_min, company.min_date)\n    print repr(company.name).ljust(25), repr(company.min_date).ljust(20), repr(company.max_date).ljust(20)\nprint \"Union (at least one company on stock): \", min_date, max_date\nprint \"Intersection (all companies on stock): \", max_min, min_max\n\nmin_user = raw_input(\"Set first day of simulation, ENTER - Intersection: \")\nif len(min_user) == 0:\n    min_user = max_min\nelse:\n    min_user = int(min_user)\nmax_user = raw_input(\"Set last day of simulation, ENTER - Intersection: \")\nif len(max_user) == 0:\n    max_user = min_max\nelse:\n    max_user = int(max_user)\nmemory = raw_input(\"Set range of calculating correlation, ENTER - 100: \")\nif len(memory) == 0:\n    memory = config.memory\nelse:\n    memory = int(memory)\n\n\n\nPo wyjaśnieniu użytkownikowi jednostek w jakich podawane są daty, skrypt oblicza\nsumę i iloczyn mnogościowy wszystkich przedziałów czasowych, jakie odpowiadają\nczasom notowania wprowadzonych spółek. Domyślnie symulacja następuje dla okresu\nw którym wszystkie spółki są notowane jednocześnie, ale użytkownik ma możliwość\nsamodzielnego decydowania o tym okresie. Ostatnią zmienną o jaką pytamy\nużytkownika jest zakres czasu w jakim korelacja będzie obliczana.\n\nPozostały jeszcze parametry jakie jak graniczna wartość korelacji między\npojawianiem się a znikaniem połączeń, czas czekania między kolejnymi krokami.\nAby nie czynić interfejsu zbyt męczącym (i tak domyślnie klikamy enter aż 5\nrazy) pozostawiłem te wartości jako domyślne. Kod skryptu jest jawny, więc osoba\nzainteresowana łatwo sobie może je zmienić.\n\nObliczanie interpolacji i korelacji cen\nPrzejdźmy teraz do obliczeń.\n\n##################################################################\n#                    Interpolation of prices                     #\n##################################################################\n\nprint \"Prices are interpolated\"\n\n# print \"min memm, max \",min_user, memory, max_user\n\nfor company in companies:\n    for date in range(min_user - memory, max_user):\n        if company.in_range(date):\n            price = round(numpy.interp(date, company.dates, company.prices), 4)\n        else:\n            price = 0\n        company.prices_evryday.append(price)\n    print repr(company.vertex_id + 1).ljust(3), \"/\", repr(Company.vertex_id).ljust(6), repr(company.name).ljust(20)\n    if config.free_mem:  # free memory\n        company.dates = []\n        company.prices = []\n\n\n\nKolejny problem do pokonania, to brak ciągłości notować. Są dni, kiedy giełada\njest zamknięta. Żeby sobie z tym poradzić w klasie Company oprócz tablicy prices \njest też tablica prices_everyday. Do niej wpisywane są ceny interpolowane ze\nwszystkich cen i wszystkich dat. Jeśli firma nie jest notowana, do tablicy \nprices_everyday zapisywane jest 0. W ten sposób radzimy sobie z nierówną\ndługością okresów notowań w danych wejściowych. Po wykonaniu tej operacji\ntablice z danymi i cenami nie są już potrzebne. Możemy je śmiało usunąć. Jeśli z\njakichś powodów nie chcieli byśmy tego robić możemy ustawić parametr free_mem na \n0. Domyślnie jednak czyścimy pamięć z tych danych.\n\nMając dane w formie wygodnej do przeprowadzania obliczeń możemy wyliczyć\nkorelacje. Tak jak przy interpolacji, pomoże nam pakiet numpy.\n\n##################################################################\n#                    Calculation of correlations                 #\n##################################################################\n\nprint \"Calculating of correlation\"\n\ncorr = []\nline = []\ncorrelations = []  # Huge layer matrix with any correlations,\n\nnumpy.seterr(divide='ignore', invalid='ignore')  # ignoring of warnings that we get\n# calculating correlation on identical lists\n\nfor date in range(0, max_user - min_user):\n    corr = numpy.corrcoef([company.prices_evryday[date:date + memory] for company in companies])\n    correlations.append(corr)\n\n\n\nWarto zauważyć, że tablica company.prices_everyday zaczyna się w chwili czasu \nmin_user - memory, to znaczy memory dni wcześniej niż przebiega symulacjia. Z\ntego względu pętla do obliczania korelacji zaczyna się od 0 a kończy na \nmax_user-min_user czyli memory indeksów przed skończeniem tablicy \ncompany.prices_everyday. Dla każdego kroku pętli obliczamy korelacje od indeksu\nbierzącego do wyprzedzającgo go o wartość memory.\n\nWewnątrz argumentu funkcji obliczającej korelację iterujemy po wszystkich\nfirmach. Należy przyznać, że skaładnia pythona jest tu bardzo zwięzła,\npozostając jednocześnie całkiem czytelną.\n\nProduktem tego kroku jest warstwowa macież korelacji, do którj będziemy się\nodwoływać do końca programu.\n\nObsługa serwera Unigraph\nNa tym w zasadzie kończą się obliczenia i następne fragmenty kodu będą związane\nz obsługą unigraph.\n\n##################################################################\n#                  Creating matrix of connections                #\n##################################################################\n\nprint \"Initialisation of matrix of connection\"\n\ne = [[0 for x in range(Company.vertex_id)] for y in range(Company.vertex_id)]  # matrix of connections\n\n\n\nNa początku inicjalizujemy pustą macież połączeń reprezentujących występowanie\nlub brak korelacji między notowaniami instrumentów finansowych.\n\n##################################################################\n#              Creation of initial vertexes                      #\n##################################################################\n\n\nfor ind in range(0, Company.vertex_id):\n    if companies[ind].prices_evryday[0] != 0:\n        G.new_vertex_w_id(ind)\n        G.set_vertex_attribute(ind, 'label', companies[ind].name)\n\n\n\nTworzymy wierzchołki dla firm notowanych od początku i nadajemy im nazwy firma\njako opisy.\n\n##################################################################\n#              Creation initial connections                      #\n##################################################################\n\nfor ind1 in range(0, Company.vertex_id):\n    for ind2 in range(ind1 + 1, Company.vertex_id):\n        if correlations[0][ind1][ind2] >= config.boundary:\n            e[ind1][ind2] = G.new_edge(ind1, ind2)\n\n\n\nIterujemy po trójkątnej macieży połączeń między firmami dodając połaczenia jeśli\npoczątkowe korelacje przekraczają graniczną wartoś ustaloną w konfiguracji. I na\nkońcu przeprowadzamy symulację:\n\n##################################################################\n#      Visualization of dynamic correlation network              #\n##################################################################\n\n# for any time\nfor x in range(1, len(correlations)):\n    # for any company\n    for ind1 in range(0, Company.vertex_id):\n        # if company starts be noted, create them\n        if companies[ind1].prices_evryday[x - 1] == 0 and companies[ind1].prices_evryday[x] != 0:\n            G.new_vertex_w_id(ind1)\n            G.set_vertex_attribute(ind1, 'label', companies[ind1].name)\n            print x, \" (a):v \", ind1\n        # for any company with index higher than last one\n        for ind2 in range(ind1 + 1, Company.vertex_id):\n            # if connection occurs, add this\n            if correlations[x - 1][ind1][ind2] < config.boundary <= correlations[x][ind1][ind2]:\n                e[ind1][ind2] = G.new_edge(ind1, ind2)\n                print x, \" (a):e \", ind1, ind2\n            # if connection vanishes, delete this\n            if correlations[x - 1][ind1][ind2] >= config.boundary > correlations[x][ind1][ind2]:\n                G.remove_edge(e[ind1][ind2])\n                print x, \" (r):e \", ind1, ind2\n            time.sleep(config.sleep)\n        if companies[ind1].prices_evryday[x - 1] != 0 and companies[ind1].prices_evryday[x] == 0:\n            G.remove_vertex(ind1)\n            print x, \" (r):v \", ind1\n\n\n\nMimo, że to tu wykonuje się najważniejsza część kodu, zajmuje on stosunkowo mało\nmiejsca. W tej pętli iterującej po dniach (a właściwie indeksach, które\nprzypisaliśmy dniom) wykonywana jest pęta po wszystkich firmach. W niej\nsprawdzamy, czy firma zaczyna być notowana i jeśli tak, dodajemy ją do\nwizualizacji. Ponownie zagnieżdżamy pętlę po firmach dbając o unikanie\npowtórzeń. Jeśli korelacja przekroczyła granicę schodząc w dół - usówamy\npołączenie, jeśliw górę dodajemy. Czekamy chwilę, żeby użytkownik nacieszył oko.\nNa koniec jeśli firma skończyła notowanie na giełdzie usówamy jej wierzchołek.\n\nPodsumowanie\nTo wszystko. Wisienka na torcie okazła się być kilkoma linijkami gęstego kodu w\nporównaniu do setek linii, które walczyły o to by poznać intencje użytkownika i\nz danych wejściowych wyłuskać struturę wygodną do przeprowadzenia obliczeń.\n\nJest to niestety poważny problem całej branży analizy danych. W wielu\nprzypadkach dane wejściowe są na tyle nie wygodne, że ich przekształcenie do\nporządanej postaci kosztuje nas więcej wysiłku niż samo wykonanie ich analizy.\n\nJednak sytuacja się polepsza. Coraz cześciej spotykane API, oraz wzrost\npopularności formatu json który wypiera powoli xml i csv są krokami w dobrym\nkierunku i ułatwiają pracę z danymi.\n\n\n\nJak zawsze zachęcam do komentowania, wyrażania wątpliwości i zadawania pytań.",
            "feature_image": "__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-00-44-14.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T19:58:01.000Z",
            "updated_at": "2021-04-29T23:11:09.000Z",
            "published_at": "2021-04-29T20:05:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f33be2fb35425592d0b4e",
            "uuid": "3816bcae-0e00-4d0b-a137-0930c819bbdc",
            "title": "Tesseract-OCR i testowanie selektów.",
            "slug": "tesseract-ocr-i-testowanie-selektow",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Opis projektu\\n\\nMiałem tylko odświeżyć sobie pisanie zapytań do bazy, a skończyłem instalując `DataGrip` i `Tesseracta`. Pierwszy program jest to IDE do baz danych od `JetBrains`, drugi jest oprogramowaniem OCR - służy do rozpoznawania tekstów w grafice rastrowej.\\n\\nNaszym zadaniem będzie **utworzenie schematów baz** danych, **odczytanie tekstu z plików graficznych**, wrzucenie odczytanej zawartości **napisanie kilku zapytań** i **testowanie zawartości** za pomocą `behata`. Jeśli jesteś ciekaw jak to się robi, zapraszam do lektury.\\n\\nSkład kodu:\\n\\n```\\nCucumber 49.9% Perl 26.7% PHP 21.8% Shell 1.6%\\n```\\n\\n## Instalacja\\n\\nPobieramy repozytorium:\\n\\n```bash\\ngit clone https://github.com/gustawdaniel/image_to_database_converter_example.git && cd image_to_database_converter_example\\n```\\n\\nInstalujemy zależności.\\n\\n```bash\\nsudo apt-get install tesseract-ocr\\n```\\n\\nPrzetważamy obrazki na teksty\\n\\n```\\nbash process.sh\\n```\\n\\nTworzymy bazy i wrzucamy do nich dane. Ten skrypt na początku usunie bazy o nazwach w z `config/parameters.yml`, sprawdź konfigurację przed jego wykonaniem.\\n\\n```\\nperl insert.pl\\n```\\n\\nInstalujemy paczki `php`\\n\\n```\\ncomposer install\\n```\\n\\nWykonujemy testy\\n\\n```\\nvendor/bin/behat\\n```\\n\\nPo instalacji wykonanie przetważania obrazu, oczyszczenie danych, zapis treści oraz testowanie bazy wyglądają następująco.\"}],[\"html\",{\"html\":\"<video src=\\\"https://www.dropbox.com/s/6s576n4h8m0iu3w/4.mp4?dl=1\\\" controls></video>\"}],[\"markdown\",{\"markdown\":\"## Struktura baz\\n\\nZa punkt wyjścia przyjmiemy zadania `2.4.1` i `2.4.3` z rozdziału [`2`](http://infolab.stanford.edu/~ullman/fcdb/ch2.pdf) książki `Database Systems: The Complete Book`. Zadanie polegają na napisaniu selektów.\\n\\nBędziemy tworzyć dwie bazy. Pierwsza zawiera magazyn sklepu elektronicznego.\\n\\n> `electronic_store`\\n\\n![struktura bazy 1](https://github.com/gustawdaniel/image_to_database_converter_example/raw/master/sql/electronic_store.png)\\n\\nJej kod w sql wygląda następująco:\\n\\n> sql/electronic_store.sql\\n\\n```sql\\nDROP DATABASE   IF     EXISTS electronic_store;\\nCREATE DATABASE IF NOT EXISTS electronic_store;\\nuse electronic_store;\\n\\nCREATE TABLE product (\\n  producer CHAR(1),\\n  model    DECIMAL(4,0),\\n  type     VARCHAR(255)\\n);\\n\\nCREATE TABLE pc (\\n  model DECIMAL(4,0),\\n  speed DECIMAL(3,2),\\n  ram   SMALLINT,\\n  disc  SMALLINT,\\n  price SMALLINT\\n);\\n\\nCREATE TABLE laptop (\\n  model DECIMAL(4,0),\\n  speed DECIMAL(3,2),\\n  ram   SMALLINT,\\n  disc  SMALLINT,\\n  screen DECIMAL(3,1),\\n  price SMALLINT\\n);\\n\\nCREATE TABLE printer (\\n  model DECIMAL(4,0),\\n  color BOOL,\\n  type  VARCHAR(255),\\n  price SMALLINT\\n);\\n```\\n\\n\\n\\nDruga to baza z danymi dotyczącymi okrętów liniowych drugiej wojny światowej.\\n\\n> `warships`\\n\\n![struktura bazy 2](https://github.com/gustawdaniel/image_to_database_converter_example/raw/master/sql/warships.png)\\n\\nMa bardzo podobną strukturę kodu\\n\\n> sq/warships.sql\\n\\n```sql\\nDROP DATABASE   IF     EXISTS warships;\\nCREATE DATABASE IF NOT EXISTS warships;\\nuse warships;\\n\\nCREATE TABLE classes (\\n  class VARCHAR(255),\\n  type CHAR(2),\\n  country VARCHAR(255),\\n  numGuns SMALLINT,\\n  bore SMALLINT,\\n  displacement INTEGER\\n);\\n\\nCREATE TABLE ships (\\n  name VARCHAR(255),\\n  class VARCHAR(255),\\n  launched SMALLINT\\n);\\n\\nCREATE TABLE battles (\\n  name VARCHAR(255),\\n  date VARCHAR(255)\\n);\\n\\nCREATE TABLE outcomes (\\n  ship VARCHAR(255),\\n  battle VARCHAR(255),\\n  result VARCHAR(255)\\n)\\n\\n```\\n\\nDane nie są powiązane żadnymi więzami integralności referencyjnej.\\n\\n## Źródło danych\\n\\nProblem z danymi zaczyna się od tego, że baza jest zapisana w pliku `pdf`, jest to po prostu fragment książki. Jest to słabo zrobiony `pdf` i dane z niego nie nadają się do zaznaczenia i skopiowania. Na szczęście znajdziemy rozwiązanie stosując OCR.\\n\\n### Grafiki\\n\\nZaczniemy od zrobienia screenów tabel z książki. W [repozytorium](https://github.com/gustawdaniel/image_to_database_converter_example), znajdują się te screeny. Są zapisane do plików o nazwach odpowiadających nazwom tabel w katalogu `raw/1` dla pierwszej bazy i `raw/2` dla drugiej. Przykładowy plik `raw/1/laptop.png` wygląda następująco.\\n\\n![laptop](http://i.imgur.com/CPRm97P.png)\\n\\n### Wydobycie tekstu (OCR)\\n\\nTeraz trzeba zainstalować `tesseract-ocr` komendą:\\n\\n```\\nsudo apt-get install tesseract-ocr\\n\\n```\\n\\nWykonamy rozpoznawanie tekstu na każdym z zapisanych plików. Pomoże nam w tym prosty skrypt:\\n\\n> process.sh\\n\\n```bash\\n#!/usr/bin/env bash\\n\\nRAW=raw;\\nBUILD=build;\\n\\nmkdir -p $BUILD;\\nrm -rf $BUILD/*\\n\\nfor cat in $RAW/*\\ndo\\n    baseCat=$(basename $cat .png);\\n    for file in $cat/*.png\\n    do\\n        baseFile=$(basename $file .png);\\n        mkdir -p $BUILD/$baseCat;\\n        tesseract $file $BUILD/$baseCat/$baseFile;\\n    done\\ndone\\n\\n```\\n\\nWyniki są w zasadzie dobre, poza tym, że czasami pojawiają się puste linie, w jednym miejscu pojawiła się spacja i `ram` został wczytany jako `mm`. Jednak poważnym problemem jest to, że w drugiej bazie część rekordów ma nazwy składające się z kilku wyrazów. Mimo to wyrażenia regularne szybko załatwią ten problem. Z wyrażeniami regularnymi i transformowaniem danych do strukturyzowanej postaci kojarzy mi się perl, dlatego ten język wykorzystamy do wypełnienia bazy danymi.\"}],[\"markdown\",{\"markdown\":\"### Przetworzenie tekstu\\n\\nJak zwykle zaczynamy od konfiguracji, ponieważ korzystać z niej będą `perl` i `php`, wydzielamy ją do osobnego pliku.\\n\\n> config/parameters.yml\\n\\n```yml\\nconfig:\\n  type: mysql\\n  host: localhost\\n  user: root\\n  pass: \\\"\\\"\\n  bases:\\n   - electronic_store\\n   - warships\\n\\n```\\n\\nTeraz zajmiemy się poprawą jakości tekstu i wrzuceniem go do bazy.\\n\\n#### Definicje\\n\\nWiększość moich skryptów zaczyna się podobnie. Są to nagłówki z paczkami.\\n\\n> insert.pl\\n\\n```perl\\n#!/usr/bin/env perl\\n# This script save data to database\\n\\nuse Modern::Perl;       # modern syntax\\nuse File::Basename;     # parsing names of files\\nuse YAML::Tiny;         # open yml config\\nuse DBI();              # database connection\\n\\nuse strict;             # strict mode\\nuse warnings;\\nuse open ':std', ':encoding(UTF-8)';\\n\\n```\\n\\nPóźniej wchodzą zmienne z konfiguracją związaną ze środowiskiem:\\n\\n```perl\\n#----------------------------------------------------------------------#\\n#                        Configuration                                 #\\n#----------------------------------------------------------------------#\\nmy $build = \\\"build/\\\";\\nmy $sql = \\\"sql/\\\";\\nmy $parameters = 'config/parameters.yml';\\n\\n\\nmy $yaml = YAML::Tiny->read( $parameters );\\nmy $config = $yaml->[0]->{config};\\n\\n```\\n\\nNastępnie mamy definicje. Jedyną zdefiniowaną tu funkcją jest procedura wykonywania wyrażeń regularnych - znajdź i zamień. Jest to zbiór filtrów przez jakie będzie przechodził tekst przeczytany przez OCR.\\n\\n```perl\\n#--------------------------------------------------------------#\\n#         Fix file structure broken by OCR inaccuracy          #\\n#--------------------------------------------------------------#\\nsub fixStructure\\n{\\n    s/mm/ram/g;\\n    s/\\\\s(\\\\d{3})\\\\s(\\\\d)\\\\s/ $1$2 /g;\\n    s/\\\\|\\\\s//g;\\n    s/true/1/g;\\n    s/false/0/g;\\n\\n    s/(\\\\w+)\\\\s(\\\\w+)\\\\s(\\\\d{1,2}\\\\/)/$1_$2 $3/g;\\n    s/North\\\\s(\\\\w+)/North_$1/g;\\n    s/West Virginia/West_Virginia/g;\\n    s/South Dakota/South_Dakota/g;\\n    s/Royal\\\\s(\\\\w+)/Royal_$1/g;\\n    s/New Jersey/New_Jersey/g;\\n    s/King George V/King_George_V/g;\\n    s/Pearl Harbor/Pearl_Harbor/g;\\n    s/Prince of Wales/Prince_of_Wales/g;\\n    s/Duke of York/Duke_of_York/g;\\n    s/Gt. Britain/Gt._Britain/g;\\n    s/\\\\sStrait/_Strait/g;\\n};\\n\\n\\n```\\n\\nFunkcja nie ma parametrów, ponieważ działa na zmiennej `$_`. Warto przy tym zwrócić na pewną ciekawą właściwość `perla`, która wyróżnia go na tle innych języków. Jest to między innymi właśnie zmienna `$_` której wartość zależy od kontekstu i której nie trzeba nawet pisać jeśli kontekst wskazuje, że o nią chodzi. W zamyśle twórcy języka - Larry'ego Walla - upodabniało go to do języka mówionego, w którym nie wskazujemy ciągle podmiotu, jeśli jest on oczywisty. Z jednej strony pozwala to szybko pisać gęsty kod dużych możliwościach, z drugiej bardzo utrudnia jego czytanie, jeśli nie jest on wystarczająco dobrze udokumentowany, a osoba czytająca nie zna tego języka wystarczająco dobrze. Być może ta elastyczność jest jednym z powodów upadku tego języka w starciu z bardzo restrykcyjnym `pythonem`, ale dla mnie jest ona raczej zaletą niż wadą. W każdym razie u nas zmienna `$_` będzie przyjmować wartość ciągu znaków z jednej linii czytanego tekstu\\n\\nPrzyjrzyjmy się dokładnie regułom jakie wprowadziłem, bo to jest serce całego programu.\\n\\nReguły `s/A/B/g` wykonują na zmiennej `$_` operację wyszukania ciągu `A` i zamiany go na ciąg `B`. Pierwsza z nich naprawia błędny odczyt kolumny `ram` odczytanej przez `OCR` jako `mm`, druga usuwa spację z jednego z identyfikatorów, kolejna pozbywa się linii pionowych. Dwie następne przekształcają wartości logiczne do postaci zero-jedynkowej. Wszystkie następne to wybieranie odpowiednich spacji i zastępowanie ich znakami `_`. Jest to poprawne podejście jeśli w analizowanym tekście nie ma znaku `_`, co jest prawdą w omawianym tutaj przykładzie.\\n\\n#### Skrypt\\n\\nWykonywalna część skryptu zaczyna się od iterowania po bazach danych wymienionych w konfiguracji:\\n\\n```perl\\n#----------------------------------------------------------------------#\\n#                            Script                                    #\\n#----------------------------------------------------------------------#\\n\\n        #--------------------------------------------------------------#\\n        #                      Loop over databases                     #\\n        #--------------------------------------------------------------#\\nwhile (my ($baseNumber, $baseName) = each @{ $config->{\\\"bases\\\"} })\\n{\\n    print $baseNumber.\\\"\\\\t\\\".$baseName.\\\".sql\\\".\\\"\\\\n\\\";\\n\\n```\\n\\nNastępnie dbamy o idempotentność czyli możliwość powtarzania skryptu wiele razy bez zmiany wyniku. Wykonujemy kody `sql` przywracające stany baz do czystej postaci. Możliwe, że w Twoim systemie będziesz musiał dopisać `sudo` przed komendą `mysql`.  Ja jestem zwolennikiem raczej zmiany uprawnień dostępu do bazy, jeśli to mój prywatny, lokalny komputer, niż wpisywania haseł przy każdym włączaniu bazy z terminala.\\n\\n```perl\\n    #--------------------------------------------------------------#\\n    #  Reset database, put `sudo` before `mysql` if access error   #\\n    #--------------------------------------------------------------#\\n\\n    my $passSting = ($config->{pass} eq \\\"\\\") ? \\\"\\\" : \\\" -p \\\".$config->{pass};\\n    system('mysql -h '.$config->{host}.' -u '.$config->{user}.$passSting.' < '.$sql.$baseName.\\\".sql\\\");\\n\\n```\\n\\nPołączenie z bazą danych było już omawiane na tym blogu, dla przypomnienia, wygląda ono tak:\\n\\n```perl\\n    #--------------------------------------------------------------#\\n    #                 Connect to the database                      #\\n    #--------------------------------------------------------------#\\n\\n    my $dbh = DBI->connect( \\\"DBI:mysql:database=\\\".$baseName.\\\";host=\\\".$config->{host},\\n        $config->{user}, $config->{pass}, {\\n            'PrintError'        => 0,\\n            'RaiseError'        => 1,\\n            'mysql_enable_utf8' => 1\\n        } ) or die \\\"Connect to database failed\\\";\\n\\n```\\n\\nCiekawiej robi się przy pętli po wszystkich plikach:\\n\\n```perl\\n            #--------------------------------------------------------------#\\n            #                     Loop over files                          #\\n            #--------------------------------------------------------------#\\n\\n        my @files = <$build$baseNumber\\\"/\\\"*.txt>;\\n        foreach my $file (@files) {\\n\\n            my $name = basename($file, \\\".txt\\\");\\n            print $file.\\\"\\\\t\\\".$name.\\\"\\\\n\\\";\\n            open(my $fh, '<:encoding(UTF-8)', $file)\\n                or die \\\"Could not open file '$file' $!\\\";\\n\\n```\\n\\nW zmiennej `$name` zapisywane są nazwy pozbawione ścieżki i rozszerzenia. Tak się składa, że są to dokładnie nazwy tabel w naszej bazie. Jeszcze to wykorzystamy w przy składaniu insertów. Naturalną konsekwencją iterowania po plikach tekstowych jest otwieranie ich. Uchwyt pliku trzymamy w zmiennej `$fh`, więc wykonujemy po nim pętle:\\n\\n```perl\\n        #--------------------------------------------------------------#\\n        #               Read all lines of given file                   #\\n        #--------------------------------------------------------------#\\n\\n        my $index = 0; my $statement;\\n        while (<$fh>) {\\n\\n```\\n\\nPrzed pętlą zdefiniowaliśmy sobie dwie zmienne. `$index` pozwalającą odnieść się do numeru nie pustej linii, oraz `$statement`, która będzie przechowywała przygotowany insert. Odczytywane linie należy poddać pewnej obróbce przed zapisaniem. Zaczniemy od wycięcia znaków końca linii i pominięcia linii zawierających tylko spacje.\\n\\n```perl\\n        #--------------------------------------------------------------#\\n        #         Skip empty lines and cut new line signs              #\\n        #--------------------------------------------------------------#\\n            chomp;\\n            if(m/^\\\\s*$/) {\\n                next;\\n            }\\n\\n```\\n\\nTu właśnie objawia się magia zmiennej kontekstowej `$_`. Każdy wie, że iterując po liniach pliku, to właśnie te linie są w centrum zainteresowania. Dlatego nie musimy ich nawet nazywać. Zamiast pisać `chomp $line` możemy napisać `chomp $_`, ale po co, skoro wystarczy napisać `chomp`. Z kontekstu wynika, że znak nowej linii ma być wycięty ze zmiennej po której właśnie przechodzi bieżąca iteracja pętli. Tak więc po tym początkowym oczyszczeniu możemy zastosować nasze filtry. Nic prostszego. Odpowiada za to napis:\\n\\n```perl\\n                &fixStructure;\\n\\n```\\n\\nNa koniec rozbijamy naprawiony już wiersz `$_` spacjami i jako tablicę zapisujemy do zmiennej `@row`. Zwykle u mnie jest tak, że największa magia dzieje się na końcu skryptu, tak jest i tym razem.\\n\\n```perl\\n        #--------------------------------------------------------------#\\n        #   In first row define statement, in next ones execute them   #\\n        #--------------------------------------------------------------#\\n            if(!$index++){\\n                my $query = \\\"INSERT INTO $name (\\\".join(\\\",\\\",@row).\\\") VALUES (?\\\". \\\",?\\\"x(@row-1) .\\\")\\\";\\n                $statement = $dbh->prepare($query);\\n            } else {\\n                s/_/ / for @row;\\n                $statement->execute(@row);\\n            }\\n\\n            print \\\"\\\\t\\\" . $_ . \\\"\\\\n\\\";\\n        }\\n    }\\n\\n```\\n\\nW warunku `$if` sprawdzamy czy `$idnex` był wcześniej podnoszony jednocześnie go podnosząc. Dla pierwszego wykonania tablica `@row` powinna zawierać nazwy kolumn z tabeli `$name`. Przypominam, że `$name` było tak dobierane, żeby odpowiadało nazwom kolumn już na etapie robienia screenów. Przy pierwszym wykonaniu tworzymy `$query`, jest to treść inserta, który będziemy wykonywać dla wszystkich pozostałych linii pliku tekstowego.\\n\\nFragment `join(\\\",\\\",$row)` wykonuje na tablicy `@row` operację rzutowania jej na `sting` i łączenia przecinkami.\\n\\nOperacja `\\\",?\\\"x(@row-1)` również rzutuje tablicę `@row` ale tym razem w kontekście numerycznym - odejmujemy od niej jedynkę. Z tego względu rzutowanie wykonywane jest w najbardziej naturalny sposób na ilość elementów tablicy. Znak `x` bardzo typowy dla `perla` to operator powtarzania `stringa` określoną liczbę razy. Na przykład `\\\"a\\\"x3` jest równoważne napisaniu `\\\"aaa\\\"`.\\n\\nPo określeniu tekstowej reprezentacji zapytania następuje jego przygotowanie, a przy każdej kolejnej linii przetworzonego tekstu, już tylko przywrócenie spacji zamiast znaków `_` wykonywane na każdym wyrazie tablicy osobno i wykonanie insertu.\\n\\n```perl\\n        #-----------------------------------------------------------#\\n        #                   Close connection                        #\\n        #-----------------------------------------------------------#\\n    $dbh->disconnect();\\n\\n```\\n\\nNa końcu zamykamy połączenie z bazą.\\n\\n\"}],[\"markdown\",{\"markdown\":\"## Zapytania do bazy\\n\\nPo sklonowaniu repozytorium, możesz odtworzyć mój stan bazy wykonując komendy:\\n\\n```bash\\nbash process.sh\\nperl insert.pl\\n\\n```\\n\\nJeśli chodzi o oprogramowanie, to przez połowę życia pisałem zapytania bezpośrednio w konsoli `mysql`. Lubiłem to, ale często musiałem je kopiować do osobnego pliku, albo przepadały na zawsze. Było to trochę męczące przy opracowywaniu bardziej złożonych zapytań. Później przy pracy nad jednym z projektów zrobiłem research mając nadzieję, że znajdę jakieś przyjemne narzędzie. Udało się, trafiłem na `dbvis`. Pomogło mi przestać korzystać z `DIA`, które mimo, że jest użyteczne przy projektowaniu bazy nie nadaje się do utrzymywania jej aktualnego stanu. Teraz zacząłem korzystać z narzędzia `DataGrip`, które dostarczyło mi wszystko czego chciałem - podświetlanie składni, wizualizację schematów, zapisywanie selektów.\\n\\nPrzejdziemy teraz do zapytań, które będziemy projektować. Będę wymieniał na przemian pytanie i selekt, który daje odpowiedź.\\n\\n### Baza skelpu elektronicznego\\n\\nKtóre modele komputerów PC mają szybkość równą przynajmniej 3.00?\\n\\n```sql\\nSELECT model FROM pc WHERE speed >= 3.0;\\n\\n```\\n\\nKtórzy producenci wytwarzają laptopy z dyskiem twardym o wielkości przynajmniej 100 gigabajtów?\\n\\n```sql\\nSELECT maker FROM product NATURAL JOIN laptop WHERE hd >= 100;\\n\\n```\\n\\nZnajdź numery modeli i ceny wszystkich produktów dowolnego typu wytwarzanych przez producenta B\\n\\n```sql\\nSELECT model,price FROM laptop UNION SELECT model,price FROM pc UNION SELECT model,price FROM printer NATURAL JOIN product as p WHERE p.maker='B';\\n\\n```\\n\\nZnajdź numery wszystkich kolorowych drukarek laserowych\\n\\n```sql\\nSELECT model FROM printer WHERE color AND type='laser';\\n\\n```\\n\\nZnajdź producentów sprzedających laptopy, ale już nie komputery pc\\n\\n```sql\\nSELECT DISTINCT maker FROM laptop NATURAL JOIN product WHERE maker NOT IN (SELECT DISTINCT maker FROM pc NATURAL JOIN product);\\n\\n```\\n\\nZnajdź wielkości dysków twardych występujące w przynajmniej dwóch komputerach pc\\n\\n```sql\\nSELECT hd FROM (SELECT count(*) as c, hd FROM pc GROUP BY hd) as calc WHERE c>=2;\\n\\n```\\n\\nZnajdź pary modeli PC o tej samej ilości pamięci ram i szybkości. pary powinny pojawiać się jednokrotnie, na przykład, należy wymienić parę (i,j) ale już nie (j,i)\\n\\n```sql\\nSELECT a.model, b.model FROM pc as a JOIN pc as b ON a.speed=b.speed AND a.ram=b.ram WHERE a.model>b.model;\\n\\n```\\n\\nZnajdź producentów wytwarzjących przynajmniej dwa różne komputery pc lub laptopy o szybkości co najmniej 2.8\\n\\n```sql\\nSELECT  maker from (SELECT maker, count(model) as c FROM product as p NATURAL JOIN (SELECT model, speed FROM pc WHERE speed>=2.8 UNION SELECT model, speed FROM laptop WHERE speed>=2.8) as u GROUP BY maker) as mc WHERE c>=2;\\n\\n```\\n\\nZnajdź producenta lub producentów najszybszych komputerów (pc lub laptopów)\\n\\n```sql\\nSELECT DISTINCT maker FROM product as p NATURAL JOIN (SELECT model,speed FROM laptop UNION SELECT model,speed FROM pc) as c WHERE speed=(SELECT MAX(speed) FROM (SELECT speed FROM laptop UNION SELECT speed FROM pc) as u);\\n\\n```\\n\\nZnajdź producentów komputerów PC o przynajmniej trzech różnych szybkościach\\n\\n```sql\\nSELECT maker from (SELECT maker, count(speed) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c>=3;\\n\\n```\\n\\nZnajdź producentów którzy sprzedają dokładnie trzy różne modele komputerów PC\\n\\n```sql\\nSELECT maker from (SELECT maker, count(model) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c=3;\\n\\n```\\n\\n### Baza okrętów liniowych\\n\\nPodaj nazwy i kraje klas okrętów z działami o kalibrze przynajmniej szesnastu cali.\\n\\n```sql\\nSELECT name, country FROM classes NATURAL JOIN ships WHERE bore>=16;\\n\\n```\\n\\nZnajdź okręty zwodowane przed 1921 rokiem\\n\\n```sql\\nSELECT name FROM ships WHERE launched<1921;\\n\\n```\\n\\nZnajdź okręty zatopione w bitwie pod Denamrk Strait\\n\\n```sql\\nSELECT ship FROM outcomes WHERE result=\\\"sunk\\\" AND battle=\\\"Denmark Strait\\\";\\n\\n```\\n\\nTraktat Waszyngtoński z 1921 zabraniał budowania okrętów liniowych o masie powyżej 35 000 ton. Wymień okręty niezgodne z traktatem.\\n\\n```sql\\nSELECT name FROM classes NATURAL JOIN ships WHERE launched>1921 AND displacement>35000;\\n\\n```\\n\\nPodać nazwę, wyporność i liczbę dział okrętów biorących udział w bitwie pod Guadalcanal\\n\\n```sql\\nSELECT DISTINCT name, displacement, numGuns FROM classes NATURAL JOIN ships NATURAL JOIN outcomes WHERE battle='Guadalcanal';\\n\\n```\\n\\nPodaj wszystkie okręty znajdujące się bazie danych, pamiętaj, że niektóre okręty nie znajdują się w relacji Okręty\\n\\n```sql\\nSELECT name FROM ships UNION SELECT ship FROM outcomes;\\n\\n```\\n\\nZnajdź klasy reprezentowane tylko przez jeden okręt\\n\\n```sql\\nSELECT class FROM (SELECT class, count(class) as c FROM classes as cl NATURAL JOIN (SELECT ship, ship as class FROM outcomes as o UNION SELECT name, class FROM ships as s) as ext_ship GROUP BY class) as total WHERE c=1;\\n\\n```\\n\\nZnajdź kraje które posiadały zarówno pancerniki jak i krążowniki\\n\\n```sql\\nSELECT t1.country FROM classes as t1 JOIN classes as t2 ON t1.country=t2.country WHERE t1.type='bb' AND t2.type='bc';\\n\\n```\\n\\nZnajdź okręty, które \\\"przetrwały, ale mogły jeszcze wziąć udział w boju\\\" - zostały uszkodzone w jednej bitwie, a później uczestniczyły w innej.\\n\\n```sql\\nSELECT f.name as name FROM\\n  (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN     outcomes as o1 ON b1.name=o1.battle) as f\\n    JOIN\\n  (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN    outcomes as o1 ON b1.name=o1.battle) as s\\n    ON f.name=s.name AND s.year < f.year AND s.result='sunk';\\n\\n```\\n\\nZdziwiło mnie to, ale baza nie zawiera żadnego rekordu odpowiadającego na ostatnie pytanie. Jednak sprawdziłem to ręcznie przeglądając bazę i faktycznie tak jest.\\n\\n## Testy\\n\\nDo testów wykorzystamy `behat`. Jeśli skopiowałeś to repozytorium, wystarczy, że wpiszesz `composer install` i nie musisz wykonywać żadnej z trzech poniższych instrukcji. W przeciwnym wypadku, możesz zainstalować `behat` komendą\\n\\n```\\ncomposer require behat/behat\\n\\n```\\n\\nŻeby nie wymyślać koła od nowa, do assertów podepniemy `phpunit`\\n\\n```\\ncomposer require phpunit/phpunit\\n\\n```\\n\\nPrzygodę z `behatem` zaczynamy od utworzenia pustego kontekstu za pomocą komendy.\\n\\n```\\nvendor/bin/behat --init\\n\\n```\\n\\nWypełnimy go teraz treścią.\\n\\n### Kontekst\\n\\nZaczynamy od podpięcia klas, z których będziemy korzystać:\\n\\n> features/bootstrap/FeatureContext.php\\n\\n```php\\n<?php\\n\\nuse Behat\\\\Behat\\\\Context\\\\Context;\\nuse Behat\\\\Gherkin\\\\Node\\\\TableNode;\\nuse Symfony\\\\Component\\\\Yaml\\\\Yaml;\\nuse PHPUnit\\\\Framework\\\\TestCase;\\n\\n/**\\n * Defines application features from the specific context.\\n */\\nclass FeatureContext extends TestCase implements Context\\n{\\n\\n```\\n\\nNasz kontekst rozszerza klasę `TestCase`, dostarczaną przez `phpunit` abyśmy mogli łatwo narzucać warunki. Podczas działania testów będą nam potrzebne trzy zmienne.\\n\\n```php?start_inline=1\\nprivate $config;\\nprivate $pdo;\\nprivate $data;\\n\\n```\\n\\nDo zmiennej `$config` zapiszemy konfigurację z pliku `config/parameters.yml`, w `$pdo` będziemy trzymać połączenie z bazą, a `$data` będzie przechowywać wynik ostatniego zapytania. Dwóm pierwszym możemy przypisać wartości już w konstruktorze.\\n\\n```php?start_inline=1\\n    public function __construct()\\n    {\\n        parent::__construct();\\n\\n        $this->config = Yaml::parse(file_get_contents(__DIR__.'/../../config/parameters.yml'))[\\\"config\\\"];\\n        $this->setPdoUsingBaseNumber(0);\\n    }\\n\\n```\\n\\nDziedziczymy tutaj konstruktor z `phpunit`. Następnie ustawiany zmienną `$config`. Nie musimy instalować dodatkowego parsera do `yml` ponieważ `behat` wziął sobie ten z `symfony`, sam przecież używa swojej własnej konfiguracji w formacie `yml`. Na koniec ustawiamy połączenie z domyślną bazą - `electronic_store` za pomocą funkcji `setPdoUsingBaseNumber(0)`. Jej kod jest następujący:\\n\\n```php?start_inline=1\\n    private function setPdoUsingBaseNumber($baseNumber)\\n    {\\n        try {\\n            $this->pdo = new PDO(\\n                $this->config[\\\"type\\\"].\\n                ':host='.$this->config[\\\"host\\\"].\\n                ';dbname='.$this->config[\\\"bases\\\"][$baseNumber],\\n                $this->config[\\\"user\\\"],\\n                $this->config[\\\"pass\\\"]);\\n\\n            $this->pdo->setAttribute(PDO::ATTR_DEFAULT_FETCH_MODE, PDO::FETCH_OBJ);\\n\\n        } catch (PDOException $e) {\\n            echo 'Connection failed: ' . $e->getMessage();\\n        }\\n    }\\n\\n```\\n\\nGeneralnie można się było tego spodziewać. Z ciekawych rzeczy jest tu tylko ustawienie atrybutów naszego połączenia. Chcemy, żeby konwertował wyniki zapytań do obiektów. Mimo, że do większości assertów wykorzystamy `phpunit` nie ma on sprawdzania występowania w tablicy dla bardziej złożonych obiektów.  Można by to ominąć serializując obiekty, ale tutaj zastosowałem inne podejście i porównałem je ręcznie.\\n\\n```php?start_inline=1\\n    private function assertArrayContainsHash($theArray, $hash)\\n    {\\n        foreach($theArray as $arrayItem) {\\n            if((array) $arrayItem == $hash) {\\n                return true;\\n            }\\n        }\\n        throw new Exception(print_r($theArray).\\\" do not contain \\\".print_r($hash));\\n    }\\n\\n    private function assertArrayNotContainsHash($theArray, $hash)\\n    {\\n        foreach($theArray as $arrayItem) {\\n            if((array) $arrayItem == $hash) {\\n                throw new Exception(print_r($theArray).\\\" do contain \\\".print_r($hash));\\n            }\\n        }\\n        return true;\\n    }\\n\\n```\\n\\nTe funkcje sprawdzają, czy w wyniku zapytania - `$theArray` pojawił się testowany przez nas zbiór atrybutów - `$hash`.\\n\\nTeraz przedstawimy możliwe kroki, jakie mogą się pojawić podczas testowania.\\n\\n```php?start_inline=1\\n    /**\\n     * @Given I'm connected to :number database\\n     */\\n    public function connectToSecondDatabase($number)\\n    {\\n        $this->setPdoUsingBaseNumber($number-1);\\n    }\\n\\n```\\n\\nPrzełączamy się między bazami, zmieniamy numerację `1`, `2` na tą w jakiej numeruje się indeksy tablicy. Teraz wybieranie selektów.\\n\\n```php?start_inline=1\\n    /**\\n     * @When I select :query from database\\n     */\\n    public function iSelectFromDatabase($query)\\n    {\\n        $stmt = $this->pdo->query($query);\\n        $stmt->execute();\\n        $this->data = $stmt->fetchAll();\\n        $stmt->closeCursor();\\n    }\\n\\n```\\n\\nPo prostu tworzymy zapytanie, wykonujemy je i wyniki zapisujemy do zmiennej `$data`. Dla zachowania porządku czyścimy zapytanie. Jeśli interesuje nas zobaczenie wyniku, przygotowałem na to metodę\\n\\n```php?start_inline=1\\n    /**\\n     * @Then I print result\\n     */\\n    public function iPrintResult()\\n    {\\n//        echo json_encode($this->data, JSON_PRETTY_PRINT);\\n        print_r($this->data);\\n    }\\n\\n```\\n\\nOpcja formatowania do `jsona` też została przewidziana, ale ponieważ poza debugowaniem ten kod nie spełnia żadnego testowego zadania, nie tworzyłem dla niej osobnej metody. Czas na pierwsze z warunków jakie narzucamy na dane:\\n\\n```php?start_inline=1\\n    /**\\n     * @Then I should see :count results\\n     */\\n    public function iShouldSeeResults($count)\\n    {\\n        $this->assertEquals(sizeof($this->data), $count);\\n    }\\n\\n    /**\\n     * @Then I should see not less than :arg1 results\\n     */\\n    public function iShouldSeeNotLessThanResults($arg1)\\n    {\\n        $this->assertGreaterThanOrEqual($arg1,count($this->data));\\n    }\\n\\n    /**\\n     * @Then I should see not more than :arg1 results\\n     */\\n    public function iShouldSeeNotMoreThanResults($arg1)\\n    {\\n        $this->assertGreaterThanOrEqual(count($this->data),$arg1);\\n    }\\n\\n```\\n\\nJeśli chemy odnieść się do ilości rekordów w wyniku naszego zapytania możemy zarządać, żeby była ona  równa, nie mniejsza, bądź nie większa od podanej.\\n\\nKolejny możliwy krok to sprawdzenie wartości atrybutu dla pierwszego wiersza danego zapytania.\\n\\n```php?start_inline=1\\n    /**\\n     * @Then Firs result should have :key equal :value\\n     */\\n    public function firsResultShouldHaveEqual($key, $value)\\n    {\\n        $this->assertArrayHasKey(0,$this->data);\\n        $this->assertObjectHasAttribute($key,$this->data[0]);\\n        $this->assertEquals($this->data[0]->$key,$value);\\n    }\\n\\n```\\n\\nKolejno sprawdzamy czy wynik ma pierwszy wiersz, czy istnieje w nim podany atrybut i czy ma wartość której oczekujemy. Ostatni krok jest tak ogólny, że jest stosowany przy prawie każdym scenariuszu w prawie każdym przykładnie.\\n\\n```php?start_inline=1\\n    /**\\n     * @Then /^Result should( not)? contain fields:$/\\n     */\\n    public function resultShouldContainFields($not = null, TableNode $table)\\n    {\\n        foreach($table->getHash() as $hash)\\n        {\\n            if (!$not) {\\n                $this->assertArrayContainsHash($this->data, $hash);\\n            } else {\\n                $this->assertArrayNotContainsHash($this->data,$hash);\\n            }\\n        }\\n    }\\n\\n```\\n\\nSprawdza on czy wynik zapytania zawiera określona wartości dla podanych pól, lub czy ich nie zawiera. Ta ogólność możliwa jest dzięki wykorzystaniu w składni `gherkina` znaku `?` ozaczającego wystąpienie `0` lub `1` raz. Jeśli nie napiszemy `not`, zmienna `$not` przyjmie wartość domyślną `null` i jej zaprzeczenie będzie prawdziwe. Jednak ciekawsze niż sama logika instrukcji warunkowej jest zastosowanie obiektu `TableNode`. Jest to obiekt dostarczany przez `behat` i zawiera wszystkie dane z tabel, które użytkownik podaje w plikach `feature`. Tabele te mają nagłówk i wartości zapisane w wierszach. Obiekt `TableNode` powstał żeby nie powtarzać sztuczki jaką w `perlu` wykorzystałem do osobnego traktowania nagłówka i nie przetważać tych danych ręcznie. Iterując po jego metodzie `getHash()` przechodzimy po wszystkich wierszach tej tabeli z pominięciem nagłówka. W zmiennej `$hash`, trzymamy tablicę asocjacyjną z kluczami pobranymi z nagłówka (atrybutami w tabeli) i wartościm pobranymi z danego wiersza.\\n\\nTo właśnie tą tablicę asocjacyjną wrzucamy do pokazanych wczęśniej metod sprawdzania występowania danego rekordu w wyniku zapytania.\\n\\n### Scenariusze testowe\\n\\nW praktyce pisałem testy nie mając jeszcze zapytań i mój workflow był następujący:\\n\\n1) Przeczytać treść zapytania w języku naturalnym.\\n2) Napisać zapytanie w języku SQL.\\n3) Spojrzeć na obrazki z danymi.\\n4) Wybrać przykładowe rekordy, które powinny znaleźć się w odpowiedzi.\\n5) Wybrać przykładowe rekordy które nie powinny znaleźć się w odpowiedzi.\\n6) Wkleić selekt i dane do tabeli z testami.\\n7) Jeśli warunki nie są standardowe, dopisać brakujący scenariusz.\\n\\nOstatecznie plik ze scenariuszami testowymi wyewoluował do takiego postaci:\\n\\n> features/select.feature\\n\\n```gherkin\\nFeature: Selecting chosen fields from database\\n  In order to check if my queries are correct\\n  As an an database user\\n  I want to execute them and test some asserts\\n\\n```\\n\\nTo jest nagłówek, jest tylko dokumentacja, bo ten kod się nie wykonuje. Poniżej pierwszy scenariusz.\\n\\n```gherkin\\n  Scenario Outline: Checking number of rows\\n    Given I'm connected to <db> database\\n    When I select \\\"SELECT count(*) AS c FROM <table>\\\" from database\\n    Then I should see 1 results\\n    And Firs result should have \\\"c\\\" equal <count>\\n\\n    Examples:\\n      | db | table    | count |\\n      | 1  | product  | 30    |\\n      | 1  | pc       | 13    |\\n      | 1  | laptop   | 10    |\\n      | 1  | printer  | 7     |\\n      | 2  | classes  | 8     |\\n      | 2  | battles  | 4     |\\n      | 2  | outcomes | 16    |\\n      | 2  | ships    | 21    |\\n\\n```\\n\\nZostały tu sprawdzone czy ilości rekordów w bazie odpowiadają tym z ksiązki. Następnie zostają sprawdzone wszystkie zapytania, które mają tylko jedną kolumnę z wynikiem.\\n\\n```gherkin\\n  Scenario Outline: Testing query\\n    Given I'm connected to <db> database\\n    When I select <query> from database\\n    Then Result should contain fields:\\n      | <row>  |\\n      | <yes1> |\\n      | <yes2> |\\n    And Result should not contain fields:\\n      | <row>  |\\n      | <no1>  |\\n      | <no2>  |\\n\\n    Examples:\\n      | db | row   | yes1      | yes2             | no1       | no2        | query                                                                                                                                                                                                                              |\\n      | 1  | model | 1013      | 1006             | 1012      | 1007       | \\\"SELECT model FROM pc WHERE speed >= 3.0;\\\"                                                                                                                                                                                         |\\n      | 1  | maker | E         | A                | C         | H          | \\\"SELECT maker FROM product NATURAL JOIN laptop WHERE hd >= 100;\\\"                                                                                                                                                                   |\\n      | 1  | model | 3003      | 3007             | 3002      | 3005       | \\\"SELECT model FROM printer WHERE color AND type='laser'\\\"                                                                                                                                                                           |\\n      | 1  | maker | F         | G                | A         | D          | \\\"SELECT DISTINCT maker FROM laptop NATURAL JOIN product WHERE maker NOT IN (SELECT DISTINCT maker FROM pc NATURAL JOIN product);\\\"                                                                                                  |\\n      | 1  | maker | F         | G                | A         | D          | \\\"SELECT l.maker FROM (SELECT maker,type FROM product WHERE type='laptop') as l LEFT JOIN (SELECT maker,type FROM product WHERE type='pc') as p ON l.maker=p.maker WHERE p.maker IS NULL;\\\"                                          |\\n      | 1  | hd    | 250       | 80               | 300       | 350        | \\\"SELECT hd FROM (SELECT count(*) as c, hd FROM pc GROUP BY hd) as calc WHERE c>=2;\\\"                                                                                                                                                |\\n      | 1  | maker | B         | E                | H         | G          | \\\"SELECT  maker from (SELECT maker, count(model) as c FROM product as p NATURAL JOIN (SELECT model, speed FROM pc WHERE speed>=2.8 UNION  SELECT model, speed FROM laptop WHERE speed>=2.8) as u GROUP BY maker) as mc WHERE c>=2;\\\" |\\n      | 1  | maker | A         | B                | C         | G          | \\\"SELECT maker from (SELECT maker, count(speed) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c>=3;\\\"                                                                                                               |\\n      | 1  | maker | A         | D                | C         | H          | \\\"SELECT maker from (SELECT maker, count(model) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c=3;\\\"                                                                                                                |\\n      | 2  | name  | Ramillies | Royal Oak        | Wisconsin | Yamato     | \\\"SELECT name FROM ships WHERE launched<1921;\\\"                                                                                                                                                                                      |\\n      | 2  | ship  | Bismarck  | Hood             | Wisconsin | Rodney     | \\\"SELECT ship FROM outcomes WHERE result='sunk' AND battle='Denmark Strait'\\\"                                                                                                                                                        |\\n      | 2  | name  | Yamato    | North Carolina   | Kirishima | California | \\\"SELECT name FROM classes NATURAL JOIN ships WHERE launched>1921 AND displacement>35000\\\"                                                                                                                                           |\\n      | 2  |country| Japan     | Gt. Britain      |USA        | Germany    | \\\"SELECT t1.country FROM classes as t1 JOIN classes as t2 ON t1.country=t2.country WHERE t1.type='bb' AND t2.type='bc';\\\"                                                                                                            |\\n\\n```\\n\\nCiężko to nawet skomentować, ponieważ ten kod jest samowyjaśniający się. Po prostu łączymy się z bazę, wykonujemy selekt, sprawdzamy czy rezultat zawiera dwie przykładowe wartości, których się spodziewamy i czy nie zawiera dwóch innych, których nie powinno być.\\n\\nZupełnie analogicznie wygląda sytuacja, jeśli mamy dwie kolumny w wyniku.\\n\\n```gherkin\\n  Scenario Outline: Testing query with two attributes\\n    Given I'm connected to <db> database\\n    When I select <query> from database\\n    Then Result should contain fields:\\n      | <rowA>  | <rowB>  |\\n      | <yes1A> | <yes1B> |\\n      | <yes2A> | <yes2B> |\\n    And Result should not contain fields:\\n      | <rowA> | <rowB> |\\n      | <no1A> | <no1B> |\\n      | <no2A> | <no2B> |\\n    Examples:\\n      | db | rowA  | rowB    | yes1A  | yes1B | yes2A          | yes2B | no1A    | no1B         | no2A       | no2B | query                                                                                                                                                                            |\\n      | 1  | model | price   | 1004   | 649   | 2007           | 1429  | 2004    | 1150         | 3007       | 200  | \\\"SELECT model,price FROM product as p NATURAL JOIN (SELECT model,price FROM pc UNION SELECT model,price FROM laptop UNION SELECT model,price FROM printer) as s WHERE maker='B'\\\" |\\n      | 2  | name  | country | Yamato | Japan | North Carolina | USA   | Repulse | Gr. Brritain | California | USA  | \\\"SELECT name, country FROM classes NATURAL JOIN ships WHERE bore>=16;\\\"                                                                                                           |\\n\\n```\\n\\nNiestety nie znam mechanizmu, który pozwolił by połączyć te dwa scenariusze w jeden, nigdzie w dokumentacji nie było nawet słowa o dziedziczeniu scenariuszy. Może ktoś na [stacku](http://stackoverflow.com/questions/40941114/flexibility-of-scenarios-in-gherkin) zna na to jakiś hack.\\n\\nJeśli masz przeczucie czym to się skończy, to właśnie tak się kończy.\\n\\n```gherkin\\n  Scenario: Testing query with three attributes\\n    Given I'm connected to 2 database\\n    When I select \\\"SELECT DISTINCT name, displacement, numGuns FROM classes NATURAL JOIN ships NATURAL JOIN outcomes WHERE battle='Guadalcanal';\\\" from database\\n    Then Result should contain fields:\\n      | name       | numGuns | displacement |\\n      | Kirishima  | 8       | 32000        |\\n      | Washington | 9       | 37000        |\\n    And Result should not contain fields:\\n      | name     | numGuns | displacement |\\n      | Tenessee | 12      | 32000        |\\n      | Bismarck | 8       | 42000        |\\n\\n```\\n\\nI stało się, powtarzam ten sam kod trzeci raz. Wyrywałem sobie włosy z głowy, kiedy to pisałem. Okazało się, że jest tylko jeden przypadek selekta z trzema kolumnami, ale już widzimy niedoskonałość tego kodu.\\n\\nCzasem zdażało się, że chciałem przetestować występowanie tylko jednego wiersza, za to z dwoma atrybutami:\\n\\n```gherkin\\n  Scenario: Testing query (pairs)\\n    When I select \\\"SELECT a.model as a, b.model as b FROM pc as a JOIN pc as b ON a.speed=b.speed AND a.ram=b.ram WHERE a.model>b.model;\\\" from database\\n    Then Result should contain fields:\\n      | a     | b       |\\n      | 1012  | 1004    |\\n    And I should see 1 results\\n\\n```\\n\\nByły też przypadki z jednym rezultatem i jednym atrybutem\\n\\n```gherkin\\n  Scenario Outline: Testing query (max speed)\\n    Given I'm connected to <db> database\\n    When I select <query> from database\\n    And I should see 1 results\\n    And Firs result should have <row> equal <value>\\n    Examples:\\n      | db | row   | value    | query                                                                                                                                                                                                                          |\\n      | 1  | maker | B        | \\\"SELECT DISTINCT maker FROM product as p NATURAL JOIN (SELECT model,speed FROM laptop UNION SELECT model,speed FROM pc) as c WHERE speed=(SELECT MAX(speed) FROM (SELECT speed FROM laptop UNION SELECT speed FROM pc) as u);\\\" |\\n      | 2  | class | Bismarck | \\\"SELECT class FROM (SELECT class, count(class) as c FROM classes as cl NATURAL JOIN (SELECT ship, ship as class FROM outcomes as o UNION SELECT name, class FROM ships as s) as ext_ship GROUP BY class) as total WHERE c=1;\\\"  |\\n\\n```\\n\\nI przypadek z w którym nie znałem dokładnej liczby wyników, ale mogłem określić przedział w jakim się znajduje.\\n\\n```gherkin\\n  Scenario: Select all ships\\n    Given I'm connected to 2 database\\n    When I select \\\"SELECT name FROM ships UNION SELECT ship FROM outcomes;\\\" from database\\n    Then I should see not less than \\\"21\\\" results\\n    And I should see not less than \\\"16\\\" results\\n    And I should see not more than 37 results\\n    And Result should contain fields:\\n      | name |\\n      | Yamashiro |\\n      | Bismarck |\\n      | Fuso |\\n\\n```\\n\\nNa końcu zostałem zaskoczony przez scenariusz, w którym na wyjściu niczego nie dostałem.\\n\\n```gherkin\\n  Scenario: Select null\\n    Given I'm connected to 2 database\\n    When I select \\\"SELECT f.name as name FROM (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN outcomes as o1 ON b1.name=o1.battle) as f JOIN (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN outcomes as o1 ON b1.name=o1.battle) as s ON f.name=s.name AND s.year < f.year AND s.result='sunk';\\\" from database\\n    Then I should see 0 results\\n\\n```\\n\\nTak doszliśmy dokońca projektu.\\n\\nMam nadzieję, że przedstawiony materiał Ci się spodbał. Daj znać w komentarzu, jeśli coś wymaga dodatkowego wyjaśnienia, albo jeśli wiesz jak mógł bym napisać bardziej ogólne testy niż te przedstawione powyżej. Mam na myśli jeden scenariusz dla N atrubutów, z M przykładami, które występują i L które nie występują.\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"opis-projektu\">Opis projektu</h2>\n<p>Miałem tylko odświeżyć sobie pisanie zapytań do bazy, a skończyłem instalując <code>DataGrip</code> i <code>Tesseracta</code>. Pierwszy program jest to IDE do baz danych od <code>JetBrains</code>, drugi jest oprogramowaniem OCR - służy do rozpoznawania tekstów w grafice rastrowej.</p>\n<p>Naszym zadaniem będzie <strong>utworzenie schematów baz</strong> danych, <strong>odczytanie tekstu z plików graficznych</strong>, wrzucenie odczytanej zawartości <strong>napisanie kilku zapytań</strong> i <strong>testowanie zawartości</strong> za pomocą <code>behata</code>. Jeśli jesteś ciekaw jak to się robi, zapraszam do lektury.</p>\n<p>Skład kodu:</p>\n<pre><code>Cucumber 49.9% Perl 26.7% PHP 21.8% Shell 1.6%\n</code></pre>\n<h2 id=\"instalacja\">Instalacja</h2>\n<p>Pobieramy repozytorium:</p>\n<pre><code class=\"language-bash\">git clone https://github.com/gustawdaniel/image_to_database_converter_example.git &amp;&amp; cd image_to_database_converter_example\n</code></pre>\n<p>Instalujemy zależności.</p>\n<pre><code class=\"language-bash\">sudo apt-get install tesseract-ocr\n</code></pre>\n<p>Przetważamy obrazki na teksty</p>\n<pre><code>bash process.sh\n</code></pre>\n<p>Tworzymy bazy i wrzucamy do nich dane. Ten skrypt na początku usunie bazy o nazwach w z <code>config/parameters.yml</code>, sprawdź konfigurację przed jego wykonaniem.</p>\n<pre><code>perl insert.pl\n</code></pre>\n<p>Instalujemy paczki <code>php</code></p>\n<pre><code>composer install\n</code></pre>\n<p>Wykonujemy testy</p>\n<pre><code>vendor/bin/behat\n</code></pre>\n<p>Po instalacji wykonanie przetważania obrazu, oczyszczenie danych, zapis treści oraz testowanie bazy wyglądają następująco.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: html--><video src=\"https://www.dropbox.com/s/6s576n4h8m0iu3w/4.mp4?dl=1\" controls></video><!--kg-card-end: html--><!--kg-card-begin: markdown--><h2 id=\"struktura-baz\">Struktura baz</h2>\n<p>Za punkt wyjścia przyjmiemy zadania <code>2.4.1</code> i <code>2.4.3</code> z rozdziału <a href=\"http://infolab.stanford.edu/~ullman/fcdb/ch2.pdf\"><code>2</code></a> książki <code>Database Systems: The Complete Book</code>. Zadanie polegają na napisaniu selektów.</p>\n<p>Będziemy tworzyć dwie bazy. Pierwsza zawiera magazyn sklepu elektronicznego.</p>\n<blockquote>\n<p><code>electronic_store</code></p>\n</blockquote>\n<p><img src=\"https://github.com/gustawdaniel/image_to_database_converter_example/raw/master/sql/electronic_store.png\" alt=\"struktura bazy 1\" loading=\"lazy\"></p>\n<p>Jej kod w sql wygląda następująco:</p>\n<blockquote>\n<p>sql/electronic_store.sql</p>\n</blockquote>\n<pre><code class=\"language-sql\">DROP DATABASE   IF     EXISTS electronic_store;\nCREATE DATABASE IF NOT EXISTS electronic_store;\nuse electronic_store;\n\nCREATE TABLE product (\n  producer CHAR(1),\n  model    DECIMAL(4,0),\n  type     VARCHAR(255)\n);\n\nCREATE TABLE pc (\n  model DECIMAL(4,0),\n  speed DECIMAL(3,2),\n  ram   SMALLINT,\n  disc  SMALLINT,\n  price SMALLINT\n);\n\nCREATE TABLE laptop (\n  model DECIMAL(4,0),\n  speed DECIMAL(3,2),\n  ram   SMALLINT,\n  disc  SMALLINT,\n  screen DECIMAL(3,1),\n  price SMALLINT\n);\n\nCREATE TABLE printer (\n  model DECIMAL(4,0),\n  color BOOL,\n  type  VARCHAR(255),\n  price SMALLINT\n);\n</code></pre>\n<p>Druga to baza z danymi dotyczącymi okrętów liniowych drugiej wojny światowej.</p>\n<blockquote>\n<p><code>warships</code></p>\n</blockquote>\n<p><img src=\"https://github.com/gustawdaniel/image_to_database_converter_example/raw/master/sql/warships.png\" alt=\"struktura bazy 2\" loading=\"lazy\"></p>\n<p>Ma bardzo podobną strukturę kodu</p>\n<blockquote>\n<p>sq/warships.sql</p>\n</blockquote>\n<pre><code class=\"language-sql\">DROP DATABASE   IF     EXISTS warships;\nCREATE DATABASE IF NOT EXISTS warships;\nuse warships;\n\nCREATE TABLE classes (\n  class VARCHAR(255),\n  type CHAR(2),\n  country VARCHAR(255),\n  numGuns SMALLINT,\n  bore SMALLINT,\n  displacement INTEGER\n);\n\nCREATE TABLE ships (\n  name VARCHAR(255),\n  class VARCHAR(255),\n  launched SMALLINT\n);\n\nCREATE TABLE battles (\n  name VARCHAR(255),\n  date VARCHAR(255)\n);\n\nCREATE TABLE outcomes (\n  ship VARCHAR(255),\n  battle VARCHAR(255),\n  result VARCHAR(255)\n)\n\n</code></pre>\n<p>Dane nie są powiązane żadnymi więzami integralności referencyjnej.</p>\n<h2 id=\"%C5%BAr%C3%B3d%C5%82o-danych\">Źródło danych</h2>\n<p>Problem z danymi zaczyna się od tego, że baza jest zapisana w pliku <code>pdf</code>, jest to po prostu fragment książki. Jest to słabo zrobiony <code>pdf</code> i dane z niego nie nadają się do zaznaczenia i skopiowania. Na szczęście znajdziemy rozwiązanie stosując OCR.</p>\n<h3 id=\"grafiki\">Grafiki</h3>\n<p>Zaczniemy od zrobienia screenów tabel z książki. W <a href=\"https://github.com/gustawdaniel/image_to_database_converter_example\">repozytorium</a>, znajdują się te screeny. Są zapisane do plików o nazwach odpowiadających nazwom tabel w katalogu <code>raw/1</code> dla pierwszej bazy i <code>raw/2</code> dla drugiej. Przykładowy plik <code>raw/1/laptop.png</code> wygląda następująco.</p>\n<p><img src=\"http://i.imgur.com/CPRm97P.png\" alt=\"laptop\" loading=\"lazy\"></p>\n<h3 id=\"wydobycie-tekstu-ocr\">Wydobycie tekstu (OCR)</h3>\n<p>Teraz trzeba zainstalować <code>tesseract-ocr</code> komendą:</p>\n<pre><code>sudo apt-get install tesseract-ocr\n\n</code></pre>\n<p>Wykonamy rozpoznawanie tekstu na każdym z zapisanych plików. Pomoże nam w tym prosty skrypt:</p>\n<blockquote>\n<p>process.sh</p>\n</blockquote>\n<pre><code class=\"language-bash\">#!/usr/bin/env bash\n\nRAW=raw;\nBUILD=build;\n\nmkdir -p $BUILD;\nrm -rf $BUILD/*\n\nfor cat in $RAW/*\ndo\n    baseCat=$(basename $cat .png);\n    for file in $cat/*.png\n    do\n        baseFile=$(basename $file .png);\n        mkdir -p $BUILD/$baseCat;\n        tesseract $file $BUILD/$baseCat/$baseFile;\n    done\ndone\n\n</code></pre>\n<p>Wyniki są w zasadzie dobre, poza tym, że czasami pojawiają się puste linie, w jednym miejscu pojawiła się spacja i <code>ram</code> został wczytany jako <code>mm</code>. Jednak poważnym problemem jest to, że w drugiej bazie część rekordów ma nazwy składające się z kilku wyrazów. Mimo to wyrażenia regularne szybko załatwią ten problem. Z wyrażeniami regularnymi i transformowaniem danych do strukturyzowanej postaci kojarzy mi się perl, dlatego ten język wykorzystamy do wypełnienia bazy danymi.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id=\"przetworzenie-tekstu\">Przetworzenie tekstu</h3>\n<p>Jak zwykle zaczynamy od konfiguracji, ponieważ korzystać z niej będą <code>perl</code> i <code>php</code>, wydzielamy ją do osobnego pliku.</p>\n<blockquote>\n<p>config/parameters.yml</p>\n</blockquote>\n<pre><code class=\"language-yml\">config:\n  type: mysql\n  host: localhost\n  user: root\n  pass: &quot;&quot;\n  bases:\n   - electronic_store\n   - warships\n\n</code></pre>\n<p>Teraz zajmiemy się poprawą jakości tekstu i wrzuceniem go do bazy.</p>\n<h4 id=\"definicje\">Definicje</h4>\n<p>Większość moich skryptów zaczyna się podobnie. Są to nagłówki z paczkami.</p>\n<blockquote>\n<p>insert.pl</p>\n</blockquote>\n<pre><code class=\"language-perl\">#!/usr/bin/env perl\n# This script save data to database\n\nuse Modern::Perl;       # modern syntax\nuse File::Basename;     # parsing names of files\nuse YAML::Tiny;         # open yml config\nuse DBI();              # database connection\n\nuse strict;             # strict mode\nuse warnings;\nuse open ':std', ':encoding(UTF-8)';\n\n</code></pre>\n<p>Później wchodzą zmienne z konfiguracją związaną ze środowiskiem:</p>\n<pre><code class=\"language-perl\">#----------------------------------------------------------------------#\n#                        Configuration                                 #\n#----------------------------------------------------------------------#\nmy $build = &quot;build/&quot;;\nmy $sql = &quot;sql/&quot;;\nmy $parameters = 'config/parameters.yml';\n\n\nmy $yaml = YAML::Tiny-&gt;read( $parameters );\nmy $config = $yaml-&gt;[0]-&gt;{config};\n\n</code></pre>\n<p>Następnie mamy definicje. Jedyną zdefiniowaną tu funkcją jest procedura wykonywania wyrażeń regularnych - znajdź i zamień. Jest to zbiór filtrów przez jakie będzie przechodził tekst przeczytany przez OCR.</p>\n<pre><code class=\"language-perl\">#--------------------------------------------------------------#\n#         Fix file structure broken by OCR inaccuracy          #\n#--------------------------------------------------------------#\nsub fixStructure\n{\n    s/mm/ram/g;\n    s/\\s(\\d{3})\\s(\\d)\\s/ $1$2 /g;\n    s/\\|\\s//g;\n    s/true/1/g;\n    s/false/0/g;\n\n    s/(\\w+)\\s(\\w+)\\s(\\d{1,2}\\/)/$1_$2 $3/g;\n    s/North\\s(\\w+)/North_$1/g;\n    s/West Virginia/West_Virginia/g;\n    s/South Dakota/South_Dakota/g;\n    s/Royal\\s(\\w+)/Royal_$1/g;\n    s/New Jersey/New_Jersey/g;\n    s/King George V/King_George_V/g;\n    s/Pearl Harbor/Pearl_Harbor/g;\n    s/Prince of Wales/Prince_of_Wales/g;\n    s/Duke of York/Duke_of_York/g;\n    s/Gt. Britain/Gt._Britain/g;\n    s/\\sStrait/_Strait/g;\n};\n\n\n</code></pre>\n<p>Funkcja nie ma parametrów, ponieważ działa na zmiennej <code>$_</code>. Warto przy tym zwrócić na pewną ciekawą właściwość <code>perla</code>, która wyróżnia go na tle innych języków. Jest to między innymi właśnie zmienna <code>$_</code> której wartość zależy od kontekstu i której nie trzeba nawet pisać jeśli kontekst wskazuje, że o nią chodzi. W zamyśle twórcy języka - Larry'ego Walla - upodabniało go to do języka mówionego, w którym nie wskazujemy ciągle podmiotu, jeśli jest on oczywisty. Z jednej strony pozwala to szybko pisać gęsty kod dużych możliwościach, z drugiej bardzo utrudnia jego czytanie, jeśli nie jest on wystarczająco dobrze udokumentowany, a osoba czytająca nie zna tego języka wystarczająco dobrze. Być może ta elastyczność jest jednym z powodów upadku tego języka w starciu z bardzo restrykcyjnym <code>pythonem</code>, ale dla mnie jest ona raczej zaletą niż wadą. W każdym razie u nas zmienna <code>$_</code> będzie przyjmować wartość ciągu znaków z jednej linii czytanego tekstu</p>\n<p>Przyjrzyjmy się dokładnie regułom jakie wprowadziłem, bo to jest serce całego programu.</p>\n<p>Reguły <code>s/A/B/g</code> wykonują na zmiennej <code>$_</code> operację wyszukania ciągu <code>A</code> i zamiany go na ciąg <code>B</code>. Pierwsza z nich naprawia błędny odczyt kolumny <code>ram</code> odczytanej przez <code>OCR</code> jako <code>mm</code>, druga usuwa spację z jednego z identyfikatorów, kolejna pozbywa się linii pionowych. Dwie następne przekształcają wartości logiczne do postaci zero-jedynkowej. Wszystkie następne to wybieranie odpowiednich spacji i zastępowanie ich znakami <code>_</code>. Jest to poprawne podejście jeśli w analizowanym tekście nie ma znaku <code>_</code>, co jest prawdą w omawianym tutaj przykładzie.</p>\n<h4 id=\"skrypt\">Skrypt</h4>\n<p>Wykonywalna część skryptu zaczyna się od iterowania po bazach danych wymienionych w konfiguracji:</p>\n<pre><code class=\"language-perl\">#----------------------------------------------------------------------#\n#                            Script                                    #\n#----------------------------------------------------------------------#\n\n        #--------------------------------------------------------------#\n        #                      Loop over databases                     #\n        #--------------------------------------------------------------#\nwhile (my ($baseNumber, $baseName) = each @{ $config-&gt;{&quot;bases&quot;} })\n{\n    print $baseNumber.&quot;\\t&quot;.$baseName.&quot;.sql&quot;.&quot;\\n&quot;;\n\n</code></pre>\n<p>Następnie dbamy o idempotentność czyli możliwość powtarzania skryptu wiele razy bez zmiany wyniku. Wykonujemy kody <code>sql</code> przywracające stany baz do czystej postaci. Możliwe, że w Twoim systemie będziesz musiał dopisać <code>sudo</code> przed komendą <code>mysql</code>.  Ja jestem zwolennikiem raczej zmiany uprawnień dostępu do bazy, jeśli to mój prywatny, lokalny komputer, niż wpisywania haseł przy każdym włączaniu bazy z terminala.</p>\n<pre><code class=\"language-perl\">    #--------------------------------------------------------------#\n    #  Reset database, put `sudo` before `mysql` if access error   #\n    #--------------------------------------------------------------#\n\n    my $passSting = ($config-&gt;{pass} eq &quot;&quot;) ? &quot;&quot; : &quot; -p &quot;.$config-&gt;{pass};\n    system('mysql -h '.$config-&gt;{host}.' -u '.$config-&gt;{user}.$passSting.' &lt; '.$sql.$baseName.&quot;.sql&quot;);\n\n</code></pre>\n<p>Połączenie z bazą danych było już omawiane na tym blogu, dla przypomnienia, wygląda ono tak:</p>\n<pre><code class=\"language-perl\">    #--------------------------------------------------------------#\n    #                 Connect to the database                      #\n    #--------------------------------------------------------------#\n\n    my $dbh = DBI-&gt;connect( &quot;DBI:mysql:database=&quot;.$baseName.&quot;;host=&quot;.$config-&gt;{host},\n        $config-&gt;{user}, $config-&gt;{pass}, {\n            'PrintError'        =&gt; 0,\n            'RaiseError'        =&gt; 1,\n            'mysql_enable_utf8' =&gt; 1\n        } ) or die &quot;Connect to database failed&quot;;\n\n</code></pre>\n<p>Ciekawiej robi się przy pętli po wszystkich plikach:</p>\n<pre><code class=\"language-perl\">            #--------------------------------------------------------------#\n            #                     Loop over files                          #\n            #--------------------------------------------------------------#\n\n        my @files = &lt;$build$baseNumber&quot;/&quot;*.txt&gt;;\n        foreach my $file (@files) {\n\n            my $name = basename($file, &quot;.txt&quot;);\n            print $file.&quot;\\t&quot;.$name.&quot;\\n&quot;;\n            open(my $fh, '&lt;:encoding(UTF-8)', $file)\n                or die &quot;Could not open file '$file' $!&quot;;\n\n</code></pre>\n<p>W zmiennej <code>$name</code> zapisywane są nazwy pozbawione ścieżki i rozszerzenia. Tak się składa, że są to dokładnie nazwy tabel w naszej bazie. Jeszcze to wykorzystamy w przy składaniu insertów. Naturalną konsekwencją iterowania po plikach tekstowych jest otwieranie ich. Uchwyt pliku trzymamy w zmiennej <code>$fh</code>, więc wykonujemy po nim pętle:</p>\n<pre><code class=\"language-perl\">        #--------------------------------------------------------------#\n        #               Read all lines of given file                   #\n        #--------------------------------------------------------------#\n\n        my $index = 0; my $statement;\n        while (&lt;$fh&gt;) {\n\n</code></pre>\n<p>Przed pętlą zdefiniowaliśmy sobie dwie zmienne. <code>$index</code> pozwalającą odnieść się do numeru nie pustej linii, oraz <code>$statement</code>, która będzie przechowywała przygotowany insert. Odczytywane linie należy poddać pewnej obróbce przed zapisaniem. Zaczniemy od wycięcia znaków końca linii i pominięcia linii zawierających tylko spacje.</p>\n<pre><code class=\"language-perl\">        #--------------------------------------------------------------#\n        #         Skip empty lines and cut new line signs              #\n        #--------------------------------------------------------------#\n            chomp;\n            if(m/^\\s*$/) {\n                next;\n            }\n\n</code></pre>\n<p>Tu właśnie objawia się magia zmiennej kontekstowej <code>$_</code>. Każdy wie, że iterując po liniach pliku, to właśnie te linie są w centrum zainteresowania. Dlatego nie musimy ich nawet nazywać. Zamiast pisać <code>chomp $line</code> możemy napisać <code>chomp $_</code>, ale po co, skoro wystarczy napisać <code>chomp</code>. Z kontekstu wynika, że znak nowej linii ma być wycięty ze zmiennej po której właśnie przechodzi bieżąca iteracja pętli. Tak więc po tym początkowym oczyszczeniu możemy zastosować nasze filtry. Nic prostszego. Odpowiada za to napis:</p>\n<pre><code class=\"language-perl\">                &amp;fixStructure;\n\n</code></pre>\n<p>Na koniec rozbijamy naprawiony już wiersz <code>$_</code> spacjami i jako tablicę zapisujemy do zmiennej <code>@row</code>. Zwykle u mnie jest tak, że największa magia dzieje się na końcu skryptu, tak jest i tym razem.</p>\n<pre><code class=\"language-perl\">        #--------------------------------------------------------------#\n        #   In first row define statement, in next ones execute them   #\n        #--------------------------------------------------------------#\n            if(!$index++){\n                my $query = &quot;INSERT INTO $name (&quot;.join(&quot;,&quot;,@row).&quot;) VALUES (?&quot;. &quot;,?&quot;x(@row-1) .&quot;)&quot;;\n                $statement = $dbh-&gt;prepare($query);\n            } else {\n                s/_/ / for @row;\n                $statement-&gt;execute(@row);\n            }\n\n            print &quot;\\t&quot; . $_ . &quot;\\n&quot;;\n        }\n    }\n\n</code></pre>\n<p>W warunku <code>$if</code> sprawdzamy czy <code>$idnex</code> był wcześniej podnoszony jednocześnie go podnosząc. Dla pierwszego wykonania tablica <code>@row</code> powinna zawierać nazwy kolumn z tabeli <code>$name</code>. Przypominam, że <code>$name</code> było tak dobierane, żeby odpowiadało nazwom kolumn już na etapie robienia screenów. Przy pierwszym wykonaniu tworzymy <code>$query</code>, jest to treść inserta, który będziemy wykonywać dla wszystkich pozostałych linii pliku tekstowego.</p>\n<p>Fragment <code>join(&quot;,&quot;,$row)</code> wykonuje na tablicy <code>@row</code> operację rzutowania jej na <code>sting</code> i łączenia przecinkami.</p>\n<p>Operacja <code>&quot;,?&quot;x(@row-1)</code> również rzutuje tablicę <code>@row</code> ale tym razem w kontekście numerycznym - odejmujemy od niej jedynkę. Z tego względu rzutowanie wykonywane jest w najbardziej naturalny sposób na ilość elementów tablicy. Znak <code>x</code> bardzo typowy dla <code>perla</code> to operator powtarzania <code>stringa</code> określoną liczbę razy. Na przykład <code>&quot;a&quot;x3</code> jest równoważne napisaniu <code>&quot;aaa&quot;</code>.</p>\n<p>Po określeniu tekstowej reprezentacji zapytania następuje jego przygotowanie, a przy każdej kolejnej linii przetworzonego tekstu, już tylko przywrócenie spacji zamiast znaków <code>_</code> wykonywane na każdym wyrazie tablicy osobno i wykonanie insertu.</p>\n<pre><code class=\"language-perl\">        #-----------------------------------------------------------#\n        #                   Close connection                        #\n        #-----------------------------------------------------------#\n    $dbh-&gt;disconnect();\n\n</code></pre>\n<p>Na końcu zamykamy połączenie z bazą.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"zapytania-do-bazy\">Zapytania do bazy</h2>\n<p>Po sklonowaniu repozytorium, możesz odtworzyć mój stan bazy wykonując komendy:</p>\n<pre><code class=\"language-bash\">bash process.sh\nperl insert.pl\n\n</code></pre>\n<p>Jeśli chodzi o oprogramowanie, to przez połowę życia pisałem zapytania bezpośrednio w konsoli <code>mysql</code>. Lubiłem to, ale często musiałem je kopiować do osobnego pliku, albo przepadały na zawsze. Było to trochę męczące przy opracowywaniu bardziej złożonych zapytań. Później przy pracy nad jednym z projektów zrobiłem research mając nadzieję, że znajdę jakieś przyjemne narzędzie. Udało się, trafiłem na <code>dbvis</code>. Pomogło mi przestać korzystać z <code>DIA</code>, które mimo, że jest użyteczne przy projektowaniu bazy nie nadaje się do utrzymywania jej aktualnego stanu. Teraz zacząłem korzystać z narzędzia <code>DataGrip</code>, które dostarczyło mi wszystko czego chciałem - podświetlanie składni, wizualizację schematów, zapisywanie selektów.</p>\n<p>Przejdziemy teraz do zapytań, które będziemy projektować. Będę wymieniał na przemian pytanie i selekt, który daje odpowiedź.</p>\n<h3 id=\"baza-skelpu-elektronicznego\">Baza skelpu elektronicznego</h3>\n<p>Które modele komputerów PC mają szybkość równą przynajmniej 3.00?</p>\n<pre><code class=\"language-sql\">SELECT model FROM pc WHERE speed &gt;= 3.0;\n\n</code></pre>\n<p>Którzy producenci wytwarzają laptopy z dyskiem twardym o wielkości przynajmniej 100 gigabajtów?</p>\n<pre><code class=\"language-sql\">SELECT maker FROM product NATURAL JOIN laptop WHERE hd &gt;= 100;\n\n</code></pre>\n<p>Znajdź numery modeli i ceny wszystkich produktów dowolnego typu wytwarzanych przez producenta B</p>\n<pre><code class=\"language-sql\">SELECT model,price FROM laptop UNION SELECT model,price FROM pc UNION SELECT model,price FROM printer NATURAL JOIN product as p WHERE p.maker='B';\n\n</code></pre>\n<p>Znajdź numery wszystkich kolorowych drukarek laserowych</p>\n<pre><code class=\"language-sql\">SELECT model FROM printer WHERE color AND type='laser';\n\n</code></pre>\n<p>Znajdź producentów sprzedających laptopy, ale już nie komputery pc</p>\n<pre><code class=\"language-sql\">SELECT DISTINCT maker FROM laptop NATURAL JOIN product WHERE maker NOT IN (SELECT DISTINCT maker FROM pc NATURAL JOIN product);\n\n</code></pre>\n<p>Znajdź wielkości dysków twardych występujące w przynajmniej dwóch komputerach pc</p>\n<pre><code class=\"language-sql\">SELECT hd FROM (SELECT count(*) as c, hd FROM pc GROUP BY hd) as calc WHERE c&gt;=2;\n\n</code></pre>\n<p>Znajdź pary modeli PC o tej samej ilości pamięci ram i szybkości. pary powinny pojawiać się jednokrotnie, na przykład, należy wymienić parę (i,j) ale już nie (j,i)</p>\n<pre><code class=\"language-sql\">SELECT a.model, b.model FROM pc as a JOIN pc as b ON a.speed=b.speed AND a.ram=b.ram WHERE a.model&gt;b.model;\n\n</code></pre>\n<p>Znajdź producentów wytwarzjących przynajmniej dwa różne komputery pc lub laptopy o szybkości co najmniej 2.8</p>\n<pre><code class=\"language-sql\">SELECT  maker from (SELECT maker, count(model) as c FROM product as p NATURAL JOIN (SELECT model, speed FROM pc WHERE speed&gt;=2.8 UNION SELECT model, speed FROM laptop WHERE speed&gt;=2.8) as u GROUP BY maker) as mc WHERE c&gt;=2;\n\n</code></pre>\n<p>Znajdź producenta lub producentów najszybszych komputerów (pc lub laptopów)</p>\n<pre><code class=\"language-sql\">SELECT DISTINCT maker FROM product as p NATURAL JOIN (SELECT model,speed FROM laptop UNION SELECT model,speed FROM pc) as c WHERE speed=(SELECT MAX(speed) FROM (SELECT speed FROM laptop UNION SELECT speed FROM pc) as u);\n\n</code></pre>\n<p>Znajdź producentów komputerów PC o przynajmniej trzech różnych szybkościach</p>\n<pre><code class=\"language-sql\">SELECT maker from (SELECT maker, count(speed) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c&gt;=3;\n\n</code></pre>\n<p>Znajdź producentów którzy sprzedają dokładnie trzy różne modele komputerów PC</p>\n<pre><code class=\"language-sql\">SELECT maker from (SELECT maker, count(model) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c=3;\n\n</code></pre>\n<h3 id=\"baza-okr%C4%99t%C3%B3w-liniowych\">Baza okrętów liniowych</h3>\n<p>Podaj nazwy i kraje klas okrętów z działami o kalibrze przynajmniej szesnastu cali.</p>\n<pre><code class=\"language-sql\">SELECT name, country FROM classes NATURAL JOIN ships WHERE bore&gt;=16;\n\n</code></pre>\n<p>Znajdź okręty zwodowane przed 1921 rokiem</p>\n<pre><code class=\"language-sql\">SELECT name FROM ships WHERE launched&lt;1921;\n\n</code></pre>\n<p>Znajdź okręty zatopione w bitwie pod Denamrk Strait</p>\n<pre><code class=\"language-sql\">SELECT ship FROM outcomes WHERE result=&quot;sunk&quot; AND battle=&quot;Denmark Strait&quot;;\n\n</code></pre>\n<p>Traktat Waszyngtoński z 1921 zabraniał budowania okrętów liniowych o masie powyżej 35 000 ton. Wymień okręty niezgodne z traktatem.</p>\n<pre><code class=\"language-sql\">SELECT name FROM classes NATURAL JOIN ships WHERE launched&gt;1921 AND displacement&gt;35000;\n\n</code></pre>\n<p>Podać nazwę, wyporność i liczbę dział okrętów biorących udział w bitwie pod Guadalcanal</p>\n<pre><code class=\"language-sql\">SELECT DISTINCT name, displacement, numGuns FROM classes NATURAL JOIN ships NATURAL JOIN outcomes WHERE battle='Guadalcanal';\n\n</code></pre>\n<p>Podaj wszystkie okręty znajdujące się bazie danych, pamiętaj, że niektóre okręty nie znajdują się w relacji Okręty</p>\n<pre><code class=\"language-sql\">SELECT name FROM ships UNION SELECT ship FROM outcomes;\n\n</code></pre>\n<p>Znajdź klasy reprezentowane tylko przez jeden okręt</p>\n<pre><code class=\"language-sql\">SELECT class FROM (SELECT class, count(class) as c FROM classes as cl NATURAL JOIN (SELECT ship, ship as class FROM outcomes as o UNION SELECT name, class FROM ships as s) as ext_ship GROUP BY class) as total WHERE c=1;\n\n</code></pre>\n<p>Znajdź kraje które posiadały zarówno pancerniki jak i krążowniki</p>\n<pre><code class=\"language-sql\">SELECT t1.country FROM classes as t1 JOIN classes as t2 ON t1.country=t2.country WHERE t1.type='bb' AND t2.type='bc';\n\n</code></pre>\n<p>Znajdź okręty, które &quot;przetrwały, ale mogły jeszcze wziąć udział w boju&quot; - zostały uszkodzone w jednej bitwie, a później uczestniczyły w innej.</p>\n<pre><code class=\"language-sql\">SELECT f.name as name FROM\n  (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN     outcomes as o1 ON b1.name=o1.battle) as f\n    JOIN\n  (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN    outcomes as o1 ON b1.name=o1.battle) as s\n    ON f.name=s.name AND s.year &lt; f.year AND s.result='sunk';\n\n</code></pre>\n<p>Zdziwiło mnie to, ale baza nie zawiera żadnego rekordu odpowiadającego na ostatnie pytanie. Jednak sprawdziłem to ręcznie przeglądając bazę i faktycznie tak jest.</p>\n<h2 id=\"testy\">Testy</h2>\n<p>Do testów wykorzystamy <code>behat</code>. Jeśli skopiowałeś to repozytorium, wystarczy, że wpiszesz <code>composer install</code> i nie musisz wykonywać żadnej z trzech poniższych instrukcji. W przeciwnym wypadku, możesz zainstalować <code>behat</code> komendą</p>\n<pre><code>composer require behat/behat\n\n</code></pre>\n<p>Żeby nie wymyślać koła od nowa, do assertów podepniemy <code>phpunit</code></p>\n<pre><code>composer require phpunit/phpunit\n\n</code></pre>\n<p>Przygodę z <code>behatem</code> zaczynamy od utworzenia pustego kontekstu za pomocą komendy.</p>\n<pre><code>vendor/bin/behat --init\n\n</code></pre>\n<p>Wypełnimy go teraz treścią.</p>\n<h3 id=\"kontekst\">Kontekst</h3>\n<p>Zaczynamy od podpięcia klas, z których będziemy korzystać:</p>\n<blockquote>\n<p>features/bootstrap/FeatureContext.php</p>\n</blockquote>\n<pre><code class=\"language-php\">&lt;?php\n\nuse Behat\\Behat\\Context\\Context;\nuse Behat\\Gherkin\\Node\\TableNode;\nuse Symfony\\Component\\Yaml\\Yaml;\nuse PHPUnit\\Framework\\TestCase;\n\n/**\n * Defines application features from the specific context.\n */\nclass FeatureContext extends TestCase implements Context\n{\n\n</code></pre>\n<p>Nasz kontekst rozszerza klasę <code>TestCase</code>, dostarczaną przez <code>phpunit</code> abyśmy mogli łatwo narzucać warunki. Podczas działania testów będą nam potrzebne trzy zmienne.</p>\n<pre><code class=\"language-php?start_inline=1\">private $config;\nprivate $pdo;\nprivate $data;\n\n</code></pre>\n<p>Do zmiennej <code>$config</code> zapiszemy konfigurację z pliku <code>config/parameters.yml</code>, w <code>$pdo</code> będziemy trzymać połączenie z bazą, a <code>$data</code> będzie przechowywać wynik ostatniego zapytania. Dwóm pierwszym możemy przypisać wartości już w konstruktorze.</p>\n<pre><code class=\"language-php?start_inline=1\">    public function __construct()\n    {\n        parent::__construct();\n\n        $this-&gt;config = Yaml::parse(file_get_contents(__DIR__.'/../../config/parameters.yml'))[&quot;config&quot;];\n        $this-&gt;setPdoUsingBaseNumber(0);\n    }\n\n</code></pre>\n<p>Dziedziczymy tutaj konstruktor z <code>phpunit</code>. Następnie ustawiany zmienną <code>$config</code>. Nie musimy instalować dodatkowego parsera do <code>yml</code> ponieważ <code>behat</code> wziął sobie ten z <code>symfony</code>, sam przecież używa swojej własnej konfiguracji w formacie <code>yml</code>. Na koniec ustawiamy połączenie z domyślną bazą - <code>electronic_store</code> za pomocą funkcji <code>setPdoUsingBaseNumber(0)</code>. Jej kod jest następujący:</p>\n<pre><code class=\"language-php?start_inline=1\">    private function setPdoUsingBaseNumber($baseNumber)\n    {\n        try {\n            $this-&gt;pdo = new PDO(\n                $this-&gt;config[&quot;type&quot;].\n                ':host='.$this-&gt;config[&quot;host&quot;].\n                ';dbname='.$this-&gt;config[&quot;bases&quot;][$baseNumber],\n                $this-&gt;config[&quot;user&quot;],\n                $this-&gt;config[&quot;pass&quot;]);\n\n            $this-&gt;pdo-&gt;setAttribute(PDO::ATTR_DEFAULT_FETCH_MODE, PDO::FETCH_OBJ);\n\n        } catch (PDOException $e) {\n            echo 'Connection failed: ' . $e-&gt;getMessage();\n        }\n    }\n\n</code></pre>\n<p>Generalnie można się było tego spodziewać. Z ciekawych rzeczy jest tu tylko ustawienie atrybutów naszego połączenia. Chcemy, żeby konwertował wyniki zapytań do obiektów. Mimo, że do większości assertów wykorzystamy <code>phpunit</code> nie ma on sprawdzania występowania w tablicy dla bardziej złożonych obiektów.  Można by to ominąć serializując obiekty, ale tutaj zastosowałem inne podejście i porównałem je ręcznie.</p>\n<pre><code class=\"language-php?start_inline=1\">    private function assertArrayContainsHash($theArray, $hash)\n    {\n        foreach($theArray as $arrayItem) {\n            if((array) $arrayItem == $hash) {\n                return true;\n            }\n        }\n        throw new Exception(print_r($theArray).&quot; do not contain &quot;.print_r($hash));\n    }\n\n    private function assertArrayNotContainsHash($theArray, $hash)\n    {\n        foreach($theArray as $arrayItem) {\n            if((array) $arrayItem == $hash) {\n                throw new Exception(print_r($theArray).&quot; do contain &quot;.print_r($hash));\n            }\n        }\n        return true;\n    }\n\n</code></pre>\n<p>Te funkcje sprawdzają, czy w wyniku zapytania - <code>$theArray</code> pojawił się testowany przez nas zbiór atrybutów - <code>$hash</code>.</p>\n<p>Teraz przedstawimy możliwe kroki, jakie mogą się pojawić podczas testowania.</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @Given I'm connected to :number database\n     */\n    public function connectToSecondDatabase($number)\n    {\n        $this-&gt;setPdoUsingBaseNumber($number-1);\n    }\n\n</code></pre>\n<p>Przełączamy się między bazami, zmieniamy numerację <code>1</code>, <code>2</code> na tą w jakiej numeruje się indeksy tablicy. Teraz wybieranie selektów.</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @When I select :query from database\n     */\n    public function iSelectFromDatabase($query)\n    {\n        $stmt = $this-&gt;pdo-&gt;query($query);\n        $stmt-&gt;execute();\n        $this-&gt;data = $stmt-&gt;fetchAll();\n        $stmt-&gt;closeCursor();\n    }\n\n</code></pre>\n<p>Po prostu tworzymy zapytanie, wykonujemy je i wyniki zapisujemy do zmiennej <code>$data</code>. Dla zachowania porządku czyścimy zapytanie. Jeśli interesuje nas zobaczenie wyniku, przygotowałem na to metodę</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @Then I print result\n     */\n    public function iPrintResult()\n    {\n//        echo json_encode($this-&gt;data, JSON_PRETTY_PRINT);\n        print_r($this-&gt;data);\n    }\n\n</code></pre>\n<p>Opcja formatowania do <code>jsona</code> też została przewidziana, ale ponieważ poza debugowaniem ten kod nie spełnia żadnego testowego zadania, nie tworzyłem dla niej osobnej metody. Czas na pierwsze z warunków jakie narzucamy na dane:</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @Then I should see :count results\n     */\n    public function iShouldSeeResults($count)\n    {\n        $this-&gt;assertEquals(sizeof($this-&gt;data), $count);\n    }\n\n    /**\n     * @Then I should see not less than :arg1 results\n     */\n    public function iShouldSeeNotLessThanResults($arg1)\n    {\n        $this-&gt;assertGreaterThanOrEqual($arg1,count($this-&gt;data));\n    }\n\n    /**\n     * @Then I should see not more than :arg1 results\n     */\n    public function iShouldSeeNotMoreThanResults($arg1)\n    {\n        $this-&gt;assertGreaterThanOrEqual(count($this-&gt;data),$arg1);\n    }\n\n</code></pre>\n<p>Jeśli chemy odnieść się do ilości rekordów w wyniku naszego zapytania możemy zarządać, żeby była ona  równa, nie mniejsza, bądź nie większa od podanej.</p>\n<p>Kolejny możliwy krok to sprawdzenie wartości atrybutu dla pierwszego wiersza danego zapytania.</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @Then Firs result should have :key equal :value\n     */\n    public function firsResultShouldHaveEqual($key, $value)\n    {\n        $this-&gt;assertArrayHasKey(0,$this-&gt;data);\n        $this-&gt;assertObjectHasAttribute($key,$this-&gt;data[0]);\n        $this-&gt;assertEquals($this-&gt;data[0]-&gt;$key,$value);\n    }\n\n</code></pre>\n<p>Kolejno sprawdzamy czy wynik ma pierwszy wiersz, czy istnieje w nim podany atrybut i czy ma wartość której oczekujemy. Ostatni krok jest tak ogólny, że jest stosowany przy prawie każdym scenariuszu w prawie każdym przykładnie.</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @Then /^Result should( not)? contain fields:$/\n     */\n    public function resultShouldContainFields($not = null, TableNode $table)\n    {\n        foreach($table-&gt;getHash() as $hash)\n        {\n            if (!$not) {\n                $this-&gt;assertArrayContainsHash($this-&gt;data, $hash);\n            } else {\n                $this-&gt;assertArrayNotContainsHash($this-&gt;data,$hash);\n            }\n        }\n    }\n\n</code></pre>\n<p>Sprawdza on czy wynik zapytania zawiera określona wartości dla podanych pól, lub czy ich nie zawiera. Ta ogólność możliwa jest dzięki wykorzystaniu w składni <code>gherkina</code> znaku <code>?</code> ozaczającego wystąpienie <code>0</code> lub <code>1</code> raz. Jeśli nie napiszemy <code>not</code>, zmienna <code>$not</code> przyjmie wartość domyślną <code>null</code> i jej zaprzeczenie będzie prawdziwe. Jednak ciekawsze niż sama logika instrukcji warunkowej jest zastosowanie obiektu <code>TableNode</code>. Jest to obiekt dostarczany przez <code>behat</code> i zawiera wszystkie dane z tabel, które użytkownik podaje w plikach <code>feature</code>. Tabele te mają nagłówk i wartości zapisane w wierszach. Obiekt <code>TableNode</code> powstał żeby nie powtarzać sztuczki jaką w <code>perlu</code> wykorzystałem do osobnego traktowania nagłówka i nie przetważać tych danych ręcznie. Iterując po jego metodzie <code>getHash()</code> przechodzimy po wszystkich wierszach tej tabeli z pominięciem nagłówka. W zmiennej <code>$hash</code>, trzymamy tablicę asocjacyjną z kluczami pobranymi z nagłówka (atrybutami w tabeli) i wartościm pobranymi z danego wiersza.</p>\n<p>To właśnie tą tablicę asocjacyjną wrzucamy do pokazanych wczęśniej metod sprawdzania występowania danego rekordu w wyniku zapytania.</p>\n<h3 id=\"scenariusze-testowe\">Scenariusze testowe</h3>\n<p>W praktyce pisałem testy nie mając jeszcze zapytań i mój workflow był następujący:</p>\n<ol>\n<li>Przeczytać treść zapytania w języku naturalnym.</li>\n<li>Napisać zapytanie w języku SQL.</li>\n<li>Spojrzeć na obrazki z danymi.</li>\n<li>Wybrać przykładowe rekordy, które powinny znaleźć się w odpowiedzi.</li>\n<li>Wybrać przykładowe rekordy które nie powinny znaleźć się w odpowiedzi.</li>\n<li>Wkleić selekt i dane do tabeli z testami.</li>\n<li>Jeśli warunki nie są standardowe, dopisać brakujący scenariusz.</li>\n</ol>\n<p>Ostatecznie plik ze scenariuszami testowymi wyewoluował do takiego postaci:</p>\n<blockquote>\n<p>features/select.feature</p>\n</blockquote>\n<pre><code class=\"language-gherkin\">Feature: Selecting chosen fields from database\n  In order to check if my queries are correct\n  As an an database user\n  I want to execute them and test some asserts\n\n</code></pre>\n<p>To jest nagłówek, jest tylko dokumentacja, bo ten kod się nie wykonuje. Poniżej pierwszy scenariusz.</p>\n<pre><code class=\"language-gherkin\">  Scenario Outline: Checking number of rows\n    Given I'm connected to &lt;db&gt; database\n    When I select &quot;SELECT count(*) AS c FROM &lt;table&gt;&quot; from database\n    Then I should see 1 results\n    And Firs result should have &quot;c&quot; equal &lt;count&gt;\n\n    Examples:\n      | db | table    | count |\n      | 1  | product  | 30    |\n      | 1  | pc       | 13    |\n      | 1  | laptop   | 10    |\n      | 1  | printer  | 7     |\n      | 2  | classes  | 8     |\n      | 2  | battles  | 4     |\n      | 2  | outcomes | 16    |\n      | 2  | ships    | 21    |\n\n</code></pre>\n<p>Zostały tu sprawdzone czy ilości rekordów w bazie odpowiadają tym z ksiązki. Następnie zostają sprawdzone wszystkie zapytania, które mają tylko jedną kolumnę z wynikiem.</p>\n<pre><code class=\"language-gherkin\">  Scenario Outline: Testing query\n    Given I'm connected to &lt;db&gt; database\n    When I select &lt;query&gt; from database\n    Then Result should contain fields:\n      | &lt;row&gt;  |\n      | &lt;yes1&gt; |\n      | &lt;yes2&gt; |\n    And Result should not contain fields:\n      | &lt;row&gt;  |\n      | &lt;no1&gt;  |\n      | &lt;no2&gt;  |\n\n    Examples:\n      | db | row   | yes1      | yes2             | no1       | no2        | query                                                                                                                                                                                                                              |\n      | 1  | model | 1013      | 1006             | 1012      | 1007       | &quot;SELECT model FROM pc WHERE speed &gt;= 3.0;&quot;                                                                                                                                                                                         |\n      | 1  | maker | E         | A                | C         | H          | &quot;SELECT maker FROM product NATURAL JOIN laptop WHERE hd &gt;= 100;&quot;                                                                                                                                                                   |\n      | 1  | model | 3003      | 3007             | 3002      | 3005       | &quot;SELECT model FROM printer WHERE color AND type='laser'&quot;                                                                                                                                                                           |\n      | 1  | maker | F         | G                | A         | D          | &quot;SELECT DISTINCT maker FROM laptop NATURAL JOIN product WHERE maker NOT IN (SELECT DISTINCT maker FROM pc NATURAL JOIN product);&quot;                                                                                                  |\n      | 1  | maker | F         | G                | A         | D          | &quot;SELECT l.maker FROM (SELECT maker,type FROM product WHERE type='laptop') as l LEFT JOIN (SELECT maker,type FROM product WHERE type='pc') as p ON l.maker=p.maker WHERE p.maker IS NULL;&quot;                                          |\n      | 1  | hd    | 250       | 80               | 300       | 350        | &quot;SELECT hd FROM (SELECT count(*) as c, hd FROM pc GROUP BY hd) as calc WHERE c&gt;=2;&quot;                                                                                                                                                |\n      | 1  | maker | B         | E                | H         | G          | &quot;SELECT  maker from (SELECT maker, count(model) as c FROM product as p NATURAL JOIN (SELECT model, speed FROM pc WHERE speed&gt;=2.8 UNION  SELECT model, speed FROM laptop WHERE speed&gt;=2.8) as u GROUP BY maker) as mc WHERE c&gt;=2;&quot; |\n      | 1  | maker | A         | B                | C         | G          | &quot;SELECT maker from (SELECT maker, count(speed) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c&gt;=3;&quot;                                                                                                               |\n      | 1  | maker | A         | D                | C         | H          | &quot;SELECT maker from (SELECT maker, count(model) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c=3;&quot;                                                                                                                |\n      | 2  | name  | Ramillies | Royal Oak        | Wisconsin | Yamato     | &quot;SELECT name FROM ships WHERE launched&lt;1921;&quot;                                                                                                                                                                                      |\n      | 2  | ship  | Bismarck  | Hood             | Wisconsin | Rodney     | &quot;SELECT ship FROM outcomes WHERE result='sunk' AND battle='Denmark Strait'&quot;                                                                                                                                                        |\n      | 2  | name  | Yamato    | North Carolina   | Kirishima | California | &quot;SELECT name FROM classes NATURAL JOIN ships WHERE launched&gt;1921 AND displacement&gt;35000&quot;                                                                                                                                           |\n      | 2  |country| Japan     | Gt. Britain      |USA        | Germany    | &quot;SELECT t1.country FROM classes as t1 JOIN classes as t2 ON t1.country=t2.country WHERE t1.type='bb' AND t2.type='bc';&quot;                                                                                                            |\n\n</code></pre>\n<p>Ciężko to nawet skomentować, ponieważ ten kod jest samowyjaśniający się. Po prostu łączymy się z bazę, wykonujemy selekt, sprawdzamy czy rezultat zawiera dwie przykładowe wartości, których się spodziewamy i czy nie zawiera dwóch innych, których nie powinno być.</p>\n<p>Zupełnie analogicznie wygląda sytuacja, jeśli mamy dwie kolumny w wyniku.</p>\n<pre><code class=\"language-gherkin\">  Scenario Outline: Testing query with two attributes\n    Given I'm connected to &lt;db&gt; database\n    When I select &lt;query&gt; from database\n    Then Result should contain fields:\n      | &lt;rowA&gt;  | &lt;rowB&gt;  |\n      | &lt;yes1A&gt; | &lt;yes1B&gt; |\n      | &lt;yes2A&gt; | &lt;yes2B&gt; |\n    And Result should not contain fields:\n      | &lt;rowA&gt; | &lt;rowB&gt; |\n      | &lt;no1A&gt; | &lt;no1B&gt; |\n      | &lt;no2A&gt; | &lt;no2B&gt; |\n    Examples:\n      | db | rowA  | rowB    | yes1A  | yes1B | yes2A          | yes2B | no1A    | no1B         | no2A       | no2B | query                                                                                                                                                                            |\n      | 1  | model | price   | 1004   | 649   | 2007           | 1429  | 2004    | 1150         | 3007       | 200  | &quot;SELECT model,price FROM product as p NATURAL JOIN (SELECT model,price FROM pc UNION SELECT model,price FROM laptop UNION SELECT model,price FROM printer) as s WHERE maker='B'&quot; |\n      | 2  | name  | country | Yamato | Japan | North Carolina | USA   | Repulse | Gr. Brritain | California | USA  | &quot;SELECT name, country FROM classes NATURAL JOIN ships WHERE bore&gt;=16;&quot;                                                                                                           |\n\n</code></pre>\n<p>Niestety nie znam mechanizmu, który pozwolił by połączyć te dwa scenariusze w jeden, nigdzie w dokumentacji nie było nawet słowa o dziedziczeniu scenariuszy. Może ktoś na <a href=\"http://stackoverflow.com/questions/40941114/flexibility-of-scenarios-in-gherkin\">stacku</a> zna na to jakiś hack.</p>\n<p>Jeśli masz przeczucie czym to się skończy, to właśnie tak się kończy.</p>\n<pre><code class=\"language-gherkin\">  Scenario: Testing query with three attributes\n    Given I'm connected to 2 database\n    When I select &quot;SELECT DISTINCT name, displacement, numGuns FROM classes NATURAL JOIN ships NATURAL JOIN outcomes WHERE battle='Guadalcanal';&quot; from database\n    Then Result should contain fields:\n      | name       | numGuns | displacement |\n      | Kirishima  | 8       | 32000        |\n      | Washington | 9       | 37000        |\n    And Result should not contain fields:\n      | name     | numGuns | displacement |\n      | Tenessee | 12      | 32000        |\n      | Bismarck | 8       | 42000        |\n\n</code></pre>\n<p>I stało się, powtarzam ten sam kod trzeci raz. Wyrywałem sobie włosy z głowy, kiedy to pisałem. Okazało się, że jest tylko jeden przypadek selekta z trzema kolumnami, ale już widzimy niedoskonałość tego kodu.</p>\n<p>Czasem zdażało się, że chciałem przetestować występowanie tylko jednego wiersza, za to z dwoma atrybutami:</p>\n<pre><code class=\"language-gherkin\">  Scenario: Testing query (pairs)\n    When I select &quot;SELECT a.model as a, b.model as b FROM pc as a JOIN pc as b ON a.speed=b.speed AND a.ram=b.ram WHERE a.model&gt;b.model;&quot; from database\n    Then Result should contain fields:\n      | a     | b       |\n      | 1012  | 1004    |\n    And I should see 1 results\n\n</code></pre>\n<p>Były też przypadki z jednym rezultatem i jednym atrybutem</p>\n<pre><code class=\"language-gherkin\">  Scenario Outline: Testing query (max speed)\n    Given I'm connected to &lt;db&gt; database\n    When I select &lt;query&gt; from database\n    And I should see 1 results\n    And Firs result should have &lt;row&gt; equal &lt;value&gt;\n    Examples:\n      | db | row   | value    | query                                                                                                                                                                                                                          |\n      | 1  | maker | B        | &quot;SELECT DISTINCT maker FROM product as p NATURAL JOIN (SELECT model,speed FROM laptop UNION SELECT model,speed FROM pc) as c WHERE speed=(SELECT MAX(speed) FROM (SELECT speed FROM laptop UNION SELECT speed FROM pc) as u);&quot; |\n      | 2  | class | Bismarck | &quot;SELECT class FROM (SELECT class, count(class) as c FROM classes as cl NATURAL JOIN (SELECT ship, ship as class FROM outcomes as o UNION SELECT name, class FROM ships as s) as ext_ship GROUP BY class) as total WHERE c=1;&quot;  |\n\n</code></pre>\n<p>I przypadek z w którym nie znałem dokładnej liczby wyników, ale mogłem określić przedział w jakim się znajduje.</p>\n<pre><code class=\"language-gherkin\">  Scenario: Select all ships\n    Given I'm connected to 2 database\n    When I select &quot;SELECT name FROM ships UNION SELECT ship FROM outcomes;&quot; from database\n    Then I should see not less than &quot;21&quot; results\n    And I should see not less than &quot;16&quot; results\n    And I should see not more than 37 results\n    And Result should contain fields:\n      | name |\n      | Yamashiro |\n      | Bismarck |\n      | Fuso |\n\n</code></pre>\n<p>Na końcu zostałem zaskoczony przez scenariusz, w którym na wyjściu niczego nie dostałem.</p>\n<pre><code class=\"language-gherkin\">  Scenario: Select null\n    Given I'm connected to 2 database\n    When I select &quot;SELECT f.name as name FROM (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN outcomes as o1 ON b1.name=o1.battle) as f JOIN (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN outcomes as o1 ON b1.name=o1.battle) as s ON f.name=s.name AND s.year &lt; f.year AND s.result='sunk';&quot; from database\n    Then I should see 0 results\n\n</code></pre>\n<p>Tak doszliśmy dokońca projektu.</p>\n<p>Mam nadzieję, że przedstawiony materiał Ci się spodbał. Daj znać w komentarzu, jeśli coś wymaga dodatkowego wyjaśnienia, albo jeśli wiesz jak mógł bym napisać bardziej ogólne testy niż te przedstawione powyżej. Mam na myśli jeden scenariusz dla N atrubutów, z M przykładami, które występują i L które nie występują.</p>\n<!--kg-card-end: markdown--><p></p>",
            "comment_id": "607f33be2fb35425592d0b4e",
            "plaintext": "Opis projektu\nMiałem tylko odświeżyć sobie pisanie zapytań do bazy, a skończyłem instalując \nDataGrip i Tesseracta. Pierwszy program jest to IDE do baz danych od JetBrains,\ndrugi jest oprogramowaniem OCR - służy do rozpoznawania tekstów w grafice\nrastrowej.\n\nNaszym zadaniem będzie utworzenie schematów baz danych, odczytanie tekstu z\nplików graficznych, wrzucenie odczytanej zawartości napisanie kilku zapytań i \ntestowanie zawartości za pomocą behata. Jeśli jesteś ciekaw jak to się robi,\nzapraszam do lektury.\n\nSkład kodu:\n\nCucumber 49.9% Perl 26.7% PHP 21.8% Shell 1.6%\n\n\nInstalacja\nPobieramy repozytorium:\n\ngit clone https://github.com/gustawdaniel/image_to_database_converter_example.git && cd image_to_database_converter_example\n\n\nInstalujemy zależności.\n\nsudo apt-get install tesseract-ocr\n\n\nPrzetważamy obrazki na teksty\n\nbash process.sh\n\n\nTworzymy bazy i wrzucamy do nich dane. Ten skrypt na początku usunie bazy o\nnazwach w z config/parameters.yml, sprawdź konfigurację przed jego wykonaniem.\n\nperl insert.pl\n\n\nInstalujemy paczki php\n\ncomposer install\n\n\nWykonujemy testy\n\nvendor/bin/behat\n\n\nPo instalacji wykonanie przetważania obrazu, oczyszczenie danych, zapis treści\noraz testowanie bazy wyglądają następująco.\n\nStruktura baz\nZa punkt wyjścia przyjmiemy zadania 2.4.1 i 2.4.3 z rozdziału 2\n[http://infolab.stanford.edu/~ullman/fcdb/ch2.pdf] książki Database Systems: The\nComplete Book. Zadanie polegają na napisaniu selektów.\n\nBędziemy tworzyć dwie bazy. Pierwsza zawiera magazyn sklepu elektronicznego.\n\n> electronic_store\n\n\n\n\nJej kod w sql wygląda następująco:\n\n> sql/electronic_store.sql\n\n\nDROP DATABASE   IF     EXISTS electronic_store;\nCREATE DATABASE IF NOT EXISTS electronic_store;\nuse electronic_store;\n\nCREATE TABLE product (\n  producer CHAR(1),\n  model    DECIMAL(4,0),\n  type     VARCHAR(255)\n);\n\nCREATE TABLE pc (\n  model DECIMAL(4,0),\n  speed DECIMAL(3,2),\n  ram   SMALLINT,\n  disc  SMALLINT,\n  price SMALLINT\n);\n\nCREATE TABLE laptop (\n  model DECIMAL(4,0),\n  speed DECIMAL(3,2),\n  ram   SMALLINT,\n  disc  SMALLINT,\n  screen DECIMAL(3,1),\n  price SMALLINT\n);\n\nCREATE TABLE printer (\n  model DECIMAL(4,0),\n  color BOOL,\n  type  VARCHAR(255),\n  price SMALLINT\n);\n\n\nDruga to baza z danymi dotyczącymi okrętów liniowych drugiej wojny światowej.\n\n> warships\n\n\n\n\nMa bardzo podobną strukturę kodu\n\n> sq/warships.sql\n\n\nDROP DATABASE   IF     EXISTS warships;\nCREATE DATABASE IF NOT EXISTS warships;\nuse warships;\n\nCREATE TABLE classes (\n  class VARCHAR(255),\n  type CHAR(2),\n  country VARCHAR(255),\n  numGuns SMALLINT,\n  bore SMALLINT,\n  displacement INTEGER\n);\n\nCREATE TABLE ships (\n  name VARCHAR(255),\n  class VARCHAR(255),\n  launched SMALLINT\n);\n\nCREATE TABLE battles (\n  name VARCHAR(255),\n  date VARCHAR(255)\n);\n\nCREATE TABLE outcomes (\n  ship VARCHAR(255),\n  battle VARCHAR(255),\n  result VARCHAR(255)\n)\n\n\n\nDane nie są powiązane żadnymi więzami integralności referencyjnej.\n\nŹródło danych\nProblem z danymi zaczyna się od tego, że baza jest zapisana w pliku pdf, jest to\npo prostu fragment książki. Jest to słabo zrobiony pdf i dane z niego nie nadają\nsię do zaznaczenia i skopiowania. Na szczęście znajdziemy rozwiązanie stosując\nOCR.\n\nGrafiki\nZaczniemy od zrobienia screenów tabel z książki. W repozytorium\n[https://github.com/gustawdaniel/image_to_database_converter_example], znajdują\nsię te screeny. Są zapisane do plików o nazwach odpowiadających nazwom tabel w\nkatalogu raw/1 dla pierwszej bazy i raw/2 dla drugiej. Przykładowy plik \nraw/1/laptop.png wygląda następująco.\n\n\n\nWydobycie tekstu (OCR)\nTeraz trzeba zainstalować tesseract-ocr komendą:\n\nsudo apt-get install tesseract-ocr\n\n\n\nWykonamy rozpoznawanie tekstu na każdym z zapisanych plików. Pomoże nam w tym\nprosty skrypt:\n\n> process.sh\n\n\n#!/usr/bin/env bash\n\nRAW=raw;\nBUILD=build;\n\nmkdir -p $BUILD;\nrm -rf $BUILD/*\n\nfor cat in $RAW/*\ndo\n    baseCat=$(basename $cat .png);\n    for file in $cat/*.png\n    do\n        baseFile=$(basename $file .png);\n        mkdir -p $BUILD/$baseCat;\n        tesseract $file $BUILD/$baseCat/$baseFile;\n    done\ndone\n\n\n\nWyniki są w zasadzie dobre, poza tym, że czasami pojawiają się puste linie, w\njednym miejscu pojawiła się spacja i ram został wczytany jako mm. Jednak\npoważnym problemem jest to, że w drugiej bazie część rekordów ma nazwy\nskładające się z kilku wyrazów. Mimo to wyrażenia regularne szybko załatwią ten\nproblem. Z wyrażeniami regularnymi i transformowaniem danych do strukturyzowanej\npostaci kojarzy mi się perl, dlatego ten język wykorzystamy do wypełnienia bazy\ndanymi.\n\nPrzetworzenie tekstu\nJak zwykle zaczynamy od konfiguracji, ponieważ korzystać z niej będą perl i php,\nwydzielamy ją do osobnego pliku.\n\n> config/parameters.yml\n\n\nconfig:\n  type: mysql\n  host: localhost\n  user: root\n  pass: \"\"\n  bases:\n   - electronic_store\n   - warships\n\n\n\nTeraz zajmiemy się poprawą jakości tekstu i wrzuceniem go do bazy.\n\nDefinicje\nWiększość moich skryptów zaczyna się podobnie. Są to nagłówki z paczkami.\n\n> insert.pl\n\n\n#!/usr/bin/env perl\n# This script save data to database\n\nuse Modern::Perl;       # modern syntax\nuse File::Basename;     # parsing names of files\nuse YAML::Tiny;         # open yml config\nuse DBI();              # database connection\n\nuse strict;             # strict mode\nuse warnings;\nuse open ':std', ':encoding(UTF-8)';\n\n\n\nPóźniej wchodzą zmienne z konfiguracją związaną ze środowiskiem:\n\n#----------------------------------------------------------------------#\n#                        Configuration                                 #\n#----------------------------------------------------------------------#\nmy $build = \"build/\";\nmy $sql = \"sql/\";\nmy $parameters = 'config/parameters.yml';\n\n\nmy $yaml = YAML::Tiny->read( $parameters );\nmy $config = $yaml->[0]->{config};\n\n\n\nNastępnie mamy definicje. Jedyną zdefiniowaną tu funkcją jest procedura\nwykonywania wyrażeń regularnych - znajdź i zamień. Jest to zbiór filtrów przez\njakie będzie przechodził tekst przeczytany przez OCR.\n\n#--------------------------------------------------------------#\n#         Fix file structure broken by OCR inaccuracy          #\n#--------------------------------------------------------------#\nsub fixStructure\n{\n    s/mm/ram/g;\n    s/\\s(\\d{3})\\s(\\d)\\s/ $1$2 /g;\n    s/\\|\\s//g;\n    s/true/1/g;\n    s/false/0/g;\n\n    s/(\\w+)\\s(\\w+)\\s(\\d{1,2}\\/)/$1_$2 $3/g;\n    s/North\\s(\\w+)/North_$1/g;\n    s/West Virginia/West_Virginia/g;\n    s/South Dakota/South_Dakota/g;\n    s/Royal\\s(\\w+)/Royal_$1/g;\n    s/New Jersey/New_Jersey/g;\n    s/King George V/King_George_V/g;\n    s/Pearl Harbor/Pearl_Harbor/g;\n    s/Prince of Wales/Prince_of_Wales/g;\n    s/Duke of York/Duke_of_York/g;\n    s/Gt. Britain/Gt._Britain/g;\n    s/\\sStrait/_Strait/g;\n};\n\n\n\n\nFunkcja nie ma parametrów, ponieważ działa na zmiennej $_. Warto przy tym\nzwrócić na pewną ciekawą właściwość perla, która wyróżnia go na tle innych\njęzyków. Jest to między innymi właśnie zmienna $_ której wartość zależy od\nkontekstu i której nie trzeba nawet pisać jeśli kontekst wskazuje, że o nią\nchodzi. W zamyśle twórcy języka - Larry'ego Walla - upodabniało go to do języka\nmówionego, w którym nie wskazujemy ciągle podmiotu, jeśli jest on oczywisty. Z\njednej strony pozwala to szybko pisać gęsty kod dużych możliwościach, z drugiej\nbardzo utrudnia jego czytanie, jeśli nie jest on wystarczająco dobrze\nudokumentowany, a osoba czytająca nie zna tego języka wystarczająco dobrze. Być\nmoże ta elastyczność jest jednym z powodów upadku tego języka w starciu z bardzo\nrestrykcyjnym pythonem, ale dla mnie jest ona raczej zaletą niż wadą. W każdym\nrazie u nas zmienna $_ będzie przyjmować wartość ciągu znaków z jednej linii\nczytanego tekstu\n\nPrzyjrzyjmy się dokładnie regułom jakie wprowadziłem, bo to jest serce całego\nprogramu.\n\nReguły s/A/B/g wykonują na zmiennej $_ operację wyszukania ciągu A i zamiany go\nna ciąg B. Pierwsza z nich naprawia błędny odczyt kolumny ram odczytanej przez \nOCR jako mm, druga usuwa spację z jednego z identyfikatorów, kolejna pozbywa się\nlinii pionowych. Dwie następne przekształcają wartości logiczne do postaci\nzero-jedynkowej. Wszystkie następne to wybieranie odpowiednich spacji i\nzastępowanie ich znakami _. Jest to poprawne podejście jeśli w analizowanym\ntekście nie ma znaku _, co jest prawdą w omawianym tutaj przykładzie.\n\nSkrypt\nWykonywalna część skryptu zaczyna się od iterowania po bazach danych\nwymienionych w konfiguracji:\n\n#----------------------------------------------------------------------#\n#                            Script                                    #\n#----------------------------------------------------------------------#\n\n        #--------------------------------------------------------------#\n        #                      Loop over databases                     #\n        #--------------------------------------------------------------#\nwhile (my ($baseNumber, $baseName) = each @{ $config->{\"bases\"} })\n{\n    print $baseNumber.\"\\t\".$baseName.\".sql\".\"\\n\";\n\n\n\nNastępnie dbamy o idempotentność czyli możliwość powtarzania skryptu wiele razy\nbez zmiany wyniku. Wykonujemy kody sql przywracające stany baz do czystej\npostaci. Możliwe, że w Twoim systemie będziesz musiał dopisać sudo przed komendą \nmysql. Ja jestem zwolennikiem raczej zmiany uprawnień dostępu do bazy, jeśli to\nmój prywatny, lokalny komputer, niż wpisywania haseł przy każdym włączaniu bazy\nz terminala.\n\n    #--------------------------------------------------------------#\n    #  Reset database, put `sudo` before `mysql` if access error   #\n    #--------------------------------------------------------------#\n\n    my $passSting = ($config->{pass} eq \"\") ? \"\" : \" -p \".$config->{pass};\n    system('mysql -h '.$config->{host}.' -u '.$config->{user}.$passSting.' < '.$sql.$baseName.\".sql\");\n\n\n\nPołączenie z bazą danych było już omawiane na tym blogu, dla przypomnienia,\nwygląda ono tak:\n\n    #--------------------------------------------------------------#\n    #                 Connect to the database                      #\n    #--------------------------------------------------------------#\n\n    my $dbh = DBI->connect( \"DBI:mysql:database=\".$baseName.\";host=\".$config->{host},\n        $config->{user}, $config->{pass}, {\n            'PrintError'        => 0,\n            'RaiseError'        => 1,\n            'mysql_enable_utf8' => 1\n        } ) or die \"Connect to database failed\";\n\n\n\nCiekawiej robi się przy pętli po wszystkich plikach:\n\n            #--------------------------------------------------------------#\n            #                     Loop over files                          #\n            #--------------------------------------------------------------#\n\n        my @files = <$build$baseNumber\"/\"*.txt>;\n        foreach my $file (@files) {\n\n            my $name = basename($file, \".txt\");\n            print $file.\"\\t\".$name.\"\\n\";\n            open(my $fh, '<:encoding(UTF-8)', $file)\n                or die \"Could not open file '$file' $!\";\n\n\n\nW zmiennej $name zapisywane są nazwy pozbawione ścieżki i rozszerzenia. Tak się\nskłada, że są to dokładnie nazwy tabel w naszej bazie. Jeszcze to wykorzystamy w\nprzy składaniu insertów. Naturalną konsekwencją iterowania po plikach tekstowych\njest otwieranie ich. Uchwyt pliku trzymamy w zmiennej $fh, więc wykonujemy po\nnim pętle:\n\n        #--------------------------------------------------------------#\n        #               Read all lines of given file                   #\n        #--------------------------------------------------------------#\n\n        my $index = 0; my $statement;\n        while (<$fh>) {\n\n\n\nPrzed pętlą zdefiniowaliśmy sobie dwie zmienne. $index pozwalającą odnieść się\ndo numeru nie pustej linii, oraz $statement, która będzie przechowywała\nprzygotowany insert. Odczytywane linie należy poddać pewnej obróbce przed\nzapisaniem. Zaczniemy od wycięcia znaków końca linii i pominięcia linii\nzawierających tylko spacje.\n\n        #--------------------------------------------------------------#\n        #         Skip empty lines and cut new line signs              #\n        #--------------------------------------------------------------#\n            chomp;\n            if(m/^\\s*$/) {\n                next;\n            }\n\n\n\nTu właśnie objawia się magia zmiennej kontekstowej $_. Każdy wie, że iterując po\nliniach pliku, to właśnie te linie są w centrum zainteresowania. Dlatego nie\nmusimy ich nawet nazywać. Zamiast pisać chomp $line możemy napisać chomp $_, ale\npo co, skoro wystarczy napisać chomp. Z kontekstu wynika, że znak nowej linii ma\nbyć wycięty ze zmiennej po której właśnie przechodzi bieżąca iteracja pętli. Tak\nwięc po tym początkowym oczyszczeniu możemy zastosować nasze filtry. Nic\nprostszego. Odpowiada za to napis:\n\n                &fixStructure;\n\n\n\nNa koniec rozbijamy naprawiony już wiersz $_ spacjami i jako tablicę zapisujemy\ndo zmiennej @row. Zwykle u mnie jest tak, że największa magia dzieje się na\nkońcu skryptu, tak jest i tym razem.\n\n        #--------------------------------------------------------------#\n        #   In first row define statement, in next ones execute them   #\n        #--------------------------------------------------------------#\n            if(!$index++){\n                my $query = \"INSERT INTO $name (\".join(\",\",@row).\") VALUES (?\". \",?\"x(@row-1) .\")\";\n                $statement = $dbh->prepare($query);\n            } else {\n                s/_/ / for @row;\n                $statement->execute(@row);\n            }\n\n            print \"\\t\" . $_ . \"\\n\";\n        }\n    }\n\n\n\nW warunku $if sprawdzamy czy $idnex był wcześniej podnoszony jednocześnie go\npodnosząc. Dla pierwszego wykonania tablica @row powinna zawierać nazwy kolumn z\ntabeli $name. Przypominam, że $name było tak dobierane, żeby odpowiadało nazwom\nkolumn już na etapie robienia screenów. Przy pierwszym wykonaniu tworzymy $query\n, jest to treść inserta, który będziemy wykonywać dla wszystkich pozostałych\nlinii pliku tekstowego.\n\nFragment join(\",\",$row) wykonuje na tablicy @row operację rzutowania jej na \nsting i łączenia przecinkami.\n\nOperacja \",?\"x(@row-1) również rzutuje tablicę @row ale tym razem w kontekście\nnumerycznym - odejmujemy od niej jedynkę. Z tego względu rzutowanie wykonywane\njest w najbardziej naturalny sposób na ilość elementów tablicy. Znak x bardzo\ntypowy dla perla to operator powtarzania stringa określoną liczbę razy. Na\nprzykład \"a\"x3 jest równoważne napisaniu \"aaa\".\n\nPo określeniu tekstowej reprezentacji zapytania następuje jego przygotowanie, a\nprzy każdej kolejnej linii przetworzonego tekstu, już tylko przywrócenie spacji\nzamiast znaków _ wykonywane na każdym wyrazie tablicy osobno i wykonanie\ninsertu.\n\n        #-----------------------------------------------------------#\n        #                   Close connection                        #\n        #-----------------------------------------------------------#\n    $dbh->disconnect();\n\n\n\nNa końcu zamykamy połączenie z bazą.\n\nZapytania do bazy\nPo sklonowaniu repozytorium, możesz odtworzyć mój stan bazy wykonując komendy:\n\nbash process.sh\nperl insert.pl\n\n\n\nJeśli chodzi o oprogramowanie, to przez połowę życia pisałem zapytania\nbezpośrednio w konsoli mysql. Lubiłem to, ale często musiałem je kopiować do\nosobnego pliku, albo przepadały na zawsze. Było to trochę męczące przy\nopracowywaniu bardziej złożonych zapytań. Później przy pracy nad jednym z\nprojektów zrobiłem research mając nadzieję, że znajdę jakieś przyjemne\nnarzędzie. Udało się, trafiłem na dbvis. Pomogło mi przestać korzystać z DIA,\nktóre mimo, że jest użyteczne przy projektowaniu bazy nie nadaje się do\nutrzymywania jej aktualnego stanu. Teraz zacząłem korzystać z narzędzia DataGrip\n, które dostarczyło mi wszystko czego chciałem - podświetlanie składni,\nwizualizację schematów, zapisywanie selektów.\n\nPrzejdziemy teraz do zapytań, które będziemy projektować. Będę wymieniał na\nprzemian pytanie i selekt, który daje odpowiedź.\n\nBaza skelpu elektronicznego\nKtóre modele komputerów PC mają szybkość równą przynajmniej 3.00?\n\nSELECT model FROM pc WHERE speed >= 3.0;\n\n\n\nKtórzy producenci wytwarzają laptopy z dyskiem twardym o wielkości przynajmniej\n100 gigabajtów?\n\nSELECT maker FROM product NATURAL JOIN laptop WHERE hd >= 100;\n\n\n\nZnajdź numery modeli i ceny wszystkich produktów dowolnego typu wytwarzanych\nprzez producenta B\n\nSELECT model,price FROM laptop UNION SELECT model,price FROM pc UNION SELECT model,price FROM printer NATURAL JOIN product as p WHERE p.maker='B';\n\n\n\nZnajdź numery wszystkich kolorowych drukarek laserowych\n\nSELECT model FROM printer WHERE color AND type='laser';\n\n\n\nZnajdź producentów sprzedających laptopy, ale już nie komputery pc\n\nSELECT DISTINCT maker FROM laptop NATURAL JOIN product WHERE maker NOT IN (SELECT DISTINCT maker FROM pc NATURAL JOIN product);\n\n\n\nZnajdź wielkości dysków twardych występujące w przynajmniej dwóch komputerach pc\n\nSELECT hd FROM (SELECT count(*) as c, hd FROM pc GROUP BY hd) as calc WHERE c>=2;\n\n\n\nZnajdź pary modeli PC o tej samej ilości pamięci ram i szybkości. pary powinny\npojawiać się jednokrotnie, na przykład, należy wymienić parę (i,j) ale już nie\n(j,i)\n\nSELECT a.model, b.model FROM pc as a JOIN pc as b ON a.speed=b.speed AND a.ram=b.ram WHERE a.model>b.model;\n\n\n\nZnajdź producentów wytwarzjących przynajmniej dwa różne komputery pc lub laptopy\no szybkości co najmniej 2.8\n\nSELECT  maker from (SELECT maker, count(model) as c FROM product as p NATURAL JOIN (SELECT model, speed FROM pc WHERE speed>=2.8 UNION SELECT model, speed FROM laptop WHERE speed>=2.8) as u GROUP BY maker) as mc WHERE c>=2;\n\n\n\nZnajdź producenta lub producentów najszybszych komputerów (pc lub laptopów)\n\nSELECT DISTINCT maker FROM product as p NATURAL JOIN (SELECT model,speed FROM laptop UNION SELECT model,speed FROM pc) as c WHERE speed=(SELECT MAX(speed) FROM (SELECT speed FROM laptop UNION SELECT speed FROM pc) as u);\n\n\n\nZnajdź producentów komputerów PC o przynajmniej trzech różnych szybkościach\n\nSELECT maker from (SELECT maker, count(speed) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c>=3;\n\n\n\nZnajdź producentów którzy sprzedają dokładnie trzy różne modele komputerów PC\n\nSELECT maker from (SELECT maker, count(model) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c=3;\n\n\n\nBaza okrętów liniowych\nPodaj nazwy i kraje klas okrętów z działami o kalibrze przynajmniej szesnastu\ncali.\n\nSELECT name, country FROM classes NATURAL JOIN ships WHERE bore>=16;\n\n\n\nZnajdź okręty zwodowane przed 1921 rokiem\n\nSELECT name FROM ships WHERE launched<1921;\n\n\n\nZnajdź okręty zatopione w bitwie pod Denamrk Strait\n\nSELECT ship FROM outcomes WHERE result=\"sunk\" AND battle=\"Denmark Strait\";\n\n\n\nTraktat Waszyngtoński z 1921 zabraniał budowania okrętów liniowych o masie\npowyżej 35 000 ton. Wymień okręty niezgodne z traktatem.\n\nSELECT name FROM classes NATURAL JOIN ships WHERE launched>1921 AND displacement>35000;\n\n\n\nPodać nazwę, wyporność i liczbę dział okrętów biorących udział w bitwie pod\nGuadalcanal\n\nSELECT DISTINCT name, displacement, numGuns FROM classes NATURAL JOIN ships NATURAL JOIN outcomes WHERE battle='Guadalcanal';\n\n\n\nPodaj wszystkie okręty znajdujące się bazie danych, pamiętaj, że niektóre okręty\nnie znajdują się w relacji Okręty\n\nSELECT name FROM ships UNION SELECT ship FROM outcomes;\n\n\n\nZnajdź klasy reprezentowane tylko przez jeden okręt\n\nSELECT class FROM (SELECT class, count(class) as c FROM classes as cl NATURAL JOIN (SELECT ship, ship as class FROM outcomes as o UNION SELECT name, class FROM ships as s) as ext_ship GROUP BY class) as total WHERE c=1;\n\n\n\nZnajdź kraje które posiadały zarówno pancerniki jak i krążowniki\n\nSELECT t1.country FROM classes as t1 JOIN classes as t2 ON t1.country=t2.country WHERE t1.type='bb' AND t2.type='bc';\n\n\n\nZnajdź okręty, które \"przetrwały, ale mogły jeszcze wziąć udział w boju\" -\nzostały uszkodzone w jednej bitwie, a później uczestniczyły w innej.\n\nSELECT f.name as name FROM\n  (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN     outcomes as o1 ON b1.name=o1.battle) as f\n    JOIN\n  (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN    outcomes as o1 ON b1.name=o1.battle) as s\n    ON f.name=s.name AND s.year < f.year AND s.result='sunk';\n\n\n\nZdziwiło mnie to, ale baza nie zawiera żadnego rekordu odpowiadającego na\nostatnie pytanie. Jednak sprawdziłem to ręcznie przeglądając bazę i faktycznie\ntak jest.\n\nTesty\nDo testów wykorzystamy behat. Jeśli skopiowałeś to repozytorium, wystarczy, że\nwpiszesz composer install i nie musisz wykonywać żadnej z trzech poniższych\ninstrukcji. W przeciwnym wypadku, możesz zainstalować behat komendą\n\ncomposer require behat/behat\n\n\n\nŻeby nie wymyślać koła od nowa, do assertów podepniemy phpunit\n\ncomposer require phpunit/phpunit\n\n\n\nPrzygodę z behatem zaczynamy od utworzenia pustego kontekstu za pomocą komendy.\n\nvendor/bin/behat --init\n\n\n\nWypełnimy go teraz treścią.\n\nKontekst\nZaczynamy od podpięcia klas, z których będziemy korzystać:\n\n> features/bootstrap/FeatureContext.php\n\n\n<?php\n\nuse Behat\\Behat\\Context\\Context;\nuse Behat\\Gherkin\\Node\\TableNode;\nuse Symfony\\Component\\Yaml\\Yaml;\nuse PHPUnit\\Framework\\TestCase;\n\n/**\n * Defines application features from the specific context.\n */\nclass FeatureContext extends TestCase implements Context\n{\n\n\n\nNasz kontekst rozszerza klasę TestCase, dostarczaną przez phpunit abyśmy mogli\nłatwo narzucać warunki. Podczas działania testów będą nam potrzebne trzy\nzmienne.\n\nprivate $config;\nprivate $pdo;\nprivate $data;\n\n\n\nDo zmiennej $config zapiszemy konfigurację z pliku config/parameters.yml, w $pdo \nbędziemy trzymać połączenie z bazą, a $data będzie przechowywać wynik ostatniego\nzapytania. Dwóm pierwszym możemy przypisać wartości już w konstruktorze.\n\n    public function __construct()\n    {\n        parent::__construct();\n\n        $this->config = Yaml::parse(file_get_contents(__DIR__.'/../../config/parameters.yml'))[\"config\"];\n        $this->setPdoUsingBaseNumber(0);\n    }\n\n\n\nDziedziczymy tutaj konstruktor z phpunit. Następnie ustawiany zmienną $config.\nNie musimy instalować dodatkowego parsera do yml ponieważ behat wziął sobie ten\nz symfony, sam przecież używa swojej własnej konfiguracji w formacie yml. Na\nkoniec ustawiamy połączenie z domyślną bazą - electronic_store za pomocą funkcji \nsetPdoUsingBaseNumber(0). Jej kod jest następujący:\n\n    private function setPdoUsingBaseNumber($baseNumber)\n    {\n        try {\n            $this->pdo = new PDO(\n                $this->config[\"type\"].\n                ':host='.$this->config[\"host\"].\n                ';dbname='.$this->config[\"bases\"][$baseNumber],\n                $this->config[\"user\"],\n                $this->config[\"pass\"]);\n\n            $this->pdo->setAttribute(PDO::ATTR_DEFAULT_FETCH_MODE, PDO::FETCH_OBJ);\n\n        } catch (PDOException $e) {\n            echo 'Connection failed: ' . $e->getMessage();\n        }\n    }\n\n\n\nGeneralnie można się było tego spodziewać. Z ciekawych rzeczy jest tu tylko\nustawienie atrybutów naszego połączenia. Chcemy, żeby konwertował wyniki zapytań\ndo obiektów. Mimo, że do większości assertów wykorzystamy phpunit nie ma on\nsprawdzania występowania w tablicy dla bardziej złożonych obiektów. Można by to\nominąć serializując obiekty, ale tutaj zastosowałem inne podejście i porównałem\nje ręcznie.\n\n    private function assertArrayContainsHash($theArray, $hash)\n    {\n        foreach($theArray as $arrayItem) {\n            if((array) $arrayItem == $hash) {\n                return true;\n            }\n        }\n        throw new Exception(print_r($theArray).\" do not contain \".print_r($hash));\n    }\n\n    private function assertArrayNotContainsHash($theArray, $hash)\n    {\n        foreach($theArray as $arrayItem) {\n            if((array) $arrayItem == $hash) {\n                throw new Exception(print_r($theArray).\" do contain \".print_r($hash));\n            }\n        }\n        return true;\n    }\n\n\n\nTe funkcje sprawdzają, czy w wyniku zapytania - $theArray pojawił się testowany\nprzez nas zbiór atrybutów - $hash.\n\nTeraz przedstawimy możliwe kroki, jakie mogą się pojawić podczas testowania.\n\n    /**\n     * @Given I'm connected to :number database\n     */\n    public function connectToSecondDatabase($number)\n    {\n        $this->setPdoUsingBaseNumber($number-1);\n    }\n\n\n\nPrzełączamy się między bazami, zmieniamy numerację 1, 2 na tą w jakiej numeruje\nsię indeksy tablicy. Teraz wybieranie selektów.\n\n    /**\n     * @When I select :query from database\n     */\n    public function iSelectFromDatabase($query)\n    {\n        $stmt = $this->pdo->query($query);\n        $stmt->execute();\n        $this->data = $stmt->fetchAll();\n        $stmt->closeCursor();\n    }\n\n\n\nPo prostu tworzymy zapytanie, wykonujemy je i wyniki zapisujemy do zmiennej \n$data. Dla zachowania porządku czyścimy zapytanie. Jeśli interesuje nas\nzobaczenie wyniku, przygotowałem na to metodę\n\n    /**\n     * @Then I print result\n     */\n    public function iPrintResult()\n    {\n//        echo json_encode($this->data, JSON_PRETTY_PRINT);\n        print_r($this->data);\n    }\n\n\n\nOpcja formatowania do jsona też została przewidziana, ale ponieważ poza\ndebugowaniem ten kod nie spełnia żadnego testowego zadania, nie tworzyłem dla\nniej osobnej metody. Czas na pierwsze z warunków jakie narzucamy na dane:\n\n    /**\n     * @Then I should see :count results\n     */\n    public function iShouldSeeResults($count)\n    {\n        $this->assertEquals(sizeof($this->data), $count);\n    }\n\n    /**\n     * @Then I should see not less than :arg1 results\n     */\n    public function iShouldSeeNotLessThanResults($arg1)\n    {\n        $this->assertGreaterThanOrEqual($arg1,count($this->data));\n    }\n\n    /**\n     * @Then I should see not more than :arg1 results\n     */\n    public function iShouldSeeNotMoreThanResults($arg1)\n    {\n        $this->assertGreaterThanOrEqual(count($this->data),$arg1);\n    }\n\n\n\nJeśli chemy odnieść się do ilości rekordów w wyniku naszego zapytania możemy\nzarządać, żeby była ona równa, nie mniejsza, bądź nie większa od podanej.\n\nKolejny możliwy krok to sprawdzenie wartości atrybutu dla pierwszego wiersza\ndanego zapytania.\n\n    /**\n     * @Then Firs result should have :key equal :value\n     */\n    public function firsResultShouldHaveEqual($key, $value)\n    {\n        $this->assertArrayHasKey(0,$this->data);\n        $this->assertObjectHasAttribute($key,$this->data[0]);\n        $this->assertEquals($this->data[0]->$key,$value);\n    }\n\n\n\nKolejno sprawdzamy czy wynik ma pierwszy wiersz, czy istnieje w nim podany\natrybut i czy ma wartość której oczekujemy. Ostatni krok jest tak ogólny, że\njest stosowany przy prawie każdym scenariuszu w prawie każdym przykładnie.\n\n    /**\n     * @Then /^Result should( not)? contain fields:$/\n     */\n    public function resultShouldContainFields($not = null, TableNode $table)\n    {\n        foreach($table->getHash() as $hash)\n        {\n            if (!$not) {\n                $this->assertArrayContainsHash($this->data, $hash);\n            } else {\n                $this->assertArrayNotContainsHash($this->data,$hash);\n            }\n        }\n    }\n\n\n\nSprawdza on czy wynik zapytania zawiera określona wartości dla podanych pól, lub\nczy ich nie zawiera. Ta ogólność możliwa jest dzięki wykorzystaniu w składni \ngherkina znaku ? ozaczającego wystąpienie 0 lub 1 raz. Jeśli nie napiszemy not,\nzmienna $not przyjmie wartość domyślną null i jej zaprzeczenie będzie prawdziwe.\nJednak ciekawsze niż sama logika instrukcji warunkowej jest zastosowanie obiektu \nTableNode. Jest to obiekt dostarczany przez behat i zawiera wszystkie dane z\ntabel, które użytkownik podaje w plikach feature. Tabele te mają nagłówk i\nwartości zapisane w wierszach. Obiekt TableNode powstał żeby nie powtarzać\nsztuczki jaką w perlu wykorzystałem do osobnego traktowania nagłówka i nie\nprzetważać tych danych ręcznie. Iterując po jego metodzie getHash() przechodzimy\npo wszystkich wierszach tej tabeli z pominięciem nagłówka. W zmiennej $hash,\ntrzymamy tablicę asocjacyjną z kluczami pobranymi z nagłówka (atrybutami w\ntabeli) i wartościm pobranymi z danego wiersza.\n\nTo właśnie tą tablicę asocjacyjną wrzucamy do pokazanych wczęśniej metod\nsprawdzania występowania danego rekordu w wyniku zapytania.\n\nScenariusze testowe\nW praktyce pisałem testy nie mając jeszcze zapytań i mój workflow był\nnastępujący:\n\n 1. Przeczytać treść zapytania w języku naturalnym.\n 2. Napisać zapytanie w języku SQL.\n 3. Spojrzeć na obrazki z danymi.\n 4. Wybrać przykładowe rekordy, które powinny znaleźć się w odpowiedzi.\n 5. Wybrać przykładowe rekordy które nie powinny znaleźć się w odpowiedzi.\n 6. Wkleić selekt i dane do tabeli z testami.\n 7. Jeśli warunki nie są standardowe, dopisać brakujący scenariusz.\n\nOstatecznie plik ze scenariuszami testowymi wyewoluował do takiego postaci:\n\n> features/select.feature\n\n\nFeature: Selecting chosen fields from database\n  In order to check if my queries are correct\n  As an an database user\n  I want to execute them and test some asserts\n\n\n\nTo jest nagłówek, jest tylko dokumentacja, bo ten kod się nie wykonuje. Poniżej\npierwszy scenariusz.\n\n  Scenario Outline: Checking number of rows\n    Given I'm connected to <db> database\n    When I select \"SELECT count(*) AS c FROM <table>\" from database\n    Then I should see 1 results\n    And Firs result should have \"c\" equal <count>\n\n    Examples:\n      | db | table    | count |\n      | 1  | product  | 30    |\n      | 1  | pc       | 13    |\n      | 1  | laptop   | 10    |\n      | 1  | printer  | 7     |\n      | 2  | classes  | 8     |\n      | 2  | battles  | 4     |\n      | 2  | outcomes | 16    |\n      | 2  | ships    | 21    |\n\n\n\nZostały tu sprawdzone czy ilości rekordów w bazie odpowiadają tym z ksiązki.\nNastępnie zostają sprawdzone wszystkie zapytania, które mają tylko jedną kolumnę\nz wynikiem.\n\n  Scenario Outline: Testing query\n    Given I'm connected to <db> database\n    When I select <query> from database\n    Then Result should contain fields:\n      | <row>  |\n      | <yes1> |\n      | <yes2> |\n    And Result should not contain fields:\n      | <row>  |\n      | <no1>  |\n      | <no2>  |\n\n    Examples:\n      | db | row   | yes1      | yes2             | no1       | no2        | query                                                                                                                                                                                                                              |\n      | 1  | model | 1013      | 1006             | 1012      | 1007       | \"SELECT model FROM pc WHERE speed >= 3.0;\"                                                                                                                                                                                         |\n      | 1  | maker | E         | A                | C         | H          | \"SELECT maker FROM product NATURAL JOIN laptop WHERE hd >= 100;\"                                                                                                                                                                   |\n      | 1  | model | 3003      | 3007             | 3002      | 3005       | \"SELECT model FROM printer WHERE color AND type='laser'\"                                                                                                                                                                           |\n      | 1  | maker | F         | G                | A         | D          | \"SELECT DISTINCT maker FROM laptop NATURAL JOIN product WHERE maker NOT IN (SELECT DISTINCT maker FROM pc NATURAL JOIN product);\"                                                                                                  |\n      | 1  | maker | F         | G                | A         | D          | \"SELECT l.maker FROM (SELECT maker,type FROM product WHERE type='laptop') as l LEFT JOIN (SELECT maker,type FROM product WHERE type='pc') as p ON l.maker=p.maker WHERE p.maker IS NULL;\"                                          |\n      | 1  | hd    | 250       | 80               | 300       | 350        | \"SELECT hd FROM (SELECT count(*) as c, hd FROM pc GROUP BY hd) as calc WHERE c>=2;\"                                                                                                                                                |\n      | 1  | maker | B         | E                | H         | G          | \"SELECT  maker from (SELECT maker, count(model) as c FROM product as p NATURAL JOIN (SELECT model, speed FROM pc WHERE speed>=2.8 UNION  SELECT model, speed FROM laptop WHERE speed>=2.8) as u GROUP BY maker) as mc WHERE c>=2;\" |\n      | 1  | maker | A         | B                | C         | G          | \"SELECT maker from (SELECT maker, count(speed) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c>=3;\"                                                                                                               |\n      | 1  | maker | A         | D                | C         | H          | \"SELECT maker from (SELECT maker, count(model) as c FROM product NATURAL JOIN pc GROUP BY maker) as s WHERE s.c=3;\"                                                                                                                |\n      | 2  | name  | Ramillies | Royal Oak        | Wisconsin | Yamato     | \"SELECT name FROM ships WHERE launched<1921;\"                                                                                                                                                                                      |\n      | 2  | ship  | Bismarck  | Hood             | Wisconsin | Rodney     | \"SELECT ship FROM outcomes WHERE result='sunk' AND battle='Denmark Strait'\"                                                                                                                                                        |\n      | 2  | name  | Yamato    | North Carolina   | Kirishima | California | \"SELECT name FROM classes NATURAL JOIN ships WHERE launched>1921 AND displacement>35000\"                                                                                                                                           |\n      | 2  |country| Japan     | Gt. Britain      |USA        | Germany    | \"SELECT t1.country FROM classes as t1 JOIN classes as t2 ON t1.country=t2.country WHERE t1.type='bb' AND t2.type='bc';\"                                                                                                            |\n\n\n\nCiężko to nawet skomentować, ponieważ ten kod jest samowyjaśniający się. Po\nprostu łączymy się z bazę, wykonujemy selekt, sprawdzamy czy rezultat zawiera\ndwie przykładowe wartości, których się spodziewamy i czy nie zawiera dwóch\ninnych, których nie powinno być.\n\nZupełnie analogicznie wygląda sytuacja, jeśli mamy dwie kolumny w wyniku.\n\n  Scenario Outline: Testing query with two attributes\n    Given I'm connected to <db> database\n    When I select <query> from database\n    Then Result should contain fields:\n      | <rowA>  | <rowB>  |\n      | <yes1A> | <yes1B> |\n      | <yes2A> | <yes2B> |\n    And Result should not contain fields:\n      | <rowA> | <rowB> |\n      | <no1A> | <no1B> |\n      | <no2A> | <no2B> |\n    Examples:\n      | db | rowA  | rowB    | yes1A  | yes1B | yes2A          | yes2B | no1A    | no1B         | no2A       | no2B | query                                                                                                                                                                            |\n      | 1  | model | price   | 1004   | 649   | 2007           | 1429  | 2004    | 1150         | 3007       | 200  | \"SELECT model,price FROM product as p NATURAL JOIN (SELECT model,price FROM pc UNION SELECT model,price FROM laptop UNION SELECT model,price FROM printer) as s WHERE maker='B'\" |\n      | 2  | name  | country | Yamato | Japan | North Carolina | USA   | Repulse | Gr. Brritain | California | USA  | \"SELECT name, country FROM classes NATURAL JOIN ships WHERE bore>=16;\"                                                                                                           |\n\n\n\nNiestety nie znam mechanizmu, który pozwolił by połączyć te dwa scenariusze w\njeden, nigdzie w dokumentacji nie było nawet słowa o dziedziczeniu scenariuszy.\nMoże ktoś na stacku\n[http://stackoverflow.com/questions/40941114/flexibility-of-scenarios-in-gherkin] \nzna na to jakiś hack.\n\nJeśli masz przeczucie czym to się skończy, to właśnie tak się kończy.\n\n  Scenario: Testing query with three attributes\n    Given I'm connected to 2 database\n    When I select \"SELECT DISTINCT name, displacement, numGuns FROM classes NATURAL JOIN ships NATURAL JOIN outcomes WHERE battle='Guadalcanal';\" from database\n    Then Result should contain fields:\n      | name       | numGuns | displacement |\n      | Kirishima  | 8       | 32000        |\n      | Washington | 9       | 37000        |\n    And Result should not contain fields:\n      | name     | numGuns | displacement |\n      | Tenessee | 12      | 32000        |\n      | Bismarck | 8       | 42000        |\n\n\n\nI stało się, powtarzam ten sam kod trzeci raz. Wyrywałem sobie włosy z głowy,\nkiedy to pisałem. Okazało się, że jest tylko jeden przypadek selekta z trzema\nkolumnami, ale już widzimy niedoskonałość tego kodu.\n\nCzasem zdażało się, że chciałem przetestować występowanie tylko jednego wiersza,\nza to z dwoma atrybutami:\n\n  Scenario: Testing query (pairs)\n    When I select \"SELECT a.model as a, b.model as b FROM pc as a JOIN pc as b ON a.speed=b.speed AND a.ram=b.ram WHERE a.model>b.model;\" from database\n    Then Result should contain fields:\n      | a     | b       |\n      | 1012  | 1004    |\n    And I should see 1 results\n\n\n\nByły też przypadki z jednym rezultatem i jednym atrybutem\n\n  Scenario Outline: Testing query (max speed)\n    Given I'm connected to <db> database\n    When I select <query> from database\n    And I should see 1 results\n    And Firs result should have <row> equal <value>\n    Examples:\n      | db | row   | value    | query                                                                                                                                                                                                                          |\n      | 1  | maker | B        | \"SELECT DISTINCT maker FROM product as p NATURAL JOIN (SELECT model,speed FROM laptop UNION SELECT model,speed FROM pc) as c WHERE speed=(SELECT MAX(speed) FROM (SELECT speed FROM laptop UNION SELECT speed FROM pc) as u);\" |\n      | 2  | class | Bismarck | \"SELECT class FROM (SELECT class, count(class) as c FROM classes as cl NATURAL JOIN (SELECT ship, ship as class FROM outcomes as o UNION SELECT name, class FROM ships as s) as ext_ship GROUP BY class) as total WHERE c=1;\"  |\n\n\n\nI przypadek z w którym nie znałem dokładnej liczby wyników, ale mogłem określić\nprzedział w jakim się znajduje.\n\n  Scenario: Select all ships\n    Given I'm connected to 2 database\n    When I select \"SELECT name FROM ships UNION SELECT ship FROM outcomes;\" from database\n    Then I should see not less than \"21\" results\n    And I should see not less than \"16\" results\n    And I should see not more than 37 results\n    And Result should contain fields:\n      | name |\n      | Yamashiro |\n      | Bismarck |\n      | Fuso |\n\n\n\nNa końcu zostałem zaskoczony przez scenariusz, w którym na wyjściu niczego nie\ndostałem.\n\n  Scenario: Select null\n    Given I'm connected to 2 database\n    When I select \"SELECT f.name as name FROM (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN outcomes as o1 ON b1.name=o1.battle) as f JOIN (SELECT name, RIGHT(date,2) as year,ship,battle,result FROM battles as b1 JOIN outcomes as o1 ON b1.name=o1.battle) as s ON f.name=s.name AND s.year < f.year AND s.result='sunk';\" from database\n    Then I should see 0 results\n\n\n\nTak doszliśmy dokońca projektu.\n\nMam nadzieję, że przedstawiony materiał Ci się spodbał. Daj znać w komentarzu,\njeśli coś wymaga dodatkowego wyjaśnienia, albo jeśli wiesz jak mógł bym napisać\nbardziej ogólne testy niż te przedstawione powyżej. Mam na myśli jeden\nscenariusz dla N atrubutów, z M przykładami, które występują i L które nie\nwystępują.",
            "feature_image": "__GHOST_URL__/content/images/2021/06/behat-mysql.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:04:14.000Z",
            "updated_at": "2021-06-21T16:53:20.000Z",
            "published_at": "2021-05-04T20:18:00.000Z",
            "custom_excerpt": "Odczytamy ze zdjęcia treść tabeli bazodanowej i napiszemy w behacie kilka testów na zapytania bazodanowe.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f36072fb35425592d0b71",
            "uuid": "34516579-ca96-463c-862a-44a341726dea",
            "title": "Wpływ indeksacji na wydajność wyszukiwania w bazie MySQL",
            "slug": "testowanie-szybkosci-selektow",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"46% MySql 54% Mathematica\\n\"}],[\"code\",{\"code\":\"DROP DATABASE IF EXISTS test;\\nCREATE DATABASE IF NOT EXISTS test;\\nUSE test;\\n\",\"language\":\"sql\"}],[\"code\",{\"code\":\"CREATE TABLE main(\\n  id INTEGER UNIQUE NOT NULL AUTO_INCREMENT PRIMARY KEY,\\n  value INTEGER\\n);\",\"language\":\"sql\"}],[\"code\",{\"code\":\"drop procedure if exists load_data;\\n\\ndelimiter #\\ncreate procedure load_data(IN _max INTEGER)\\nbegin\\n\\ndeclare counter int unsigned default 0;\\n\\n  truncate table main;\\n  start transaction;\\n  while counter < _max do\\n    set counter=counter+1;\\n    insert into main (value) values (counter);\\n  end while;\\n  commit;\\nend #\\n\\ndelimiter ;\",\"language\":\"sql\"}],[\"code\",{\"code\":\"call load_data(5);\",\"language\":\"sql\"}],[\"code\",{\"code\":\"SELECT * FROM main;\\n+----+-------+\\n| id | value |\\n+----+-------+\\n|  1 |     1 |\\n|  2 |     2 |\\n|  3 |     3 |\\n|  4 |     4 |\\n|  5 |     5 |\\n+----+-------+\\n5 rows in set (0,00 sec)\",\"language\":\"sql\"}],[\"code\",{\"code\":\"drop procedure if exists add_data;\\n\\ndelimiter #\\ncreate procedure add_data(IN _max INTEGER)\\nbegin\\n\\ndeclare counter int unsigned;\\nSELECT COUNT(*) INTO counter FROM main;\\n\\n  start transaction;\\n  while counter < _max do\\n    set counter=counter+1;\\n    insert into main (value) values (counter);\\n  end while;\\n  commit;\\nend #\\n\\ndelimiter ;\",\"language\":\"sql\"}],[\"code\",{\"code\":\"SELECT @@performance_schema;\"}],[\"code\",{\"code\":\"sudo nvim /etc/my.cnf.d/server.cnf\"}],[\"code\",{\"code\":\"performance_schema\"}],[\"code\",{\"code\":\"[mysqld]\"}],[\"code\",{\"code\":\"sudo systemctl restart mysql\"}],[\"code\",{\"code\":\"SELECT NAME,ENABLED FROM performance_schema.setup_consumers;\"}],[\"code\",{\"code\":\"+----------------------------------+---------+\\n| NAME                             | ENABLED |\\n+----------------------------------+---------+\\n| events_stages_current            | NO      |\\n| events_stages_history            | NO      |\\n| events_stages_history_long       | NO      |\\n| events_statements_current        | NO      |\\n| events_statements_history        | NO      |\\n| events_statements_history_long   | NO      |\\n| events_transactions_current      | NO      |\\n| events_transactions_history      | NO      |\\n| events_transactions_history_long | NO      |\\n| events_waits_current             | NO      |\\n| events_waits_history             | NO      |\\n| events_waits_history_long        | NO      |\\n| global_instrumentation           | YES     |\\n| thread_instrumentation           | YES     |\\n| statements_digest                | YES     |\\n+----------------------------------+---------+\"}],[\"code\",{\"code\":\"SELECT NAME,ENABLED,TIMED FROM performance_schema.setup_instruments;\",\"language\":\"\"}],[\"code\",{\"code\":\"SELECT NAME,ENABLED,TIMED FROM performance_schema.setup_instruments WHERE NAME LIKE '%long%';\"}],[\"code\",{\"code\":\"+------------------------------------------------------------------+---------+-------+\\n| NAME                                                             | ENABLED | TIMED |\\n+------------------------------------------------------------------+---------+-------+\\n| statement/com/Long Data                                          | YES     | YES   |\\n| memory/performance_schema/events_stages_history_long             | YES     | NO    |\\n| memory/performance_schema/events_statements_history_long         | YES     | NO    |\\n| memory/performance_schema/events_statements_history_long.tokens  | YES     | NO    |\\n| memory/performance_schema/events_statements_history_long.sqltext | YES     | NO    |\\n| memory/performance_schema/events_transactions_history_long       | YES     | NO    |\\n| memory/performance_schema/events_waits_history_long              | YES     | NO    |\\n+------------------------------------------------------------------+---------+-------+\\n\"}],[\"code\",{\"code\":\"select * from main WHERE value=5;\"}],[\"code\",{\"code\":\"SELECT TIMER_WAIT FROM performance_schema.events_statements_history_long;\"}],[\"code\",{\"code\":\"UPDATE performance_schema.setup_consumers SET ENABLED = 'YES' WHERE NAME = 'events_statements_current' OR NAME = 'events_statements_history_long';\"}],[\"code\",{\"code\":\"SELECT * FROM performance_schema.setup_consumers;\"}],[\"code\",{\"code\":\"+----------------------------------+---------+\\n| NAME                             | ENABLED |\\n+----------------------------------+---------+\\n| events_stages_current            | NO      |\\n| events_stages_history            | NO      |\\n| events_stages_history_long       | NO      |\\n| events_statements_current        | YES     |\\n| events_statements_history        | NO      |\\n| events_statements_history_long   | YES     |\\n| events_transactions_current      | NO      |\\n| events_transactions_history      | NO      |\\n| events_transactions_history_long | NO      |\\n| events_waits_current             | NO      |\\n| events_waits_history             | NO      |\\n| events_waits_history_long        | NO      |\\n| global_instrumentation           | YES     |\\n| thread_instrumentation           | YES     |\\n| statements_digest                | YES     |\\n+----------------------------------+---------+\"}],[\"code\",{\"code\":\"use test; SELECT * from main WHERE value=5;\"}],[\"code\",{\"code\":\"SELECT SQL_TEXT,TIMER_WAIT FROM performance_schema.events_statements_history_long;\\n\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-23-10-29-36.png\",\"width\":601,\"height\":334}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://mariadb.com/kb/en/performance-schema-overview/\",\"metadata\":{\"url\":\"https://mariadb.com/kb/en/performance-schema-overview/\",\"title\":\"Performance Schema Overview\",\"description\":\"Quick overview of the Performance Schema.\",\"author\":null,\"publisher\":\"MariaDB KnowledgeBase\",\"thumbnail\":\"http://mariadb.comaskmonty-logo.png\",\"icon\":\"https://mariadb.com/kb/static/images/favicons/apple-touch-icon.159e713979be.png\"}}],[\"code\",{\"code\":\"select * from main WHERE id=5;\\nselect * from main WHERE value=5;\\n\",\"language\":\"sql\"}],[\"code\",{\"code\":\"CREATE TABLE IF NOT EXISTS result (\\n  counter INTEGER PRIMARY KEY,\\n  time_id DECIMAL(10,6),\\n  time_val DECIMAL(10,6)\\n);\",\"language\":\"sql\"}],[\"code\",{\"code\":\"drop procedure if exists time_of_select;\\n\\ndelimiter #\\ncreate procedure time_of_select(IN _max INTEGER, IN _step INTEGER)\\nbegin\\n    declare counter int unsigned DEFAULT 0;\\n    declare temp_id int unsigned DEFAULT 0;\\n    declare temp_value int unsigned DEFAULT 0;\\n    declare time_id DECIMAL(10,6);\\n    declare time_val DECIMAL(10,6);\",\"language\":\"sql\"}],[\"code\",{\"code\":\"    truncate table result;\\n    call load_data(0);\",\"language\":\"sql\"}],[\"code\",{\"code\":\"    while counter < _max do\\n        set counter=counter+_step;\\n        call add_data(counter);\",\"language\":\"sql\"}],[\"code\",{\"code\":\"        truncate performance_schema.events_statements_history_long;\\n        RESET QUERY CACHE;\",\"language\":\"sql\"}],[\"code\",{\"code\":\"        select * INTO temp_id, temp_value from main WHERE id=counter;\\n        select * INTO temp_id, temp_value from main WHERE value=counter;\",\"language\":\"sql\"}],[\"code\",{\"code\":\"        SELECT TRUNCATE(TIMER_WAIT/1000000000000,6) INTO time_id\\n             FROM performance_schema.events_statements_history_long WHERE SQL_TEXT like '%id=%';\\n        SELECT TRUNCATE(TIMER_WAIT/1000000000000,6) INTO time_val\\n             FROM performance_schema.events_statements_history_long WHERE SQL_TEXT like '%value=%';\",\"language\":\"sql\"}],[\"code\",{\"code\":\"        INSERT INTO result (counter, time_id, time_val) VALUES (counter,time_id,time_val);\\n\\n        SELECT counter/_max \\\"state\\\", counter, time_id, time_val;\\n    end while;\\nend #\\n\\ndelimiter ;\",\"language\":\"sql\"}],[\"code\",{\"code\":\"CREATE TABLE IF NOT EXISTS innoDB_result (\\n  counter INTEGER PRIMARY KEY,\\n  time_id DECIMAL(10,6),\\n  time_val DECIMAL(10,6)\\n) AS SELECT * FROM result LIMIT 2500;\\n\\n\",\"language\":\"sql\"}],[\"code\",{\"code\":\"DROP TABLE main;\\n\\nCREATE TABLE main(\\n  id INTEGER UNIQUE NOT NULL AUTO_INCREMENT PRIMARY KEY,\\n  value INTEGER\\n) ENGINE=MEMORY;\",\"language\":\"sql\"}],[\"code\",{\"code\":\"ERROR 1114 (HY000): The table 'main' is full\"}],[\"code\",{\"code\":\"SELECT max_heap_table_size;\"}],[\"code\",{\"code\":\"SET max_heap_table_size = 2048*1024*1024;\",\"language\":\"sql\"}],[\"code\",{\"code\":\"call time_of_select(25000000,10000)\"}],[\"code\",{\"code\":\"DROP TABLE main;\",\"language\":\"sql\"}],[\"code\",{\"code\":\"Needs[\\\"DatabaseLink`\\\"]\"}],[\"code\",{\"code\":\"conn = OpenSQLConnection[\\n  JDBC[\\\"MySQL(Connector/J)\\\", \\\"127.0.0.1:3306/test\\\"],\\n  \\\"Username\\\" -> \\\"root\\\", \\\"Password\\\" -> \\\"\\\"]\"}],[\"code\",{\"code\":\"counterTimeIdInnoDB = SQLExecute[conn, \\\"SELECT counter, time_id FROM innoDB_result\\\"];\\ncounterTimeValInnoDB = SQLExecute[conn, \\\"SELECT counter, time_val FROM innoDB_result\\\"];\\ncounterTimeIdMemory = SQLExecute[conn, \\\"SELECT counter, time_id FROM result\\\"];\\ncounterTimeValMemory = SQLExecute[conn, \\\"SELECT counter, time_val FROM result\\\"];\"}],[\"code\",{\"code\":\"ListPlot[{counterTimeIdInnoDB, counterTimeIdMemory},\\n PlotLabel ->\\n  \\\"Time of SELECT using PRIMARY KEY for InnoDB and MEMORY engines for \\\\\\ndifferent number of rows.\\\",\\n PlotLegends ->\\n  Placed[SwatchLegend[{\\\"InnoDB\\\", \\\"MEMORY\\\"},\\n    LegendMarkerSize -> {30, 30}], {0.5, 0.25}],\\n AxesLabel -> {\\\"Rows\\\", \\\"Time[s]\\\"} , BaseStyle -> {FontSize -> 14},\\n ImageSize -> 1200]\\nExport[\\\"plotId.png\\\", %];\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/plotId.png\",\"width\":1537,\"height\":951}],[\"code\",{\"code\":\"ListPlot[{counterTimeValInnoDB, counterTimeValMemory},\\n PlotLabel ->\\n  \\\"Time of SELECT using not indexed attribute for InnoDB and MEMORY \\\\\\nengines for different number of rows.\\\",\\n PlotLegends ->\\n  Placed[SwatchLegend[{\\\"InnoDB\\\", \\\"MEMORY\\\"},\\n    LegendMarkerSize -> {30, 30}], {0.5, 0.25}],\\n AxesLabel -> {\\\"Rows\\\", \\\"Time[s]\\\"} , BaseStyle -> {FontSize -> 14},\\n ImageSize -> 1200]\\nExport[\\\"plotVal.png\\\", %];\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/plotVal.png\",\"width\":1537,\"height\":971}],[\"code\",{\"code\":\"timeIdInnoDB = Transpose[counterTimeIdInnoDB][[2]];\\ntimeIdMemory = Transpose[counterTimeIdMemory][[2]];\\nHistogram[{Flatten[timeIdInnoDB],\\n  Flatten[timeIdMemory]}, {90, 180, 1}*10^-6,\\n PlotLabel ->\\n  \\\"Histogram of times of select by PRIMARY KEY for different times \\\\\\n(from 90\\\\[Mu]s to 180\\\\[Mu]s with step 1\\\\[Mu]s)\\\",\\n AxesLabel -> {\\\"Time[s]\\\", \\\"Count\\\"} ,\\n ChartLegends ->\\n  Placed[SwatchLegend[{\\\"InnoDB\\\", \\\"MEMORY\\\"},\\n    LegendMarkerSize -> {30, 30}], {0.5, 0.75}],\\n BaseStyle -> {FontSize -> 14},\\n ChartStyle -> ColorData[97, \\\"ColorList\\\"], ImageSize -> 1200]\\nExport[\\\"histogram.png\\\", %];\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/histogram.png\",\"width\":1537,\"height\":942}],[\"code\",{\"code\":\"dataInnoDB = Transpose[{Range[0.5, 299.5],\\n    BinCounts[Flatten[timeIdInnoDB], {0, 300, 1}*10^-6]}];\\ndataMemory = Transpose[{Range[0.5, 299.5],\\n    BinCounts[Flatten[timeIdMemory], {0, 300, 1}*10^-6]}];\"}],[\"code\",{\"code\":\"model = c HeavisideTheta[x - a] (x - a)*Exp[-b (x - a)];\"}],[\"code\",{\"code\":\"lineInnoDB =\\n FindFit[dataInnoDB, model, { {a, 120}, {b, 0.2}, {c, 100} }, x]\\nlineMemory =\\n FindFit[dataMemory, model, { {a, 100}, {b, 0.8}, {c, 100} }, x]\"}],[\"code\",{\"code\":\"{a -> 126.08, b -> 0.212895, c -> 102.94}\"}],[\"code\",{\"code\":\"{a -> 99.4551, b -> 0.836701, c -> 1587.85}\",\"caption\":\"\"}],[\"code\",{\"code\":\"Show[ListPlot[{dataInnoDB, dataMemory}, Filling -> Axis,\\n  PlotRange -> All, PlotMarkers -> {\\\"\\\\[FilledCircle]\\\", 4},\\n  PlotLegends ->\\n   Placed[SwatchLegend[{\\\"InnoDB\\\", \\\"MEMORY\\\"},\\n     LegendMarkerSize -> {30, 30}], {0.5, 0.75}]],\\n Plot[{model /. lineInnoDB, model /. lineMemory}, {x, 0, 300},\\n  PlotRange -> All], AxesLabel -> {\\\"Time[\\\\[Mu]s]\\\", \\\"Count\\\"},\\n PlotLabel ->\\n  \\\"Histogram of times of selects execution with curves fitted for \\\\\\nmodel c HeavisideTheta[x-a](x-a)*Exp[-b(x-a)]\\\",\\n BaseStyle -> {FontSize -> 14}, ImageSize -> 1200]\\nExport[\\\"model.png\\\", %]\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/model.png\",\"width\":1537,\"height\":954}]],\"markups\":[[\"strong\"],[\"code\"],[\"a\",[\"href\",\"http://dev.mysql.com/doc/refman/5.6/en/performance-schema-query-profiling.html\"]],[\"a\",[\"href\",\"http://stackoverflow.com/questions/11274892/measuring-actual-mysql-query-time\"]],[\"a\",[\"href\",\"http://dba.stackexchange.com/questions/157525/difference-between-size-of-table-saved-on-hard-drive-or-in-ram-how-to-calculate\"]],[\"a\",[\"href\",\"http://mathematica.stackexchange.com/questions/26174/recommended-settings-for-git-when-using-with-mathematica-projects\"]],[\"a\",[\"href\",\"http://dba.stackexchange.com/users/1876/rick-james\"]],[\"a\",[\"href\",\"http://dba.stackexchange.com\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Wyszukiwanie po kluczu jest szybsze niż wyszukiwanie po zwykłym atrybucie. Nic odkrywczego. Jednak byłem ciekaw jakiego rzędu są to różnice. Przygotowałem eksperyment.\"]]],[1,\"p\",[[0,[],0,\"W tym artykule przedstawię porównanie szybkości wyszukiwania po \"],[0,[0],1,\"kluczu głównym\"],[0,[],0,\" z wyszukiwaniem po \"],[0,[0],1,\"nie indeksowanym atrybucie\"],[0,[],0,\". Zobaczę jak na wydajność wyszukiwania wpływa przeniesienie tabeli do \"],[0,[0],1,\"pamięci operacyjnej\"],[0,[],0,\". Oraz przeanalizuję wyniki za pomocą oprogramowania \"],[0,[1],1,\"Mathematica\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Skład kodu\"]]],[10,0],[1,\"h2\",[[0,[],0,\"Baza danych\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od standardowego nagłówka zapewniającego idempotentność. W MySql jest to dość proste\"]]],[10,1],[1,\"p\",[[0,[],0,\"Tworzymy jedną tabelę z kluczem oraz zwykłym atrybutem\"]]],[10,2],[1,\"h3\",[[0,[],0,\"Procedury zapisu danych\"]]],[1,\"p\",[[0,[],0,\"Definiujemy procedurę wypełniającą tabelę danymi\"]]],[10,3],[1,\"p\",[[0,[],0,\"Najpierw usunęliśmy procedurę o tej nazwie, jeśli już istniała. W kolejnej linii ustawiliśmy znak końca komendy na \"],[0,[1],1,\"#\"],[0,[],0,\". Dzięki temu definiowanie procedury nie zostanie przerwane w środku przez występujące tam średniki. Naszą procedurę nazwaliśmy \"],[0,[1],1,\"load_data\"],[0,[],0,\" i posiada ona jeden argument całkowitoliczbowy - liczbę wierszy jakimi wypełni tabelę. Linia zaczynająca się od \"],[0,[1],1,\"declare\"],[0,[],0,\" odpowiada za ustawienie zmiennej lokalnej przechowującą nasz licznik. Przed rozpoczęciem transakcji czyścimy tabelę którą będziemy wypełniać. Wewnątrz transakcji wykonuje się pętla zapisująca do tabeli wartości od \"],[0,[1],1,\"1\"],[0,[],0,\" do \"],[0,[1],1,\"_max\"],[0,[],0,\". Na końcu używamy znaku \"],[0,[1],1,\"#\"],[0,[],0,\" jako średnika i przywracamy średnikowi jego domyślne znaczenia. Całkiem sporo kodu jak na tak prostą operację. Jednak zysk z tego jest taki, że teraz wystarczy wpisać np.:\"]]],[10,4],[1,\"p\",[[0,[],0,\"a tabela wypełni się danymi zgodnie z naszymi oczekiwaniami\"]]],[10,5],[1,\"p\",[[0,[],0,\"Ta procedura jest bardzo wygodna, bo pozwala ustawić dowolny rozmiar tabeli, ale ponieważ będziemy testować duże tabele i często podnosić ich rozmiary dodamy bardziej ograniczoną, ale wydajniejszą w naszym przypadku procedurę, która nie usuwa tablicy, a zamiast tego dopełnia ją danymi do podanego rozmiaru.\"]]],[10,6],[1,\"p\",[[0,[],0,\"Nie ma tu już czyszczenia dotychczasowej zawartości tabeli. Counter nie przyjmuje wartości domyślnej \"],[0,[1],1,\"0\"],[0,[],0,\", za to użyliśmy instrukcji \"],[0,[1],1,\"SELECT ... INTO ...\"],[0,[],0,\" która wynik selektu przypisuje do zmiennej.\"]]],[1,\"p\",[[0,[],0,\"Teraz wykonanie \"],[0,[1],1,\"call add_data(5)\"],[0,[],0,\" nie zmieni stanu naszej tabeli, ale po wykonaniu \"],[0,[1],1,\"call add_data(10)\"],[0,[],0,\" rezultat będzie taki sam jak po \"],[0,[1],1,\"call load_data(10)\"],[0,[],0,\" tyle, że oszczędziliśmy czas na usuwanie i wstawianie 5 wierszy, które już tam były.\"]]],[1,\"h3\",[[0,[],0,\"Performance Schema\"]]],[1,\"p\",[[0,[],0,\"Zarówno w \"],[0,[1],1,\"mysql\"],[0,[],0,\" jak i w \"],[0,[1],1,\"mariadb\"],[0,[],0,\" do badania wydajności zapytań służy jest baza \"],[0,[1],1,\"performance_schema\"],[0,[],0,\". Może się okazać, że jej używanie jest wyłączone. Sprawdzimy to dzięki zmiennej \"],[0,[1],1,\"performance_schema\"],[0,[],0,\". \"]]],[10,7],[1,\"p\",[[0,[],0,\"Jeśli jest stawiona na wartość \"],[0,[1],1,\"0\"],[0,[],0,\" należy w pliku konfiguracyjnym:\"]]],[10,8],[1,\"p\",[[0,[],0,\"dodać linię:\"]]],[10,9],[1,\"p\",[[0,[],0,\"w sekcji:\"]]],[10,10],[1,\"p\",[[0,[],0,\"następnie zrestartować bazę danych poleceniem\"]]],[10,11],[1,\"p\",[[0,[],0,\"Jeśli \"],[0,[1],1,\"SELECT @@performance_schema;\"],[0,[],0,\" zwraca 1 oznacza to, że aktywowaliśmy ten mechanizm, ale nie jest to równoważne z możliwością wykonywaniem pomiarów, których potrzebujemy. Mechanizm zbierania logów może być bardzo rozbudowany i musimy go skonfigurować samodzielnie ze względów wydajnościowych.\"]]],[1,\"p\",[[0,[],0,\"Na przegląd aktualnych ustawień pozwolą nam zapytania o \"],[0,[1],1,\"setup_consumers\"],[0,[],0,\" \"]]],[10,12],[10,13],[1,\"p\",[[0,[],0,\"oraz o instrumentacje z tabeli \"],[0,[1],1,\"setup_instruments\"]]],[10,14],[1,\"p\",[[0,[],0,\"wyników jest bardzo dużo więc ograniczymy się do tych:\"]]],[10,15],[10,16],[1,\"p\",[[0,[],0,\"Chcemy doprowadzić do sytuacji w której po wykonaniu zapytania:\"]]],[10,17],[1,\"p\",[[0,[],0,\"odpytują o \"]]],[10,18],[1,\"p\",[[0,[],0,\"zobaczymy zmierzony czas trwania ostatniego zapytania.\"]]],[1,\"p\",[[0,[],0,\"Aby to uzyskać włączymy konsumentów \"],[0,[1],1,\"events_statements_history_long\"],[0,[],0,\" oraz \"],[0,[1],1,\"events_statements_current\"],[0,[],0,\" zapytaniem:\"]]],[10,19],[1,\"p\",[[0,[],0,\"Teraz dla zapytania:\"]]],[10,20],[1,\"p\",[[0,[],0,\"powinniśmy zobaczyć:\"]]],[10,21],[1,\"p\",[[0,[],0,\"A po wykonaniu\"]]],[10,22],[1,\"p\",[[0,[],0,\"a następnie\"]]],[10,23],[1,\"p\",[[0,[],0,\"powinniśmy zobaczyć czas trwania zapytania wyrażony w pikosekundach\"]]],[10,24],[1,\"p\",[[0,[],0,\"Jeśli temat konfiguracji mechanizmu profilowania Cię zainteresował możesz pogłębić wiedzę bezpośrednio w dokumentacji: \"]]],[10,25],[1,\"h3\",[[0,[],0,\"Procedura testująca (InnoDB)\"]]],[1,\"p\",[[0,[],0,\"Wykonamy teraz testy. Interesują nas czasy wykonywania selektów po \"],[0,[1],1,\"id\"],[0,[],0,\" oraz po \"],[0,[1],1,\"value\"],[0,[],0,\".\"]]],[10,26],[1,\"p\",[[0,[],0,\"Pierwszy z nich nazwiemy \"],[0,[1],1,\"time_id\"],[0,[],0,\" drugi \"],[0,[1],1,\"time_val\"],[0,[],0,\", liczbę wierszy nazwiemy \"],[0,[1],1,\"counter\"],[0,[],0,\". Wyniki testów będziemy chcieli później przetwarzać, dlatego stworzymy dla nich specjalną tabelę.\"]]],[10,27],[1,\"p\",[[0,[],0,\"Za jej wypełnianie odpowiedzialna będzie procedura, którą rozbijemy na kilka części. Oto jej początek.\"]]],[10,28],[1,\"p\",[[0,[],0,\"Zaczyna się jak wszystkie pozostałe - czyści dla siebie miejsce, ustawia znak nowej komendy na \"],[0,[1],1,\"#\"],[0,[],0,\" wybiera sobie nazwę, argumenty i deklaruje zmienne lokalne. Argumenty to maksymalna wielkość tabeli dla jakiej chcemy testować, oraz krok jaki ma wykonywać nasz licznik. Zmienne lokalne służą do iteracji - \"],[0,[1],1,\"counter\"],[0,[],0,\", zapobiegają wyświetlaniu nie potrzebnych danych \"],[0,[1],1,\"temp_id\"],[0,[],0,\" i \"],[0,[1],1,\"temp_value\"],[0,[],0,\", oraz przechowują wyniki pomiarów czasu - \"],[0,[1],1,\"time_id\"],[0,[],0,\" i \"],[0,[1],1,\"time_val\"],[0,[],0,\". Następnie jest czyszczenie tabel.\"]]],[10,29],[1,\"p\",[[0,[],0,\"Zauważ, że \"],[0,[1],1,\"call load_data(0)\"],[0,[],0,\" jest równoważne komendzie \"],[0,[1],1,\"truncate table main\"],[0,[],0,\". Po wyczyszczeniu wszystkich danych możemy zacząć przebieganie pętli\"]]],[10,30],[1,\"p\",[[0,[],0,\"Podnosimy licznik i dodajemy wiersze do tabeli \"],[0,[1],1,\"main\"],[0,[],0,\".\"]]],[10,31],[1,\"p\",[[0,[],0,\"Czyścimy historię pomiarów wydajności i resetujemy cache.\"]]],[10,32],[1,\"p\",[[0,[],0,\"Wykonujemy selekty które chcemy testować. Żeby nie zaśmiecały nam ekranu przekierowujemy je do lokalnych zmiennych, z którymi już nic nie będziemy robić. Teraz najciekawsza część - mierzenie wydajności:\"]]],[10,33],[1,\"p\",[[0,[],0,\"Jest to nowa \"],[0,[2],1,\"zalecana\"],[0,[],0,\" metoda na mierzenie wydajności ponieważ \"],[0,[1],1,\"SET profiling = 1;\"],[0,[],0,\" jest już \"],[0,[3],1,\"zdeprecjonowany\"],[0,[],0,\". Mając wszystkie potrzebne parametry dopisujemy je do tabeli \"],[0,[1],1,\"result\"],[0,[],0,\", wyświetlamy je i kończymy definiowanie procedury w standardowy sposób.\"]]],[10,34],[1,\"p\",[[0,[],0,\"Dokładnie 4 godziny, 40 minut zajęło mi wykonanie procedury \"],[0,[1],1,\"call time_of_select(25000000,10000)\"],[0,[],0,\", czyli wykonywanie pomiarów dla tabeli o rozmiarach od 10 tysięcy do 25 milionów rekordów z krokiem 10 tysięcy.\"]]],[1,\"h3\",[[0,[],0,\"Testowanie silnika MEMORY\"]]],[1,\"p\",[[0,[],0,\"Żeby móc wrócić do tych danych i bez żadnych zmian w kodzie procedur wykonać pomiar na tabeli trzymanej w pamięci RAM przepiszemy nasze wyniki do nowej tabeli.\"]]],[10,35],[1,\"p\",[[0,[],0,\"Oraz postawimy naszą tabelę \"],[0,[1],1,\"result\"],[0,[],0,\" od nowa tym razem w pamięci RAM.\"]]],[10,36],[1,\"p\",[[0,[],0,\"Jeśli w tym momencie włączyli byśmy procedurę testującą, to po 8 sekundach dostali byśmy następujący błąd:\"]]],[10,37],[1,\"p\",[[0,[],0,\"Jest tak dlatego, że domyślnie \"],[0,[1],1,\"MySQL\"],[0,[],0,\" ma ustawiony rozmiar tabel w pamięci \"],[0,[1],1,\"RAM\"],[0,[],0,\" na 16 MB.  Możemy to sprawdzić wpisując\"]]],[10,38],[1,\"p\",[[0,[],0,\"Zmienimy go komendą:\"]]],[10,39],[1,\"p\",[[0,[],0,\"Która na wszelki wypadek ustawi 2 GB RAM dla bazy danych. I tu pojawia się pytanie, skąd wziąłem akurat 2 GB. Szczerze przyznam, że nie wiedziałem w momencie pisania tego artykułu. Ta tabela na dysku zajmowała u mnie 930.72 MB, więc myślałem, że w 1 GB RAM powinna się zmieścić, ale okazało się, że po zapisaniu w pamięci operacyjnej jej rozmiar to aż 1538.54 MB. Zadałem na ten temat pytanie na \"],[0,[4],1,\"stacku\"],[0,[],0,\". Okazało się, że \"],[0,[1],1,\"InnoDB\"],[0,[],0,\" przechowuje dane w \"],[0,[1],1,\"BTree\"],[0,[],0,\" a \"],[0,[1],1,\"MEMORY\"],[0,[],0,\" w \"],[0,[1],1,\"Hash\"],[0,[],0,\", co znacząco obniża możliwość kompresji kluczy w tabeli trzymanej w pamięci RAM. Teraz testy powinny pójść gładko. Możemy ponownie uruchomić procedurę do testowania.\"]]],[10,40],[1,\"p\",[[0,[],0,\"Tym razem test trwał 46 minut.\"]]],[1,\"p\",[[0,[],0,\"Tabela \"],[0,[1],1,\"main\"],[0,[],0,\" nie będzie nas już interesować. Aby zwolnić pamięć możemy ją usunąć.\"]]],[10,41],[1,\"p\",[[0,[],0,\"Po tych operacjach mamy następującą sytuację: w bazie zostały dwie tabele z wynikami \"],[0,[1],1,\"innoDB_result\"],[0,[],0,\" dla silnika \"],[0,[1],1,\"innoDB\"],[0,[],0,\" oraz \"],[0,[1],1,\"result\"],[0,[],0,\" dla silnika \"],[0,[1],1,\"MEMORY\"],[0,[],0,\". Do ich analizy nie będziemy wykorzystywać już MqSQL. Możemy zamknąć połączenie z bazą.\"]]],[1,\"h2\",[[0,[],0,\"Analiza wyników\"]]],[1,\"p\",[[0,[],0,\"Do analizy danych wykorzystamy program \"],[0,[1],1,\"Mathematica\"],[0,[],0,\" firmy \"],[0,[1],1,\"Wolfram Research\"],[0,[],0,\". Z tego programu można korzystać na dwa sposoby - pisząc w notebookach (coś jak brudnopis) i pisząc paczki oraz skrypty wykonywalne z konsoli. Paczki i skrypty są to czyste pliki tekstowe, które nadają się do trzymania w repozytorium. Notebooki niestety \"],[0,[5],1,\"nie\"],[0,[],0,\". Notebooki nadają się do rozbudowy kodu i liczenia czegoś, co ma zostać policzone jeden raz, a paczki i skrypty do wielokrotnego użytku i automatyzacji. W naszym przypadku odpowiednim narzędziem będzie notebook. Zaczynamy więc pisanie w nowym notebooku.\"]]],[1,\"h3\",[[0,[],0,\"Wizualizacja danych z bazy\"]]],[1,\"p\",[[0,[],0,\"Aby połączyć się z bazą danych importujemy odpowiednią paczkę.\"]]],[10,42],[1,\"p\",[[0,[],0,\"I ustawiamy zmienną zawierającą połączenie\"]]],[10,43],[1,\"p\",[[0,[],0,\"Wyciągamy z bazy interesujące nas dane.\"]]],[10,44],[1,\"p\",[[0,[],0,\"I od razu przechodzimy do rysowania wykresu.\"]]],[10,45],[10,46],[1,\"p\",[[0,[],0,\"Widzimy, że zarówno dla \"],[0,[1],1,\"InnoDB\"],[0,[],0,\" jak i \"],[0,[1],1,\"MEMORY\"],[0,[],0,\" szybkość wybierania po identyfikatorze nie zależy od ilości rekordów w bazie dla naszego zakresu. Na pewno nie jest to zależność, którą można by wyłowić z szumu, który jest tutaj obecny. Widać, że dla tabeli w pamięci operacyjnej selekty są wykonywane szybciej, a czas ich wykonywania jest bardziej regularny. Zupełnie inaczej sytuacja wygląda dla nie indeksowanych atrybutów.\"]]],[10,47],[10,48],[1,\"p\",[[0,[],0,\"Czas wybierania nie indeksowanego atrybutu rośnie liniowo z wielkością bazy. Tu również tabela zapisana w pamięci operacyjnej działa szybciej.\"]]],[1,\"p\",[[0,[],0,\"Dzięki dopasowaniu prostej poleceniem \"],[0,[1],1,\"Fit[counterTimeValInnoDB, {x}, x]\"],[0,[],0,\" widzimy, że współczynnik kierunkowy dla tabeli na dysku to \"],[0,[1],1,\"3.06e-7\"],[0,[],0,\", co oznacza, że na milion rekordów przypada 0.3 sekundy wyszukiwania. Obliczając współczynnik kierunkowy dla silnika \"],[0,[1],1,\"MEMORY\"],[0,[],0,\" poleceniem \"],[0,[1],1,\"Fit[counterTimeValMemory, {x}, x]\"],[0,[],0,\" otrzymamy \"],[0,[1],1,\"6.46e-8\"],[0,[],0,\", czyli 0.06 sekundy na milion rekordów, a więc 4.7 raza krócej.\"]]],[1,\"h3\",[[0,[],0,\"Histogram\"]]],[1,\"p\",[[0,[],0,\"Wróćmy do wybierania po kluczach. Ponieważ w tamtym przypadku zależność od czasu nie była widoczna, zredukujmy tą zmienną przyjrzyjmy się histogramowi przedstawiającemu liczbę zliczeń których czas wykonywania mieścił się w określonym przedziale. Za rysowanie odpowiada poniższy kod.\"]]],[10,49],[10,50],[1,\"h3\",[[0,[],0,\"Model\"]]],[1,\"p\",[[0,[],0,\"Nie znam wystarczająco dobrze mechanizmu odpowiadającego za ten rozkład. Jego znajomość pozwoliła by mi wybrać odpowiedni model matematyczny, który można by dopasować do danych. Z tego względu dalsza część to dopasowanie rozkładu, który tylko z grubsza przypomina ten rzeczywisty. Zaczynamy od wycięcia danych do dopasowywania modelu.\"]]],[10,51],[1,\"p\",[[0,[],0,\"Te tablice zawierają czas przeliczony na mikrosekundy oraz odpowiadające chwilom czasu liczby zliczeń. Przesunięcie o 0.5 wynika z tego, że punktowi 0.5 odpowiada przedział od 0 do 1. Następnie postulujemy model.\"]]],[10,52],[1,\"p\",[[0,[],0,\"Jak wspomniałem nie jest to model wywnioskowany z właściwości niskopoziomowej implementacji baz danych, a jedynie pierwszy prosty model jaki mi przyszedł do głowy. Kiedy mamy dane i model zostało tylko wyliczyć jego współczynniki. Odpowiadają za to linie:\"]]],[10,53],[1,\"p\",[[0,[],0,\"Współczynniki, które otrzymaliśmy to odpowiednio\"]]],[10,54],[1,\"p\",[[0,[],0,\"dla \"],[0,[1],1,\"InnoDB\"],[0,[],0,\" oraz\"]]],[10,55],[1,\"p\",[[0,[],0,\"dla \"],[0,[1],1,\"MEMORY\"],[0,[],0,\". Pozostało tylko wyrysowanie wykresu porównującego dopasowane krzywe z danymi doświadczalnymi. Do łączenia wykresów różnych typów służy polecenie \"],[0,[1],1,\"Show\"],[0,[],0,\", jego składnia jest następująca:\"]]],[10,56],[10,57],[1,\"p\",[[0,[],0,\"To dopiero początek mojej przygody z bazami danych i wciąż temat ten jest znany mi tylko pobieżnie. Z tego względu wpisy dotyczące baz należy taktować bardziej jako notatki ucznia, niż wskazówki eksperta. Mimo to, mam nadzieję, że czas poświęcony na czytanie przełożył się u Ciebie na lepsze wyczucie ilościowych aspektów związanych z wydajnością indeksowania.\"]]],[1,\"p\",[[0,[],0,\"Na koniec dziękuję \"],[0,[6],1,\"Rickowi Jamesowi\"],[0,[],0,\" za odpowiedzi na praktycznie każde pytanie, jakie do tej pory zadałem na \"],[0,[7],1,\"dba.stackexchange.com\"],[0,[],0,\".\"]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Wyszukiwanie po kluczu jest szybsze niż wyszukiwanie po zwykłym atrybucie. Nic odkrywczego. Jednak byłem ciekaw jakiego rzędu są to różnice. Przygotowałem eksperyment.</p><p>W tym artykule przedstawię porównanie szybkości wyszukiwania po <strong>kluczu głównym</strong> z wyszukiwaniem po <strong>nie indeksowanym atrybucie</strong>. Zobaczę jak na wydajność wyszukiwania wpływa przeniesienie tabeli do <strong>pamięci operacyjnej</strong>. Oraz przeanalizuję wyniki za pomocą oprogramowania <code>Mathematica</code>.</p><p>Skład kodu</p><pre><code>46% MySql 54% Mathematica\n</code></pre><h2 id=\"baza-danych\">Baza danych</h2><p>Zaczniemy od standardowego nagłówka zapewniającego idempotentność. W MySql jest to dość proste</p><pre><code class=\"language-sql\">DROP DATABASE IF EXISTS test;\nCREATE DATABASE IF NOT EXISTS test;\nUSE test;\n</code></pre><p>Tworzymy jedną tabelę z kluczem oraz zwykłym atrybutem</p><pre><code class=\"language-sql\">CREATE TABLE main(\n  id INTEGER UNIQUE NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  value INTEGER\n);</code></pre><h3 id=\"procedury-zapisu-danych\">Procedury zapisu danych</h3><p>Definiujemy procedurę wypełniającą tabelę danymi</p><pre><code class=\"language-sql\">drop procedure if exists load_data;\n\ndelimiter #\ncreate procedure load_data(IN _max INTEGER)\nbegin\n\ndeclare counter int unsigned default 0;\n\n  truncate table main;\n  start transaction;\n  while counter &lt; _max do\n    set counter=counter+1;\n    insert into main (value) values (counter);\n  end while;\n  commit;\nend #\n\ndelimiter ;</code></pre><p>Najpierw usunęliśmy procedurę o tej nazwie, jeśli już istniała. W kolejnej linii ustawiliśmy znak końca komendy na <code>#</code>. Dzięki temu definiowanie procedury nie zostanie przerwane w środku przez występujące tam średniki. Naszą procedurę nazwaliśmy <code>load_data</code> i posiada ona jeden argument całkowitoliczbowy - liczbę wierszy jakimi wypełni tabelę. Linia zaczynająca się od <code>declare</code> odpowiada za ustawienie zmiennej lokalnej przechowującą nasz licznik. Przed rozpoczęciem transakcji czyścimy tabelę którą będziemy wypełniać. Wewnątrz transakcji wykonuje się pętla zapisująca do tabeli wartości od <code>1</code> do <code>_max</code>. Na końcu używamy znaku <code>#</code> jako średnika i przywracamy średnikowi jego domyślne znaczenia. Całkiem sporo kodu jak na tak prostą operację. Jednak zysk z tego jest taki, że teraz wystarczy wpisać np.:</p><pre><code class=\"language-sql\">call load_data(5);</code></pre><p>a tabela wypełni się danymi zgodnie z naszymi oczekiwaniami</p><pre><code class=\"language-sql\">SELECT * FROM main;\n+----+-------+\n| id | value |\n+----+-------+\n|  1 |     1 |\n|  2 |     2 |\n|  3 |     3 |\n|  4 |     4 |\n|  5 |     5 |\n+----+-------+\n5 rows in set (0,00 sec)</code></pre><p>Ta procedura jest bardzo wygodna, bo pozwala ustawić dowolny rozmiar tabeli, ale ponieważ będziemy testować duże tabele i często podnosić ich rozmiary dodamy bardziej ograniczoną, ale wydajniejszą w naszym przypadku procedurę, która nie usuwa tablicy, a zamiast tego dopełnia ją danymi do podanego rozmiaru.</p><pre><code class=\"language-sql\">drop procedure if exists add_data;\n\ndelimiter #\ncreate procedure add_data(IN _max INTEGER)\nbegin\n\ndeclare counter int unsigned;\nSELECT COUNT(*) INTO counter FROM main;\n\n  start transaction;\n  while counter &lt; _max do\n    set counter=counter+1;\n    insert into main (value) values (counter);\n  end while;\n  commit;\nend #\n\ndelimiter ;</code></pre><p>Nie ma tu już czyszczenia dotychczasowej zawartości tabeli. Counter nie przyjmuje wartości domyślnej <code>0</code>, za to użyliśmy instrukcji <code>SELECT ... INTO ...</code> która wynik selektu przypisuje do zmiennej.</p><p>Teraz wykonanie <code>call add_data(5)</code> nie zmieni stanu naszej tabeli, ale po wykonaniu <code>call add_data(10)</code> rezultat będzie taki sam jak po <code>call load_data(10)</code> tyle, że oszczędziliśmy czas na usuwanie i wstawianie 5 wierszy, które już tam były.</p><h3 id=\"performance-schema\">Performance Schema</h3><p>Zarówno w <code>mysql</code> jak i w <code>mariadb</code> do badania wydajności zapytań służy jest baza <code>performance_schema</code>. Może się okazać, że jej używanie jest wyłączone. Sprawdzimy to dzięki zmiennej <code>performance_schema</code>. </p><pre><code>SELECT @@performance_schema;</code></pre><p>Jeśli jest stawiona na wartość <code>0</code> należy w pliku konfiguracyjnym:</p><pre><code>sudo nvim /etc/my.cnf.d/server.cnf</code></pre><p>dodać linię:</p><pre><code>performance_schema</code></pre><p>w sekcji:</p><pre><code>[mysqld]</code></pre><p>następnie zrestartować bazę danych poleceniem</p><pre><code>sudo systemctl restart mysql</code></pre><p>Jeśli <code>SELECT @@performance_schema;</code> zwraca 1 oznacza to, że aktywowaliśmy ten mechanizm, ale nie jest to równoważne z możliwością wykonywaniem pomiarów, których potrzebujemy. Mechanizm zbierania logów może być bardzo rozbudowany i musimy go skonfigurować samodzielnie ze względów wydajnościowych.</p><p>Na przegląd aktualnych ustawień pozwolą nam zapytania o <code>setup_consumers</code> </p><pre><code>SELECT NAME,ENABLED FROM performance_schema.setup_consumers;</code></pre><pre><code>+----------------------------------+---------+\n| NAME                             | ENABLED |\n+----------------------------------+---------+\n| events_stages_current            | NO      |\n| events_stages_history            | NO      |\n| events_stages_history_long       | NO      |\n| events_statements_current        | NO      |\n| events_statements_history        | NO      |\n| events_statements_history_long   | NO      |\n| events_transactions_current      | NO      |\n| events_transactions_history      | NO      |\n| events_transactions_history_long | NO      |\n| events_waits_current             | NO      |\n| events_waits_history             | NO      |\n| events_waits_history_long        | NO      |\n| global_instrumentation           | YES     |\n| thread_instrumentation           | YES     |\n| statements_digest                | YES     |\n+----------------------------------+---------+</code></pre><p>oraz o instrumentacje z tabeli <code>setup_instruments</code></p><pre><code>SELECT NAME,ENABLED,TIMED FROM performance_schema.setup_instruments;</code></pre><p>wyników jest bardzo dużo więc ograniczymy się do tych:</p><pre><code>SELECT NAME,ENABLED,TIMED FROM performance_schema.setup_instruments WHERE NAME LIKE '%long%';</code></pre><pre><code>+------------------------------------------------------------------+---------+-------+\n| NAME                                                             | ENABLED | TIMED |\n+------------------------------------------------------------------+---------+-------+\n| statement/com/Long Data                                          | YES     | YES   |\n| memory/performance_schema/events_stages_history_long             | YES     | NO    |\n| memory/performance_schema/events_statements_history_long         | YES     | NO    |\n| memory/performance_schema/events_statements_history_long.tokens  | YES     | NO    |\n| memory/performance_schema/events_statements_history_long.sqltext | YES     | NO    |\n| memory/performance_schema/events_transactions_history_long       | YES     | NO    |\n| memory/performance_schema/events_waits_history_long              | YES     | NO    |\n+------------------------------------------------------------------+---------+-------+\n</code></pre><p>Chcemy doprowadzić do sytuacji w której po wykonaniu zapytania:</p><pre><code>select * from main WHERE value=5;</code></pre><p>odpytują o </p><pre><code>SELECT TIMER_WAIT FROM performance_schema.events_statements_history_long;</code></pre><p>zobaczymy zmierzony czas trwania ostatniego zapytania.</p><p>Aby to uzyskać włączymy konsumentów <code>events_statements_history_long</code> oraz <code>events_statements_current</code> zapytaniem:</p><pre><code>UPDATE performance_schema.setup_consumers SET ENABLED = 'YES' WHERE NAME = 'events_statements_current' OR NAME = 'events_statements_history_long';</code></pre><p>Teraz dla zapytania:</p><pre><code>SELECT * FROM performance_schema.setup_consumers;</code></pre><p>powinniśmy zobaczyć:</p><pre><code>+----------------------------------+---------+\n| NAME                             | ENABLED |\n+----------------------------------+---------+\n| events_stages_current            | NO      |\n| events_stages_history            | NO      |\n| events_stages_history_long       | NO      |\n| events_statements_current        | YES     |\n| events_statements_history        | NO      |\n| events_statements_history_long   | YES     |\n| events_transactions_current      | NO      |\n| events_transactions_history      | NO      |\n| events_transactions_history_long | NO      |\n| events_waits_current             | NO      |\n| events_waits_history             | NO      |\n| events_waits_history_long        | NO      |\n| global_instrumentation           | YES     |\n| thread_instrumentation           | YES     |\n| statements_digest                | YES     |\n+----------------------------------+---------+</code></pre><p>A po wykonaniu</p><pre><code>use test; SELECT * from main WHERE value=5;</code></pre><p>a następnie</p><pre><code>SELECT SQL_TEXT,TIMER_WAIT FROM performance_schema.events_statements_history_long;\n</code></pre><p>powinniśmy zobaczyć czas trwania zapytania wyrażony w pikosekundach</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-23-10-29-36.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"601\" height=\"334\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/Screenshot-from-2021-06-23-10-29-36.png 600w, __GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-23-10-29-36.png 601w\"></figure><p>Jeśli temat konfiguracji mechanizmu profilowania Cię zainteresował możesz pogłębić wiedzę bezpośrednio w dokumentacji: </p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://mariadb.com/kb/en/performance-schema-overview/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Performance Schema Overview</div><div class=\"kg-bookmark-description\">Quick overview of the Performance Schema.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://mariadb.com/kb/static/images/favicons/apple-touch-icon.159e713979be.png\"><span class=\"kg-bookmark-author\">MariaDB KnowledgeBase</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"http://mariadb.comaskmonty-logo.png\"></div></a></figure><h3 id=\"procedura-testuj%C4%85ca-innodb\">Procedura testująca (InnoDB)</h3><p>Wykonamy teraz testy. Interesują nas czasy wykonywania selektów po <code>id</code> oraz po <code>value</code>.</p><pre><code class=\"language-sql\">select * from main WHERE id=5;\nselect * from main WHERE value=5;\n</code></pre><p>Pierwszy z nich nazwiemy <code>time_id</code> drugi <code>time_val</code>, liczbę wierszy nazwiemy <code>counter</code>. Wyniki testów będziemy chcieli później przetwarzać, dlatego stworzymy dla nich specjalną tabelę.</p><pre><code class=\"language-sql\">CREATE TABLE IF NOT EXISTS result (\n  counter INTEGER PRIMARY KEY,\n  time_id DECIMAL(10,6),\n  time_val DECIMAL(10,6)\n);</code></pre><p>Za jej wypełnianie odpowiedzialna będzie procedura, którą rozbijemy na kilka części. Oto jej początek.</p><pre><code class=\"language-sql\">drop procedure if exists time_of_select;\n\ndelimiter #\ncreate procedure time_of_select(IN _max INTEGER, IN _step INTEGER)\nbegin\n    declare counter int unsigned DEFAULT 0;\n    declare temp_id int unsigned DEFAULT 0;\n    declare temp_value int unsigned DEFAULT 0;\n    declare time_id DECIMAL(10,6);\n    declare time_val DECIMAL(10,6);</code></pre><p>Zaczyna się jak wszystkie pozostałe - czyści dla siebie miejsce, ustawia znak nowej komendy na <code>#</code> wybiera sobie nazwę, argumenty i deklaruje zmienne lokalne. Argumenty to maksymalna wielkość tabeli dla jakiej chcemy testować, oraz krok jaki ma wykonywać nasz licznik. Zmienne lokalne służą do iteracji - <code>counter</code>, zapobiegają wyświetlaniu nie potrzebnych danych <code>temp_id</code> i <code>temp_value</code>, oraz przechowują wyniki pomiarów czasu - <code>time_id</code> i <code>time_val</code>. Następnie jest czyszczenie tabel.</p><pre><code class=\"language-sql\">    truncate table result;\n    call load_data(0);</code></pre><p>Zauważ, że <code>call load_data(0)</code> jest równoważne komendzie <code>truncate table main</code>. Po wyczyszczeniu wszystkich danych możemy zacząć przebieganie pętli</p><pre><code class=\"language-sql\">    while counter &lt; _max do\n        set counter=counter+_step;\n        call add_data(counter);</code></pre><p>Podnosimy licznik i dodajemy wiersze do tabeli <code>main</code>.</p><pre><code class=\"language-sql\">        truncate performance_schema.events_statements_history_long;\n        RESET QUERY CACHE;</code></pre><p>Czyścimy historię pomiarów wydajności i resetujemy cache.</p><pre><code class=\"language-sql\">        select * INTO temp_id, temp_value from main WHERE id=counter;\n        select * INTO temp_id, temp_value from main WHERE value=counter;</code></pre><p>Wykonujemy selekty które chcemy testować. Żeby nie zaśmiecały nam ekranu przekierowujemy je do lokalnych zmiennych, z którymi już nic nie będziemy robić. Teraz najciekawsza część - mierzenie wydajności:</p><pre><code class=\"language-sql\">        SELECT TRUNCATE(TIMER_WAIT/1000000000000,6) INTO time_id\n             FROM performance_schema.events_statements_history_long WHERE SQL_TEXT like '%id=%';\n        SELECT TRUNCATE(TIMER_WAIT/1000000000000,6) INTO time_val\n             FROM performance_schema.events_statements_history_long WHERE SQL_TEXT like '%value=%';</code></pre><p>Jest to nowa <a href=\"http://dev.mysql.com/doc/refman/5.6/en/performance-schema-query-profiling.html\">zalecana</a> metoda na mierzenie wydajności ponieważ <code>SET profiling = 1;</code> jest już <a href=\"http://stackoverflow.com/questions/11274892/measuring-actual-mysql-query-time\">zdeprecjonowany</a>. Mając wszystkie potrzebne parametry dopisujemy je do tabeli <code>result</code>, wyświetlamy je i kończymy definiowanie procedury w standardowy sposób.</p><pre><code class=\"language-sql\">        INSERT INTO result (counter, time_id, time_val) VALUES (counter,time_id,time_val);\n\n        SELECT counter/_max \"state\", counter, time_id, time_val;\n    end while;\nend #\n\ndelimiter ;</code></pre><p>Dokładnie 4 godziny, 40 minut zajęło mi wykonanie procedury <code>call time_of_select(25000000,10000)</code>, czyli wykonywanie pomiarów dla tabeli o rozmiarach od 10 tysięcy do 25 milionów rekordów z krokiem 10 tysięcy.</p><h3 id=\"testowanie-silnika-memory\">Testowanie silnika MEMORY</h3><p>Żeby móc wrócić do tych danych i bez żadnych zmian w kodzie procedur wykonać pomiar na tabeli trzymanej w pamięci RAM przepiszemy nasze wyniki do nowej tabeli.</p><pre><code class=\"language-sql\">CREATE TABLE IF NOT EXISTS innoDB_result (\n  counter INTEGER PRIMARY KEY,\n  time_id DECIMAL(10,6),\n  time_val DECIMAL(10,6)\n) AS SELECT * FROM result LIMIT 2500;\n\n</code></pre><p>Oraz postawimy naszą tabelę <code>result</code> od nowa tym razem w pamięci RAM.</p><pre><code class=\"language-sql\">DROP TABLE main;\n\nCREATE TABLE main(\n  id INTEGER UNIQUE NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  value INTEGER\n) ENGINE=MEMORY;</code></pre><p>Jeśli w tym momencie włączyli byśmy procedurę testującą, to po 8 sekundach dostali byśmy następujący błąd:</p><pre><code>ERROR 1114 (HY000): The table 'main' is full</code></pre><p>Jest tak dlatego, że domyślnie <code>MySQL</code> ma ustawiony rozmiar tabel w pamięci <code>RAM</code> na 16 MB.  Możemy to sprawdzić wpisując</p><pre><code>SELECT max_heap_table_size;</code></pre><p>Zmienimy go komendą:</p><pre><code class=\"language-sql\">SET max_heap_table_size = 2048*1024*1024;</code></pre><p>Która na wszelki wypadek ustawi 2 GB RAM dla bazy danych. I tu pojawia się pytanie, skąd wziąłem akurat 2 GB. Szczerze przyznam, że nie wiedziałem w momencie pisania tego artykułu. Ta tabela na dysku zajmowała u mnie 930.72 MB, więc myślałem, że w 1 GB RAM powinna się zmieścić, ale okazało się, że po zapisaniu w pamięci operacyjnej jej rozmiar to aż 1538.54 MB. Zadałem na ten temat pytanie na <a href=\"http://dba.stackexchange.com/questions/157525/difference-between-size-of-table-saved-on-hard-drive-or-in-ram-how-to-calculate\">stacku</a>. Okazało się, że <code>InnoDB</code> przechowuje dane w <code>BTree</code> a <code>MEMORY</code> w <code>Hash</code>, co znacząco obniża możliwość kompresji kluczy w tabeli trzymanej w pamięci RAM. Teraz testy powinny pójść gładko. Możemy ponownie uruchomić procedurę do testowania.</p><pre><code>call time_of_select(25000000,10000)</code></pre><p>Tym razem test trwał 46 minut.</p><p>Tabela <code>main</code> nie będzie nas już interesować. Aby zwolnić pamięć możemy ją usunąć.</p><pre><code class=\"language-sql\">DROP TABLE main;</code></pre><p>Po tych operacjach mamy następującą sytuację: w bazie zostały dwie tabele z wynikami <code>innoDB_result</code> dla silnika <code>innoDB</code> oraz <code>result</code> dla silnika <code>MEMORY</code>. Do ich analizy nie będziemy wykorzystywać już MqSQL. Możemy zamknąć połączenie z bazą.</p><h2 id=\"analiza-wynik%C3%B3w\">Analiza wyników</h2><p>Do analizy danych wykorzystamy program <code>Mathematica</code> firmy <code>Wolfram Research</code>. Z tego programu można korzystać na dwa sposoby - pisząc w notebookach (coś jak brudnopis) i pisząc paczki oraz skrypty wykonywalne z konsoli. Paczki i skrypty są to czyste pliki tekstowe, które nadają się do trzymania w repozytorium. Notebooki niestety <a href=\"http://mathematica.stackexchange.com/questions/26174/recommended-settings-for-git-when-using-with-mathematica-projects\">nie</a>. Notebooki nadają się do rozbudowy kodu i liczenia czegoś, co ma zostać policzone jeden raz, a paczki i skrypty do wielokrotnego użytku i automatyzacji. W naszym przypadku odpowiednim narzędziem będzie notebook. Zaczynamy więc pisanie w nowym notebooku.</p><h3 id=\"wizualizacja-danych-z-bazy\">Wizualizacja danych z bazy</h3><p>Aby połączyć się z bazą danych importujemy odpowiednią paczkę.</p><pre><code>Needs[\"DatabaseLink`\"]</code></pre><p>I ustawiamy zmienną zawierającą połączenie</p><pre><code>conn = OpenSQLConnection[\n  JDBC[\"MySQL(Connector/J)\", \"127.0.0.1:3306/test\"],\n  \"Username\" -&gt; \"root\", \"Password\" -&gt; \"\"]</code></pre><p>Wyciągamy z bazy interesujące nas dane.</p><pre><code>counterTimeIdInnoDB = SQLExecute[conn, \"SELECT counter, time_id FROM innoDB_result\"];\ncounterTimeValInnoDB = SQLExecute[conn, \"SELECT counter, time_val FROM innoDB_result\"];\ncounterTimeIdMemory = SQLExecute[conn, \"SELECT counter, time_id FROM result\"];\ncounterTimeValMemory = SQLExecute[conn, \"SELECT counter, time_val FROM result\"];</code></pre><p>I od razu przechodzimy do rysowania wykresu.</p><pre><code>ListPlot[{counterTimeIdInnoDB, counterTimeIdMemory},\n PlotLabel -&gt;\n  \"Time of SELECT using PRIMARY KEY for InnoDB and MEMORY engines for \\\ndifferent number of rows.\",\n PlotLegends -&gt;\n  Placed[SwatchLegend[{\"InnoDB\", \"MEMORY\"},\n    LegendMarkerSize -&gt; {30, 30}], {0.5, 0.25}],\n AxesLabel -&gt; {\"Rows\", \"Time[s]\"} , BaseStyle -&gt; {FontSize -&gt; 14},\n ImageSize -&gt; 1200]\nExport[\"plotId.png\", %];</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/plotId.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1537\" height=\"951\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/plotId.png 600w, __GHOST_URL__/content/images/size/w1000/2021/06/plotId.png 1000w, __GHOST_URL__/content/images/2021/06/plotId.png 1537w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Widzimy, że zarówno dla <code>InnoDB</code> jak i <code>MEMORY</code> szybkość wybierania po identyfikatorze nie zależy od ilości rekordów w bazie dla naszego zakresu. Na pewno nie jest to zależność, którą można by wyłowić z szumu, który jest tutaj obecny. Widać, że dla tabeli w pamięci operacyjnej selekty są wykonywane szybciej, a czas ich wykonywania jest bardziej regularny. Zupełnie inaczej sytuacja wygląda dla nie indeksowanych atrybutów.</p><pre><code>ListPlot[{counterTimeValInnoDB, counterTimeValMemory},\n PlotLabel -&gt;\n  \"Time of SELECT using not indexed attribute for InnoDB and MEMORY \\\nengines for different number of rows.\",\n PlotLegends -&gt;\n  Placed[SwatchLegend[{\"InnoDB\", \"MEMORY\"},\n    LegendMarkerSize -&gt; {30, 30}], {0.5, 0.25}],\n AxesLabel -&gt; {\"Rows\", \"Time[s]\"} , BaseStyle -&gt; {FontSize -&gt; 14},\n ImageSize -&gt; 1200]\nExport[\"plotVal.png\", %];</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/plotVal.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1537\" height=\"971\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/plotVal.png 600w, __GHOST_URL__/content/images/size/w1000/2021/06/plotVal.png 1000w, __GHOST_URL__/content/images/2021/06/plotVal.png 1537w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Czas wybierania nie indeksowanego atrybutu rośnie liniowo z wielkością bazy. Tu również tabela zapisana w pamięci operacyjnej działa szybciej.</p><p>Dzięki dopasowaniu prostej poleceniem <code>Fit[counterTimeValInnoDB, {x}, x]</code> widzimy, że współczynnik kierunkowy dla tabeli na dysku to <code>3.06e-7</code>, co oznacza, że na milion rekordów przypada 0.3 sekundy wyszukiwania. Obliczając współczynnik kierunkowy dla silnika <code>MEMORY</code> poleceniem <code>Fit[counterTimeValMemory, {x}, x]</code> otrzymamy <code>6.46e-8</code>, czyli 0.06 sekundy na milion rekordów, a więc 4.7 raza krócej.</p><h3 id=\"histogram\">Histogram</h3><p>Wróćmy do wybierania po kluczach. Ponieważ w tamtym przypadku zależność od czasu nie była widoczna, zredukujmy tą zmienną przyjrzyjmy się histogramowi przedstawiającemu liczbę zliczeń których czas wykonywania mieścił się w określonym przedziale. Za rysowanie odpowiada poniższy kod.</p><pre><code>timeIdInnoDB = Transpose[counterTimeIdInnoDB][[2]];\ntimeIdMemory = Transpose[counterTimeIdMemory][[2]];\nHistogram[{Flatten[timeIdInnoDB],\n  Flatten[timeIdMemory]}, {90, 180, 1}*10^-6,\n PlotLabel -&gt;\n  \"Histogram of times of select by PRIMARY KEY for different times \\\n(from 90\\[Mu]s to 180\\[Mu]s with step 1\\[Mu]s)\",\n AxesLabel -&gt; {\"Time[s]\", \"Count\"} ,\n ChartLegends -&gt;\n  Placed[SwatchLegend[{\"InnoDB\", \"MEMORY\"},\n    LegendMarkerSize -&gt; {30, 30}], {0.5, 0.75}],\n BaseStyle -&gt; {FontSize -&gt; 14},\n ChartStyle -&gt; ColorData[97, \"ColorList\"], ImageSize -&gt; 1200]\nExport[\"histogram.png\", %];</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/histogram.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1537\" height=\"942\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/histogram.png 600w, __GHOST_URL__/content/images/size/w1000/2021/06/histogram.png 1000w, __GHOST_URL__/content/images/2021/06/histogram.png 1537w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"model\">Model</h3><p>Nie znam wystarczająco dobrze mechanizmu odpowiadającego za ten rozkład. Jego znajomość pozwoliła by mi wybrać odpowiedni model matematyczny, który można by dopasować do danych. Z tego względu dalsza część to dopasowanie rozkładu, który tylko z grubsza przypomina ten rzeczywisty. Zaczynamy od wycięcia danych do dopasowywania modelu.</p><pre><code>dataInnoDB = Transpose[{Range[0.5, 299.5],\n    BinCounts[Flatten[timeIdInnoDB], {0, 300, 1}*10^-6]}];\ndataMemory = Transpose[{Range[0.5, 299.5],\n    BinCounts[Flatten[timeIdMemory], {0, 300, 1}*10^-6]}];</code></pre><p>Te tablice zawierają czas przeliczony na mikrosekundy oraz odpowiadające chwilom czasu liczby zliczeń. Przesunięcie o 0.5 wynika z tego, że punktowi 0.5 odpowiada przedział od 0 do 1. Następnie postulujemy model.</p><pre><code>model = c HeavisideTheta[x - a] (x - a)*Exp[-b (x - a)];</code></pre><p>Jak wspomniałem nie jest to model wywnioskowany z właściwości niskopoziomowej implementacji baz danych, a jedynie pierwszy prosty model jaki mi przyszedł do głowy. Kiedy mamy dane i model zostało tylko wyliczyć jego współczynniki. Odpowiadają za to linie:</p><pre><code>lineInnoDB =\n FindFit[dataInnoDB, model, { {a, 120}, {b, 0.2}, {c, 100} }, x]\nlineMemory =\n FindFit[dataMemory, model, { {a, 100}, {b, 0.8}, {c, 100} }, x]</code></pre><p>Współczynniki, które otrzymaliśmy to odpowiednio</p><pre><code>{a -&gt; 126.08, b -&gt; 0.212895, c -&gt; 102.94}</code></pre><p>dla <code>InnoDB</code> oraz</p><pre><code>{a -&gt; 99.4551, b -&gt; 0.836701, c -&gt; 1587.85}</code></pre><p>dla <code>MEMORY</code>. Pozostało tylko wyrysowanie wykresu porównującego dopasowane krzywe z danymi doświadczalnymi. Do łączenia wykresów różnych typów służy polecenie <code>Show</code>, jego składnia jest następująca:</p><pre><code>Show[ListPlot[{dataInnoDB, dataMemory}, Filling -&gt; Axis,\n  PlotRange -&gt; All, PlotMarkers -&gt; {\"\\[FilledCircle]\", 4},\n  PlotLegends -&gt;\n   Placed[SwatchLegend[{\"InnoDB\", \"MEMORY\"},\n     LegendMarkerSize -&gt; {30, 30}], {0.5, 0.75}]],\n Plot[{model /. lineInnoDB, model /. lineMemory}, {x, 0, 300},\n  PlotRange -&gt; All], AxesLabel -&gt; {\"Time[\\[Mu]s]\", \"Count\"},\n PlotLabel -&gt;\n  \"Histogram of times of selects execution with curves fitted for \\\nmodel c HeavisideTheta[x-a](x-a)*Exp[-b(x-a)]\",\n BaseStyle -&gt; {FontSize -&gt; 14}, ImageSize -&gt; 1200]\nExport[\"model.png\", %]</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/model.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1537\" height=\"954\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/model.png 600w, __GHOST_URL__/content/images/size/w1000/2021/06/model.png 1000w, __GHOST_URL__/content/images/2021/06/model.png 1537w\" sizes=\"(min-width: 720px) 720px\"></figure><p>To dopiero początek mojej przygody z bazami danych i wciąż temat ten jest znany mi tylko pobieżnie. Z tego względu wpisy dotyczące baz należy taktować bardziej jako notatki ucznia, niż wskazówki eksperta. Mimo to, mam nadzieję, że czas poświęcony na czytanie przełożył się u Ciebie na lepsze wyczucie ilościowych aspektów związanych z wydajnością indeksowania.</p><p>Na koniec dziękuję <a href=\"http://dba.stackexchange.com/users/1876/rick-james\">Rickowi Jamesowi</a> za odpowiedzi na praktycznie każde pytanie, jakie do tej pory zadałem na <a href=\"http://dba.stackexchange.com\">dba.stackexchange.com</a>.</p>",
            "comment_id": "607f36072fb35425592d0b71",
            "plaintext": "Wyszukiwanie po kluczu jest szybsze niż wyszukiwanie po zwykłym atrybucie. Nic\nodkrywczego. Jednak byłem ciekaw jakiego rzędu są to różnice. Przygotowałem\neksperyment.\n\nW tym artykule przedstawię porównanie szybkości wyszukiwania po kluczu głównym z\nwyszukiwaniem po nie indeksowanym atrybucie. Zobaczę jak na wydajność\nwyszukiwania wpływa przeniesienie tabeli do pamięci operacyjnej. Oraz\nprzeanalizuję wyniki za pomocą oprogramowania Mathematica.\n\nSkład kodu\n\n46% MySql 54% Mathematica\n\n\nBaza danych\nZaczniemy od standardowego nagłówka zapewniającego idempotentność. W MySql jest\nto dość proste\n\nDROP DATABASE IF EXISTS test;\nCREATE DATABASE IF NOT EXISTS test;\nUSE test;\n\n\nTworzymy jedną tabelę z kluczem oraz zwykłym atrybutem\n\nCREATE TABLE main(\n  id INTEGER UNIQUE NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  value INTEGER\n);\n\nProcedury zapisu danych\nDefiniujemy procedurę wypełniającą tabelę danymi\n\ndrop procedure if exists load_data;\n\ndelimiter #\ncreate procedure load_data(IN _max INTEGER)\nbegin\n\ndeclare counter int unsigned default 0;\n\n  truncate table main;\n  start transaction;\n  while counter < _max do\n    set counter=counter+1;\n    insert into main (value) values (counter);\n  end while;\n  commit;\nend #\n\ndelimiter ;\n\nNajpierw usunęliśmy procedurę o tej nazwie, jeśli już istniała. W kolejnej linii\nustawiliśmy znak końca komendy na #. Dzięki temu definiowanie procedury nie\nzostanie przerwane w środku przez występujące tam średniki. Naszą procedurę\nnazwaliśmy load_data i posiada ona jeden argument całkowitoliczbowy - liczbę\nwierszy jakimi wypełni tabelę. Linia zaczynająca się od declare odpowiada za\nustawienie zmiennej lokalnej przechowującą nasz licznik. Przed rozpoczęciem\ntransakcji czyścimy tabelę którą będziemy wypełniać. Wewnątrz transakcji\nwykonuje się pętla zapisująca do tabeli wartości od 1 do _max. Na końcu używamy\nznaku # jako średnika i przywracamy średnikowi jego domyślne znaczenia. Całkiem\nsporo kodu jak na tak prostą operację. Jednak zysk z tego jest taki, że teraz\nwystarczy wpisać np.:\n\ncall load_data(5);\n\na tabela wypełni się danymi zgodnie z naszymi oczekiwaniami\n\nSELECT * FROM main;\n+----+-------+\n| id | value |\n+----+-------+\n|  1 |     1 |\n|  2 |     2 |\n|  3 |     3 |\n|  4 |     4 |\n|  5 |     5 |\n+----+-------+\n5 rows in set (0,00 sec)\n\nTa procedura jest bardzo wygodna, bo pozwala ustawić dowolny rozmiar tabeli, ale\nponieważ będziemy testować duże tabele i często podnosić ich rozmiary dodamy\nbardziej ograniczoną, ale wydajniejszą w naszym przypadku procedurę, która nie\nusuwa tablicy, a zamiast tego dopełnia ją danymi do podanego rozmiaru.\n\ndrop procedure if exists add_data;\n\ndelimiter #\ncreate procedure add_data(IN _max INTEGER)\nbegin\n\ndeclare counter int unsigned;\nSELECT COUNT(*) INTO counter FROM main;\n\n  start transaction;\n  while counter < _max do\n    set counter=counter+1;\n    insert into main (value) values (counter);\n  end while;\n  commit;\nend #\n\ndelimiter ;\n\nNie ma tu już czyszczenia dotychczasowej zawartości tabeli. Counter nie\nprzyjmuje wartości domyślnej 0, za to użyliśmy instrukcji SELECT ... INTO ... \nktóra wynik selektu przypisuje do zmiennej.\n\nTeraz wykonanie call add_data(5) nie zmieni stanu naszej tabeli, ale po\nwykonaniu call add_data(10) rezultat będzie taki sam jak po call load_data(10) \ntyle, że oszczędziliśmy czas na usuwanie i wstawianie 5 wierszy, które już tam\nbyły.\n\nPerformance Schema\nZarówno w mysql jak i w mariadb do badania wydajności zapytań służy jest baza \nperformance_schema. Może się okazać, że jej używanie jest wyłączone. Sprawdzimy\nto dzięki zmiennej performance_schema. \n\nSELECT @@performance_schema;\n\nJeśli jest stawiona na wartość 0 należy w pliku konfiguracyjnym:\n\nsudo nvim /etc/my.cnf.d/server.cnf\n\ndodać linię:\n\nperformance_schema\n\nw sekcji:\n\n[mysqld]\n\nnastępnie zrestartować bazę danych poleceniem\n\nsudo systemctl restart mysql\n\nJeśli SELECT @@performance_schema; zwraca 1 oznacza to, że aktywowaliśmy ten\nmechanizm, ale nie jest to równoważne z możliwością wykonywaniem pomiarów,\nktórych potrzebujemy. Mechanizm zbierania logów może być bardzo rozbudowany i\nmusimy go skonfigurować samodzielnie ze względów wydajnościowych.\n\nNa przegląd aktualnych ustawień pozwolą nam zapytania o setup_consumers \n\nSELECT NAME,ENABLED FROM performance_schema.setup_consumers;\n\n+----------------------------------+---------+\n| NAME                             | ENABLED |\n+----------------------------------+---------+\n| events_stages_current            | NO      |\n| events_stages_history            | NO      |\n| events_stages_history_long       | NO      |\n| events_statements_current        | NO      |\n| events_statements_history        | NO      |\n| events_statements_history_long   | NO      |\n| events_transactions_current      | NO      |\n| events_transactions_history      | NO      |\n| events_transactions_history_long | NO      |\n| events_waits_current             | NO      |\n| events_waits_history             | NO      |\n| events_waits_history_long        | NO      |\n| global_instrumentation           | YES     |\n| thread_instrumentation           | YES     |\n| statements_digest                | YES     |\n+----------------------------------+---------+\n\noraz o instrumentacje z tabeli setup_instruments\n\nSELECT NAME,ENABLED,TIMED FROM performance_schema.setup_instruments;\n\nwyników jest bardzo dużo więc ograniczymy się do tych:\n\nSELECT NAME,ENABLED,TIMED FROM performance_schema.setup_instruments WHERE NAME LIKE '%long%';\n\n+------------------------------------------------------------------+---------+-------+\n| NAME                                                             | ENABLED | TIMED |\n+------------------------------------------------------------------+---------+-------+\n| statement/com/Long Data                                          | YES     | YES   |\n| memory/performance_schema/events_stages_history_long             | YES     | NO    |\n| memory/performance_schema/events_statements_history_long         | YES     | NO    |\n| memory/performance_schema/events_statements_history_long.tokens  | YES     | NO    |\n| memory/performance_schema/events_statements_history_long.sqltext | YES     | NO    |\n| memory/performance_schema/events_transactions_history_long       | YES     | NO    |\n| memory/performance_schema/events_waits_history_long              | YES     | NO    |\n+------------------------------------------------------------------+---------+-------+\n\n\nChcemy doprowadzić do sytuacji w której po wykonaniu zapytania:\n\nselect * from main WHERE value=5;\n\nodpytują o \n\nSELECT TIMER_WAIT FROM performance_schema.events_statements_history_long;\n\nzobaczymy zmierzony czas trwania ostatniego zapytania.\n\nAby to uzyskać włączymy konsumentów events_statements_history_long oraz \nevents_statements_current zapytaniem:\n\nUPDATE performance_schema.setup_consumers SET ENABLED = 'YES' WHERE NAME = 'events_statements_current' OR NAME = 'events_statements_history_long';\n\nTeraz dla zapytania:\n\nSELECT * FROM performance_schema.setup_consumers;\n\npowinniśmy zobaczyć:\n\n+----------------------------------+---------+\n| NAME                             | ENABLED |\n+----------------------------------+---------+\n| events_stages_current            | NO      |\n| events_stages_history            | NO      |\n| events_stages_history_long       | NO      |\n| events_statements_current        | YES     |\n| events_statements_history        | NO      |\n| events_statements_history_long   | YES     |\n| events_transactions_current      | NO      |\n| events_transactions_history      | NO      |\n| events_transactions_history_long | NO      |\n| events_waits_current             | NO      |\n| events_waits_history             | NO      |\n| events_waits_history_long        | NO      |\n| global_instrumentation           | YES     |\n| thread_instrumentation           | YES     |\n| statements_digest                | YES     |\n+----------------------------------+---------+\n\nA po wykonaniu\n\nuse test; SELECT * from main WHERE value=5;\n\na następnie\n\nSELECT SQL_TEXT,TIMER_WAIT FROM performance_schema.events_statements_history_long;\n\n\npowinniśmy zobaczyć czas trwania zapytania wyrażony w pikosekundach\n\nJeśli temat konfiguracji mechanizmu profilowania Cię zainteresował możesz\npogłębić wiedzę bezpośrednio w dokumentacji: \n\nPerformance Schema OverviewQuick overview of the Performance Schema.MariaDB\nKnowledgeBase [https://mariadb.com/kb/en/performance-schema-overview/]Procedura\ntestująca (InnoDB)\nWykonamy teraz testy. Interesują nas czasy wykonywania selektów po id oraz po \nvalue.\n\nselect * from main WHERE id=5;\nselect * from main WHERE value=5;\n\n\nPierwszy z nich nazwiemy time_id drugi time_val, liczbę wierszy nazwiemy counter\n. Wyniki testów będziemy chcieli później przetwarzać, dlatego stworzymy dla nich\nspecjalną tabelę.\n\nCREATE TABLE IF NOT EXISTS result (\n  counter INTEGER PRIMARY KEY,\n  time_id DECIMAL(10,6),\n  time_val DECIMAL(10,6)\n);\n\nZa jej wypełnianie odpowiedzialna będzie procedura, którą rozbijemy na kilka\nczęści. Oto jej początek.\n\ndrop procedure if exists time_of_select;\n\ndelimiter #\ncreate procedure time_of_select(IN _max INTEGER, IN _step INTEGER)\nbegin\n    declare counter int unsigned DEFAULT 0;\n    declare temp_id int unsigned DEFAULT 0;\n    declare temp_value int unsigned DEFAULT 0;\n    declare time_id DECIMAL(10,6);\n    declare time_val DECIMAL(10,6);\n\nZaczyna się jak wszystkie pozostałe - czyści dla siebie miejsce, ustawia znak\nnowej komendy na # wybiera sobie nazwę, argumenty i deklaruje zmienne lokalne.\nArgumenty to maksymalna wielkość tabeli dla jakiej chcemy testować, oraz krok\njaki ma wykonywać nasz licznik. Zmienne lokalne służą do iteracji - counter,\nzapobiegają wyświetlaniu nie potrzebnych danych temp_id i temp_value, oraz\nprzechowują wyniki pomiarów czasu - time_id i time_val. Następnie jest\nczyszczenie tabel.\n\n    truncate table result;\n    call load_data(0);\n\nZauważ, że call load_data(0) jest równoważne komendzie truncate table main. Po\nwyczyszczeniu wszystkich danych możemy zacząć przebieganie pętli\n\n    while counter < _max do\n        set counter=counter+_step;\n        call add_data(counter);\n\nPodnosimy licznik i dodajemy wiersze do tabeli main.\n\n        truncate performance_schema.events_statements_history_long;\n        RESET QUERY CACHE;\n\nCzyścimy historię pomiarów wydajności i resetujemy cache.\n\n        select * INTO temp_id, temp_value from main WHERE id=counter;\n        select * INTO temp_id, temp_value from main WHERE value=counter;\n\nWykonujemy selekty które chcemy testować. Żeby nie zaśmiecały nam ekranu\nprzekierowujemy je do lokalnych zmiennych, z którymi już nic nie będziemy robić.\nTeraz najciekawsza część - mierzenie wydajności:\n\n        SELECT TRUNCATE(TIMER_WAIT/1000000000000,6) INTO time_id\n             FROM performance_schema.events_statements_history_long WHERE SQL_TEXT like '%id=%';\n        SELECT TRUNCATE(TIMER_WAIT/1000000000000,6) INTO time_val\n             FROM performance_schema.events_statements_history_long WHERE SQL_TEXT like '%value=%';\n\nJest to nowa zalecana\n[http://dev.mysql.com/doc/refman/5.6/en/performance-schema-query-profiling.html] \nmetoda na mierzenie wydajności ponieważ SET profiling = 1; jest już \nzdeprecjonowany\n[http://stackoverflow.com/questions/11274892/measuring-actual-mysql-query-time].\nMając wszystkie potrzebne parametry dopisujemy je do tabeli result, wyświetlamy\nje i kończymy definiowanie procedury w standardowy sposób.\n\n        INSERT INTO result (counter, time_id, time_val) VALUES (counter,time_id,time_val);\n\n        SELECT counter/_max \"state\", counter, time_id, time_val;\n    end while;\nend #\n\ndelimiter ;\n\nDokładnie 4 godziny, 40 minut zajęło mi wykonanie procedury call\ntime_of_select(25000000,10000), czyli wykonywanie pomiarów dla tabeli o\nrozmiarach od 10 tysięcy do 25 milionów rekordów z krokiem 10 tysięcy.\n\nTestowanie silnika MEMORY\nŻeby móc wrócić do tych danych i bez żadnych zmian w kodzie procedur wykonać\npomiar na tabeli trzymanej w pamięci RAM przepiszemy nasze wyniki do nowej\ntabeli.\n\nCREATE TABLE IF NOT EXISTS innoDB_result (\n  counter INTEGER PRIMARY KEY,\n  time_id DECIMAL(10,6),\n  time_val DECIMAL(10,6)\n) AS SELECT * FROM result LIMIT 2500;\n\n\n\nOraz postawimy naszą tabelę result od nowa tym razem w pamięci RAM.\n\nDROP TABLE main;\n\nCREATE TABLE main(\n  id INTEGER UNIQUE NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  value INTEGER\n) ENGINE=MEMORY;\n\nJeśli w tym momencie włączyli byśmy procedurę testującą, to po 8 sekundach\ndostali byśmy następujący błąd:\n\nERROR 1114 (HY000): The table 'main' is full\n\nJest tak dlatego, że domyślnie MySQL ma ustawiony rozmiar tabel w pamięci RAM na\n16 MB.  Możemy to sprawdzić wpisując\n\nSELECT max_heap_table_size;\n\nZmienimy go komendą:\n\nSET max_heap_table_size = 2048*1024*1024;\n\nKtóra na wszelki wypadek ustawi 2 GB RAM dla bazy danych. I tu pojawia się\npytanie, skąd wziąłem akurat 2 GB. Szczerze przyznam, że nie wiedziałem w\nmomencie pisania tego artykułu. Ta tabela na dysku zajmowała u mnie 930.72 MB,\nwięc myślałem, że w 1 GB RAM powinna się zmieścić, ale okazało się, że po\nzapisaniu w pamięci operacyjnej jej rozmiar to aż 1538.54 MB. Zadałem na ten\ntemat pytanie na stacku\n[http://dba.stackexchange.com/questions/157525/difference-between-size-of-table-saved-on-hard-drive-or-in-ram-how-to-calculate]\n. Okazało się, że InnoDB przechowuje dane w BTree a MEMORY w Hash, co znacząco\nobniża możliwość kompresji kluczy w tabeli trzymanej w pamięci RAM. Teraz testy\npowinny pójść gładko. Możemy ponownie uruchomić procedurę do testowania.\n\ncall time_of_select(25000000,10000)\n\nTym razem test trwał 46 minut.\n\nTabela main nie będzie nas już interesować. Aby zwolnić pamięć możemy ją usunąć.\n\nDROP TABLE main;\n\nPo tych operacjach mamy następującą sytuację: w bazie zostały dwie tabele z\nwynikami innoDB_result dla silnika innoDB oraz result dla silnika MEMORY. Do ich\nanalizy nie będziemy wykorzystywać już MqSQL. Możemy zamknąć połączenie z bazą.\n\nAnaliza wyników\nDo analizy danych wykorzystamy program Mathematica firmy Wolfram Research. Z\ntego programu można korzystać na dwa sposoby - pisząc w notebookach (coś jak\nbrudnopis) i pisząc paczki oraz skrypty wykonywalne z konsoli. Paczki i skrypty\nsą to czyste pliki tekstowe, które nadają się do trzymania w repozytorium.\nNotebooki niestety nie\n[http://mathematica.stackexchange.com/questions/26174/recommended-settings-for-git-when-using-with-mathematica-projects]\n. Notebooki nadają się do rozbudowy kodu i liczenia czegoś, co ma zostać\npoliczone jeden raz, a paczki i skrypty do wielokrotnego użytku i automatyzacji.\nW naszym przypadku odpowiednim narzędziem będzie notebook. Zaczynamy więc\npisanie w nowym notebooku.\n\nWizualizacja danych z bazy\nAby połączyć się z bazą danych importujemy odpowiednią paczkę.\n\nNeeds[\"DatabaseLink`\"]\n\nI ustawiamy zmienną zawierającą połączenie\n\nconn = OpenSQLConnection[\n  JDBC[\"MySQL(Connector/J)\", \"127.0.0.1:3306/test\"],\n  \"Username\" -> \"root\", \"Password\" -> \"\"]\n\nWyciągamy z bazy interesujące nas dane.\n\ncounterTimeIdInnoDB = SQLExecute[conn, \"SELECT counter, time_id FROM innoDB_result\"];\ncounterTimeValInnoDB = SQLExecute[conn, \"SELECT counter, time_val FROM innoDB_result\"];\ncounterTimeIdMemory = SQLExecute[conn, \"SELECT counter, time_id FROM result\"];\ncounterTimeValMemory = SQLExecute[conn, \"SELECT counter, time_val FROM result\"];\n\nI od razu przechodzimy do rysowania wykresu.\n\nListPlot[{counterTimeIdInnoDB, counterTimeIdMemory},\n PlotLabel ->\n  \"Time of SELECT using PRIMARY KEY for InnoDB and MEMORY engines for \\\ndifferent number of rows.\",\n PlotLegends ->\n  Placed[SwatchLegend[{\"InnoDB\", \"MEMORY\"},\n    LegendMarkerSize -> {30, 30}], {0.5, 0.25}],\n AxesLabel -> {\"Rows\", \"Time[s]\"} , BaseStyle -> {FontSize -> 14},\n ImageSize -> 1200]\nExport[\"plotId.png\", %];\n\nWidzimy, że zarówno dla InnoDB jak i MEMORY szybkość wybierania po\nidentyfikatorze nie zależy od ilości rekordów w bazie dla naszego zakresu. Na\npewno nie jest to zależność, którą można by wyłowić z szumu, który jest tutaj\nobecny. Widać, że dla tabeli w pamięci operacyjnej selekty są wykonywane\nszybciej, a czas ich wykonywania jest bardziej regularny. Zupełnie inaczej\nsytuacja wygląda dla nie indeksowanych atrybutów.\n\nListPlot[{counterTimeValInnoDB, counterTimeValMemory},\n PlotLabel ->\n  \"Time of SELECT using not indexed attribute for InnoDB and MEMORY \\\nengines for different number of rows.\",\n PlotLegends ->\n  Placed[SwatchLegend[{\"InnoDB\", \"MEMORY\"},\n    LegendMarkerSize -> {30, 30}], {0.5, 0.25}],\n AxesLabel -> {\"Rows\", \"Time[s]\"} , BaseStyle -> {FontSize -> 14},\n ImageSize -> 1200]\nExport[\"plotVal.png\", %];\n\nCzas wybierania nie indeksowanego atrybutu rośnie liniowo z wielkością bazy. Tu\nrównież tabela zapisana w pamięci operacyjnej działa szybciej.\n\nDzięki dopasowaniu prostej poleceniem Fit[counterTimeValInnoDB, {x}, x] widzimy,\nże współczynnik kierunkowy dla tabeli na dysku to 3.06e-7, co oznacza, że na\nmilion rekordów przypada 0.3 sekundy wyszukiwania. Obliczając współczynnik\nkierunkowy dla silnika MEMORY poleceniem Fit[counterTimeValMemory, {x}, x] \notrzymamy 6.46e-8, czyli 0.06 sekundy na milion rekordów, a więc 4.7 raza\nkrócej.\n\nHistogram\nWróćmy do wybierania po kluczach. Ponieważ w tamtym przypadku zależność od czasu\nnie była widoczna, zredukujmy tą zmienną przyjrzyjmy się histogramowi\nprzedstawiającemu liczbę zliczeń których czas wykonywania mieścił się w\nokreślonym przedziale. Za rysowanie odpowiada poniższy kod.\n\ntimeIdInnoDB = Transpose[counterTimeIdInnoDB][[2]];\ntimeIdMemory = Transpose[counterTimeIdMemory][[2]];\nHistogram[{Flatten[timeIdInnoDB],\n  Flatten[timeIdMemory]}, {90, 180, 1}*10^-6,\n PlotLabel ->\n  \"Histogram of times of select by PRIMARY KEY for different times \\\n(from 90\\[Mu]s to 180\\[Mu]s with step 1\\[Mu]s)\",\n AxesLabel -> {\"Time[s]\", \"Count\"} ,\n ChartLegends ->\n  Placed[SwatchLegend[{\"InnoDB\", \"MEMORY\"},\n    LegendMarkerSize -> {30, 30}], {0.5, 0.75}],\n BaseStyle -> {FontSize -> 14},\n ChartStyle -> ColorData[97, \"ColorList\"], ImageSize -> 1200]\nExport[\"histogram.png\", %];\n\nModel\nNie znam wystarczająco dobrze mechanizmu odpowiadającego za ten rozkład. Jego\nznajomość pozwoliła by mi wybrać odpowiedni model matematyczny, który można by\ndopasować do danych. Z tego względu dalsza część to dopasowanie rozkładu, który\ntylko z grubsza przypomina ten rzeczywisty. Zaczynamy od wycięcia danych do\ndopasowywania modelu.\n\ndataInnoDB = Transpose[{Range[0.5, 299.5],\n    BinCounts[Flatten[timeIdInnoDB], {0, 300, 1}*10^-6]}];\ndataMemory = Transpose[{Range[0.5, 299.5],\n    BinCounts[Flatten[timeIdMemory], {0, 300, 1}*10^-6]}];\n\nTe tablice zawierają czas przeliczony na mikrosekundy oraz odpowiadające chwilom\nczasu liczby zliczeń. Przesunięcie o 0.5 wynika z tego, że punktowi 0.5\nodpowiada przedział od 0 do 1. Następnie postulujemy model.\n\nmodel = c HeavisideTheta[x - a] (x - a)*Exp[-b (x - a)];\n\nJak wspomniałem nie jest to model wywnioskowany z właściwości niskopoziomowej\nimplementacji baz danych, a jedynie pierwszy prosty model jaki mi przyszedł do\ngłowy. Kiedy mamy dane i model zostało tylko wyliczyć jego współczynniki.\nOdpowiadają za to linie:\n\nlineInnoDB =\n FindFit[dataInnoDB, model, { {a, 120}, {b, 0.2}, {c, 100} }, x]\nlineMemory =\n FindFit[dataMemory, model, { {a, 100}, {b, 0.8}, {c, 100} }, x]\n\nWspółczynniki, które otrzymaliśmy to odpowiednio\n\n{a -> 126.08, b -> 0.212895, c -> 102.94}\n\ndla InnoDB oraz\n\n{a -> 99.4551, b -> 0.836701, c -> 1587.85}\n\ndla MEMORY. Pozostało tylko wyrysowanie wykresu porównującego dopasowane krzywe\nz danymi doświadczalnymi. Do łączenia wykresów różnych typów służy polecenie \nShow, jego składnia jest następująca:\n\nShow[ListPlot[{dataInnoDB, dataMemory}, Filling -> Axis,\n  PlotRange -> All, PlotMarkers -> {\"\\[FilledCircle]\", 4},\n  PlotLegends ->\n   Placed[SwatchLegend[{\"InnoDB\", \"MEMORY\"},\n     LegendMarkerSize -> {30, 30}], {0.5, 0.75}]],\n Plot[{model /. lineInnoDB, model /. lineMemory}, {x, 0, 300},\n  PlotRange -> All], AxesLabel -> {\"Time[\\[Mu]s]\", \"Count\"},\n PlotLabel ->\n  \"Histogram of times of selects execution with curves fitted for \\\nmodel c HeavisideTheta[x-a](x-a)*Exp[-b(x-a)]\",\n BaseStyle -> {FontSize -> 14}, ImageSize -> 1200]\nExport[\"model.png\", %]\n\nTo dopiero początek mojej przygody z bazami danych i wciąż temat ten jest znany\nmi tylko pobieżnie. Z tego względu wpisy dotyczące baz należy taktować bardziej\njako notatki ucznia, niż wskazówki eksperta. Mimo to, mam nadzieję, że czas\npoświęcony na czytanie przełożył się u Ciebie na lepsze wyczucie ilościowych\naspektów związanych z wydajnością indeksowania.\n\nNa koniec dziękuję Rickowi Jamesowi\n[http://dba.stackexchange.com/users/1876/rick-james] za odpowiedzi na\npraktycznie każde pytanie, jakie do tej pory zadałem na dba.stackexchange.com\n[http://dba.stackexchange.com].",
            "feature_image": "__GHOST_URL__/content/images/2021/06/mysql-selectors-1.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:13:59.000Z",
            "updated_at": "2021-06-27T17:40:00.000Z",
            "published_at": "2021-06-27T17:40:00.000Z",
            "custom_excerpt": "Wszyscy wiemy, że stosowanie indeksów przyśpiesza wyszukiwanie i podnosi wielkość tabel spowalniając modyfikacje. Artykuł pokazuje jak profilować zapytania i mierzyć ilościowe aspekty wpływu indeksów na wydajność wyszukiwania.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f36b62fb35425592d0b7b",
            "uuid": "c99b2158-1a85-4514-9ec4-fd3d7917bd79",
            "title": "Analiza logów Apache z GoAccess",
            "slug": "analiza-logow-apache-z-goaccess",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}]],\"cards\":[[\"code\",{\"code\":\"PHP 32.9% HTML 22.6% JavaScript 20.5% Shell 18.5% CSS 5.5%\\n\"}],[\"embed\",{\"url\":\"https://youtu.be/VlZa0HlAIuw\",\"html\":\"<iframe width=\\\"200\\\" height=\\\"150\\\" src=\\\"https://www.youtube.com/embed/VlZa0HlAIuw?feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\",\"metadata\":{\"title\":\"Analiza logów Apache z GoAccess\",\"author_name\":\"gustawdaniel\",\"author_url\":\"https://www.youtube.com/user/gustawdaniel\",\"height\":150,\"width\":200,\"version\":\"1.0\",\"provider_name\":\"YouTube\",\"provider_url\":\"https://www.youtube.com/\",\"thumbnail_height\":360,\"thumbnail_width\":480,\"thumbnail_url\":\"https://i.ytimg.com/vi/VlZa0HlAIuw/hqdefault.jpg\"}}],[\"code\",{\"code\":\"echo \\\"deb http://deb.goaccess.io/ $(lsb_release -cs) main\\\" | sudo tee -a /etc/apt/sources.list.d/goaccess.list\\nwget -O - https://deb.goaccess.io/gnugpg.key | sudo apt-key add -\\nsudo apt-get update\\nsudo apt-get install goaccess\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"time-format %H:%M:%S\\ndate-format %d/%b/%Y\\nlog-format %h %^[%d:%t %^] \\\"%r\\\" %s %b \\\"%R\\\" \\\"%u\\\"\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"git clone https://github.com/gustawdaniel/Apache-Log-Analysis-Admin-Panel.git\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"config:\\n  apache: /var/log/apache2/*access.log\\n  report: report\\nsecurity:\\n  user: user\\n  pass: pass\\n  authorization: api\\n\",\"language\":\"yml\"}],[\"code\",{\"code\":\"bash install.sh\\n\"}],[\"code\",{\"code\":\"#!/usr/bin/env bash\\n\\nparse_yaml() {\\n   local prefix=$2\\n   local s='[[:space:]]*' w='[a-zA-Z0-9_]*' fs=$(echo @|tr @ '\\\\034')\\n   sed -ne \\\"s|^\\\\($s\\\\)\\\\($w\\\\)$s:$s\\\\\\\"\\\\(.*\\\\)\\\\\\\"$s\\\\$|\\\\1$fs\\\\2$fs\\\\3|p\\\" \\\\\\n        -e \\\"s|^\\\\($s\\\\)\\\\($w\\\\)$s:$s\\\\(.*\\\\)$s\\\\$|\\\\1$fs\\\\2$fs\\\\3|p\\\"  $1 |\\n   awk -F$fs '{\\n      indent = length($1)/2;\\n      vname[indent] = $2;\\n      for (i in vname) {if (i > indent) {delete vname[i]}}\\n      if (length($3) > 0) {\\n         vn=\\\"\\\"; for (i=0; i<indent; i++) {vn=(vn)(vname[i])(\\\"_\\\")}\\n         printf(\\\"%s%s%s=\\\\\\\"%s\\\\\\\"\\\\n\\\", \\\"'$prefix'\\\",vn, $2, $3);\\n      }\\n   }'\\n}\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"#!/usr/bin/env bash\\n\\n# include parse_yaml function\\n. lib/parse_yaml.sh\\n\\n# read yaml file\\neval $(parse_yaml config/parameters.yml \\\"parameters_\\\")\\n\\nmkdir -p $parameters_config_report $parameters_config_report/html $parameters_config_report/json\\n\\narr=();\\n\\n# loop over apache logs\\nfor file in $parameters_config_apache\\ndo\\n  out=$(basename \\\"$file\\\" .log)\\n  out=${out%_access}\\n\\n  if [ ! -s $file ];\\n  then\\n    continue;\\n  fi\\n\\n  echo \\\"Processed: \\\"$out;\\n  goaccess -f $file -a -o $parameters_config_report/html/$out.html;\\n  goaccess -f $file -a -o $parameters_config_report/json/$out.json;\\n\\n  arr+=($out);\\ndone\\n\\njq -n --arg inarr \\\"${arr[*]}\\\" '{ list: $inarr | split(\\\" \\\") }' > $parameters_config_report/list.json\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"apt-get install jq\\n\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"composer require symfony/yaml\\n\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"<?php\\n\\nrequire_once __DIR__.\\\"/../vendor/autoload.php\\\";\\nuse Symfony\\\\Component\\\\Yaml\\\\Yaml;\\n\\n$config = Yaml::parse(file_get_contents(__DIR__.'/../config/parameters.yml'));\\n\\nsession_start();\\n\\n$uri = explode('/', strtolower(substr($_SERVER['REQUEST_URI'], 1)));\\n$route = isset($uri[1]) ? $uri[1] : \\\"\\\";\\n$parameter = isset($uri[2]) ? $uri[2] : \\\"\\\";\\n\\n$data = array();\\n\\nheader(\\\"Access-Control-Allow-Origin: *\\\");\\nheader(\\\"Access-Control-Allow-Headers: Content-Type\\\");\\nheader(\\\"Access-Control-Allow-Methods: GET, POST\\\");\\nheader('Content-Type: application/json');\\n\\n\",\"language\":\"php?start_inline=1\"}],[\"code\",{\"code\":\"function returnError($code,$type,$message){\\n    $data[\\\"error\\\"] = [\\\"code\\\" => $code, \\\"type\\\" => $type, \\\"message\\\" => $message];\\n    echo json_encode($data);\\n    die();\\n}\\n\\n\",\"language\":\"php?start_inline=1\"}],[\"code\",{\"code\":\"switch ($route) {\\n        case \\\"login\\\": {\\n\\n            if(!isset($_POST[\\\"user\\\"]) || !isset($_POST[\\\"pass\\\"])) {\\n                returnError(400,\\\"Bad Request\\\",\\\"Invalid form\\\");\\n            } elseif($_POST[\\\"user\\\"]!=$config[\\\"security\\\"][\\\"user\\\"] || $_POST[\\\"pass\\\"]!=$config[\\\"security\\\"][\\\"pass\\\"]) {\\n                returnError(403,\\\"Forbidden\\\",\\\"Incorrect Login or Password\\\");\\n            }\\n\\n            $_SESSION['user'] = $config[\\\"security\\\"][\\\"user\\\"];\\n            $data = [\\\"state\\\" => \\\"loggedIn\\\"];\\n\\n        }\\n\\n\",\"language\":\"php?start_inline=1\"}],[\"code\",{\"code\":\"        case \\\"report\\\": {\\n\\n            if(\\n                (!isset($_SESSION['user'])\\n                    ||!$_SESSION['user'])\\n                &&(!isset(getallheaders()[\\\"Authorization\\\"])\\n                    ||getallheaders()[\\\"Authorization\\\"]!=$config[\\\"security\\\"][\\\"authorization\\\"]\\n                )\\n            ){\\n                returnError(403,\\\"Forbidden\\\",\\\"Incorrect Login or Password\\\");\\n            }\\n\\n\",\"language\":\"php?start_inline=1\"}],[\"code\",{\"code\":\"            $data[\\\"report\\\"] = [];\\n\\n            $list = json_decode(file_get_contents(__DIR__ . \\\"/../\\\" . $config[\\\"config\\\"][\\\"report\\\"] . \\\"/list.json\\\"));\\n\\n            foreach ($list->list as $key => $value) {\\n                $data[\\\"report\\\"][] = [\\\"name\\\" => $value, \\\"key\\\" => $key, \\\"link\\\" => \\\"api.php/report/\\\" . $value];\\n            };\\n\\n\",\"language\":\"php?start_inline=1\"}],[\"code\",{\"code\":\"            if ($parameter != \\\"\\\") {\\n                if (preg_match('/text\\\\/html/', $_SERVER[\\\"HTTP_ACCEPT\\\"])) {\\n                    header('Content-Type: text/html');\\n                    echo file_get_contents(__DIR__ . \\\"/../\\\" . $config[\\\"config\\\"][\\\"report\\\"] . \\\"/html/\\\" . $parameter . \\\".html\\\");\\n                } elseif (preg_match('/application\\\\/json|\\\\*\\\\/\\\\*/', $_SERVER[\\\"HTTP_ACCEPT\\\"])) {\\n                    header('Content-Type: application/json');\\n                    echo file_get_contents(__DIR__ . \\\"/../\\\" . $config[\\\"config\\\"][\\\"report\\\"] . \\\"/json/\\\" . $parameter . \\\".json\\\");\\n                } else {\\n                    returnError(415,\\\"Unsupported Media Type\\\",\\\"Incorrect Content Type\\\");\\n                }\\n                die();\\n            }\\n            break;\\n        }\\n\\n\",\"language\":\"php?start_inline=1\"}],[\"code\",{\"code\":\"        case \\\"logout\\\": {\\n            session_unset();\\n            session_destroy();\\n            $data = [\\\"state\\\" => \\\"loggedOut\\\"];\\n            break;\\n        }\\n\\n\",\"language\":\"php?start_inline=1\"}],[\"code\",{\"code\":\"        default: {\\n            returnError(404,\\\"Not Found\\\",\\\"Use route /report with Authorization header\\\");\\n            break;\\n        }\\n    }\\n\\necho json_encode($data);\\n\\n\",\"language\":\"php?start_inline=1\"}],[\"code\",{\"code\":\"http -v --pretty=all GET localhost:8000/api.php/report Authorization:api\\n\\n\",\"language\":\"bash\"}],[\"image\",{\"src\":\"http://i.imgur.com/PEjG18F.png\",\"alt\":\"api\",\"title\":\"\"}],[\"code\",{\"code\":\"http -v --pretty=all GET localhost:8000/api.php/report/api_brainjinn Authorization:api\\n\\n\",\"language\":\"bash\"}],[\"image\",{\"src\":\"http://i.imgur.com/8p3nHB7.png\",\"alt\":\"api2\",\"title\":\"\"}],[\"code\",{\"code\":\"{\\n  \\\"directory\\\": \\\"web/bower_components\\\"\\n}\\n\\n\",\"language\":\"json\"}],[\"code\",{\"code\":\"bower init\\nbower install --save bootstrap#v4.0.0-alpha.5\\nbower install --save mustache\\n\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"<!DOCTYPE html>\\n<html>\\n<head>\\n    <meta charset=\\\"UTF-8\\\">\\n    <title>Apache Log Analysis</title>\\n    <meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1.0, user-scalable=no\\\">\\n    <link rel=\\\"stylesheet\\\" href=\\\"bower_components/bootstrap/dist/css/bootstrap.min.css\\\">\\n    <link rel=\\\"stylesheet\\\" href=\\\"bower_components/tether/dist/css/tether.min.css\\\">\\n    <link href=\\\"https://fonts.googleapis.com/css?family=Lato:300&amp;subset=latin-ext\\\" rel=\\\"stylesheet\\\">\\n    <link rel=\\\"stylesheet\\\" href=\\\"css/style.css\\\">\\n</head>\\n<body>\\n\\n    <div id=\\\"content\\\"></div>\\n\\n\\n\\n    <script src=\\\"bower_components/jquery/dist/jquery.min.js\\\"></script>\\n    <script src=\\\"bower_components/tether/dist/js/tether.min.js\\\"></script>\\n    <script src=\\\"bower_components/bootstrap/dist/js/bootstrap.min.js\\\"></script>\\n    <script src=\\\"bower_components/mustache.js/mustache.min.js\\\"></script>\\n\\n    <script src=\\\"js/site.js\\\"></script>\\n\\n    <script>\\n        var url = \\\"/api.php/\\\";\\n    </script>\\n\\n    <script src=\\\"js/routing.js\\\"></script>\\n\\n</body>\\n\\n\",\"language\":\"html\"}],[\"code\",{\"code\":\"body {\\n    font-family: 'Lato', sans-serif;\\n}\\n.login-container {\\n    padding-top: 25vh;\\n}\\n.report-container {\\n    padding-top: 15vh;\\n}\\n.btn-login {\\n    background-color: #59B2E0;\\n    outline: none;\\n    color: #fff;\\n    font-size: 14px;\\n    height: auto;\\n    font-weight: normal;\\n    padding: 14px 0;\\n    text-transform: uppercase;\\n    border-color: #59B2E6;\\n}\\n.btn-login:hover,\\n.btn-login:focus {\\n    color: #fff;\\n    background-color: #53A3CD;\\n    border-color: #53A3CD;\\n}\\n.padding-b-10{\\n    padding-bottom: 10px;\\n}\\n\\n\",\"language\":\"css\"}],[\"code\",{\"code\":\"function getFormData($form){\\n    var unindexed_array = $form.serializeArray();\\n    var indexed_array = {};\\n\\n    $.map(unindexed_array, function(n, i){\\n        indexed_array[n['name']] = n['value'];\\n    });\\n\\n    return indexed_array;\\n}\\n\\n\",\"language\":\"js\"}],[\"code\",{\"code\":\"function deleteAllCookies() {\\n    var cookies = document.cookie.split(\\\";\\\");\\n\\n    for (var i = 0; i < cookies.length; i++) {\\n        var cookie = cookies[i];\\n        var eqPos = cookie.indexOf(\\\"=\\\");\\n        var name = eqPos > -1 ? cookie.substr(0, eqPos) : cookie;\\n        document.cookie = name + \\\"=;expires=Thu, 01 Jan 1970 00:00:00 GMT\\\";\\n    }\\n}\\n\\n\",\"language\":\"js\"}],[\"code\",{\"code\":\"function loadComponent(name,data){\\n    $.get(\\\"component/\\\"+name+\\\"/\\\"+name+\\\".html\\\").done(function(template){\\n        var html = Mustache.render(template, data);\\n        $(\\\"#content\\\").html(html);\\n        $.getScript(\\\"component/\\\"+name+\\\"/\\\"+name+\\\".js\\\")\\n    });\\n}\\n\\n\",\"language\":\"js\"}],[\"code\",{\"code\":\"$.get(url+\\\"report\\\").done(function(data){\\n    //console.log(data);\\n    if(data.hasOwnProperty('report')){\\n        loadComponent(\\\"report\\\",data);\\n    } else {\\n        loadComponent(\\\"login\\\",{});\\n    }\\n});\\n\\n\",\"language\":\"js\"}],[\"code\",{\"code\":\"<div class=\\\"container login-container\\\">\\n    <div class=\\\"row\\\">\\n        <div class=\\\"offset-lg-3 col-lg-6 col-md-12 col-sm-12 col-xs-12\\\">\\n            <div class=\\\"card card-block text-xs-center\\\">\\n                <h4 class=\\\"card-title\\\">Apache Log Analysis</h4>\\n                <div class=\\\"card-block\\\">\\n                    <form id=\\\"login-form\\\">\\n                        <div class=\\\"form-group\\\">\\n                            <input type=\\\"text\\\" name=\\\"user\\\" tabindex=\\\"1\\\" class=\\\"form-control\\\" placeholder=\\\"Username\\\" value=\\\"\\\">\\n                        </div>\\n                        <div class=\\\"form-group\\\">\\n                            <input type=\\\"password\\\" name=\\\"pass\\\" tabindex=\\\"2\\\" class=\\\"form-control\\\" placeholder=\\\"Password\\\">\\n                        </div>\\n                        <div class=\\\"form-group\\\">\\n                            <input type=\\\"submit\\\" name=\\\"login-submit\\\" id=\\\"login-submit\\\" tabindex=\\\"4\\\" class=\\\"form-control btn btn-login\\\" value=\\\"Log In\\\">\\n                        </div>\\n                    </form>\\n                    <div id=\\\"login-error\\\"></div>\\n                </div>\\n            </div>\\n        </div>\\n    </div>\\n</div>\\n\\n\",\"language\":\"html\"}],[\"image\",{\"src\":\"http://i.imgur.com/yRTGig4.png\",\"alt\":\"login\",\"title\":\"\"}],[\"code\",{\"code\":\"    var form = document.getElementById(\\\"login-form\\\");\\n    var error = document.getElementById(\\\"login-error\\\");\\n\\n\\n    form.addEventListener(\\\"submit\\\", function (e) {\\n        e.preventDefault();\\n        //console.log(JSON.stringify(getFormData($(this))));\\n        $.post(url + 'login', getFormData($(this))).done(function (data) {\\n            //console.log(\\\"s\\\",data);\\n            if (data.hasOwnProperty('error')) {\\n                //console.log(\\\"error_detected\\\");\\n                error.innerHTML = '<div class=\\\"alert alert-danger\\\">' + data.error.message + '</div>';\\n            } else if (data.hasOwnProperty('state')) {\\n                if (data.state == \\\"loggedIn\\\") {\\n                    loadComponent(\\\"report\\\", data);\\n                }\\n            }\\n        }).fail(function (data) {\\n            error.innerHTML = '<div class=\\\"alert alert-danger\\\">' + 'There are unidentified problems with service.' + '</div>';\\n            //console.log(data);\\n        });\\n        return false;\\n\\n    });\\n\\n\",\"language\":\"js\"}],[\"code\",{\"code\":\"<div class=\\\"container report-container\\\">\\n    <div class=\\\"row\\\">\\n        <div class=\\\"col-lg-12 col-md-12 col-sm-12 col-xs-12\\\">\\n            <div class=\\\"card card-block text-xs-center\\\">\\n                <h4 class=\\\"card-title\\\">Apache Log Analysis</h4>\\n                <div class=\\\"card-block\\\">\\n                    <ul class=\\\"list-group row\\\">\\n                        {{ \\\"{{ #report \\\" }}}}\\n                        <div class=\\\"col-sm-6 col-md-4 col-lg-3 padding-b-10\\\">\\n                        <a target=\\\"_blank\\\" href=\\\"{{link}}\\\" class=\\\"list-group-item \\\">{{ \\\"{{ #name \\\" }}}}</a>\\n                        </div>\\n                        {{ \\\"{{ /report \\\" }}}}\\n                    </ul>\\n                </div>\\n                <div class=\\\"card-block\\\">\\n                    <button id=\\\"logout\\\" class=\\\"btn btn-danger btn-block\\\">Logout</button>\\n                </div>\\n            </div>\\n        </div>\\n    </div>\\n</div>\\n\\n\",\"language\":\"html\"}],[\"image\",{\"src\":\"http://i.imgur.com/1Bb5BVf.png\",\"alt\":\"report\",\"title\":\"\"}],[\"code\",{\"code\":\"    var logout = document.getElementById(\\\"logout\\\");\\n\\n    logout.addEventListener(\\\"click\\\", function () {\\n        deleteAllCookies();\\n        $.get(url + \\\"logout\\\");\\n        loadComponent(\\\"login\\\", {});\\n    });\\n\\n\",\"language\":\"js\"}],[\"image\",{\"src\":\"http://i.imgur.com/n3sleEF.png\",\"alt\":\"log\",\"title\":\"\"}],[\"code\",{\"code\":\"git remote add live ssh://root@$ip_gs/var/repo/log_analysis\\n\\n\"}],[\"code\",{\"code\":\"mkdir -p /var/repo/log_analysis && cd /var/repo/log_analysis\\ngit init --bare\\n\\n\"}],[\"code\",{\"code\":\"#!/bin/sh\\nWORK_TREE=/var/www/log_analysis\\nGIT_DIR=/var/repo/log_analysis\\n\\ngit --work-tree=$WORK_TREE --git-dir=$GIT_DIR checkout -f\\nexit\\n\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"mkdir -p /var/www/log_analysis\\n\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"git push live master\\n\\n\"}],[\"code\",{\"code\":\"apt-get install jq\\ncomposer install\\nbower install\\nbash build.sh\\n\\n\"}],[\"code\",{\"code\":\"# log analysis\\nListen 8001\\n\\n\"}],[\"code\",{\"code\":\"<VirtualHost *:8001>\\n    DocumentRoot /var/www/log_analysis/web\\n\\n    ErrorLog /var/log/apache2/log_analysis_error.log\\n    CustomLog /var/log/apache2/log_analysis_access.log combined\\n</VirtualHost>\\n\\n\"}],[\"code\",{\"code\":\"a2ensite log_analysis.conf\\n\\n\"}],[\"code\",{\"code\":\"service apache2 reload\\n\\n\"}],[\"code\",{\"code\":\"#!/bin/bash\\n\\ncd /var/www/log_analysis/\\nbash build.sh\\n\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"chmod a+x /etc/cron.daily/log_analysis\\n\\n\",\"language\":\"bash\"}]],\"markups\":[[\"strong\"],[\"a\",[\"href\",\"https://goaccess.io/download\"]],[\"code\"],[\"a\",[\"href\",\"http://localhost:8000\"]],[\"a\",[\"href\",\"https://gist.github.com/pkuczynski/8665367\"]],[\"a\",[\"href\",\"http://blog.gustawdaniel.pl/2016/12/02/tesseract-ocr-i-testowanie-selekt%C3%B3w.html#kontekst\"]],[\"a\",[\"href\",\"https://www.digitalocean.com/community/tutorials/how-to-set-up-automatic-deployment-with-git-with-a-vps\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Kiedyś, usłyszałem od kolegi, że nie ma gorszego zajęcia, niż analiza logów Apache. Przeraziło mnie to bo myślałem, że to zmywanie naczyń jest najgorsze. Było to dość dawno i od tego czasu w moim życiu dużo zmieniło się na lepsze. Dzisiaj do zmywania używam zmywarki, a do analizy logów GoAccess.\"]]],[1,\"p\",[[0,[],0,\"W tym projekcie poznamy narzędzie pozwalające \"],[0,[0],1,\"wydobywać ciekawe informacje\"],[0,[],0,\" z plików generowanych automatycznie podczas pracy serwera. Napiszemy \"],[0,[0],1,\"panel \"],[0,[],0,\"udostępniający wyniki analizy logów. Na koniec dodamy do niego mechanizm \"],[0,[0],1,\"content negotiation\"],[0,[],0,\" czyli sposób na reprezentowanie tych samych obiektów za pomocą różnego typu danych.\"]]],[1,\"p\",[[0,[],0,\"Skład kodu\"]]],[10,0],[1,\"p\",[[0,[],0,\"Po napisaniu projekt będzie wyglądał tak:\"]]],[10,1],[1,\"h2\",[[0,[],0,\"Instalcja GoAccess\"]]],[1,\"p\",[[0,[],0,\"GoAccess jest przystosowany do działania na wielu systemach z różnymi rodzajami logów. Zakładam, że, mamy dystrybucję z repozytoriami Debiana/Ubuntu, serwer Apache2. W tym przypadku do \"],[0,[1],1,\"instalacji GoAccess\"],[0,[],0,\" posłużą nam komendy:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Konfiguracja polega na wycięciu komentarzy z pliku konfiguracyjnego \"],[0,[2],1,\"/etc/goaccess.conf\"],[0,[],0,\" przy liniach zawierających wpisy:\"]]],[10,3],[1,\"p\",[[0,[],0,\"Teraz należy pobrać repozytorium z gihuba\"]]],[10,4],[1,\"p\",[[0,[],0,\"Tworzymy naszą własną konfigurację do tego projektu. Jak zwykle posłużymy się plikiem \"],[0,[2],1,\"yml\"],[0,[],0,\".\"]]],[1,\"blockquote\",[[0,[],0,\"config/parameters.yml\"]]],[10,5],[1,\"p\",[[0,[],0,\"Własność \"],[0,[2],1,\"apache\"],[0,[],0,\" jest to zbiór wszystkich plików z logami dostępu do poszczególnych domen, które trzymamy na serwerze. Końcówka \"],[0,[2],1,\"access.log\"],[0,[],0,\" jest związana z przyjętą przeze mnie konwencją zgodnie z którą w konfiguracji domen przekierowuję wszystkie logi dostępu do plików \"],[0,[2],1,\"domain_access.log\"],[0,[],0,\". Natomiast \"],[0,[2],1,\"report\"],[0,[],0,\" jest to lokalizacja do której będziemy zapisywać wyniki parsowania.\"]]],[1,\"p\",[[0,[],0,\"Na koniec wykonujemy skrypt instalacyjny\"]]],[10,6],[1,\"p\",[[0,[],0,\"Projekt powinien być dostępny w przeglądarce pod adresem \"],[0,[3],1,\"localhost:8000\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Parsowanie logów\"]]],[1,\"p\",[[0,[],0,\"Naszym celem jest teraz wykorzystanie programu \"],[0,[2],1,\"GoAccess\"],[0,[],0,\" do przetworzenia wszystkich logów do postaci plików html.\"]]],[1,\"p\",[[0,[],0,\"Do odczytywania pliku konfiguracyjnego w bashu wykorzystamy funkcję napisaną przez \"],[0,[4],1,\"Piotra Kuczyńskiego\"],[0,[],0,\".\"]]],[1,\"blockquote\",[[0,[],0,\"lib/parse_yml.sh\"]]],[10,7],[1,\"p\",[[0,[],0,\"Ta funkcja przyjmuje dwa parametry, pierwszy to nazwa pliku do parsowania, drugi jest prefixem nazw nadawanych wewnątrz naszego skryptu parametrom wydobytym z pliku \"],[0,[2],1,\"yml\"],[0,[],0,\". Jej zastosowanie widzimy poniżej.\"]]],[10,8],[1,\"p\",[[0,[],0,\"W tym skrypcie kolejno: załączamy powyższą funkcję, wczytujemy konfigurację do zmiennych. Następnie tworzymy katalogi w których mają się znaleźć wyniki parsowania logów, inicjalizujemy tablicę i przebiegamy pętlę po wszystkich plikach z logami. W tej pętli wydobywamy nazwę bazową pliku. Jeśli ma w nazwie \"],[0,[2],1,\"_access\"],[0,[],0,\" to wycinamy, pomijamy puste pliki, wykonujemy na logach program goaccess który tworzy nam we wskazanym w konfiguracji katalogu pliki \"],[0,[2],1,\"html\"],[0,[],0,\" gotowe do wyświetlania. Na końcu dodajemy do tablicy przetworzoną nazwę pliku.\"]]],[1,\"p\",[[0,[],0,\"Po wykonaniu pętli konwertujemy listę przetworzonych nazw do formatu \"],[0,[2],1,\"json\"],[0,[],0,\" i zapisujemy razem z raportami. Dzięki tej liście nie będziemy musieli wykonywać pętli po katalogu w \"],[0,[2],1,\"php\"],[0,[],0,\". Zanim wykonamy ten skrypt, możliwe, że będziemy potrzebowali zainstalować jq. Jest to bardzo proste:\"]]],[10,9],[1,\"h2\",[[0,[],0,\"Backend\"]]],[1,\"p\",[[0,[],0,\"Logi mamy gotowe, teraz stworzymy API, które będzie je udostępniać. Nie chcemy trzymać ich w lokacji dostępnej z poziomu przeglądarki. Przeglądarka będzie miała dostęp tylko do katalogu \"],[0,[2],1,\"web\"],[0,[],0,\" i dlatego tam umieścimy plik \"],[0,[2],1,\"api.php\"],[0,[],0,\". Ponieważ będziemy potrzebowali dostępu do konfiguracji zainstalujemy jeszcze parser \"],[0,[2],1,\"yml\"],[0,[],0,\".\"]]],[10,10],[1,\"p\",[[0,[],0,\"Plik z API to przede wszystkim routing. Zaczyna się jednak od podłączenia paczek, ustawienia zmiennych i nagłówków:\"]]],[1,\"blockquote\",[[0,[],0,\"web/api.php\"]]],[10,11],[1,\"p\",[[0,[],0,\"Podpinanie konfiguracji w ten sposób \"],[0,[5],1,\"było już omawiane\"],[0,[],0,\". Nowością jest ustawianie sesji. Jest to na tyle sprytna funkcja, że tworzy u użytkownika plik cookie z losowym numerem sesji i jednocześnie ten numer zapisuje po stronie serwera, tak aby w zmiennej \"],[0,[2],1,\"$_SESSION\"],[0,[],0,\" można było odwoływać się do tej konkretnej ani nie sprawdzając cookie ręcznie, ani nie martwiąc się o to, że\"]]],[1,\"p\",[[0,[],0,\"Nowością jest cięcie adresu \"],[0,[2],1,\"uri\"],[0,[],0,\" na tablicę za pomocą znaków \"],[0,[2],1,\"/\"],[0,[],0,\". Pierwszy jej element będzie miał wartość \"],[0,[2],1,\"api.php\"],[0,[],0,\" dlatego wychwytujemy dwa kolejne jeśli istnieją. Ustawiamy sobie pustą tablicę \"],[0,[2],1,\"data\"],[0,[],0,\" i na koniec dodajemy nagłówki pozwalające ominąć problemy z CORS oraz ustawić domyślny typ zwracanych danych.\"]]],[1,\"p\",[[0,[],0,\"W Symfony istnieją specjalne klasy \"],[0,[2],1,\"Response\"],[0,[],0,\" i \"],[0,[2],1,\"JsonResponse\"],[0,[],0,\", które ułatwiają zwracanie odpowiedzi, tu jednak posłużymy się bardziej prymitywną metodą ze względu na jej prostotę. Zdefiniujemy funkcję do zwracania błędów.\"]]],[10,12],[1,\"p\",[[0,[],0,\"Warto zwrócić uwagę, że zwraca ona kody błędów, ale sama ma kod zawsze równy 200. Wyjątkiem będą błędy po stronie serwera, których nie przechwycę. Tylko w takim wypadku chcę zwracać kod błędu. Czas rozpocząć omawianie routingu. Zaczniemy od ścieżki do sprawdzania poprawności loginu. W \"],[0,[2],1,\"Symfony\"],[0,[],0,\" odpoiada jej nie \"],[0,[2],1,\"login\"],[0,[],0,\" ale \"],[0,[2],1,\"login_check\"],[0,[],0,\".\"]]],[10,13],[1,\"p\",[[0,[],0,\"Nasz switch przyjmuje do porównań ścieżkę wpisaną po \"],[0,[2],1,\"api.php/\"],[0,[],0,\" ale przed kolejnym znakiem \"],[0,[2],1,\"/\"],[0,[],0,\". W tej części kodu zajmujemy się przypadkiem kiedy adres zapytania zawierał \"],[0,[2],1,\"login\"],[0,[],0,\". Ponieważ do logowania używamy metody \"],[0,[2],1,\"$_POST\"],[0,[],0,\", kontroler na tej ścieżce sprawdza czy wysłano zmienne \"],[0,[2],1,\"user\"],[0,[],0,\" i \"],[0,[2],1,\"pass\"],[0,[],0,\", oraz czy są zgodne z tymi ustawionymi w konfiguracji. Jeśli sprawdzanie danych przebiegnie pomyślnie, zostanie utworzona zmienna \"],[0,[2],1,\"$_SESSION['user']\"],[0,[],0,\", a do listy danych odsyłanych w odpowiedzi zostanie dodany stan potwierdzający zalogowanie.\"]]],[1,\"p\",[[0,[],0,\"Zauważ, że na końcu nie dodałem instrukcji \"],[0,[2],1,\"break;\"],[0,[],0,\". Zrobiłem to celowo. Od razu po zalogowaniu bez wysyłania kolejnego requestu zawsze chcę dostawać listę domen, dla których Apache tworzy logi. Dlatego pod blokiem \"],[0,[2],1,\"login\"],[0,[],0,\" umieściłem blok \"],[0,[2],1,\"report\"],[0,[],0,\", który ma wykonać się zarówno po wybraniu ścieżki \"],[0,[2],1,\"report\"],[0,[],0,\" jak i po poprawnym zalogowaniu użytkownika. Jednak ponieważ chcę mieć dostęp do tej ścieżki przez \"],[0,[2],1,\"API\"],[0,[],0,\" z pominięciem logowania formularzem, przed wydobyciem potrzebnych danych sprawdzę prawo dostępu za pomocą następującego warunku:\"]]],[10,14],[1,\"p\",[[0,[],0,\"Poza sprawdzaniem, czy sesja jest ustawiona sprawdzamy tutaj też nagłówek \"],[0,[2],1,\"Authorization\"],[0,[],0,\" jako alternatywną metodę logowania. Jeśli przynajmniej jedna z metod logowania (sesja albo nagłówek) zostaną uznane za poprawne, wykona się następujący kod:\"]]],[10,15],[1,\"p\",[[0,[],0,\"Stworzyliśmy tu klucz \"],[0,[2],1,\"report\"],[0,[],0,\" do tablicy z odpowiedzią. Odczytaliśmy i zdekodowaliśmy listę nazw plików  z przetworzonymi logami apache wygenerowaną przez skrypt \"],[0,[2],1,\"build.sh\"],[0,[],0,\". Następnie w pętli rozbudowaliśmy strukturę każdego elementu tej listy o atrybuty \"],[0,[2],1,\"key\"],[0,[],0,\" i \"],[0,[2],1,\"link\"],[0,[],0,\", a samą nazwę przypisaliśmy do klucza \"],[0,[2],1,\"name\"],[0,[],0,\". Ta transformacja służy do łatwiejszego przetwarzania tych danych przez front-end który do tego napisaliśmy.\"]]],[1,\"p\",[[0,[],0,\"Jednak główną funkcjonalnością nie jest wyświetlanie samych nazw plików, tylko ich zawartości. To dobry moment aby zapoznać się z mechanizmem \"],[0,[2],1,\"content-negotiation\"],[0,[],0,\". Jest to sposób, aby w RESTowym API temu samemu adresowi \"],[0,[2],1,\"url\"],[0,[],0,\" przypisać reprezentację za pomocą różnego typu danych. W naszym przykładzie będą to \"],[0,[2],1,\"html\"],[0,[],0,\" i \"],[0,[2],1,\"json\"],[0,[],0,\". Typ danych jaki chcemy otrzymać ustawiamy na nagłówku \"],[0,[2],1,\"Accept\"],[0,[],0,\" przygotowując żądanie. Poniższy kod odpowiada za odpowiednią interpretację tego nagłówka.\"]]],[10,16],[1,\"p\",[[0,[],0,\"Wykona się on tylko jeśli \"],[0,[2],1,\"url\"],[0,[],0,\" będzie zawierał po \"],[0,[2],1,\"api.php/report/\"],[0,[],0,\" coś jeszcze. Ten ostatni kawałek zapisany był do zmiennej \"],[0,[2],1,\"$parameter\"],[0,[],0,\" na początku skryptu przy dzieleniu \"],[0,[2],1,\"uri\"],[0,[],0,\" na kawałki. Wskazuje on na to, który plik mamy wyciągnąć i za jego ustawianie odpowiedzialny jest klucz \"],[0,[2],1,\"link\"],[0,[],0,\" z tablicy \"],[0,[2],1,\"$data[\\\"report\\\"]\"],[0,[],0,\".  Funkcja \"],[0,[2],1,\"preg_match\"],[0,[],0,\" sprawdza czy wyrażenie regularne podane w pierwszym argumencie występuje w ciągu znaków z drugiego argumentu. I w zależności od tego czy dopasowano \"],[0,[2],1,\"text/html\"],[0,[],0,\" czy \"],[0,[2],1,\"application/json\"],[0,[],0,\" albo \"],[0,[2],1,\"*/*\"],[0,[],0,\" zwracany jest \"],[0,[2],1,\"html\"],[0,[],0,\" lub \"],[0,[2],1,\"json\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Ostatnią ścieżką obsługiwaną przez \"],[0,[2],1,\"api\"],[0,[],0,\" jest \"],[0,[2],1,\"logout\"],[0,[],0,\".\"]]],[10,17],[1,\"p\",[[0,[],0,\"Odpowiada on za usunięcie sesji i przypisanie stanu \"],[0,[2],1,\"loggedOut\"],[0,[],0,\". Na koniec obsługujemy wyjątek związany z nie poprawną ścieżką, w szczególności jest to też nasz punkt startowy \"],[0,[2],1,\"api.php/\"]]],[10,18],[1,\"p\",[[0,[],0,\"Po wykonaniu instrukcji \"],[0,[2],1,\"switch\"],[0,[],0,\" wysyłamy dane które zostały zebrane do tablicy \"],[0,[2],1,\"$data\"],[0,[],0,\" podczas przetwarzania żądania.\"]]],[1,\"h3\",[[0,[],0,\"Dostęp przez API\"]]],[1,\"p\",[[0,[],0,\"Aby uzyskać dostęp przez \"],[0,[2],1,\"API\"],[0,[],0,\" wystarczy wysłać następujący request:\"]]],[10,19],[10,20],[1,\"p\",[[0,[],0,\"Otrzymaliśmy listę dostępnych plików. Jeśli chcemy konkretny  plik wpisujemy:\"]]],[10,21],[10,22],[1,\"h2\",[[0,[],0,\"Frontend\"]]],[1,\"p\",[[0,[],0,\"Oddzielenie frontu od backednu od pewnego czasu bardzo mnie interesowało. Spodobały mi się sposoby patrzenia na uporządkowanie kodu w frameworkach takich jak \"],[0,[2],1,\"aurelia\"],[0,[],0,\" czy \"],[0,[2],1,\"angular\"],[0,[],0,\". Jednak bez przesady. Nie będziemy zaprzęgać armaty do zestrzeliwania muchy i nie skorzystamy tu z żadnego z nich.\"]]],[1,\"p\",[[0,[],0,\"Na mój front nałożyłem tylko jeden warunek - ma to być single page application obsługująca poprawnie logowanie i wylogowywanie. Zrezygnowałem też ze stosowania gulpa, ze względu na to, że była by to niepotrzebna komplikacja w tak małym projekcie.\"]]],[1,\"p\",[[0,[],0,\"Mimo to zastosowałem tutaj mechanizmy templatingu i bardzo prymitywny routing oparty na tanie odpowiedzi \"],[0,[2],1,\"api\"],[0,[],0,\" albo eventach a nie na samych fragmentach \"],[0,[2],1,\"url\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od instalacji zewnętrznych bibliotek do frontu. Będzie to \"],[0,[2],1,\"bootstrap 4\"],[0,[],0,\" oraz \"],[0,[2],1,\"mustache 2.3\"],[0,[],0,\". O ile pierwsza paczka powszechnie dobrze znana, o tyle z \"],[0,[2],1,\"mustache\"],[0,[],0,\" spotkałem się pierwszy raz. Jest to odpowiednik \"],[0,[2],1,\"twiga\"],[0,[],0,\" tylko wykonywany po stronie klienta a nie serwera. Zanim zaczniemy instalację stworzymy plik konfiguracyjny bowera:\"]]],[1,\"blockquote\",[[0,[],0,\".bowerrc\"]]],[10,23],[1,\"p\",[[0,[],0,\"Wskazuje on, żeby instalować bezpośrednio do katalogu \"],[0,[2],1,\"web\"],[0,[],0,\". Jest to związane z tym, że rezygnując z \"],[0,[2],1,\"gulpa\"],[0,[],0,\" chemy mieć gotowe do użycia paczki wystawione na zewnątrz. Przypominam, że przeglądarka ma dostęp tylko do katalogu \"],[0,[2],1,\"web\"],[0,[],0,\" w naszej strukturze projektu. Aby zainstalować paczki wykonujemy:\"]]],[10,24],[1,\"p\",[[0,[],0,\"Teraz przejdziemy do punktu wejściowego naszej aplikacji - pliku \"],[0,[2],1,\"index.html\"],[0,[],0,\".\"]]],[1,\"blockquote\",[[0,[],0,\"web/index.html\"]]],[10,25],[1,\"p\",[[0,[],0,\"Jego struktura przypomina trochę strukturę \"],[0,[2],1,\"index.html\"],[0,[],0,\" z Aurelii czy Angulara. Jest to praktycznie pusty \"],[0,[2],1,\"html\"],[0,[],0,\" z podpiętymi stylami, jednym divem służącym za punkt zaczepienia i następnie samymi skryptami. Jeśli chodzi o style, mamy tu \"],[0,[2],1,\"bootstrapa\"],[0,[],0,\", \"],[0,[2],1,\"tethera\"],[0,[],0,\" jako jego zależność, czcionka \"],[0,[2],1,\"Lato\"],[0,[],0,\", i nasze style. Później jest miejsce dla wspomnianego punktu zaczepienia. To w divie z \"],[0,[2],1,\"id=\\\"content\\\"\"],[0,[],0,\" będzie dynamicznie budowana nasza aplikacja. Jeśli chodzi o skrypty, to podpinamy \"],[0,[2],1,\"bootstrapa\"],[0,[],0,\" i \"],[0,[2],1,\"mustache\"],[0,[],0,\" wraz z zależnościami \"],[0,[2],1,\"bootstrapa\"],[0,[],0,\". Plik \"],[0,[2],1,\"site.js\"],[0,[],0,\" jest naszą biblioteką zawierającą często używane funkcje. Zmienna globalna \"],[0,[2],1,\"url\"],[0,[],0,\" została wyeksponowana w \"],[0,[2],1,\"index.html\"],[0,[],0,\" ponieważ dla tej jednej zmiennej nie opłacało się tworzyć oddzielnie środowiska produkcyjnego i developerskiego. Na końcu podpięty jest \"],[0,[2],1,\"routing.js\"],[0,[],0,\" który sprawdzając czy użytkownik jest zalogowany przekierowuje nas do strony logowania, albo wyświetlania lisy plików z logami.\"]]],[1,\"p\",[[0,[],0,\"Jednak o tym później, teraz przejrzymy załączniki z \"],[0,[2],1,\"index.html\"],[0,[],0,\" od góry na dół. Zaczniemy od stylów:\"]]],[1,\"blockquote\",[[0,[],0,\"web/css/style.css\"]]],[10,26],[1,\"p\",[[0,[],0,\"Style jak style. Nic specjalnego. Dodaliśmy czcionkę, \"],[0,[2],1,\"paddingi\"],[0,[],0,\" na główny \"],[0,[2],1,\"container\"],[0,[],0,\", customowy button do logowania i \"],[0,[2],1,\"padding\"],[0,[],0,\" na wyświetlanie listy plików z logami. Skrypty są ciekawsze, oto nasza biblioteka z przydatnymi funkcjami:\"]]],[1,\"blockquote\",[[0,[],0,\"web/js/site.js\"]]],[10,27],[1,\"p\",[[0,[],0,\"Pierwsza z nich służy do przekształcania formulaża do postaci formatu \"],[0,[2],1,\"json\"],[0,[],0,\" bardziej intuicyjnego niż to co oferuje \"],[0,[2],1,\"serializeArray\"],[0,[],0,\", a jednocześnie dużo bardziej eleganckiego niż to co robi \"],[0,[2],1,\"serialize\"],[0,[],0,\".\"]]],[10,28],[1,\"p\",[[0,[],0,\"Druga funkcja odpowiada za czyszczenie ciasteczek. Co ciekawe nie da się ich po prostu usunąć, ale da się ustawić datę ich wygaśnięcia na kilkadziesiąt lat temu.\"]]],[10,29],[1,\"p\",[[0,[],0,\"Ostatnia funkcja jest najbardziej dostosowana do naszej struktury katalogów i treści, więc zanim ją omówię wspomnę jeszcze o strukturze katalogów. Otuż w \"],[0,[2],1,\"web\"],[0,[],0,\" oprócz oczywistych \"],[0,[2],1,\"js\"],[0,[],0,\", \"],[0,[2],1,\"css\"],[0,[],0,\", \"],[0,[2],1,\"bower_components\"],[0,[],0,\" mamy też katalog \"],[0,[2],1,\"component\"],[0,[],0,\". Nazwa porzyczona od angulara wskazuje, że wewnątz znajdą się skrypty i szablony odpowiadające pewnej konkretnej funkcjonalności. Jest to poprawna intuicja i tak w \"],[0,[2],1,\"component\"],[0,[],0,\" mamy katalogi \"],[0,[2],1,\"login\"],[0,[],0,\" z plikami \"],[0,[2],1,\"login.html\"],[0,[],0,\" i \"],[0,[2],1,\"login.js\"],[0,[],0,\" oraz \"],[0,[2],1,\"report\"],[0,[],0,\" z plikami \"],[0,[2],1,\"report.html\"],[0,[],0,\" i \"],[0,[2],1,\"report.js\"],[0,[],0,\". Ta funkcja odpowiada za pobranie pliku \"],[0,[2],1,\"html\"],[0,[],0,\" z komponentu za pomocą metody \"],[0,[2],1,\"GET\"],[0,[],0,\", renderowanie go za pomocą biblioteki \"],[0,[2],1,\"mustache\"],[0,[],0,\" która wstawia do niego dane zawarte w zmiennej \"],[0,[2],1,\"data\"],[0,[],0,\". Następnie plik ten jest podpinany do naszego punktu zaczepienia w \"],[0,[2],1,\"index.html\"],[0,[],0,\" a kiedy to nastąpi zostają mu dostarczone skrypty. Mechanizm piękny dzięki swojej prostocie, a jest on sercem całego frontu. To dzięki tej metodzie front żyje i zmienia widoki bez przeładowywania strony.\"]]],[1,\"p\",[[0,[],0,\"Jednak ta funkcja nie wywoła się sama. Wspominałem o prymitywnym routingu. To on zarządza tym co zobaczymy kiedy strona zostanie załadowana:\"]]],[1,\"blockquote\",[[0,[],0,\"web/js/routing.js\"]]],[10,30],[1,\"h3\",[[0,[],0,\"Komponenty\"]]],[1,\"p\",[[0,[],0,\"Jego działanie polega na próbie pobrania zawartości zarezerwowanej dla zalogowanych użytkowników. Nie chciałem tu zwracać kodu błędu \"],[0,[2],1,\"403\"],[0,[],0,\", bo to tak naprawdę nie jest błąd. Jest całkiem normalne, że czasem nie jesteśmy zalogowani. Dzięki temu nawet jeśli użytkownik nie ma prawa dostępu do tych zasobów posługuję się metodą \"],[0,[2],1,\"done\"],[0,[],0,\". Oczywiście jeśli nie jesteśmy zalogowani, to odpowiedź nie będzie zawierała klucza \"],[0,[2],1,\"report\"],[0,[],0,\" tylko \"],[0,[2],1,\"error\"],[0,[],0,\". W tym przypadku zostanie załadowany \"],[0,[2],1,\"login\"],[0,[],0,\" z pustą tablicą danych. Jeśli jednak sesja jest stworzona i użytkownik jest zalogowany poprawnie ładujemy komponent \"],[0,[2],1,\"report\"],[0,[],0,\" i przekazujemy mu dane otrzymane od serwera.\"]]],[1,\"p\",[[0,[],0,\"Do omówienia zostały nam już tylko 4 pliki z komponentów. Zaczniemy od szablonu loginu:\"]]],[1,\"blockquote\",[[0,[],0,\"web/component/login/login.html\"]]],[10,31],[1,\"p\",[[0,[],0,\"Prosty formularz z dwoma polami i div na potencjalne błędy. Wygląda tak:\"]]],[10,32],[1,\"p\",[[0,[],0,\"Skrypt który go obsługuje jest podręcznikowym przykładem obsługi formulaża w js\"]]],[10,33],[1,\"p\",[[0,[],0,\"Namierzamy elementy. Dodajemy listener. Przy próbie wysłania wysyłamy \"],[0,[2],1,\"POST\"],[0,[],0,\" z treścią formulaża. Obsługa błędów \"],[0,[2],1,\"4xx\"],[0,[],0,\" jest tu w \"],[0,[2],1,\"done\"],[0,[],0,\" a nie \"],[0,[2],1,\"fail\"],[0,[],0,\". W przypadku sukcesu ładujemy \"],[0,[2],1,\"report\"],[0,[],0,\". Na koniec obsługujemy błędy \"],[0,[2],1,\"5xx\"],[0,[],0,\" przez \"],[0,[2],1,\"fail\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"W widoku raportu jest ciekawiej, bo tu \"],[0,[2],1,\"mustache\"],[0,[],0,\" robi pętlę.\"]]],[1,\"blockquote\",[[0,[],0,\"web/component/report/report.html\"]]],[10,34],[1,\"p\",[[0,[],0,\"Pętla po tablicy \"],[0,[2],1,\"report\"],[0,[],0,\" wyświetla wszystkie elementy listy podpinając do nich nazwy oraz linki. Dla moich logów wygląda to tak:\"]]],[10,35],[1,\"p\",[[0,[],0,\"Skrypt robi tu jedynie wylogowanie i dlatego jest dość któdki:\"]]],[1,\"blockquote\",[[0,[],0,\"web/component/report/report.js\"]]],[10,36],[1,\"p\",[[0,[],0,\"Na koniec podam jeszcze screen z przykładowej analizy logów. Jest to obraz jaki zobaczymy po wybraniu któregoś z listy plików z widoku \"],[0,[2],1,\"report\"],[0,[],0,\". W tym przypadku są to logi tego bloga.\"]]],[10,37],[1,\"h2\",[[0,[],0,\"Deployment\"]]],[1,\"p\",[[0,[],0,\"Bardzo lubianą przeze mnie, ale jeszcze nie opisywaną techniką wypuszczania projektu na produkcję jest użycie \"],[0,[6],1,\"gita\"],[0,[],0,\". Git pozwala nam przesłać jedynie istotne pliki, a zewnętrzne biblioteki możemy instalować sobie już z poziomu środowiska produkcyjnego. Aby to zadziałało musimy dodać lokalizację repozytorium na naszym serwerze do lokalnego zbioru repozytoriów zdalnych.\"]]],[1,\"p\",[[0,[],0,\"Zakładamy, że logujemy się na użytkownika nazwanego \"],[0,[2],1,\"root\"],[0,[],0,\" a \"],[0,[2],1,\"ip\"],[0,[],0,\" naszego serwera mamy w zmiennej \"],[0,[2],1,\"$ip_gs\"],[0,[],0,\". Repozytorium projektu na serwerze będzie trzymane w katalogu \"],[0,[2],1,\"/var/repo/log_analysis\"],[0,[],0,\".\"]]],[10,38],[1,\"p\",[[0,[],0,\"Na serwerze wykonujemy komendy:\"]]],[10,39],[1,\"p\",[[0,[],0,\"Następnie tworzymy plik \"],[0,[2],1,\"post-receive\"],[0,[],0,\" w katalogu \"],[0,[2],1,\"hooks\"],[0,[],0,\" i zapisujemy do niego poniższą treść:\"]]],[1,\"blockquote\",[[0,[],0,\"/var/repo/log_analysis/hooks/post-receive\"]]],[10,40],[1,\"p\",[[0,[],0,\"Na koniec nadajemy mu uprawnienia \"],[0,[2],1,\"chmod a+x post-receive\"],[0,[],0,\" i tworzymy katalog w którym mają się znaleźć pliki projektu.\"]]],[10,41],[1,\"p\",[[0,[],0,\"Wracamy na maszynę lokalną i wypychamy repozytorium do serwera.\"]]],[10,42],[1,\"p\",[[0,[],0,\"Wracamy na serwer i ustawiamy produkcyjną konfigurację w pliku \"],[0,[2],1,\"/var/www/log_analysis/config/parameters.yml\"],[0,[],0,\". Chodzi tutaj o to, żeby nie zostawić użytkownika \"],[0,[2],1,\"user\"],[0,[],0,\" z hasłem \"],[0,[2],1,\"pass\"],[0,[],0,\" na produkcji. Najprościej będzie skopiować plik \"],[0,[2],1,\"/var/www/log_analysis/config/parameters.yml.dist\"],[0,[],0,\" i pozmieniać wartości pod kluczem \"],[0,[2],1,\"security\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Instalacja polega na wykonaniu czterech poleceń:\"]]],[10,43],[1,\"p\",[[0,[],0,\"Teraz naszym zadaniem jest podpiąć web do którejś domeny albo portu. U nas będzie to port 8001. Dodamy więc nasłuch na tym porcie do Apache dodając odpowiednią linię do konfiguracji:\"]]],[1,\"blockquote\",[[0,[],0,\"/etc/apache2/ports.conf\"]]],[10,44],[1,\"p\",[[0,[],0,\"Do katalogu \"],[0,[2],1,\"sites-avaliable\"],[0,[],0,\" dodajemy plik:\"]]],[1,\"blockquote\",[[0,[],0,\"/etc/apache2/sites-avaliable/log_analysis.conf\"]]],[10,45],[1,\"p\",[[0,[],0,\"Linkujemy go symbolicznie z \"],[0,[2],1,\"sites-enabled\"],[0,[],0,\" za pomocą polecenia:\"]]],[10,46],[1,\"p\",[[0,[],0,\"Przeładowujemy apache\"]]],[10,47],[1,\"p\",[[0,[],0,\"Usługa powinna działać, ale chcieli zautomatyzować proces aktualizacji widoków przetworzonych logów.\"]]],[1,\"h3\",[[0,[],0,\"Cron\"]]],[1,\"p\",[[0,[],0,\"Są różne możliwe podejścia. Pierwsze to budować widoki przy każdej rozpoczynającej się sesji. Drugie - budować tylko ten widok o który w danym momencie pytamy. Trzecie to budować wszystkie widoki codziennie i nie męczyć użytkownika czekaniem.\"]]],[1,\"p\",[[0,[],0,\"Ponieważ aktualność logów z dokładnością co do godzin nie jest dla mnie większą wartością niż kilka sekund czekania na załadowanie się widoku zdecydowałem się na cykliczne tworzenie wszystkich widoków co jeden dzień.\"]]],[1,\"p\",[[0,[],0,\"Żeby to osiągnąć wystarczy stworzyć plik:\"]]],[1,\"blockquote\",[[0,[],0,\"/etc/cron.daily/log_analysis\"]]],[10,48],[1,\"p\",[[0,[],0,\"i nadać mu uprawnienia do wykonywania:\"]]],[10,49],[1,\"p\",[[0,[],0,\"Logi Apache są cennym źródłem informacji. Nie mają co prawda takich możliwości pomiarowych jak skrypty instalowane na stronie (mapy cieplne, czas aktywności, śledzenie\"],[1,[],0,0],[0,[],0,\"eventów), ale dzięki temu, że są zbierane automatycznie, można bez żadnego dodatkowego obciążania strony, po prostu je wykorzystać.\"]]],[1,\"p\",[[0,[],0,\"Daj znać w komentarzu, czy ten projekt znalazł zastosowanie u Ciebie, albo jeśli masz jakieś pomysły, gdzie można by go ulepszyć.\"]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Kiedyś, usłyszałem od kolegi, że nie ma gorszego zajęcia, niż analiza logów Apache. Przeraziło mnie to bo myślałem, że to zmywanie naczyń jest najgorsze. Było to dość dawno i od tego czasu w moim życiu dużo zmieniło się na lepsze. Dzisiaj do zmywania używam zmywarki, a do analizy logów GoAccess.</p><p>W tym projekcie poznamy narzędzie pozwalające <strong>wydobywać ciekawe informacje</strong> z plików generowanych automatycznie podczas pracy serwera. Napiszemy <strong>panel </strong>udostępniający wyniki analizy logów. Na koniec dodamy do niego mechanizm <strong>content negotiation</strong> czyli sposób na reprezentowanie tych samych obiektów za pomocą różnego typu danych.</p><p>Skład kodu</p><pre><code>PHP 32.9% HTML 22.6% JavaScript 20.5% Shell 18.5% CSS 5.5%\n</code></pre><p>Po napisaniu projekt będzie wyglądał tak:</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"150\" src=\"https://www.youtube.com/embed/VlZa0HlAIuw?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><h2 id=\"instalcja-goaccess\">Instalcja GoAccess</h2><p>GoAccess jest przystosowany do działania na wielu systemach z różnymi rodzajami logów. Zakładam, że, mamy dystrybucję z repozytoriami Debiana/Ubuntu, serwer Apache2. W tym przypadku do <a href=\"https://goaccess.io/download\">instalacji GoAccess</a> posłużą nam komendy:</p><pre><code class=\"language-bash\">echo \"deb http://deb.goaccess.io/ $(lsb_release -cs) main\" | sudo tee -a /etc/apt/sources.list.d/goaccess.list\nwget -O - https://deb.goaccess.io/gnugpg.key | sudo apt-key add -\nsudo apt-get update\nsudo apt-get install goaccess\n</code></pre><p>Konfiguracja polega na wycięciu komentarzy z pliku konfiguracyjnego <code>/etc/goaccess.conf</code> przy liniach zawierających wpisy:</p><pre><code class=\"language-bash\">time-format %H:%M:%S\ndate-format %d/%b/%Y\nlog-format %h %^[%d:%t %^] \"%r\" %s %b \"%R\" \"%u\"\n</code></pre><p>Teraz należy pobrać repozytorium z gihuba</p><pre><code class=\"language-bash\">git clone https://github.com/gustawdaniel/Apache-Log-Analysis-Admin-Panel.git\n</code></pre><p>Tworzymy naszą własną konfigurację do tego projektu. Jak zwykle posłużymy się plikiem <code>yml</code>.</p><blockquote>config/parameters.yml</blockquote><pre><code class=\"language-yml\">config:\n  apache: /var/log/apache2/*access.log\n  report: report\nsecurity:\n  user: user\n  pass: pass\n  authorization: api\n</code></pre><p>Własność <code>apache</code> jest to zbiór wszystkich plików z logami dostępu do poszczególnych domen, które trzymamy na serwerze. Końcówka <code>access.log</code> jest związana z przyjętą przeze mnie konwencją zgodnie z którą w konfiguracji domen przekierowuję wszystkie logi dostępu do plików <code>domain_access.log</code>. Natomiast <code>report</code> jest to lokalizacja do której będziemy zapisywać wyniki parsowania.</p><p>Na koniec wykonujemy skrypt instalacyjny</p><pre><code>bash install.sh\n</code></pre><p>Projekt powinien być dostępny w przeglądarce pod adresem <a href=\"http://localhost:8000\">localhost:8000</a>.</p><h2 id=\"parsowanie-log%C3%B3w\">Parsowanie logów</h2><p>Naszym celem jest teraz wykorzystanie programu <code>GoAccess</code> do przetworzenia wszystkich logów do postaci plików html.</p><p>Do odczytywania pliku konfiguracyjnego w bashu wykorzystamy funkcję napisaną przez <a href=\"https://gist.github.com/pkuczynski/8665367\">Piotra Kuczyńskiego</a>.</p><blockquote>lib/parse_yml.sh</blockquote><pre><code class=\"language-bash\">#!/usr/bin/env bash\n\nparse_yaml() {\n   local prefix=$2\n   local s='[[:space:]]*' w='[a-zA-Z0-9_]*' fs=$(echo @|tr @ '\\034')\n   sed -ne \"s|^\\($s\\)\\($w\\)$s:$s\\\"\\(.*\\)\\\"$s\\$|\\1$fs\\2$fs\\3|p\" \\\n        -e \"s|^\\($s\\)\\($w\\)$s:$s\\(.*\\)$s\\$|\\1$fs\\2$fs\\3|p\"  $1 |\n   awk -F$fs '{\n      indent = length($1)/2;\n      vname[indent] = $2;\n      for (i in vname) {if (i &gt; indent) {delete vname[i]}}\n      if (length($3) &gt; 0) {\n         vn=\"\"; for (i=0; i&lt;indent; i++) {vn=(vn)(vname[i])(\"_\")}\n         printf(\"%s%s%s=\\\"%s\\\"\\n\", \"'$prefix'\",vn, $2, $3);\n      }\n   }'\n}\n</code></pre><p>Ta funkcja przyjmuje dwa parametry, pierwszy to nazwa pliku do parsowania, drugi jest prefixem nazw nadawanych wewnątrz naszego skryptu parametrom wydobytym z pliku <code>yml</code>. Jej zastosowanie widzimy poniżej.</p><pre><code class=\"language-bash\">#!/usr/bin/env bash\n\n# include parse_yaml function\n. lib/parse_yaml.sh\n\n# read yaml file\neval $(parse_yaml config/parameters.yml \"parameters_\")\n\nmkdir -p $parameters_config_report $parameters_config_report/html $parameters_config_report/json\n\narr=();\n\n# loop over apache logs\nfor file in $parameters_config_apache\ndo\n  out=$(basename \"$file\" .log)\n  out=${out%_access}\n\n  if [ ! -s $file ];\n  then\n    continue;\n  fi\n\n  echo \"Processed: \"$out;\n  goaccess -f $file -a -o $parameters_config_report/html/$out.html;\n  goaccess -f $file -a -o $parameters_config_report/json/$out.json;\n\n  arr+=($out);\ndone\n\njq -n --arg inarr \"${arr[*]}\" '{ list: $inarr | split(\" \") }' &gt; $parameters_config_report/list.json\n</code></pre><p>W tym skrypcie kolejno: załączamy powyższą funkcję, wczytujemy konfigurację do zmiennych. Następnie tworzymy katalogi w których mają się znaleźć wyniki parsowania logów, inicjalizujemy tablicę i przebiegamy pętlę po wszystkich plikach z logami. W tej pętli wydobywamy nazwę bazową pliku. Jeśli ma w nazwie <code>_access</code> to wycinamy, pomijamy puste pliki, wykonujemy na logach program goaccess który tworzy nam we wskazanym w konfiguracji katalogu pliki <code>html</code> gotowe do wyświetlania. Na końcu dodajemy do tablicy przetworzoną nazwę pliku.</p><p>Po wykonaniu pętli konwertujemy listę przetworzonych nazw do formatu <code>json</code> i zapisujemy razem z raportami. Dzięki tej liście nie będziemy musieli wykonywać pętli po katalogu w <code>php</code>. Zanim wykonamy ten skrypt, możliwe, że będziemy potrzebowali zainstalować jq. Jest to bardzo proste:</p><pre><code class=\"language-bash\">apt-get install jq\n\n</code></pre><h2 id=\"backend\">Backend</h2><p>Logi mamy gotowe, teraz stworzymy API, które będzie je udostępniać. Nie chcemy trzymać ich w lokacji dostępnej z poziomu przeglądarki. Przeglądarka będzie miała dostęp tylko do katalogu <code>web</code> i dlatego tam umieścimy plik <code>api.php</code>. Ponieważ będziemy potrzebowali dostępu do konfiguracji zainstalujemy jeszcze parser <code>yml</code>.</p><pre><code class=\"language-bash\">composer require symfony/yaml\n\n</code></pre><p>Plik z API to przede wszystkim routing. Zaczyna się jednak od podłączenia paczek, ustawienia zmiennych i nagłówków:</p><blockquote>web/api.php</blockquote><pre><code class=\"language-php?start_inline=1\">&lt;?php\n\nrequire_once __DIR__.\"/../vendor/autoload.php\";\nuse Symfony\\Component\\Yaml\\Yaml;\n\n$config = Yaml::parse(file_get_contents(__DIR__.'/../config/parameters.yml'));\n\nsession_start();\n\n$uri = explode('/', strtolower(substr($_SERVER['REQUEST_URI'], 1)));\n$route = isset($uri[1]) ? $uri[1] : \"\";\n$parameter = isset($uri[2]) ? $uri[2] : \"\";\n\n$data = array();\n\nheader(\"Access-Control-Allow-Origin: *\");\nheader(\"Access-Control-Allow-Headers: Content-Type\");\nheader(\"Access-Control-Allow-Methods: GET, POST\");\nheader('Content-Type: application/json');\n\n</code></pre><p>Podpinanie konfiguracji w ten sposób <a href=\"http://blog.gustawdaniel.pl/2016/12/02/tesseract-ocr-i-testowanie-selekt%C3%B3w.html#kontekst\">było już omawiane</a>. Nowością jest ustawianie sesji. Jest to na tyle sprytna funkcja, że tworzy u użytkownika plik cookie z losowym numerem sesji i jednocześnie ten numer zapisuje po stronie serwera, tak aby w zmiennej <code>$_SESSION</code> można było odwoływać się do tej konkretnej ani nie sprawdzając cookie ręcznie, ani nie martwiąc się o to, że</p><p>Nowością jest cięcie adresu <code>uri</code> na tablicę za pomocą znaków <code>/</code>. Pierwszy jej element będzie miał wartość <code>api.php</code> dlatego wychwytujemy dwa kolejne jeśli istnieją. Ustawiamy sobie pustą tablicę <code>data</code> i na koniec dodajemy nagłówki pozwalające ominąć problemy z CORS oraz ustawić domyślny typ zwracanych danych.</p><p>W Symfony istnieją specjalne klasy <code>Response</code> i <code>JsonResponse</code>, które ułatwiają zwracanie odpowiedzi, tu jednak posłużymy się bardziej prymitywną metodą ze względu na jej prostotę. Zdefiniujemy funkcję do zwracania błędów.</p><pre><code class=\"language-php?start_inline=1\">function returnError($code,$type,$message){\n    $data[\"error\"] = [\"code\" =&gt; $code, \"type\" =&gt; $type, \"message\" =&gt; $message];\n    echo json_encode($data);\n    die();\n}\n\n</code></pre><p>Warto zwrócić uwagę, że zwraca ona kody błędów, ale sama ma kod zawsze równy 200. Wyjątkiem będą błędy po stronie serwera, których nie przechwycę. Tylko w takim wypadku chcę zwracać kod błędu. Czas rozpocząć omawianie routingu. Zaczniemy od ścieżki do sprawdzania poprawności loginu. W <code>Symfony</code> odpoiada jej nie <code>login</code> ale <code>login_check</code>.</p><pre><code class=\"language-php?start_inline=1\">switch ($route) {\n        case \"login\": {\n\n            if(!isset($_POST[\"user\"]) || !isset($_POST[\"pass\"])) {\n                returnError(400,\"Bad Request\",\"Invalid form\");\n            } elseif($_POST[\"user\"]!=$config[\"security\"][\"user\"] || $_POST[\"pass\"]!=$config[\"security\"][\"pass\"]) {\n                returnError(403,\"Forbidden\",\"Incorrect Login or Password\");\n            }\n\n            $_SESSION['user'] = $config[\"security\"][\"user\"];\n            $data = [\"state\" =&gt; \"loggedIn\"];\n\n        }\n\n</code></pre><p>Nasz switch przyjmuje do porównań ścieżkę wpisaną po <code>api.php/</code> ale przed kolejnym znakiem <code>/</code>. W tej części kodu zajmujemy się przypadkiem kiedy adres zapytania zawierał <code>login</code>. Ponieważ do logowania używamy metody <code>$_POST</code>, kontroler na tej ścieżce sprawdza czy wysłano zmienne <code>user</code> i <code>pass</code>, oraz czy są zgodne z tymi ustawionymi w konfiguracji. Jeśli sprawdzanie danych przebiegnie pomyślnie, zostanie utworzona zmienna <code>$_SESSION['user']</code>, a do listy danych odsyłanych w odpowiedzi zostanie dodany stan potwierdzający zalogowanie.</p><p>Zauważ, że na końcu nie dodałem instrukcji <code>break;</code>. Zrobiłem to celowo. Od razu po zalogowaniu bez wysyłania kolejnego requestu zawsze chcę dostawać listę domen, dla których Apache tworzy logi. Dlatego pod blokiem <code>login</code> umieściłem blok <code>report</code>, który ma wykonać się zarówno po wybraniu ścieżki <code>report</code> jak i po poprawnym zalogowaniu użytkownika. Jednak ponieważ chcę mieć dostęp do tej ścieżki przez <code>API</code> z pominięciem logowania formularzem, przed wydobyciem potrzebnych danych sprawdzę prawo dostępu za pomocą następującego warunku:</p><pre><code class=\"language-php?start_inline=1\">        case \"report\": {\n\n            if(\n                (!isset($_SESSION['user'])\n                    ||!$_SESSION['user'])\n                &amp;&amp;(!isset(getallheaders()[\"Authorization\"])\n                    ||getallheaders()[\"Authorization\"]!=$config[\"security\"][\"authorization\"]\n                )\n            ){\n                returnError(403,\"Forbidden\",\"Incorrect Login or Password\");\n            }\n\n</code></pre><p>Poza sprawdzaniem, czy sesja jest ustawiona sprawdzamy tutaj też nagłówek <code>Authorization</code> jako alternatywną metodę logowania. Jeśli przynajmniej jedna z metod logowania (sesja albo nagłówek) zostaną uznane za poprawne, wykona się następujący kod:</p><pre><code class=\"language-php?start_inline=1\">            $data[\"report\"] = [];\n\n            $list = json_decode(file_get_contents(__DIR__ . \"/../\" . $config[\"config\"][\"report\"] . \"/list.json\"));\n\n            foreach ($list-&gt;list as $key =&gt; $value) {\n                $data[\"report\"][] = [\"name\" =&gt; $value, \"key\" =&gt; $key, \"link\" =&gt; \"api.php/report/\" . $value];\n            };\n\n</code></pre><p>Stworzyliśmy tu klucz <code>report</code> do tablicy z odpowiedzią. Odczytaliśmy i zdekodowaliśmy listę nazw plików  z przetworzonymi logami apache wygenerowaną przez skrypt <code>build.sh</code>. Następnie w pętli rozbudowaliśmy strukturę każdego elementu tej listy o atrybuty <code>key</code> i <code>link</code>, a samą nazwę przypisaliśmy do klucza <code>name</code>. Ta transformacja służy do łatwiejszego przetwarzania tych danych przez front-end który do tego napisaliśmy.</p><p>Jednak główną funkcjonalnością nie jest wyświetlanie samych nazw plików, tylko ich zawartości. To dobry moment aby zapoznać się z mechanizmem <code>content-negotiation</code>. Jest to sposób, aby w RESTowym API temu samemu adresowi <code>url</code> przypisać reprezentację za pomocą różnego typu danych. W naszym przykładzie będą to <code>html</code> i <code>json</code>. Typ danych jaki chcemy otrzymać ustawiamy na nagłówku <code>Accept</code> przygotowując żądanie. Poniższy kod odpowiada za odpowiednią interpretację tego nagłówka.</p><pre><code class=\"language-php?start_inline=1\">            if ($parameter != \"\") {\n                if (preg_match('/text\\/html/', $_SERVER[\"HTTP_ACCEPT\"])) {\n                    header('Content-Type: text/html');\n                    echo file_get_contents(__DIR__ . \"/../\" . $config[\"config\"][\"report\"] . \"/html/\" . $parameter . \".html\");\n                } elseif (preg_match('/application\\/json|\\*\\/\\*/', $_SERVER[\"HTTP_ACCEPT\"])) {\n                    header('Content-Type: application/json');\n                    echo file_get_contents(__DIR__ . \"/../\" . $config[\"config\"][\"report\"] . \"/json/\" . $parameter . \".json\");\n                } else {\n                    returnError(415,\"Unsupported Media Type\",\"Incorrect Content Type\");\n                }\n                die();\n            }\n            break;\n        }\n\n</code></pre><p>Wykona się on tylko jeśli <code>url</code> będzie zawierał po <code>api.php/report/</code> coś jeszcze. Ten ostatni kawałek zapisany był do zmiennej <code>$parameter</code> na początku skryptu przy dzieleniu <code>uri</code> na kawałki. Wskazuje on na to, który plik mamy wyciągnąć i za jego ustawianie odpowiedzialny jest klucz <code>link</code> z tablicy <code>$data[\"report\"]</code>.  Funkcja <code>preg_match</code> sprawdza czy wyrażenie regularne podane w pierwszym argumencie występuje w ciągu znaków z drugiego argumentu. I w zależności od tego czy dopasowano <code>text/html</code> czy <code>application/json</code> albo <code>*/*</code> zwracany jest <code>html</code> lub <code>json</code>.</p><p>Ostatnią ścieżką obsługiwaną przez <code>api</code> jest <code>logout</code>.</p><pre><code class=\"language-php?start_inline=1\">        case \"logout\": {\n            session_unset();\n            session_destroy();\n            $data = [\"state\" =&gt; \"loggedOut\"];\n            break;\n        }\n\n</code></pre><p>Odpowiada on za usunięcie sesji i przypisanie stanu <code>loggedOut</code>. Na koniec obsługujemy wyjątek związany z nie poprawną ścieżką, w szczególności jest to też nasz punkt startowy <code>api.php/</code></p><pre><code class=\"language-php?start_inline=1\">        default: {\n            returnError(404,\"Not Found\",\"Use route /report with Authorization header\");\n            break;\n        }\n    }\n\necho json_encode($data);\n\n</code></pre><p>Po wykonaniu instrukcji <code>switch</code> wysyłamy dane które zostały zebrane do tablicy <code>$data</code> podczas przetwarzania żądania.</p><h3 id=\"dost%C4%99p-przez-api\">Dostęp przez API</h3><p>Aby uzyskać dostęp przez <code>API</code> wystarczy wysłać następujący request:</p><pre><code class=\"language-bash\">http -v --pretty=all GET localhost:8000/api.php/report Authorization:api\n\n</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"http://i.imgur.com/PEjG18F.png\" class=\"kg-image\" alt=\"api\" loading=\"lazy\"></figure><p>Otrzymaliśmy listę dostępnych plików. Jeśli chcemy konkretny  plik wpisujemy:</p><pre><code class=\"language-bash\">http -v --pretty=all GET localhost:8000/api.php/report/api_brainjinn Authorization:api\n\n</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"http://i.imgur.com/8p3nHB7.png\" class=\"kg-image\" alt=\"api2\" loading=\"lazy\"></figure><h2 id=\"frontend\">Frontend</h2><p>Oddzielenie frontu od backednu od pewnego czasu bardzo mnie interesowało. Spodobały mi się sposoby patrzenia na uporządkowanie kodu w frameworkach takich jak <code>aurelia</code> czy <code>angular</code>. Jednak bez przesady. Nie będziemy zaprzęgać armaty do zestrzeliwania muchy i nie skorzystamy tu z żadnego z nich.</p><p>Na mój front nałożyłem tylko jeden warunek - ma to być single page application obsługująca poprawnie logowanie i wylogowywanie. Zrezygnowałem też ze stosowania gulpa, ze względu na to, że była by to niepotrzebna komplikacja w tak małym projekcie.</p><p>Mimo to zastosowałem tutaj mechanizmy templatingu i bardzo prymitywny routing oparty na tanie odpowiedzi <code>api</code> albo eventach a nie na samych fragmentach <code>url</code>.</p><p>Zaczniemy od instalacji zewnętrznych bibliotek do frontu. Będzie to <code>bootstrap 4</code> oraz <code>mustache 2.3</code>. O ile pierwsza paczka powszechnie dobrze znana, o tyle z <code>mustache</code> spotkałem się pierwszy raz. Jest to odpowiednik <code>twiga</code> tylko wykonywany po stronie klienta a nie serwera. Zanim zaczniemy instalację stworzymy plik konfiguracyjny bowera:</p><blockquote>.bowerrc</blockquote><pre><code class=\"language-json\">{\n  \"directory\": \"web/bower_components\"\n}\n\n</code></pre><p>Wskazuje on, żeby instalować bezpośrednio do katalogu <code>web</code>. Jest to związane z tym, że rezygnując z <code>gulpa</code> chemy mieć gotowe do użycia paczki wystawione na zewnątrz. Przypominam, że przeglądarka ma dostęp tylko do katalogu <code>web</code> w naszej strukturze projektu. Aby zainstalować paczki wykonujemy:</p><pre><code class=\"language-bash\">bower init\nbower install --save bootstrap#v4.0.0-alpha.5\nbower install --save mustache\n\n</code></pre><p>Teraz przejdziemy do punktu wejściowego naszej aplikacji - pliku <code>index.html</code>.</p><blockquote>web/index.html</blockquote><pre><code class=\"language-html\">&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;Apache Log Analysis&lt;/title&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=no\"&gt;\n    &lt;link rel=\"stylesheet\" href=\"bower_components/bootstrap/dist/css/bootstrap.min.css\"&gt;\n    &lt;link rel=\"stylesheet\" href=\"bower_components/tether/dist/css/tether.min.css\"&gt;\n    &lt;link href=\"https://fonts.googleapis.com/css?family=Lato:300&amp;amp;subset=latin-ext\" rel=\"stylesheet\"&gt;\n    &lt;link rel=\"stylesheet\" href=\"css/style.css\"&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n    &lt;div id=\"content\"&gt;&lt;/div&gt;\n\n\n\n    &lt;script src=\"bower_components/jquery/dist/jquery.min.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"bower_components/tether/dist/js/tether.min.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"bower_components/bootstrap/dist/js/bootstrap.min.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"bower_components/mustache.js/mustache.min.js\"&gt;&lt;/script&gt;\n\n    &lt;script src=\"js/site.js\"&gt;&lt;/script&gt;\n\n    &lt;script&gt;\n        var url = \"/api.php/\";\n    &lt;/script&gt;\n\n    &lt;script src=\"js/routing.js\"&gt;&lt;/script&gt;\n\n&lt;/body&gt;\n\n</code></pre><p>Jego struktura przypomina trochę strukturę <code>index.html</code> z Aurelii czy Angulara. Jest to praktycznie pusty <code>html</code> z podpiętymi stylami, jednym divem służącym za punkt zaczepienia i następnie samymi skryptami. Jeśli chodzi o style, mamy tu <code>bootstrapa</code>, <code>tethera</code> jako jego zależność, czcionka <code>Lato</code>, i nasze style. Później jest miejsce dla wspomnianego punktu zaczepienia. To w divie z <code>id=\"content\"</code> będzie dynamicznie budowana nasza aplikacja. Jeśli chodzi o skrypty, to podpinamy <code>bootstrapa</code> i <code>mustache</code> wraz z zależnościami <code>bootstrapa</code>. Plik <code>site.js</code> jest naszą biblioteką zawierającą często używane funkcje. Zmienna globalna <code>url</code> została wyeksponowana w <code>index.html</code> ponieważ dla tej jednej zmiennej nie opłacało się tworzyć oddzielnie środowiska produkcyjnego i developerskiego. Na końcu podpięty jest <code>routing.js</code> który sprawdzając czy użytkownik jest zalogowany przekierowuje nas do strony logowania, albo wyświetlania lisy plików z logami.</p><p>Jednak o tym później, teraz przejrzymy załączniki z <code>index.html</code> od góry na dół. Zaczniemy od stylów:</p><blockquote>web/css/style.css</blockquote><pre><code class=\"language-css\">body {\n    font-family: 'Lato', sans-serif;\n}\n.login-container {\n    padding-top: 25vh;\n}\n.report-container {\n    padding-top: 15vh;\n}\n.btn-login {\n    background-color: #59B2E0;\n    outline: none;\n    color: #fff;\n    font-size: 14px;\n    height: auto;\n    font-weight: normal;\n    padding: 14px 0;\n    text-transform: uppercase;\n    border-color: #59B2E6;\n}\n.btn-login:hover,\n.btn-login:focus {\n    color: #fff;\n    background-color: #53A3CD;\n    border-color: #53A3CD;\n}\n.padding-b-10{\n    padding-bottom: 10px;\n}\n\n</code></pre><p>Style jak style. Nic specjalnego. Dodaliśmy czcionkę, <code>paddingi</code> na główny <code>container</code>, customowy button do logowania i <code>padding</code> na wyświetlanie listy plików z logami. Skrypty są ciekawsze, oto nasza biblioteka z przydatnymi funkcjami:</p><blockquote>web/js/site.js</blockquote><pre><code class=\"language-js\">function getFormData($form){\n    var unindexed_array = $form.serializeArray();\n    var indexed_array = {};\n\n    $.map(unindexed_array, function(n, i){\n        indexed_array[n['name']] = n['value'];\n    });\n\n    return indexed_array;\n}\n\n</code></pre><p>Pierwsza z nich służy do przekształcania formulaża do postaci formatu <code>json</code> bardziej intuicyjnego niż to co oferuje <code>serializeArray</code>, a jednocześnie dużo bardziej eleganckiego niż to co robi <code>serialize</code>.</p><pre><code class=\"language-js\">function deleteAllCookies() {\n    var cookies = document.cookie.split(\";\");\n\n    for (var i = 0; i &lt; cookies.length; i++) {\n        var cookie = cookies[i];\n        var eqPos = cookie.indexOf(\"=\");\n        var name = eqPos &gt; -1 ? cookie.substr(0, eqPos) : cookie;\n        document.cookie = name + \"=;expires=Thu, 01 Jan 1970 00:00:00 GMT\";\n    }\n}\n\n</code></pre><p>Druga funkcja odpowiada za czyszczenie ciasteczek. Co ciekawe nie da się ich po prostu usunąć, ale da się ustawić datę ich wygaśnięcia na kilkadziesiąt lat temu.</p><pre><code class=\"language-js\">function loadComponent(name,data){\n    $.get(\"component/\"+name+\"/\"+name+\".html\").done(function(template){\n        var html = Mustache.render(template, data);\n        $(\"#content\").html(html);\n        $.getScript(\"component/\"+name+\"/\"+name+\".js\")\n    });\n}\n\n</code></pre><p>Ostatnia funkcja jest najbardziej dostosowana do naszej struktury katalogów i treści, więc zanim ją omówię wspomnę jeszcze o strukturze katalogów. Otuż w <code>web</code> oprócz oczywistych <code>js</code>, <code>css</code>, <code>bower_components</code> mamy też katalog <code>component</code>. Nazwa porzyczona od angulara wskazuje, że wewnątz znajdą się skrypty i szablony odpowiadające pewnej konkretnej funkcjonalności. Jest to poprawna intuicja i tak w <code>component</code> mamy katalogi <code>login</code> z plikami <code>login.html</code> i <code>login.js</code> oraz <code>report</code> z plikami <code>report.html</code> i <code>report.js</code>. Ta funkcja odpowiada za pobranie pliku <code>html</code> z komponentu za pomocą metody <code>GET</code>, renderowanie go za pomocą biblioteki <code>mustache</code> która wstawia do niego dane zawarte w zmiennej <code>data</code>. Następnie plik ten jest podpinany do naszego punktu zaczepienia w <code>index.html</code> a kiedy to nastąpi zostają mu dostarczone skrypty. Mechanizm piękny dzięki swojej prostocie, a jest on sercem całego frontu. To dzięki tej metodzie front żyje i zmienia widoki bez przeładowywania strony.</p><p>Jednak ta funkcja nie wywoła się sama. Wspominałem o prymitywnym routingu. To on zarządza tym co zobaczymy kiedy strona zostanie załadowana:</p><blockquote>web/js/routing.js</blockquote><pre><code class=\"language-js\">$.get(url+\"report\").done(function(data){\n    //console.log(data);\n    if(data.hasOwnProperty('report')){\n        loadComponent(\"report\",data);\n    } else {\n        loadComponent(\"login\",{});\n    }\n});\n\n</code></pre><h3 id=\"komponenty\">Komponenty</h3><p>Jego działanie polega na próbie pobrania zawartości zarezerwowanej dla zalogowanych użytkowników. Nie chciałem tu zwracać kodu błędu <code>403</code>, bo to tak naprawdę nie jest błąd. Jest całkiem normalne, że czasem nie jesteśmy zalogowani. Dzięki temu nawet jeśli użytkownik nie ma prawa dostępu do tych zasobów posługuję się metodą <code>done</code>. Oczywiście jeśli nie jesteśmy zalogowani, to odpowiedź nie będzie zawierała klucza <code>report</code> tylko <code>error</code>. W tym przypadku zostanie załadowany <code>login</code> z pustą tablicą danych. Jeśli jednak sesja jest stworzona i użytkownik jest zalogowany poprawnie ładujemy komponent <code>report</code> i przekazujemy mu dane otrzymane od serwera.</p><p>Do omówienia zostały nam już tylko 4 pliki z komponentów. Zaczniemy od szablonu loginu:</p><blockquote>web/component/login/login.html</blockquote><pre><code class=\"language-html\">&lt;div class=\"container login-container\"&gt;\n    &lt;div class=\"row\"&gt;\n        &lt;div class=\"offset-lg-3 col-lg-6 col-md-12 col-sm-12 col-xs-12\"&gt;\n            &lt;div class=\"card card-block text-xs-center\"&gt;\n                &lt;h4 class=\"card-title\"&gt;Apache Log Analysis&lt;/h4&gt;\n                &lt;div class=\"card-block\"&gt;\n                    &lt;form id=\"login-form\"&gt;\n                        &lt;div class=\"form-group\"&gt;\n                            &lt;input type=\"text\" name=\"user\" tabindex=\"1\" class=\"form-control\" placeholder=\"Username\" value=\"\"&gt;\n                        &lt;/div&gt;\n                        &lt;div class=\"form-group\"&gt;\n                            &lt;input type=\"password\" name=\"pass\" tabindex=\"2\" class=\"form-control\" placeholder=\"Password\"&gt;\n                        &lt;/div&gt;\n                        &lt;div class=\"form-group\"&gt;\n                            &lt;input type=\"submit\" name=\"login-submit\" id=\"login-submit\" tabindex=\"4\" class=\"form-control btn btn-login\" value=\"Log In\"&gt;\n                        &lt;/div&gt;\n                    &lt;/form&gt;\n                    &lt;div id=\"login-error\"&gt;&lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n</code></pre><p>Prosty formularz z dwoma polami i div na potencjalne błędy. Wygląda tak:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://i.imgur.com/yRTGig4.png\" class=\"kg-image\" alt=\"login\" loading=\"lazy\"></figure><p>Skrypt który go obsługuje jest podręcznikowym przykładem obsługi formulaża w js</p><pre><code class=\"language-js\">    var form = document.getElementById(\"login-form\");\n    var error = document.getElementById(\"login-error\");\n\n\n    form.addEventListener(\"submit\", function (e) {\n        e.preventDefault();\n        //console.log(JSON.stringify(getFormData($(this))));\n        $.post(url + 'login', getFormData($(this))).done(function (data) {\n            //console.log(\"s\",data);\n            if (data.hasOwnProperty('error')) {\n                //console.log(\"error_detected\");\n                error.innerHTML = '&lt;div class=\"alert alert-danger\"&gt;' + data.error.message + '&lt;/div&gt;';\n            } else if (data.hasOwnProperty('state')) {\n                if (data.state == \"loggedIn\") {\n                    loadComponent(\"report\", data);\n                }\n            }\n        }).fail(function (data) {\n            error.innerHTML = '&lt;div class=\"alert alert-danger\"&gt;' + 'There are unidentified problems with service.' + '&lt;/div&gt;';\n            //console.log(data);\n        });\n        return false;\n\n    });\n\n</code></pre><p>Namierzamy elementy. Dodajemy listener. Przy próbie wysłania wysyłamy <code>POST</code> z treścią formulaża. Obsługa błędów <code>4xx</code> jest tu w <code>done</code> a nie <code>fail</code>. W przypadku sukcesu ładujemy <code>report</code>. Na koniec obsługujemy błędy <code>5xx</code> przez <code>fail</code>.</p><p>W widoku raportu jest ciekawiej, bo tu <code>mustache</code> robi pętlę.</p><blockquote>web/component/report/report.html</blockquote><pre><code class=\"language-html\">&lt;div class=\"container report-container\"&gt;\n    &lt;div class=\"row\"&gt;\n        &lt;div class=\"col-lg-12 col-md-12 col-sm-12 col-xs-12\"&gt;\n            &lt;div class=\"card card-block text-xs-center\"&gt;\n                &lt;h4 class=\"card-title\"&gt;Apache Log Analysis&lt;/h4&gt;\n                &lt;div class=\"card-block\"&gt;\n                    &lt;ul class=\"list-group row\"&gt;\n                        {{ \"{{ #report \" }}}}\n                        &lt;div class=\"col-sm-6 col-md-4 col-lg-3 padding-b-10\"&gt;\n                        &lt;a target=\"_blank\" href=\"{{link}}\" class=\"list-group-item \"&gt;{{ \"{{ #name \" }}}}&lt;/a&gt;\n                        &lt;/div&gt;\n                        {{ \"{{ /report \" }}}}\n                    &lt;/ul&gt;\n                &lt;/div&gt;\n                &lt;div class=\"card-block\"&gt;\n                    &lt;button id=\"logout\" class=\"btn btn-danger btn-block\"&gt;Logout&lt;/button&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n</code></pre><p>Pętla po tablicy <code>report</code> wyświetla wszystkie elementy listy podpinając do nich nazwy oraz linki. Dla moich logów wygląda to tak:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://i.imgur.com/1Bb5BVf.png\" class=\"kg-image\" alt=\"report\" loading=\"lazy\"></figure><p>Skrypt robi tu jedynie wylogowanie i dlatego jest dość któdki:</p><blockquote>web/component/report/report.js</blockquote><pre><code class=\"language-js\">    var logout = document.getElementById(\"logout\");\n\n    logout.addEventListener(\"click\", function () {\n        deleteAllCookies();\n        $.get(url + \"logout\");\n        loadComponent(\"login\", {});\n    });\n\n</code></pre><p>Na koniec podam jeszcze screen z przykładowej analizy logów. Jest to obraz jaki zobaczymy po wybraniu któregoś z listy plików z widoku <code>report</code>. W tym przypadku są to logi tego bloga.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://i.imgur.com/n3sleEF.png\" class=\"kg-image\" alt=\"log\" loading=\"lazy\"></figure><h2 id=\"deployment\">Deployment</h2><p>Bardzo lubianą przeze mnie, ale jeszcze nie opisywaną techniką wypuszczania projektu na produkcję jest użycie <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-automatic-deployment-with-git-with-a-vps\">gita</a>. Git pozwala nam przesłać jedynie istotne pliki, a zewnętrzne biblioteki możemy instalować sobie już z poziomu środowiska produkcyjnego. Aby to zadziałało musimy dodać lokalizację repozytorium na naszym serwerze do lokalnego zbioru repozytoriów zdalnych.</p><p>Zakładamy, że logujemy się na użytkownika nazwanego <code>root</code> a <code>ip</code> naszego serwera mamy w zmiennej <code>$ip_gs</code>. Repozytorium projektu na serwerze będzie trzymane w katalogu <code>/var/repo/log_analysis</code>.</p><pre><code>git remote add live ssh://root@$ip_gs/var/repo/log_analysis\n\n</code></pre><p>Na serwerze wykonujemy komendy:</p><pre><code>mkdir -p /var/repo/log_analysis &amp;&amp; cd /var/repo/log_analysis\ngit init --bare\n\n</code></pre><p>Następnie tworzymy plik <code>post-receive</code> w katalogu <code>hooks</code> i zapisujemy do niego poniższą treść:</p><blockquote>/var/repo/log_analysis/hooks/post-receive</blockquote><pre><code class=\"language-bash\">#!/bin/sh\nWORK_TREE=/var/www/log_analysis\nGIT_DIR=/var/repo/log_analysis\n\ngit --work-tree=$WORK_TREE --git-dir=$GIT_DIR checkout -f\nexit\n\n</code></pre><p>Na koniec nadajemy mu uprawnienia <code>chmod a+x post-receive</code> i tworzymy katalog w którym mają się znaleźć pliki projektu.</p><pre><code class=\"language-bash\">mkdir -p /var/www/log_analysis\n\n</code></pre><p>Wracamy na maszynę lokalną i wypychamy repozytorium do serwera.</p><pre><code>git push live master\n\n</code></pre><p>Wracamy na serwer i ustawiamy produkcyjną konfigurację w pliku <code>/var/www/log_analysis/config/parameters.yml</code>. Chodzi tutaj o to, żeby nie zostawić użytkownika <code>user</code> z hasłem <code>pass</code> na produkcji. Najprościej będzie skopiować plik <code>/var/www/log_analysis/config/parameters.yml.dist</code> i pozmieniać wartości pod kluczem <code>security</code>.</p><p>Instalacja polega na wykonaniu czterech poleceń:</p><pre><code>apt-get install jq\ncomposer install\nbower install\nbash build.sh\n\n</code></pre><p>Teraz naszym zadaniem jest podpiąć web do którejś domeny albo portu. U nas będzie to port 8001. Dodamy więc nasłuch na tym porcie do Apache dodając odpowiednią linię do konfiguracji:</p><blockquote>/etc/apache2/ports.conf</blockquote><pre><code># log analysis\nListen 8001\n\n</code></pre><p>Do katalogu <code>sites-avaliable</code> dodajemy plik:</p><blockquote>/etc/apache2/sites-avaliable/log_analysis.conf</blockquote><pre><code>&lt;VirtualHost *:8001&gt;\n    DocumentRoot /var/www/log_analysis/web\n\n    ErrorLog /var/log/apache2/log_analysis_error.log\n    CustomLog /var/log/apache2/log_analysis_access.log combined\n&lt;/VirtualHost&gt;\n\n</code></pre><p>Linkujemy go symbolicznie z <code>sites-enabled</code> za pomocą polecenia:</p><pre><code>a2ensite log_analysis.conf\n\n</code></pre><p>Przeładowujemy apache</p><pre><code>service apache2 reload\n\n</code></pre><p>Usługa powinna działać, ale chcieli zautomatyzować proces aktualizacji widoków przetworzonych logów.</p><h3 id=\"cron\">Cron</h3><p>Są różne możliwe podejścia. Pierwsze to budować widoki przy każdej rozpoczynającej się sesji. Drugie - budować tylko ten widok o który w danym momencie pytamy. Trzecie to budować wszystkie widoki codziennie i nie męczyć użytkownika czekaniem.</p><p>Ponieważ aktualność logów z dokładnością co do godzin nie jest dla mnie większą wartością niż kilka sekund czekania na załadowanie się widoku zdecydowałem się na cykliczne tworzenie wszystkich widoków co jeden dzień.</p><p>Żeby to osiągnąć wystarczy stworzyć plik:</p><blockquote>/etc/cron.daily/log_analysis</blockquote><pre><code class=\"language-bash\">#!/bin/bash\n\ncd /var/www/log_analysis/\nbash build.sh\n\n</code></pre><p>i nadać mu uprawnienia do wykonywania:</p><pre><code class=\"language-bash\">chmod a+x /etc/cron.daily/log_analysis\n\n</code></pre><p>Logi Apache są cennym źródłem informacji. Nie mają co prawda takich możliwości pomiarowych jak skrypty instalowane na stronie (mapy cieplne, czas aktywności, śledzenie<br>eventów), ale dzięki temu, że są zbierane automatycznie, można bez żadnego dodatkowego obciążania strony, po prostu je wykorzystać.</p><p>Daj znać w komentarzu, czy ten projekt znalazł zastosowanie u Ciebie, albo jeśli masz jakieś pomysły, gdzie można by go ulepszyć.</p>",
            "comment_id": "607f36b62fb35425592d0b7b",
            "plaintext": "Kiedyś, usłyszałem od kolegi, że nie ma gorszego zajęcia, niż analiza logów\nApache. Przeraziło mnie to bo myślałem, że to zmywanie naczyń jest najgorsze.\nByło to dość dawno i od tego czasu w moim życiu dużo zmieniło się na lepsze.\nDzisiaj do zmywania używam zmywarki, a do analizy logów GoAccess.\n\nW tym projekcie poznamy narzędzie pozwalające wydobywać ciekawe informacje z\nplików generowanych automatycznie podczas pracy serwera. Napiszemy panel \nudostępniający wyniki analizy logów. Na koniec dodamy do niego mechanizm content\nnegotiation czyli sposób na reprezentowanie tych samych obiektów za pomocą\nróżnego typu danych.\n\nSkład kodu\n\nPHP 32.9% HTML 22.6% JavaScript 20.5% Shell 18.5% CSS 5.5%\n\n\nPo napisaniu projekt będzie wyglądał tak:\n\nInstalcja GoAccess\nGoAccess jest przystosowany do działania na wielu systemach z różnymi rodzajami\nlogów. Zakładam, że, mamy dystrybucję z repozytoriami Debiana/Ubuntu, serwer\nApache2. W tym przypadku do instalacji GoAccess [https://goaccess.io/download] \nposłużą nam komendy:\n\necho \"deb http://deb.goaccess.io/ $(lsb_release -cs) main\" | sudo tee -a /etc/apt/sources.list.d/goaccess.list\nwget -O - https://deb.goaccess.io/gnugpg.key | sudo apt-key add -\nsudo apt-get update\nsudo apt-get install goaccess\n\n\nKonfiguracja polega na wycięciu komentarzy z pliku konfiguracyjnego \n/etc/goaccess.conf przy liniach zawierających wpisy:\n\ntime-format %H:%M:%S\ndate-format %d/%b/%Y\nlog-format %h %^[%d:%t %^] \"%r\" %s %b \"%R\" \"%u\"\n\n\nTeraz należy pobrać repozytorium z gihuba\n\ngit clone https://github.com/gustawdaniel/Apache-Log-Analysis-Admin-Panel.git\n\n\nTworzymy naszą własną konfigurację do tego projektu. Jak zwykle posłużymy się\nplikiem yml.\n\n> config/parameters.yml\nconfig:\n  apache: /var/log/apache2/*access.log\n  report: report\nsecurity:\n  user: user\n  pass: pass\n  authorization: api\n\n\nWłasność apache jest to zbiór wszystkich plików z logami dostępu do\nposzczególnych domen, które trzymamy na serwerze. Końcówka access.log jest\nzwiązana z przyjętą przeze mnie konwencją zgodnie z którą w konfiguracji domen\nprzekierowuję wszystkie logi dostępu do plików domain_access.log. Natomiast \nreport jest to lokalizacja do której będziemy zapisywać wyniki parsowania.\n\nNa koniec wykonujemy skrypt instalacyjny\n\nbash install.sh\n\n\nProjekt powinien być dostępny w przeglądarce pod adresem localhost:8000\n[http://localhost:8000].\n\nParsowanie logów\nNaszym celem jest teraz wykorzystanie programu GoAccess do przetworzenia\nwszystkich logów do postaci plików html.\n\nDo odczytywania pliku konfiguracyjnego w bashu wykorzystamy funkcję napisaną\nprzez Piotra Kuczyńskiego [https://gist.github.com/pkuczynski/8665367].\n\n> lib/parse_yml.sh\n#!/usr/bin/env bash\n\nparse_yaml() {\n   local prefix=$2\n   local s='[[:space:]]*' w='[a-zA-Z0-9_]*' fs=$(echo @|tr @ '\\034')\n   sed -ne \"s|^\\($s\\)\\($w\\)$s:$s\\\"\\(.*\\)\\\"$s\\$|\\1$fs\\2$fs\\3|p\" \\\n        -e \"s|^\\($s\\)\\($w\\)$s:$s\\(.*\\)$s\\$|\\1$fs\\2$fs\\3|p\"  $1 |\n   awk -F$fs '{\n      indent = length($1)/2;\n      vname[indent] = $2;\n      for (i in vname) {if (i > indent) {delete vname[i]}}\n      if (length($3) > 0) {\n         vn=\"\"; for (i=0; i<indent; i++) {vn=(vn)(vname[i])(\"_\")}\n         printf(\"%s%s%s=\\\"%s\\\"\\n\", \"'$prefix'\",vn, $2, $3);\n      }\n   }'\n}\n\n\nTa funkcja przyjmuje dwa parametry, pierwszy to nazwa pliku do parsowania, drugi\njest prefixem nazw nadawanych wewnątrz naszego skryptu parametrom wydobytym z\npliku yml. Jej zastosowanie widzimy poniżej.\n\n#!/usr/bin/env bash\n\n# include parse_yaml function\n. lib/parse_yaml.sh\n\n# read yaml file\neval $(parse_yaml config/parameters.yml \"parameters_\")\n\nmkdir -p $parameters_config_report $parameters_config_report/html $parameters_config_report/json\n\narr=();\n\n# loop over apache logs\nfor file in $parameters_config_apache\ndo\n  out=$(basename \"$file\" .log)\n  out=${out%_access}\n\n  if [ ! -s $file ];\n  then\n    continue;\n  fi\n\n  echo \"Processed: \"$out;\n  goaccess -f $file -a -o $parameters_config_report/html/$out.html;\n  goaccess -f $file -a -o $parameters_config_report/json/$out.json;\n\n  arr+=($out);\ndone\n\njq -n --arg inarr \"${arr[*]}\" '{ list: $inarr | split(\" \") }' > $parameters_config_report/list.json\n\n\nW tym skrypcie kolejno: załączamy powyższą funkcję, wczytujemy konfigurację do\nzmiennych. Następnie tworzymy katalogi w których mają się znaleźć wyniki\nparsowania logów, inicjalizujemy tablicę i przebiegamy pętlę po wszystkich\nplikach z logami. W tej pętli wydobywamy nazwę bazową pliku. Jeśli ma w nazwie \n_access to wycinamy, pomijamy puste pliki, wykonujemy na logach program goaccess\nktóry tworzy nam we wskazanym w konfiguracji katalogu pliki html gotowe do\nwyświetlania. Na końcu dodajemy do tablicy przetworzoną nazwę pliku.\n\nPo wykonaniu pętli konwertujemy listę przetworzonych nazw do formatu json i\nzapisujemy razem z raportami. Dzięki tej liście nie będziemy musieli wykonywać\npętli po katalogu w php. Zanim wykonamy ten skrypt, możliwe, że będziemy\npotrzebowali zainstalować jq. Jest to bardzo proste:\n\napt-get install jq\n\n\n\nBackend\nLogi mamy gotowe, teraz stworzymy API, które będzie je udostępniać. Nie chcemy\ntrzymać ich w lokacji dostępnej z poziomu przeglądarki. Przeglądarka będzie\nmiała dostęp tylko do katalogu web i dlatego tam umieścimy plik api.php.\nPonieważ będziemy potrzebowali dostępu do konfiguracji zainstalujemy jeszcze\nparser yml.\n\ncomposer require symfony/yaml\n\n\n\nPlik z API to przede wszystkim routing. Zaczyna się jednak od podłączenia\npaczek, ustawienia zmiennych i nagłówków:\n\n> web/api.php\n<?php\n\nrequire_once __DIR__.\"/../vendor/autoload.php\";\nuse Symfony\\Component\\Yaml\\Yaml;\n\n$config = Yaml::parse(file_get_contents(__DIR__.'/../config/parameters.yml'));\n\nsession_start();\n\n$uri = explode('/', strtolower(substr($_SERVER['REQUEST_URI'], 1)));\n$route = isset($uri[1]) ? $uri[1] : \"\";\n$parameter = isset($uri[2]) ? $uri[2] : \"\";\n\n$data = array();\n\nheader(\"Access-Control-Allow-Origin: *\");\nheader(\"Access-Control-Allow-Headers: Content-Type\");\nheader(\"Access-Control-Allow-Methods: GET, POST\");\nheader('Content-Type: application/json');\n\n\n\nPodpinanie konfiguracji w ten sposób było już omawiane\n[http://blog.gustawdaniel.pl/2016/12/02/tesseract-ocr-i-testowanie-selekt%C3%B3w.html#kontekst]\n. Nowością jest ustawianie sesji. Jest to na tyle sprytna funkcja, że tworzy u\nużytkownika plik cookie z losowym numerem sesji i jednocześnie ten numer\nzapisuje po stronie serwera, tak aby w zmiennej $_SESSION można było odwoływać\nsię do tej konkretnej ani nie sprawdzając cookie ręcznie, ani nie martwiąc się o\nto, że\n\nNowością jest cięcie adresu uri na tablicę za pomocą znaków /. Pierwszy jej\nelement będzie miał wartość api.php dlatego wychwytujemy dwa kolejne jeśli\nistnieją. Ustawiamy sobie pustą tablicę data i na koniec dodajemy nagłówki\npozwalające ominąć problemy z CORS oraz ustawić domyślny typ zwracanych danych.\n\nW Symfony istnieją specjalne klasy Response i JsonResponse, które ułatwiają\nzwracanie odpowiedzi, tu jednak posłużymy się bardziej prymitywną metodą ze\nwzględu na jej prostotę. Zdefiniujemy funkcję do zwracania błędów.\n\nfunction returnError($code,$type,$message){\n    $data[\"error\"] = [\"code\" => $code, \"type\" => $type, \"message\" => $message];\n    echo json_encode($data);\n    die();\n}\n\n\n\nWarto zwrócić uwagę, że zwraca ona kody błędów, ale sama ma kod zawsze równy\n200. Wyjątkiem będą błędy po stronie serwera, których nie przechwycę. Tylko w\ntakim wypadku chcę zwracać kod błędu. Czas rozpocząć omawianie routingu.\nZaczniemy od ścieżki do sprawdzania poprawności loginu. W Symfony odpoiada jej\nnie login ale login_check.\n\nswitch ($route) {\n        case \"login\": {\n\n            if(!isset($_POST[\"user\"]) || !isset($_POST[\"pass\"])) {\n                returnError(400,\"Bad Request\",\"Invalid form\");\n            } elseif($_POST[\"user\"]!=$config[\"security\"][\"user\"] || $_POST[\"pass\"]!=$config[\"security\"][\"pass\"]) {\n                returnError(403,\"Forbidden\",\"Incorrect Login or Password\");\n            }\n\n            $_SESSION['user'] = $config[\"security\"][\"user\"];\n            $data = [\"state\" => \"loggedIn\"];\n\n        }\n\n\n\nNasz switch przyjmuje do porównań ścieżkę wpisaną po api.php/ ale przed kolejnym\nznakiem /. W tej części kodu zajmujemy się przypadkiem kiedy adres zapytania\nzawierał login. Ponieważ do logowania używamy metody $_POST, kontroler na tej\nścieżce sprawdza czy wysłano zmienne user i pass, oraz czy są zgodne z tymi\nustawionymi w konfiguracji. Jeśli sprawdzanie danych przebiegnie pomyślnie,\nzostanie utworzona zmienna $_SESSION['user'], a do listy danych odsyłanych w\nodpowiedzi zostanie dodany stan potwierdzający zalogowanie.\n\nZauważ, że na końcu nie dodałem instrukcji break;. Zrobiłem to celowo. Od razu\npo zalogowaniu bez wysyłania kolejnego requestu zawsze chcę dostawać listę\ndomen, dla których Apache tworzy logi. Dlatego pod blokiem login umieściłem blok \nreport, który ma wykonać się zarówno po wybraniu ścieżki report jak i po\npoprawnym zalogowaniu użytkownika. Jednak ponieważ chcę mieć dostęp do tej\nścieżki przez API z pominięciem logowania formularzem, przed wydobyciem\npotrzebnych danych sprawdzę prawo dostępu za pomocą następującego warunku:\n\n        case \"report\": {\n\n            if(\n                (!isset($_SESSION['user'])\n                    ||!$_SESSION['user'])\n                &&(!isset(getallheaders()[\"Authorization\"])\n                    ||getallheaders()[\"Authorization\"]!=$config[\"security\"][\"authorization\"]\n                )\n            ){\n                returnError(403,\"Forbidden\",\"Incorrect Login or Password\");\n            }\n\n\n\nPoza sprawdzaniem, czy sesja jest ustawiona sprawdzamy tutaj też nagłówek \nAuthorization jako alternatywną metodę logowania. Jeśli przynajmniej jedna z\nmetod logowania (sesja albo nagłówek) zostaną uznane za poprawne, wykona się\nnastępujący kod:\n\n            $data[\"report\"] = [];\n\n            $list = json_decode(file_get_contents(__DIR__ . \"/../\" . $config[\"config\"][\"report\"] . \"/list.json\"));\n\n            foreach ($list->list as $key => $value) {\n                $data[\"report\"][] = [\"name\" => $value, \"key\" => $key, \"link\" => \"api.php/report/\" . $value];\n            };\n\n\n\nStworzyliśmy tu klucz report do tablicy z odpowiedzią. Odczytaliśmy i\nzdekodowaliśmy listę nazw plików  z przetworzonymi logami apache wygenerowaną\nprzez skrypt build.sh. Następnie w pętli rozbudowaliśmy strukturę każdego\nelementu tej listy o atrybuty key i link, a samą nazwę przypisaliśmy do klucza \nname. Ta transformacja służy do łatwiejszego przetwarzania tych danych przez\nfront-end który do tego napisaliśmy.\n\nJednak główną funkcjonalnością nie jest wyświetlanie samych nazw plików, tylko\nich zawartości. To dobry moment aby zapoznać się z mechanizmem \ncontent-negotiation. Jest to sposób, aby w RESTowym API temu samemu adresowi url \nprzypisać reprezentację za pomocą różnego typu danych. W naszym przykładzie będą\nto html i json. Typ danych jaki chcemy otrzymać ustawiamy na nagłówku Accept \nprzygotowując żądanie. Poniższy kod odpowiada za odpowiednią interpretację tego\nnagłówka.\n\n            if ($parameter != \"\") {\n                if (preg_match('/text\\/html/', $_SERVER[\"HTTP_ACCEPT\"])) {\n                    header('Content-Type: text/html');\n                    echo file_get_contents(__DIR__ . \"/../\" . $config[\"config\"][\"report\"] . \"/html/\" . $parameter . \".html\");\n                } elseif (preg_match('/application\\/json|\\*\\/\\*/', $_SERVER[\"HTTP_ACCEPT\"])) {\n                    header('Content-Type: application/json');\n                    echo file_get_contents(__DIR__ . \"/../\" . $config[\"config\"][\"report\"] . \"/json/\" . $parameter . \".json\");\n                } else {\n                    returnError(415,\"Unsupported Media Type\",\"Incorrect Content Type\");\n                }\n                die();\n            }\n            break;\n        }\n\n\n\nWykona się on tylko jeśli url będzie zawierał po api.php/report/ coś jeszcze.\nTen ostatni kawałek zapisany był do zmiennej $parameter na początku skryptu przy\ndzieleniu uri na kawałki. Wskazuje on na to, który plik mamy wyciągnąć i za jego\nustawianie odpowiedzialny jest klucz link z tablicy $data[\"report\"].  Funkcja \npreg_match sprawdza czy wyrażenie regularne podane w pierwszym argumencie\nwystępuje w ciągu znaków z drugiego argumentu. I w zależności od tego czy\ndopasowano text/html czy application/json albo */* zwracany jest html lub json.\n\nOstatnią ścieżką obsługiwaną przez api jest logout.\n\n        case \"logout\": {\n            session_unset();\n            session_destroy();\n            $data = [\"state\" => \"loggedOut\"];\n            break;\n        }\n\n\n\nOdpowiada on za usunięcie sesji i przypisanie stanu loggedOut. Na koniec\nobsługujemy wyjątek związany z nie poprawną ścieżką, w szczególności jest to też\nnasz punkt startowy api.php/\n\n        default: {\n            returnError(404,\"Not Found\",\"Use route /report with Authorization header\");\n            break;\n        }\n    }\n\necho json_encode($data);\n\n\n\nPo wykonaniu instrukcji switch wysyłamy dane które zostały zebrane do tablicy \n$data podczas przetwarzania żądania.\n\nDostęp przez API\nAby uzyskać dostęp przez API wystarczy wysłać następujący request:\n\nhttp -v --pretty=all GET localhost:8000/api.php/report Authorization:api\n\n\n\nOtrzymaliśmy listę dostępnych plików. Jeśli chcemy konkretny  plik wpisujemy:\n\nhttp -v --pretty=all GET localhost:8000/api.php/report/api_brainjinn Authorization:api\n\n\n\nFrontend\nOddzielenie frontu od backednu od pewnego czasu bardzo mnie interesowało.\nSpodobały mi się sposoby patrzenia na uporządkowanie kodu w frameworkach takich\njak aurelia czy angular. Jednak bez przesady. Nie będziemy zaprzęgać armaty do\nzestrzeliwania muchy i nie skorzystamy tu z żadnego z nich.\n\nNa mój front nałożyłem tylko jeden warunek - ma to być single page application\nobsługująca poprawnie logowanie i wylogowywanie. Zrezygnowałem też ze stosowania\ngulpa, ze względu na to, że była by to niepotrzebna komplikacja w tak małym\nprojekcie.\n\nMimo to zastosowałem tutaj mechanizmy templatingu i bardzo prymitywny routing\noparty na tanie odpowiedzi api albo eventach a nie na samych fragmentach url.\n\nZaczniemy od instalacji zewnętrznych bibliotek do frontu. Będzie to bootstrap 4 \noraz mustache 2.3. O ile pierwsza paczka powszechnie dobrze znana, o tyle z \nmustache spotkałem się pierwszy raz. Jest to odpowiednik twiga tylko wykonywany\npo stronie klienta a nie serwera. Zanim zaczniemy instalację stworzymy plik\nkonfiguracyjny bowera:\n\n> .bowerrc\n{\n  \"directory\": \"web/bower_components\"\n}\n\n\n\nWskazuje on, żeby instalować bezpośrednio do katalogu web. Jest to związane z\ntym, że rezygnując z gulpa chemy mieć gotowe do użycia paczki wystawione na\nzewnątrz. Przypominam, że przeglądarka ma dostęp tylko do katalogu web w naszej\nstrukturze projektu. Aby zainstalować paczki wykonujemy:\n\nbower init\nbower install --save bootstrap#v4.0.0-alpha.5\nbower install --save mustache\n\n\n\nTeraz przejdziemy do punktu wejściowego naszej aplikacji - pliku index.html.\n\n> web/index.html\n<!DOCTYPE html>\n<html>\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Apache Log Analysis</title>\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=no\">\n    <link rel=\"stylesheet\" href=\"bower_components/bootstrap/dist/css/bootstrap.min.css\">\n    <link rel=\"stylesheet\" href=\"bower_components/tether/dist/css/tether.min.css\">\n    <link href=\"https://fonts.googleapis.com/css?family=Lato:300&amp;subset=latin-ext\" rel=\"stylesheet\">\n    <link rel=\"stylesheet\" href=\"css/style.css\">\n</head>\n<body>\n\n    <div id=\"content\"></div>\n\n\n\n    <script src=\"bower_components/jquery/dist/jquery.min.js\"></script>\n    <script src=\"bower_components/tether/dist/js/tether.min.js\"></script>\n    <script src=\"bower_components/bootstrap/dist/js/bootstrap.min.js\"></script>\n    <script src=\"bower_components/mustache.js/mustache.min.js\"></script>\n\n    <script src=\"js/site.js\"></script>\n\n    <script>\n        var url = \"/api.php/\";\n    </script>\n\n    <script src=\"js/routing.js\"></script>\n\n</body>\n\n\n\nJego struktura przypomina trochę strukturę index.html z Aurelii czy Angulara.\nJest to praktycznie pusty html z podpiętymi stylami, jednym divem służącym za\npunkt zaczepienia i następnie samymi skryptami. Jeśli chodzi o style, mamy tu \nbootstrapa, tethera jako jego zależność, czcionka Lato, i nasze style. Później\njest miejsce dla wspomnianego punktu zaczepienia. To w divie z id=\"content\" \nbędzie dynamicznie budowana nasza aplikacja. Jeśli chodzi o skrypty, to\npodpinamy bootstrapa i mustache wraz z zależnościami bootstrapa. Plik site.js \njest naszą biblioteką zawierającą często używane funkcje. Zmienna globalna url \nzostała wyeksponowana w index.html ponieważ dla tej jednej zmiennej nie opłacało\nsię tworzyć oddzielnie środowiska produkcyjnego i developerskiego. Na końcu\npodpięty jest routing.js który sprawdzając czy użytkownik jest zalogowany\nprzekierowuje nas do strony logowania, albo wyświetlania lisy plików z logami.\n\nJednak o tym później, teraz przejrzymy załączniki z index.html od góry na dół.\nZaczniemy od stylów:\n\n> web/css/style.css\nbody {\n    font-family: 'Lato', sans-serif;\n}\n.login-container {\n    padding-top: 25vh;\n}\n.report-container {\n    padding-top: 15vh;\n}\n.btn-login {\n    background-color: #59B2E0;\n    outline: none;\n    color: #fff;\n    font-size: 14px;\n    height: auto;\n    font-weight: normal;\n    padding: 14px 0;\n    text-transform: uppercase;\n    border-color: #59B2E6;\n}\n.btn-login:hover,\n.btn-login:focus {\n    color: #fff;\n    background-color: #53A3CD;\n    border-color: #53A3CD;\n}\n.padding-b-10{\n    padding-bottom: 10px;\n}\n\n\n\nStyle jak style. Nic specjalnego. Dodaliśmy czcionkę, paddingi na główny \ncontainer, customowy button do logowania i padding na wyświetlanie listy plików\nz logami. Skrypty są ciekawsze, oto nasza biblioteka z przydatnymi funkcjami:\n\n> web/js/site.js\nfunction getFormData($form){\n    var unindexed_array = $form.serializeArray();\n    var indexed_array = {};\n\n    $.map(unindexed_array, function(n, i){\n        indexed_array[n['name']] = n['value'];\n    });\n\n    return indexed_array;\n}\n\n\n\nPierwsza z nich służy do przekształcania formulaża do postaci formatu json \nbardziej intuicyjnego niż to co oferuje serializeArray, a jednocześnie dużo\nbardziej eleganckiego niż to co robi serialize.\n\nfunction deleteAllCookies() {\n    var cookies = document.cookie.split(\";\");\n\n    for (var i = 0; i < cookies.length; i++) {\n        var cookie = cookies[i];\n        var eqPos = cookie.indexOf(\"=\");\n        var name = eqPos > -1 ? cookie.substr(0, eqPos) : cookie;\n        document.cookie = name + \"=;expires=Thu, 01 Jan 1970 00:00:00 GMT\";\n    }\n}\n\n\n\nDruga funkcja odpowiada za czyszczenie ciasteczek. Co ciekawe nie da się ich po\nprostu usunąć, ale da się ustawić datę ich wygaśnięcia na kilkadziesiąt lat\ntemu.\n\nfunction loadComponent(name,data){\n    $.get(\"component/\"+name+\"/\"+name+\".html\").done(function(template){\n        var html = Mustache.render(template, data);\n        $(\"#content\").html(html);\n        $.getScript(\"component/\"+name+\"/\"+name+\".js\")\n    });\n}\n\n\n\nOstatnia funkcja jest najbardziej dostosowana do naszej struktury katalogów i\ntreści, więc zanim ją omówię wspomnę jeszcze o strukturze katalogów. Otuż w web \noprócz oczywistych js, css, bower_components mamy też katalog component. Nazwa\nporzyczona od angulara wskazuje, że wewnątz znajdą się skrypty i szablony\nodpowiadające pewnej konkretnej funkcjonalności. Jest to poprawna intuicja i tak\nw component mamy katalogi login z plikami login.html i login.js oraz report z\nplikami report.html i report.js. Ta funkcja odpowiada za pobranie pliku html z\nkomponentu za pomocą metody GET, renderowanie go za pomocą biblioteki mustache \nktóra wstawia do niego dane zawarte w zmiennej data. Następnie plik ten jest\npodpinany do naszego punktu zaczepienia w index.html a kiedy to nastąpi zostają\nmu dostarczone skrypty. Mechanizm piękny dzięki swojej prostocie, a jest on\nsercem całego frontu. To dzięki tej metodzie front żyje i zmienia widoki bez\nprzeładowywania strony.\n\nJednak ta funkcja nie wywoła się sama. Wspominałem o prymitywnym routingu. To on\nzarządza tym co zobaczymy kiedy strona zostanie załadowana:\n\n> web/js/routing.js\n$.get(url+\"report\").done(function(data){\n    //console.log(data);\n    if(data.hasOwnProperty('report')){\n        loadComponent(\"report\",data);\n    } else {\n        loadComponent(\"login\",{});\n    }\n});\n\n\n\nKomponenty\nJego działanie polega na próbie pobrania zawartości zarezerwowanej dla\nzalogowanych użytkowników. Nie chciałem tu zwracać kodu błędu 403, bo to tak\nnaprawdę nie jest błąd. Jest całkiem normalne, że czasem nie jesteśmy\nzalogowani. Dzięki temu nawet jeśli użytkownik nie ma prawa dostępu do tych\nzasobów posługuję się metodą done. Oczywiście jeśli nie jesteśmy zalogowani, to\nodpowiedź nie będzie zawierała klucza report tylko error. W tym przypadku\nzostanie załadowany login z pustą tablicą danych. Jeśli jednak sesja jest\nstworzona i użytkownik jest zalogowany poprawnie ładujemy komponent report i\nprzekazujemy mu dane otrzymane od serwera.\n\nDo omówienia zostały nam już tylko 4 pliki z komponentów. Zaczniemy od szablonu\nloginu:\n\n> web/component/login/login.html\n<div class=\"container login-container\">\n    <div class=\"row\">\n        <div class=\"offset-lg-3 col-lg-6 col-md-12 col-sm-12 col-xs-12\">\n            <div class=\"card card-block text-xs-center\">\n                <h4 class=\"card-title\">Apache Log Analysis</h4>\n                <div class=\"card-block\">\n                    <form id=\"login-form\">\n                        <div class=\"form-group\">\n                            <input type=\"text\" name=\"user\" tabindex=\"1\" class=\"form-control\" placeholder=\"Username\" value=\"\">\n                        </div>\n                        <div class=\"form-group\">\n                            <input type=\"password\" name=\"pass\" tabindex=\"2\" class=\"form-control\" placeholder=\"Password\">\n                        </div>\n                        <div class=\"form-group\">\n                            <input type=\"submit\" name=\"login-submit\" id=\"login-submit\" tabindex=\"4\" class=\"form-control btn btn-login\" value=\"Log In\">\n                        </div>\n                    </form>\n                    <div id=\"login-error\"></div>\n                </div>\n            </div>\n        </div>\n    </div>\n</div>\n\n\n\nProsty formularz z dwoma polami i div na potencjalne błędy. Wygląda tak:\n\nSkrypt który go obsługuje jest podręcznikowym przykładem obsługi formulaża w js\n\n    var form = document.getElementById(\"login-form\");\n    var error = document.getElementById(\"login-error\");\n\n\n    form.addEventListener(\"submit\", function (e) {\n        e.preventDefault();\n        //console.log(JSON.stringify(getFormData($(this))));\n        $.post(url + 'login', getFormData($(this))).done(function (data) {\n            //console.log(\"s\",data);\n            if (data.hasOwnProperty('error')) {\n                //console.log(\"error_detected\");\n                error.innerHTML = '<div class=\"alert alert-danger\">' + data.error.message + '</div>';\n            } else if (data.hasOwnProperty('state')) {\n                if (data.state == \"loggedIn\") {\n                    loadComponent(\"report\", data);\n                }\n            }\n        }).fail(function (data) {\n            error.innerHTML = '<div class=\"alert alert-danger\">' + 'There are unidentified problems with service.' + '</div>';\n            //console.log(data);\n        });\n        return false;\n\n    });\n\n\n\nNamierzamy elementy. Dodajemy listener. Przy próbie wysłania wysyłamy POST z\ntreścią formulaża. Obsługa błędów 4xx jest tu w done a nie fail. W przypadku\nsukcesu ładujemy report. Na koniec obsługujemy błędy 5xx przez fail.\n\nW widoku raportu jest ciekawiej, bo tu mustache robi pętlę.\n\n> web/component/report/report.html\n<div class=\"container report-container\">\n    <div class=\"row\">\n        <div class=\"col-lg-12 col-md-12 col-sm-12 col-xs-12\">\n            <div class=\"card card-block text-xs-center\">\n                <h4 class=\"card-title\">Apache Log Analysis</h4>\n                <div class=\"card-block\">\n                    <ul class=\"list-group row\">\n                        {{ \"{{ #report \" }}}}\n                        <div class=\"col-sm-6 col-md-4 col-lg-3 padding-b-10\">\n                        <a target=\"_blank\" href=\"{{link}}\" class=\"list-group-item \">{{ \"{{ #name \" }}}}</a>\n                        </div>\n                        {{ \"{{ /report \" }}}}\n                    </ul>\n                </div>\n                <div class=\"card-block\">\n                    <button id=\"logout\" class=\"btn btn-danger btn-block\">Logout</button>\n                </div>\n            </div>\n        </div>\n    </div>\n</div>\n\n\n\nPętla po tablicy report wyświetla wszystkie elementy listy podpinając do nich\nnazwy oraz linki. Dla moich logów wygląda to tak:\n\nSkrypt robi tu jedynie wylogowanie i dlatego jest dość któdki:\n\n> web/component/report/report.js\n    var logout = document.getElementById(\"logout\");\n\n    logout.addEventListener(\"click\", function () {\n        deleteAllCookies();\n        $.get(url + \"logout\");\n        loadComponent(\"login\", {});\n    });\n\n\n\nNa koniec podam jeszcze screen z przykładowej analizy logów. Jest to obraz jaki\nzobaczymy po wybraniu któregoś z listy plików z widoku report. W tym przypadku\nsą to logi tego bloga.\n\nDeployment\nBardzo lubianą przeze mnie, ale jeszcze nie opisywaną techniką wypuszczania\nprojektu na produkcję jest użycie gita\n[https://www.digitalocean.com/community/tutorials/how-to-set-up-automatic-deployment-with-git-with-a-vps]\n. Git pozwala nam przesłać jedynie istotne pliki, a zewnętrzne biblioteki możemy\ninstalować sobie już z poziomu środowiska produkcyjnego. Aby to zadziałało\nmusimy dodać lokalizację repozytorium na naszym serwerze do lokalnego zbioru\nrepozytoriów zdalnych.\n\nZakładamy, że logujemy się na użytkownika nazwanego root a ip naszego serwera\nmamy w zmiennej $ip_gs. Repozytorium projektu na serwerze będzie trzymane w\nkatalogu /var/repo/log_analysis.\n\ngit remote add live ssh://root@$ip_gs/var/repo/log_analysis\n\n\n\nNa serwerze wykonujemy komendy:\n\nmkdir -p /var/repo/log_analysis && cd /var/repo/log_analysis\ngit init --bare\n\n\n\nNastępnie tworzymy plik post-receive w katalogu hooks i zapisujemy do niego\nponiższą treść:\n\n> /var/repo/log_analysis/hooks/post-receive\n#!/bin/sh\nWORK_TREE=/var/www/log_analysis\nGIT_DIR=/var/repo/log_analysis\n\ngit --work-tree=$WORK_TREE --git-dir=$GIT_DIR checkout -f\nexit\n\n\n\nNa koniec nadajemy mu uprawnienia chmod a+x post-receive i tworzymy katalog w\nktórym mają się znaleźć pliki projektu.\n\nmkdir -p /var/www/log_analysis\n\n\n\nWracamy na maszynę lokalną i wypychamy repozytorium do serwera.\n\ngit push live master\n\n\n\nWracamy na serwer i ustawiamy produkcyjną konfigurację w pliku \n/var/www/log_analysis/config/parameters.yml. Chodzi tutaj o to, żeby nie\nzostawić użytkownika user z hasłem pass na produkcji. Najprościej będzie\nskopiować plik /var/www/log_analysis/config/parameters.yml.dist i pozmieniać\nwartości pod kluczem security.\n\nInstalacja polega na wykonaniu czterech poleceń:\n\napt-get install jq\ncomposer install\nbower install\nbash build.sh\n\n\n\nTeraz naszym zadaniem jest podpiąć web do którejś domeny albo portu. U nas\nbędzie to port 8001. Dodamy więc nasłuch na tym porcie do Apache dodając\nodpowiednią linię do konfiguracji:\n\n> /etc/apache2/ports.conf\n# log analysis\nListen 8001\n\n\n\nDo katalogu sites-avaliable dodajemy plik:\n\n> /etc/apache2/sites-avaliable/log_analysis.conf\n<VirtualHost *:8001>\n    DocumentRoot /var/www/log_analysis/web\n\n    ErrorLog /var/log/apache2/log_analysis_error.log\n    CustomLog /var/log/apache2/log_analysis_access.log combined\n</VirtualHost>\n\n\n\nLinkujemy go symbolicznie z sites-enabled za pomocą polecenia:\n\na2ensite log_analysis.conf\n\n\n\nPrzeładowujemy apache\n\nservice apache2 reload\n\n\n\nUsługa powinna działać, ale chcieli zautomatyzować proces aktualizacji widoków\nprzetworzonych logów.\n\nCron\nSą różne możliwe podejścia. Pierwsze to budować widoki przy każdej\nrozpoczynającej się sesji. Drugie - budować tylko ten widok o który w danym\nmomencie pytamy. Trzecie to budować wszystkie widoki codziennie i nie męczyć\nużytkownika czekaniem.\n\nPonieważ aktualność logów z dokładnością co do godzin nie jest dla mnie większą\nwartością niż kilka sekund czekania na załadowanie się widoku zdecydowałem się\nna cykliczne tworzenie wszystkich widoków co jeden dzień.\n\nŻeby to osiągnąć wystarczy stworzyć plik:\n\n> /etc/cron.daily/log_analysis\n#!/bin/bash\n\ncd /var/www/log_analysis/\nbash build.sh\n\n\n\ni nadać mu uprawnienia do wykonywania:\n\nchmod a+x /etc/cron.daily/log_analysis\n\n\n\nLogi Apache są cennym źródłem informacji. Nie mają co prawda takich możliwości\npomiarowych jak skrypty instalowane na stronie (mapy cieplne, czas aktywności,\nśledzenie\neventów), ale dzięki temu, że są zbierane automatycznie, można bez żadnego\ndodatkowego obciążania strony, po prostu je wykorzystać.\n\nDaj znać w komentarzu, czy ten projekt znalazł zastosowanie u Ciebie, albo jeśli\nmasz jakieś pomysły, gdzie można by go ulepszyć.",
            "feature_image": "__GHOST_URL__/content/images/2021/06/goaccess-demo-ma.ttias.be.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:16:54.000Z",
            "updated_at": "2021-07-18T18:21:38.000Z",
            "published_at": "2021-05-07T20:26:00.000Z",
            "custom_excerpt": "W tym wpisie pokazuję narzędzie pozwalające wydobywać ciekawe informacje z plików generowanych automatycznie podczas pracy serwera.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f37552fb35425592d0b8f",
            "uuid": "6feef8f4-a6df-4b79-adbb-f37b7d56469f",
            "title": "Kompilacja interpretera php 7 w BunsenLabs",
            "slug": "kompilacja-interpretera-php-7-w-bunsenlabs",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Instalacja Bunsenlabs\\n\\nZwykle używam Ubuntu, czasem Debiana. Jednak na jednym komputerze postawiłem dystrybucję [Bunsenlabs](https://www.bunsenlabs.org/index.html). Jest to notebook, którego kupiłem za 400 zł jako maszynę do pisania podczas podróży. Gnome3 jest dla niego za ciężki, a [Openbox](http://openbox.org/wiki/Main_Page) zainstalowany w Bunshenlabs wprost przeciwnie - daje mu nowe życie. Wygląda przy tym naprawdę dobrze:\\n\\n![Bunshenlabs](https://www.bunsenlabs.org/img/frontpage-gallery/hydrogen2.jpg)\\n\\nW tym artykule zainstalujemy `Bunsenlabs` na maszynie wirtualnej.\\n\\nZaczniemy od pobrania dystrybucji ze strony: [https://www.bunsenlabs.org/installation.html](https://www.bunsenlabs.org/installation.html)\\n\\n[![instalacja](http://i.imgur.com/v4SafV3.png)](https://www.bunsenlabs.org/installation.html)\\n\\nWybieramy `bl-Hydrogen-amd64_20160710.iso` i pobieramy (najlepiej przez klienta sieci Torrent). Cały proces instalacji od włączenia `VirtualBoxa` do skonfigurowania środowiska przedstawiony jest na poniższym video.\"}],[\"html\",{\"html\":\"<video src=\\\"https://www.dropbox.com/s/52o1vqiqsm04opi/6.ogv?dl=1\\\" controls></video>\"}],[\"markdown\",{\"markdown\":\"Kluczowym momentem było pominięcie instalacji `LAPMA` kiedy zorientowałem się, że `php` występuje tam w wersji `5`. Żeby mieć wersję `7` będziemy go teraz kompilować.\\n\\n## Połączenie do Virtualboxa przez SSH\\n\\nWyłączymy teraz maszynę wirtualną, żeby zmienić jej ustawienia sieciowe. Zaznaczamy naszą maszynę w panelu VirtualBoxa. Wybieramy ustawienia wciskając kombinację `ctr+s`. W zakładce `sieć` zmieniamy `NAT` na `Mostkowa karta sieciowa (bridget)`. Klikamy `Ok` i ponownie włączamy maszynę.\\n\\n**Maszyna wirtualna:**\\n\\nInstalujemy serwer `ssh` na maszynie wirtualnej\\n\\n    sudo apt-get install openssh-server \\n\\nŻeby sprawdzić czy wszystko jest ok, wpisujemy\\n\\n    netstat -lnpt | grep 22\\n\\nŻeby sprawdzić jakie `ip` dostaliśmy wpisujemy komendę:\\n\\n    ifconfig\\n\\nŻeby umożliwić logowanie jako root przez ssh edytujemy plik z ustawieniami logowania\\n\\n    sudo nano /etc/ssh/sshd_config\\n\\nZmieniamy linię \\n\\n    PermitRootLogin without-password\\n\\nna\\n\\n    PermitRootLogin yes \\n\\nRestartujemy `ssh`\\n\\n    sudo /etc/init.d/ssh restart\\n\\nI tworzymy katalog dla kluczy roota:\\n\\n    sudo mkdir -p /root/.ssh\\n\\nUstawiamy hasło roota\\n\\n    sudo su && passwd\\n\\n**Maszyna lokalna**\\n\\nNa naszym komputerze zapisujemy `ip` do zmiennych środowiskowych. Do `~/.bashrc` dodajemy linie które mogą wyglądać na przykład tak:\\n\\n```\\nip_hy=\\\"192.168.0.11\\\"             # ip of hydrogen_x86_64\\nalias 'sh_hy'='ssh root@$ip_hy'  # ssh shortcut\\n```\\n\\nresetujemy zmienne powłoki wpisując:\\n\\n    bash\\n\\nAutoryzujemy dostęp z maszyny lokalnej do wirtualnej.\\n\\n    cat ~/.ssh/id_rsa.pub | sh_hy 'cat >> .ssh/authorized_keys'\\n\\nWpisujemy hasło roota na wirtualce i możemy już logować się do niej przez \\n\\n    sh_hy\\n\\nNajważniejsze komendy zostały przedstawione na filmie zamieszczonym poniżej\"}],[\"html\",{\"html\":\"<video src=\\\"https://www.dropbox.com/s/njf1k2ahle77pdk/7.mp4?dl=1\\\" controls></video>\"}],[\"markdown\",{\"markdown\":\"## Kompilacja PHP\\n\\nInterpreter [`php`](https://github.com/php/php-src) ma już ponad 100 000 commitów. Interesuje nas numer jego [ostatniego wydania](https://github.com/php/php-src/releases). W momencie, w którym to piszę jest to 7.0.14. Przechodzimy do katalogu `/usr/src` i pobieramy je:\\n\\n    git clone -b PHP-7.0.14 https://github.com/php/php-src --depth 1\\n\\nRepozytorium pobrane w ten sposób waży 20.8 MB. Gdybyśmy nie wybrali wersji teraz, tylko zrobili `checkout` po pobraniu całości, kosztowało by to nas ponad 320 MB. Przechodzimy do katalogu `php-src`. \\n\\n### Konfiguracja\\n\\nChecmy wygenerować plik konfiguracyjny:\\n\\n    ./buildconf --force\\n\\nMógł bym od razu podać skrypt, który instaluje wszystkie zależności. Jednak bardziej przydatne - szczególnie dla osób które napotkają podane tutaj błędy - uważam wypisanie tabelki z potencjalnymi błędami jakie mogą się pojawić przy tej komendzie. Skrypt z pełną kompilacją załączę na koniec\\n\\n| Problem             | Rozwiązanie              |\\n| ------------------- | ------------------------ |\\n| make: not found     | apt-get install make     |\\n| autoconf not found. | apt-get install autoconf |\\n\\nPo świeżej instalacji `BunsenLabs` generacja pliku konfiguracyjnego poszła stosunkowo prosto. Wystarczyło doinstalować tylko dwie zależności. Ciekawiej było samym procesem konfiguracji: \\n\\n```\\n./configure --prefix=/usr/local/php/7.0 \\\\\\n    --with-config-file-path=/etc/php/7.0/apache2 \\\\\\n    --with-config-file-scan-dir=/etc/php/7.0/apache2/conf.d \\\\\\n    --enable-mbstring \\\\\\n    --enable-zip \\\\\\n    --enable-bcmath \\\\\\n    --enable-pcntl \\\\\\n    --enable-ftp \\\\\\n    --enable-exif \\\\\\n    --enable-calendar \\\\\\n    --enable-sysvmsg \\\\\\n    --enable-sysvsem \\\\\\n    --enable-sysvshm \\\\\\n    --enable-wddx \\\\\\n    --enable-intl \\\\\\n    --with-curl \\\\\\n    --with-mcrypt \\\\\\n    --with-iconv \\\\\\n    --with-gmp \\\\\\n    --with-pspell \\\\\\n    --with-gd \\\\\\n    --with-jpeg-dir=/usr \\\\\\n    --with-png-dir=/usr \\\\\\n    --with-zlib-dir=/usr \\\\\\n    --with-xpm-dir=/usr \\\\\\n    --with-freetype-dir=/usr \\\\\\n    --enable-gd-native-ttf \\\\\\n    --enable-gd-jis-conv \\\\\\n    --with-openssl \\\\\\n    --with-pdo-mysql=/usr \\\\\\n    --with-gettext=/usr \\\\\\n    --with-zlib=/usr \\\\\\n    --with-bz2 \\\\\\n    --with-recode=/usr \\\\\\n    --with-apxs2=/usr/bin/apxs2 \\\\\\n    --with-mysqli=/usr/bin/mysql_config \\\\\\n    --with-ldap \\\\\\n```\\n\\nTutaj doinstalowywałem albo linkowałem 19 dodatkowych paczek.\\n\\n| Problem                          | Rozwiązanie                                     |\\n| -------------------------------- | ----------------------------------------------- |\\n| checking for gcc... no           | apt-get install gcc                             |\\n| bison is required                | apt-get install bison                           |\\n| /usr/bin/apxs: No such file      | apt-get install apache2-dev                     |\\n| xml2-config not found            | apt-get install libxml2-dev                     |\\n| Cannot find OpenSSL's <evp.h>    | apt-get install libssl-dev                      |\\n| Cannot find OpenSSL's libraries  | apt-get install pkg-config                      |\\n| Please reinstall the BZip2       | apt-get install libbz2-dev                      |\\n| easy.h should be in `<curl-dir>` | apt-get install libcurl4-gnutls-dev             |\\n| jpeglib.h not found.             | apt-get install libjpeg-dev                     |\\n| png.h not found                  | apt-get install libpng-dev                      |\\n| xpm.h not found                  | apt-get install libxpm-devel                    |\\n| freetype-config not found        | apt-get install libfreetype6-dev                |\\n| Unable to locate gmp.h           | apt-get install libgmp-dev *1                   |\\n| Unable to detect ICU             | apt-get install libicu-dev                      |\\n| Cannot find ldap                 | *2                                              |\\n| mcrypt.h not found               | apt-get install libmcrypt-dev                   |\\n| mysql_config not found           | apt-get install mysql-server libmysqlclient-dev |\\n| Cannot find pspell               | apt-get install libpspell-dev                   |\\n| Can not find recode.h            | apt-get install librecode-dev                   |\\n\\nGwiazdki związane są z tym, że mimo, że pakiety są zainstalowane, instalator `php` ich nie wykrywa. W tym przypadku problem można rozwiązać dowiązując je symbolicznie do lokalizacji przeszukiwanych przez instalator.\\n\\n```\\nln -sf /usr/include/x86_64-linux-gnu/gmp.h /usr/include/gmp.h\\nln -sf /usr/lib/x86_64-linux-gnu/liblber.so /usr/lib/liblber.so\\n```\\n\\n\\n### Kompilacja\\n\\nJeśli teraz wykonamy kompilacje, to mimo pozytywnie zakończonej konfiguracji wyrzuci ona następujący błąd\\n\\n```\\n/usr/bin/ld: ext/ldap/.libs/ldap.o: undefined reference to symbol 'ber_scanf@@OPENLDAP_2.4_2'\\n/usr/lib/x86_64-linux-gnu/liblber-2.4.so.2: error adding symbols: DSO missing from command line\\ncollect2: error: ld returned 1 exit status\\nMakefile:289: polecenia dla obiektu 'sapi/cli/php' nie powiodły się\\nmake: *** [sapi/cli/php] Błąd 1\\n```\\n\\nProblem ten rozwiązujemy doinstalowaniem `apache2`, ale, żeby przejść dalej wymagane jest ponowne wykonanie całej konfiguracji od początku. Przed samą kompilacją czyścimy wyniki wcześniejszych niepowodzeń.\\n\\n    sudo make clean\\n\\nI zaprzęgamy do kompilacji tak wiele procesorów jak to tylko możliwe\\n\\n    sudo make -j `cat /proc/cpuinfo | grep processor | wc -l`\\n\\nDawno nie było obrazka więc oto screen z kompilacji:\\n\\n![komplacja](http://i.imgur.com/5HPC4MC.png)\\n\\nPonieważ kompilowałem zalogowany przez `ssh` na wspomnianego laptopa, oraz maszynę wirtualną jednocześnie, mamy trzy htopy po prawej: pierwszy z 2 procesorami (notebook), środkowy z 1 procesorem (wirtualka), ostatni z 8 (maszyna lokalna na której piszę). Widać, jak mój główny komputer (trzeci htop) przerzuca sobie w tym momencie zadanie kompilacji wykonywane na maszynie wirtualnej między dwoma fizycznymi rdzeniami. \\n\\nJest to stosunkowo długi proces, może zająć kilka do kilkunastu minut w zależności od sprzętu. Jest to dobry moment, żeby się zrelaksować. Kompilacja kończy się wyświetlaniem komunikatu:\\n\\n```\\nBuild complete.\\nDon't forget to run 'make test'.\\n```\\n\\nTesty trwają kilka minut, ale nie wpływają na końcowy wynik. Wszystkie źródła z których korzystałem pomijały ten krok. Niezależnie od tego czy przetestujesz swojego `php` czy nie następnym ważnym krokiem po kompilacji jest instalacja. \\n\\n    sudo make install\\n\\nŻeby \\t`php` trafił do odpowiednich lokalizacji wpisujemy:\\n\\n```\\nsudo update-alternatives --install /usr/bin/php php /usr/local/php/7.0/bin/php 50 --slave /usr/share/man/man1/php.1.gz php.1.gz /usr/local/php/7.0/php/man/man1/php.1\\n```\\n\\nJeśli w tym momencie zapytamy system o wersję `php` dostaniemy \\n\\n```\\n# php -v\\nPHP 7.0.14 (cli) (built: Dec 18 2016 21:56:13) ( NTS )\\nCopyright (c) 1997-2016 The PHP Group\\nZend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies\\n```\\n\\nJednak nie będzie on działał na stronach internetowych. Żeby to naprawić  konfigurujemy mouły apache2. \\n\\n### Podłączenie do Apache2\\n\\nZaczniemy od dodania pliku `/etc/apache2/mods-available/php7.conf` o treści:\\n\\n```\\n<FilesMatch \\\".+\\\\.ph(p[3457]?|t|tml)$\\\">\\n    SetHandler application/x-httpd-php\\n</FilesMatch>\\n<FilesMatch \\\".+\\\\.phps$\\\">\\n    SetHandler application/x-httpd-php-source\\n    # Deny access to raw php sources by default\\n    # To re-enable it's recommended to enable access to the files\\n    # only in specific virtual host or directory\\n    Require all denied\\n</FilesMatch>\\n<FilesMatch \\\"^\\\\.ph(p[345]?|t|tml|ps)$\\\">\\n    Require all denied\\n</FilesMatch>\\n```\\n\\na następnie powłączamy i powyłączamy odpowiednie moduły.\\n\\n```\\na2dismod mpm_event\\na2enmod mpm_prefork\\na2enmod php7\\n```\\n\\nI restartujemy go:\\n\\n    service apache2 restart\\n\\nŻeby sprawdzić, czy wszystko gra w katalogu `/var/www/html` zastępujemy plik `index.html` plikiem `index.php` o treści\\n\\n```\\n5=<?php\\necho 2+3;\\n```\\n\\nCałość procesu kompilacji można obejrzeć na poniższym video:\\n\\n\"}],[\"html\",{\"html\":\"<video src=\\\"https://www.dropbox.com/s/cbna5xb718oaqp6/8.mp4?dl=1\\\" controls></video>\"}],[\"markdown\",{\"markdown\":\"### Gist ze skryptami\\n\\nŻeby nie wykonywać wszystkich komend ręcznie załączam [gist](https://gist.github.com/gustawdaniel/79aae802d0c99ba3ef633efa441d5863) z skryptami. Mamy tam trzy pliki:\\n\\n```\\n├── php7.conf\\n├── php_install.sh\\n└── send.sh\\n```\\n\\nJeśli chcemy startować z maszyny lokalnej, to ściągamy je lokalnie do tego samego folderu i edytujemy `send.sh` wpisując tam `ip` maszyny na której chcemy przeprowadzić instalację. Skrypt `send.sh` wysyła pliki `php7.conf` i `php_install.sh` na maszynę wirtualną do lokacji `/ust/src`. Możemy też ściągnąć `php7.conf` i `php_install.sh` do `/usr/src` maszyny wirtualnej od razu.\\n\\nTam wykonujemy `php_install.sh`, który doinstalowuje potrzebne paczki, ściąga źródła, przeprowadza konfiguracje i kompilację, instalację `php`, na koniec kopiuje `php7.conf` do katalogu z konfiguracją `apache` i konfiguruje go tak, aby poprawnie współpracował z `php`. \\n\\n## Źródła:\\n\\nPrzy pisaniu tego wpisu skorzystałem z pomocy dziesiątek ludzi, którzy na swoich blogach, w różnych społecznościach Stacka, czy w dyskusjach na Githubie rozwiązywali problemy z kompilacją nie chcąc za to żadnego wynagrodzenia. Jestem im wszystkim ogromnie wdzięczny. Nie jestem w stanie wymienić ich wszystkich dlatego podam tylko kilka źródeł, które pomogły mi najbardziej: \\n\\n+ [Kompilacja PHP 7 Na Cent OS](http://www.shaunfreeman.name/compiling-php-7-on-centos/)\\n+ [Kompilacja PHP 7 Na Ubuntu](https://gist.github.com/m1st0/1c41b8d0eb42169ce71a)\\n+ [Logowanie jako root przez SSH](https://linuxconfig.org/enable-ssh-root-login-on-debian-linux-server)\\n+ [Zapamiętanie hasła do SSH](http://www.linuxproblem.org/art_9.html)\\n+ [Oficjalna lista zależności PHP](http://php.net/manual/en/install.unix.php)\\n+ [Konfiguracja Apache przy kompilacji PHP](https://docs.moodle.org/32/en/Compiling_PHP_from_source)\\n+ [AskUbuntu](http://askubuntu.com/questions/760907/upgrade-to-16-04-php7-not-working-in-browser)\\n\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[10,5],[10,6],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"instalacja-bunsenlabs\">Instalacja Bunsenlabs</h2>\n<p>Zwykle używam Ubuntu, czasem Debiana. Jednak na jednym komputerze postawiłem dystrybucję <a href=\"https://www.bunsenlabs.org/index.html\">Bunsenlabs</a>. Jest to notebook, którego kupiłem za 400 zł jako maszynę do pisania podczas podróży. Gnome3 jest dla niego za ciężki, a <a href=\"http://openbox.org/wiki/Main_Page\">Openbox</a> zainstalowany w Bunshenlabs wprost przeciwnie - daje mu nowe życie. Wygląda przy tym naprawdę dobrze:</p>\n<p><img src=\"https://www.bunsenlabs.org/img/frontpage-gallery/hydrogen2.jpg\" alt=\"Bunshenlabs\" loading=\"lazy\"></p>\n<p>W tym artykule zainstalujemy <code>Bunsenlabs</code> na maszynie wirtualnej.</p>\n<p>Zaczniemy od pobrania dystrybucji ze strony: <a href=\"https://www.bunsenlabs.org/installation.html\">https://www.bunsenlabs.org/installation.html</a></p>\n<p><a href=\"https://www.bunsenlabs.org/installation.html\"><img src=\"http://i.imgur.com/v4SafV3.png\" alt=\"instalacja\" loading=\"lazy\"></a></p>\n<p>Wybieramy <code>bl-Hydrogen-amd64_20160710.iso</code> i pobieramy (najlepiej przez klienta sieci Torrent). Cały proces instalacji od włączenia <code>VirtualBoxa</code> do skonfigurowania środowiska przedstawiony jest na poniższym video.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: html--><video src=\"https://www.dropbox.com/s/52o1vqiqsm04opi/6.ogv?dl=1\" controls></video><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>Kluczowym momentem było pominięcie instalacji <code>LAPMA</code> kiedy zorientowałem się, że <code>php</code> występuje tam w wersji <code>5</code>. Żeby mieć wersję <code>7</code> będziemy go teraz kompilować.</p>\n<h2 id=\"po%C5%82%C4%85czenie-do-virtualboxa-przez-ssh\">Połączenie do Virtualboxa przez SSH</h2>\n<p>Wyłączymy teraz maszynę wirtualną, żeby zmienić jej ustawienia sieciowe. Zaznaczamy naszą maszynę w panelu VirtualBoxa. Wybieramy ustawienia wciskając kombinację <code>ctr+s</code>. W zakładce <code>sieć</code> zmieniamy <code>NAT</code> na <code>Mostkowa karta sieciowa (bridget)</code>. Klikamy <code>Ok</code> i ponownie włączamy maszynę.</p>\n<p><strong>Maszyna wirtualna:</strong></p>\n<p>Instalujemy serwer <code>ssh</code> na maszynie wirtualnej</p>\n<pre><code>sudo apt-get install openssh-server \n</code></pre>\n<p>Żeby sprawdzić czy wszystko jest ok, wpisujemy</p>\n<pre><code>netstat -lnpt | grep 22\n</code></pre>\n<p>Żeby sprawdzić jakie <code>ip</code> dostaliśmy wpisujemy komendę:</p>\n<pre><code>ifconfig\n</code></pre>\n<p>Żeby umożliwić logowanie jako root przez ssh edytujemy plik z ustawieniami logowania</p>\n<pre><code>sudo nano /etc/ssh/sshd_config\n</code></pre>\n<p>Zmieniamy linię</p>\n<pre><code>PermitRootLogin without-password\n</code></pre>\n<p>na</p>\n<pre><code>PermitRootLogin yes \n</code></pre>\n<p>Restartujemy <code>ssh</code></p>\n<pre><code>sudo /etc/init.d/ssh restart\n</code></pre>\n<p>I tworzymy katalog dla kluczy roota:</p>\n<pre><code>sudo mkdir -p /root/.ssh\n</code></pre>\n<p>Ustawiamy hasło roota</p>\n<pre><code>sudo su &amp;&amp; passwd\n</code></pre>\n<p><strong>Maszyna lokalna</strong></p>\n<p>Na naszym komputerze zapisujemy <code>ip</code> do zmiennych środowiskowych. Do <code>~/.bashrc</code> dodajemy linie które mogą wyglądać na przykład tak:</p>\n<pre><code>ip_hy=&quot;192.168.0.11&quot;             # ip of hydrogen_x86_64\nalias 'sh_hy'='ssh root@$ip_hy'  # ssh shortcut\n</code></pre>\n<p>resetujemy zmienne powłoki wpisując:</p>\n<pre><code>bash\n</code></pre>\n<p>Autoryzujemy dostęp z maszyny lokalnej do wirtualnej.</p>\n<pre><code>cat ~/.ssh/id_rsa.pub | sh_hy 'cat &gt;&gt; .ssh/authorized_keys'\n</code></pre>\n<p>Wpisujemy hasło roota na wirtualce i możemy już logować się do niej przez</p>\n<pre><code>sh_hy\n</code></pre>\n<p>Najważniejsze komendy zostały przedstawione na filmie zamieszczonym poniżej</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: html--><video src=\"https://www.dropbox.com/s/njf1k2ahle77pdk/7.mp4?dl=1\" controls></video><!--kg-card-end: html--><!--kg-card-begin: markdown--><h2 id=\"kompilacja-php\">Kompilacja PHP</h2>\n<p>Interpreter <a href=\"https://github.com/php/php-src\"><code>php</code></a> ma już ponad 100 000 commitów. Interesuje nas numer jego <a href=\"https://github.com/php/php-src/releases\">ostatniego wydania</a>. W momencie, w którym to piszę jest to 7.0.14. Przechodzimy do katalogu <code>/usr/src</code> i pobieramy je:</p>\n<pre><code>git clone -b PHP-7.0.14 https://github.com/php/php-src --depth 1\n</code></pre>\n<p>Repozytorium pobrane w ten sposób waży 20.8 MB. Gdybyśmy nie wybrali wersji teraz, tylko zrobili <code>checkout</code> po pobraniu całości, kosztowało by to nas ponad 320 MB. Przechodzimy do katalogu <code>php-src</code>.</p>\n<h3 id=\"konfiguracja\">Konfiguracja</h3>\n<p>Checmy wygenerować plik konfiguracyjny:</p>\n<pre><code>./buildconf --force\n</code></pre>\n<p>Mógł bym od razu podać skrypt, który instaluje wszystkie zależności. Jednak bardziej przydatne - szczególnie dla osób które napotkają podane tutaj błędy - uważam wypisanie tabelki z potencjalnymi błędami jakie mogą się pojawić przy tej komendzie. Skrypt z pełną kompilacją załączę na koniec</p>\n<table>\n<thead>\n<tr>\n<th>Problem</th>\n<th>Rozwiązanie</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>make: not found</td>\n<td>apt-get install make</td>\n</tr>\n<tr>\n<td>autoconf not found.</td>\n<td>apt-get install autoconf</td>\n</tr>\n</tbody>\n</table>\n<p>Po świeżej instalacji <code>BunsenLabs</code> generacja pliku konfiguracyjnego poszła stosunkowo prosto. Wystarczyło doinstalować tylko dwie zależności. Ciekawiej było samym procesem konfiguracji:</p>\n<pre><code>./configure --prefix=/usr/local/php/7.0 \\\n    --with-config-file-path=/etc/php/7.0/apache2 \\\n    --with-config-file-scan-dir=/etc/php/7.0/apache2/conf.d \\\n    --enable-mbstring \\\n    --enable-zip \\\n    --enable-bcmath \\\n    --enable-pcntl \\\n    --enable-ftp \\\n    --enable-exif \\\n    --enable-calendar \\\n    --enable-sysvmsg \\\n    --enable-sysvsem \\\n    --enable-sysvshm \\\n    --enable-wddx \\\n    --enable-intl \\\n    --with-curl \\\n    --with-mcrypt \\\n    --with-iconv \\\n    --with-gmp \\\n    --with-pspell \\\n    --with-gd \\\n    --with-jpeg-dir=/usr \\\n    --with-png-dir=/usr \\\n    --with-zlib-dir=/usr \\\n    --with-xpm-dir=/usr \\\n    --with-freetype-dir=/usr \\\n    --enable-gd-native-ttf \\\n    --enable-gd-jis-conv \\\n    --with-openssl \\\n    --with-pdo-mysql=/usr \\\n    --with-gettext=/usr \\\n    --with-zlib=/usr \\\n    --with-bz2 \\\n    --with-recode=/usr \\\n    --with-apxs2=/usr/bin/apxs2 \\\n    --with-mysqli=/usr/bin/mysql_config \\\n    --with-ldap \\\n</code></pre>\n<p>Tutaj doinstalowywałem albo linkowałem 19 dodatkowych paczek.</p>\n<table>\n<thead>\n<tr>\n<th>Problem</th>\n<th>Rozwiązanie</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>checking for gcc... no</td>\n<td>apt-get install gcc</td>\n</tr>\n<tr>\n<td>bison is required</td>\n<td>apt-get install bison</td>\n</tr>\n<tr>\n<td>/usr/bin/apxs: No such file</td>\n<td>apt-get install apache2-dev</td>\n</tr>\n<tr>\n<td>xml2-config not found</td>\n<td>apt-get install libxml2-dev</td>\n</tr>\n<tr>\n<td>Cannot find OpenSSL's &lt;evp.h&gt;</td>\n<td>apt-get install libssl-dev</td>\n</tr>\n<tr>\n<td>Cannot find OpenSSL's libraries</td>\n<td>apt-get install pkg-config</td>\n</tr>\n<tr>\n<td>Please reinstall the BZip2</td>\n<td>apt-get install libbz2-dev</td>\n</tr>\n<tr>\n<td>easy.h should be in <code>&lt;curl-dir&gt;</code></td>\n<td>apt-get install libcurl4-gnutls-dev</td>\n</tr>\n<tr>\n<td>jpeglib.h not found.</td>\n<td>apt-get install libjpeg-dev</td>\n</tr>\n<tr>\n<td>png.h not found</td>\n<td>apt-get install libpng-dev</td>\n</tr>\n<tr>\n<td>xpm.h not found</td>\n<td>apt-get install libxpm-devel</td>\n</tr>\n<tr>\n<td>freetype-config not found</td>\n<td>apt-get install libfreetype6-dev</td>\n</tr>\n<tr>\n<td>Unable to locate gmp.h</td>\n<td>apt-get install libgmp-dev *1</td>\n</tr>\n<tr>\n<td>Unable to detect ICU</td>\n<td>apt-get install libicu-dev</td>\n</tr>\n<tr>\n<td>Cannot find ldap</td>\n<td>*2</td>\n</tr>\n<tr>\n<td>mcrypt.h not found</td>\n<td>apt-get install libmcrypt-dev</td>\n</tr>\n<tr>\n<td>mysql_config not found</td>\n<td>apt-get install mysql-server libmysqlclient-dev</td>\n</tr>\n<tr>\n<td>Cannot find pspell</td>\n<td>apt-get install libpspell-dev</td>\n</tr>\n<tr>\n<td>Can not find recode.h</td>\n<td>apt-get install librecode-dev</td>\n</tr>\n</tbody>\n</table>\n<p>Gwiazdki związane są z tym, że mimo, że pakiety są zainstalowane, instalator <code>php</code> ich nie wykrywa. W tym przypadku problem można rozwiązać dowiązując je symbolicznie do lokalizacji przeszukiwanych przez instalator.</p>\n<pre><code>ln -sf /usr/include/x86_64-linux-gnu/gmp.h /usr/include/gmp.h\nln -sf /usr/lib/x86_64-linux-gnu/liblber.so /usr/lib/liblber.so\n</code></pre>\n<h3 id=\"kompilacja\">Kompilacja</h3>\n<p>Jeśli teraz wykonamy kompilacje, to mimo pozytywnie zakończonej konfiguracji wyrzuci ona następujący błąd</p>\n<pre><code>/usr/bin/ld: ext/ldap/.libs/ldap.o: undefined reference to symbol 'ber_scanf@@OPENLDAP_2.4_2'\n/usr/lib/x86_64-linux-gnu/liblber-2.4.so.2: error adding symbols: DSO missing from command line\ncollect2: error: ld returned 1 exit status\nMakefile:289: polecenia dla obiektu 'sapi/cli/php' nie powiodły się\nmake: *** [sapi/cli/php] Błąd 1\n</code></pre>\n<p>Problem ten rozwiązujemy doinstalowaniem <code>apache2</code>, ale, żeby przejść dalej wymagane jest ponowne wykonanie całej konfiguracji od początku. Przed samą kompilacją czyścimy wyniki wcześniejszych niepowodzeń.</p>\n<pre><code>sudo make clean\n</code></pre>\n<p>I zaprzęgamy do kompilacji tak wiele procesorów jak to tylko możliwe</p>\n<pre><code>sudo make -j `cat /proc/cpuinfo | grep processor | wc -l`\n</code></pre>\n<p>Dawno nie było obrazka więc oto screen z kompilacji:</p>\n<p><img src=\"http://i.imgur.com/5HPC4MC.png\" alt=\"komplacja\" loading=\"lazy\"></p>\n<p>Ponieważ kompilowałem zalogowany przez <code>ssh</code> na wspomnianego laptopa, oraz maszynę wirtualną jednocześnie, mamy trzy htopy po prawej: pierwszy z 2 procesorami (notebook), środkowy z 1 procesorem (wirtualka), ostatni z 8 (maszyna lokalna na której piszę). Widać, jak mój główny komputer (trzeci htop) przerzuca sobie w tym momencie zadanie kompilacji wykonywane na maszynie wirtualnej między dwoma fizycznymi rdzeniami.</p>\n<p>Jest to stosunkowo długi proces, może zająć kilka do kilkunastu minut w zależności od sprzętu. Jest to dobry moment, żeby się zrelaksować. Kompilacja kończy się wyświetlaniem komunikatu:</p>\n<pre><code>Build complete.\nDon't forget to run 'make test'.\n</code></pre>\n<p>Testy trwają kilka minut, ale nie wpływają na końcowy wynik. Wszystkie źródła z których korzystałem pomijały ten krok. Niezależnie od tego czy przetestujesz swojego <code>php</code> czy nie następnym ważnym krokiem po kompilacji jest instalacja.</p>\n<pre><code>sudo make install\n</code></pre>\n<p>Żeby \t<code>php</code> trafił do odpowiednich lokalizacji wpisujemy:</p>\n<pre><code>sudo update-alternatives --install /usr/bin/php php /usr/local/php/7.0/bin/php 50 --slave /usr/share/man/man1/php.1.gz php.1.gz /usr/local/php/7.0/php/man/man1/php.1\n</code></pre>\n<p>Jeśli w tym momencie zapytamy system o wersję <code>php</code> dostaniemy</p>\n<pre><code># php -v\nPHP 7.0.14 (cli) (built: Dec 18 2016 21:56:13) ( NTS )\nCopyright (c) 1997-2016 The PHP Group\nZend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies\n</code></pre>\n<p>Jednak nie będzie on działał na stronach internetowych. Żeby to naprawić  konfigurujemy mouły apache2.</p>\n<h3 id=\"pod%C5%82%C4%85czenie-do-apache2\">Podłączenie do Apache2</h3>\n<p>Zaczniemy od dodania pliku <code>/etc/apache2/mods-available/php7.conf</code> o treści:</p>\n<pre><code>&lt;FilesMatch &quot;.+\\.ph(p[3457]?|t|tml)$&quot;&gt;\n    SetHandler application/x-httpd-php\n&lt;/FilesMatch&gt;\n&lt;FilesMatch &quot;.+\\.phps$&quot;&gt;\n    SetHandler application/x-httpd-php-source\n    # Deny access to raw php sources by default\n    # To re-enable it's recommended to enable access to the files\n    # only in specific virtual host or directory\n    Require all denied\n&lt;/FilesMatch&gt;\n&lt;FilesMatch &quot;^\\.ph(p[345]?|t|tml|ps)$&quot;&gt;\n    Require all denied\n&lt;/FilesMatch&gt;\n</code></pre>\n<p>a następnie powłączamy i powyłączamy odpowiednie moduły.</p>\n<pre><code>a2dismod mpm_event\na2enmod mpm_prefork\na2enmod php7\n</code></pre>\n<p>I restartujemy go:</p>\n<pre><code>service apache2 restart\n</code></pre>\n<p>Żeby sprawdzić, czy wszystko gra w katalogu <code>/var/www/html</code> zastępujemy plik <code>index.html</code> plikiem <code>index.php</code> o treści</p>\n<pre><code>5=&lt;?php\necho 2+3;\n</code></pre>\n<p>Całość procesu kompilacji można obejrzeć na poniższym video:</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: html--><video src=\"https://www.dropbox.com/s/cbna5xb718oaqp6/8.mp4?dl=1\" controls></video><!--kg-card-end: html--><!--kg-card-begin: markdown--><h3 id=\"gist-ze-skryptami\">Gist ze skryptami</h3>\n<p>Żeby nie wykonywać wszystkich komend ręcznie załączam <a href=\"https://gist.github.com/gustawdaniel/79aae802d0c99ba3ef633efa441d5863\">gist</a> z skryptami. Mamy tam trzy pliki:</p>\n<pre><code>├── php7.conf\n├── php_install.sh\n└── send.sh\n</code></pre>\n<p>Jeśli chcemy startować z maszyny lokalnej, to ściągamy je lokalnie do tego samego folderu i edytujemy <code>send.sh</code> wpisując tam <code>ip</code> maszyny na której chcemy przeprowadzić instalację. Skrypt <code>send.sh</code> wysyła pliki <code>php7.conf</code> i <code>php_install.sh</code> na maszynę wirtualną do lokacji <code>/ust/src</code>. Możemy też ściągnąć <code>php7.conf</code> i <code>php_install.sh</code> do <code>/usr/src</code> maszyny wirtualnej od razu.</p>\n<p>Tam wykonujemy <code>php_install.sh</code>, który doinstalowuje potrzebne paczki, ściąga źródła, przeprowadza konfiguracje i kompilację, instalację <code>php</code>, na koniec kopiuje <code>php7.conf</code> do katalogu z konfiguracją <code>apache</code> i konfiguruje go tak, aby poprawnie współpracował z <code>php</code>.</p>\n<h2 id=\"%C5%BAr%C3%B3d%C5%82a\">Źródła:</h2>\n<p>Przy pisaniu tego wpisu skorzystałem z pomocy dziesiątek ludzi, którzy na swoich blogach, w różnych społecznościach Stacka, czy w dyskusjach na Githubie rozwiązywali problemy z kompilacją nie chcąc za to żadnego wynagrodzenia. Jestem im wszystkim ogromnie wdzięczny. Nie jestem w stanie wymienić ich wszystkich dlatego podam tylko kilka źródeł, które pomogły mi najbardziej:</p>\n<ul>\n<li><a href=\"http://www.shaunfreeman.name/compiling-php-7-on-centos/\">Kompilacja PHP 7 Na Cent OS</a></li>\n<li><a href=\"https://gist.github.com/m1st0/1c41b8d0eb42169ce71a\">Kompilacja PHP 7 Na Ubuntu</a></li>\n<li><a href=\"https://linuxconfig.org/enable-ssh-root-login-on-debian-linux-server\">Logowanie jako root przez SSH</a></li>\n<li><a href=\"http://www.linuxproblem.org/art_9.html\">Zapamiętanie hasła do SSH</a></li>\n<li><a href=\"http://php.net/manual/en/install.unix.php\">Oficjalna lista zależności PHP</a></li>\n<li><a href=\"https://docs.moodle.org/32/en/Compiling_PHP_from_source\">Konfiguracja Apache przy kompilacji PHP</a></li>\n<li><a href=\"http://askubuntu.com/questions/760907/upgrade-to-16-04-php7-not-working-in-browser\">AskUbuntu</a></li>\n</ul>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f37552fb35425592d0b8f",
            "plaintext": "Instalacja Bunsenlabs\nZwykle używam Ubuntu, czasem Debiana. Jednak na jednym komputerze postawiłem\ndystrybucję Bunsenlabs [https://www.bunsenlabs.org/index.html]. Jest to\nnotebook, którego kupiłem za 400 zł jako maszynę do pisania podczas podróży.\nGnome3 jest dla niego za ciężki, a Openbox [http://openbox.org/wiki/Main_Page] \nzainstalowany w Bunshenlabs wprost przeciwnie - daje mu nowe życie. Wygląda przy\ntym naprawdę dobrze:\n\n\n\nW tym artykule zainstalujemy Bunsenlabs na maszynie wirtualnej.\n\nZaczniemy od pobrania dystrybucji ze strony: \nhttps://www.bunsenlabs.org/installation.html\n\n [https://www.bunsenlabs.org/installation.html]\n\nWybieramy bl-Hydrogen-amd64_20160710.iso i pobieramy (najlepiej przez klienta\nsieci Torrent). Cały proces instalacji od włączenia VirtualBoxa do\nskonfigurowania środowiska przedstawiony jest na poniższym video.\n\nKluczowym momentem było pominięcie instalacji LAPMA kiedy zorientowałem się, że \nphp występuje tam w wersji 5. Żeby mieć wersję 7 będziemy go teraz kompilować.\n\nPołączenie do Virtualboxa przez SSH\nWyłączymy teraz maszynę wirtualną, żeby zmienić jej ustawienia sieciowe.\nZaznaczamy naszą maszynę w panelu VirtualBoxa. Wybieramy ustawienia wciskając\nkombinację ctr+s. W zakładce sieć zmieniamy NAT na Mostkowa karta sieciowa\n(bridget). Klikamy Ok i ponownie włączamy maszynę.\n\nMaszyna wirtualna:\n\nInstalujemy serwer ssh na maszynie wirtualnej\n\nsudo apt-get install openssh-server \n\n\nŻeby sprawdzić czy wszystko jest ok, wpisujemy\n\nnetstat -lnpt | grep 22\n\n\nŻeby sprawdzić jakie ip dostaliśmy wpisujemy komendę:\n\nifconfig\n\n\nŻeby umożliwić logowanie jako root przez ssh edytujemy plik z ustawieniami\nlogowania\n\nsudo nano /etc/ssh/sshd_config\n\n\nZmieniamy linię\n\nPermitRootLogin without-password\n\n\nna\n\nPermitRootLogin yes \n\n\nRestartujemy ssh\n\nsudo /etc/init.d/ssh restart\n\n\nI tworzymy katalog dla kluczy roota:\n\nsudo mkdir -p /root/.ssh\n\n\nUstawiamy hasło roota\n\nsudo su && passwd\n\n\nMaszyna lokalna\n\nNa naszym komputerze zapisujemy ip do zmiennych środowiskowych. Do ~/.bashrc \ndodajemy linie które mogą wyglądać na przykład tak:\n\nip_hy=\"192.168.0.11\"             # ip of hydrogen_x86_64\nalias 'sh_hy'='ssh root@$ip_hy'  # ssh shortcut\n\n\nresetujemy zmienne powłoki wpisując:\n\nbash\n\n\nAutoryzujemy dostęp z maszyny lokalnej do wirtualnej.\n\ncat ~/.ssh/id_rsa.pub | sh_hy 'cat >> .ssh/authorized_keys'\n\n\nWpisujemy hasło roota na wirtualce i możemy już logować się do niej przez\n\nsh_hy\n\n\nNajważniejsze komendy zostały przedstawione na filmie zamieszczonym poniżej\n\nKompilacja PHP\nInterpreter php [https://github.com/php/php-src] ma już ponad 100 000 commitów.\nInteresuje nas numer jego ostatniego wydania\n[https://github.com/php/php-src/releases]. W momencie, w którym to piszę jest to\n7.0.14. Przechodzimy do katalogu /usr/src i pobieramy je:\n\ngit clone -b PHP-7.0.14 https://github.com/php/php-src --depth 1\n\n\nRepozytorium pobrane w ten sposób waży 20.8 MB. Gdybyśmy nie wybrali wersji\nteraz, tylko zrobili checkout po pobraniu całości, kosztowało by to nas ponad\n320 MB. Przechodzimy do katalogu php-src.\n\nKonfiguracja\nChecmy wygenerować plik konfiguracyjny:\n\n./buildconf --force\n\n\nMógł bym od razu podać skrypt, który instaluje wszystkie zależności. Jednak\nbardziej przydatne - szczególnie dla osób które napotkają podane tutaj błędy -\nuważam wypisanie tabelki z potencjalnymi błędami jakie mogą się pojawić przy tej\nkomendzie. Skrypt z pełną kompilacją załączę na koniec\n\nProblemRozwiązaniemake: not foundapt-get install makeautoconf not found.apt-get\ninstall autoconfPo świeżej instalacji BunsenLabs generacja pliku konfiguracyjnego poszła\nstosunkowo prosto. Wystarczyło doinstalować tylko dwie zależności. Ciekawiej\nbyło samym procesem konfiguracji:\n\n./configure --prefix=/usr/local/php/7.0 \\\n    --with-config-file-path=/etc/php/7.0/apache2 \\\n    --with-config-file-scan-dir=/etc/php/7.0/apache2/conf.d \\\n    --enable-mbstring \\\n    --enable-zip \\\n    --enable-bcmath \\\n    --enable-pcntl \\\n    --enable-ftp \\\n    --enable-exif \\\n    --enable-calendar \\\n    --enable-sysvmsg \\\n    --enable-sysvsem \\\n    --enable-sysvshm \\\n    --enable-wddx \\\n    --enable-intl \\\n    --with-curl \\\n    --with-mcrypt \\\n    --with-iconv \\\n    --with-gmp \\\n    --with-pspell \\\n    --with-gd \\\n    --with-jpeg-dir=/usr \\\n    --with-png-dir=/usr \\\n    --with-zlib-dir=/usr \\\n    --with-xpm-dir=/usr \\\n    --with-freetype-dir=/usr \\\n    --enable-gd-native-ttf \\\n    --enable-gd-jis-conv \\\n    --with-openssl \\\n    --with-pdo-mysql=/usr \\\n    --with-gettext=/usr \\\n    --with-zlib=/usr \\\n    --with-bz2 \\\n    --with-recode=/usr \\\n    --with-apxs2=/usr/bin/apxs2 \\\n    --with-mysqli=/usr/bin/mysql_config \\\n    --with-ldap \\\n\n\nTutaj doinstalowywałem albo linkowałem 19 dodatkowych paczek.\n\nProblemRozwiązaniechecking for gcc... noapt-get install gccbison is required\napt-get install bison/usr/bin/apxs: No such fileapt-get install apache2-dev\nxml2-config not foundapt-get install libxml2-devCannot find OpenSSL's <evp.h>\napt-get install libssl-devCannot find OpenSSL's librariesapt-get install\npkg-configPlease reinstall the BZip2apt-get install libbz2-deveasy.h should be\nin <curl-dir>apt-get install libcurl4-gnutls-devjpeglib.h not found.apt-get\ninstall libjpeg-devpng.h not foundapt-get install libpng-devxpm.h not found\napt-get install libxpm-develfreetype-config not foundapt-get install\nlibfreetype6-devUnable to locate gmp.hapt-get install libgmp-dev *1Unable to\ndetect ICUapt-get install libicu-devCannot find ldap*2mcrypt.h not foundapt-get\ninstall libmcrypt-devmysql_config not foundapt-get install mysql-server\nlibmysqlclient-devCannot find pspellapt-get install libpspell-devCan not find\nrecode.hapt-get install librecode-devGwiazdki związane są z tym, że mimo, że\npakiety są zainstalowane, instalator php ich nie wykrywa. W tym przypadku\nproblem można rozwiązać dowiązując je symbolicznie do lokalizacji\nprzeszukiwanych przez instalator.\n\nln -sf /usr/include/x86_64-linux-gnu/gmp.h /usr/include/gmp.h\nln -sf /usr/lib/x86_64-linux-gnu/liblber.so /usr/lib/liblber.so\n\n\nKompilacja\nJeśli teraz wykonamy kompilacje, to mimo pozytywnie zakończonej konfiguracji\nwyrzuci ona następujący błąd\n\n/usr/bin/ld: ext/ldap/.libs/ldap.o: undefined reference to symbol 'ber_scanf@@OPENLDAP_2.4_2'\n/usr/lib/x86_64-linux-gnu/liblber-2.4.so.2: error adding symbols: DSO missing from command line\ncollect2: error: ld returned 1 exit status\nMakefile:289: polecenia dla obiektu 'sapi/cli/php' nie powiodły się\nmake: *** [sapi/cli/php] Błąd 1\n\n\nProblem ten rozwiązujemy doinstalowaniem apache2, ale, żeby przejść dalej\nwymagane jest ponowne wykonanie całej konfiguracji od początku. Przed samą\nkompilacją czyścimy wyniki wcześniejszych niepowodzeń.\n\nsudo make clean\n\n\nI zaprzęgamy do kompilacji tak wiele procesorów jak to tylko możliwe\n\nsudo make -j `cat /proc/cpuinfo | grep processor | wc -l`\n\n\nDawno nie było obrazka więc oto screen z kompilacji:\n\n\n\nPonieważ kompilowałem zalogowany przez ssh na wspomnianego laptopa, oraz maszynę\nwirtualną jednocześnie, mamy trzy htopy po prawej: pierwszy z 2 procesorami\n(notebook), środkowy z 1 procesorem (wirtualka), ostatni z 8 (maszyna lokalna na\nktórej piszę). Widać, jak mój główny komputer (trzeci htop) przerzuca sobie w\ntym momencie zadanie kompilacji wykonywane na maszynie wirtualnej między dwoma\nfizycznymi rdzeniami.\n\nJest to stosunkowo długi proces, może zająć kilka do kilkunastu minut w\nzależności od sprzętu. Jest to dobry moment, żeby się zrelaksować. Kompilacja\nkończy się wyświetlaniem komunikatu:\n\nBuild complete.\nDon't forget to run 'make test'.\n\n\nTesty trwają kilka minut, ale nie wpływają na końcowy wynik. Wszystkie źródła z\nktórych korzystałem pomijały ten krok. Niezależnie od tego czy przetestujesz\nswojego php czy nie następnym ważnym krokiem po kompilacji jest instalacja.\n\nsudo make install\n\n\nŻebyphp trafił do odpowiednich lokalizacji wpisujemy:\n\nsudo update-alternatives --install /usr/bin/php php /usr/local/php/7.0/bin/php 50 --slave /usr/share/man/man1/php.1.gz php.1.gz /usr/local/php/7.0/php/man/man1/php.1\n\n\nJeśli w tym momencie zapytamy system o wersję php dostaniemy\n\n# php -v\nPHP 7.0.14 (cli) (built: Dec 18 2016 21:56:13) ( NTS )\nCopyright (c) 1997-2016 The PHP Group\nZend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies\n\n\nJednak nie będzie on działał na stronach internetowych. Żeby to naprawić\nkonfigurujemy mouły apache2.\n\nPodłączenie do Apache2\nZaczniemy od dodania pliku /etc/apache2/mods-available/php7.conf o treści:\n\n<FilesMatch \".+\\.ph(p[3457]?|t|tml)$\">\n    SetHandler application/x-httpd-php\n</FilesMatch>\n<FilesMatch \".+\\.phps$\">\n    SetHandler application/x-httpd-php-source\n    # Deny access to raw php sources by default\n    # To re-enable it's recommended to enable access to the files\n    # only in specific virtual host or directory\n    Require all denied\n</FilesMatch>\n<FilesMatch \"^\\.ph(p[345]?|t|tml|ps)$\">\n    Require all denied\n</FilesMatch>\n\n\na następnie powłączamy i powyłączamy odpowiednie moduły.\n\na2dismod mpm_event\na2enmod mpm_prefork\na2enmod php7\n\n\nI restartujemy go:\n\nservice apache2 restart\n\n\nŻeby sprawdzić, czy wszystko gra w katalogu /var/www/html zastępujemy plik \nindex.html plikiem index.php o treści\n\n5=<?php\necho 2+3;\n\n\nCałość procesu kompilacji można obejrzeć na poniższym video:\n\nGist ze skryptami\nŻeby nie wykonywać wszystkich komend ręcznie załączam gist\n[https://gist.github.com/gustawdaniel/79aae802d0c99ba3ef633efa441d5863] z\nskryptami. Mamy tam trzy pliki:\n\n├── php7.conf\n├── php_install.sh\n└── send.sh\n\n\nJeśli chcemy startować z maszyny lokalnej, to ściągamy je lokalnie do tego\nsamego folderu i edytujemy send.sh wpisując tam ip maszyny na której chcemy\nprzeprowadzić instalację. Skrypt send.sh wysyła pliki php7.conf i php_install.sh \nna maszynę wirtualną do lokacji /ust/src. Możemy też ściągnąć php7.conf i \nphp_install.sh do /usr/src maszyny wirtualnej od razu.\n\nTam wykonujemy php_install.sh, który doinstalowuje potrzebne paczki, ściąga\nźródła, przeprowadza konfiguracje i kompilację, instalację php, na koniec\nkopiuje php7.conf do katalogu z konfiguracją apache i konfiguruje go tak, aby\npoprawnie współpracował z php.\n\nŹródła:\nPrzy pisaniu tego wpisu skorzystałem z pomocy dziesiątek ludzi, którzy na swoich\nblogach, w różnych społecznościach Stacka, czy w dyskusjach na Githubie\nrozwiązywali problemy z kompilacją nie chcąc za to żadnego wynagrodzenia. Jestem\nim wszystkim ogromnie wdzięczny. Nie jestem w stanie wymienić ich wszystkich\ndlatego podam tylko kilka źródeł, które pomogły mi najbardziej:\n\n * Kompilacja PHP 7 Na Cent OS\n   [http://www.shaunfreeman.name/compiling-php-7-on-centos/]\n * Kompilacja PHP 7 Na Ubuntu\n   [https://gist.github.com/m1st0/1c41b8d0eb42169ce71a]\n * Logowanie jako root przez SSH\n   [https://linuxconfig.org/enable-ssh-root-login-on-debian-linux-server]\n * Zapamiętanie hasła do SSH [http://www.linuxproblem.org/art_9.html]\n * Oficjalna lista zależności PHP [http://php.net/manual/en/install.unix.php]\n * Konfiguracja Apache przy kompilacji PHP\n   [https://docs.moodle.org/32/en/Compiling_PHP_from_source]\n * AskUbuntu\n   [http://askubuntu.com/questions/760907/upgrade-to-16-04-php7-not-working-in-browser]",
            "feature_image": "__GHOST_URL__/content/images/2021/06/1200x800_blog-1-768x512.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:19:33.000Z",
            "updated_at": "2021-06-21T17:02:31.000Z",
            "published_at": "2021-05-07T20:30:00.000Z",
            "custom_excerpt": "Samodzielna kompilacja to proces, który czasami wymaga instalacji kilku paczek lub linkowania niektórych zależności. W tym przypadku zadanie polegało na dostarczeniu php7, na system na który nie miał go w dostępnych repozytoriach.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f39282fb35425592d0ba8",
            "uuid": "026aecc0-b9cb-4415-a7b0-8353a905e87c",
            "title": "Fetch, Promise oraz  Template String",
            "slug": "fetch-promise-oraz-string-templates",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Opis projektu\\n\\nProjekt prezentuje zastosowanie interfejsu `fetch`, przykłady użycia `promise` oraz kilka sztuczek cssowych jak własności `transform`, `user-select` czy dyrektywa `@media`.\\n\\nSkład kodu źródłowego:\\n\\n    JavaScript 49.5% CSS 40.3% HTML 10.2%\\n\\nPo napisaniu projekt będzie wyglądał tak:\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/1_qm93PtCN3Y0mZWzQrqVAFw.png\",\"width\":666,\"height\":447,\"caption\":\"To Do List typed in pure JavaScript that will be presented in this article.\"}],[\"markdown\",{\"markdown\":\"## Instalacja\\n\\nJeśli chcesz przetestować kod u siebie bez jego przepisywania najszybciej będzie ściągnąć release komendą\\n\\n    wget -qO- https://github.com/gustawdaniel/simple_todo_app_js/archive/1.0.tar.gz | tar xvz\\n\\nNastępnie należy przejść do utworzonego katalogu\\n\\n    cd simple-todo-app-js-tutorial-1.0\\n\\nTeraz należy zainstalować zależności\\n\\n    npm i\\n\\nŻeby rozstawić serwery będziemy potrzebowali dwóch terminali. W pierwszym stawiamy serwer z naszym projektem\\n\\n    node node_modules/http-server/bin/http-server\\n\\nW drugim terminalu (`ctrl+n`) stawiamy serwer REST API z pozwalający używać bazy danych\\n\\n    node node_modules/json-server/bin/index.js --watch db.json\\n\\nJeśli wszystko poszło dobrze powinniśmy zobaczyć coś takiego:\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/1_PD3FHn76We8mFzIivvnpvg.png\",\"width\":800,\"height\":264,\"caption\":\"Server with application (on the right) and with REST API connected with db.json file (on the left)\"}],[\"markdown\",{\"markdown\":\"Strona powinna być dostępna pod adresem [`localhost:8080`](http://localhost:8080)\\n\\n## Struktura projektu\\n\\nProjekt zawiera następujące pliki\\n\\n```\\n├── app.js              // skrypt obsługujący pobieranie, tworzenie i usuwanie wpisów\\n├── db.json             // plik json z danymi do którego dostajemy się przez API\\n├── index.html          // plik html ze stroną\\n├── LICENSE             // licencje WTFPL\\n├── package.json        // plik z zależnościami do zainstalowania, tutaj serwer http i json\\n├── README.md           // instrukcja z komendami do obsługi serwera\\n└── style.css           // style\\n```\\n\\nWidać, że jest bardzo prosty. Możliwości jakie daje strona to\\n\\n+ tworzenie wpisów\\n+ wyświetlanie wpisów\\n+ usuwanie wpisów\\n\\nW kolejnym rozdziale opiszemy zawartość plików `index.html` oraz `style.css`. Później omówimy serwery jakie postawiliśmy, rolę pliku `db.json` i na końcu logikę umieszczoną w pliku `app.js`.\\n\\n## Statyczny dokument\\n\\nPlik `index.html` zaczyna się dość klasycznie. Pobieramy czcionkę `Lato` oraz załączamy nasz customowy styl.\\n\\n```html\\n<html>\\n<head>\\n    <link href=\\\"https://fonts.googleapis.com/css?family=Lato:300&amp;subset=latin-ext\\\" rel=\\\"stylesheet\\\">\\n    <link rel=\\\"stylesheet\\\" href=\\\"style.css\\\">\\n</head>\\n```\\n\\nPonieważ kod pisany jest zgodnie z zasadami semantyki HTML5 mamy tu podział na `header` oraz `main`. W nagłówku znajduje się formularz z jednym polem do wpisywania teksu notatek.\\n\\n```html\\n<body>\\n<header>\\n    <form class=\\\"todo\\\">\\n        <input name=\\\"task\\\" type=\\\"text\\\" placeholder=\\\"Type text to add note\\\">\\n    </form>\\n</header>\\n```\\n\\nW części `main` znajduje się lista z trzema przykładowymi elementami.\\nElementy mają swoje identyfikatory i są podzielone na dwie części\\npierwsza zawiera identyfikator, druga tekst oraz przycisk do usuwania\\nnotatki.\\n\\n```html\\n<main>\\n  <ul>\\n    <li data-id=\\\"1\\\">\\n      <div class=\\\"list-elem-head\\\">\\n          <span class=\\\"id\\\">1</span>\\n      </div>\\n      <div class=\\\"list-elem-body\\\">\\n          <span class=\\\"text\\\">First One</span>\\n          <span class=\\\"delete\\\">x</span>\\n      </div>\\n    </li>\\n    <li data-id=\\\"2\\\">\\n      <div class=\\\"list-elem-head\\\">\\n          <span class=\\\"id\\\">2</span>\\n      </div>\\n      <div class=\\\"list-elem-body\\\">\\n          <span class=\\\"text\\\">Second todo</span>\\n          <span class=\\\"delete\\\">x</span>\\n      </div>\\n    </li>\\n    <li data-id=\\\"5\\\">\\n      <div class=\\\"list-elem-head\\\">\\n          <span class=\\\"id\\\">5</span>\\n      </div>\\n      <div class=\\\"list-elem-body\\\">\\n          <span class=\\\"text\\\">At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa qui officia deserunt mollitia animi, id est laborum et dolorum fuga. Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et voluptates repudiandae sint et molestiae non recusandae. Itaque earum rerum hic tenetur a sapiente delectus, ut aut reiciendis voluptatibus maiores alias consequatur aut perferendis doloribus asperiores repellat.</span>\\n          <span class=\\\"delete\\\">x</span>\\n      </div>\\n    </li>\\n  </ul>\\n</main>\\n```\\n\\nNa końcu załączamy skrypt, który omówimy później. Na razie może być to pusty plik.\\n\\n```html\\n<script src=\\\"app.js\\\"></script>\\n</body>\\n</html>\\n```\\n\\nGdyby nie stylowanie, nie dało by się na to patrzeć, ale zainspirowany zajęciami z html i css, które ostatnio prowadziłem postanowiłem napisać plik css całkowicie samodzielnie od zera. Reguły które dodałem zaczynają się od ustalenia szerokości dokumentu w zależności od szerokości ekranu. Zwykle stosuje się do tego bootstrapa, ale można to robić również bez niego. Służy to tego dyrektywa `@media` której zastosowanie zaprezentowane jest poniżej:\\n\\n```css\\n@media (max-width: 575px) {\\n    input,main {\\n        width: 100%;\\n    }\\n}\\n@media (min-width: 576px) {\\n    input,main {\\n        width: 80%;\\n    }\\n    main {\\n        margin-left: 10%;\\n    }\\n}\\n```\\n\\nWidać tutaj, że na większych urządzeniach chcę mieć margines, który na mniejszych nie jest już potrzebny. Następną regułą jest zastosowanie czcionki `Lato` do całego dokumentu:\\n\\n```css\\nbody {\\n    font-family: 'Lato', sans-serif;\\n}\\n```\\n\\nW nagłówku centrujemy formularz i pozbywamy się jego naturalnych marginesów.\\n\\n```css\\nheader {\\n    text-align: center;\\n}\\nform {\\n    margin: 0;\\n}\\n```\\n\\nNastępnie definiujemy zasady podświetlania inputa na który klikniemy, albo\\nnad którym nasuniemy myszkę. Oprócz usunięcia przezroczystości z ramki mamy\\ntutaj dodanie rozmytego cienia oraz zaczerwienienie tła.\\n\\n```css\\ninput:focus, input:hover {\\n    border: solid 1px crimson;\\n    box-shadow: 0 0 5px -1px crimson;\\n    background-color: rgba(220, 20, 60, 0.05);\\n}\\n```\\n\\nInteresującą własnością nie zaznaczonego inputa jest `transition`. Pozwala ona na określenie opóźnienia z jakim dany zmienia swoją własność. Dzięki niemu zobaczymy, że tło pojawia się i znika płynnie.\\n\\n```css\\ninput {\\n    padding: 20px;\\n    border: solid 1px rgba(220, 20, 60, 0.52);\\n    margin: 10px 0;\\n    transition: box-shadow 1s, background-color 2s;\\n}\\n```\\n\\nNieco inne efekty nadane są na najechanie myszką nad element listy. Najmocniej wyróżniającym się elementem jest przesunięcie się lewej krawędzi listy w prawo co ustawiane jest we własności `margin`.\\n\\n```css\\nli:hover {\\n    border: solid 1px rgba(220, 20, 60, 0.8);\\n    background-color: rgba(220, 20, 60, 0.05);\\n    box-shadow: 0 0 2px -1px crimson;\\n    margin: 3px 0 3px 10px;\\n}\\n```\\n\\nDla porównania jeśli myszka nie znajduje się nad elementem listy margines jest symetryczny. Tutaj również zastosowano `transition` uzyskując animację wcinania i wysuwania elementu listy.\\n\\n```css\\nli {\\n    list-style: none;\\n    border: solid 1px rgba(220, 20, 60, 0.52);\\n    margin: 3px 0;\\n    color: gray;\\n    transition: margin 0.5s, background-color 2s;\\n}\\n```\\n\\nElementy listy podzielone są na dwie części, `.list-elem-head` służy do wyświetlania identyfikatora. Przestrzeń wokół rozepchana jest marginesami. Warto zwrócić też uwagę na `float: left` pozwalający divom na sąsiadowanie w jednej linii.\\n\\n```css\\n.list-elem-head {\\n    float: left;\\n    margin: 20px;\\n}\\n```\\n\\nZupełnie inaczej jest w przypadku `.list-elem-body`. Tutaj nie marginesy a paddingi odpowiadają za rozpychanie się i centrowanie względem granic elementu listy. Jest tak dlatego, że potrzebujemy pełnej wysokości elementu `.list-elem-body` wewnątrz elementu `li` aby dodać granicę `border-left`.\\n\\n```css\\n.list-elem-body {\\n    margin-left: 50px;\\n    padding: 20px 20px 20px 20px;\\n    border-left: solid 1px rgba(220, 20, 60, 0.52);\\n}\\n```\\n\\nSama lista nie potrzebuje ani marginesów, ani paddingów. Razem z `list-style: none` zastosowanym dla `li` pozbywamy się dzięki temu domyślnego stylowania list.\\n\\n```css\\nul {\\n    margin: 0;\\n    padding: 0;\\n}\\n```\\n\\nJedną z ostatnich zmian jest odsunięcie tekstu z notatką od wewnętrznej granicy elementu listy.\\n\\n```css\\nli > span.text {\\n    padding-right: 20px;\\n}\\n```\\n\\nNa koniec stylujemy przycisk do usuwania. Jest to span zawierający literę x. Nie ściągałem tu żadnych dodatkowych czcionek. Mimo to dzięki zaokrągleniu rogów, odpowiednim kolorom, paddigom i zafixowaniu wielkości elementu udało się uzyskać dość jednoznacznie wyglądający przycisk do usuwania. Jedak dodana została tu jeszcze jedna ciekawa własność: `user-select`. Pozwala ona pominąć dany element przy zaznaczaniu. Dzięki temu podwójne kliknięcie na tekst notatki nie spowoduje zaznaczenia `x` na końcu.\\n\\n```css\\nli > div > span.delete {\\n    float: right;\\n    border: solid 1px crimson;\\n    border-radius: 50%;\\n    padding: 5px;\\n    width: 7px;\\n    height: 7px;\\n    line-height: 5px;\\n    color: crimson;\\n    cursor: pointer;\\n    -moz-user-select: none;\\n    -webkit-user-select: none;\\n    -ms-user-select:none;\\n    user-select:none;\\n}\\n```\\n\\n## Logika\\n\\nTeraz omówimy w jaki sposób dodać do projektu możliwość tworzenia nowych wpisów, usuwania ich i wyświetlania wpisów zapisanych w bazie. Jeśli przyjrzymy się wycinkowi pliku `package.json` zobaczymy tam następujące linie:\\n\\n```\\n  \\\"dependencies\\\": {\\n    \\\"http-server\\\": \\\"^0.11.1\\\",\\n    \\\"json-server\\\": \\\"^0.12.1\\\"\\n  }\\n```\\n\\nPierwsza z paczek to serwer http który odpowiada za to, że pod portem 8080 wystawia się nasza aplikacja. Daje to z grubsza taki sam efekt jak napisanie `php -S localhost:8080`.\\n\\nDruga to serwer REST do obsługi bazy danych zapisanych w pliku `db.json`. W pliku `README.md` zapisane są komendy do włączania tych serwerów oraz requesty jakie należy wykonać aby dokonać zmian w bazie:\\n\\nDo dodana wpisu konieczne jest wysłanie żądania metodą POST:\\n\\n    http POST localhost:3000/todo text=\\\"First One\\\"\\n\\nŻeby wylistować wszystkie wpisy wysyłamy żądanie GET:\\n\\n    http GET localhost:3000/todo\\n\\nA w celu usunięcia n-tego wpisu metodą DELETE i wskazujemy numer wpisu w adresie URL:\\n\\n    http DELETE localhost:3000/todo/n\\n\\nSam plik `db.json` może wyglądać następująco:\\n\\n```json\\n{\\n  \\\"todo\\\": [\\n    {\\n      \\\"text\\\": \\\"First One\\\",\\n      \\\"id\\\": 1\\n    },\\n    {\\n      \\\"text\\\": \\\"Second todo\\\",\\n      \\\"id\\\": 2\\n    },\\n    {\\n      \\\"text\\\": \\\"At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa qui officia deserunt mollitia animi, id est laborum et dolorum fuga. Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et voluptates repudiandae sint et molestiae non recusandae. Itaque earum rerum hic tenetur a sapiente delectus, ut aut reiciendis voluptatibus maiores alias consequatur aut perferendis doloribus asperiores repellat.\\\",\\n      \\\"id\\\": 5\\n    }\\n  ]\\n}\\n```\\n\\nTeraz przejdziemy do omówienia logiki aplikacji umieszczonej w pliku `app.js`. Zanim jednak to nastąpi musimy wyczyścić plik `index.html` usuwając wszystko co znajduje się miedzy elementami `<ul></ul>`. Modyfikujemy html czyszcząc listę z zawartości ponieważ za dodawania zawartości odpowiadać będzie teraz skrypt w `app.js`.\\n\\nCały skrypt zawarto jest w funkjci anonimowej wykonywanej po wydarzeniu `DOMContentLoaded`.\\nZapobiega to wykonywaniu skryptu przed załadowaniem drzewa `DOM`.\\n\\n```js\\ndocument.addEventListener('DOMContentLoaded',function () {\\n\\n   // there should be placed code presented below\\n\\n})\\n```\\n\\nwewnątrz tej funkcji definiujemy zmienne które wykorzystywane będą w skrypcie. Są to `dbUrl` zawierająca adres do API zarządzającego bazą danych. Dwie kolejne zmienne zawierając formularz oraz listę.\\n\\n```js\\n    const dbUrl = 'http://localhost:3000/todo';\\n    let form = document.querySelector('form.todo');\\n    let list = document.querySelector('ul');\\n```\\n\\nTeraz czas na definiowanie przydatnych funkcji. Zaczniemy od funkcji pobierającej wszystkie notatki. Ponieważ funkcja ta wysyła request musi poczekać na jego odpowiedź, ale oczekiwanie na odpowiedź oznacza, że metodą then nadajemy nasłuch i jak by wypinamy się z synchronicznej kolejności wykonywania kolejnych linii kodu. Żeby zachować asynchroniczną naturę dobrego kodu JavaScript na kliencie nie możemy pozwolić sobie na blokowanie reszty skryptu. Sposobem na poradzenie sobie z koniecznością zwracania danych, których jeszcze nie ma jest zwracanie obietnicy ich dostarczenia czyli obiektu `Promise`. Obiekt te przyjmuje w swoim konstruktorze funkcję, której argumentem jest funkcja której jako argument powinniśmy przekazać interesujące nas dane. Widać to dobrze w poniższym kodzie:\\n\\n```js\\n    function getAllTodos() {\\n        return new Promise(resolve => {\\n            fetch(new Request(dbUrl))\\n                .then(res => { return res.json(); })\\n                .then(data => { resolve(data); });\\n        });\\n    }\\n```\\n\\nJenak `Promise` to nie jedyna ciekawa rzecz, którą można dostrzec w tych kilku liniach. Kolejną jest funkcji `fetch`. Jest to następca interfejsu XMLHttpRequest. Różni się od niego między innymi lepiej przemyślaną i nowocześniejszą składnią, lepszym wsparciem dla przetwarzania strumieni danych. Argumentem funkcji fetch jest obiekt `Request`. Najprostszym requestem jest request metodą `GET` pod podany adres - to jest nasz przypadek. Do funkcji tej doczepia się nasłuch na odpowiedź przez `then`. pierwszy z nich służy temu żeby poczekać na dojście całej odpowiedzi i sparsowanie jej jako `json`. Drugi `then` rozwiązuje obietnicę zwracając obiekt z danymi wydobyty za pomocą wysłanego żądania.\\n\\nDruga metoda pozwala na zapisanie notatki do bazy. Tu również stosujemy `Promise` w sposób identyczny jak poprzednio, ale tym razem request jest bardziej skomplikowany. Aby zwiększyć czytelność kodu zapisuję go to tymczasowej zmiennej `req`. Widzimy, że `URL` jest taki sam, ale w drugim argumencie obiektu `Request` mamy jego dodatkową konfigurację: metodę, obiekt zawierający nagłówki oraz ciało requestu.\\n\\n```js\\n    function saveTodo(text) {\\n        let req = new Request(dbUrl,{ method: 'POST',\\n            headers: new Headers({'Content-Type': 'application/json'}),\\n            body: JSON.stringify({text: text})\\n        });\\n\\n        return new Promise(resolve => {\\n            fetch(req)\\n                .then(res => { return res.json(); })\\n                .then(data => { resolve(data); });\\n        })\\n    }\\n```\\n\\nOstatnia funkcja w tym projekcie nie ma nic wspólnego z interfejsem `fetch` ani obiektem `Promise`, ale prezentuje inną nowość z ES6 - `string templates`. Są to ciągi znakowe otoczone ukośnymi cudzysłowami takimi jak ten - \\\"\\\\`\\\". Które zawierają zmienne wywoływane za pomocą znaku dolara i nawiasów klamrowych. Do tej funkcji przekujemy obiekt mający własności `id` oraz `text`. Tworzy ona odpowiedni kod `html` który załączony będzie następnie do listy. Jest to znacznie wygodniejsze niż stosowanie `document.createElement()`.\\n\\n```js\\n    function appendTextToList(todo) {\\n        list.innerHTML += `\\n<li data-id=\\\"${todo.id}\\\">\\n    <div class=\\\"list-elem-head\\\">\\n        <span class=\\\"id\\\">${todo.id}</span>\\n    </div>\\n    <div class=\\\"list-elem-body\\\">\\n        <span class=\\\"text\\\">${todo.text}</span>\\n        <span class=\\\"delete\\\">x</span>\\n    </div>\\n</li>`;\\n    }\\n```\\n\\nPo zdefiniowaniu funkcji możemy przejść do części wykonywalnej. Zaczyna się ona od prze-iterowania po liście notatek pobranych z bazy i załączenia ich do listy na stronie.\\n\\n```js\\n    getAllTodos().then(todos => {\\n        todos.forEach(todo => { appendTextToList(todo); });\\n    });\\n```\\n\\nNastępnie dodajemy nasłuch na formularz. W przypadku dodania wpisu wysyłamy go do bazy, a po otrzymaniu identyfikatora załączamy do listy.\\n\\n```js\\n    form.addEventListener('submit', function (e) {\\n        e.preventDefault();\\n        saveTodo(form.task.value).then(res => {\\n            console.log(res);\\n            appendTextToList(res);\\n        });\\n        form.reset();\\n    });\\n```\\n\\nNa koniec dodajemy nasłuch na kliknięcia w listę. Ma on dotyczyć jedynie usuwania, więc za pomocą metody `contains` na liście klas sprawdzamy, czy kliknięto na element o klasie `delete`. Jeśli tak, to wyciągamy `id` z tego elementu listy, wysyłamy żądanie z metodą `DELETE` na url zakończony tym `id` oraz wycinamy go z listy.\\n\\n```js\\n    list.addEventListener('click',function (e) {\\n        if(e.target.classList.contains('delete')) {\\n            const id = e.target.parentElement.parentElement.dataset.id;\\n            console.log(id);\\n            fetch(new Request(`${dbUrl}/${id}`,{ method: 'DELETE'}));\\n            document.querySelector(`li[data-id=\\\"${id}\\\"]`).outerHTML = \\\"\\\";\\n        }\\n    })\\n```\\n\\n## Podsumowanie\\n\\nTen prosty projekt nadaje się świetnie jako wprowadzenie do programowania w JavaScript. Zaprezentowaliśmy tu również elementy CSS, które pokazują, że nie zawsze trzeba używać bootstrapa, żeby uzyskać atrakcyjnie wyglądające inputy oraz listy. Jeśli po przeczytaniu tego tekstu masz jakieś pytania, nie wahaj się i zadaj je w komentarzu.\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"opis-projektu\">Opis projektu</h2>\n<p>Projekt prezentuje zastosowanie interfejsu <code>fetch</code>, przykłady użycia <code>promise</code> oraz kilka sztuczek cssowych jak własności <code>transform</code>, <code>user-select</code> czy dyrektywa <code>@media</code>.</p>\n<p>Skład kodu źródłowego:</p>\n<pre><code>JavaScript 49.5% CSS 40.3% HTML 10.2%\n</code></pre>\n<p>Po napisaniu projekt będzie wyglądał tak:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/04/1_qm93PtCN3Y0mZWzQrqVAFw.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"666\" height=\"447\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/1_qm93PtCN3Y0mZWzQrqVAFw.png 600w, __GHOST_URL__/content/images/2021/04/1_qm93PtCN3Y0mZWzQrqVAFw.png 666w\"><figcaption>To Do List typed in pure JavaScript that will be presented in this article.</figcaption></figure><!--kg-card-begin: markdown--><h2 id=\"instalacja\">Instalacja</h2>\n<p>Jeśli chcesz przetestować kod u siebie bez jego przepisywania najszybciej będzie ściągnąć release komendą</p>\n<pre><code>wget -qO- https://github.com/gustawdaniel/simple_todo_app_js/archive/1.0.tar.gz | tar xvz\n</code></pre>\n<p>Następnie należy przejść do utworzonego katalogu</p>\n<pre><code>cd simple-todo-app-js-tutorial-1.0\n</code></pre>\n<p>Teraz należy zainstalować zależności</p>\n<pre><code>npm i\n</code></pre>\n<p>Żeby rozstawić serwery będziemy potrzebowali dwóch terminali. W pierwszym stawiamy serwer z naszym projektem</p>\n<pre><code>node node_modules/http-server/bin/http-server\n</code></pre>\n<p>W drugim terminalu (<code>ctrl+n</code>) stawiamy serwer REST API z pozwalający używać bazy danych</p>\n<pre><code>node node_modules/json-server/bin/index.js --watch db.json\n</code></pre>\n<p>Jeśli wszystko poszło dobrze powinniśmy zobaczyć coś takiego:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/04/1_PD3FHn76We8mFzIivvnpvg.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"800\" height=\"264\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/1_PD3FHn76We8mFzIivvnpvg.png 600w, __GHOST_URL__/content/images/2021/04/1_PD3FHn76We8mFzIivvnpvg.png 800w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Server with application (on the right) and with REST API connected with db.json file (on the left)</figcaption></figure><!--kg-card-begin: markdown--><p>Strona powinna być dostępna pod adresem <a href=\"http://localhost:8080\"><code>localhost:8080</code></a></p>\n<h2 id=\"struktura-projektu\">Struktura projektu</h2>\n<p>Projekt zawiera następujące pliki</p>\n<pre><code>├── app.js              // skrypt obsługujący pobieranie, tworzenie i usuwanie wpisów\n├── db.json             // plik json z danymi do którego dostajemy się przez API\n├── index.html          // plik html ze stroną\n├── LICENSE             // licencje WTFPL\n├── package.json        // plik z zależnościami do zainstalowania, tutaj serwer http i json\n├── README.md           // instrukcja z komendami do obsługi serwera\n└── style.css           // style\n</code></pre>\n<p>Widać, że jest bardzo prosty. Możliwości jakie daje strona to</p>\n<ul>\n<li>tworzenie wpisów</li>\n<li>wyświetlanie wpisów</li>\n<li>usuwanie wpisów</li>\n</ul>\n<p>W kolejnym rozdziale opiszemy zawartość plików <code>index.html</code> oraz <code>style.css</code>. Później omówimy serwery jakie postawiliśmy, rolę pliku <code>db.json</code> i na końcu logikę umieszczoną w pliku <code>app.js</code>.</p>\n<h2 id=\"statyczny-dokument\">Statyczny dokument</h2>\n<p>Plik <code>index.html</code> zaczyna się dość klasycznie. Pobieramy czcionkę <code>Lato</code> oraz załączamy nasz customowy styl.</p>\n<pre><code class=\"language-html\">&lt;html&gt;\n&lt;head&gt;\n    &lt;link href=&quot;https://fonts.googleapis.com/css?family=Lato:300&amp;amp;subset=latin-ext&quot; rel=&quot;stylesheet&quot;&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot;&gt;\n&lt;/head&gt;\n</code></pre>\n<p>Ponieważ kod pisany jest zgodnie z zasadami semantyki HTML5 mamy tu podział na <code>header</code> oraz <code>main</code>. W nagłówku znajduje się formularz z jednym polem do wpisywania teksu notatek.</p>\n<pre><code class=\"language-html\">&lt;body&gt;\n&lt;header&gt;\n    &lt;form class=&quot;todo&quot;&gt;\n        &lt;input name=&quot;task&quot; type=&quot;text&quot; placeholder=&quot;Type text to add note&quot;&gt;\n    &lt;/form&gt;\n&lt;/header&gt;\n</code></pre>\n<p>W części <code>main</code> znajduje się lista z trzema przykładowymi elementami.<br>\nElementy mają swoje identyfikatory i są podzielone na dwie części<br>\npierwsza zawiera identyfikator, druga tekst oraz przycisk do usuwania<br>\nnotatki.</p>\n<pre><code class=\"language-html\">&lt;main&gt;\n  &lt;ul&gt;\n    &lt;li data-id=&quot;1&quot;&gt;\n      &lt;div class=&quot;list-elem-head&quot;&gt;\n          &lt;span class=&quot;id&quot;&gt;1&lt;/span&gt;\n      &lt;/div&gt;\n      &lt;div class=&quot;list-elem-body&quot;&gt;\n          &lt;span class=&quot;text&quot;&gt;First One&lt;/span&gt;\n          &lt;span class=&quot;delete&quot;&gt;x&lt;/span&gt;\n      &lt;/div&gt;\n    &lt;/li&gt;\n    &lt;li data-id=&quot;2&quot;&gt;\n      &lt;div class=&quot;list-elem-head&quot;&gt;\n          &lt;span class=&quot;id&quot;&gt;2&lt;/span&gt;\n      &lt;/div&gt;\n      &lt;div class=&quot;list-elem-body&quot;&gt;\n          &lt;span class=&quot;text&quot;&gt;Second todo&lt;/span&gt;\n          &lt;span class=&quot;delete&quot;&gt;x&lt;/span&gt;\n      &lt;/div&gt;\n    &lt;/li&gt;\n    &lt;li data-id=&quot;5&quot;&gt;\n      &lt;div class=&quot;list-elem-head&quot;&gt;\n          &lt;span class=&quot;id&quot;&gt;5&lt;/span&gt;\n      &lt;/div&gt;\n      &lt;div class=&quot;list-elem-body&quot;&gt;\n          &lt;span class=&quot;text&quot;&gt;At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa qui officia deserunt mollitia animi, id est laborum et dolorum fuga. Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et voluptates repudiandae sint et molestiae non recusandae. Itaque earum rerum hic tenetur a sapiente delectus, ut aut reiciendis voluptatibus maiores alias consequatur aut perferendis doloribus asperiores repellat.&lt;/span&gt;\n          &lt;span class=&quot;delete&quot;&gt;x&lt;/span&gt;\n      &lt;/div&gt;\n    &lt;/li&gt;\n  &lt;/ul&gt;\n&lt;/main&gt;\n</code></pre>\n<p>Na końcu załączamy skrypt, który omówimy później. Na razie może być to pusty plik.</p>\n<pre><code class=\"language-html\">&lt;script src=&quot;app.js&quot;&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>Gdyby nie stylowanie, nie dało by się na to patrzeć, ale zainspirowany zajęciami z html i css, które ostatnio prowadziłem postanowiłem napisać plik css całkowicie samodzielnie od zera. Reguły które dodałem zaczynają się od ustalenia szerokości dokumentu w zależności od szerokości ekranu. Zwykle stosuje się do tego bootstrapa, ale można to robić również bez niego. Służy to tego dyrektywa <code>@media</code> której zastosowanie zaprezentowane jest poniżej:</p>\n<pre><code class=\"language-css\">@media (max-width: 575px) {\n    input,main {\n        width: 100%;\n    }\n}\n@media (min-width: 576px) {\n    input,main {\n        width: 80%;\n    }\n    main {\n        margin-left: 10%;\n    }\n}\n</code></pre>\n<p>Widać tutaj, że na większych urządzeniach chcę mieć margines, który na mniejszych nie jest już potrzebny. Następną regułą jest zastosowanie czcionki <code>Lato</code> do całego dokumentu:</p>\n<pre><code class=\"language-css\">body {\n    font-family: 'Lato', sans-serif;\n}\n</code></pre>\n<p>W nagłówku centrujemy formularz i pozbywamy się jego naturalnych marginesów.</p>\n<pre><code class=\"language-css\">header {\n    text-align: center;\n}\nform {\n    margin: 0;\n}\n</code></pre>\n<p>Następnie definiujemy zasady podświetlania inputa na który klikniemy, albo<br>\nnad którym nasuniemy myszkę. Oprócz usunięcia przezroczystości z ramki mamy<br>\ntutaj dodanie rozmytego cienia oraz zaczerwienienie tła.</p>\n<pre><code class=\"language-css\">input:focus, input:hover {\n    border: solid 1px crimson;\n    box-shadow: 0 0 5px -1px crimson;\n    background-color: rgba(220, 20, 60, 0.05);\n}\n</code></pre>\n<p>Interesującą własnością nie zaznaczonego inputa jest <code>transition</code>. Pozwala ona na określenie opóźnienia z jakim dany zmienia swoją własność. Dzięki niemu zobaczymy, że tło pojawia się i znika płynnie.</p>\n<pre><code class=\"language-css\">input {\n    padding: 20px;\n    border: solid 1px rgba(220, 20, 60, 0.52);\n    margin: 10px 0;\n    transition: box-shadow 1s, background-color 2s;\n}\n</code></pre>\n<p>Nieco inne efekty nadane są na najechanie myszką nad element listy. Najmocniej wyróżniającym się elementem jest przesunięcie się lewej krawędzi listy w prawo co ustawiane jest we własności <code>margin</code>.</p>\n<pre><code class=\"language-css\">li:hover {\n    border: solid 1px rgba(220, 20, 60, 0.8);\n    background-color: rgba(220, 20, 60, 0.05);\n    box-shadow: 0 0 2px -1px crimson;\n    margin: 3px 0 3px 10px;\n}\n</code></pre>\n<p>Dla porównania jeśli myszka nie znajduje się nad elementem listy margines jest symetryczny. Tutaj również zastosowano <code>transition</code> uzyskując animację wcinania i wysuwania elementu listy.</p>\n<pre><code class=\"language-css\">li {\n    list-style: none;\n    border: solid 1px rgba(220, 20, 60, 0.52);\n    margin: 3px 0;\n    color: gray;\n    transition: margin 0.5s, background-color 2s;\n}\n</code></pre>\n<p>Elementy listy podzielone są na dwie części, <code>.list-elem-head</code> służy do wyświetlania identyfikatora. Przestrzeń wokół rozepchana jest marginesami. Warto zwrócić też uwagę na <code>float: left</code> pozwalający divom na sąsiadowanie w jednej linii.</p>\n<pre><code class=\"language-css\">.list-elem-head {\n    float: left;\n    margin: 20px;\n}\n</code></pre>\n<p>Zupełnie inaczej jest w przypadku <code>.list-elem-body</code>. Tutaj nie marginesy a paddingi odpowiadają za rozpychanie się i centrowanie względem granic elementu listy. Jest tak dlatego, że potrzebujemy pełnej wysokości elementu <code>.list-elem-body</code> wewnątrz elementu <code>li</code> aby dodać granicę <code>border-left</code>.</p>\n<pre><code class=\"language-css\">.list-elem-body {\n    margin-left: 50px;\n    padding: 20px 20px 20px 20px;\n    border-left: solid 1px rgba(220, 20, 60, 0.52);\n}\n</code></pre>\n<p>Sama lista nie potrzebuje ani marginesów, ani paddingów. Razem z <code>list-style: none</code> zastosowanym dla <code>li</code> pozbywamy się dzięki temu domyślnego stylowania list.</p>\n<pre><code class=\"language-css\">ul {\n    margin: 0;\n    padding: 0;\n}\n</code></pre>\n<p>Jedną z ostatnich zmian jest odsunięcie tekstu z notatką od wewnętrznej granicy elementu listy.</p>\n<pre><code class=\"language-css\">li &gt; span.text {\n    padding-right: 20px;\n}\n</code></pre>\n<p>Na koniec stylujemy przycisk do usuwania. Jest to span zawierający literę x. Nie ściągałem tu żadnych dodatkowych czcionek. Mimo to dzięki zaokrągleniu rogów, odpowiednim kolorom, paddigom i zafixowaniu wielkości elementu udało się uzyskać dość jednoznacznie wyglądający przycisk do usuwania. Jedak dodana została tu jeszcze jedna ciekawa własność: <code>user-select</code>. Pozwala ona pominąć dany element przy zaznaczaniu. Dzięki temu podwójne kliknięcie na tekst notatki nie spowoduje zaznaczenia <code>x</code> na końcu.</p>\n<pre><code class=\"language-css\">li &gt; div &gt; span.delete {\n    float: right;\n    border: solid 1px crimson;\n    border-radius: 50%;\n    padding: 5px;\n    width: 7px;\n    height: 7px;\n    line-height: 5px;\n    color: crimson;\n    cursor: pointer;\n    -moz-user-select: none;\n    -webkit-user-select: none;\n    -ms-user-select:none;\n    user-select:none;\n}\n</code></pre>\n<h2 id=\"logika\">Logika</h2>\n<p>Teraz omówimy w jaki sposób dodać do projektu możliwość tworzenia nowych wpisów, usuwania ich i wyświetlania wpisów zapisanych w bazie. Jeśli przyjrzymy się wycinkowi pliku <code>package.json</code> zobaczymy tam następujące linie:</p>\n<pre><code>  &quot;dependencies&quot;: {\n    &quot;http-server&quot;: &quot;^0.11.1&quot;,\n    &quot;json-server&quot;: &quot;^0.12.1&quot;\n  }\n</code></pre>\n<p>Pierwsza z paczek to serwer http który odpowiada za to, że pod portem 8080 wystawia się nasza aplikacja. Daje to z grubsza taki sam efekt jak napisanie <code>php -S localhost:8080</code>.</p>\n<p>Druga to serwer REST do obsługi bazy danych zapisanych w pliku <code>db.json</code>. W pliku <code>README.md</code> zapisane są komendy do włączania tych serwerów oraz requesty jakie należy wykonać aby dokonać zmian w bazie:</p>\n<p>Do dodana wpisu konieczne jest wysłanie żądania metodą POST:</p>\n<pre><code>http POST localhost:3000/todo text=&quot;First One&quot;\n</code></pre>\n<p>Żeby wylistować wszystkie wpisy wysyłamy żądanie GET:</p>\n<pre><code>http GET localhost:3000/todo\n</code></pre>\n<p>A w celu usunięcia n-tego wpisu metodą DELETE i wskazujemy numer wpisu w adresie URL:</p>\n<pre><code>http DELETE localhost:3000/todo/n\n</code></pre>\n<p>Sam plik <code>db.json</code> może wyglądać następująco:</p>\n<pre><code class=\"language-json\">{\n  &quot;todo&quot;: [\n    {\n      &quot;text&quot;: &quot;First One&quot;,\n      &quot;id&quot;: 1\n    },\n    {\n      &quot;text&quot;: &quot;Second todo&quot;,\n      &quot;id&quot;: 2\n    },\n    {\n      &quot;text&quot;: &quot;At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa qui officia deserunt mollitia animi, id est laborum et dolorum fuga. Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et voluptates repudiandae sint et molestiae non recusandae. Itaque earum rerum hic tenetur a sapiente delectus, ut aut reiciendis voluptatibus maiores alias consequatur aut perferendis doloribus asperiores repellat.&quot;,\n      &quot;id&quot;: 5\n    }\n  ]\n}\n</code></pre>\n<p>Teraz przejdziemy do omówienia logiki aplikacji umieszczonej w pliku <code>app.js</code>. Zanim jednak to nastąpi musimy wyczyścić plik <code>index.html</code> usuwając wszystko co znajduje się miedzy elementami <code>&lt;ul&gt;&lt;/ul&gt;</code>. Modyfikujemy html czyszcząc listę z zawartości ponieważ za dodawania zawartości odpowiadać będzie teraz skrypt w <code>app.js</code>.</p>\n<p>Cały skrypt zawarto jest w funkjci anonimowej wykonywanej po wydarzeniu <code>DOMContentLoaded</code>.<br>\nZapobiega to wykonywaniu skryptu przed załadowaniem drzewa <code>DOM</code>.</p>\n<pre><code class=\"language-js\">document.addEventListener('DOMContentLoaded',function () {\n\n   // there should be placed code presented below\n\n})\n</code></pre>\n<p>wewnątrz tej funkcji definiujemy zmienne które wykorzystywane będą w skrypcie. Są to <code>dbUrl</code> zawierająca adres do API zarządzającego bazą danych. Dwie kolejne zmienne zawierając formularz oraz listę.</p>\n<pre><code class=\"language-js\">    const dbUrl = 'http://localhost:3000/todo';\n    let form = document.querySelector('form.todo');\n    let list = document.querySelector('ul');\n</code></pre>\n<p>Teraz czas na definiowanie przydatnych funkcji. Zaczniemy od funkcji pobierającej wszystkie notatki. Ponieważ funkcja ta wysyła request musi poczekać na jego odpowiedź, ale oczekiwanie na odpowiedź oznacza, że metodą then nadajemy nasłuch i jak by wypinamy się z synchronicznej kolejności wykonywania kolejnych linii kodu. Żeby zachować asynchroniczną naturę dobrego kodu JavaScript na kliencie nie możemy pozwolić sobie na blokowanie reszty skryptu. Sposobem na poradzenie sobie z koniecznością zwracania danych, których jeszcze nie ma jest zwracanie obietnicy ich dostarczenia czyli obiektu <code>Promise</code>. Obiekt te przyjmuje w swoim konstruktorze funkcję, której argumentem jest funkcja której jako argument powinniśmy przekazać interesujące nas dane. Widać to dobrze w poniższym kodzie:</p>\n<pre><code class=\"language-js\">    function getAllTodos() {\n        return new Promise(resolve =&gt; {\n            fetch(new Request(dbUrl))\n                .then(res =&gt; { return res.json(); })\n                .then(data =&gt; { resolve(data); });\n        });\n    }\n</code></pre>\n<p>Jenak <code>Promise</code> to nie jedyna ciekawa rzecz, którą można dostrzec w tych kilku liniach. Kolejną jest funkcji <code>fetch</code>. Jest to następca interfejsu XMLHttpRequest. Różni się od niego między innymi lepiej przemyślaną i nowocześniejszą składnią, lepszym wsparciem dla przetwarzania strumieni danych. Argumentem funkcji fetch jest obiekt <code>Request</code>. Najprostszym requestem jest request metodą <code>GET</code> pod podany adres - to jest nasz przypadek. Do funkcji tej doczepia się nasłuch na odpowiedź przez <code>then</code>. pierwszy z nich służy temu żeby poczekać na dojście całej odpowiedzi i sparsowanie jej jako <code>json</code>. Drugi <code>then</code> rozwiązuje obietnicę zwracając obiekt z danymi wydobyty za pomocą wysłanego żądania.</p>\n<p>Druga metoda pozwala na zapisanie notatki do bazy. Tu również stosujemy <code>Promise</code> w sposób identyczny jak poprzednio, ale tym razem request jest bardziej skomplikowany. Aby zwiększyć czytelność kodu zapisuję go to tymczasowej zmiennej <code>req</code>. Widzimy, że <code>URL</code> jest taki sam, ale w drugim argumencie obiektu <code>Request</code> mamy jego dodatkową konfigurację: metodę, obiekt zawierający nagłówki oraz ciało requestu.</p>\n<pre><code class=\"language-js\">    function saveTodo(text) {\n        let req = new Request(dbUrl,{ method: 'POST',\n            headers: new Headers({'Content-Type': 'application/json'}),\n            body: JSON.stringify({text: text})\n        });\n\n        return new Promise(resolve =&gt; {\n            fetch(req)\n                .then(res =&gt; { return res.json(); })\n                .then(data =&gt; { resolve(data); });\n        })\n    }\n</code></pre>\n<p>Ostatnia funkcja w tym projekcie nie ma nic wspólnego z interfejsem <code>fetch</code> ani obiektem <code>Promise</code>, ale prezentuje inną nowość z ES6 - <code>string templates</code>. Są to ciągi znakowe otoczone ukośnymi cudzysłowami takimi jak ten - &quot;`&quot;. Które zawierają zmienne wywoływane za pomocą znaku dolara i nawiasów klamrowych. Do tej funkcji przekujemy obiekt mający własności <code>id</code> oraz <code>text</code>. Tworzy ona odpowiedni kod <code>html</code> który załączony będzie następnie do listy. Jest to znacznie wygodniejsze niż stosowanie <code>document.createElement()</code>.</p>\n<pre><code class=\"language-js\">    function appendTextToList(todo) {\n        list.innerHTML += `\n&lt;li data-id=&quot;${todo.id}&quot;&gt;\n    &lt;div class=&quot;list-elem-head&quot;&gt;\n        &lt;span class=&quot;id&quot;&gt;${todo.id}&lt;/span&gt;\n    &lt;/div&gt;\n    &lt;div class=&quot;list-elem-body&quot;&gt;\n        &lt;span class=&quot;text&quot;&gt;${todo.text}&lt;/span&gt;\n        &lt;span class=&quot;delete&quot;&gt;x&lt;/span&gt;\n    &lt;/div&gt;\n&lt;/li&gt;`;\n    }\n</code></pre>\n<p>Po zdefiniowaniu funkcji możemy przejść do części wykonywalnej. Zaczyna się ona od prze-iterowania po liście notatek pobranych z bazy i załączenia ich do listy na stronie.</p>\n<pre><code class=\"language-js\">    getAllTodos().then(todos =&gt; {\n        todos.forEach(todo =&gt; { appendTextToList(todo); });\n    });\n</code></pre>\n<p>Następnie dodajemy nasłuch na formularz. W przypadku dodania wpisu wysyłamy go do bazy, a po otrzymaniu identyfikatora załączamy do listy.</p>\n<pre><code class=\"language-js\">    form.addEventListener('submit', function (e) {\n        e.preventDefault();\n        saveTodo(form.task.value).then(res =&gt; {\n            console.log(res);\n            appendTextToList(res);\n        });\n        form.reset();\n    });\n</code></pre>\n<p>Na koniec dodajemy nasłuch na kliknięcia w listę. Ma on dotyczyć jedynie usuwania, więc za pomocą metody <code>contains</code> na liście klas sprawdzamy, czy kliknięto na element o klasie <code>delete</code>. Jeśli tak, to wyciągamy <code>id</code> z tego elementu listy, wysyłamy żądanie z metodą <code>DELETE</code> na url zakończony tym <code>id</code> oraz wycinamy go z listy.</p>\n<pre><code class=\"language-js\">    list.addEventListener('click',function (e) {\n        if(e.target.classList.contains('delete')) {\n            const id = e.target.parentElement.parentElement.dataset.id;\n            console.log(id);\n            fetch(new Request(`${dbUrl}/${id}`,{ method: 'DELETE'}));\n            document.querySelector(`li[data-id=&quot;${id}&quot;]`).outerHTML = &quot;&quot;;\n        }\n    })\n</code></pre>\n<h2 id=\"podsumowanie\">Podsumowanie</h2>\n<p>Ten prosty projekt nadaje się świetnie jako wprowadzenie do programowania w JavaScript. Zaprezentowaliśmy tu również elementy CSS, które pokazują, że nie zawsze trzeba używać bootstrapa, żeby uzyskać atrakcyjnie wyglądające inputy oraz listy. Jeśli po przeczytaniu tego tekstu masz jakieś pytania, nie wahaj się i zadaj je w komentarzu.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f39282fb35425592d0ba8",
            "plaintext": "Opis projektu\nProjekt prezentuje zastosowanie interfejsu fetch, przykłady użycia promise oraz\nkilka sztuczek cssowych jak własności transform, user-select czy dyrektywa \n@media.\n\nSkład kodu źródłowego:\n\nJavaScript 49.5% CSS 40.3% HTML 10.2%\n\n\nPo napisaniu projekt będzie wyglądał tak:\n\nTo Do List typed in pure JavaScript that will be presented in this article.\nInstalacja\nJeśli chcesz przetestować kod u siebie bez jego przepisywania najszybciej będzie\nściągnąć release komendą\n\nwget -qO- https://github.com/gustawdaniel/simple_todo_app_js/archive/1.0.tar.gz | tar xvz\n\n\nNastępnie należy przejść do utworzonego katalogu\n\ncd simple-todo-app-js-tutorial-1.0\n\n\nTeraz należy zainstalować zależności\n\nnpm i\n\n\nŻeby rozstawić serwery będziemy potrzebowali dwóch terminali. W pierwszym\nstawiamy serwer z naszym projektem\n\nnode node_modules/http-server/bin/http-server\n\n\nW drugim terminalu (ctrl+n) stawiamy serwer REST API z pozwalający używać bazy\ndanych\n\nnode node_modules/json-server/bin/index.js --watch db.json\n\n\nJeśli wszystko poszło dobrze powinniśmy zobaczyć coś takiego:\n\nServer with application (on the right) and with REST API connected with db.json\nfile (on the left)Strona powinna być dostępna pod adresem localhost:8080 [http://localhost:8080]\n\nStruktura projektu\nProjekt zawiera następujące pliki\n\n├── app.js              // skrypt obsługujący pobieranie, tworzenie i usuwanie wpisów\n├── db.json             // plik json z danymi do którego dostajemy się przez API\n├── index.html          // plik html ze stroną\n├── LICENSE             // licencje WTFPL\n├── package.json        // plik z zależnościami do zainstalowania, tutaj serwer http i json\n├── README.md           // instrukcja z komendami do obsługi serwera\n└── style.css           // style\n\n\nWidać, że jest bardzo prosty. Możliwości jakie daje strona to\n\n * tworzenie wpisów\n * wyświetlanie wpisów\n * usuwanie wpisów\n\nW kolejnym rozdziale opiszemy zawartość plików index.html oraz style.css.\nPóźniej omówimy serwery jakie postawiliśmy, rolę pliku db.json i na końcu logikę\numieszczoną w pliku app.js.\n\nStatyczny dokument\nPlik index.html zaczyna się dość klasycznie. Pobieramy czcionkę Lato oraz\nzałączamy nasz customowy styl.\n\n<html>\n<head>\n    <link href=\"https://fonts.googleapis.com/css?family=Lato:300&amp;subset=latin-ext\" rel=\"stylesheet\">\n    <link rel=\"stylesheet\" href=\"style.css\">\n</head>\n\n\nPonieważ kod pisany jest zgodnie z zasadami semantyki HTML5 mamy tu podział na \nheader oraz main. W nagłówku znajduje się formularz z jednym polem do wpisywania\nteksu notatek.\n\n<body>\n<header>\n    <form class=\"todo\">\n        <input name=\"task\" type=\"text\" placeholder=\"Type text to add note\">\n    </form>\n</header>\n\n\nW części main znajduje się lista z trzema przykładowymi elementami.\nElementy mają swoje identyfikatory i są podzielone na dwie części\npierwsza zawiera identyfikator, druga tekst oraz przycisk do usuwania\nnotatki.\n\n<main>\n  <ul>\n    <li data-id=\"1\">\n      <div class=\"list-elem-head\">\n          <span class=\"id\">1</span>\n      </div>\n      <div class=\"list-elem-body\">\n          <span class=\"text\">First One</span>\n          <span class=\"delete\">x</span>\n      </div>\n    </li>\n    <li data-id=\"2\">\n      <div class=\"list-elem-head\">\n          <span class=\"id\">2</span>\n      </div>\n      <div class=\"list-elem-body\">\n          <span class=\"text\">Second todo</span>\n          <span class=\"delete\">x</span>\n      </div>\n    </li>\n    <li data-id=\"5\">\n      <div class=\"list-elem-head\">\n          <span class=\"id\">5</span>\n      </div>\n      <div class=\"list-elem-body\">\n          <span class=\"text\">At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa qui officia deserunt mollitia animi, id est laborum et dolorum fuga. Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et voluptates repudiandae sint et molestiae non recusandae. Itaque earum rerum hic tenetur a sapiente delectus, ut aut reiciendis voluptatibus maiores alias consequatur aut perferendis doloribus asperiores repellat.</span>\n          <span class=\"delete\">x</span>\n      </div>\n    </li>\n  </ul>\n</main>\n\n\nNa końcu załączamy skrypt, który omówimy później. Na razie może być to pusty\nplik.\n\n<script src=\"app.js\"></script>\n</body>\n</html>\n\n\nGdyby nie stylowanie, nie dało by się na to patrzeć, ale zainspirowany zajęciami\nz html i css, które ostatnio prowadziłem postanowiłem napisać plik css\ncałkowicie samodzielnie od zera. Reguły które dodałem zaczynają się od ustalenia\nszerokości dokumentu w zależności od szerokości ekranu. Zwykle stosuje się do\ntego bootstrapa, ale można to robić również bez niego. Służy to tego dyrektywa \n@media której zastosowanie zaprezentowane jest poniżej:\n\n@media (max-width: 575px) {\n    input,main {\n        width: 100%;\n    }\n}\n@media (min-width: 576px) {\n    input,main {\n        width: 80%;\n    }\n    main {\n        margin-left: 10%;\n    }\n}\n\n\nWidać tutaj, że na większych urządzeniach chcę mieć margines, który na\nmniejszych nie jest już potrzebny. Następną regułą jest zastosowanie czcionki \nLato do całego dokumentu:\n\nbody {\n    font-family: 'Lato', sans-serif;\n}\n\n\nW nagłówku centrujemy formularz i pozbywamy się jego naturalnych marginesów.\n\nheader {\n    text-align: center;\n}\nform {\n    margin: 0;\n}\n\n\nNastępnie definiujemy zasady podświetlania inputa na który klikniemy, albo\nnad którym nasuniemy myszkę. Oprócz usunięcia przezroczystości z ramki mamy\ntutaj dodanie rozmytego cienia oraz zaczerwienienie tła.\n\ninput:focus, input:hover {\n    border: solid 1px crimson;\n    box-shadow: 0 0 5px -1px crimson;\n    background-color: rgba(220, 20, 60, 0.05);\n}\n\n\nInteresującą własnością nie zaznaczonego inputa jest transition. Pozwala ona na\nokreślenie opóźnienia z jakim dany zmienia swoją własność. Dzięki niemu\nzobaczymy, że tło pojawia się i znika płynnie.\n\ninput {\n    padding: 20px;\n    border: solid 1px rgba(220, 20, 60, 0.52);\n    margin: 10px 0;\n    transition: box-shadow 1s, background-color 2s;\n}\n\n\nNieco inne efekty nadane są na najechanie myszką nad element listy. Najmocniej\nwyróżniającym się elementem jest przesunięcie się lewej krawędzi listy w prawo\nco ustawiane jest we własności margin.\n\nli:hover {\n    border: solid 1px rgba(220, 20, 60, 0.8);\n    background-color: rgba(220, 20, 60, 0.05);\n    box-shadow: 0 0 2px -1px crimson;\n    margin: 3px 0 3px 10px;\n}\n\n\nDla porównania jeśli myszka nie znajduje się nad elementem listy margines jest\nsymetryczny. Tutaj również zastosowano transition uzyskując animację wcinania i\nwysuwania elementu listy.\n\nli {\n    list-style: none;\n    border: solid 1px rgba(220, 20, 60, 0.52);\n    margin: 3px 0;\n    color: gray;\n    transition: margin 0.5s, background-color 2s;\n}\n\n\nElementy listy podzielone są na dwie części, .list-elem-head służy do\nwyświetlania identyfikatora. Przestrzeń wokół rozepchana jest marginesami. Warto\nzwrócić też uwagę na float: left pozwalający divom na sąsiadowanie w jednej\nlinii.\n\n.list-elem-head {\n    float: left;\n    margin: 20px;\n}\n\n\nZupełnie inaczej jest w przypadku .list-elem-body. Tutaj nie marginesy a\npaddingi odpowiadają za rozpychanie się i centrowanie względem granic elementu\nlisty. Jest tak dlatego, że potrzebujemy pełnej wysokości elementu \n.list-elem-body wewnątrz elementu li aby dodać granicę border-left.\n\n.list-elem-body {\n    margin-left: 50px;\n    padding: 20px 20px 20px 20px;\n    border-left: solid 1px rgba(220, 20, 60, 0.52);\n}\n\n\nSama lista nie potrzebuje ani marginesów, ani paddingów. Razem z list-style:\nnone zastosowanym dla li pozbywamy się dzięki temu domyślnego stylowania list.\n\nul {\n    margin: 0;\n    padding: 0;\n}\n\n\nJedną z ostatnich zmian jest odsunięcie tekstu z notatką od wewnętrznej granicy\nelementu listy.\n\nli > span.text {\n    padding-right: 20px;\n}\n\n\nNa koniec stylujemy przycisk do usuwania. Jest to span zawierający literę x. Nie\nściągałem tu żadnych dodatkowych czcionek. Mimo to dzięki zaokrągleniu rogów,\nodpowiednim kolorom, paddigom i zafixowaniu wielkości elementu udało się uzyskać\ndość jednoznacznie wyglądający przycisk do usuwania. Jedak dodana została tu\njeszcze jedna ciekawa własność: user-select. Pozwala ona pominąć dany element\nprzy zaznaczaniu. Dzięki temu podwójne kliknięcie na tekst notatki nie spowoduje\nzaznaczenia x na końcu.\n\nli > div > span.delete {\n    float: right;\n    border: solid 1px crimson;\n    border-radius: 50%;\n    padding: 5px;\n    width: 7px;\n    height: 7px;\n    line-height: 5px;\n    color: crimson;\n    cursor: pointer;\n    -moz-user-select: none;\n    -webkit-user-select: none;\n    -ms-user-select:none;\n    user-select:none;\n}\n\n\nLogika\nTeraz omówimy w jaki sposób dodać do projektu możliwość tworzenia nowych wpisów,\nusuwania ich i wyświetlania wpisów zapisanych w bazie. Jeśli przyjrzymy się\nwycinkowi pliku package.json zobaczymy tam następujące linie:\n\n  \"dependencies\": {\n    \"http-server\": \"^0.11.1\",\n    \"json-server\": \"^0.12.1\"\n  }\n\n\nPierwsza z paczek to serwer http który odpowiada za to, że pod portem 8080\nwystawia się nasza aplikacja. Daje to z grubsza taki sam efekt jak napisanie php\n-S localhost:8080.\n\nDruga to serwer REST do obsługi bazy danych zapisanych w pliku db.json. W pliku \nREADME.md zapisane są komendy do włączania tych serwerów oraz requesty jakie\nnależy wykonać aby dokonać zmian w bazie:\n\nDo dodana wpisu konieczne jest wysłanie żądania metodą POST:\n\nhttp POST localhost:3000/todo text=\"First One\"\n\n\nŻeby wylistować wszystkie wpisy wysyłamy żądanie GET:\n\nhttp GET localhost:3000/todo\n\n\nA w celu usunięcia n-tego wpisu metodą DELETE i wskazujemy numer wpisu w adresie\nURL:\n\nhttp DELETE localhost:3000/todo/n\n\n\nSam plik db.json może wyglądać następująco:\n\n{\n  \"todo\": [\n    {\n      \"text\": \"First One\",\n      \"id\": 1\n    },\n    {\n      \"text\": \"Second todo\",\n      \"id\": 2\n    },\n    {\n      \"text\": \"At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa qui officia deserunt mollitia animi, id est laborum et dolorum fuga. Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et voluptates repudiandae sint et molestiae non recusandae. Itaque earum rerum hic tenetur a sapiente delectus, ut aut reiciendis voluptatibus maiores alias consequatur aut perferendis doloribus asperiores repellat.\",\n      \"id\": 5\n    }\n  ]\n}\n\n\nTeraz przejdziemy do omówienia logiki aplikacji umieszczonej w pliku app.js.\nZanim jednak to nastąpi musimy wyczyścić plik index.html usuwając wszystko co\nznajduje się miedzy elementami <ul></ul>. Modyfikujemy html czyszcząc listę z\nzawartości ponieważ za dodawania zawartości odpowiadać będzie teraz skrypt w \napp.js.\n\nCały skrypt zawarto jest w funkjci anonimowej wykonywanej po wydarzeniu \nDOMContentLoaded.\nZapobiega to wykonywaniu skryptu przed załadowaniem drzewa DOM.\n\ndocument.addEventListener('DOMContentLoaded',function () {\n\n   // there should be placed code presented below\n\n})\n\n\nwewnątrz tej funkcji definiujemy zmienne które wykorzystywane będą w skrypcie.\nSą to dbUrl zawierająca adres do API zarządzającego bazą danych. Dwie kolejne\nzmienne zawierając formularz oraz listę.\n\n    const dbUrl = 'http://localhost:3000/todo';\n    let form = document.querySelector('form.todo');\n    let list = document.querySelector('ul');\n\n\nTeraz czas na definiowanie przydatnych funkcji. Zaczniemy od funkcji\npobierającej wszystkie notatki. Ponieważ funkcja ta wysyła request musi poczekać\nna jego odpowiedź, ale oczekiwanie na odpowiedź oznacza, że metodą then nadajemy\nnasłuch i jak by wypinamy się z synchronicznej kolejności wykonywania kolejnych\nlinii kodu. Żeby zachować asynchroniczną naturę dobrego kodu JavaScript na\nkliencie nie możemy pozwolić sobie na blokowanie reszty skryptu. Sposobem na\nporadzenie sobie z koniecznością zwracania danych, których jeszcze nie ma jest\nzwracanie obietnicy ich dostarczenia czyli obiektu Promise. Obiekt te przyjmuje\nw swoim konstruktorze funkcję, której argumentem jest funkcja której jako\nargument powinniśmy przekazać interesujące nas dane. Widać to dobrze w poniższym\nkodzie:\n\n    function getAllTodos() {\n        return new Promise(resolve => {\n            fetch(new Request(dbUrl))\n                .then(res => { return res.json(); })\n                .then(data => { resolve(data); });\n        });\n    }\n\n\nJenak Promise to nie jedyna ciekawa rzecz, którą można dostrzec w tych kilku\nliniach. Kolejną jest funkcji fetch. Jest to następca interfejsu XMLHttpRequest.\nRóżni się od niego między innymi lepiej przemyślaną i nowocześniejszą składnią,\nlepszym wsparciem dla przetwarzania strumieni danych. Argumentem funkcji fetch\njest obiekt Request. Najprostszym requestem jest request metodą GET pod podany\nadres - to jest nasz przypadek. Do funkcji tej doczepia się nasłuch na odpowiedź\nprzez then. pierwszy z nich służy temu żeby poczekać na dojście całej odpowiedzi\ni sparsowanie jej jako json. Drugi then rozwiązuje obietnicę zwracając obiekt z\ndanymi wydobyty za pomocą wysłanego żądania.\n\nDruga metoda pozwala na zapisanie notatki do bazy. Tu również stosujemy Promise \nw sposób identyczny jak poprzednio, ale tym razem request jest bardziej\nskomplikowany. Aby zwiększyć czytelność kodu zapisuję go to tymczasowej zmiennej \nreq. Widzimy, że URL jest taki sam, ale w drugim argumencie obiektu Request mamy\njego dodatkową konfigurację: metodę, obiekt zawierający nagłówki oraz ciało\nrequestu.\n\n    function saveTodo(text) {\n        let req = new Request(dbUrl,{ method: 'POST',\n            headers: new Headers({'Content-Type': 'application/json'}),\n            body: JSON.stringify({text: text})\n        });\n\n        return new Promise(resolve => {\n            fetch(req)\n                .then(res => { return res.json(); })\n                .then(data => { resolve(data); });\n        })\n    }\n\n\nOstatnia funkcja w tym projekcie nie ma nic wspólnego z interfejsem fetch ani\nobiektem Promise, ale prezentuje inną nowość z ES6 - string templates. Są to\nciągi znakowe otoczone ukośnymi cudzysłowami takimi jak ten - \"`\". Które\nzawierają zmienne wywoływane za pomocą znaku dolara i nawiasów klamrowych. Do\ntej funkcji przekujemy obiekt mający własności id oraz text. Tworzy ona\nodpowiedni kod html który załączony będzie następnie do listy. Jest to znacznie\nwygodniejsze niż stosowanie document.createElement().\n\n    function appendTextToList(todo) {\n        list.innerHTML += `\n<li data-id=\"${todo.id}\">\n    <div class=\"list-elem-head\">\n        <span class=\"id\">${todo.id}</span>\n    </div>\n    <div class=\"list-elem-body\">\n        <span class=\"text\">${todo.text}</span>\n        <span class=\"delete\">x</span>\n    </div>\n</li>`;\n    }\n\n\nPo zdefiniowaniu funkcji możemy przejść do części wykonywalnej. Zaczyna się ona\nod prze-iterowania po liście notatek pobranych z bazy i załączenia ich do listy\nna stronie.\n\n    getAllTodos().then(todos => {\n        todos.forEach(todo => { appendTextToList(todo); });\n    });\n\n\nNastępnie dodajemy nasłuch na formularz. W przypadku dodania wpisu wysyłamy go\ndo bazy, a po otrzymaniu identyfikatora załączamy do listy.\n\n    form.addEventListener('submit', function (e) {\n        e.preventDefault();\n        saveTodo(form.task.value).then(res => {\n            console.log(res);\n            appendTextToList(res);\n        });\n        form.reset();\n    });\n\n\nNa koniec dodajemy nasłuch na kliknięcia w listę. Ma on dotyczyć jedynie\nusuwania, więc za pomocą metody contains na liście klas sprawdzamy, czy\nkliknięto na element o klasie delete. Jeśli tak, to wyciągamy id z tego elementu\nlisty, wysyłamy żądanie z metodą DELETE na url zakończony tym id oraz wycinamy\ngo z listy.\n\n    list.addEventListener('click',function (e) {\n        if(e.target.classList.contains('delete')) {\n            const id = e.target.parentElement.parentElement.dataset.id;\n            console.log(id);\n            fetch(new Request(`${dbUrl}/${id}`,{ method: 'DELETE'}));\n            document.querySelector(`li[data-id=\"${id}\"]`).outerHTML = \"\";\n        }\n    })\n\n\nPodsumowanie\nTen prosty projekt nadaje się świetnie jako wprowadzenie do programowania w\nJavaScript. Zaprezentowaliśmy tu również elementy CSS, które pokazują, że nie\nzawsze trzeba używać bootstrapa, żeby uzyskać atrakcyjnie wyglądające inputy\noraz listy. Jeśli po przeczytaniu tego tekstu masz jakieś pytania, nie wahaj się\ni zadaj je w komentarzu.",
            "feature_image": "__GHOST_URL__/content/images/2021/04/maxresdefault.jpg",
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:27:20.000Z",
            "updated_at": "2021-04-20T21:34:41.000Z",
            "published_at": "2021-04-20T21:28:44.000Z",
            "custom_excerpt": "Ten prosty projekt nadaje się świetnie jako wprowadzenie do programowania w JavaScript. Nacisk położony jest na elementy ES6 oraz frontend.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f39a92fb35425592d0bae",
            "uuid": "3cdeefd2-e8bf-4962-9766-1cf7d33df8a3",
            "title": "Scrapowanie danych w języku Perl",
            "slug": "scrapowanie-danych-w-jezyku-perl",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Opis projektu\\n\\nInternet zwykle kojarzy się z przeglądaniem go w postaci renderowanej przez przeglądarkę z pliku html. Jest to wygodne, jeśli zależy nam na ładnej oprawie i łatwej nawigacji.\\n\\nJeśli jednak chcemy przeglądać i analizować dane, wtedy forma strony html może okazać się nie optymalna i prościej jest pobrać strony html na swój dysk, a następnie przetworzyć je do bardziej przyjaznego dla dalszej obróbki formatu. Proces ten nazywa się scrapowaniem.\\n\\nNapiszemy dzisiaj aplikację która pozwala pobierać dane z różych stron, po których można iterować za pomocą parametru w adresie url i przetwarzać je do postaci plików json.\\n\\nWykorzystamy do tego język Perl. Aplikacja będzie składała się z części pobierającej dane oraz przetwarzającej. Konfiguracja będzie wydzielona do osobnej klasy co pozwoli na łatwe rozszerzanie zbioru obsługiwanych stron.\\n\\n## Instalacja\\n\\nPobieramy repo z gita i przechodzimy do utworzonego katalogu\\n\\n    git clone git@github.com:gustawdaniel/scraper.git && cd scraper\\n\\n## Ładownia konfiguracji\\n\\nProces scrapowania można podzielić na dwie fazy: pobranie danych i ich przetworzenie. W niegkórych wypadkach - kiedy to co pobieramy decyduje o tym co będziemy pobierać\\n\\n- powinny one się zazębiać, u nas nie muszą. Za pobieranie danych będzie odpowiedzialny plik `app.pl`, a za analizę `json.pl`. Pliki z rozszerzeniem `pm`, to moduły, klasy, lub biblioteki, które sami piszemy, ale nie jest to kod wykonywalny aplikacji. Mamy tu `Loader.pm` moduł odpowiedzialny za rozpoznanie parametru przekazanego do `app.pl` i załadowanie jednej z trzech dostępnych konfiguracji z plików `*Config.pm`.\\n\\nPonieważ zarówno dla `app.pl` jak i `json.pl` pierwszą czynnością jest właśnie załadowanie konfiguracji, zaczniemy od omówinia modułów. Aby kod był modułem wymagane jest zadeklarowanie go zwrotem `package`:\\n\\n> Loader.pm\\n\\n```perl\\nuse strict;\\nuse warnings FATAL => 'all';\\n\\npackage Loader;\\n```\\n\\nPosiada on jedną metodę - `load`, która rozpoznaje, czy podano argument określający rodzaj scrapowaej treści. Mamy do wyoboru `rhf` - rejestr hurotwni farmaceutycznych, `scpp` - Scandinavian-Polish Chamber of Commerce oraz domyślne `ra` - rejestr aptek.\\n\\nNie zajmujmy się teraz pytaniem czym są te instytucje i dlaczego pobieramy ich dane. Można je potraktować jako przykłady i samemu dopisać tutaj inne. Istotne jest, że parametr `$ARGV[0]` jest ciągiem znakowym wpisanym za nazwią programu i w zależności od niego dociągane są odpowiednie moduły z konfiguracją, na których wykonywana jest metoda `new`. Jest to konstruktor obiektu zawierającego konfigurację. Następnie obiekt otrzymuje swoją nazwę i jest zwracany.\\n\\n```perl\\nsub load\\n{\\n    if(scalar @ARGV && $ARGV[0] eq \\\"rhf\\\") {\\n        use RhfConfig;\\n        my $config = RhfConfig->new();\\n        $config->{name} = \\\"rhf\\\";\\n        return $config;\\n    } elsif (scalar @ARGV && $ARGV[0] eq \\\"spcc\\\") {\\n        use SpccConfig;\\n        my $config = SpccConfig->new();\\n        $config->{name} = \\\"spcc\\\";\\n        return $config;\\n    } else {\\n        use RaConfig;\\n        my $config = RaConfig->new();\\n        $config->{name} = \\\"ra\\\";\\n        return $config;\\n    }\\n}\\n```\\n\\nNa tym skończył by się kod w większości języków, ale Perl wymaga dopisanie jeszcze jednej linii:\\n\\n```perl\\n1;\\n```\\n\\nJedynka jest tutaj wymagana aby poinformować o sukcesie operacji ładowania modułu. Ma to sens, jeśli przy inicjalizacji poszło by coś źle. Wtedy zwracając fałsz mogli byśmy w bardziej czysty sposób zakończyć nasz program.\\n\\nJak wspomnieliśmy wcześniej mamy dostępnych kilka konfiguracji. Żeby nie powtarzać kodu zamykamy je do obiektów, które konfigurowane są przez własności i metody. W innych językach zastosowali byśmy interfejs. W perlu nie ma wbudowanego mechanizmu interfejsów, ale można go napisać samemu. Pewnie zrobili byśmy to gdyby to był większy projekt, ale dla tak prostego przypadku nie warto. Umawiamy się więc, że każda konfiguracja musi mieć kilka metod i własności, ale może je implementować na swój własny sposób. Zaczniemy do rejestru aptek:\\n\\n> RaConfig.pm\\n\\n```perl\\nuse strict;\\nuse warnings FATAL => 'all';\\n\\npackage RaConfig;\\n```\\n\\nPo określeniu nazwy paczki utworzymy jej konstruktor. Zastosujemy do tego funkcję bless, której zadaniem jest zwrócić instancję obiektu tworzonej przez nas klasy.\\n\\nPierwszym argumentem konstuktora (którego nie będziemy podawać, a ustawiamy jest automatycznie w tle) jest sam moduł, na którym wywoływana jest funkcja. Coś jak this, albo self w innych języakch. Wkładamy to jako drugi argument do funkcji bless za pomocą funkcji `shift`, która z tablicy z domyślnym kontekstem czyli właśnie argumentów `new` wyciąga pierwszy element. Za pierwszy argument funkcji `bless` podajemy zbiór własności obiektu. W tym przypadku `limit` równy maksymalnemu indeksowi strony, oraz\\n`rows` - selektor w którym znajduje się interesująca nas treść. Pozwala on przyśpieszyć wyszukiwanie bo wszystkie późniejsze zapytania będą ograniczone tylko od obszaru wybranego przez ten selektor.\\n\\n```perl\\nsub new { return bless {limit=>100000,rows=>'.pharmacyDetailsControl_Div.controlContainer'}, shift; }\\n```\\n\\nDla pobierania danych najważniejszą informacją jest adres `url` z którego można je uzyskać. Konstruowanie tego adresu na podstawie iterowanego indeksu strony wykonuje metoda `source`\\n\\n```perl\\nsub source { # arg index\\n    return \\\"http://ra.rejestrymedyczne.csioz.gov.pl/_layouts/15/RA/PharmacyDetailsPublic.aspx?id=\\\".$_[1].\\\"&IsDlg=1\\\";\\n}\\n```\\n\\nMetoda `invalid` pozwala nam wyłapać strony, które z jakichś powodów należy ominąć. Podajemy do niej html, bo respons może mieć kod 200, ale jeśli jest z nim coś nie tak, to ta metoda zapobiegnie dalszemu przetwarzaniu tego htmla. W tym konkretnym przypadku zwróci ona true, jeśli html ma ciąg znaków zawarty w wyrażeniu regularnym:\\n\\n```perl\\nsub invalid { # arg html\\n    return $_[1] =~ /ctl00_PlaceHolderPageTitleInTitleArea_ErrorPageTitlePanel/;\\n}\\n```\\n\\nDo przetwarzania kluczowa jest informacja jakie klucze i selektory odpowiadają instancji pobieranych danych. Tutaj strona jest prostą tabelą, której klucze znajdują się w elementach h3, a wartości w span. Argumentem\\nmetody jest obiekt służący do wyszukiwania w dokumencie html określonych wartości. Za pomocą swoich metod `query` zwraca tablicę elementów pasujących do wzorca, a przez `as_trimmed_text` rzutuje je do ciągów znakowych wewnątrz tych elementów. W metodzie `select` kolejno: tworzymy `hash` - czyli strukturę danych zawierającą klucze i wartości bez patrzenia na kolejność. Następnie odnosimy się do niej jak do tablicy co pozwala\\nwłożyć tablicę zwracaną przez pierwszy selektor jako klucze, a przez drugi jako wartości. Na koniec zwracamy hasha.\\n\\n```perl\\nsub select { # arg query\\n    my %hash;\\n    @hash{$_[1]->query('.inputArea.full h3')->as_trimmed_text} = $_[1]->query('.inputArea.full span')->as_trimmed_text;\\n    return %hash;\\n}\\n```\\n\\nNa koniec tak jak wcześnie zwracamy `1;`\\n\\n```perl\\n1;\\n```\\n\\nKlasa dla rejestru hurtowni farmaceutycznych zostanie zaprezentowana już w całości, ponieważ jest bardzo podobna.\\n\\n> RhfConfig.pm\\n\\n```perl\\nuse strict;\\nuse warnings FATAL => 'all';\\n\\npackage RhfConfig;\\n\\nsub new { return bless {limit=>100000,rows=>'.pharmacyDetailsControl_Div.controlContainer'}, shift; }\\n\\nsub source {\\n    return \\\"http://rhf.rejestrymedyczne.csioz.gov.pl/_layouts/15/RHF/WarehouseDetailsPublic.aspx?id=\\\".$_[1].\\\"&IsDlg=1\\\";\\n}\\n\\nsub invalid {\\n    return $_[1] =~ /ctl00_PlaceHolderPageTitleInTitleArea_ErrorPageTitlePanel/;\\n}\\n\\nsub select { # arg query\\n    my %hash;\\n    @hash{$_[1]->query('.inputArea.full h3')->as_trimmed_text} = $_[1]->query('.inputArea.full span')->as_trimmed_text;\\n    return %hash;\\n}\\n\\n1;\\n```\\n\\nTrochę inaczej natomiast skonfigurowano Skandynawsko-Polską Izbę Gospodarczą.\\n\\n> SpccConfig.pm\\n\\n```perl\\nuse strict;\\nuse warnings FATAL => 'all';\\n\\npackage SpccConfig;\\n\\nsub new { return bless {limit=>12,rows=>'td.col-1'}, shift; }\\n\\nsub source {\\n    my $link = \\\"https://www.spcc.pl/members/search/all/all/all\\\";\\n    if($_[1]) { $link .= \\\"?page=\\\".$_[1]; }\\n    return $link;\\n}\\n\\nsub invalid { return 0; }\\n\\nsub select {\\n    my $q = $_[1];\\n    return (\\n        'name'       => $q->query('.members_search_title')->as_trimmed_text,\\n        'phone'      => $q->query('.views-field-field-telefon-value')->as_trimmed_text,\\n        'person'      => $q->query('.views-field-field-kontakt-osoba-value')->as_trimmed_text,\\n        'email'      => $q->query('.views-field-field-email-email')->as_trimmed_text,\\n        'www'      => $q->query('.views-field-field-www-url')->as_trimmed_text,\\n        'branches'     => $q->query('.views-field-phpcode-2')->as_trimmed_text\\n    )\\n}\\n\\n1;\\n```\\n\\nW kodzie widzimy, że za pobieranie danych służą już inne selektory. Nie ma szans, żeby kod 200 oznaczał błędą stronę oraz źródło pierwszej strony nie zawiera żadnych parametrów przekazywanych do adresu `URL`. Poza tym jednak wszystkie funkcji spełniają to samo zadanie. Dzięki temu w kolejnej części będziemy mogli wykorzystać jeden kod do pobierania danych z każdego z tych źródeł.\\n\\n## Pobieranie treści\\n\\nZa samo pobieranie danych odpowiada `app.pl`. Zaczynamy standordowo od załadowania wymaganych modułów:\\n\\n> app.pl\\n\\n```perl\\n#!/usr/bin/env perl\\nuse strict;\\nuse warnings FATAL => 'all';\\nuse LWP::Simple;\\nuse open ':std', ':encoding(UTF-8)';\\nuse Loader;\\n```\\n\\n`LWP` służy do wysyłania żądań `get`, `Loader` to nasz moduł omówiony w poprzednim rozdziale. Ładujemy konfigurację określoną parametrem za nazwą programu za pomocą linii:\\n\\n```perl\\nmy $config = Loader->load();\\n```\\n\\nNastawiamy na `0` liczniki sukcesów pobierania `s` i błędów `e`.\\n\\n```perl\\nmy $e = 0;\\nmy $s = 0;\\n```\\n\\nTworzymy katalog `raw` na pobrane dane i wewnątrz podkatalog odpowiadający skróconej nazwie naszego źródła danych.\\n\\n```perl\\nmkdir 'raw', 0755;\\nmkdir 'raw/'.$config->{name}, 0755;\\n```\\n\\nPonieważ jest to liniowy bardzo prosty scraper, indeks podawany do metody `source` obiektu `config` obliczamy poprzez iterowanie go o jeden od zera do limitu podanego w konfiguracji.\\n\\n```perl\\nfor(my $i = 7480; $i<=$config->{limit}; $i++) {\\n```\\n\\nUrl wyciągamy za pomocą metody `source` podając jej właśnie ten index. Funkcja get z modułu `LWP:Simple` wysyła request do zadany adres i zwraca ciało odpowiedzi.\\n\\n```perl\\n    my $html = get $config->source($i);\\n```\\n\\nJeśli w zwróconej odpowiedzi - czyli kodzie html znajdują się informacje o błędzie to metoda `invalid` określona w konfiguracji powinna zwrócić true. Wówczas wyświetli się czerwony napisa `ERROR`, a licznik błędów podniesie się. Spowoduje to również automatyczne przejście do kolejnego indeksu pętli.\\n\\n```perl\\n    if ($config->invalid($html))\\n    {\\n        print \\\"ID:\\\\t\\\" . $i . \\\" - \\\\e[31mERROR\\\\e[0m - [e: \\\".++$e.\\\", s: $s]\\\\n\\\";\\n        next;\\n    }\\n```\\n\\nJeśli wszystko poszło dobrze, to do pliku którego nazwa to po prostu `index` pętli zapisywany jest kod html strony.\\n\\n```perl\\n    open(my $fh, '>', \\\"raw/\\\".$config->{name}.\\\"/\\\".$i.\\\".html\\\") or die \\\"Could not open file: $!\\\";\\n    print $fh ($html);\\n    close $fh;\\n```\\n\\nIndex numerujący sukcesy podnosi się i zielony komunikat SUCCESS pojawia się an ekranie.\\n\\n```perl\\n    print \\\"ID:\\\\t\\\" . $i . \\\" - \\\\e[32mSUCCESS\\\\e[0m - [e: $e, s: \\\".++$s.\\\"]\\\\n\\\";\\n}\\n```\\n\\nCzas wykonywania pobierania zależy od szybkości łącza. U mnie time wykonany na tym programie dla spcc dał wynik:\\n\\n```\\nreal\\t0m35.027s\\nuser\\t0m0.456s\\nsys\\t0m0.080s\\n```\\n\\nCo pokazuje, ogromny potencjał tkwiący w zrównolegleniu operacji pobierania danych.\\n\\nPrzykład screenu z pobierania danch:\\n\\n![](http://i.imgur.com/yAuhj4a.png)\\n\\n## Analiza danych\\n\\nDo przetworzenia pobranych plkiów html do postaci pliku `json` służy program `json.pl`. Zastanawiałem się nad tym, czy nie włączyć tu sqlite3 albo mongodb, ale zależało mi na lekkiej, możliwie prostej bazie NoSQL. Niestety sqlite3 nie jest NoSQL, a mondodb nie jest tak łatwa w instalacji i konfiguracji. Ostatecznie zostałem przy zwykłym pliku `json`, lecz należy pamiętać, że to rozwiązanie nie sprawdzi się przy nprawdę dużych zbiorach danych, gdzie musimy liczyć się ze skończoną ilością pamięci RAM.\\n\\nProgram zaczyna się od ładowani modułów.\\n\\n> json.pl\\n\\n```perl\\n#!/usr/bin/env perl\\nuse strict;\\nuse warnings FATAL => 'all';\\n\\nuse HTML::Query 'Query';\\nuse JSON;\\nuse Loader;\\n```\\n\\nPierwszym jest `HTML::Query` - silnik do parsowania html i wykonywani na nim selektorów. Moduł `JSON` pozwala konwertować hashe i tablice do foramtu `json`. `Loader` poznaliśmy już i widzieliśmy go w akcji. Odpowiada on za ładownie konfiguracji. Obok konfiguracji drugą zmienną globalną w tym programie jest tablica instancji obieków reprezentujących pobrane dane - firmy, apteki lub hurtownie.\\n\\n```perl\\nmy $config = Loader->load();\\nmy @instances = ();\\n```\\n\\nPonownie robimy przebieg po wszystkich indeksach.\\n\\n```perl\\nfor(my $i = 0; $i<=$config->{limit}; $i++) {\\n```\\n\\nTym razem za opuszczenie pętli odpowiada sprawdzenie czy plik istnieje, jeśli nie, to przechodzimy do kolejnego przebiegu\\n\\n```perl\\n    if (! -f 'raw/'.$config->{name}.\\\"/\\\".$i.\\\".html\\\") { next; }\\n```\\n\\nJeśli plik istnieje, to ładujemy go do obiektu `Query`, na którym będziemy wykonywać selektory.\\n\\n```perl\\n    my $q = Query( file => 'raw/'.$config->{name}.\\\"/\\\".$i.\\\".html\\\" );\\n```\\n\\nOkazja do ich użycia nadarza się dość szybko. Pierwszy raz korzystamy z selektora określonego w konstruktorze obiektu `config` we własności `rows`. Nim wycinamy obszar w którym są interesujące dane. Może się okazać, że jest więcej takich obszarów.\\n\\nNa przykład apteki mają układ z jedną apteką na stronie, a spcc ma wiele firm na jednym widoku. Niezależnie od tego wszystkie obszary odpowiadają pojedyńczym instancjom wyszukiwanego obiektu.\\n\\n```perl\\n    my @rows = $q->query($config->{rows})->get_elements(); #\\n```\\n\\nNie ważne, czy instancja jest jedna, czy jest ich kilka iterujemy po nich:\\n\\n```perl\\n    foreach my $row (@rows)\\n    {\\n```\\n\\nWewnąrz pęli przesłaniamy nasze `query` przez `query` obcięte tylko do obszaru danej instancji.\\n\\n```perl\\n        $q = Query( tree => $row );\\n```\\n\\nTak ustawiony selektor przekazujemy do metody `select` obiektu config.\\n\\n```perl\\n        my %object = $config->select($q);\\n```\\n\\nW metodzie `select` leżą szczegóły dotyczące tego jak parsować daną instancję obiektu. Tu nie musimy się tym przejmować. Istostne jest, że to co otrzymamy będzie obiektem typu `hash`, który następnie dołączamy do tablicy `instances`.\\n\\n```perl\\n        push @instances, \\\\%object;\\n    }\\n}\\n```\\n\\nKiedy pętla zakończy się. Tablica `instances` zostaje przekazana do obiektu kodującego ją do formatu `json`. Z powodu polskich znaków obiekt dostaje po drodze konfigurację nakazującą mu korzystać z `utf-8`.\\n\\n```perl\\nprint JSON->new->utf8(0)->encode(\\n    {\\n        'instances'=> \\\\@instances\\n    }\\n);\\n```\\n\\nPrzetworzenie danych dla spcc zajmuje nie całe trzy sekundy, tym razem przy pełnym obciążenieu procesora.\\n\\n```\\nreal\\t0m2.772s\\nuser\\t0m2.768s\\nsys\\t0m0.000s\\n```\\n\\nScreen z widokiem przetworzonych danych\\n\\n![](http://i.imgur.com/Hs7axWN.png)\\n\\n## Podsumowanie\\n\\nProgram był pisany około pół roku temu. Teraz przed publikacją standardowo odrobinę go dopracowałem. Zastosowano w nim staroszkolną metodę oobsługi obiektów w Perlu. Warto wspomnieć, że istnieją w nim również biblioteki jak [Moose](https://metacpan.org/pod/release/ETHER/Moose-2.0802/lib/Moose.pm), albo  [Moo](https://metacpan.org/pod/Moo) które wprowadzają obiekty dodając do nich trochę tzw. \\\"cukru składniowego\\\". Jednak znacznie ciekawsze jest to, że dokładnie dwa tygodnie temu - 24 lipca wyszła stabilna wersja interpretera szóstej wersji języka Perl. Wprowadza ona obiektowość jako część natywnej składni języka. Zapewnia przy tym lepsze typowanie, czyli łata chyba ten główny brak Perla 5, przez który trudno było pisać w nim bezpiecznie. Być może oznacza to, że perl 6 powróci do wyższych poziomów\\npopularności.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"opis-projektu\">Opis projektu</h2>\n<p>Internet zwykle kojarzy się z przeglądaniem go w postaci renderowanej przez przeglądarkę z pliku html. Jest to wygodne, jeśli zależy nam na ładnej oprawie i łatwej nawigacji.</p>\n<p>Jeśli jednak chcemy przeglądać i analizować dane, wtedy forma strony html może okazać się nie optymalna i prościej jest pobrać strony html na swój dysk, a następnie przetworzyć je do bardziej przyjaznego dla dalszej obróbki formatu. Proces ten nazywa się scrapowaniem.</p>\n<p>Napiszemy dzisiaj aplikację która pozwala pobierać dane z różych stron, po których można iterować za pomocą parametru w adresie url i przetwarzać je do postaci plików json.</p>\n<p>Wykorzystamy do tego język Perl. Aplikacja będzie składała się z części pobierającej dane oraz przetwarzającej. Konfiguracja będzie wydzielona do osobnej klasy co pozwoli na łatwe rozszerzanie zbioru obsługiwanych stron.</p>\n<h2 id=\"instalacja\">Instalacja</h2>\n<p>Pobieramy repo z gita i przechodzimy do utworzonego katalogu</p>\n<pre><code>git clone git@github.com:gustawdaniel/scraper.git &amp;&amp; cd scraper\n</code></pre>\n<h2 id=\"%C5%82adownia-konfiguracji\">Ładownia konfiguracji</h2>\n<p>Proces scrapowania można podzielić na dwie fazy: pobranie danych i ich przetworzenie. W niegkórych wypadkach - kiedy to co pobieramy decyduje o tym co będziemy pobierać</p>\n<ul>\n<li>powinny one się zazębiać, u nas nie muszą. Za pobieranie danych będzie odpowiedzialny plik <code>app.pl</code>, a za analizę <code>json.pl</code>. Pliki z rozszerzeniem <code>pm</code>, to moduły, klasy, lub biblioteki, które sami piszemy, ale nie jest to kod wykonywalny aplikacji. Mamy tu <code>Loader.pm</code> moduł odpowiedzialny za rozpoznanie parametru przekazanego do <code>app.pl</code> i załadowanie jednej z trzech dostępnych konfiguracji z plików <code>*Config.pm</code>.</li>\n</ul>\n<p>Ponieważ zarówno dla <code>app.pl</code> jak i <code>json.pl</code> pierwszą czynnością jest właśnie załadowanie konfiguracji, zaczniemy od omówinia modułów. Aby kod był modułem wymagane jest zadeklarowanie go zwrotem <code>package</code>:</p>\n<blockquote>\n<p>Loader.pm</p>\n</blockquote>\n<pre><code class=\"language-perl\">use strict;\nuse warnings FATAL =&gt; 'all';\n\npackage Loader;\n</code></pre>\n<p>Posiada on jedną metodę - <code>load</code>, która rozpoznaje, czy podano argument określający rodzaj scrapowaej treści. Mamy do wyoboru <code>rhf</code> - rejestr hurotwni farmaceutycznych, <code>scpp</code> - Scandinavian-Polish Chamber of Commerce oraz domyślne <code>ra</code> - rejestr aptek.</p>\n<p>Nie zajmujmy się teraz pytaniem czym są te instytucje i dlaczego pobieramy ich dane. Można je potraktować jako przykłady i samemu dopisać tutaj inne. Istotne jest, że parametr <code>$ARGV[0]</code> jest ciągiem znakowym wpisanym za nazwią programu i w zależności od niego dociągane są odpowiednie moduły z konfiguracją, na których wykonywana jest metoda <code>new</code>. Jest to konstruktor obiektu zawierającego konfigurację. Następnie obiekt otrzymuje swoją nazwę i jest zwracany.</p>\n<pre><code class=\"language-perl\">sub load\n{\n    if(scalar @ARGV &amp;&amp; $ARGV[0] eq &quot;rhf&quot;) {\n        use RhfConfig;\n        my $config = RhfConfig-&gt;new();\n        $config-&gt;{name} = &quot;rhf&quot;;\n        return $config;\n    } elsif (scalar @ARGV &amp;&amp; $ARGV[0] eq &quot;spcc&quot;) {\n        use SpccConfig;\n        my $config = SpccConfig-&gt;new();\n        $config-&gt;{name} = &quot;spcc&quot;;\n        return $config;\n    } else {\n        use RaConfig;\n        my $config = RaConfig-&gt;new();\n        $config-&gt;{name} = &quot;ra&quot;;\n        return $config;\n    }\n}\n</code></pre>\n<p>Na tym skończył by się kod w większości języków, ale Perl wymaga dopisanie jeszcze jednej linii:</p>\n<pre><code class=\"language-perl\">1;\n</code></pre>\n<p>Jedynka jest tutaj wymagana aby poinformować o sukcesie operacji ładowania modułu. Ma to sens, jeśli przy inicjalizacji poszło by coś źle. Wtedy zwracając fałsz mogli byśmy w bardziej czysty sposób zakończyć nasz program.</p>\n<p>Jak wspomnieliśmy wcześniej mamy dostępnych kilka konfiguracji. Żeby nie powtarzać kodu zamykamy je do obiektów, które konfigurowane są przez własności i metody. W innych językach zastosowali byśmy interfejs. W perlu nie ma wbudowanego mechanizmu interfejsów, ale można go napisać samemu. Pewnie zrobili byśmy to gdyby to był większy projekt, ale dla tak prostego przypadku nie warto. Umawiamy się więc, że każda konfiguracja musi mieć kilka metod i własności, ale może je implementować na swój własny sposób. Zaczniemy do rejestru aptek:</p>\n<blockquote>\n<p>RaConfig.pm</p>\n</blockquote>\n<pre><code class=\"language-perl\">use strict;\nuse warnings FATAL =&gt; 'all';\n\npackage RaConfig;\n</code></pre>\n<p>Po określeniu nazwy paczki utworzymy jej konstruktor. Zastosujemy do tego funkcję bless, której zadaniem jest zwrócić instancję obiektu tworzonej przez nas klasy.</p>\n<p>Pierwszym argumentem konstuktora (którego nie będziemy podawać, a ustawiamy jest automatycznie w tle) jest sam moduł, na którym wywoływana jest funkcja. Coś jak this, albo self w innych języakch. Wkładamy to jako drugi argument do funkcji bless za pomocą funkcji <code>shift</code>, która z tablicy z domyślnym kontekstem czyli właśnie argumentów <code>new</code> wyciąga pierwszy element. Za pierwszy argument funkcji <code>bless</code> podajemy zbiór własności obiektu. W tym przypadku <code>limit</code> równy maksymalnemu indeksowi strony, oraz<br>\n<code>rows</code> - selektor w którym znajduje się interesująca nas treść. Pozwala on przyśpieszyć wyszukiwanie bo wszystkie późniejsze zapytania będą ograniczone tylko od obszaru wybranego przez ten selektor.</p>\n<pre><code class=\"language-perl\">sub new { return bless {limit=&gt;100000,rows=&gt;'.pharmacyDetailsControl_Div.controlContainer'}, shift; }\n</code></pre>\n<p>Dla pobierania danych najważniejszą informacją jest adres <code>url</code> z którego można je uzyskać. Konstruowanie tego adresu na podstawie iterowanego indeksu strony wykonuje metoda <code>source</code></p>\n<pre><code class=\"language-perl\">sub source { # arg index\n    return &quot;http://ra.rejestrymedyczne.csioz.gov.pl/_layouts/15/RA/PharmacyDetailsPublic.aspx?id=&quot;.$_[1].&quot;&amp;IsDlg=1&quot;;\n}\n</code></pre>\n<p>Metoda <code>invalid</code> pozwala nam wyłapać strony, które z jakichś powodów należy ominąć. Podajemy do niej html, bo respons może mieć kod 200, ale jeśli jest z nim coś nie tak, to ta metoda zapobiegnie dalszemu przetwarzaniu tego htmla. W tym konkretnym przypadku zwróci ona true, jeśli html ma ciąg znaków zawarty w wyrażeniu regularnym:</p>\n<pre><code class=\"language-perl\">sub invalid { # arg html\n    return $_[1] =~ /ctl00_PlaceHolderPageTitleInTitleArea_ErrorPageTitlePanel/;\n}\n</code></pre>\n<p>Do przetwarzania kluczowa jest informacja jakie klucze i selektory odpowiadają instancji pobieranych danych. Tutaj strona jest prostą tabelą, której klucze znajdują się w elementach h3, a wartości w span. Argumentem<br>\nmetody jest obiekt służący do wyszukiwania w dokumencie html określonych wartości. Za pomocą swoich metod <code>query</code> zwraca tablicę elementów pasujących do wzorca, a przez <code>as_trimmed_text</code> rzutuje je do ciągów znakowych wewnątrz tych elementów. W metodzie <code>select</code> kolejno: tworzymy <code>hash</code> - czyli strukturę danych zawierającą klucze i wartości bez patrzenia na kolejność. Następnie odnosimy się do niej jak do tablicy co pozwala<br>\nwłożyć tablicę zwracaną przez pierwszy selektor jako klucze, a przez drugi jako wartości. Na koniec zwracamy hasha.</p>\n<pre><code class=\"language-perl\">sub select { # arg query\n    my %hash;\n    @hash{$_[1]-&gt;query('.inputArea.full h3')-&gt;as_trimmed_text} = $_[1]-&gt;query('.inputArea.full span')-&gt;as_trimmed_text;\n    return %hash;\n}\n</code></pre>\n<p>Na koniec tak jak wcześnie zwracamy <code>1;</code></p>\n<pre><code class=\"language-perl\">1;\n</code></pre>\n<p>Klasa dla rejestru hurtowni farmaceutycznych zostanie zaprezentowana już w całości, ponieważ jest bardzo podobna.</p>\n<blockquote>\n<p>RhfConfig.pm</p>\n</blockquote>\n<pre><code class=\"language-perl\">use strict;\nuse warnings FATAL =&gt; 'all';\n\npackage RhfConfig;\n\nsub new { return bless {limit=&gt;100000,rows=&gt;'.pharmacyDetailsControl_Div.controlContainer'}, shift; }\n\nsub source {\n    return &quot;http://rhf.rejestrymedyczne.csioz.gov.pl/_layouts/15/RHF/WarehouseDetailsPublic.aspx?id=&quot;.$_[1].&quot;&amp;IsDlg=1&quot;;\n}\n\nsub invalid {\n    return $_[1] =~ /ctl00_PlaceHolderPageTitleInTitleArea_ErrorPageTitlePanel/;\n}\n\nsub select { # arg query\n    my %hash;\n    @hash{$_[1]-&gt;query('.inputArea.full h3')-&gt;as_trimmed_text} = $_[1]-&gt;query('.inputArea.full span')-&gt;as_trimmed_text;\n    return %hash;\n}\n\n1;\n</code></pre>\n<p>Trochę inaczej natomiast skonfigurowano Skandynawsko-Polską Izbę Gospodarczą.</p>\n<blockquote>\n<p>SpccConfig.pm</p>\n</blockquote>\n<pre><code class=\"language-perl\">use strict;\nuse warnings FATAL =&gt; 'all';\n\npackage SpccConfig;\n\nsub new { return bless {limit=&gt;12,rows=&gt;'td.col-1'}, shift; }\n\nsub source {\n    my $link = &quot;https://www.spcc.pl/members/search/all/all/all&quot;;\n    if($_[1]) { $link .= &quot;?page=&quot;.$_[1]; }\n    return $link;\n}\n\nsub invalid { return 0; }\n\nsub select {\n    my $q = $_[1];\n    return (\n        'name'       =&gt; $q-&gt;query('.members_search_title')-&gt;as_trimmed_text,\n        'phone'      =&gt; $q-&gt;query('.views-field-field-telefon-value')-&gt;as_trimmed_text,\n        'person'      =&gt; $q-&gt;query('.views-field-field-kontakt-osoba-value')-&gt;as_trimmed_text,\n        'email'      =&gt; $q-&gt;query('.views-field-field-email-email')-&gt;as_trimmed_text,\n        'www'      =&gt; $q-&gt;query('.views-field-field-www-url')-&gt;as_trimmed_text,\n        'branches'     =&gt; $q-&gt;query('.views-field-phpcode-2')-&gt;as_trimmed_text\n    )\n}\n\n1;\n</code></pre>\n<p>W kodzie widzimy, że za pobieranie danych służą już inne selektory. Nie ma szans, żeby kod 200 oznaczał błędą stronę oraz źródło pierwszej strony nie zawiera żadnych parametrów przekazywanych do adresu <code>URL</code>. Poza tym jednak wszystkie funkcji spełniają to samo zadanie. Dzięki temu w kolejnej części będziemy mogli wykorzystać jeden kod do pobierania danych z każdego z tych źródeł.</p>\n<h2 id=\"pobieranie-tre%C5%9Bci\">Pobieranie treści</h2>\n<p>Za samo pobieranie danych odpowiada <code>app.pl</code>. Zaczynamy standordowo od załadowania wymaganych modułów:</p>\n<blockquote>\n<p>app.pl</p>\n</blockquote>\n<pre><code class=\"language-perl\">#!/usr/bin/env perl\nuse strict;\nuse warnings FATAL =&gt; 'all';\nuse LWP::Simple;\nuse open ':std', ':encoding(UTF-8)';\nuse Loader;\n</code></pre>\n<p><code>LWP</code> służy do wysyłania żądań <code>get</code>, <code>Loader</code> to nasz moduł omówiony w poprzednim rozdziale. Ładujemy konfigurację określoną parametrem za nazwą programu za pomocą linii:</p>\n<pre><code class=\"language-perl\">my $config = Loader-&gt;load();\n</code></pre>\n<p>Nastawiamy na <code>0</code> liczniki sukcesów pobierania <code>s</code> i błędów <code>e</code>.</p>\n<pre><code class=\"language-perl\">my $e = 0;\nmy $s = 0;\n</code></pre>\n<p>Tworzymy katalog <code>raw</code> na pobrane dane i wewnątrz podkatalog odpowiadający skróconej nazwie naszego źródła danych.</p>\n<pre><code class=\"language-perl\">mkdir 'raw', 0755;\nmkdir 'raw/'.$config-&gt;{name}, 0755;\n</code></pre>\n<p>Ponieważ jest to liniowy bardzo prosty scraper, indeks podawany do metody <code>source</code> obiektu <code>config</code> obliczamy poprzez iterowanie go o jeden od zera do limitu podanego w konfiguracji.</p>\n<pre><code class=\"language-perl\">for(my $i = 7480; $i&lt;=$config-&gt;{limit}; $i++) {\n</code></pre>\n<p>Url wyciągamy za pomocą metody <code>source</code> podając jej właśnie ten index. Funkcja get z modułu <code>LWP:Simple</code> wysyła request do zadany adres i zwraca ciało odpowiedzi.</p>\n<pre><code class=\"language-perl\">    my $html = get $config-&gt;source($i);\n</code></pre>\n<p>Jeśli w zwróconej odpowiedzi - czyli kodzie html znajdują się informacje o błędzie to metoda <code>invalid</code> określona w konfiguracji powinna zwrócić true. Wówczas wyświetli się czerwony napisa <code>ERROR</code>, a licznik błędów podniesie się. Spowoduje to również automatyczne przejście do kolejnego indeksu pętli.</p>\n<pre><code class=\"language-perl\">    if ($config-&gt;invalid($html))\n    {\n        print &quot;ID:\\t&quot; . $i . &quot; - \\e[31mERROR\\e[0m - [e: &quot;.++$e.&quot;, s: $s]\\n&quot;;\n        next;\n    }\n</code></pre>\n<p>Jeśli wszystko poszło dobrze, to do pliku którego nazwa to po prostu <code>index</code> pętli zapisywany jest kod html strony.</p>\n<pre><code class=\"language-perl\">    open(my $fh, '&gt;', &quot;raw/&quot;.$config-&gt;{name}.&quot;/&quot;.$i.&quot;.html&quot;) or die &quot;Could not open file: $!&quot;;\n    print $fh ($html);\n    close $fh;\n</code></pre>\n<p>Index numerujący sukcesy podnosi się i zielony komunikat SUCCESS pojawia się an ekranie.</p>\n<pre><code class=\"language-perl\">    print &quot;ID:\\t&quot; . $i . &quot; - \\e[32mSUCCESS\\e[0m - [e: $e, s: &quot;.++$s.&quot;]\\n&quot;;\n}\n</code></pre>\n<p>Czas wykonywania pobierania zależy od szybkości łącza. U mnie time wykonany na tym programie dla spcc dał wynik:</p>\n<pre><code>real\t0m35.027s\nuser\t0m0.456s\nsys\t0m0.080s\n</code></pre>\n<p>Co pokazuje, ogromny potencjał tkwiący w zrównolegleniu operacji pobierania danych.</p>\n<p>Przykład screenu z pobierania danch:</p>\n<p><img src=\"http://i.imgur.com/yAuhj4a.png\" alt=\"\" loading=\"lazy\"></p>\n<h2 id=\"analiza-danych\">Analiza danych</h2>\n<p>Do przetworzenia pobranych plkiów html do postaci pliku <code>json</code> służy program <code>json.pl</code>. Zastanawiałem się nad tym, czy nie włączyć tu sqlite3 albo mongodb, ale zależało mi na lekkiej, możliwie prostej bazie NoSQL. Niestety sqlite3 nie jest NoSQL, a mondodb nie jest tak łatwa w instalacji i konfiguracji. Ostatecznie zostałem przy zwykłym pliku <code>json</code>, lecz należy pamiętać, że to rozwiązanie nie sprawdzi się przy nprawdę dużych zbiorach danych, gdzie musimy liczyć się ze skończoną ilością pamięci RAM.</p>\n<p>Program zaczyna się od ładowani modułów.</p>\n<blockquote>\n<p>json.pl</p>\n</blockquote>\n<pre><code class=\"language-perl\">#!/usr/bin/env perl\nuse strict;\nuse warnings FATAL =&gt; 'all';\n\nuse HTML::Query 'Query';\nuse JSON;\nuse Loader;\n</code></pre>\n<p>Pierwszym jest <code>HTML::Query</code> - silnik do parsowania html i wykonywani na nim selektorów. Moduł <code>JSON</code> pozwala konwertować hashe i tablice do foramtu <code>json</code>. <code>Loader</code> poznaliśmy już i widzieliśmy go w akcji. Odpowiada on za ładownie konfiguracji. Obok konfiguracji drugą zmienną globalną w tym programie jest tablica instancji obieków reprezentujących pobrane dane - firmy, apteki lub hurtownie.</p>\n<pre><code class=\"language-perl\">my $config = Loader-&gt;load();\nmy @instances = ();\n</code></pre>\n<p>Ponownie robimy przebieg po wszystkich indeksach.</p>\n<pre><code class=\"language-perl\">for(my $i = 0; $i&lt;=$config-&gt;{limit}; $i++) {\n</code></pre>\n<p>Tym razem za opuszczenie pętli odpowiada sprawdzenie czy plik istnieje, jeśli nie, to przechodzimy do kolejnego przebiegu</p>\n<pre><code class=\"language-perl\">    if (! -f 'raw/'.$config-&gt;{name}.&quot;/&quot;.$i.&quot;.html&quot;) { next; }\n</code></pre>\n<p>Jeśli plik istnieje, to ładujemy go do obiektu <code>Query</code>, na którym będziemy wykonywać selektory.</p>\n<pre><code class=\"language-perl\">    my $q = Query( file =&gt; 'raw/'.$config-&gt;{name}.&quot;/&quot;.$i.&quot;.html&quot; );\n</code></pre>\n<p>Okazja do ich użycia nadarza się dość szybko. Pierwszy raz korzystamy z selektora określonego w konstruktorze obiektu <code>config</code> we własności <code>rows</code>. Nim wycinamy obszar w którym są interesujące dane. Może się okazać, że jest więcej takich obszarów.</p>\n<p>Na przykład apteki mają układ z jedną apteką na stronie, a spcc ma wiele firm na jednym widoku. Niezależnie od tego wszystkie obszary odpowiadają pojedyńczym instancjom wyszukiwanego obiektu.</p>\n<pre><code class=\"language-perl\">    my @rows = $q-&gt;query($config-&gt;{rows})-&gt;get_elements(); #\n</code></pre>\n<p>Nie ważne, czy instancja jest jedna, czy jest ich kilka iterujemy po nich:</p>\n<pre><code class=\"language-perl\">    foreach my $row (@rows)\n    {\n</code></pre>\n<p>Wewnąrz pęli przesłaniamy nasze <code>query</code> przez <code>query</code> obcięte tylko do obszaru danej instancji.</p>\n<pre><code class=\"language-perl\">        $q = Query( tree =&gt; $row );\n</code></pre>\n<p>Tak ustawiony selektor przekazujemy do metody <code>select</code> obiektu config.</p>\n<pre><code class=\"language-perl\">        my %object = $config-&gt;select($q);\n</code></pre>\n<p>W metodzie <code>select</code> leżą szczegóły dotyczące tego jak parsować daną instancję obiektu. Tu nie musimy się tym przejmować. Istostne jest, że to co otrzymamy będzie obiektem typu <code>hash</code>, który następnie dołączamy do tablicy <code>instances</code>.</p>\n<pre><code class=\"language-perl\">        push @instances, \\%object;\n    }\n}\n</code></pre>\n<p>Kiedy pętla zakończy się. Tablica <code>instances</code> zostaje przekazana do obiektu kodującego ją do formatu <code>json</code>. Z powodu polskich znaków obiekt dostaje po drodze konfigurację nakazującą mu korzystać z <code>utf-8</code>.</p>\n<pre><code class=\"language-perl\">print JSON-&gt;new-&gt;utf8(0)-&gt;encode(\n    {\n        'instances'=&gt; \\@instances\n    }\n);\n</code></pre>\n<p>Przetworzenie danych dla spcc zajmuje nie całe trzy sekundy, tym razem przy pełnym obciążenieu procesora.</p>\n<pre><code>real\t0m2.772s\nuser\t0m2.768s\nsys\t0m0.000s\n</code></pre>\n<p>Screen z widokiem przetworzonych danych</p>\n<p><img src=\"http://i.imgur.com/Hs7axWN.png\" alt=\"\" loading=\"lazy\"></p>\n<h2 id=\"podsumowanie\">Podsumowanie</h2>\n<p>Program był pisany około pół roku temu. Teraz przed publikacją standardowo odrobinę go dopracowałem. Zastosowano w nim staroszkolną metodę oobsługi obiektów w Perlu. Warto wspomnieć, że istnieją w nim również biblioteki jak <a href=\"https://metacpan.org/pod/release/ETHER/Moose-2.0802/lib/Moose.pm\">Moose</a>, albo  <a href=\"https://metacpan.org/pod/Moo\">Moo</a> które wprowadzają obiekty dodając do nich trochę tzw. &quot;cukru składniowego&quot;. Jednak znacznie ciekawsze jest to, że dokładnie dwa tygodnie temu - 24 lipca wyszła stabilna wersja interpretera szóstej wersji języka Perl. Wprowadza ona obiektowość jako część natywnej składni języka. Zapewnia przy tym lepsze typowanie, czyli łata chyba ten główny brak Perla 5, przez który trudno było pisać w nim bezpiecznie. Być może oznacza to, że perl 6 powróci do wyższych poziomów<br>\npopularności.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f39a92fb35425592d0bae",
            "plaintext": "Opis projektu\nInternet zwykle kojarzy się z przeglądaniem go w postaci renderowanej przez\nprzeglądarkę z pliku html. Jest to wygodne, jeśli zależy nam na ładnej oprawie i\nłatwej nawigacji.\n\nJeśli jednak chcemy przeglądać i analizować dane, wtedy forma strony html może\nokazać się nie optymalna i prościej jest pobrać strony html na swój dysk, a\nnastępnie przetworzyć je do bardziej przyjaznego dla dalszej obróbki formatu.\nProces ten nazywa się scrapowaniem.\n\nNapiszemy dzisiaj aplikację która pozwala pobierać dane z różych stron, po\nktórych można iterować za pomocą parametru w adresie url i przetwarzać je do\npostaci plików json.\n\nWykorzystamy do tego język Perl. Aplikacja będzie składała się z części\npobierającej dane oraz przetwarzającej. Konfiguracja będzie wydzielona do\nosobnej klasy co pozwoli na łatwe rozszerzanie zbioru obsługiwanych stron.\n\nInstalacja\nPobieramy repo z gita i przechodzimy do utworzonego katalogu\n\ngit clone git@github.com:gustawdaniel/scraper.git && cd scraper\n\n\nŁadownia konfiguracji\nProces scrapowania można podzielić na dwie fazy: pobranie danych i ich\nprzetworzenie. W niegkórych wypadkach - kiedy to co pobieramy decyduje o tym co\nbędziemy pobierać\n\n * powinny one się zazębiać, u nas nie muszą. Za pobieranie danych będzie\n   odpowiedzialny plik app.pl, a za analizę json.pl. Pliki z rozszerzeniem pm,\n   to moduły, klasy, lub biblioteki, które sami piszemy, ale nie jest to kod\n   wykonywalny aplikacji. Mamy tu Loader.pm moduł odpowiedzialny za rozpoznanie\n   parametru przekazanego do app.pl i załadowanie jednej z trzech dostępnych\n   konfiguracji z plików *Config.pm.\n\nPonieważ zarówno dla app.pl jak i json.pl pierwszą czynnością jest właśnie\nzaładowanie konfiguracji, zaczniemy od omówinia modułów. Aby kod był modułem\nwymagane jest zadeklarowanie go zwrotem package:\n\n> Loader.pm\n\n\nuse strict;\nuse warnings FATAL => 'all';\n\npackage Loader;\n\n\nPosiada on jedną metodę - load, która rozpoznaje, czy podano argument\nokreślający rodzaj scrapowaej treści. Mamy do wyoboru rhf - rejestr hurotwni\nfarmaceutycznych, scpp - Scandinavian-Polish Chamber of Commerce oraz domyślne \nra - rejestr aptek.\n\nNie zajmujmy się teraz pytaniem czym są te instytucje i dlaczego pobieramy ich\ndane. Można je potraktować jako przykłady i samemu dopisać tutaj inne. Istotne\njest, że parametr $ARGV[0] jest ciągiem znakowym wpisanym za nazwią programu i w\nzależności od niego dociągane są odpowiednie moduły z konfiguracją, na których\nwykonywana jest metoda new. Jest to konstruktor obiektu zawierającego\nkonfigurację. Następnie obiekt otrzymuje swoją nazwę i jest zwracany.\n\nsub load\n{\n    if(scalar @ARGV && $ARGV[0] eq \"rhf\") {\n        use RhfConfig;\n        my $config = RhfConfig->new();\n        $config->{name} = \"rhf\";\n        return $config;\n    } elsif (scalar @ARGV && $ARGV[0] eq \"spcc\") {\n        use SpccConfig;\n        my $config = SpccConfig->new();\n        $config->{name} = \"spcc\";\n        return $config;\n    } else {\n        use RaConfig;\n        my $config = RaConfig->new();\n        $config->{name} = \"ra\";\n        return $config;\n    }\n}\n\n\nNa tym skończył by się kod w większości języków, ale Perl wymaga dopisanie\njeszcze jednej linii:\n\n1;\n\n\nJedynka jest tutaj wymagana aby poinformować o sukcesie operacji ładowania\nmodułu. Ma to sens, jeśli przy inicjalizacji poszło by coś źle. Wtedy zwracając\nfałsz mogli byśmy w bardziej czysty sposób zakończyć nasz program.\n\nJak wspomnieliśmy wcześniej mamy dostępnych kilka konfiguracji. Żeby nie\npowtarzać kodu zamykamy je do obiektów, które konfigurowane są przez własności i\nmetody. W innych językach zastosowali byśmy interfejs. W perlu nie ma\nwbudowanego mechanizmu interfejsów, ale można go napisać samemu. Pewnie zrobili\nbyśmy to gdyby to był większy projekt, ale dla tak prostego przypadku nie warto.\nUmawiamy się więc, że każda konfiguracja musi mieć kilka metod i własności, ale\nmoże je implementować na swój własny sposób. Zaczniemy do rejestru aptek:\n\n> RaConfig.pm\n\n\nuse strict;\nuse warnings FATAL => 'all';\n\npackage RaConfig;\n\n\nPo określeniu nazwy paczki utworzymy jej konstruktor. Zastosujemy do tego\nfunkcję bless, której zadaniem jest zwrócić instancję obiektu tworzonej przez\nnas klasy.\n\nPierwszym argumentem konstuktora (którego nie będziemy podawać, a ustawiamy jest\nautomatycznie w tle) jest sam moduł, na którym wywoływana jest funkcja. Coś jak\nthis, albo self w innych języakch. Wkładamy to jako drugi argument do funkcji\nbless za pomocą funkcji shift, która z tablicy z domyślnym kontekstem czyli\nwłaśnie argumentów new wyciąga pierwszy element. Za pierwszy argument funkcji \nbless podajemy zbiór własności obiektu. W tym przypadku limit równy maksymalnemu\nindeksowi strony, oraz\nrows - selektor w którym znajduje się interesująca nas treść. Pozwala on\nprzyśpieszyć wyszukiwanie bo wszystkie późniejsze zapytania będą ograniczone\ntylko od obszaru wybranego przez ten selektor.\n\nsub new { return bless {limit=>100000,rows=>'.pharmacyDetailsControl_Div.controlContainer'}, shift; }\n\n\nDla pobierania danych najważniejszą informacją jest adres url z którego można je\nuzyskać. Konstruowanie tego adresu na podstawie iterowanego indeksu strony\nwykonuje metoda source\n\nsub source { # arg index\n    return \"http://ra.rejestrymedyczne.csioz.gov.pl/_layouts/15/RA/PharmacyDetailsPublic.aspx?id=\".$_[1].\"&IsDlg=1\";\n}\n\n\nMetoda invalid pozwala nam wyłapać strony, które z jakichś powodów należy\nominąć. Podajemy do niej html, bo respons może mieć kod 200, ale jeśli jest z\nnim coś nie tak, to ta metoda zapobiegnie dalszemu przetwarzaniu tego htmla. W\ntym konkretnym przypadku zwróci ona true, jeśli html ma ciąg znaków zawarty w\nwyrażeniu regularnym:\n\nsub invalid { # arg html\n    return $_[1] =~ /ctl00_PlaceHolderPageTitleInTitleArea_ErrorPageTitlePanel/;\n}\n\n\nDo przetwarzania kluczowa jest informacja jakie klucze i selektory odpowiadają\ninstancji pobieranych danych. Tutaj strona jest prostą tabelą, której klucze\nznajdują się w elementach h3, a wartości w span. Argumentem\nmetody jest obiekt służący do wyszukiwania w dokumencie html określonych\nwartości. Za pomocą swoich metod query zwraca tablicę elementów pasujących do\nwzorca, a przez as_trimmed_text rzutuje je do ciągów znakowych wewnątrz tych\nelementów. W metodzie select kolejno: tworzymy hash - czyli strukturę danych\nzawierającą klucze i wartości bez patrzenia na kolejność. Następnie odnosimy się\ndo niej jak do tablicy co pozwala\nwłożyć tablicę zwracaną przez pierwszy selektor jako klucze, a przez drugi jako\nwartości. Na koniec zwracamy hasha.\n\nsub select { # arg query\n    my %hash;\n    @hash{$_[1]->query('.inputArea.full h3')->as_trimmed_text} = $_[1]->query('.inputArea.full span')->as_trimmed_text;\n    return %hash;\n}\n\n\nNa koniec tak jak wcześnie zwracamy 1;\n\n1;\n\n\nKlasa dla rejestru hurtowni farmaceutycznych zostanie zaprezentowana już w\ncałości, ponieważ jest bardzo podobna.\n\n> RhfConfig.pm\n\n\nuse strict;\nuse warnings FATAL => 'all';\n\npackage RhfConfig;\n\nsub new { return bless {limit=>100000,rows=>'.pharmacyDetailsControl_Div.controlContainer'}, shift; }\n\nsub source {\n    return \"http://rhf.rejestrymedyczne.csioz.gov.pl/_layouts/15/RHF/WarehouseDetailsPublic.aspx?id=\".$_[1].\"&IsDlg=1\";\n}\n\nsub invalid {\n    return $_[1] =~ /ctl00_PlaceHolderPageTitleInTitleArea_ErrorPageTitlePanel/;\n}\n\nsub select { # arg query\n    my %hash;\n    @hash{$_[1]->query('.inputArea.full h3')->as_trimmed_text} = $_[1]->query('.inputArea.full span')->as_trimmed_text;\n    return %hash;\n}\n\n1;\n\n\nTrochę inaczej natomiast skonfigurowano Skandynawsko-Polską Izbę Gospodarczą.\n\n> SpccConfig.pm\n\n\nuse strict;\nuse warnings FATAL => 'all';\n\npackage SpccConfig;\n\nsub new { return bless {limit=>12,rows=>'td.col-1'}, shift; }\n\nsub source {\n    my $link = \"https://www.spcc.pl/members/search/all/all/all\";\n    if($_[1]) { $link .= \"?page=\".$_[1]; }\n    return $link;\n}\n\nsub invalid { return 0; }\n\nsub select {\n    my $q = $_[1];\n    return (\n        'name'       => $q->query('.members_search_title')->as_trimmed_text,\n        'phone'      => $q->query('.views-field-field-telefon-value')->as_trimmed_text,\n        'person'      => $q->query('.views-field-field-kontakt-osoba-value')->as_trimmed_text,\n        'email'      => $q->query('.views-field-field-email-email')->as_trimmed_text,\n        'www'      => $q->query('.views-field-field-www-url')->as_trimmed_text,\n        'branches'     => $q->query('.views-field-phpcode-2')->as_trimmed_text\n    )\n}\n\n1;\n\n\nW kodzie widzimy, że za pobieranie danych służą już inne selektory. Nie ma\nszans, żeby kod 200 oznaczał błędą stronę oraz źródło pierwszej strony nie\nzawiera żadnych parametrów przekazywanych do adresu URL. Poza tym jednak\nwszystkie funkcji spełniają to samo zadanie. Dzięki temu w kolejnej części\nbędziemy mogli wykorzystać jeden kod do pobierania danych z każdego z tych\nźródeł.\n\nPobieranie treści\nZa samo pobieranie danych odpowiada app.pl. Zaczynamy standordowo od załadowania\nwymaganych modułów:\n\n> app.pl\n\n\n#!/usr/bin/env perl\nuse strict;\nuse warnings FATAL => 'all';\nuse LWP::Simple;\nuse open ':std', ':encoding(UTF-8)';\nuse Loader;\n\n\nLWP służy do wysyłania żądań get, Loader to nasz moduł omówiony w poprzednim\nrozdziale. Ładujemy konfigurację określoną parametrem za nazwą programu za\npomocą linii:\n\nmy $config = Loader->load();\n\n\nNastawiamy na 0 liczniki sukcesów pobierania s i błędów e.\n\nmy $e = 0;\nmy $s = 0;\n\n\nTworzymy katalog raw na pobrane dane i wewnątrz podkatalog odpowiadający\nskróconej nazwie naszego źródła danych.\n\nmkdir 'raw', 0755;\nmkdir 'raw/'.$config->{name}, 0755;\n\n\nPonieważ jest to liniowy bardzo prosty scraper, indeks podawany do metody source \nobiektu config obliczamy poprzez iterowanie go o jeden od zera do limitu\npodanego w konfiguracji.\n\nfor(my $i = 7480; $i<=$config->{limit}; $i++) {\n\n\nUrl wyciągamy za pomocą metody source podając jej właśnie ten index. Funkcja get\nz modułu LWP:Simple wysyła request do zadany adres i zwraca ciało odpowiedzi.\n\n    my $html = get $config->source($i);\n\n\nJeśli w zwróconej odpowiedzi - czyli kodzie html znajdują się informacje o\nbłędzie to metoda invalid określona w konfiguracji powinna zwrócić true. Wówczas\nwyświetli się czerwony napisa ERROR, a licznik błędów podniesie się. Spowoduje\nto również automatyczne przejście do kolejnego indeksu pętli.\n\n    if ($config->invalid($html))\n    {\n        print \"ID:\\t\" . $i . \" - \\e[31mERROR\\e[0m - [e: \".++$e.\", s: $s]\\n\";\n        next;\n    }\n\n\nJeśli wszystko poszło dobrze, to do pliku którego nazwa to po prostu index pętli\nzapisywany jest kod html strony.\n\n    open(my $fh, '>', \"raw/\".$config->{name}.\"/\".$i.\".html\") or die \"Could not open file: $!\";\n    print $fh ($html);\n    close $fh;\n\n\nIndex numerujący sukcesy podnosi się i zielony komunikat SUCCESS pojawia się an\nekranie.\n\n    print \"ID:\\t\" . $i . \" - \\e[32mSUCCESS\\e[0m - [e: $e, s: \".++$s.\"]\\n\";\n}\n\n\nCzas wykonywania pobierania zależy od szybkości łącza. U mnie time wykonany na\ntym programie dla spcc dał wynik:\n\nreal\t0m35.027s\nuser\t0m0.456s\nsys\t0m0.080s\n\n\nCo pokazuje, ogromny potencjał tkwiący w zrównolegleniu operacji pobierania\ndanych.\n\nPrzykład screenu z pobierania danch:\n\n\n\nAnaliza danych\nDo przetworzenia pobranych plkiów html do postaci pliku json służy program \njson.pl. Zastanawiałem się nad tym, czy nie włączyć tu sqlite3 albo mongodb, ale\nzależało mi na lekkiej, możliwie prostej bazie NoSQL. Niestety sqlite3 nie jest\nNoSQL, a mondodb nie jest tak łatwa w instalacji i konfiguracji. Ostatecznie\nzostałem przy zwykłym pliku json, lecz należy pamiętać, że to rozwiązanie nie\nsprawdzi się przy nprawdę dużych zbiorach danych, gdzie musimy liczyć się ze\nskończoną ilością pamięci RAM.\n\nProgram zaczyna się od ładowani modułów.\n\n> json.pl\n\n\n#!/usr/bin/env perl\nuse strict;\nuse warnings FATAL => 'all';\n\nuse HTML::Query 'Query';\nuse JSON;\nuse Loader;\n\n\nPierwszym jest HTML::Query - silnik do parsowania html i wykonywani na nim\nselektorów. Moduł JSON pozwala konwertować hashe i tablice do foramtu json. \nLoader poznaliśmy już i widzieliśmy go w akcji. Odpowiada on za ładownie\nkonfiguracji. Obok konfiguracji drugą zmienną globalną w tym programie jest\ntablica instancji obieków reprezentujących pobrane dane - firmy, apteki lub\nhurtownie.\n\nmy $config = Loader->load();\nmy @instances = ();\n\n\nPonownie robimy przebieg po wszystkich indeksach.\n\nfor(my $i = 0; $i<=$config->{limit}; $i++) {\n\n\nTym razem za opuszczenie pętli odpowiada sprawdzenie czy plik istnieje, jeśli\nnie, to przechodzimy do kolejnego przebiegu\n\n    if (! -f 'raw/'.$config->{name}.\"/\".$i.\".html\") { next; }\n\n\nJeśli plik istnieje, to ładujemy go do obiektu Query, na którym będziemy\nwykonywać selektory.\n\n    my $q = Query( file => 'raw/'.$config->{name}.\"/\".$i.\".html\" );\n\n\nOkazja do ich użycia nadarza się dość szybko. Pierwszy raz korzystamy z\nselektora określonego w konstruktorze obiektu config we własności rows. Nim\nwycinamy obszar w którym są interesujące dane. Może się okazać, że jest więcej\ntakich obszarów.\n\nNa przykład apteki mają układ z jedną apteką na stronie, a spcc ma wiele firm na\njednym widoku. Niezależnie od tego wszystkie obszary odpowiadają pojedyńczym\ninstancjom wyszukiwanego obiektu.\n\n    my @rows = $q->query($config->{rows})->get_elements(); #\n\n\nNie ważne, czy instancja jest jedna, czy jest ich kilka iterujemy po nich:\n\n    foreach my $row (@rows)\n    {\n\n\nWewnąrz pęli przesłaniamy nasze query przez query obcięte tylko do obszaru danej\ninstancji.\n\n        $q = Query( tree => $row );\n\n\nTak ustawiony selektor przekazujemy do metody select obiektu config.\n\n        my %object = $config->select($q);\n\n\nW metodzie select leżą szczegóły dotyczące tego jak parsować daną instancję\nobiektu. Tu nie musimy się tym przejmować. Istostne jest, że to co otrzymamy\nbędzie obiektem typu hash, który następnie dołączamy do tablicy instances.\n\n        push @instances, \\%object;\n    }\n}\n\n\nKiedy pętla zakończy się. Tablica instances zostaje przekazana do obiektu\nkodującego ją do formatu json. Z powodu polskich znaków obiekt dostaje po drodze\nkonfigurację nakazującą mu korzystać z utf-8.\n\nprint JSON->new->utf8(0)->encode(\n    {\n        'instances'=> \\@instances\n    }\n);\n\n\nPrzetworzenie danych dla spcc zajmuje nie całe trzy sekundy, tym razem przy\npełnym obciążenieu procesora.\n\nreal\t0m2.772s\nuser\t0m2.768s\nsys\t0m0.000s\n\n\nScreen z widokiem przetworzonych danych\n\n\n\nPodsumowanie\nProgram był pisany około pół roku temu. Teraz przed publikacją standardowo\nodrobinę go dopracowałem. Zastosowano w nim staroszkolną metodę oobsługi\nobiektów w Perlu. Warto wspomnieć, że istnieją w nim również biblioteki jak \nMoose [https://metacpan.org/pod/release/ETHER/Moose-2.0802/lib/Moose.pm], albo \nMoo [https://metacpan.org/pod/Moo] które wprowadzają obiekty dodając do nich\ntrochę tzw. \"cukru składniowego\". Jednak znacznie ciekawsze jest to, że\ndokładnie dwa tygodnie temu - 24 lipca wyszła stabilna wersja interpretera\nszóstej wersji języka Perl. Wprowadza ona obiektowość jako część natywnej\nskładni języka. Zapewnia przy tym lepsze typowanie, czyli łata chyba ten główny\nbrak Perla 5, przez który trudno było pisać w nim bezpiecznie. Być może oznacza\nto, że perl 6 powróci do wyższych poziomów\npopularności.",
            "feature_image": "__GHOST_URL__/content/images/2021/06/Hs7axWN.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:29:29.000Z",
            "updated_at": "2021-06-22T09:00:09.000Z",
            "published_at": "2021-05-11T20:37:00.000Z",
            "custom_excerpt": "Artykuł prezentuje prosty scraper napisany w perlu 5. Mimo obsługiwania trzech rejestrów danych jego kod jest wyjątkowo krótki.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f3a1c2fb35425592d0bb5",
            "uuid": "dec824b8-b4c4-4584-9e1e-31fbf37dae20",
            "title": "Instalacja odnawialnego certyfikatu TLS (certbot + apache na Ubuntu)",
            "slug": "instalacja-odnawialnego-certyfikatu-tls",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Opis projektu\\n\\nPrzez protokół rozumie się zbiór zasad wymiany informacji. Jednym z nich jest opracowany w CERN w 1989 roku protokół HTTP - określjący sposób przesyłania dokumentów hipertekstowych. Jeśli zaszyfrujemy komunikację za pomocą protokołów kryptograficznych dostaniemy HTTPS. Jego zaletą jest to że jest odporny podsłuchiwanie oraz ataki typu man-in-the-middle.\\n\\nCo do protokołów kryptograficznych, to na dzień dzisiejszy stosowanym protokołem jest TLS 1.2. Jest on następcą protokołu SSL, w którym Google wykryło poważną lukę w postaci wrażliwości na atak typu POODLE pod koniec 2014. W internecie dostępny jest też draft wersji 1.3, która ma całkowicie wyrzucić MD5 oraz RC4 uważane dzisiaj za słabe narzędzia i wprowadzić krzywe eliptyczne, które stosowane są również w BitCoinach.\\n\\nCelem tego wpisu jest pokazanie **jak za zainstalować certyfikat TLS**.\\n\\n## Instalacja\\n\\nProtokół HTTPS jest coraz powszechniej stosowany, w dużej mierze przyczyniła się do tego fundacja Let’s Encrypt, sponsorowana przez EFF, Akamai, Cisco i Mozillę. To dzięki niej powstał program certbot, który bardzo uprościł proces otrzymywania certyfikatu. Zakładam, że mamy zainstalowany system Ubuntu oraz serwer Apache 2. Żeby go zainstalować certbot wpisujemy kolejno:\\n\\n```\\napt-get install software-properties-common\\nadd-apt-repository ppa:certbot/certbot\\nENTER\\napt-get update\\napt-get install python-certbot-apache\\n```\\n\\nUruchamiamy go komendą:\\n\\n```\\ncertbot --apache\\n```\\n\\nKolejno podajemy swój e-mail, literą A potwierdzamy zgodę na warunki usługi, odpowiadaomy na pytanie, czy chcemy udostępnić e-mail i wybieramy domeny z listy domen określonych w konfiguracji Apache2. Na koniec wybieramy czy chcemy wymuszać https czy dać https jedynie jako jedną z opcji.\\n\\n## Odświerzanie\\n\\nPonieważ certyfikat wygasa po 90 dniach od jego pobrania, potrzebujemy mechanizmu jego automatycznego odświerzania. Na szczęście jest to proste. Nie zaszkodzi, jeśli będziemy go odśwerzać częściej. Zgodnie z poradnikiem zaufanej trzeciej strony dodajemy komendę doświerzającą certyfikat do crona.\\n\\n```\\ncrontab -e\\n```\\n\\na w pliku umieszczamy linię\\n\\n```\\n45 1 * * 1 /usr/bin/certbot renew >> /var/log/certbot.log\\n```\\n\\nMożemy cieszyć się już zieloną kłódką na naszej stronie.\\n\\n![](http://i.imgur.com/6LaRspC.png)\\n\\n\\n## Żródła:\\n\\nInstalacja certbot\\n\\n> https://certbot.eff.org/#ubuntuxenial-apache\\n\\nRóżnice między SSL i TLS\\n\\n> https://luxsci.com/blog/ssl-versus-tls-whats-the-difference.html\\n\\nAtak POODLE\\n\\n> https://blog.mozilla.org/security/2014/10/14/the-poodle-attack-and-the-end-of-ssl-3-0/\\n\\nPoradnik od zaufanej trzeciej strony\\n\\n> https://zaufanatrzeciastrona.pl/post/jak-wdrozyc-automatycznie-odnawiane-darmowe-certyfikaty-ssl-od-lets-encrypt/\\n\\nStatystyki wykorzystania https\\n\\n> https://www.google.com/transparencyreport/https/metrics/?hl=en\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"opis-projektu\">Opis projektu</h2>\n<p>Przez protokół rozumie się zbiór zasad wymiany informacji. Jednym z nich jest opracowany w CERN w 1989 roku protokół HTTP - określjący sposób przesyłania dokumentów hipertekstowych. Jeśli zaszyfrujemy komunikację za pomocą protokołów kryptograficznych dostaniemy HTTPS. Jego zaletą jest to że jest odporny podsłuchiwanie oraz ataki typu man-in-the-middle.</p>\n<p>Co do protokołów kryptograficznych, to na dzień dzisiejszy stosowanym protokołem jest TLS 1.2. Jest on następcą protokołu SSL, w którym Google wykryło poważną lukę w postaci wrażliwości na atak typu POODLE pod koniec 2014. W internecie dostępny jest też draft wersji 1.3, która ma całkowicie wyrzucić MD5 oraz RC4 uważane dzisiaj za słabe narzędzia i wprowadzić krzywe eliptyczne, które stosowane są również w BitCoinach.</p>\n<p>Celem tego wpisu jest pokazanie <strong>jak za zainstalować certyfikat TLS</strong>.</p>\n<h2 id=\"instalacja\">Instalacja</h2>\n<p>Protokół HTTPS jest coraz powszechniej stosowany, w dużej mierze przyczyniła się do tego fundacja Let’s Encrypt, sponsorowana przez EFF, Akamai, Cisco i Mozillę. To dzięki niej powstał program certbot, który bardzo uprościł proces otrzymywania certyfikatu. Zakładam, że mamy zainstalowany system Ubuntu oraz serwer Apache 2. Żeby go zainstalować certbot wpisujemy kolejno:</p>\n<pre><code>apt-get install software-properties-common\nadd-apt-repository ppa:certbot/certbot\nENTER\napt-get update\napt-get install python-certbot-apache\n</code></pre>\n<p>Uruchamiamy go komendą:</p>\n<pre><code>certbot --apache\n</code></pre>\n<p>Kolejno podajemy swój e-mail, literą A potwierdzamy zgodę na warunki usługi, odpowiadaomy na pytanie, czy chcemy udostępnić e-mail i wybieramy domeny z listy domen określonych w konfiguracji Apache2. Na koniec wybieramy czy chcemy wymuszać https czy dać https jedynie jako jedną z opcji.</p>\n<h2 id=\"od%C5%9Bwierzanie\">Odświerzanie</h2>\n<p>Ponieważ certyfikat wygasa po 90 dniach od jego pobrania, potrzebujemy mechanizmu jego automatycznego odświerzania. Na szczęście jest to proste. Nie zaszkodzi, jeśli będziemy go odśwerzać częściej. Zgodnie z poradnikiem zaufanej trzeciej strony dodajemy komendę doświerzającą certyfikat do crona.</p>\n<pre><code>crontab -e\n</code></pre>\n<p>a w pliku umieszczamy linię</p>\n<pre><code>45 1 * * 1 /usr/bin/certbot renew &gt;&gt; /var/log/certbot.log\n</code></pre>\n<p>Możemy cieszyć się już zieloną kłódką na naszej stronie.</p>\n<p><img src=\"http://i.imgur.com/6LaRspC.png\" alt=\"\" loading=\"lazy\"></p>\n<h2 id=\"%C5%BCr%C3%B3d%C5%82a\">Żródła:</h2>\n<p>Instalacja certbot</p>\n<blockquote>\n<p><a href=\"https://certbot.eff.org/#ubuntuxenial-apache\">https://certbot.eff.org/#ubuntuxenial-apache</a></p>\n</blockquote>\n<p>Różnice między SSL i TLS</p>\n<blockquote>\n<p><a href=\"https://luxsci.com/blog/ssl-versus-tls-whats-the-difference.html\">https://luxsci.com/blog/ssl-versus-tls-whats-the-difference.html</a></p>\n</blockquote>\n<p>Atak POODLE</p>\n<blockquote>\n<p><a href=\"https://blog.mozilla.org/security/2014/10/14/the-poodle-attack-and-the-end-of-ssl-3-0/\">https://blog.mozilla.org/security/2014/10/14/the-poodle-attack-and-the-end-of-ssl-3-0/</a></p>\n</blockquote>\n<p>Poradnik od zaufanej trzeciej strony</p>\n<blockquote>\n<p><a href=\"https://zaufanatrzeciastrona.pl/post/jak-wdrozyc-automatycznie-odnawiane-darmowe-certyfikaty-ssl-od-lets-encrypt/\">https://zaufanatrzeciastrona.pl/post/jak-wdrozyc-automatycznie-odnawiane-darmowe-certyfikaty-ssl-od-lets-encrypt/</a></p>\n</blockquote>\n<p>Statystyki wykorzystania https</p>\n<blockquote>\n<p><a href=\"https://www.google.com/transparencyreport/https/metrics/?hl=en\">https://www.google.com/transparencyreport/https/metrics/?hl=en</a></p>\n</blockquote>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f3a1c2fb35425592d0bb5",
            "plaintext": "Opis projektu\nPrzez protokół rozumie się zbiór zasad wymiany informacji. Jednym z nich jest\nopracowany w CERN w 1989 roku protokół HTTP - określjący sposób przesyłania\ndokumentów hipertekstowych. Jeśli zaszyfrujemy komunikację za pomocą protokołów\nkryptograficznych dostaniemy HTTPS. Jego zaletą jest to że jest odporny\npodsłuchiwanie oraz ataki typu man-in-the-middle.\n\nCo do protokołów kryptograficznych, to na dzień dzisiejszy stosowanym protokołem\njest TLS 1.2. Jest on następcą protokołu SSL, w którym Google wykryło poważną\nlukę w postaci wrażliwości na atak typu POODLE pod koniec 2014. W internecie\ndostępny jest też draft wersji 1.3, która ma całkowicie wyrzucić MD5 oraz RC4\nuważane dzisiaj za słabe narzędzia i wprowadzić krzywe eliptyczne, które\nstosowane są również w BitCoinach.\n\nCelem tego wpisu jest pokazanie jak za zainstalować certyfikat TLS.\n\nInstalacja\nProtokół HTTPS jest coraz powszechniej stosowany, w dużej mierze przyczyniła się\ndo tego fundacja Let’s Encrypt, sponsorowana przez EFF, Akamai, Cisco i Mozillę.\nTo dzięki niej powstał program certbot, który bardzo uprościł proces\notrzymywania certyfikatu. Zakładam, że mamy zainstalowany system Ubuntu oraz\nserwer Apache 2. Żeby go zainstalować certbot wpisujemy kolejno:\n\napt-get install software-properties-common\nadd-apt-repository ppa:certbot/certbot\nENTER\napt-get update\napt-get install python-certbot-apache\n\n\nUruchamiamy go komendą:\n\ncertbot --apache\n\n\nKolejno podajemy swój e-mail, literą A potwierdzamy zgodę na warunki usługi,\nodpowiadaomy na pytanie, czy chcemy udostępnić e-mail i wybieramy domeny z listy\ndomen określonych w konfiguracji Apache2. Na koniec wybieramy czy chcemy\nwymuszać https czy dać https jedynie jako jedną z opcji.\n\nOdświerzanie\nPonieważ certyfikat wygasa po 90 dniach od jego pobrania, potrzebujemy\nmechanizmu jego automatycznego odświerzania. Na szczęście jest to proste. Nie\nzaszkodzi, jeśli będziemy go odśwerzać częściej. Zgodnie z poradnikiem zaufanej\ntrzeciej strony dodajemy komendę doświerzającą certyfikat do crona.\n\ncrontab -e\n\n\na w pliku umieszczamy linię\n\n45 1 * * 1 /usr/bin/certbot renew >> /var/log/certbot.log\n\n\nMożemy cieszyć się już zieloną kłódką na naszej stronie.\n\n\n\nŻródła:\nInstalacja certbot\n\n> https://certbot.eff.org/#ubuntuxenial-apache\n\n\nRóżnice między SSL i TLS\n\n> https://luxsci.com/blog/ssl-versus-tls-whats-the-difference.html\n\n\nAtak POODLE\n\n> https://blog.mozilla.org/security/2014/10/14/the-poodle-attack-and-the-end-of-ssl-3-0/\n\n\nPoradnik od zaufanej trzeciej strony\n\n> https://zaufanatrzeciastrona.pl/post/jak-wdrozyc-automatycznie-odnawiane-darmowe-certyfikaty-ssl-od-lets-encrypt/\n\n\nStatystyki wykorzystania https\n\n> https://www.google.com/transparencyreport/https/metrics/?hl=en",
            "feature_image": "__GHOST_URL__/content/images/2021/06/https.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:31:24.000Z",
            "updated_at": "2021-06-22T09:05:15.000Z",
            "published_at": "2021-05-14T20:38:00.000Z",
            "custom_excerpt": "Jest wiele metod uzyskiwania certyfikatu pozwalającego szyfrować ruch http. Jedną z nich jest instalacja certbota i użycie go w zestawieniu z serwerem apache.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f3a8e2fb35425592d0bbc",
            "uuid": "e79871d2-1e46-4fe3-af77-3724c011f3cb",
            "title": "Analiza wydajności pustych pętli w 16 językach",
            "slug": "analiza-wydajnosci-pustych-petli-w-16-jezykach",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Opis projektu\\n\\nNie wiem, jakie są wasze wymarzone prezenty gwiazdkowe, ale moim jest kawałek ciekawego kodu. I właśnie taki prezent dostałem około półtora miesiąca temu.\\n\\nMój przyjaciel wysłał mi w e-mailu [Kod źródłowy programu](https://www.dropbox.com/s/s9dy1jabkzxzls6/loopspeed.zip?dl=1), który mierzył czasy wykonywania pustych pętli w czterech różnych językach programowania. Dopisałem testy dla dwunastu innych języków, lekko zautomatyzowałem testowanie i przeanalizowałem wyniki.\\n\\nW tym wpisie pokażę jak wyglądają i jak szybko działają programy wykonujące puste pętle językach:\\n\\n+ Matlab,\\n+ Bash,\\n+ SQL,\\n+ Mathematica,\\n+ C#,\\n+ JavaScript,\\n+ Python,\\n+ Ruby,\\n+ Perl,\\n+ R,\\n+ Php,\\n+ Fortran 95,\\n+ C++,\\n+ C,\\n+ Pascal\\n+ Java.\\n\\nDo logowania danych wykorzystamy plik tekstowy oraz silnik bazodanowy `SQLite`. Analizę danych przeprowadzimy w programie Mathematica.\\n\\n## Instalacja\\n\\nZ automatyzacją instalacji serwera bazy danych `mysql` zawsze wiążą się pewne problemy jak [konieczność podawania hasła](http://stackoverflow.com/questions/7739645/install-mysql-on-ubuntu-without-password-prompt) albo zmieniania [zakresu lokacji](http://askubuntu.com/questions/766334/cant-login-as-mysql-user-root-from-normal-user-account-in-ubuntu-16-04) z których można łączyć się z bazą jako `root`. Dlatego nie umieściłem instalacji serwera `mysql` w pliku `install.sh`. Jeśli nie masz serwera bazy danych, zainstaluj go ręcznie:\\n\\n```bash\\nsudo apt-get install -y mysql-server mysql-client\\n```\\n\\nNiestety, a raczej niestety dla mnie, od kilku miesięcy świeżo zainstalowany serwer `MySQL` nie pozwala już domyślnie logować się komendą `mysql -u root`, zamiast tego wymaga `sudo mysql -u root`. Jest to zrozumiałe ze względów bezpieczeństwa i na pewno pomaga na serwerach produkcyjnych, ale z drugiej strony jest to niewygodne przy bawieniu się kodem w domu. Jeśli twój komputer to maszyna lokalna i tak jak ja nie chcesz używać `sudo` do każdego łączenia z bazą z `basha`, możesz wykonać następujący [manewr](http://stackoverflow.com/questions/38098505/mysql-works-with-sudo-but-without-not-ubuntu-16-04-mysql-5-7-12-0ubuntu1-1):\\n\\n```bash\\nsudo mysql -u root\\nDROP USER 'root'@'localhost';\\nCREATE USER 'root'@'%' IDENTIFIED BY '';\\nGRANT ALL PRIVILEGES ON *.* TO 'root'@'%';\\nFLUSH PRIVILEGES;\\nexit\\n```\\n\\nw ten sposób przywrócisz `mysql -u root` jako działającą metodę łączenia się z bazą. Prezentowany tutaj program używa właśnie takiej metody -  to znaczy bez `sudo`.\\n\\nJeśli nie chcesz zmieniać ustawień bazy danych zawsze możesz użyć [zmiennych środowiskowych](https://dev.mysql.com/doc/refman/5.7/en/environment-variables.html).\\n\\n```bash\\nexport MYSQL_PWD=<your password to mysql server>\\nexport MYSQL_HOST=localhost;\\n```\\n\\nNie jest to rozwiązanie, które należy stosować na serwerach produkcyjnych, natomiast świetnie nadaje się na maszyny lokalne, bo jest wygodne.\\n\\nŻeby sprawdzić, czy Twoja konfiguracja bazy jest poprawna wykonaj komendę:\\n\\n```bash\\nmysql --user=root \\\"$MYSQL_DATABASE\\\" -e \\\"SELECT 'OK' as 'state'\\\"\\n```\\n\\nJeśli zobaczysz\\n\\n```sql\\n+-------+\\n| state |\\n+-------+\\n| OK    |\\n+-------+\\n```\\n\\nto reszta instalacji jest jeszcze prostsza.\\n\\nInstalację projektu na czystym Ubuntu 16.04.1 LTS wymaga wpisania trzech komend:\\n\\n```bash\\nsudo apt-get install git\\ngit clone --depth=1 http://gitlab.com/gustawdaniel/loopspeed && cd loopspeed\\nsudo bash install.sh\\nperl util/parameters_load.pl\\n```\\n\\nJest to pierwszy wpis z repozytorium na `gitlabie` a nie `githubie`. Nie jest to przypadek, lecz zasługa świetnego narzędzia do ciągłej integracji - `gitlab-ci`, które omówię na samym końcu.\\n\\nTeraz przyjrzymy się skryptom: instalacyjnemu i ładującemu parametry.\\n\\nSkrypt instalacyjny `install.sh` wykonuje aktualizację listy dostępnych paczek i instalację wymaganych kompilatorów i interpreterów języków:\\n\\n```bash\\n#!/usr/bin/env bash\\n\\napt-get update -y\\napt-get install -y php\\napt-get install -y python default-jdk g++ mono-mcs gfortran fp-compiler r-base nodejs-legacy ruby\\n```\\n\\ndorzuca do tego kilka programów, które wykorzystujemy\\n\\n```bash\\napt-get install -y sqlite3 bc git mysql-client curl\\n```\\n\\noraz paczki perla, których używamy głównie do komunikacji z bazą danych `SQLite`\\n\\n```\\napt-get install -y libtext-csv-perl libdbi-perl libdbd-sqlite3-perl\\n```\\n\\nNastępnie tworzy bazę do przechowywania wyników pomiarów oraz wyliczonych na ich podstawie parametrów:\\n\\n```bash\\nsqlite3 log/log.db \\\\\\n\\\"create table IF NOT EXISTS log (\\n    id INTEGER PRIMARY KEY,\\n    name VARCHAR(255),\\n    size UNSIGNED INTEGER,\\n    time DECIMAL(12,6),\\n    git CHAR(41)\\n);\\\"\\n\\nsqlite3 log/log.db \\\\\\n\\\"create table result (\\n    name varchar(255),\\n    a real,\\n    b real,\\n    ea real,\\n    eb real\\n);\\\"\\n```\\n\\nI na koniec instalator pobiera bibliotekę do testowania kodu pisanego w `bashu` - `shunit2`.\\n\\n```bash\\ncurl -L \\\"https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/shunit2/shunit2-2.1.6.tgz\\\" | tar zx\\n```\\n\\nDrugim skryptem który wykonaliśmy był\\n\\n> util/parameters_load.pl\\n\\n```perl\\n#!/usr/bin/perl -w\\n\\nuse v5.10;\\nuse strict;\\nuse warnings;\\nuse autodie;\\n\\nuse Text::CSV_XS;\\nuse DBI;\\n\\nmy $dbh = DBI->connect(\\n    \\\"dbi:SQLite:log/log.db\\\", \\\"\\\", \\\"\\\",\\n    {\\n        RaiseError => 1, AutoCommit => 0\\n    }\\n);\\n\\n$dbh->do(\\\"DELETE FROM result\\\");\\n\\n# Using bind parameters avoids having to recompile the statement every time\\nmy $sth = $dbh->prepare(<<'SQL');\\nINSERT INTO result\\n       (name, a,     b,     ea,    eb)\\nVALUES (?,    ?,     ?,     ?,     ?)\\nSQL\\n\\nmy $csv = Text::CSV_XS->new or die;\\nopen my $fh, \\\"<\\\", \\\"config/parameters.csv\\\";\\nwhile(my $row = $csv->getline($fh)) {\\n    $sth->execute(@$row);\\n}\\n$csv->eof;\\nclose $fh;\\n\\n$sth->finish;\\n$dbh->commit;\\n```\\n\\nJego zadaniem jest przeniesienie zawartości pliku tekstowego `config/parameters.csv` do tabeli `result` bazy danych `log/log.db`. Przenoszone dane dotyczą szacowanych czasów wykonywania pętli i zostały wyliczone z wyników przeprowadzonych wcześniej pomiarów.\\n\\n\\nDwa z języków, które testowałem - `Matlab` i `Mathematica` - wymagają zainstalowanego licencjonowanego oprogramowania. Co prawda, studenci mają zwykle te licencje dzięki uczelniom, ale ze względu na to, że jest licencjonowane, testy dla tych języków są domyślnie wyłączone.\\n\\n## Framework\\n\\nNasz program do testowania pustych pętli ma następującą strukturę katalogów:\\n\\n```\\n├── config\\n│   ├── list.txt\\n│   └── parameters.csv\\n├── inc\\n│   ├── def.sql\\n│   ├── inc.bash\\n│   ├── inc.c\\n│   ├── inc.cpp\\n│   ├── inc.cs\\n│   ├── inc.f95\\n│   ├── inc.java\\n│   ├── inc.js\\n│   ├── inc.m.sh\\n│   ├── inc.p\\n│   ├── inc.perl\\n│   ├── inc.php\\n│   ├── inc.python\\n│   ├── inc.r\\n│   ├── inc.rb\\n│   ├── inc.sql.sh\\n│   └── inc.wl\\n├── util\\n│   ├── generate_parameters.wl\\n│   ├── parameters_load.pl\\n│   ├── text_to_sqlite.pl\\n│   ├── timing_methods.sh\\n│   └── timing.sh\\n├── log\\n│   ├── log.db\\n│   ├── results_timing_methods.log\\n│   └── results.log\\n├── install.sh\\n├── analysis.nb\\n├── inc.bash\\n├── test.sh\\n├── README.md\\n└── .gitlab-ci.yml\\n```\\n\\nKatalog `config` zawiera pliki pomocnicze z ustawieniami. Pierwszym z nich jest lista parametrów dla których będziemy wykonywać serie testowe `config/list.txt` - zwykły plik tekstowy z liczbami całkowitymi w kolejnych liniach. Drugim oszacowane wartości parametrów określających szybkość wykonywania pustych pętli `config/parameteres.csv`.\\n\\nW `inc` znajduje się 16 plików odpowiadających za testowanie pętli oraz jeden do definiowania procedury w `MySQL`, która dopiero, kiedy zostanie wywołana wywołana będzie wykonywać pętle.\\n\\nW `util` umieściłem narzędzia pomocnicze, które pozwalały mi na przerzucanie danych z pliku tekstowego do bazy `SQLite`, oraz mierzenie różnic między wynikami dwóch metod pomiaru czasu trwania programu. Jest tam też skrypt do dopasowywania modelu i tworzenia pliku `config/parameters.csv`, oraz skrypt do ładowania tych parametrów do bazy danych `sqlite`. Wykorzystanie plików tekstowych do logowania wyników pomiarów jest z jednej strony związane z rozwijaniem tego softu. Pliki tekstowe były stosowane zanim przeszedłem na silnik bazodanowy. Z drugiej strony nie chciałem zaśmiecać bazy danymi pomiarowymi, których nie byłem pewien, więc jeśli istniało ryzyko, że program, który testuję będzie działał źle - na przykład kiedy spodziewałem się, że wyjdę poza zakres danego typu liczbowego - wyłączałem logowanie do bazy i posługiwałem się tylko plikiem. Jeśli wszystko było ok, mogłem bez problemu załączyć nowe wyniki do uzyskanych wcześniej.\\n\\nKatalog `log` służy do przechowywania plików tekstowych oraz bazy danych `SQLite`. Plik `result.log` zawiera kopię danych, które trafiają do bazy danych, `results_timing_methods.log` przechowuje wyniki pomiarów czasu. Podczas testowania w tym katalogu pojawiają się na czas testów inne pliki z logami.\\n\\nPoza tym projekt zawiera:\\n\\n+ `install.sh` - skrypt instalacyjny (omówiłem go w poprzednim paragrafie),\\n+ `inc.bash` - bazowy skrypt do robienia pomiarów czasu trwania pustych pętli,\\n+ `analysis.nb` - notebook programu Mathematica. Służył on do badania wyników.\\n+ `test.sh` - skrypt do testowania działania `inc.bash` oraz innych elementów projektu.\\n\\nDzięki takiej strukturze jesteśmy w stanie bez problemu dodawać nowe języki programowania. Trzymanie w bazie numeru rewizji pozwala nam również sprawdzać, jak różne instrukcje spełniające teoretycznie tą samą funkcjonalność (np: `for` vs `while`) różnią się od siebie wydajnością.\\n\\n## Dataflow\\n\\nPrzepływ danych w programie posiada wbudowane sprzężenie zwrotne. Z jednej strony `inc.bash` testuje pętle za pomocą parametrów wyliczonych z modelu za pomocą `util/generate_parameters.wl`, z drugiej strony, żeby móc dopasować model do danych, musieliśmy je najpierw dostać właśnie uruchamiając `inc.bash`.\\n\\nPatrząc na wykres przepływu danych łatwo znajdziemy zamknięte koło, które mam na myśli.\\n\\n[![Loopspeed.png](https://s9.postimg.org/fbg1yihnz/Loopspeed.png)](https://postimg.org/image/mrfbkb5d7/)\\n\\nJest to klasyczny problem, co było pierwsze, jajko czy kura? Pierwszy był model teoretyczny, który określił co warto mierzyć czy dane doświadczalne, dzięki którym możemy go zgadnąć? Tak jak w biologicznym odpowiedniku, tak tutaj odpowiedzią jest ewolucja. Początkowo każdy z programów `inc.i`, (gdzie `i` jest numerem testowanego języka programowania) był włączany ręcznie. Z jedną pętlą. Później z tysiącem, milionem, miliardem. Kiedy widziałem, że wykonuje się dłużej niż kilka sekund obniżałem liczbę pętli, kiedy krócej niż sekundę podnosiłem ją. Dążyłem do tego, żeby ręcznie znaleźć liczbę pętli odpowiadającą miej więcej 4-5 sekund wykonywania programu. Tak uzyskiwałem pierwsze wartości parametrów, które jeszcze wtedy były wpisywane ręcznie do kodu programu `inc.bash`. Dzięki temu uwspólniłem skalę dla wszystkich z wyjątkiem języka `Matlab`, którego inicjalizacja trwała 5 sekund z kawałkiem. Dla `Matlaba` robiłem oddzielną serię pomiarową zanim go wyczułem. Dane z tego typu testów trafiały do pliku `results.log`, ale o tym czy przenosić je do `log.db` decydowałem na podstawie zdrowego rozsądku, w jednym przypadku zdarzyło się, że dla jednego z języków czasy rosły wraz z liczbą pętli `$size` do pewnego momentu, a zaczęły trzymać się stałego poziomu. Okazało się, że zakresy zmiennych nie wystarczają do pomieszczenia liczby iteracji i jest ona po prostu rzutowana na mniejszą wartość. Były przypadki (`python` oraz `r`) gdzie brakowało pamięci RAM, bo pętla `for` zamiast inkrementować skalarny wskaźnik była skonstruowana tak, że ładowała do pamięci operacyjnej całą tablicę, po której później przebiegała. Ogólnie rzecz biorąc, nie dało by się zupełnie zautomatyzować testów na tym etapie. W niektórych językach trzeba było zmieniać typy, na przykład w `Pascalu` zwykły `Int` nie wystarczył i trzeba było stosować `QWord`, analogicznie w `C#` typ `Int32` był zmieniany na `UInt64`. Podsumowując: początkowo model istniał tylko w mojej głowie. Na początku nie było `analysis.nb` ani `list.txt`, `inc.bash` zawierał zakodowane na sztywno przybliżone szybkości pętli i nie miał tylu opcji, z którymi można było go włączać.\\n\\nKiedy `results.log` rozrósł się, a ja zrozumiałem, że testowanie w stronę krótszych czasów jest nieopłacalne bo generuje za dużo błędu pomiarowego, a w stronę dłuższych czasów nieopłacalne, bo nie wnosi żadnych nowych efektów, wtedy powstał program `text_to_sqlite.pl` do konwertowania pliku tekstowego do postaci wierszy w bazie danych. Zrezygnowałem z zapisywania zmiennej `$speed` - szybkości pętli, jako, że dzięki silnikowi bazodanowemu jej wyliczanie było prostsze, uznałem natomiast, że jeśli wprowadzam zmiany w programach `inc.i`, to w danych może pojawić się bałagan. Żeby móc wykrywać, z jakiej wersji programu pochodzą dane zapisy dodałem zmienną `$git` z numerem rewizji. Wtedy powstał notebook `analysis.nb` i z jego pomocą wyliczyłem parametry do `bash.inc` z większą dokładnością.  Zaplanowałem też serię pomiarową `list.txt` która wykładniczo rozrzedzała się dla rosnących czasów pomiarów. Na koniec obliczanie parametrów przeniosłem do skryptu `util/generate_parameters.wl`, dopisałem `util/parameters_load.pl` do ich konwersji do bazy `sqlite` i podłączyłem te dane do `inc.bash`. Dzięki modelowi mogłem wyliczyć ile czasu będzie trwał jaki pomiar. W ten sposób obieg danych zamknął się. Model zaczął wyznaczać optymalne punkty pomiarowe, a uzyskiwane dane zaczęły płynąć w coraz bardziej zautomatyzowany i zracjonalizowany sposób.\\n\\n### Jądro programu\\n\\nKiedy wiemy już co jak działa i do czego służy obejrzymy kod programu `inc.bash`. Program zaczyna się od funkcji odpowiedzialnej za wyświetlanie okna pomocy.\\n\\n> inc.bash\\n\\n```bash\\n#! /bin/bash\\n\\nshow_help() {\\ncat << EOF\\nUsage: bash inc.bash [-a](-f|-l) (single_number|-f file_with_numbers_in_lines)\\n\\n    -h          display this help and exit\\n    -a          all programs enable, enable this only if you have\\n                license on Mathematica and Matlab.\\n    -t          time based mode of calculations. You assign number\\n                of seconds for each program. Programs goes equally.\\n    -l          line based mode of calculations. You assign number\\n                of lines executed by loop. Good mode for debug.\\n    -f file     load numbers of seconds (-t) or loops (-l) from file,\\n                default config/list.txt\\nEOF\\n}\\n```\\n\\nWidzimy, że posiada on kilka flag, z których możemy korzystać. Pierwszą znich jest `-a` służąca do wykonywania testów z wykorzystaniem oprogramowania komercyjnego: `matlab` i `mathematica`. Domyślnie jest to wyłączone, żeby program był dostępny bez konieczności ich instalowania. Następnie mamy do wyboru `-t` i `-l` odpowiadających za sposób wyznaczania ilości pętli. W opcji `-t` użytkownik wyznacza czas w sekundach jaki ma zająć wykonywanie każdego z badanych programów `inc/inc.i`, na podstawie tego czasu i parametrów wyznaczonych wcześniej przez `util/generate_parameters.wl` określane są liczby pętli dla każdego z nich. Opcja `-l` pozwala na pomiar dokładnej ilości pętli jakie chcemy wykonać. Na koniec określamy liczbowo ilość oczekiwanych sekund lub wykonywanych pętli albo za pomocą flagi `-f` ładujemy plik z serią pomiarową. Następnie program stosuje bardzo ciekawy mechanizm czyszczenia po sobie niezależnie od sposobu w jaki ma zostać zamknięty.\\n\\n```bash\\nfunction onExit {\\n\\t[ ! -z \\\"$TMP\\\" ] && \\\\\\n\\t[   -d \\\"$TMP\\\" ] && \\\\\\n\\trm -Rf \\\"$TMP\\\";\\n\\trm -f inc.class;\\n\\texit;\\n}\\n```\\n\\nZastosowano tutaj ciekawą składnię z flagami `-z` i `-d`. Dokumentacja [basha](http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html) wyjaśnia, że lokalizacja wskazywana przez zmienną `$TMP` ma zostać usunięta jeśli zmienna `$TMP` coś w ogóle zawiera i jeśli wskazuje na katalog. Kolejna linia to usunięcie pliku pochodzącego z kompilacji `javy`, który nie trafił do `$TMP` tylko dlatego, że nie potrafiłem go tam wrzucić.\\n\\nFunkcja `onExit` wykona się przy zamykaniu programu, co będzie zaznaczone później. Teraz przyjrzymy się funkcji `test` - kompletującej wszystkie dane, wykonującej testy i wysyłającej dane do bazy oraz pliku. Jest to centralny punkt całego systemu, odpowiada ona za uwspólnienie interfejsu wszystkich programów.\\n\\n```bash\\nfunction test {\\n\\tname=\\\"$1\\\";\\n\\tsize=\\\"$2\\\";\\n\\tcomm=\\\"${@:3}\\\"\\n```\\n\\nPrzyjmuje ona na wejściu trzy lub więcej parametrów. Pierwszy to nazwa: zwykle `inc.<rozszerzenie języka>` np: `inc.c` lub `inc.js`. Nie jest ona w żaden sposób powiązana ani z lokalizacją pliku źródłowego, ani wykonywalnego. W zasadzie mogła by być dowolna. Przyjąłem jednak konwencję, że nazywa się tak jak plik źródłowy. Drugi parametr to liczba pętli jaka ma zostać wykonana `$size`. Kolejne parametry, niezależnie od ich ilości wrzucane są do zmiennej `$comm` - jest to komenda do włączenia programu, ale bez liczby pętli.\\n\\n```bash\\n    [ $size -le 0 ] && return;\\n```\\n\\nPo zabezpieczeniu się, że liczba pętli nie może być ujemna funkcja `test` może wykonywać pomiar czasu.\\n\\n```bash\\n    time=`bash util/timing.sh $comm $size`\\n\\techo $name,$size,$time,$GIT\\t\\\\\\n\\t    | tee -a log/results.log \\\\\\n\\t    | awk -F ',' '{printf \\\"| %-12s | %15s | %12.6f s | %19.2f |\\\\n\\\", $1, $2, $3, $2/$3;}'\\n```\\n\\nWidzimy, że wykorzystuje do tego program `util/timing.sh` podając mu komendę do wykonania wraz z liczbą pętli. Wynik działania programu `timing.sh` przekazywany jest do zmiennej `time`. Następnie nazwa, ilość tętli, czas i numer rewizji wysyłane są do pliku `log/results.log` oraz a nazwa, ilość pętli, czas i szybkość wyświetlane na ekranie. Numer rewizji znajduje się w globalnej zmiennej `GIT` i będzie zdefiniowany później. Ten sam zestaw danych, który zapisany było do pliku `log/resutls.log` trafia do bazy danych.\\n\\n```bash\\n     sqlite3 log/log.db  \\\"insert into log (name,size,time,git) values ('$name',$size,$time,'$GIT');\\\"\\n}\\n```\\n\\nKolejna funkcja służy głównie uporządkowaniu kodu programu i zostanie wywołana tylko raz bez żadnych parametrów.\\n\\n```bash\\nfunction compile {\\n    g++ -O1 -o \\\"$TMP/cpp\\\" 'inc/inc.cpp';\\n    gcc -O1 -o \\\"$TMP/c\\\"   'inc/inc.c';\\n    mcs -out:\\\"$TMP/cs.exe\\\" inc/inc.cs\\n    javac 'inc/inc.java' -d .;\\n    mysql -u root < inc/def.sql;\\n    f95 -O1 -o \\\"$TMP/f\\\" inc/inc.f95\\n    fpc -O2 inc/inc.p -o\\\"$TMP/p\\\" -Tlinux &>/dev/null\\n}\\n```\\n\\nWykonuje ona kompilacje języków które tego wymagają. Czas kompilacji nie jest nigdzie mierzony.\\n\\nZupełnie inaczej jest z funkcją `calculate` obliczającą ilość pętli która ma się wykonać. Ta funkcja będzie wykonywana przy każdym pojedynczym teście. Jej działanie uzależnione jest od wartości zmiennej globalnej `$timeMode`. Jeśli włączamy program z flagą `-l` to `$timeMode=0` i funkcja zwróci nam swój pierwszy argument oraz wartość liczbową zmiennej globalnej `$POW`. Jedynym argumentem tej funkcji jest nazwa języka - u nas zapisywana jako `inc.<rozszerzeie>`. Zmienna `$POW` odpowiada liczbie którą podajemy do programu niezależnie czy robimy to za jego nazwą, czy jest to jedna z liczb z pliku jaki wrzucamy za flagą `-f`. Jeśli program działa z flagą `-t` to za pomocą programu `awk` wyliczamy liczbę pętli ze wzoru `(pow-b)/a` gdzie `pow` jest czasem w sekundach, natomiast `b` oraz `a` są parametrami dopasowania prostej. Nasze `a` i `b` to w programie elementy tablicy asocjacyjnej, którą będziemy niedługo definiować.\\n\\n```bash\\n# number of loops for given languages in dependence from $timeMode\\nfunction calculate {\\n\\n    if [[ \\\"$timeMode\\\" -eq \\\"1\\\"  ]]; then\\n        echo $1 ${a[$1]} ${b[$1]} $POW | awk '{ printf \\\"%s %.0f\\\\n\\\", $1, ($4-$3)/$2 }';\\n    else # linemode for debug\\n        echo $1 $[1*POW];\\n    fi\\n}\\n```\\n\\nTymczasem przyjżymy się funkcji odpowiedzialnej za testowanie całego zbioru programów dla danego parametru `$POW`.\\n\\n```bash\\nfunction testbundle {\\n    [ \\\"$allPrograms\\\" -eq \\\"1\\\" ] && test    $(calculate inc.m.sh    )    bash    inc/inc.m.sh; # long time of setup about 5 sec\\n    test    $(calculate inc.bash    )    bash    inc/inc.bash;\\n    test    $(calculate inc.sql.sh  )    bash    inc/inc.sql.sh;\\n    [ \\\"$allPrograms\\\" -eq \\\"1\\\" ] && test    $(calculate inc.wl      )    MathematicaScript -script inc/inc.wl;\\n    test    $(calculate inc.r       )    Rscript inc/inc.r;\\n    test    $(calculate inc.cs      )    mono    \\\"$TMP/cs.exe\\\";\\n    test    $(calculate inc.js      )    node    inc/inc.js;\\n    test    $(calculate inc.python  )    python  inc/inc.python;\\n    test    $(calculate inc.rb      )    ruby    inc/inc.rb;\\n    test    $(calculate inc.pl      )    perl    inc/inc.pl;\\n    test    $(calculate inc.php     )    php     inc/inc.php;\\n    test    $(calculate inc.f95     )    \\\"/$TMP/f\\\";\\n    test    $(calculate inc.cpp     )    \\\"$TMP/cpp\\\";\\n    test    $(calculate inc.c       )    \\\"$TMP/c\\\";\\n    test    $(calculate inc.p       )    \\\"$TMP/p\\\";\\n    test    $(calculate inc.java    )    java inc;\\n}\\n```\\n\\nWidzimy, że sprawdza ona wartość zmiennej `$allPrograms` powiązanej z flagą `-a`, żeby włączać testy `mathematica` i `matlab` tylko jeśli ustawiono tą flagę. Poza tym wykonuje ona bardzo powtarzalny schemat - dla każdego programu włącza funkcję `test`. Za dwa pierwsze parametry - nazwę i liczbę pętli podstawia wynik funkcji `calculate`, wszystkie pozostałe są zwijane do komendy odpalającej testowany program.\\n\\nDo wyjaśnienia pozostaje jeszcze - skąd wzięły się tablice asocjacyjne  parametrami. Za ich utworzenie odpowiada funkcja `loadParams`.\\n\\n```bash\\nfunction loadParams {\\nsource <(sqlite3 log/log.db \\\"select name, a from result\\\" |\\n         awk -F '|' '{printf(\\\"a[%s]=%s;\\\\n\\\",$1,$2);}')\\n\\nsource <(sqlite3 log/log.db \\\"select name, b from result\\\" |\\n         awk -F '|' '{printf(\\\"b[%s]=%s;\\\\n\\\",$1,$2);}')\\n}\\n```\\n\\nStosowana tu składnia z wykorzystaniem `source` jest bardzo niezalecana w przypadku danych pochodzących od użytkowników. Tutaj jednak dane sami generujemy i uznałem, że jest to najłatwiejszy sposób na zdefiniowanie tych tablic. `Source` odpowiada za wykonanie kodu, który dostaje, a dostaje przetworzone do postaci np: `a[inc.bash]=4.231982349e-06` wyniki zapytań do tabeli z parametrami.\\n\\nLogika skryptu jest dość przewidywalna. Zaczyn się od przejścia do katalogu gdzie zlokalizowany jest skrypt. Następnie ustawiamy coś w rodzaju nasłuchu na zdarzenia `SIGINT`, `SIGTERM ` i `EXIT`. Oznacza to, że jeśli będziemy chcieli wyłączyć program zanim skończy działać, to po sobie posprząta.\\n\\n```bash\\ncd \\\"$(dirname \\\"${BASH_SOURCE[0]}\\\")\\\";\\ntrap onExit SIGINT SIGTERM EXIT;\\n```\\n\\nJeśli zastanawiasz się, co tu jest do sprzątania, to kolejna linijka stanowi odpowiedź na Twoje pytanie. Tworzymy w niej katalog tymczasowy do przechowywania skompilowanych wersji programów i wstawiamy jego lokalizację do zmiennej `$TMP`.\\n\\n```bash\\nTMP=\\\"$(mktemp -d)\\\";\\n```\\n\\nDo zmiennej globalnej `$GIT` przypisujemy aktualny numer rewizji.\\n\\n```bash\\nGIT=`git rev-parse HEAD`;\\n```\\n\\nTworzymy tablice asocjacyjne `a` oraz `b`\\n\\n```bash\\ndeclare -A a\\ndeclare -A b\\n```\\n\\nI ustawiamy domyślne wartości wszystkich falg oraz zmiennych.\\n\\n```bash\\nallPrograms=0; # if all programs should be tested? Default: no, because licence is not free.\\nconfigFile='config/list.txt';\\ntimeMode=1;\\nfileMode=0;\\n```\\n\\nW pętli `while` przetwarzamy wszystkie danej wprowadzone przez użytkownika.\\n\\n```bash\\nwhile getopts hatlf opt; do\\n    case $opt in\\n        h)\\n            show_help\\n            exit 0\\n            ;;\\n        a)  allPrograms=$((allPrograms+1))\\n            ;;\\n        t)  timeMode=1;\\n            ;;\\n        l)  timeMode=0;\\n            ;;\\n        f)  configFile=${2:-${configFile}}; fileMode=1;\\n            ;;\\n        *)\\n            show_help >&2\\n            exit 1\\n            ;;\\n    esac\\ndone\\nshift \\\"$((OPTIND-1))\\\" # Shift off the options and optional --.\\n```\\n\\nPo wychwyceniu wszystkich opcji przechwytujemy jeszcze parametr określający liczbę pętli lub sekund. Ładujemy parametry do tablic asocjacyjnych i kompilujemy programy.\\n\\n```bash\\nPOW=${1:-4};\\nloadParams;\\ncompile\\n```\\n\\nWyświetalmy przyjazne elementy interfejsu użytkownika z nagłówkami tabeli.\\n\\n```bash\\necho '+--------------+-----------------+----------------+---------------------+';\\necho '|     File     |      Size       |      Time      |        Speed        |';\\necho '+--------------+-----------------+----------------+---------------------+';\\n\\n```\\n\\nWykonujemy testowanie odpowiednią liczbę razy.\\n\\n```bash\\nif [[ \\\"$fileMode\\\" -eq \\\"1\\\" ]]; then\\n   while IFS='' read -r POW || [[ -n \\\"$POW\\\" ]]; do\\n      testbundle;\\n   done < ${1:-${configFile}}\\nelse\\n  testbundle;\\nfi\\n```\\n\\nI kończymy program domknięciem tabeli.\\n\\n```bash\\necho '+--------------+-----------------+----------------+---------------------+';\\n```\\n\\n### Skrypty usprawniające przepływ danych\\n\\nZ czasem zwiększania ilości danych i testowania nowych zakresów pojawiła się potrzeba automatyzacji procesu przepływu danych. Służy do tego kilka poniższych skryptów.\\n\\nDo przerzucania tekstowych wyników pomiarów do bazy danych służy program:\\n\\n> util/text_to_sqlite.pl\\n\\n```perl\\n#!/usr/bin/perl -w\\nuse warnings FATAL => 'all';\\nuse DBI;\\nuse strict;\\n#https://mailliststock.wordpress.com/2007/03/01/sqlite-examples-with-bash-perl-and-python/\\nmy $db = DBI->connect(\\\"dbi:SQLite:log/log.db\\\", \\\"\\\", \\\"\\\",{RaiseError => 1, AutoCommit => 1});\\n\\n\\nmy $filename =  $ARGV[0] || 'log/results.log';\\n```\\n\\nPo nagłówkach mamy tutaj zmienną `$db` przechowującą połączenie z bazą i `$filename` pobierającą argument z linii komend z domyślą wartością ustawioną na lokalizację pliku z logami. Takie ustawienie zmiennych dawało elastyczność, a jednocześnie nie wymagało wpisywania parametrów w najbardziej powtarzalnych sytuacjach. Następnie program otwierał plik:\\n\\n```perl\\nopen( my $fh => $filename) || die \\\"Cannot open $filename: $!\\\";\\n```\\n\\ni iterując po jego liniach zapisywał odpowiednio przekształcone rekordy do bazy:\\n\\n```perl\\nwhile(my $line = <$fh>) {\\n        my @row = split(\\\",\\\",$line);\\n        $db->do(\\\"INSERT INTO log (name,size,time,git) values ('\\\".$row[0].\\\"',$row[1],$row[2],'$row[3]');\\\");\\n}\\nclose($fh);\\n```\\n\\n\\n\\n## Analiza\\n\\n\\nZdarzało nam się na tym blogu analizować dane. Schemat jest prosty. Łączymy się z bazą. Wyciągamy dane do zmiennej, dopasowujemy model, na koniec rysujemy wykresy lub eksportujemy wyniki obliczeń.\\n\\nOmówimy teraz skrypt który przekształca wyniki pomiarów na parametry modelu.\\n\\n> util/generate_parameters.wl\\n\\n```\\n(*MathematicaScript -script util/generate_parameters.wl*)\\n\\nNeeds[\\\"DatabaseLink`\\\"]\\nconn = OpenSQLConnection[\\n  JDBC[\\\"SQLite\\\", $InitialDirectory <> \\\"/log/log.db\\\"]];\\n\\nPrint[\\\"Conection with database established...\\\"];\\n```\\n\\nSkrypt zaczyna pracę od połączenia do bazy. Robi to za pomocą dwóch linii kodu. Pierwsza z nich to importowanie paczki. Druga zapisuje do zmiennej `conn` nowe połączenie realizowane za pomocą interfejsu `JDBC`. Zmienna `$InitialDirectory` zwraca lokalizację z której startujemy, a znaki `<>` są operatorem konkatenacji stringów. W ten sposób `JDBC` przyjmuje tu tylko dwa argumenty: nazwę silnika bazodanowego i lokalizację pliku z bazą.\\n\\nPierwsze zapytanie do bazy wyciąga listę języków jakich używamy.\\n\\n```\\nlist = Flatten[\\n  SQLExecute[conn, \\\"SELECT name FROM log GROUP BY name\\\"]];\\n```\\n\\nZa wykonanie zapytania na połączeniu `conn` odpowiada `SQLExecute`. Komenda `Flatten` służy spłaszczeniu tablicy, która w przeciwnym wypadku była by tablicą tablic. Jest to związane z tym, że jeśli wybieramy więcej niż jeden atrybut to tablica dwuwymiarowa jest bardziej naturalnym sposobem reprezentacji wyniku zapytania. Widać to dobrze na przykładzie kolejnego zapytania, a raczej całej serii zapytań wykonywanych wewnątrz instrukcji `Table`:\\n\\n```\\ndata = Table[{i,\\n  SQLExecute[conn,\\n    \\\"SELECT size,time FROM log WHERE name='\\\" <> ToString[i] <>\\n        \\\"'\\\"]}, {i, list}];\\n\\nPrint[\\\"Data extracted from database...\\\"];\\n```\\n\\nTutaj do zmiennej `data` zapisujemy tablicę, która iterując po wyciągniętej wcześniej liście języków każdy swój element układa w dwuelementowa tablicę. Pierwszy z nich jest właśnie tą nazwą, drugi jest tablicą par zmiennych `size` i `time`, czyli liczb pętli i czasów wykonywania odpowiadających danemu językowi.\\n\\n\\n\\nKolejny \\\"oneliner\\\" odpowiada za modelowanie:\\n\\n```\\nnlm = NonlinearModelFit[Log[data[[#, 2]]],\\n  Log[Exp[a] Exp[x] + b^2], {a, b}, x] & /@ Range[list // Length];\\n\\nPrint[\\\"Nonlienear models calculated...\\\"];\\n```\\n\\nPierwsza linijka dopasowuje modele dla wszystkich języków za jednym razem. Rozłożymy ją na czynniki pierwsze.\\n\\nZacznijmy od najbardziej tajemniczych znaczków, czyli składni `f[#]&/@{1,2,3}` . Znaki `a/@b` oznaczają mapowanie, czyli zastosowanie operacji `a` do elementów pierwszego poziomu tablicy `b`. Znak `#` oznacza slot na włożenie danych, a `&` jest znacznikiem informującym, że to co nastąpi później będzie wkładane do slotów. Tak więc `f[#]&[a]` jest tym samym co `f[a]`. Ostatecznie `f[#]&/@{1,2,3}` jest równoważne `{f[1],f[2],f[3]}`. Wielkość `list//Length` to długość zmiennej `list`. W naszym przypadku `16`. Funkcja `Range` tworzy tablicę od jedności do swojego argumentu. Dlatego `Range[list//Length]` będzie tablicą od `1` do `16`. Więc te liczby kolejno będziemy wkładać do slotu oznaczonego `#` w wyrażeniu `NonlinearModelFit`.\\n\\n`NonlinearModelFit` jest funkcją języka `Mathematica` odpowiadającą za dopasowywanie modelu do danych, oraz zwracanie dodatkowych informacji związanych na przykład z błędami pomiarowymi.\\n\\nJej pierwszym argumentem jest zbiór danych. W naszym przypadku zlogarytmowana lista par czasów i rozmiarów pętli. Działa tu zasada: \\\"logarytm tablicy to tablica logarytmów\\\".\\n\\nDrugi argument to model danych jaki dopasowujemy. U nas `Log[Exp[a] Exp[x] + b^2]`. Choć na pierwszy rzut oka, tak nie wygląda, jest to prosta `Ax+B` tylko w zmienionym układzie współrzędnych. Spójrzmy na to tak. Do `x` i `y` dopasowywali byśmy prostą `y=Ax+B`, Jeśli zlogarytmujemy obie strony to mamy `log(y)=log(A exp(log(x))+B)`, dane, do jakich dopasowujemy to `{Log[x], Log[y]}`, więc tymczasowo nazywająć `log(x)=X` i `log(y)=Y` dostajemy wyrażenie `Y = log(A exp(X) + B)` dla danych `X,Y`. Jednak ponieważ nasze `A` jest bardzo małe, a `B` zawsze dodatnie, wprowadzamy oznaczenia `A=exp(a)` oraz `B=b^2`. Teraz `a` może mieć naturalne rzędy wielkości - tak lubiane przez metody numeryczne, a na `b` nie narzucamy żadnych ograniczeń dotyczących znaku - metody numeryczne skaczą ze szczęścia, kiedy widzą takie podstawienia. Od teraz będziemy operować zmiennymi `a` i `b` mając na myśli, że `A` i `B` możemy z nich łatwo obliczyć.\\n\\nTrzeci argument `NonlinearModelFit` to lista stopni swobody, a czwarty nazwany po prostu `x` odpowiada naszemu dużemu `X` czyli logarytmowi z liczby powtórzeń pętli.\\n\\nCały zbiór dopasowanych modeli został zapisany w zmiennej `nlm`. Czas wydobyć z niego parametry, które chcemy zapisać do pliku. Odpowiada za to kod:\\n\\n```\\nnameABlist = {list[[#]],\\n  Exp[a],\\n  b^2,\\n  Exp[a]*nlm[[#]][\\\"ParameterErrors\\\"][[1]],\\n  Abs[2*b]*nlm[[#]][\\\"ParameterErrors\\\"][[2]]} /. nlm[[#, 1, 2]] & /@\\n    Range[Length[list]];\\n\\nPrint[\\\"Parameters extracted from models...\\\"];\\n```\\n\\nTworzona przez niego tablica `nameABList` jest prostokątną macierzą o wymiarach 5 kolumn na 16 wierszy. Ponownie wykorzystujemy mapowanie z przebieganiem po zakresie wskaźników odpowiadających językom `/@Range[Length[list]]`. Za `list[[#]]` zostaje wstawiona nazwa języka, dwie kolejne wielkości dzięki znacznikowi `/.` są podstawiane z modelu `nlm`. Dwie ostatnie to błędy pomiarowe odpowiednio przeskalowane w związku ze zmianą układu współrzędnych.\\n\\nNa samym końcu wysyłamy naszą macierz do pliku:\\n\\n```\\nExport[$InitialDirectory <> \\\"/config/parameters.csv\\\",\\n  SetPrecision[nameABlist, 10]];\\n\\nPrint[\\\"Parameters saved to file. Process finished correctly.\\\"];\\nExit[];\\n```\\n\\n## Wyniki\\n\\nDla każdego języka omówimy wyniki. Zamiast podawać ilość wykonywanych pętli na sekundę, na wykresach prezentujemy jej logarytm `a`, jako łatwiejszy do porównywania. A zamiast czasu włączania programu odpowiadającemu jednemu wykonaniu pętli jego pierwiastek `b`. Do wyrysowania wykresów zastosowaliśmy następujący kod z pliku `analysisi.nb`\\n\\nDo prezentacji wyników wykorzystamy interfejs zrozumiały dla człowieka, czyli wykresy. Za ich wyświetlenie odpowiada poniższy fragment programu `analysis.nb`.\\n\\n```\\nDo[Module[{img, bands},\\n  bands[x_] =\\n   nlm[[i]][\\\"SinglePredictionBands\\\", ConfidenceLevel -> .99];\\n  img = Show[{ListLogLogPlot[{data[[i, 2]]}, PlotRange -> Full,\\n      PlotLabel -> data[[i, 1]], ImageSize -> 800,\\n      BaseStyle -> {FontSize -> 15},\\n      FrameLabel -> {\\\"$size [number of loops]\\\", \\\"$time [sec]\\\"},\\n      Frame -> True, PlotStyle -> {Lighter[Red]},\\n      PlotLegends ->\\n       Placed[SwatchLegend[{\\\"Experimental data\\\"},\\n         LegendMarkerSize -> {30, 30}], {0.3, 0.85}]],\\n     LogLogPlot[{Exp[nlm[[i]][Log[x]]], Exp[bands[Log[x]]]}, {x, 1,\\n       10^13}, PlotLegends ->\\n       Placed[SwatchLegend[{nlm[[i]][\\n           \\\"ParameterConfidenceIntervalTable\\\"]},\\n         LegendMarkerSize -> {1, 1}], {0.3, 0.75}]]}];\\n  Print[img];\\n  Export[\\\"inc_\\\" <> ToString[list[[i]]] <> \\\".png\\\", img];\\n  ], {i, list // Length}]\\n```\\n\\nFunkcja `Do` wykonuje swój pierwszy argument iterując po `i` od `1` do liczby badanych języków programowania. `Module` z jednej strony porządkuje kod zbierając go w jedną niepodzielną całość, z drugiej pozwala nie zaśmiecać głównego programu zmiennymi lokalnymi do przechowywania wykresów (`img`) i linii granicznych (`bands`). Owe linie graniczne to możliwie najkrótszy i najdłuższy czas wykonywania określonej ilości pętli przy założonym przedziale ufności. Nie wchodząc już w szczegóły, które związane głównie z formatowaniem nie są tak ciekawe: `img` zawiera wykres. Funkcja `Print` wyświetla go na ekranie a `Export` zapisuje do pliku.\\n\\n\\n### Bash\\n\\nJęzyk powłok [bash](https://pl.wikipedia.org/wiki/Bash) powstał w 1987 roku, czyli 4 lata przed powstaniem pierwszego jądra Linuxa. Obecnie jest używany głównie do wykonywania operacji związanych z systemem operacyjnym Linux, mimo, że Linux i Bash mogą istnieć bez siebie. Jest to język interpretowany i z tego względu nie jest zoptymalizowany pod wykonywanie obliczeń. Kod wykonujący puste pętle wygląda tak:\\n\\n```bash\\n#! /bin/bash\\n\\ni=0;\\nmax=$1;\\n\\nwhile [[ $i -le $max ]];\\ndo\\n\\ti=$[i+1];\\ndone\\n```\\n\\nA oto wyniki pomiarów czasu:\\n\\n[![inc_inc.bash.png](https://s23.postimg.org/6tnjwy8yz/inc_inc_bash.png)](https://postimg.org/image/6tnjwy8yv/)\\n\\nW naszym teście wypadł najsłabiej, jeśli chodzi o ilość wykonywanych pętli na jednostkę czasu, ale spośród wszystkich języków interpretowanych jest pierwszy, jeśli chodzi o czas włączania. Nie ustępuje jednak bardzo pod tym względem językom kompilowanym.\\n\\n\\n### Matlab\\n\\n[Matlab](https://pl.wikipedia.org/wiki/MATLAB) jest językiem zaprojektowanym do obliczeń macierzowych. Jego historia sięga 1980 roku. Początkowo napisany w Fortranie miał ułatwić studentom obliczenia macierzowe, trzy lata później przepisany w `c` i systematycznie rozbudowywany o nowe funkcjonalności stał się jednym z najpopularniejszych języków stosowanych przez naukowców szczególnie w zastosowaniach związanych z obliczeniami numerycznymi.\\n\\n`Matlab` nie ma wygodnego interfejsu konsolowego. Żeby przekazać mu zmienną musieliśmy sklejać kod interpretowany w `Matlabie` za pomocą `basha`.\\n\\n```bash\\n#!/usr/bin/env bash\\n\\nread -r -d '' VAR << EOM\\nfor c = 1:$1\\n%  disp(c)\\nend\\nEOM\\n\\necho \\\"$VAR\\\" | matlab -nodesktop -nosplash 1>/dev/null\\n```\\n\\n[![inc_inc.m.sh.png](https://s28.postimg.org/6ujap8x31/inc_inc_m_sh.png)](https://postimg.org/image/dxr64v2ih/)\\n\\nJeśli chodzi o szybkość wykonywania jednej pętli to `Matlab` poradził sobie najlepiej w kategorii języków interpretowanych (z wyjątkiem `javy`, która jest takim hybrydowym rozwiązaniem). Opłacił to jednak potwornie długim czasem włączania sięgającym 5 sekund. Jest to znacznie dłuższy czas niż zabierany na którąkolwiek z kompilacji. `Matlab` jest dobry, ale do dużych rzeczy, w przeciwnym wypadku nie opłaca się go włączać, ponieważ przez te 5 sekund `bash` wykonał by milion pętli, a typowe skryptowe języki do 100 milionów.\\n\\n### MySQL\\n\\nSam [`MySQL`](https://pl.wikipedia.org/wiki/MySQL) jest raczej systemem do zarządzania bazą danych niż językiem. Język to `SQL`, ale ze względu na różnice w implementacjach silników bazodanowych wolałem podkreślić `MySQL`, niż zostawić `SQL`. Tak czy inaczej silniki bazodanowe, jak i język zapytań do baz danych nie były tworzone z myślą o inkrementacji zmiennych i sprawdzaniu warunków. Można by powiedzieć, że procedury i instrukcje sterujące to raczej dodatek, który pomaga ograniczyć ilość zapytań niż główna funkcjonalność baz danych. Należy pamiętać, że taka mikro-optymalizacja na tym poziomie nie ma sensu, ponieważ najbardziej kosztowne czasowo operacje znajdują się w selektach i trzymaniu spójności danych przy update/delete/insert.\\n\\nDo `mysql` również nie da się łatwo przekazać parametru z konsoli jako wartości podanej po nazwie programu. Użyliśmy następującego konektora\\n\\n```bash\\n#!/usr/bin/env bash\\n\\nmysql -u root inc -e \\\"CALL inc_loop($1)\\\";\\n```\\n\\nA procedura `inc_loop` definiowana była w ten sposób:\\n\\n```sql\\nCREATE DATABASE IF NOT EXISTS inc;\\nuse inc;\\n\\nDROP PROCEDURE IF EXISTS inc_loop;\\n\\nDELIMITER $$\\nCREATE PROCEDURE inc_loop(IN n INT)\\n BEGIN\\n DECLARE _n INT DEFAULT 0;\\n\\n WHILE _n <= n DO\\n SET  _n = _n + 1;\\n END WHILE;\\n\\n END$$\\nDELIMITER ;\\n```\\n\\n[![inc_inc.sql.sh.png](https://s24.postimg.org/k07fsopkl/inc_inc_sql_sh.png)](https://postimg.org/image/cwzkd2k4x/)\\n\\nZ tego względu `MySQL` w tym zestawieniu zajmuje miejsce drugie od końca. Należy jednak przyznać, że prawdziwe wąskie gardło baz danych - czas łączenia uplasował się na umiarkowanie dobrej pozycji pośród języków skryptowych: między perlem a `pythonem`.\\n\\n### Wolfram Language - Mathematica\\n\\nMathematica jest programem. [Wolfram Language](https://en.wikipedia.org/wiki/Wolfram_Language) językiem w jakim piszemy w tym programie. Język ten sięga historią roku 1988, został zaprojektowany z myślą o algebrze symbolicznej. Obecnie ma bardzo szerokie możliwości związane z wszelkiego rodzaju obliczeniami. Ustępuje `Matlabowi` w temacie wydajności przetwarzania macierzy i numeryki, nadrabia wygodą i bardziej intuicyjną reprezentacją danych.\\n\\nW porównaniu z dwoma poprzednikami, kod programu `inc.wl` jest bardzo prosty\\n\\n```\\nnum  = ToExpression[$ScriptCommandLine[[2]]];\\nFor[i = 0, i < num, i++];\\nExit[];\\n```\\n\\n[![inc_inc.wl.png](https://s27.postimg.org/519tj8x1f/inc_inc_wl.png)](https://postimg.org/image/75u6kbynz/)\\n\\nW tym teście Mathematica poradziła sobie słabo lokując się w kategorii szybkości pętli na 4 miejscu od końca, a w kontekście szybkości włączania na 2 od końca.\\n\\n### C\\\\#\\n\\nJęzyk [C#](https://pl.wikipedia.org/wiki/C_Sharp) powstał w 2000 i aktualnie jest wciąż rozwijany. Ma w sobie wiele cech języków `Object Pascal`, `Delphi`, `C++` i `Java`. Do działania wymaga mono, lub innego środowiska uruchomieniowego. Kompiluje się nie do kodu binarnego, ale do kodu pośredniego. Niestety nie udało mi się zoptymalizować jego kompilacji tak jak dla `Pascala`, `C`, `C++` i `Fortrana`. Jeśli znasz się na tym, proszę o komentarz, lub kontakt w tej sprawie.\\n\\nSam program wygląda rzeczywiście podobnie do swoich pierwowzorów.\\n\\n```c#\\nusing System;\\npublic class Program\\n{\\n    public static void Main(string[] args)\\n    {\\n        for (ulong i = 1; i <= UInt64.Parse(args[0]); i++)\\n        {}\\n    }\\n}\\n```\\n\\n[![inc_inc.cs.png](https://s28.postimg.org/wtbuvxy3h/inc_inc_cs.png)](https://postimg.org/image/zanm37hzt/)\\n\\nSzybkość włączania jest umiarkowania, a szybkość pojedynczej pętli plasuje język na umiarkowanie słabej pozycji - 6 od końca.\\n\\n### JS\\n\\n[JavaScript](https://pl.wikipedia.org/wiki/JavaScript) z pewnością wielu ludziom myli się z Javą. Teraz się to wydaje zabawne, ale mi też się na początku mylił. Nic dziwnego, bo w 1995, kiedy język powstał nazwę wzięto od Javy, żeby JavaScript miał lepszy marketing. Tak naprawdę nie mają ze sobą wiele wspólnego. Obecnie jest to żywy wciąż rozwijany język, który zainspirował i bardzo spopularyzował funkcyjny styl programowania. Za jego sprawą w wielu innych językach pojawiły się tak zwane funkcje lambda, których składnia w ES6 została skrócona, tak, że nazywa się je [strzałkowymi](http://shebang.pl/artykuly/es6-funkcje-strzalkowe/).\\n\\nKod źródłowy jest całkiem przyjemny i wygląda tak:\\n\\n```js\\nvar max=process.argv[2];\\nfor(var i=0;i<=max;i++){}\\n```\\n\\n[![inc_inc.js.png](https://s23.postimg.org/fdvlylzqj/inc_inc_js.png)](https://postimg.org/image/ixhjof2g7/)\\n\\nW przeciwieństwie do `C#`, `JavaScript` jest umiarkowanie słaby jeśli chodzi o szybkość włączania, ale z szybkością pętli radzi sobie już lepiej - jak typowy język skryptowy.\\n\\n### Python\\n\\n[Python](https://pl.wikipedia.org/wiki/Python) pojawił się w roku 1991. Jest językiem ogólnego przeznaczenia, którego głównymi cechami są: sztywne wcięcia a wiec czytelna i klarowna składnia. Jest też dość zwięzły i stanowi bardzo ważną alternatywę dla `perla`. Jest bardzo popularny w środowisku naukowym.\\n\\n```python\\n#!/usr/bin/python\\n\\nimport sys\\n\\nmax=int(sys.argv[1]);\\n\\ncount = 0\\nwhile (count < max):\\n   count = count + 1\\n```\\n\\nOd razu zaznaczę, że ten kod da się napisać krócej i wykonać szybciej używając pętli `for in`, ale ma ona zupełnie inną mechanikę działania - tworzy tablicę liczb z podanego zakresu, wrzuca całą tablicę do pamięci i ją przegląda. Więcej o tym piszę na końcu w dziale RAM vs Procesor. Pozbycie się zmiennej max i napisanie\\n\\n```python\\nwhile (count < int(sys.argv[1])):\\n```\\n\\nwydłużyło by czas wykonywania kilkukrotnie.\\n\\n[![inc_inc.python.png](https://s30.postimg.org/gdrdtsu81/inc_inc_python.png)](https://postimg.org/image/ka4ppsf7h/)\\n\\nMimo, że python jest jednym z wolniejszych języków skryptowych, różnice te są na tyle małe, że można uczciwie przyznać, że mieści się dokładnie na środku rankingu. Ilość kodu nie jest przerażająca, a krzywa nauki? Jak dla mnie ciężko mówić o krzywej nauki w przypadku tego języka. Można w nim pisać, nawet go nie umiejąc, po prostu zgadując jak coś powinno być napisane. Jest to bardzo intuicyjny język o rozsądnej wydajności w większości przypadków.\\n\\n### Ruby\\n\\n[Ruby](https://pl.wikipedia.org/wiki/Ruby_(j%C4%99zyk_programowania)) jest stosunkowo młody, jak na język. Pierwsze wydanie ujrzało światło dzienne w 1995. Jest to dynamicznie typowany, obiektowy, interpretowany język popularny głównie w stanach. Jego znaczenie wzrosło po wydaniu frameworku Ruby on Rails - przeznaczonego do tworzenia aplikacji internetowych, ale widziałem Ruby w innych zastosowaniach od analizy danych giełdowych po platformę do blogowania - jekylla.\\n\\nW tym języku, nie miałem okazji dużo pisać, ale kod wygląda dość przyjemnie\\n\\n```ruby\\nfor i in (1 .. ARGV[0].to_i)\\nend\\n```\\n\\nZaskakujące, że ta składnia, wcale nie zamula pamięci RAM nawet przy bardzo dużych tablicach ani nie powoduje problemów jakie w `pythonie` powoduje nie utworzenie zmiennej `max`. Składnia jest więc znacznie lepsza.\\n\\n[![inc_inc.rb.png](https://s28.postimg.org/iirygthal/inc_inc_rb.png)](https://postimg.org/image/dwvu8gvrd/)\\n\\nNatomiast wyniki są średnie. Przy czym ruby raczej włącza się wolniej a działa szybciej na tle innych języków interpretowanych.\\n\\n### Perl\\n\\n[Perl](https://pl.wikipedia.org/wiki/Perl) pochodzi miej więcej z tych czasów co bash (1987). Jest to język o bardzo gęstej składni. Programista w nim traktowany jest raczej jak artysta niż rzemieślnik. Język pozwala na tworzenie zarówno czystego i krótkiego kodu, jak i nieczytelnej plątaniny znaków. W wielu rozwiązaniach został wyparty przez Pythona przez to, że jest trudniejszy w nauce oraz paradoksalnie bardziej elastyczny.\\n\\nJego kod źródłowy stanowi świetnym przykładem ten sam program, można napisać tak:\\n\\n```perl\\n#!/usr/bin/perl\\n\\nfor(my $i=0;$i<=$ARGV[0];$i++){}\\n```\\n\\na można tak:\\n\\n```perl\\nfor(;$_<=$ARGV[0];$_++){}\\n```\\n\\nDziałanie będzie identyczne.\\n\\n[![inc_inc.perl.png](https://s23.postimg.org/6uq89tx3v/inc_inc_perl.png)](https://postimg.org/image/engw1t32v/)\\n\\nWyniki nie są niespodzianką. Włączanie się jest najszybsze z języków skryptowych. Czas wykonywania pojedynczej pętli umiarkowany.\\n\\n### R\\n\\n[R](https://pl.wikipedia.org/wiki/R_(j%C4%99zyk_programowania)) jest środowiskiem do obliczeń statystycznych. W całym tym zestawieniu sporo jest języków powiązanych z matematyką, bo sam się nią lubię zajmować. R szczególnie często występuje w kontekście bioinformatyki.\\n\\nCechy charakterystyczne to: strzałki do przypisywania wartości i podobnie jak w Matlabie ogromna łatwość operowania na macierzach i wektorach.\\n\\n```r\\nargs <- commandArgs(trailingOnly = TRUE)\\n\\nx <- 0\\nwhile(x < as.numeric(args)) {\\n    x <- x+1;\\n}\\n```\\n\\n[![inc_inc.r.png](https://s29.postimg.org/fsrzxg0jr/inc_inc_r.png)](https://postimg.org/image/izmjh2kzn/)\\n\\nPodobnie jak Wolfram Language, tak i tan wysoko poziomowy język o specjalizacji sprofilowanej na testowanie hipotez statystycznych i prowadzenie badań poradził sobie słabo w tym teście. Zarówno pod względem szybkości pętli jak i uruchamiania zajął trzecią pozycję od końca.\\n\\n### Php\\n\\nJęzyk [Php](https://pl.wikipedia.org/wiki/PHP) pojawił się w roku 1995, jako język do generowania stron internetowych. I choć można pisać backend webowy w innych językach, trzeba przyznać, że PHP radzi sobie z tym zadaniem całkiem dobrze. Oczywiście, wielkim serwisom opłaca się kompilowanie backendu, ale w absolutnej większości zastosowań PHP stanowi świetny kompromis między wygodą języka interpretowanego a wydajnością.\\n\\nKod php wygląda standardowo i intuicyjne\\n\\n```php\\n<?php\\n\\n$max = (int)$argv[1];\\n\\nfor($i=0; $i<$max; $i++);\\n```\\n\\n[![inc_inc.php.png](https://s28.postimg.org/svv7c3xl9/inc_inc_php.png)](https://postimg.org/image/ywsw96k7d/)\\n\\nJego wydajność w tym teście oceniam bardzo pozytywnie. Szybkość włączania była średnia, a w kategorii szybkości wykonania jednej pętli poradził sobie jako jeden z najlepszych języków interpretowanych. Dał się wyprzedzić jedynie Matlabowi.\\n\\n### Fortran 95\\n\\n[Fortan](https://pl.wikipedia.org/wiki/Fortran) jest językiem z czasów tak wczesnych, że aż ciężko sobie wyobrazić, jak wtedy programowano (1957 rok), ale były to jeszcze czasy kart perforowanych, bo pierwszy komputer z klawiaturą powstał dopiero w 1960. Dzięki bogatemu zestawowi bibliotek do obliczeń macierzowych, bardzo dobrze zoptymalizowanemu kompilatorowi, wielo-platformowości i dobremu wsparciu obliczeń równoległych Fortran jest wciąż szeroko używany w środowisku inżynierskim i naukowym, w szczególności tam, gdzie numeryka jest szczególnie ciężka - w fizyce, symulacjach, modelowaniu ośrodków ciągłych.\\n\\nZe składni języka widać, że typowanie jest statyczne, rzutowanie wykonywane za pomocą instrukcji `read`, natomiast sama pętla ma już przyjemną składnię. Subiektywnie kojarzy mi się z językiem ruby.\\n\\n```fortran\\nPROGRAM loop_argument_times\\n  INTEGER(16) :: i, range\\n  CHARACTER(len=32) :: arg\\n\\n  CALL get_command_argument(1, arg)\\n  read( arg, '(i16)' ) range\\n\\n  do  i = 1, range\\n  end do\\n\\nEND PROGRAM\\n```\\n\\n[![inc_inc.f95.png](https://s27.postimg.org/zbpgu9eeb/inc_inc_f95.png)](https://postimg.org/image/4u9m2pr1b/)\\n\\nWyniki `fortrana` zasługują na wyjątkowe uznanie. W szybkości wykonywania pętli zajął pierwsze miejsce, a szybkości włączania czwarte. Warto wspomnieć, że jego twórcy dołożyli bardzo dużo pracy do optymalizacji kompilatora ponieważ obawiali się, że w przeciwnym wypadku nikt nie będzie go używać i wszyscy będą pisać w asemblerze.\\n\\n### C++\\n\\n[C++](https://pl.wikipedia.org/wiki/C%2B%2B) pojawił się w 1983 jako rozszerzenie języka `c`  o obiektowe mechanizmy abstrakcji danych i silną statyczną kontrolę typów. W latach 90 stał się najbardziej popularnym językiem ogólnego przeznaczenia. Jest to pierwszy język jakiego się uczyłem, w gimnazjum, kiedy po podłączeniu internetu w domu, z przekory chciałem pokazać rodzicom, że gry sieciowe nie zniszczą mi dzieciństwa. Później wiele razy `c++` zaspokajał moją ciekawość dotyczącą symulowania układów fizycznych i do czasu poznania języka `Mathematica` był głównym narzędziem do robienia numeryki.\\n\\n```cpp\\n#include <cstdlib>\\nint main(int argc, char *argv[])\\n{\\n\\tunsigned long long int i;\\n\\tunsigned long long int max = strtoul(argv[1], NULL, 0);\\n\\tfor(i=0; i<max; i++);\\n\\treturn 0;\\n}\\n```\\n\\n[![inc_inc.cpp.png](https://s30.postimg.org/grnuo989t/inc_inc_cpp.png)](https://postimg.org/image/n5cxrid5p/)\\n\\nJak przystało na język kompilowany ogólnego przeznaczenie `c++` staje na podium w obu rankingach. Uruchamia się jako trzeci, wykonuje pętle jako drugi najszybszy język w zestawieniu.\\n\\n### C\\n\\nHistoria języka [`C`](https://pl.wikipedia.org/wiki/C_(j%C4%99zyk_programowania)) sięga roku 1972, wywodzi się on z języka [`B`](https://pl.wikipedia.org/wiki/B_(j%C4%99zyk_programowania)) współtworzonego przez twórcę `C` - Dennisa Ritchiego. `B` natomiast wywodzi się z [`BCPL`](https://pl.wikipedia.org/wiki/BCPL) - zapomnianego już języka, który jednak wywarł ogromny wpływ na to jak dzisiaj kodujemy. To długa i ciekawa historia, ale, żeby dygresja nie poszła zbyt daleko wrócę do `C`. Został zaprojektowany do programowania systemów operacyjnych i zadań dzisiaj uważanych za niskopoziomowe.\\n\\n`C++` różni się od `C` głównie obiektowością, więc nie zobaczymy tego na przykładzie kodu źródłowego, gdzie jedyną zmianą jest użyta biblioteka.\\n\\n```c\\n#include <stdlib.h>\\n\\nint main(int argc, char *argv[])\\n{\\n\\tunsigned long long int i;\\n\\tunsigned long long int max = strtoul(argv[1], NULL, 0);\\n\\n\\tfor(i=0; i<max; i++);\\n\\treturn 0;\\n}\\n```\\n\\n[![inc_inc.c.png](https://s24.postimg.org/71q65aglx/inc_inc_c.png)](https://postimg.org/image/71q65aglt/)\\n\\nWyniki testu pokazują, że `C` jest na trzecim miejscu pod względem szybkości pętli ustępując `C++` tylko o 1%, ale zajmuje pierwsze miejsca w klasyfikacji szybkości uruchamiania wyprzedzając `Pascala` o około 1‰.\\n\\n### Pascal\\n\\nO wilku mowa. To znaczy o [`Pascalu`](https://pl.wikipedia.org/wiki/Pascal_(j%C4%99zyk_programowania)) - języku, który powstał w 1970 roku i w przeciwieństwie do `C`, nie udostępniał mechanizmów niskopoziomowych, lecz został zaprojektowany do tworzenia strukturalnych aplikacji.\\n\\nMi osobiście z Pascalem kojarzy się przeciążanie operatorów, bo mimo, że jest to możliwe również w innych językach, pierwszy raz w życiu przeciążałem operator dodawania i mnożenia macieży właśnie w Pascalu.\\n\\nSam kod przypomina mi nieco fortrana. Kiedy się go uczyliśmy, profesor który objaśniał jego składnię mówił, że nie będziemy go używać, ale będziemy programować w innych językach tak jak w nim. Na przykładzie tego kodu widać, że `Pascal` wymaga definiowania zmiennych przed rozpoczęciem wykonywania logiki. Przyznaję, faktycznie tak piszę dziś we wszystkich języakch skryptowych, jeśli chcę używać zmiennych globalnych.\\n\\n```pascal\\nprogram Project1;\\n\\nUses sysutils;\\n\\n{$mode objfpc}\\n\\nvar\\n  I,r: QWord;\\nbegin\\n\\n  r:=StrToQWord(ParamStr(1));\\n\\n  for I := 1 to r do\\nend.\\n```\\n\\n[![inc_inc.p.png](https://s23.postimg.org/kd5tcbe97/inc_inc_p.png)](https://postimg.org/image/n78yprgfb/)\\n\\nPascal zajął piąte miejsce w szybkości wykonywania pętli i drugie w kategorii szbykości startowania programu.\\n\\n### Java\\n\\n[`Java`](https://pl.wikipedia.org/wiki/Java) jest młodym językiem na tle kilku ostatnio omawianych. Powstała w 1995. Swój sukces zawdzięcza bardzo bardzo dobrej obsłudze błędów i wyjątków oraz niezależności od systemu na jakim uruchamiamy platformę java. Korporacje kochają ją za to, że można w niej pisać bezpieczne, dobrze zabezpieczone aplikacje w rozproszonej strukturze sieciowej bez szczególnego dbania o systemy operacyjne poszczególnych maszyn.\\n\\n```java\\npublic class inc {\\n    public static void main(String[] args) {\\n\\tlong max=Long.parseLong(args[0]);\\n\\tfor (long i = max; i >= 0; i--) {\\n\\t}\\n    }\\n}\\n```\\n\\n[![inc_inc.java.png](https://s24.postimg.org/5e9nuhvkl/inc_inc_java.png)](https://postimg.org/image/6gjud1edt/)\\n\\nJava zajęła czwarte miejsce pod względem szybkości pętli ustępując liderowi jedynie o 1-2%, ale jej włączanie trwało około 40 razy dłużej niż programów z czołówki rankingu. W kategorii szybkości włączania java była czwarta od końca.\\n\\n### Podsumowanie\\n\\nNa koniec załączam wykres porównujący czas trwania pojedyńczej pętli w każdym języku wykonany za w pliku `analysis.nb`\\n\\n```\\nBarChart[Log[SortBy[nameABlist, #[[2]] &][[All, 2]]],\\n ChartStyle -> \\\"DarkRainbow\\\",\\n ChartLegends -> SortBy[nameABlist, #[[2]] &][[All, 1]],\\n AxesLabel -> \\\"Log[a]\\\"]\\n```\\n\\n[![speed.png](https://s17.postimg.org/fst8rikvj/speed.png)](https://postimg.org/image/4t81fwugb/)\\n\\nWykres ma skalę logarytmiczną, im niższa wartość tym lepiej.\\n\\nJeśli jesteś ciekaw dokładnych wyników poniżej prezentuję tabelę.\\n\\n| language   | one loop time [s] | loop time error [s] | launch time [s] | launch time error [s] | launch to loop ratio [s] |\\n| ---------- | ----------------- | ------------------- | --------------- | --------------------- | ------------------------ |\\n| inc.f95    | 3.50468*10^(-10)  | 1.07954*10^(-12)    | 1.72753*10^(-3) | 5.04969*10^(-6)       | 4.92921*10^(6)           |\\n| inc.cpp    | 3.5061*10^(-10)   | 1.41184*10^(-12)    | 1.38989*10^(-3) | 5.77246*10^(-6)       | 3.9642*10^(6)            |\\n| inc.c      | 3.53343*10^(-10)  | 1.01268*10^(-12)    | 1.37686*10^(-3) | 3.62949*10^(-6)       | 3.89666*10^(6)           |\\n| inc.java   | 3.55209*10^(-10)  | 1.25794*10^(-12)    | 5.70852*10^(-2) | 6.74846*10^(-5)       | 1.60709*10^(8)           |\\n| inc.p      | 3.69329*10^(-10)  | 2.36513*10^(-12)    | 1.37772*10^(-3) | 4.0445*10^(-6)        | 3.73033*10^(6)           |\\n| inc.m.sh   | 2.69198*10^(-9)   | 2.10845*10^(-11)    | 5.28642         | 4.69114*10^(-2)       | 1.96377*10^(9)           |\\n| inc.php    | 8.89544*10^(-9)   | 2.62779*10^(-11)    | 2.13014*10^(-2) | 3.08575*10^(-5)       | 2.39464*10^(6)           |\\n| inc.rb     | 3.64662*10^(-8)   | 1.2021*10^(-10)     | 3.40208*10^(-2) | 4.46364*10^(-5)       | 9.32938*10^(5)           |\\n| inc.perl   | 4.24243*10^(-8)   | 1.23231*10^(-10)    | 2.15686*10^(-3) | 4.64159*10^(-6)       | 5.08403*10^(4)           |\\n| inc.js     | 6.14158*10^(-8)   | 2.27239*10^(-10)    | 4.14627*10^(-2) | 6.47284*10^(-5)       | 6.75115*10^(5)           |\\n| inc.python | 6.29119*10^(-8)   | 1.69606*10^(-10)    | 1.02831*10^(-2) | 1.5976*10^(-5)        | 1.63452*10^(5)           |\\n| inc.cs     | 1.59136*10^(-7)   | 5.1884*10^(-10)     | 1.06194*10^(-2) | 2.41509*10^(-5)       | 6.67321*10^(4)           |\\n| inc.wl     | 4.87908*10^(-7)   | 1.24762*10^(-9)     | 1.91462*10^(-1) | 2.2833*10^(-4)        | 3.92415*10^(5)           |\\n| inc.r      | 7.28671*10^(-7)   | 2.11159*10^(-9)     | 1.20264*10^(-1) | 1.79633*10^(-4)       | 1.65045*10^(5)           |\\n| inc.sql.sh | 2.24287*10^(-6)   | 4.28608*10^(-9)     | 5.33614*10^(-3) | 1.34152*10^(-5)       | 2.37916*10^(3)           |\\n| inc.bash   | 4.23198*10^(-6)   | 5.03612*10^(-9)     | 1.8443*10^(-3)  | 4.70927*10^(-6)       | 4.35801*10^(2)           |\\n\\nAnalogicznie dla czasów włączania programów rysujemy drugi wykres\\n\\n```\\nBarChart[Log[SortBy[nameABlist, #[[3]] &][[All, 3]]],\\n ChartStyle -> \\\"DarkRainbow\\\",\\n ChartLegends -> SortBy[nameABlist, #[[3]] &][[All, 1]],\\n AxesLabel -> \\\"Log[b]\\\"]\\n```\\n\\n[![speed2.png](https://s27.postimg.org/5zsco9ezn/speed2.png)](https://postimg.org/image/ll9o87qxr/)\\n\\nTutaj też najlepsze wartości to najniższe. Wartość zerowa oznacza czas włączania równy 1 sekundzie.\\n\\nPoniżej ta sama tabela co poprzednio, ale posortowana po czasach włączania programu:\\n\\n| language   | one loop time [s] | loop time error [s] | launch time [s] | launch time error [s] | launch to loop ratio [s] |\\n| ---------- | ----------------- | ------------------- | --------------- | --------------------- | ------------------------ |\\n| inc.c      | 3.53343*10^(-10)  | 1.01268*10^(-12)    | 1.37686*10^(-3) | 3.62949*10^(-6)       | 3.89666*10^(6)           |\\n| inc.p      | 3.69329*10^(-10)  | 2.36513*10^(-12)    | 1.37772*10^(-3) | 4.0445*10^(-6)        | 3.73033*10^(6)           |\\n| inc.cpp    | 3.5061*10^(-10)   | 1.41184*10^(-12)    | 1.38989*10^(-3) | 5.77246*10^(-6)       | 3.9642*10^(6)            |\\n| inc.f95    | 3.50468*10^(-10)  | 1.07954*10^(-12)    | 1.72753*10^(-3) | 5.04969*10^(-6)       | 4.92921*10^(6)           |\\n| inc.bash   | 4.23198*10^(-6)   | 5.03612*10^(-9)     | 1.8443*10^(-3)  | 4.70927*10^(-6)       | 4.35801*10^(2)           |\\n| inc.perl   | 4.24243*10^(-8)   | 1.23231*10^(-10)    | 2.15686*10^(-3) | 4.64159*10^(-6)       | 5.08403*10^(4)           |\\n| inc.sql.sh | 2.24287*10^(-6)   | 4.28608*10^(-9)     | 5.33614*10^(-3) | 1.34152*10^(-5)       | 2.37916*10^(3)           |\\n| inc.python | 6.29119*10^(-8)   | 1.69606*10^(-10)    | 1.02831*10^(-2) | 1.5976*10^(-5)        | 1.63452*10^(5)           |\\n| inc.cs     | 1.59136*10^(-7)   | 5.1884*10^(-10)     | 1.06194*10^(-2) | 2.41509*10^(-5)       | 6.67321*10^(4)           |\\n| inc.php    | 8.89544*10^(-9)   | 2.62779*10^(-11)    | 2.13014*10^(-2) | 3.08575*10^(-5)       | 2.39464*10^(6)           |\\n| inc.rb     | 3.64662*10^(-8)   | 1.2021*10^(-10)     | 3.40208*10^(-2) | 4.46364*10^(-5)       | 9.32938*10^(5)           |\\n| inc.js     | 6.14158*10^(-8)   | 2.27239*10^(-10)    | 4.14627*10^(-2) | 6.47284*10^(-5)       | 6.75115*10^(5)           |\\n| inc.java   | 3.55209*10^(-10)  | 1.25794*10^(-12)    | 5.70852*10^(-2) | 6.74846*10^(-5)       | 1.60709*10^(8)           |\\n| inc.r      | 7.28671*10^(-7)   | 2.11159*10^(-9)     | 1.20264*10^(-1) | 1.79633*10^(-4)       | 1.65045*10^(5)           |\\n| inc.wl     | 4.87908*10^(-7)   | 1.24762*10^(-9)     | 1.91462*10^(-1) | 2.2833*10^(-4)        | 3.92415*10^(5)           |\\n| inc.m.sh   | 2.69198*10^(-9)   | 2.10845*10^(-11)    | 5.28642         | 4.69114*10^(-2)       | 1.96377*10^(9)           |\\n\\n\\n\\n## Ciekawostki\\n\\nPodczas prowadzenia niektórych testów zdarzało się, że zmiany w kodzie, czy sposobie kompilacji bardzo istotnie wpłynęły na wyniki, mimo, że teoretycznie, każdy program miał robić to samo: puste pętle.\\n\\nPierwszy przykład to zmiana sposobu przebiegania pętli\\n\\n### RAM vs Procesor\\n\\nMamy dwie możliwości przebiegania po zakresie od 1 do n. Pierwsza to zacząć od 1 i zwiększać ją o jeden co chwilę sprawdzając czy doszliśmy już do n, czy nie. Drugi, to stworzyć tablicę od 1 do n, załadować ją do pamięci RAM i wykonać ciało pętli dla każdej z tych liczb z pamięci.\\n\\nPierwsza metoda, bardziej konserwatywna jest typową konstrukcją pętli, jaką chciałem testować. Jednak, ta druga, okazuje się być bardziej wydajna dla rozmiarów tablic, które mieszczą się nam w pamięci operacyjnej. Prezentuję na przykładzie języka `R`, jak zmiana sposobu wykonywania pętli wpłynęła na szybkość jej wykonywania.\\n\\nOto wycinek `git diff` pokazujący, jak zmienił się kod źródłowy:\\n\\n[![r.png](https://s27.postimg.org/jzgak8vab/image.png)](https://postimg.org/image/rffk61izj/)\\n\\nWidzimy, że zamieniliśmy pętlę ładującą wszystko do RAM, na iterującą co jeden ze sprawdzaniem warunku co krok. Poniżej dodaję kod do wykonania stosownego wykresu:\\n\\n```\\ngitr = SQLExecute[conn,\\n   \\\"SELECT git FROM log WHERE name='inc.r' GROUP BY git\\\"];\\ndr = SQLExecute[conn,\\n     \\\"SELECT size,time FROM log WHERE name='inc.r' AND git='\\\" <>\\n      ToString[#] <> \\\"'\\\"] & /@ Flatten[gitr];\\nListLogLogPlot[{Flatten[dr[[#]] & /@ Range[4], 1], dr[[5]]},\\n  PlotRange -> Full,\\n  PlotLabel -> \\\"Differencies in loop time for inc.r\\\",\\n  BaseStyle -> {FontSize -> 14}, ImageSize -> 800,\\n  PlotLegends ->\\n   Placed[SwatchLegend[{\\\"while loop\\\", \\\"for in loop\\\"},\\n     LegendMarkerSize -> {30, 30}], {0.3, 0.75}]]\\n```\\n\\n[![diff_loop.png](https://s23.postimg.org/9d14t0ii3/diff_loop.png)](https://postimg.org/image/hvakxcp0n/)\\n\\nWidzimy tutaj ogromną przewagę pętli `For in`. Kiedy spojrzymy na tabelę:\\n\\n[![loop_type.png](https://s24.postimg.org/73qpc5985/loop_type.png)](https://postimg.org/image/5op4nf84x/)\\n\\nOkazuje się być ona 22 krotna. To znaczy: w języku `R`, jeśli starczy nam pamięci RAM, to pusta pętla `for in` wykona się 22 razy szybciej niż pętla `while`. Podobne jakościowo rezultaty dostajemy w języku `python`, a intuicja podpowiada, że należy ten wniosek rozszerzyć na inne języki, w których istnieją konstrukcję pętli, które najpierw ładują zakres do RAM, a potem po nim przebiegają.\\n\\nOstatecznie, żeby wyrównać szanse, w końcowej wersji wykorzystałem pętlę iterującą.\\n\\n### Optymalizacja kompilacji\\n\\nKtoś przyzwyczajony do wysokopoziomowych języków, szczególnie interpretowanych, mógł by pomyśleć: \\\"kompilacje jak kompilacje, nic ciekawego\\\". Okazuje się jednak, że sposób w jaki kompilujemy program może drastycznie zmienić jego wydajność.\\n\\n#### Pascal\\n\\nPrzyjrzymy się uważniej linijce programu `inc.bash` zawierającej kompilację pascala.\\n\\n```bash\\nfpc -O2 inc/inc.p -o\\\"$TMP/p\\\" -Tlinux &>/dev/null\\n```\\n\\nZnajduje się tu flaga `-O2`, która sporo zmienia. Włącza ona analizator przepływu danych asemblera. On z kolei umożliwia procedurze eliminacji wspólnych pod-wyrażeń, na usunięcie niepotrzebnych przeładowań rejestru wartościami, które już zawierał. Więcej o falgach optymalizujących kompilację Pascala można przeczytać w [dokumentacji](http://www.math.uni-leipzig.de/pool/tuts/FreePascal/prog/node12.html).\\n\\nWpływ tej flagi można zobaczyć na tym wykresie:\\n\\n[![compilation.png](https://s30.postimg.org/h8ln3c8gh/compilation.png)](https://postimg.org/image/690frqi19/)\\n\\nA liczbowe wyniki analizy w tabeli poniżej\\n\\n[![compilation.png](https://s27.postimg.org/ajfz2n3df/compilation.png)](https://postimg.org/image/gkdnzppzj/)\\n\\nMożna z niej wyczytać, że tylko dzięki usunięciu niepotrzebnych przeładowań rejestru program przyśpieszył 5.6 raza. Inaczej ujmując - trzy znaki w komendzie kompilacyjnej `-O2` przyśpieszyły program kilkukrotnie.\\n\\n#### C++\\n\\nW przypadku `c++` sytuacja jest nawet bardziej złożona. Podobnie jak w Pascalu mamy do wyboru różne flagi mające różne zastosowania. Ostatecznie zdecydowaliśmy się, że wydajność `c++` najlepiej odda zastosowanie `-O1`.\\n\\n```bash\\ng++ -O1 -o \\\"$TMP/cpp\\\" 'inc/inc.cpp';\\n```\\n\\nZ [dokumentacji](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html) kompilatora wynika, że dzięki niej kompilator próbuje zredukować wielkość kodu i czas wykonywania, ale nie stosuje tych optymalizacji, które mogły by zająć więcej czasu.\\n\\nByło to dla mnie dużym zaskoczeniem, ale kiedy stosowałem głębszą optymalizację, to znaczy flagi `-O2`, `-O3` i `-Ofast`, okazywało się, że pętla jest całkowicie pomijana. Czas wykonywania programu spadał do rzędu tysięcznych, czasem setnych sekundy, a więc całkowicie zlewał się z szumem i był niezależny od parametru, jaki wstawiałem. Myślałem, że sytuację popraw wykorzystanie zmiennych zapisywanych, nie na 8 bajtach, tylko na 16. Okazało się, że pętle po zmiennych typu `uint128_t` z biblioteki `boost/multiprecision/cpp_int.hpp` również są pomijane. Dopiero po użyciu zmiennych zapisywanych na 32 bajtach kompilator nie radził sobie z wycięciem pustej pętli z kodu programu. Jednak taki test był dla `c++` dość nieuczciwy, bo żaden inny język nie dochodził nigdy do takich zakresów. Architektura procesora w moim laptopie (x86_64) świetnie nadaje się do liczb 8 bajtowych - 64bitowych. Używanie liczb 256 bitowych nawet przy najwyższym stopniu optymalizacji kompilacji nie dawało tak dobrych efektów jak `-O1` dla liczby 64 bitowej (unsigned long long int).\\n\\nDla porównania wyników jakie dała flaga `-O1` oraz jej brak załączam wykres\\n\\n[![cpp_optimization.png](https://s23.postimg.org/r4ewreeyj/cpp_optimization.png)](https://postimg.org/image/i9e2gvq5z/)\\n\\nOraz tabelę\\n\\n| language and parametes | one loop time [s] | loop time error [s] | launch time [s] | launch time error [s] |\\n| ---------------------- | ----------------- | ------------------- | --------------- | --------------------- |\\n| c++ -O1 optimization   | 3.50722*10^(-10)  | 1.43966*10^(-12)    | 1.38984*10^(-3) | 5.808*10^(-6)         |\\n| c++ no optimization    | 2.54525*10^(-9)   | 9.24271*10^(-12)    | 1.30566*10^(-3) | 2.83328*10^(-6)       |\\n\\n#### Fortran\\n\\nTutaj też flaga optymalizująca znacznie wpływa na wyniki. Podobnie jak wcześniej, najlepiej oddaje się szybkość pustych pętli dzięki fladze `-O1`.\\n\\n[![f_optimization.png](https://s29.postimg.org/dg6zyhszb/f_optimization.png)](https://postimg.org/image/q7l6502r7/)\\n\\n| language           | one loop time [s] | loop time error [s] | launch time [s] | launch time error [s] |\\n| ------------------ | ----------------- | ------------------- | --------------- | --------------------- |\\n| f -O1 optimization | 3.50474*10^(-10)  | 1.0804*10^(-12)     | 1.72753*10^(-3) | 5.05088*10^(-6)       |\\n| f no optimization  | 3.07201*10^(-9)   | 1.12286*10^(-11)    | 1.63708*10^(-3) | 3.55385*10^(-6)       |\\n\\n### Sposób pomiaru czasu\\n\\nDo pomiaru czasu wykonywania skryptu wykorzystywaliśmy dwie metody. Pierwsza to\\n\\n```bash\\n/usr/bin/time -o \\\"$TMP/time\\\" -f \\\"%e\\\" $comm $size &> /dev/null; #oryfinally %U instead %e\\ntime=\\\"$(cat \\\"$TMP/time\\\" 2> /dev/null)\\\";\\n```\\n\\nDruga to:\\n\\n```bash\\ntime=`bash util/timing.sh $comm $size`\\n```\\n\\ngdzie plik `util/timing.sh` zawierał poniższy kod\\n\\n```bash\\n#!/usr/bin/env bash\\nSTART=$(date +%s.%N)\\n# do something #######################\\n\\n\\\"$@\\\" &> /dev/null\\n\\n#######################################\\nEND=$(date +%s.%N)\\nDIFF=$( echo \\\"scale=6; (${END} - ${START})*1/1\\\" | bc )\\necho \\\"${DIFF}\\\"\\n```\\n\\nKtóry sprawdzał aktualny czas, wykonywał podaną instrukcję i ponownie sprawdzał aktualny czas. Następnie za pomocą programu `bc` obliczał różnicę między tymi czasami i zwracał ją z dokładnością do mikrosekund.\\n\\nZaletą pierwszej metody była prostota, mniejsza ilość kodu. Z resztą narzędzie `usr/bin/time` jest dedykowanym narzędziem do pomiarów czasu skryptów w systemie `linux`. Zaletą drugiej metody była wyższa precyzja (mikro vs setne sekundy). Oczywiście mimo wykorzystania 6 cyfr po przecinku, zamiast dwóch, precyzja nie sięgała ona tak głęboko, ale przy bardzo szybkich programach pozwoliła mierzyć czas startowania programów z błędem pomiarowym niższym, niż ten czas.\\n\\nŻeby dać tym metodom równe szanse włączyłem pętle w języku `bash`, które średnio trwały około 4.19 sekundy. Jest to wystarczająco długo, aby ograniczenie liczby cyfr wyników nie stało się kluczowe i wystarczająco krótko, żeby można było powtórzyć pomiar wiele razy. Wyniki zestawiłem na poniższym histogramie:\\n\\n[![pairedHistogramTiming.png](https://s27.postimg.org/pev7oo7zn/paired_Histogram_Timing.png)](https://postimg.org/image/wuuhagvov/)\\n\\n\\noraz w tabeli\\n\\n| method                | time [s] | standard dev [s] |\\n| --------------------- | -------- | ---------------- |\\n| uti/timing.sh         | 4.200    | 0.117            |\\n| /usr/bin/time -f \\\"%e\\\" | 4.178    | 0.119            |\\n\\nWidać, że zmiana metody pomiaru z `/usr/bin/time` na `util/timing.sh` nie wymaga kasowania poprzednich wyników. Seria pomiarowe z `/usr/bin/time` i tak nie dotyczyła wyników o czasach poniżej `0.4 sec` bo przy błędzie rzędu `0.1` i zakresie 2 liczb po przecinku nie miało to sensu.  Warto zwrócić uwagę na to, że rozkład czasów potrzebnych na wykonanie programu jest podobny do tego, jaki miał rozkład czasu selektów po indeksowanym kluczu w bazie danych.\\n\\n### Testy\\n\\nJeśli wrócili byśmy do opisu instalacji, to zobaczyli byśmy, że ostatnia linia pliku `install.sh` odpowiada za pobranie biblioteki [`shunit2`](http://ssb.stsci.edu/testing/shunit2/shunit2.html).\\n\\n```bash\\ncurl -L \\\"https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/shunit2/shunit2-2.1.6.tgz\\\" | tar zx\\n```\\n\\nZastosowaliśmy ją w skrypcie testującym, które kod pokazuję poniżej\\n\\n> `test.sh`\\n\\n```bash\\n#!/usr/bin/env bash\\n\\n# args: min, mix, file - function check if\\n# all numbers in file are in range (min,max)\\nfunction columnInRange\\n{\\n    min=\\\"$1\\\";\\n    max=\\\"$2\\\";\\n\\n    cat | while read n\\n    do\\n        echo $n;\\n        assertTrue '[ 1 -eq $(echo $min\\\"<\\\"$n | bc -l) ]'\\n        assertTrue '[ 1 -eq $(echo $n\\\"<\\\"$max | bc -l) ]'\\n    done\\n}\\n```\\n\\nZaczynamy od definiowania funkcji pomocniczej, która przyjmuje dwa parametry i strumień danych. Sprawdza ona czy strumień zawiera liczby z zakresu określonego przez te parametry. Za sprawdzenie odpowiadają funkcje `assertTrue`.\\n\\nDruga funkcja pomocnicza wykonuje dzielenie przez siebie wybranych kolumn z pary plików.\\n\\n```bash\\n# args: col, method and parameter for 1 file, method and parameter for 2 file\\n# function print ratio of given column form two files \\\"log/out.[method][parameter].log\\n# col number | meaning\\n# 3          | size\\n# 4          | time\\n# 5          | speed\\nfunction ratioOfColumns\\n{\\n    col=\\\"$1\\\";\\n\\n    awk -F \\\"|\\\" 'FNR==NR{a[FNR] = $'$col'; next} {if(/inc/) printf \\\"%12.6f\\\\n\\\", $'$col'/a[FNR]}' \\\\\\n        log/out.$2.log log/out.$3.log\\n}\\n```\\n\\nNa tą chwilę wygląda to dość enigmatycznie, ale pliki te w założeniu mają odpowiadać temu, co `inc.bash` wyświetla w konsoli. Zakres parametru `$1` to `3`,`4`,`5`, a dostępne wartości `$2` i `$3` to `l1`, `l2`, `t1` i `t2`. Odpowiedź na pytanie skąd biorą się tepliki zawarta jest w kolejnej funkcji:\\n\\n```bash\\noneTimeSetUp() {\\n\\n    for n in 1 2\\n    do\\n        for method in \\\"l\\\" \\\"t\\\"\\n        do\\n              bash inc.bash -$method $n | tee log/out.$method$n.log\\n        done\\n    done\\n}\\n```\\n\\nKtóra zgodnie z dokumentacją `shunit2` wykonana zostaje na samym początku testowania. Odpoiwada ona za wywołanie programu `inc.bash` cztery razy ze wszystkimi kombinacjami parametrów `-l` i `-t` oraz liczb `1` i `2` a następnie przekierowanie wyjścia do odpowiednio nazwanych plików.\\n\\nKolejna funkcja wykona się po zakończeniu testowania - posprząta po testach.\\n\\n```bash\\noneTimeTearDown() {\\n    rm -rf log/out.*.log\\n}\\n```\\n\\nMożemy przejść do właściwych funkjci zawierających testy:\\n\\n```bash\\n# in database there are 16 columns of parameters\\ntest_parameters_are_proporly_estimated()\\n{\\n    infile=$(grep inc config/parameters.csv | wc -l);\\n    inbase=$(sqlite3 log/log.db \\\"SELECT count(*) FROM result WHERE a>ea and b>eb\\\");\\n    echo $infile;\\n    echo $inbase;\\n    assertEquals $infile $inbase;\\n}\\n```\\n\\nPierwszy z testów sprawdza, czy plik `config/parameters.csv` został poprawnie załadowany do bazy przez skrypt `util/parameters_load.pl`.\\n\\n```bash\\n# ratio of loops for 2 sec to 1 sec is between 1.9 and 2.1\\ntest_ratio_of_loops_in_proper_range()\\n{\\n     ratioOfColumns 3 t1 t2 | columnInRange 1.95 2.2\\n}\\n```\\n\\nKolejny test bierze stosunek ilości pętli dla 2 sekund i 1 sekundy. Intuicyjnie czujemy, że powinien być on bliski dwójki, ale dopuszczamy odstępstwa w granicach błędu pomiarowego.\\n\\n```bash\\n# ratio of time for test with 2 sec and 1 sec should be near to 2\\ntest_ratio_of_time_should_be_near_2_for_time_based_test()\\n{\\n    ratioOfColumns 4 t1 t2 | columnInRange 1.5 4;\\n}\\n```\\n\\nNastępny test określa stosunek czasów dla programu zakładającego wykonywanie w 2 sekundy do 1 sekundy. Gdyby środowisko było idealne, to ten stosunek powinien wynosić dwa. jednak ponieważ na `gitlabie` moc obliczeniowa przydzielana runnerom jest dość niestabilna, pozwalamy na dużą granicę błędu pomiarowego.\\n\\n```bash\\n# ratio of time for test with 2 and 1 loop should be near to 1\\ntest_ratio_of_time_should_be_near_1_for_loop_based_test()\\n{\\n    ratioOfColumns 4 l1 l2 | columnInRange 0.4 1.8;\\n}\\n```\\n\\nPodobnie jest dla czasu wykonywania jednej i dwóch pętli. Stosunek tych czasów powinien być bliski jedności, ponieważ czas wykonywania pętli jest rzędy wielkości niższy od czasu włączania programu. Jednak i tutaj dopuszczamy duże różnice związane ze zmiennością dostępnej mocy obliczeniowej.\\n\\n```bash\\n# any free language (without matlab and mathematica) start in time small than 0.2 sec\\ntest_start_no_longer_than_150_milisecond()\\n{\\n    # time of programs for 1 loop\\n    awk '/inc/ {print $6}' log/out.l1.log | columnInRange 0.001 0.15;\\n}\\n```\\n\\nKolejny test sprawdza, czy wszystkie programy startują szybciej niż w 0.15 sec i wolniej niż 1 milisekundę.\\n\\n```bash\\n# ratio of speed for time based test should be near to 1\\ntest_speed_should_be_not_dependent_from_loops_in_limit()\\n{\\n    ratioOfColumns 5 t1 t2 | columnInRange 0.5 1.4;\\n}\\n```\\n\\nNastępny dotyczy czasów długich w porównaniu z czasem włączania programu, a 1-2 sekund za takie można uznać i wymaga aby stosunek prędokości wykonywania pętli dla tych czasów był bliski jedności, a więc nie zmieniał się wraz z czasem.\\n\\n```bash\\n# ratio of speed for 2 and 1 loop should be near to 2\\ntest_ratio_of_speed_for_small_loop_number_in_proper_range()\\n{\\n    ratioOfColumns 5 l1 l2 | columnInRange 1.1 7.0;\\n}\\n```\\n\\nZupełnie odwrotnie dla 1-2 pętli, jeśli czas jest prawie taki sam, to mierzona prędkość powinna być prawie dwa razy wyższa dla 2 pętli niż dla jednej. Nie możemy jednak mierzyć tego zbyt dokładnie, ponieważ czasy wykonywania programów dla tak niewielkich ilości pętli są zwykle bliskie błędom pomiarowym.\\n\\n```bash\\ntest_ratio_of_speed_for_1_and_2_loops_form_database()\\n{\\n    for n in 1 2\\n    do\\n        sqlite3 log/log.db \\\"SELECT name, avg(size/time) as speed FROM \\\\\\n            log WHERE size=\\\"$n\\\" AND name!='inc.m.sh' AND name!='inc.wl' GROUP BY name\\\" \\\\\\n            > log/out.l$n.speed.log\\n    done\\n\\n    ratioOfColumns 2 l1.speed l2.speed | columnInRange 1.1 7.0;\\n}\\n```\\n\\nOstatni test powtarza to samo co poprzedni, ale tym razem wydobywa dane z bazy, a nie konsoli.\\n\\n```bash\\n. shunit2-2.1.6/src/shunit2\\n```\\n\\nJako ostatnią linię skryptu testującego dołączamy zgodnie z dokumentacją program `sh2unit`.\\n\\n### Ciągła integracja\\n\\nNa sam koniec opiszę proces ciągłej integracji, który wdrożyłem w tym projekcie. Ciągła integracja jest to wykonywanie instalacji i testów automatycznych przy każdym `pushu` na serwer z repozytorium. Możemy do tego wykorzystywać różne narzędzia. Ja zdecydowałem się na [`gitlab-ci`](https://about.gitlab.com/gitlab-ci/).\\n\\nSkładnia pliku z instrukcjami dla runnera jest podobna do tej z [travisa](https://docs.travis-ci.com/). Zaczyna się od wybrania obrazu dystrybucji na której uruchamiany testy:\\n\\n```yml\\n## Select image from https://hub.docker.com/_/php/\\nimage: ubuntu:16.10\\n```\\n\\nNastępnie podpinamy serwisy, które mogły by być instalowane ręcznie, ale dla uproszczenia przygotowano je w formie gotowych do wpięcia komponentów:\\n\\n```yml\\nservices:\\n- mysql:8\\n- php:7\\n```\\n\\nDefiniujemy zmienne wykorzystywane do łączenia z bazą danych:\\n\\n```yml\\nvariables:\\n  # Configure mysql service (https://hub.docker.com/_/mysql/)\\n  MYSQL_DATABASE: inc\\n  MYSQL_ROOT_PASSWORD: pass\\n```\\n\\nOkreślamy zestaw instrukcji do wykonania przed testami:\\n\\n```yml\\nbefore_script:\\n- bash install.sh\\n- perl util/parameters_load.pl\\n- export MYSQL_PWD=$MYSQL_ROOT_PASSWORD;\\n- export MYSQL_HOST=\\\"mysql\\\";\\n- echo \\\"SELECT 'OK';\\\" | mysql --user=root \\\"$MYSQL_DATABASE\\\"\\n\\n# local variables\\n#  https://dev.mysql.com/doc/refman/5.7/en/environment-variables.html\\n```\\n\\nW ich skład wchodzi instalacja naszych zależności, ładowanie parametrów, eksportowanie zmiennych środowiskowych do łączenia z bazą i prosty test na połączenie.\\n\\nGłówna część, czyli testowanie zawarte jest w poniższym fragmencie kodu;\\n\\n```yml\\ntest:\\n  image: mysql\\n  image: php\\n  script:\\n  - bash test.sh\\n```\\n\\nŻeby przetestować kod lokalnie wykonujemy komendę:\\n\\n```bash\\nsudo gitlab-ci-multi-runner exec docker test\\n```\\n\\nTo już wszystko. Mam nadzieję, że ten artykuł uświadomił Ci, że wybór języka może mieć ogromne znaczenie dla wydajności oraz przybliżył Ci historię kilku z nich. Jednak najważniejsze, że ten kod został przygotowany tak, aby łatwo było go rozszerzyć o pomiary dotyczące zadań jak na przykład zapis do pliku, albo wykonywanie całkowania numerycznego. Jeśli będziesz zainteresowany rozwijaniem tego softu daj znać, mam parę koncepcji, w którą stronę można by rozwinąć ten projekt.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"opis-projektu\">Opis projektu</h2>\n<p>Nie wiem, jakie są wasze wymarzone prezenty gwiazdkowe, ale moim jest kawałek ciekawego kodu. I właśnie taki prezent dostałem około półtora miesiąca temu.</p>\n<p>Mój przyjaciel wysłał mi w e-mailu <a href=\"https://www.dropbox.com/s/s9dy1jabkzxzls6/loopspeed.zip?dl=1\">Kod źródłowy programu</a>, który mierzył czasy wykonywania pustych pętli w czterech różnych językach programowania. Dopisałem testy dla dwunastu innych języków, lekko zautomatyzowałem testowanie i przeanalizowałem wyniki.</p>\n<p>W tym wpisie pokażę jak wyglądają i jak szybko działają programy wykonujące puste pętle językach:</p>\n<ul>\n<li>Matlab,</li>\n<li>Bash,</li>\n<li>SQL,</li>\n<li>Mathematica,</li>\n<li>C#,</li>\n<li>JavaScript,</li>\n<li>Python,</li>\n<li>Ruby,</li>\n<li>Perl,</li>\n<li>R,</li>\n<li>Php,</li>\n<li>Fortran 95,</li>\n<li>C++,</li>\n<li>C,</li>\n<li>Pascal</li>\n<li>Java.</li>\n</ul>\n<p>Do logowania danych wykorzystamy plik tekstowy oraz silnik bazodanowy <code>SQLite</code>. Analizę danych przeprowadzimy w programie Mathematica.</p>\n<h2 id=\"instalacja\">Instalacja</h2>\n<p>Z automatyzacją instalacji serwera bazy danych <code>mysql</code> zawsze wiążą się pewne problemy jak <a href=\"http://stackoverflow.com/questions/7739645/install-mysql-on-ubuntu-without-password-prompt\">konieczność podawania hasła</a> albo zmieniania <a href=\"http://askubuntu.com/questions/766334/cant-login-as-mysql-user-root-from-normal-user-account-in-ubuntu-16-04\">zakresu lokacji</a> z których można łączyć się z bazą jako <code>root</code>. Dlatego nie umieściłem instalacji serwera <code>mysql</code> w pliku <code>install.sh</code>. Jeśli nie masz serwera bazy danych, zainstaluj go ręcznie:</p>\n<pre><code class=\"language-bash\">sudo apt-get install -y mysql-server mysql-client\n</code></pre>\n<p>Niestety, a raczej niestety dla mnie, od kilku miesięcy świeżo zainstalowany serwer <code>MySQL</code> nie pozwala już domyślnie logować się komendą <code>mysql -u root</code>, zamiast tego wymaga <code>sudo mysql -u root</code>. Jest to zrozumiałe ze względów bezpieczeństwa i na pewno pomaga na serwerach produkcyjnych, ale z drugiej strony jest to niewygodne przy bawieniu się kodem w domu. Jeśli twój komputer to maszyna lokalna i tak jak ja nie chcesz używać <code>sudo</code> do każdego łączenia z bazą z <code>basha</code>, możesz wykonać następujący <a href=\"http://stackoverflow.com/questions/38098505/mysql-works-with-sudo-but-without-not-ubuntu-16-04-mysql-5-7-12-0ubuntu1-1\">manewr</a>:</p>\n<pre><code class=\"language-bash\">sudo mysql -u root\nDROP USER 'root'@'localhost';\nCREATE USER 'root'@'%' IDENTIFIED BY '';\nGRANT ALL PRIVILEGES ON *.* TO 'root'@'%';\nFLUSH PRIVILEGES;\nexit\n</code></pre>\n<p>w ten sposób przywrócisz <code>mysql -u root</code> jako działającą metodę łączenia się z bazą. Prezentowany tutaj program używa właśnie takiej metody -  to znaczy bez <code>sudo</code>.</p>\n<p>Jeśli nie chcesz zmieniać ustawień bazy danych zawsze możesz użyć <a href=\"https://dev.mysql.com/doc/refman/5.7/en/environment-variables.html\">zmiennych środowiskowych</a>.</p>\n<pre><code class=\"language-bash\">export MYSQL_PWD=&lt;your password to mysql server&gt;\nexport MYSQL_HOST=localhost;\n</code></pre>\n<p>Nie jest to rozwiązanie, które należy stosować na serwerach produkcyjnych, natomiast świetnie nadaje się na maszyny lokalne, bo jest wygodne.</p>\n<p>Żeby sprawdzić, czy Twoja konfiguracja bazy jest poprawna wykonaj komendę:</p>\n<pre><code class=\"language-bash\">mysql --user=root &quot;$MYSQL_DATABASE&quot; -e &quot;SELECT 'OK' as 'state'&quot;\n</code></pre>\n<p>Jeśli zobaczysz</p>\n<pre><code class=\"language-sql\">+-------+\n| state |\n+-------+\n| OK    |\n+-------+\n</code></pre>\n<p>to reszta instalacji jest jeszcze prostsza.</p>\n<p>Instalację projektu na czystym Ubuntu 16.04.1 LTS wymaga wpisania trzech komend:</p>\n<pre><code class=\"language-bash\">sudo apt-get install git\ngit clone --depth=1 http://gitlab.com/gustawdaniel/loopspeed &amp;&amp; cd loopspeed\nsudo bash install.sh\nperl util/parameters_load.pl\n</code></pre>\n<p>Jest to pierwszy wpis z repozytorium na <code>gitlabie</code> a nie <code>githubie</code>. Nie jest to przypadek, lecz zasługa świetnego narzędzia do ciągłej integracji - <code>gitlab-ci</code>, które omówię na samym końcu.</p>\n<p>Teraz przyjrzymy się skryptom: instalacyjnemu i ładującemu parametry.</p>\n<p>Skrypt instalacyjny <code>install.sh</code> wykonuje aktualizację listy dostępnych paczek i instalację wymaganych kompilatorów i interpreterów języków:</p>\n<pre><code class=\"language-bash\">#!/usr/bin/env bash\n\napt-get update -y\napt-get install -y php\napt-get install -y python default-jdk g++ mono-mcs gfortran fp-compiler r-base nodejs-legacy ruby\n</code></pre>\n<p>dorzuca do tego kilka programów, które wykorzystujemy</p>\n<pre><code class=\"language-bash\">apt-get install -y sqlite3 bc git mysql-client curl\n</code></pre>\n<p>oraz paczki perla, których używamy głównie do komunikacji z bazą danych <code>SQLite</code></p>\n<pre><code>apt-get install -y libtext-csv-perl libdbi-perl libdbd-sqlite3-perl\n</code></pre>\n<p>Następnie tworzy bazę do przechowywania wyników pomiarów oraz wyliczonych na ich podstawie parametrów:</p>\n<pre><code class=\"language-bash\">sqlite3 log/log.db \\\n&quot;create table IF NOT EXISTS log (\n    id INTEGER PRIMARY KEY,\n    name VARCHAR(255),\n    size UNSIGNED INTEGER,\n    time DECIMAL(12,6),\n    git CHAR(41)\n);&quot;\n\nsqlite3 log/log.db \\\n&quot;create table result (\n    name varchar(255),\n    a real,\n    b real,\n    ea real,\n    eb real\n);&quot;\n</code></pre>\n<p>I na koniec instalator pobiera bibliotekę do testowania kodu pisanego w <code>bashu</code> - <code>shunit2</code>.</p>\n<pre><code class=\"language-bash\">curl -L &quot;https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/shunit2/shunit2-2.1.6.tgz&quot; | tar zx\n</code></pre>\n<p>Drugim skryptem który wykonaliśmy był</p>\n<blockquote>\n<p>util/parameters_load.pl</p>\n</blockquote>\n<pre><code class=\"language-perl\">#!/usr/bin/perl -w\n\nuse v5.10;\nuse strict;\nuse warnings;\nuse autodie;\n\nuse Text::CSV_XS;\nuse DBI;\n\nmy $dbh = DBI-&gt;connect(\n    &quot;dbi:SQLite:log/log.db&quot;, &quot;&quot;, &quot;&quot;,\n    {\n        RaiseError =&gt; 1, AutoCommit =&gt; 0\n    }\n);\n\n$dbh-&gt;do(&quot;DELETE FROM result&quot;);\n\n# Using bind parameters avoids having to recompile the statement every time\nmy $sth = $dbh-&gt;prepare(&lt;&lt;'SQL');\nINSERT INTO result\n       (name, a,     b,     ea,    eb)\nVALUES (?,    ?,     ?,     ?,     ?)\nSQL\n\nmy $csv = Text::CSV_XS-&gt;new or die;\nopen my $fh, &quot;&lt;&quot;, &quot;config/parameters.csv&quot;;\nwhile(my $row = $csv-&gt;getline($fh)) {\n    $sth-&gt;execute(@$row);\n}\n$csv-&gt;eof;\nclose $fh;\n\n$sth-&gt;finish;\n$dbh-&gt;commit;\n</code></pre>\n<p>Jego zadaniem jest przeniesienie zawartości pliku tekstowego <code>config/parameters.csv</code> do tabeli <code>result</code> bazy danych <code>log/log.db</code>. Przenoszone dane dotyczą szacowanych czasów wykonywania pętli i zostały wyliczone z wyników przeprowadzonych wcześniej pomiarów.</p>\n<p>Dwa z języków, które testowałem - <code>Matlab</code> i <code>Mathematica</code> - wymagają zainstalowanego licencjonowanego oprogramowania. Co prawda, studenci mają zwykle te licencje dzięki uczelniom, ale ze względu na to, że jest licencjonowane, testy dla tych języków są domyślnie wyłączone.</p>\n<h2 id=\"framework\">Framework</h2>\n<p>Nasz program do testowania pustych pętli ma następującą strukturę katalogów:</p>\n<pre><code>├── config\n│   ├── list.txt\n│   └── parameters.csv\n├── inc\n│   ├── def.sql\n│   ├── inc.bash\n│   ├── inc.c\n│   ├── inc.cpp\n│   ├── inc.cs\n│   ├── inc.f95\n│   ├── inc.java\n│   ├── inc.js\n│   ├── inc.m.sh\n│   ├── inc.p\n│   ├── inc.perl\n│   ├── inc.php\n│   ├── inc.python\n│   ├── inc.r\n│   ├── inc.rb\n│   ├── inc.sql.sh\n│   └── inc.wl\n├── util\n│   ├── generate_parameters.wl\n│   ├── parameters_load.pl\n│   ├── text_to_sqlite.pl\n│   ├── timing_methods.sh\n│   └── timing.sh\n├── log\n│   ├── log.db\n│   ├── results_timing_methods.log\n│   └── results.log\n├── install.sh\n├── analysis.nb\n├── inc.bash\n├── test.sh\n├── README.md\n└── .gitlab-ci.yml\n</code></pre>\n<p>Katalog <code>config</code> zawiera pliki pomocnicze z ustawieniami. Pierwszym z nich jest lista parametrów dla których będziemy wykonywać serie testowe <code>config/list.txt</code> - zwykły plik tekstowy z liczbami całkowitymi w kolejnych liniach. Drugim oszacowane wartości parametrów określających szybkość wykonywania pustych pętli <code>config/parameteres.csv</code>.</p>\n<p>W <code>inc</code> znajduje się 16 plików odpowiadających za testowanie pętli oraz jeden do definiowania procedury w <code>MySQL</code>, która dopiero, kiedy zostanie wywołana wywołana będzie wykonywać pętle.</p>\n<p>W <code>util</code> umieściłem narzędzia pomocnicze, które pozwalały mi na przerzucanie danych z pliku tekstowego do bazy <code>SQLite</code>, oraz mierzenie różnic między wynikami dwóch metod pomiaru czasu trwania programu. Jest tam też skrypt do dopasowywania modelu i tworzenia pliku <code>config/parameters.csv</code>, oraz skrypt do ładowania tych parametrów do bazy danych <code>sqlite</code>. Wykorzystanie plików tekstowych do logowania wyników pomiarów jest z jednej strony związane z rozwijaniem tego softu. Pliki tekstowe były stosowane zanim przeszedłem na silnik bazodanowy. Z drugiej strony nie chciałem zaśmiecać bazy danymi pomiarowymi, których nie byłem pewien, więc jeśli istniało ryzyko, że program, który testuję będzie działał źle - na przykład kiedy spodziewałem się, że wyjdę poza zakres danego typu liczbowego - wyłączałem logowanie do bazy i posługiwałem się tylko plikiem. Jeśli wszystko było ok, mogłem bez problemu załączyć nowe wyniki do uzyskanych wcześniej.</p>\n<p>Katalog <code>log</code> służy do przechowywania plików tekstowych oraz bazy danych <code>SQLite</code>. Plik <code>result.log</code> zawiera kopię danych, które trafiają do bazy danych, <code>results_timing_methods.log</code> przechowuje wyniki pomiarów czasu. Podczas testowania w tym katalogu pojawiają się na czas testów inne pliki z logami.</p>\n<p>Poza tym projekt zawiera:</p>\n<ul>\n<li><code>install.sh</code> - skrypt instalacyjny (omówiłem go w poprzednim paragrafie),</li>\n<li><code>inc.bash</code> - bazowy skrypt do robienia pomiarów czasu trwania pustych pętli,</li>\n<li><code>analysis.nb</code> - notebook programu Mathematica. Służył on do badania wyników.</li>\n<li><code>test.sh</code> - skrypt do testowania działania <code>inc.bash</code> oraz innych elementów projektu.</li>\n</ul>\n<p>Dzięki takiej strukturze jesteśmy w stanie bez problemu dodawać nowe języki programowania. Trzymanie w bazie numeru rewizji pozwala nam również sprawdzać, jak różne instrukcje spełniające teoretycznie tą samą funkcjonalność (np: <code>for</code> vs <code>while</code>) różnią się od siebie wydajnością.</p>\n<h2 id=\"dataflow\">Dataflow</h2>\n<p>Przepływ danych w programie posiada wbudowane sprzężenie zwrotne. Z jednej strony <code>inc.bash</code> testuje pętle za pomocą parametrów wyliczonych z modelu za pomocą <code>util/generate_parameters.wl</code>, z drugiej strony, żeby móc dopasować model do danych, musieliśmy je najpierw dostać właśnie uruchamiając <code>inc.bash</code>.</p>\n<p>Patrząc na wykres przepływu danych łatwo znajdziemy zamknięte koło, które mam na myśli.</p>\n<p><a href=\"https://postimg.org/image/mrfbkb5d7/\"><img src=\"https://s9.postimg.org/fbg1yihnz/Loopspeed.png\" alt=\"Loopspeed.png\" loading=\"lazy\"></a></p>\n<p>Jest to klasyczny problem, co było pierwsze, jajko czy kura? Pierwszy był model teoretyczny, który określił co warto mierzyć czy dane doświadczalne, dzięki którym możemy go zgadnąć? Tak jak w biologicznym odpowiedniku, tak tutaj odpowiedzią jest ewolucja. Początkowo każdy z programów <code>inc.i</code>, (gdzie <code>i</code> jest numerem testowanego języka programowania) był włączany ręcznie. Z jedną pętlą. Później z tysiącem, milionem, miliardem. Kiedy widziałem, że wykonuje się dłużej niż kilka sekund obniżałem liczbę pętli, kiedy krócej niż sekundę podnosiłem ją. Dążyłem do tego, żeby ręcznie znaleźć liczbę pętli odpowiadającą miej więcej 4-5 sekund wykonywania programu. Tak uzyskiwałem pierwsze wartości parametrów, które jeszcze wtedy były wpisywane ręcznie do kodu programu <code>inc.bash</code>. Dzięki temu uwspólniłem skalę dla wszystkich z wyjątkiem języka <code>Matlab</code>, którego inicjalizacja trwała 5 sekund z kawałkiem. Dla <code>Matlaba</code> robiłem oddzielną serię pomiarową zanim go wyczułem. Dane z tego typu testów trafiały do pliku <code>results.log</code>, ale o tym czy przenosić je do <code>log.db</code> decydowałem na podstawie zdrowego rozsądku, w jednym przypadku zdarzyło się, że dla jednego z języków czasy rosły wraz z liczbą pętli <code>$size</code> do pewnego momentu, a zaczęły trzymać się stałego poziomu. Okazało się, że zakresy zmiennych nie wystarczają do pomieszczenia liczby iteracji i jest ona po prostu rzutowana na mniejszą wartość. Były przypadki (<code>python</code> oraz <code>r</code>) gdzie brakowało pamięci RAM, bo pętla <code>for</code> zamiast inkrementować skalarny wskaźnik była skonstruowana tak, że ładowała do pamięci operacyjnej całą tablicę, po której później przebiegała. Ogólnie rzecz biorąc, nie dało by się zupełnie zautomatyzować testów na tym etapie. W niektórych językach trzeba było zmieniać typy, na przykład w <code>Pascalu</code> zwykły <code>Int</code> nie wystarczył i trzeba było stosować <code>QWord</code>, analogicznie w <code>C#</code> typ <code>Int32</code> był zmieniany na <code>UInt64</code>. Podsumowując: początkowo model istniał tylko w mojej głowie. Na początku nie było <code>analysis.nb</code> ani <code>list.txt</code>, <code>inc.bash</code> zawierał zakodowane na sztywno przybliżone szybkości pętli i nie miał tylu opcji, z którymi można było go włączać.</p>\n<p>Kiedy <code>results.log</code> rozrósł się, a ja zrozumiałem, że testowanie w stronę krótszych czasów jest nieopłacalne bo generuje za dużo błędu pomiarowego, a w stronę dłuższych czasów nieopłacalne, bo nie wnosi żadnych nowych efektów, wtedy powstał program <code>text_to_sqlite.pl</code> do konwertowania pliku tekstowego do postaci wierszy w bazie danych. Zrezygnowałem z zapisywania zmiennej <code>$speed</code> - szybkości pętli, jako, że dzięki silnikowi bazodanowemu jej wyliczanie było prostsze, uznałem natomiast, że jeśli wprowadzam zmiany w programach <code>inc.i</code>, to w danych może pojawić się bałagan. Żeby móc wykrywać, z jakiej wersji programu pochodzą dane zapisy dodałem zmienną <code>$git</code> z numerem rewizji. Wtedy powstał notebook <code>analysis.nb</code> i z jego pomocą wyliczyłem parametry do <code>bash.inc</code> z większą dokładnością.  Zaplanowałem też serię pomiarową <code>list.txt</code> która wykładniczo rozrzedzała się dla rosnących czasów pomiarów. Na koniec obliczanie parametrów przeniosłem do skryptu <code>util/generate_parameters.wl</code>, dopisałem <code>util/parameters_load.pl</code> do ich konwersji do bazy <code>sqlite</code> i podłączyłem te dane do <code>inc.bash</code>. Dzięki modelowi mogłem wyliczyć ile czasu będzie trwał jaki pomiar. W ten sposób obieg danych zamknął się. Model zaczął wyznaczać optymalne punkty pomiarowe, a uzyskiwane dane zaczęły płynąć w coraz bardziej zautomatyzowany i zracjonalizowany sposób.</p>\n<h3 id=\"j%C4%85dro-programu\">Jądro programu</h3>\n<p>Kiedy wiemy już co jak działa i do czego służy obejrzymy kod programu <code>inc.bash</code>. Program zaczyna się od funkcji odpowiedzialnej za wyświetlanie okna pomocy.</p>\n<blockquote>\n<p>inc.bash</p>\n</blockquote>\n<pre><code class=\"language-bash\">#! /bin/bash\n\nshow_help() {\ncat &lt;&lt; EOF\nUsage: bash inc.bash [-a](-f|-l) (single_number|-f file_with_numbers_in_lines)\n\n    -h          display this help and exit\n    -a          all programs enable, enable this only if you have\n                license on Mathematica and Matlab.\n    -t          time based mode of calculations. You assign number\n                of seconds for each program. Programs goes equally.\n    -l          line based mode of calculations. You assign number\n                of lines executed by loop. Good mode for debug.\n    -f file     load numbers of seconds (-t) or loops (-l) from file,\n                default config/list.txt\nEOF\n}\n</code></pre>\n<p>Widzimy, że posiada on kilka flag, z których możemy korzystać. Pierwszą znich jest <code>-a</code> służąca do wykonywania testów z wykorzystaniem oprogramowania komercyjnego: <code>matlab</code> i <code>mathematica</code>. Domyślnie jest to wyłączone, żeby program był dostępny bez konieczności ich instalowania. Następnie mamy do wyboru <code>-t</code> i <code>-l</code> odpowiadających za sposób wyznaczania ilości pętli. W opcji <code>-t</code> użytkownik wyznacza czas w sekundach jaki ma zająć wykonywanie każdego z badanych programów <code>inc/inc.i</code>, na podstawie tego czasu i parametrów wyznaczonych wcześniej przez <code>util/generate_parameters.wl</code> określane są liczby pętli dla każdego z nich. Opcja <code>-l</code> pozwala na pomiar dokładnej ilości pętli jakie chcemy wykonać. Na koniec określamy liczbowo ilość oczekiwanych sekund lub wykonywanych pętli albo za pomocą flagi <code>-f</code> ładujemy plik z serią pomiarową. Następnie program stosuje bardzo ciekawy mechanizm czyszczenia po sobie niezależnie od sposobu w jaki ma zostać zamknięty.</p>\n<pre><code class=\"language-bash\">function onExit {\n\t[ ! -z &quot;$TMP&quot; ] &amp;&amp; \\\n\t[   -d &quot;$TMP&quot; ] &amp;&amp; \\\n\trm -Rf &quot;$TMP&quot;;\n\trm -f inc.class;\n\texit;\n}\n</code></pre>\n<p>Zastosowano tutaj ciekawą składnię z flagami <code>-z</code> i <code>-d</code>. Dokumentacja <a href=\"http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html\">basha</a> wyjaśnia, że lokalizacja wskazywana przez zmienną <code>$TMP</code> ma zostać usunięta jeśli zmienna <code>$TMP</code> coś w ogóle zawiera i jeśli wskazuje na katalog. Kolejna linia to usunięcie pliku pochodzącego z kompilacji <code>javy</code>, który nie trafił do <code>$TMP</code> tylko dlatego, że nie potrafiłem go tam wrzucić.</p>\n<p>Funkcja <code>onExit</code> wykona się przy zamykaniu programu, co będzie zaznaczone później. Teraz przyjrzymy się funkcji <code>test</code> - kompletującej wszystkie dane, wykonującej testy i wysyłającej dane do bazy oraz pliku. Jest to centralny punkt całego systemu, odpowiada ona za uwspólnienie interfejsu wszystkich programów.</p>\n<pre><code class=\"language-bash\">function test {\n\tname=&quot;$1&quot;;\n\tsize=&quot;$2&quot;;\n\tcomm=&quot;${@:3}&quot;\n</code></pre>\n<p>Przyjmuje ona na wejściu trzy lub więcej parametrów. Pierwszy to nazwa: zwykle <code>inc.&lt;rozszerzenie języka&gt;</code> np: <code>inc.c</code> lub <code>inc.js</code>. Nie jest ona w żaden sposób powiązana ani z lokalizacją pliku źródłowego, ani wykonywalnego. W zasadzie mogła by być dowolna. Przyjąłem jednak konwencję, że nazywa się tak jak plik źródłowy. Drugi parametr to liczba pętli jaka ma zostać wykonana <code>$size</code>. Kolejne parametry, niezależnie od ich ilości wrzucane są do zmiennej <code>$comm</code> - jest to komenda do włączenia programu, ale bez liczby pętli.</p>\n<pre><code class=\"language-bash\">    [ $size -le 0 ] &amp;&amp; return;\n</code></pre>\n<p>Po zabezpieczeniu się, że liczba pętli nie może być ujemna funkcja <code>test</code> może wykonywać pomiar czasu.</p>\n<pre><code class=\"language-bash\">    time=`bash util/timing.sh $comm $size`\n\techo $name,$size,$time,$GIT\t\\\n\t    | tee -a log/results.log \\\n\t    | awk -F ',' '{printf &quot;| %-12s | %15s | %12.6f s | %19.2f |\\n&quot;, $1, $2, $3, $2/$3;}'\n</code></pre>\n<p>Widzimy, że wykorzystuje do tego program <code>util/timing.sh</code> podając mu komendę do wykonania wraz z liczbą pętli. Wynik działania programu <code>timing.sh</code> przekazywany jest do zmiennej <code>time</code>. Następnie nazwa, ilość tętli, czas i numer rewizji wysyłane są do pliku <code>log/results.log</code> oraz a nazwa, ilość pętli, czas i szybkość wyświetlane na ekranie. Numer rewizji znajduje się w globalnej zmiennej <code>GIT</code> i będzie zdefiniowany później. Ten sam zestaw danych, który zapisany było do pliku <code>log/resutls.log</code> trafia do bazy danych.</p>\n<pre><code class=\"language-bash\">     sqlite3 log/log.db  &quot;insert into log (name,size,time,git) values ('$name',$size,$time,'$GIT');&quot;\n}\n</code></pre>\n<p>Kolejna funkcja służy głównie uporządkowaniu kodu programu i zostanie wywołana tylko raz bez żadnych parametrów.</p>\n<pre><code class=\"language-bash\">function compile {\n    g++ -O1 -o &quot;$TMP/cpp&quot; 'inc/inc.cpp';\n    gcc -O1 -o &quot;$TMP/c&quot;   'inc/inc.c';\n    mcs -out:&quot;$TMP/cs.exe&quot; inc/inc.cs\n    javac 'inc/inc.java' -d .;\n    mysql -u root &lt; inc/def.sql;\n    f95 -O1 -o &quot;$TMP/f&quot; inc/inc.f95\n    fpc -O2 inc/inc.p -o&quot;$TMP/p&quot; -Tlinux &amp;&gt;/dev/null\n}\n</code></pre>\n<p>Wykonuje ona kompilacje języków które tego wymagają. Czas kompilacji nie jest nigdzie mierzony.</p>\n<p>Zupełnie inaczej jest z funkcją <code>calculate</code> obliczającą ilość pętli która ma się wykonać. Ta funkcja będzie wykonywana przy każdym pojedynczym teście. Jej działanie uzależnione jest od wartości zmiennej globalnej <code>$timeMode</code>. Jeśli włączamy program z flagą <code>-l</code> to <code>$timeMode=0</code> i funkcja zwróci nam swój pierwszy argument oraz wartość liczbową zmiennej globalnej <code>$POW</code>. Jedynym argumentem tej funkcji jest nazwa języka - u nas zapisywana jako <code>inc.&lt;rozszerzeie&gt;</code>. Zmienna <code>$POW</code> odpowiada liczbie którą podajemy do programu niezależnie czy robimy to za jego nazwą, czy jest to jedna z liczb z pliku jaki wrzucamy za flagą <code>-f</code>. Jeśli program działa z flagą <code>-t</code> to za pomocą programu <code>awk</code> wyliczamy liczbę pętli ze wzoru <code>(pow-b)/a</code> gdzie <code>pow</code> jest czasem w sekundach, natomiast <code>b</code> oraz <code>a</code> są parametrami dopasowania prostej. Nasze <code>a</code> i <code>b</code> to w programie elementy tablicy asocjacyjnej, którą będziemy niedługo definiować.</p>\n<pre><code class=\"language-bash\"># number of loops for given languages in dependence from $timeMode\nfunction calculate {\n\n    if [[ &quot;$timeMode&quot; -eq &quot;1&quot;  ]]; then\n        echo $1 ${a[$1]} ${b[$1]} $POW | awk '{ printf &quot;%s %.0f\\n&quot;, $1, ($4-$3)/$2 }';\n    else # linemode for debug\n        echo $1 $[1*POW];\n    fi\n}\n</code></pre>\n<p>Tymczasem przyjżymy się funkcji odpowiedzialnej za testowanie całego zbioru programów dla danego parametru <code>$POW</code>.</p>\n<pre><code class=\"language-bash\">function testbundle {\n    [ &quot;$allPrograms&quot; -eq &quot;1&quot; ] &amp;&amp; test    $(calculate inc.m.sh    )    bash    inc/inc.m.sh; # long time of setup about 5 sec\n    test    $(calculate inc.bash    )    bash    inc/inc.bash;\n    test    $(calculate inc.sql.sh  )    bash    inc/inc.sql.sh;\n    [ &quot;$allPrograms&quot; -eq &quot;1&quot; ] &amp;&amp; test    $(calculate inc.wl      )    MathematicaScript -script inc/inc.wl;\n    test    $(calculate inc.r       )    Rscript inc/inc.r;\n    test    $(calculate inc.cs      )    mono    &quot;$TMP/cs.exe&quot;;\n    test    $(calculate inc.js      )    node    inc/inc.js;\n    test    $(calculate inc.python  )    python  inc/inc.python;\n    test    $(calculate inc.rb      )    ruby    inc/inc.rb;\n    test    $(calculate inc.pl      )    perl    inc/inc.pl;\n    test    $(calculate inc.php     )    php     inc/inc.php;\n    test    $(calculate inc.f95     )    &quot;/$TMP/f&quot;;\n    test    $(calculate inc.cpp     )    &quot;$TMP/cpp&quot;;\n    test    $(calculate inc.c       )    &quot;$TMP/c&quot;;\n    test    $(calculate inc.p       )    &quot;$TMP/p&quot;;\n    test    $(calculate inc.java    )    java inc;\n}\n</code></pre>\n<p>Widzimy, że sprawdza ona wartość zmiennej <code>$allPrograms</code> powiązanej z flagą <code>-a</code>, żeby włączać testy <code>mathematica</code> i <code>matlab</code> tylko jeśli ustawiono tą flagę. Poza tym wykonuje ona bardzo powtarzalny schemat - dla każdego programu włącza funkcję <code>test</code>. Za dwa pierwsze parametry - nazwę i liczbę pętli podstawia wynik funkcji <code>calculate</code>, wszystkie pozostałe są zwijane do komendy odpalającej testowany program.</p>\n<p>Do wyjaśnienia pozostaje jeszcze - skąd wzięły się tablice asocjacyjne  parametrami. Za ich utworzenie odpowiada funkcja <code>loadParams</code>.</p>\n<pre><code class=\"language-bash\">function loadParams {\nsource &lt;(sqlite3 log/log.db &quot;select name, a from result&quot; |\n         awk -F '|' '{printf(&quot;a[%s]=%s;\\n&quot;,$1,$2);}')\n\nsource &lt;(sqlite3 log/log.db &quot;select name, b from result&quot; |\n         awk -F '|' '{printf(&quot;b[%s]=%s;\\n&quot;,$1,$2);}')\n}\n</code></pre>\n<p>Stosowana tu składnia z wykorzystaniem <code>source</code> jest bardzo niezalecana w przypadku danych pochodzących od użytkowników. Tutaj jednak dane sami generujemy i uznałem, że jest to najłatwiejszy sposób na zdefiniowanie tych tablic. <code>Source</code> odpowiada za wykonanie kodu, który dostaje, a dostaje przetworzone do postaci np: <code>a[inc.bash]=4.231982349e-06</code> wyniki zapytań do tabeli z parametrami.</p>\n<p>Logika skryptu jest dość przewidywalna. Zaczyn się od przejścia do katalogu gdzie zlokalizowany jest skrypt. Następnie ustawiamy coś w rodzaju nasłuchu na zdarzenia <code>SIGINT</code>, <code>SIGTERM </code> i <code>EXIT</code>. Oznacza to, że jeśli będziemy chcieli wyłączyć program zanim skończy działać, to po sobie posprząta.</p>\n<pre><code class=\"language-bash\">cd &quot;$(dirname &quot;${BASH_SOURCE[0]}&quot;)&quot;;\ntrap onExit SIGINT SIGTERM EXIT;\n</code></pre>\n<p>Jeśli zastanawiasz się, co tu jest do sprzątania, to kolejna linijka stanowi odpowiedź na Twoje pytanie. Tworzymy w niej katalog tymczasowy do przechowywania skompilowanych wersji programów i wstawiamy jego lokalizację do zmiennej <code>$TMP</code>.</p>\n<pre><code class=\"language-bash\">TMP=&quot;$(mktemp -d)&quot;;\n</code></pre>\n<p>Do zmiennej globalnej <code>$GIT</code> przypisujemy aktualny numer rewizji.</p>\n<pre><code class=\"language-bash\">GIT=`git rev-parse HEAD`;\n</code></pre>\n<p>Tworzymy tablice asocjacyjne <code>a</code> oraz <code>b</code></p>\n<pre><code class=\"language-bash\">declare -A a\ndeclare -A b\n</code></pre>\n<p>I ustawiamy domyślne wartości wszystkich falg oraz zmiennych.</p>\n<pre><code class=\"language-bash\">allPrograms=0; # if all programs should be tested? Default: no, because licence is not free.\nconfigFile='config/list.txt';\ntimeMode=1;\nfileMode=0;\n</code></pre>\n<p>W pętli <code>while</code> przetwarzamy wszystkie danej wprowadzone przez użytkownika.</p>\n<pre><code class=\"language-bash\">while getopts hatlf opt; do\n    case $opt in\n        h)\n            show_help\n            exit 0\n            ;;\n        a)  allPrograms=$((allPrograms+1))\n            ;;\n        t)  timeMode=1;\n            ;;\n        l)  timeMode=0;\n            ;;\n        f)  configFile=${2:-${configFile}}; fileMode=1;\n            ;;\n        *)\n            show_help &gt;&amp;2\n            exit 1\n            ;;\n    esac\ndone\nshift &quot;$((OPTIND-1))&quot; # Shift off the options and optional --.\n</code></pre>\n<p>Po wychwyceniu wszystkich opcji przechwytujemy jeszcze parametr określający liczbę pętli lub sekund. Ładujemy parametry do tablic asocjacyjnych i kompilujemy programy.</p>\n<pre><code class=\"language-bash\">POW=${1:-4};\nloadParams;\ncompile\n</code></pre>\n<p>Wyświetalmy przyjazne elementy interfejsu użytkownika z nagłówkami tabeli.</p>\n<pre><code class=\"language-bash\">echo '+--------------+-----------------+----------------+---------------------+';\necho '|     File     |      Size       |      Time      |        Speed        |';\necho '+--------------+-----------------+----------------+---------------------+';\n\n</code></pre>\n<p>Wykonujemy testowanie odpowiednią liczbę razy.</p>\n<pre><code class=\"language-bash\">if [[ &quot;$fileMode&quot; -eq &quot;1&quot; ]]; then\n   while IFS='' read -r POW || [[ -n &quot;$POW&quot; ]]; do\n      testbundle;\n   done &lt; ${1:-${configFile}}\nelse\n  testbundle;\nfi\n</code></pre>\n<p>I kończymy program domknięciem tabeli.</p>\n<pre><code class=\"language-bash\">echo '+--------------+-----------------+----------------+---------------------+';\n</code></pre>\n<h3 id=\"skrypty-usprawniaj%C4%85ce-przep%C5%82yw-danych\">Skrypty usprawniające przepływ danych</h3>\n<p>Z czasem zwiększania ilości danych i testowania nowych zakresów pojawiła się potrzeba automatyzacji procesu przepływu danych. Służy do tego kilka poniższych skryptów.</p>\n<p>Do przerzucania tekstowych wyników pomiarów do bazy danych służy program:</p>\n<blockquote>\n<p>util/text_to_sqlite.pl</p>\n</blockquote>\n<pre><code class=\"language-perl\">#!/usr/bin/perl -w\nuse warnings FATAL =&gt; 'all';\nuse DBI;\nuse strict;\n#https://mailliststock.wordpress.com/2007/03/01/sqlite-examples-with-bash-perl-and-python/\nmy $db = DBI-&gt;connect(&quot;dbi:SQLite:log/log.db&quot;, &quot;&quot;, &quot;&quot;,{RaiseError =&gt; 1, AutoCommit =&gt; 1});\n\n\nmy $filename =  $ARGV[0] || 'log/results.log';\n</code></pre>\n<p>Po nagłówkach mamy tutaj zmienną <code>$db</code> przechowującą połączenie z bazą i <code>$filename</code> pobierającą argument z linii komend z domyślą wartością ustawioną na lokalizację pliku z logami. Takie ustawienie zmiennych dawało elastyczność, a jednocześnie nie wymagało wpisywania parametrów w najbardziej powtarzalnych sytuacjach. Następnie program otwierał plik:</p>\n<pre><code class=\"language-perl\">open( my $fh =&gt; $filename) || die &quot;Cannot open $filename: $!&quot;;\n</code></pre>\n<p>i iterując po jego liniach zapisywał odpowiednio przekształcone rekordy do bazy:</p>\n<pre><code class=\"language-perl\">while(my $line = &lt;$fh&gt;) {\n        my @row = split(&quot;,&quot;,$line);\n        $db-&gt;do(&quot;INSERT INTO log (name,size,time,git) values ('&quot;.$row[0].&quot;',$row[1],$row[2],'$row[3]');&quot;);\n}\nclose($fh);\n</code></pre>\n<h2 id=\"analiza\">Analiza</h2>\n<p>Zdarzało nam się na tym blogu analizować dane. Schemat jest prosty. Łączymy się z bazą. Wyciągamy dane do zmiennej, dopasowujemy model, na koniec rysujemy wykresy lub eksportujemy wyniki obliczeń.</p>\n<p>Omówimy teraz skrypt który przekształca wyniki pomiarów na parametry modelu.</p>\n<blockquote>\n<p>util/generate_parameters.wl</p>\n</blockquote>\n<pre><code>(*MathematicaScript -script util/generate_parameters.wl*)\n\nNeeds[&quot;DatabaseLink`&quot;]\nconn = OpenSQLConnection[\n  JDBC[&quot;SQLite&quot;, $InitialDirectory &lt;&gt; &quot;/log/log.db&quot;]];\n\nPrint[&quot;Conection with database established...&quot;];\n</code></pre>\n<p>Skrypt zaczyna pracę od połączenia do bazy. Robi to za pomocą dwóch linii kodu. Pierwsza z nich to importowanie paczki. Druga zapisuje do zmiennej <code>conn</code> nowe połączenie realizowane za pomocą interfejsu <code>JDBC</code>. Zmienna <code>$InitialDirectory</code> zwraca lokalizację z której startujemy, a znaki <code>&lt;&gt;</code> są operatorem konkatenacji stringów. W ten sposób <code>JDBC</code> przyjmuje tu tylko dwa argumenty: nazwę silnika bazodanowego i lokalizację pliku z bazą.</p>\n<p>Pierwsze zapytanie do bazy wyciąga listę języków jakich używamy.</p>\n<pre><code>list = Flatten[\n  SQLExecute[conn, &quot;SELECT name FROM log GROUP BY name&quot;]];\n</code></pre>\n<p>Za wykonanie zapytania na połączeniu <code>conn</code> odpowiada <code>SQLExecute</code>. Komenda <code>Flatten</code> służy spłaszczeniu tablicy, która w przeciwnym wypadku była by tablicą tablic. Jest to związane z tym, że jeśli wybieramy więcej niż jeden atrybut to tablica dwuwymiarowa jest bardziej naturalnym sposobem reprezentacji wyniku zapytania. Widać to dobrze na przykładzie kolejnego zapytania, a raczej całej serii zapytań wykonywanych wewnątrz instrukcji <code>Table</code>:</p>\n<pre><code>data = Table[{i,\n  SQLExecute[conn,\n    &quot;SELECT size,time FROM log WHERE name='&quot; &lt;&gt; ToString[i] &lt;&gt;\n        &quot;'&quot;]}, {i, list}];\n\nPrint[&quot;Data extracted from database...&quot;];\n</code></pre>\n<p>Tutaj do zmiennej <code>data</code> zapisujemy tablicę, która iterując po wyciągniętej wcześniej liście języków każdy swój element układa w dwuelementowa tablicę. Pierwszy z nich jest właśnie tą nazwą, drugi jest tablicą par zmiennych <code>size</code> i <code>time</code>, czyli liczb pętli i czasów wykonywania odpowiadających danemu językowi.</p>\n<p>Kolejny &quot;oneliner&quot; odpowiada za modelowanie:</p>\n<pre><code>nlm = NonlinearModelFit[Log[data[[#, 2]]],\n  Log[Exp[a] Exp[x] + b^2], {a, b}, x] &amp; /@ Range[list // Length];\n\nPrint[&quot;Nonlienear models calculated...&quot;];\n</code></pre>\n<p>Pierwsza linijka dopasowuje modele dla wszystkich języków za jednym razem. Rozłożymy ją na czynniki pierwsze.</p>\n<p>Zacznijmy od najbardziej tajemniczych znaczków, czyli składni <code>f[#]&amp;/@{1,2,3}</code> . Znaki <code>a/@b</code> oznaczają mapowanie, czyli zastosowanie operacji <code>a</code> do elementów pierwszego poziomu tablicy <code>b</code>. Znak <code>#</code> oznacza slot na włożenie danych, a <code>&amp;</code> jest znacznikiem informującym, że to co nastąpi później będzie wkładane do slotów. Tak więc <code>f[#]&amp;[a]</code> jest tym samym co <code>f[a]</code>. Ostatecznie <code>f[#]&amp;/@{1,2,3}</code> jest równoważne <code>{f[1],f[2],f[3]}</code>. Wielkość <code>list//Length</code> to długość zmiennej <code>list</code>. W naszym przypadku <code>16</code>. Funkcja <code>Range</code> tworzy tablicę od jedności do swojego argumentu. Dlatego <code>Range[list//Length]</code> będzie tablicą od <code>1</code> do <code>16</code>. Więc te liczby kolejno będziemy wkładać do slotu oznaczonego <code>#</code> w wyrażeniu <code>NonlinearModelFit</code>.</p>\n<p><code>NonlinearModelFit</code> jest funkcją języka <code>Mathematica</code> odpowiadającą za dopasowywanie modelu do danych, oraz zwracanie dodatkowych informacji związanych na przykład z błędami pomiarowymi.</p>\n<p>Jej pierwszym argumentem jest zbiór danych. W naszym przypadku zlogarytmowana lista par czasów i rozmiarów pętli. Działa tu zasada: &quot;logarytm tablicy to tablica logarytmów&quot;.</p>\n<p>Drugi argument to model danych jaki dopasowujemy. U nas <code>Log[Exp[a] Exp[x] + b^2]</code>. Choć na pierwszy rzut oka, tak nie wygląda, jest to prosta <code>Ax+B</code> tylko w zmienionym układzie współrzędnych. Spójrzmy na to tak. Do <code>x</code> i <code>y</code> dopasowywali byśmy prostą <code>y=Ax+B</code>, Jeśli zlogarytmujemy obie strony to mamy <code>log(y)=log(A exp(log(x))+B)</code>, dane, do jakich dopasowujemy to <code>{Log[x], Log[y]}</code>, więc tymczasowo nazywająć <code>log(x)=X</code> i <code>log(y)=Y</code> dostajemy wyrażenie <code>Y = log(A exp(X) + B)</code> dla danych <code>X,Y</code>. Jednak ponieważ nasze <code>A</code> jest bardzo małe, a <code>B</code> zawsze dodatnie, wprowadzamy oznaczenia <code>A=exp(a)</code> oraz <code>B=b^2</code>. Teraz <code>a</code> może mieć naturalne rzędy wielkości - tak lubiane przez metody numeryczne, a na <code>b</code> nie narzucamy żadnych ograniczeń dotyczących znaku - metody numeryczne skaczą ze szczęścia, kiedy widzą takie podstawienia. Od teraz będziemy operować zmiennymi <code>a</code> i <code>b</code> mając na myśli, że <code>A</code> i <code>B</code> możemy z nich łatwo obliczyć.</p>\n<p>Trzeci argument <code>NonlinearModelFit</code> to lista stopni swobody, a czwarty nazwany po prostu <code>x</code> odpowiada naszemu dużemu <code>X</code> czyli logarytmowi z liczby powtórzeń pętli.</p>\n<p>Cały zbiór dopasowanych modeli został zapisany w zmiennej <code>nlm</code>. Czas wydobyć z niego parametry, które chcemy zapisać do pliku. Odpowiada za to kod:</p>\n<pre><code>nameABlist = {list[[#]],\n  Exp[a],\n  b^2,\n  Exp[a]*nlm[[#]][&quot;ParameterErrors&quot;][[1]],\n  Abs[2*b]*nlm[[#]][&quot;ParameterErrors&quot;][[2]]} /. nlm[[#, 1, 2]] &amp; /@\n    Range[Length[list]];\n\nPrint[&quot;Parameters extracted from models...&quot;];\n</code></pre>\n<p>Tworzona przez niego tablica <code>nameABList</code> jest prostokątną macierzą o wymiarach 5 kolumn na 16 wierszy. Ponownie wykorzystujemy mapowanie z przebieganiem po zakresie wskaźników odpowiadających językom <code>/@Range[Length[list]]</code>. Za <code>list[[#]]</code> zostaje wstawiona nazwa języka, dwie kolejne wielkości dzięki znacznikowi <code>/.</code> są podstawiane z modelu <code>nlm</code>. Dwie ostatnie to błędy pomiarowe odpowiednio przeskalowane w związku ze zmianą układu współrzędnych.</p>\n<p>Na samym końcu wysyłamy naszą macierz do pliku:</p>\n<pre><code>Export[$InitialDirectory &lt;&gt; &quot;/config/parameters.csv&quot;,\n  SetPrecision[nameABlist, 10]];\n\nPrint[&quot;Parameters saved to file. Process finished correctly.&quot;];\nExit[];\n</code></pre>\n<h2 id=\"wyniki\">Wyniki</h2>\n<p>Dla każdego języka omówimy wyniki. Zamiast podawać ilość wykonywanych pętli na sekundę, na wykresach prezentujemy jej logarytm <code>a</code>, jako łatwiejszy do porównywania. A zamiast czasu włączania programu odpowiadającemu jednemu wykonaniu pętli jego pierwiastek <code>b</code>. Do wyrysowania wykresów zastosowaliśmy następujący kod z pliku <code>analysisi.nb</code></p>\n<p>Do prezentacji wyników wykorzystamy interfejs zrozumiały dla człowieka, czyli wykresy. Za ich wyświetlenie odpowiada poniższy fragment programu <code>analysis.nb</code>.</p>\n<pre><code>Do[Module[{img, bands},\n  bands[x_] =\n   nlm[[i]][&quot;SinglePredictionBands&quot;, ConfidenceLevel -&gt; .99];\n  img = Show[{ListLogLogPlot[{data[[i, 2]]}, PlotRange -&gt; Full,\n      PlotLabel -&gt; data[[i, 1]], ImageSize -&gt; 800,\n      BaseStyle -&gt; {FontSize -&gt; 15},\n      FrameLabel -&gt; {&quot;$size [number of loops]&quot;, &quot;$time [sec]&quot;},\n      Frame -&gt; True, PlotStyle -&gt; {Lighter[Red]},\n      PlotLegends -&gt;\n       Placed[SwatchLegend[{&quot;Experimental data&quot;},\n         LegendMarkerSize -&gt; {30, 30}], {0.3, 0.85}]],\n     LogLogPlot[{Exp[nlm[[i]][Log[x]]], Exp[bands[Log[x]]]}, {x, 1,\n       10^13}, PlotLegends -&gt;\n       Placed[SwatchLegend[{nlm[[i]][\n           &quot;ParameterConfidenceIntervalTable&quot;]},\n         LegendMarkerSize -&gt; {1, 1}], {0.3, 0.75}]]}];\n  Print[img];\n  Export[&quot;inc_&quot; &lt;&gt; ToString[list[[i]]] &lt;&gt; &quot;.png&quot;, img];\n  ], {i, list // Length}]\n</code></pre>\n<p>Funkcja <code>Do</code> wykonuje swój pierwszy argument iterując po <code>i</code> od <code>1</code> do liczby badanych języków programowania. <code>Module</code> z jednej strony porządkuje kod zbierając go w jedną niepodzielną całość, z drugiej pozwala nie zaśmiecać głównego programu zmiennymi lokalnymi do przechowywania wykresów (<code>img</code>) i linii granicznych (<code>bands</code>). Owe linie graniczne to możliwie najkrótszy i najdłuższy czas wykonywania określonej ilości pętli przy założonym przedziale ufności. Nie wchodząc już w szczegóły, które związane głównie z formatowaniem nie są tak ciekawe: <code>img</code> zawiera wykres. Funkcja <code>Print</code> wyświetla go na ekranie a <code>Export</code> zapisuje do pliku.</p>\n<h3 id=\"bash\">Bash</h3>\n<p>Język powłok <a href=\"https://pl.wikipedia.org/wiki/Bash\">bash</a> powstał w 1987 roku, czyli 4 lata przed powstaniem pierwszego jądra Linuxa. Obecnie jest używany głównie do wykonywania operacji związanych z systemem operacyjnym Linux, mimo, że Linux i Bash mogą istnieć bez siebie. Jest to język interpretowany i z tego względu nie jest zoptymalizowany pod wykonywanie obliczeń. Kod wykonujący puste pętle wygląda tak:</p>\n<pre><code class=\"language-bash\">#! /bin/bash\n\ni=0;\nmax=$1;\n\nwhile [[ $i -le $max ]];\ndo\n\ti=$[i+1];\ndone\n</code></pre>\n<p>A oto wyniki pomiarów czasu:</p>\n<p><a href=\"https://postimg.org/image/6tnjwy8yv/\"><img src=\"https://s23.postimg.org/6tnjwy8yz/inc_inc_bash.png\" alt=\"inc_inc.bash.png\" loading=\"lazy\"></a></p>\n<p>W naszym teście wypadł najsłabiej, jeśli chodzi o ilość wykonywanych pętli na jednostkę czasu, ale spośród wszystkich języków interpretowanych jest pierwszy, jeśli chodzi o czas włączania. Nie ustępuje jednak bardzo pod tym względem językom kompilowanym.</p>\n<h3 id=\"matlab\">Matlab</h3>\n<p><a href=\"https://pl.wikipedia.org/wiki/MATLAB\">Matlab</a> jest językiem zaprojektowanym do obliczeń macierzowych. Jego historia sięga 1980 roku. Początkowo napisany w Fortranie miał ułatwić studentom obliczenia macierzowe, trzy lata później przepisany w <code>c</code> i systematycznie rozbudowywany o nowe funkcjonalności stał się jednym z najpopularniejszych języków stosowanych przez naukowców szczególnie w zastosowaniach związanych z obliczeniami numerycznymi.</p>\n<p><code>Matlab</code> nie ma wygodnego interfejsu konsolowego. Żeby przekazać mu zmienną musieliśmy sklejać kod interpretowany w <code>Matlabie</code> za pomocą <code>basha</code>.</p>\n<pre><code class=\"language-bash\">#!/usr/bin/env bash\n\nread -r -d '' VAR &lt;&lt; EOM\nfor c = 1:$1\n%  disp(c)\nend\nEOM\n\necho &quot;$VAR&quot; | matlab -nodesktop -nosplash 1&gt;/dev/null\n</code></pre>\n<p><a href=\"https://postimg.org/image/dxr64v2ih/\"><img src=\"https://s28.postimg.org/6ujap8x31/inc_inc_m_sh.png\" alt=\"inc_inc.m.sh.png\" loading=\"lazy\"></a></p>\n<p>Jeśli chodzi o szybkość wykonywania jednej pętli to <code>Matlab</code> poradził sobie najlepiej w kategorii języków interpretowanych (z wyjątkiem <code>javy</code>, która jest takim hybrydowym rozwiązaniem). Opłacił to jednak potwornie długim czasem włączania sięgającym 5 sekund. Jest to znacznie dłuższy czas niż zabierany na którąkolwiek z kompilacji. <code>Matlab</code> jest dobry, ale do dużych rzeczy, w przeciwnym wypadku nie opłaca się go włączać, ponieważ przez te 5 sekund <code>bash</code> wykonał by milion pętli, a typowe skryptowe języki do 100 milionów.</p>\n<h3 id=\"mysql\">MySQL</h3>\n<p>Sam <a href=\"https://pl.wikipedia.org/wiki/MySQL\"><code>MySQL</code></a> jest raczej systemem do zarządzania bazą danych niż językiem. Język to <code>SQL</code>, ale ze względu na różnice w implementacjach silników bazodanowych wolałem podkreślić <code>MySQL</code>, niż zostawić <code>SQL</code>. Tak czy inaczej silniki bazodanowe, jak i język zapytań do baz danych nie były tworzone z myślą o inkrementacji zmiennych i sprawdzaniu warunków. Można by powiedzieć, że procedury i instrukcje sterujące to raczej dodatek, który pomaga ograniczyć ilość zapytań niż główna funkcjonalność baz danych. Należy pamiętać, że taka mikro-optymalizacja na tym poziomie nie ma sensu, ponieważ najbardziej kosztowne czasowo operacje znajdują się w selektach i trzymaniu spójności danych przy update/delete/insert.</p>\n<p>Do <code>mysql</code> również nie da się łatwo przekazać parametru z konsoli jako wartości podanej po nazwie programu. Użyliśmy następującego konektora</p>\n<pre><code class=\"language-bash\">#!/usr/bin/env bash\n\nmysql -u root inc -e &quot;CALL inc_loop($1)&quot;;\n</code></pre>\n<p>A procedura <code>inc_loop</code> definiowana była w ten sposób:</p>\n<pre><code class=\"language-sql\">CREATE DATABASE IF NOT EXISTS inc;\nuse inc;\n\nDROP PROCEDURE IF EXISTS inc_loop;\n\nDELIMITER $$\nCREATE PROCEDURE inc_loop(IN n INT)\n BEGIN\n DECLARE _n INT DEFAULT 0;\n\n WHILE _n &lt;= n DO\n SET  _n = _n + 1;\n END WHILE;\n\n END$$\nDELIMITER ;\n</code></pre>\n<p><a href=\"https://postimg.org/image/cwzkd2k4x/\"><img src=\"https://s24.postimg.org/k07fsopkl/inc_inc_sql_sh.png\" alt=\"inc_inc.sql.sh.png\" loading=\"lazy\"></a></p>\n<p>Z tego względu <code>MySQL</code> w tym zestawieniu zajmuje miejsce drugie od końca. Należy jednak przyznać, że prawdziwe wąskie gardło baz danych - czas łączenia uplasował się na umiarkowanie dobrej pozycji pośród języków skryptowych: między perlem a <code>pythonem</code>.</p>\n<h3 id=\"wolfram-languagemathematica\">Wolfram Language - Mathematica</h3>\n<p>Mathematica jest programem. <a href=\"https://en.wikipedia.org/wiki/Wolfram_Language\">Wolfram Language</a> językiem w jakim piszemy w tym programie. Język ten sięga historią roku 1988, został zaprojektowany z myślą o algebrze symbolicznej. Obecnie ma bardzo szerokie możliwości związane z wszelkiego rodzaju obliczeniami. Ustępuje <code>Matlabowi</code> w temacie wydajności przetwarzania macierzy i numeryki, nadrabia wygodą i bardziej intuicyjną reprezentacją danych.</p>\n<p>W porównaniu z dwoma poprzednikami, kod programu <code>inc.wl</code> jest bardzo prosty</p>\n<pre><code>num  = ToExpression[$ScriptCommandLine[[2]]];\nFor[i = 0, i &lt; num, i++];\nExit[];\n</code></pre>\n<p><a href=\"https://postimg.org/image/75u6kbynz/\"><img src=\"https://s27.postimg.org/519tj8x1f/inc_inc_wl.png\" alt=\"inc_inc.wl.png\" loading=\"lazy\"></a></p>\n<p>W tym teście Mathematica poradziła sobie słabo lokując się w kategorii szybkości pętli na 4 miejscu od końca, a w kontekście szybkości włączania na 2 od końca.</p>\n<h3 id=\"c\">C#</h3>\n<p>Język <a href=\"https://pl.wikipedia.org/wiki/C_Sharp\">C#</a> powstał w 2000 i aktualnie jest wciąż rozwijany. Ma w sobie wiele cech języków <code>Object Pascal</code>, <code>Delphi</code>, <code>C++</code> i <code>Java</code>. Do działania wymaga mono, lub innego środowiska uruchomieniowego. Kompiluje się nie do kodu binarnego, ale do kodu pośredniego. Niestety nie udało mi się zoptymalizować jego kompilacji tak jak dla <code>Pascala</code>, <code>C</code>, <code>C++</code> i <code>Fortrana</code>. Jeśli znasz się na tym, proszę o komentarz, lub kontakt w tej sprawie.</p>\n<p>Sam program wygląda rzeczywiście podobnie do swoich pierwowzorów.</p>\n<pre><code class=\"language-c#\">using System;\npublic class Program\n{\n    public static void Main(string[] args)\n    {\n        for (ulong i = 1; i &lt;= UInt64.Parse(args[0]); i++)\n        {}\n    }\n}\n</code></pre>\n<p><a href=\"https://postimg.org/image/zanm37hzt/\"><img src=\"https://s28.postimg.org/wtbuvxy3h/inc_inc_cs.png\" alt=\"inc_inc.cs.png\" loading=\"lazy\"></a></p>\n<p>Szybkość włączania jest umiarkowania, a szybkość pojedynczej pętli plasuje język na umiarkowanie słabej pozycji - 6 od końca.</p>\n<h3 id=\"js\">JS</h3>\n<p><a href=\"https://pl.wikipedia.org/wiki/JavaScript\">JavaScript</a> z pewnością wielu ludziom myli się z Javą. Teraz się to wydaje zabawne, ale mi też się na początku mylił. Nic dziwnego, bo w 1995, kiedy język powstał nazwę wzięto od Javy, żeby JavaScript miał lepszy marketing. Tak naprawdę nie mają ze sobą wiele wspólnego. Obecnie jest to żywy wciąż rozwijany język, który zainspirował i bardzo spopularyzował funkcyjny styl programowania. Za jego sprawą w wielu innych językach pojawiły się tak zwane funkcje lambda, których składnia w ES6 została skrócona, tak, że nazywa się je <a href=\"http://shebang.pl/artykuly/es6-funkcje-strzalkowe/\">strzałkowymi</a>.</p>\n<p>Kod źródłowy jest całkiem przyjemny i wygląda tak:</p>\n<pre><code class=\"language-js\">var max=process.argv[2];\nfor(var i=0;i&lt;=max;i++){}\n</code></pre>\n<p><a href=\"https://postimg.org/image/ixhjof2g7/\"><img src=\"https://s23.postimg.org/fdvlylzqj/inc_inc_js.png\" alt=\"inc_inc.js.png\" loading=\"lazy\"></a></p>\n<p>W przeciwieństwie do <code>C#</code>, <code>JavaScript</code> jest umiarkowanie słaby jeśli chodzi o szybkość włączania, ale z szybkością pętli radzi sobie już lepiej - jak typowy język skryptowy.</p>\n<h3 id=\"python\">Python</h3>\n<p><a href=\"https://pl.wikipedia.org/wiki/Python\">Python</a> pojawił się w roku 1991. Jest językiem ogólnego przeznaczenia, którego głównymi cechami są: sztywne wcięcia a wiec czytelna i klarowna składnia. Jest też dość zwięzły i stanowi bardzo ważną alternatywę dla <code>perla</code>. Jest bardzo popularny w środowisku naukowym.</p>\n<pre><code class=\"language-python\">#!/usr/bin/python\n\nimport sys\n\nmax=int(sys.argv[1]);\n\ncount = 0\nwhile (count &lt; max):\n   count = count + 1\n</code></pre>\n<p>Od razu zaznaczę, że ten kod da się napisać krócej i wykonać szybciej używając pętli <code>for in</code>, ale ma ona zupełnie inną mechanikę działania - tworzy tablicę liczb z podanego zakresu, wrzuca całą tablicę do pamięci i ją przegląda. Więcej o tym piszę na końcu w dziale RAM vs Procesor. Pozbycie się zmiennej max i napisanie</p>\n<pre><code class=\"language-python\">while (count &lt; int(sys.argv[1])):\n</code></pre>\n<p>wydłużyło by czas wykonywania kilkukrotnie.</p>\n<p><a href=\"https://postimg.org/image/ka4ppsf7h/\"><img src=\"https://s30.postimg.org/gdrdtsu81/inc_inc_python.png\" alt=\"inc_inc.python.png\" loading=\"lazy\"></a></p>\n<p>Mimo, że python jest jednym z wolniejszych języków skryptowych, różnice te są na tyle małe, że można uczciwie przyznać, że mieści się dokładnie na środku rankingu. Ilość kodu nie jest przerażająca, a krzywa nauki? Jak dla mnie ciężko mówić o krzywej nauki w przypadku tego języka. Można w nim pisać, nawet go nie umiejąc, po prostu zgadując jak coś powinno być napisane. Jest to bardzo intuicyjny język o rozsądnej wydajności w większości przypadków.</p>\n<h3 id=\"ruby\">Ruby</h3>\n<p><a href=\"https://pl.wikipedia.org/wiki/Ruby_(j%C4%99zyk_programowania)\">Ruby</a> jest stosunkowo młody, jak na język. Pierwsze wydanie ujrzało światło dzienne w 1995. Jest to dynamicznie typowany, obiektowy, interpretowany język popularny głównie w stanach. Jego znaczenie wzrosło po wydaniu frameworku Ruby on Rails - przeznaczonego do tworzenia aplikacji internetowych, ale widziałem Ruby w innych zastosowaniach od analizy danych giełdowych po platformę do blogowania - jekylla.</p>\n<p>W tym języku, nie miałem okazji dużo pisać, ale kod wygląda dość przyjemnie</p>\n<pre><code class=\"language-ruby\">for i in (1 .. ARGV[0].to_i)\nend\n</code></pre>\n<p>Zaskakujące, że ta składnia, wcale nie zamula pamięci RAM nawet przy bardzo dużych tablicach ani nie powoduje problemów jakie w <code>pythonie</code> powoduje nie utworzenie zmiennej <code>max</code>. Składnia jest więc znacznie lepsza.</p>\n<p><a href=\"https://postimg.org/image/dwvu8gvrd/\"><img src=\"https://s28.postimg.org/iirygthal/inc_inc_rb.png\" alt=\"inc_inc.rb.png\" loading=\"lazy\"></a></p>\n<p>Natomiast wyniki są średnie. Przy czym ruby raczej włącza się wolniej a działa szybciej na tle innych języków interpretowanych.</p>\n<h3 id=\"perl\">Perl</h3>\n<p><a href=\"https://pl.wikipedia.org/wiki/Perl\">Perl</a> pochodzi miej więcej z tych czasów co bash (1987). Jest to język o bardzo gęstej składni. Programista w nim traktowany jest raczej jak artysta niż rzemieślnik. Język pozwala na tworzenie zarówno czystego i krótkiego kodu, jak i nieczytelnej plątaniny znaków. W wielu rozwiązaniach został wyparty przez Pythona przez to, że jest trudniejszy w nauce oraz paradoksalnie bardziej elastyczny.</p>\n<p>Jego kod źródłowy stanowi świetnym przykładem ten sam program, można napisać tak:</p>\n<pre><code class=\"language-perl\">#!/usr/bin/perl\n\nfor(my $i=0;$i&lt;=$ARGV[0];$i++){}\n</code></pre>\n<p>a można tak:</p>\n<pre><code class=\"language-perl\">for(;$_&lt;=$ARGV[0];$_++){}\n</code></pre>\n<p>Działanie będzie identyczne.</p>\n<p><a href=\"https://postimg.org/image/engw1t32v/\"><img src=\"https://s23.postimg.org/6uq89tx3v/inc_inc_perl.png\" alt=\"inc_inc.perl.png\" loading=\"lazy\"></a></p>\n<p>Wyniki nie są niespodzianką. Włączanie się jest najszybsze z języków skryptowych. Czas wykonywania pojedynczej pętli umiarkowany.</p>\n<h3 id=\"r\">R</h3>\n<p><a href=\"https://pl.wikipedia.org/wiki/R_(j%C4%99zyk_programowania)\">R</a> jest środowiskiem do obliczeń statystycznych. W całym tym zestawieniu sporo jest języków powiązanych z matematyką, bo sam się nią lubię zajmować. R szczególnie często występuje w kontekście bioinformatyki.</p>\n<p>Cechy charakterystyczne to: strzałki do przypisywania wartości i podobnie jak w Matlabie ogromna łatwość operowania na macierzach i wektorach.</p>\n<pre><code class=\"language-r\">args &lt;- commandArgs(trailingOnly = TRUE)\n\nx &lt;- 0\nwhile(x &lt; as.numeric(args)) {\n    x &lt;- x+1;\n}\n</code></pre>\n<p><a href=\"https://postimg.org/image/izmjh2kzn/\"><img src=\"https://s29.postimg.org/fsrzxg0jr/inc_inc_r.png\" alt=\"inc_inc.r.png\" loading=\"lazy\"></a></p>\n<p>Podobnie jak Wolfram Language, tak i tan wysoko poziomowy język o specjalizacji sprofilowanej na testowanie hipotez statystycznych i prowadzenie badań poradził sobie słabo w tym teście. Zarówno pod względem szybkości pętli jak i uruchamiania zajął trzecią pozycję od końca.</p>\n<h3 id=\"php\">Php</h3>\n<p>Język <a href=\"https://pl.wikipedia.org/wiki/PHP\">Php</a> pojawił się w roku 1995, jako język do generowania stron internetowych. I choć można pisać backend webowy w innych językach, trzeba przyznać, że PHP radzi sobie z tym zadaniem całkiem dobrze. Oczywiście, wielkim serwisom opłaca się kompilowanie backendu, ale w absolutnej większości zastosowań PHP stanowi świetny kompromis między wygodą języka interpretowanego a wydajnością.</p>\n<p>Kod php wygląda standardowo i intuicyjne</p>\n<pre><code class=\"language-php\">&lt;?php\n\n$max = (int)$argv[1];\n\nfor($i=0; $i&lt;$max; $i++);\n</code></pre>\n<p><a href=\"https://postimg.org/image/ywsw96k7d/\"><img src=\"https://s28.postimg.org/svv7c3xl9/inc_inc_php.png\" alt=\"inc_inc.php.png\" loading=\"lazy\"></a></p>\n<p>Jego wydajność w tym teście oceniam bardzo pozytywnie. Szybkość włączania była średnia, a w kategorii szybkości wykonania jednej pętli poradził sobie jako jeden z najlepszych języków interpretowanych. Dał się wyprzedzić jedynie Matlabowi.</p>\n<h3 id=\"fortran-95\">Fortran 95</h3>\n<p><a href=\"https://pl.wikipedia.org/wiki/Fortran\">Fortan</a> jest językiem z czasów tak wczesnych, że aż ciężko sobie wyobrazić, jak wtedy programowano (1957 rok), ale były to jeszcze czasy kart perforowanych, bo pierwszy komputer z klawiaturą powstał dopiero w 1960. Dzięki bogatemu zestawowi bibliotek do obliczeń macierzowych, bardzo dobrze zoptymalizowanemu kompilatorowi, wielo-platformowości i dobremu wsparciu obliczeń równoległych Fortran jest wciąż szeroko używany w środowisku inżynierskim i naukowym, w szczególności tam, gdzie numeryka jest szczególnie ciężka - w fizyce, symulacjach, modelowaniu ośrodków ciągłych.</p>\n<p>Ze składni języka widać, że typowanie jest statyczne, rzutowanie wykonywane za pomocą instrukcji <code>read</code>, natomiast sama pętla ma już przyjemną składnię. Subiektywnie kojarzy mi się z językiem ruby.</p>\n<pre><code class=\"language-fortran\">PROGRAM loop_argument_times\n  INTEGER(16) :: i, range\n  CHARACTER(len=32) :: arg\n\n  CALL get_command_argument(1, arg)\n  read( arg, '(i16)' ) range\n\n  do  i = 1, range\n  end do\n\nEND PROGRAM\n</code></pre>\n<p><a href=\"https://postimg.org/image/4u9m2pr1b/\"><img src=\"https://s27.postimg.org/zbpgu9eeb/inc_inc_f95.png\" alt=\"inc_inc.f95.png\" loading=\"lazy\"></a></p>\n<p>Wyniki <code>fortrana</code> zasługują na wyjątkowe uznanie. W szybkości wykonywania pętli zajął pierwsze miejsce, a szybkości włączania czwarte. Warto wspomnieć, że jego twórcy dołożyli bardzo dużo pracy do optymalizacji kompilatora ponieważ obawiali się, że w przeciwnym wypadku nikt nie będzie go używać i wszyscy będą pisać w asemblerze.</p>\n<h3 id=\"c\">C++</h3>\n<p><a href=\"https://pl.wikipedia.org/wiki/C%2B%2B\">C++</a> pojawił się w 1983 jako rozszerzenie języka <code>c</code>  o obiektowe mechanizmy abstrakcji danych i silną statyczną kontrolę typów. W latach 90 stał się najbardziej popularnym językiem ogólnego przeznaczenia. Jest to pierwszy język jakiego się uczyłem, w gimnazjum, kiedy po podłączeniu internetu w domu, z przekory chciałem pokazać rodzicom, że gry sieciowe nie zniszczą mi dzieciństwa. Później wiele razy <code>c++</code> zaspokajał moją ciekawość dotyczącą symulowania układów fizycznych i do czasu poznania języka <code>Mathematica</code> był głównym narzędziem do robienia numeryki.</p>\n<pre><code class=\"language-cpp\">#include &lt;cstdlib&gt;\nint main(int argc, char *argv[])\n{\n\tunsigned long long int i;\n\tunsigned long long int max = strtoul(argv[1], NULL, 0);\n\tfor(i=0; i&lt;max; i++);\n\treturn 0;\n}\n</code></pre>\n<p><a href=\"https://postimg.org/image/n5cxrid5p/\"><img src=\"https://s30.postimg.org/grnuo989t/inc_inc_cpp.png\" alt=\"inc_inc.cpp.png\" loading=\"lazy\"></a></p>\n<p>Jak przystało na język kompilowany ogólnego przeznaczenie <code>c++</code> staje na podium w obu rankingach. Uruchamia się jako trzeci, wykonuje pętle jako drugi najszybszy język w zestawieniu.</p>\n<h3 id=\"c\">C</h3>\n<p>Historia języka <a href=\"https://pl.wikipedia.org/wiki/C_(j%C4%99zyk_programowania)\"><code>C</code></a> sięga roku 1972, wywodzi się on z języka <a href=\"https://pl.wikipedia.org/wiki/B_(j%C4%99zyk_programowania)\"><code>B</code></a> współtworzonego przez twórcę <code>C</code> - Dennisa Ritchiego. <code>B</code> natomiast wywodzi się z <a href=\"https://pl.wikipedia.org/wiki/BCPL\"><code>BCPL</code></a> - zapomnianego już języka, który jednak wywarł ogromny wpływ na to jak dzisiaj kodujemy. To długa i ciekawa historia, ale, żeby dygresja nie poszła zbyt daleko wrócę do <code>C</code>. Został zaprojektowany do programowania systemów operacyjnych i zadań dzisiaj uważanych za niskopoziomowe.</p>\n<p><code>C++</code> różni się od <code>C</code> głównie obiektowością, więc nie zobaczymy tego na przykładzie kodu źródłowego, gdzie jedyną zmianą jest użyta biblioteka.</p>\n<pre><code class=\"language-c\">#include &lt;stdlib.h&gt;\n\nint main(int argc, char *argv[])\n{\n\tunsigned long long int i;\n\tunsigned long long int max = strtoul(argv[1], NULL, 0);\n\n\tfor(i=0; i&lt;max; i++);\n\treturn 0;\n}\n</code></pre>\n<p><a href=\"https://postimg.org/image/71q65aglt/\"><img src=\"https://s24.postimg.org/71q65aglx/inc_inc_c.png\" alt=\"inc_inc.c.png\" loading=\"lazy\"></a></p>\n<p>Wyniki testu pokazują, że <code>C</code> jest na trzecim miejscu pod względem szybkości pętli ustępując <code>C++</code> tylko o 1%, ale zajmuje pierwsze miejsca w klasyfikacji szybkości uruchamiania wyprzedzając <code>Pascala</code> o około 1‰.</p>\n<h3 id=\"pascal\">Pascal</h3>\n<p>O wilku mowa. To znaczy o <a href=\"https://pl.wikipedia.org/wiki/Pascal_(j%C4%99zyk_programowania)\"><code>Pascalu</code></a> - języku, który powstał w 1970 roku i w przeciwieństwie do <code>C</code>, nie udostępniał mechanizmów niskopoziomowych, lecz został zaprojektowany do tworzenia strukturalnych aplikacji.</p>\n<p>Mi osobiście z Pascalem kojarzy się przeciążanie operatorów, bo mimo, że jest to możliwe również w innych językach, pierwszy raz w życiu przeciążałem operator dodawania i mnożenia macieży właśnie w Pascalu.</p>\n<p>Sam kod przypomina mi nieco fortrana. Kiedy się go uczyliśmy, profesor który objaśniał jego składnię mówił, że nie będziemy go używać, ale będziemy programować w innych językach tak jak w nim. Na przykładzie tego kodu widać, że <code>Pascal</code> wymaga definiowania zmiennych przed rozpoczęciem wykonywania logiki. Przyznaję, faktycznie tak piszę dziś we wszystkich języakch skryptowych, jeśli chcę używać zmiennych globalnych.</p>\n<pre><code class=\"language-pascal\">program Project1;\n\nUses sysutils;\n\n{$mode objfpc}\n\nvar\n  I,r: QWord;\nbegin\n\n  r:=StrToQWord(ParamStr(1));\n\n  for I := 1 to r do\nend.\n</code></pre>\n<p><a href=\"https://postimg.org/image/n78yprgfb/\"><img src=\"https://s23.postimg.org/kd5tcbe97/inc_inc_p.png\" alt=\"inc_inc.p.png\" loading=\"lazy\"></a></p>\n<p>Pascal zajął piąte miejsce w szybkości wykonywania pętli i drugie w kategorii szbykości startowania programu.</p>\n<h3 id=\"java\">Java</h3>\n<p><a href=\"https://pl.wikipedia.org/wiki/Java\"><code>Java</code></a> jest młodym językiem na tle kilku ostatnio omawianych. Powstała w 1995. Swój sukces zawdzięcza bardzo bardzo dobrej obsłudze błędów i wyjątków oraz niezależności od systemu na jakim uruchamiamy platformę java. Korporacje kochają ją za to, że można w niej pisać bezpieczne, dobrze zabezpieczone aplikacje w rozproszonej strukturze sieciowej bez szczególnego dbania o systemy operacyjne poszczególnych maszyn.</p>\n<pre><code class=\"language-java\">public class inc {\n    public static void main(String[] args) {\n\tlong max=Long.parseLong(args[0]);\n\tfor (long i = max; i &gt;= 0; i--) {\n\t}\n    }\n}\n</code></pre>\n<p><a href=\"https://postimg.org/image/6gjud1edt/\"><img src=\"https://s24.postimg.org/5e9nuhvkl/inc_inc_java.png\" alt=\"inc_inc.java.png\" loading=\"lazy\"></a></p>\n<p>Java zajęła czwarte miejsce pod względem szybkości pętli ustępując liderowi jedynie o 1-2%, ale jej włączanie trwało około 40 razy dłużej niż programów z czołówki rankingu. W kategorii szybkości włączania java była czwarta od końca.</p>\n<h3 id=\"podsumowanie\">Podsumowanie</h3>\n<p>Na koniec załączam wykres porównujący czas trwania pojedyńczej pętli w każdym języku wykonany za w pliku <code>analysis.nb</code></p>\n<pre><code>BarChart[Log[SortBy[nameABlist, #[[2]] &amp;][[All, 2]]],\n ChartStyle -&gt; &quot;DarkRainbow&quot;,\n ChartLegends -&gt; SortBy[nameABlist, #[[2]] &amp;][[All, 1]],\n AxesLabel -&gt; &quot;Log[a]&quot;]\n</code></pre>\n<p><a href=\"https://postimg.org/image/4t81fwugb/\"><img src=\"https://s17.postimg.org/fst8rikvj/speed.png\" alt=\"speed.png\" loading=\"lazy\"></a></p>\n<p>Wykres ma skalę logarytmiczną, im niższa wartość tym lepiej.</p>\n<p>Jeśli jesteś ciekaw dokładnych wyników poniżej prezentuję tabelę.</p>\n<table>\n<thead>\n<tr>\n<th>language</th>\n<th>one loop time [s]</th>\n<th>loop time error [s]</th>\n<th>launch time [s]</th>\n<th>launch time error [s]</th>\n<th>launch to loop ratio [s]</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>inc.f95</td>\n<td>3.50468*10^(-10)</td>\n<td>1.07954*10^(-12)</td>\n<td>1.72753*10^(-3)</td>\n<td>5.04969*10^(-6)</td>\n<td>4.92921*10^(6)</td>\n</tr>\n<tr>\n<td>inc.cpp</td>\n<td>3.5061*10^(-10)</td>\n<td>1.41184*10^(-12)</td>\n<td>1.38989*10^(-3)</td>\n<td>5.77246*10^(-6)</td>\n<td>3.9642*10^(6)</td>\n</tr>\n<tr>\n<td>inc.c</td>\n<td>3.53343*10^(-10)</td>\n<td>1.01268*10^(-12)</td>\n<td>1.37686*10^(-3)</td>\n<td>3.62949*10^(-6)</td>\n<td>3.89666*10^(6)</td>\n</tr>\n<tr>\n<td>inc.java</td>\n<td>3.55209*10^(-10)</td>\n<td>1.25794*10^(-12)</td>\n<td>5.70852*10^(-2)</td>\n<td>6.74846*10^(-5)</td>\n<td>1.60709*10^(8)</td>\n</tr>\n<tr>\n<td>inc.p</td>\n<td>3.69329*10^(-10)</td>\n<td>2.36513*10^(-12)</td>\n<td>1.37772*10^(-3)</td>\n<td>4.0445*10^(-6)</td>\n<td>3.73033*10^(6)</td>\n</tr>\n<tr>\n<td>inc.m.sh</td>\n<td>2.69198*10^(-9)</td>\n<td>2.10845*10^(-11)</td>\n<td>5.28642</td>\n<td>4.69114*10^(-2)</td>\n<td>1.96377*10^(9)</td>\n</tr>\n<tr>\n<td>inc.php</td>\n<td>8.89544*10^(-9)</td>\n<td>2.62779*10^(-11)</td>\n<td>2.13014*10^(-2)</td>\n<td>3.08575*10^(-5)</td>\n<td>2.39464*10^(6)</td>\n</tr>\n<tr>\n<td>inc.rb</td>\n<td>3.64662*10^(-8)</td>\n<td>1.2021*10^(-10)</td>\n<td>3.40208*10^(-2)</td>\n<td>4.46364*10^(-5)</td>\n<td>9.32938*10^(5)</td>\n</tr>\n<tr>\n<td>inc.perl</td>\n<td>4.24243*10^(-8)</td>\n<td>1.23231*10^(-10)</td>\n<td>2.15686*10^(-3)</td>\n<td>4.64159*10^(-6)</td>\n<td>5.08403*10^(4)</td>\n</tr>\n<tr>\n<td>inc.js</td>\n<td>6.14158*10^(-8)</td>\n<td>2.27239*10^(-10)</td>\n<td>4.14627*10^(-2)</td>\n<td>6.47284*10^(-5)</td>\n<td>6.75115*10^(5)</td>\n</tr>\n<tr>\n<td>inc.python</td>\n<td>6.29119*10^(-8)</td>\n<td>1.69606*10^(-10)</td>\n<td>1.02831*10^(-2)</td>\n<td>1.5976*10^(-5)</td>\n<td>1.63452*10^(5)</td>\n</tr>\n<tr>\n<td>inc.cs</td>\n<td>1.59136*10^(-7)</td>\n<td>5.1884*10^(-10)</td>\n<td>1.06194*10^(-2)</td>\n<td>2.41509*10^(-5)</td>\n<td>6.67321*10^(4)</td>\n</tr>\n<tr>\n<td>inc.wl</td>\n<td>4.87908*10^(-7)</td>\n<td>1.24762*10^(-9)</td>\n<td>1.91462*10^(-1)</td>\n<td>2.2833*10^(-4)</td>\n<td>3.92415*10^(5)</td>\n</tr>\n<tr>\n<td>inc.r</td>\n<td>7.28671*10^(-7)</td>\n<td>2.11159*10^(-9)</td>\n<td>1.20264*10^(-1)</td>\n<td>1.79633*10^(-4)</td>\n<td>1.65045*10^(5)</td>\n</tr>\n<tr>\n<td>inc.sql.sh</td>\n<td>2.24287*10^(-6)</td>\n<td>4.28608*10^(-9)</td>\n<td>5.33614*10^(-3)</td>\n<td>1.34152*10^(-5)</td>\n<td>2.37916*10^(3)</td>\n</tr>\n<tr>\n<td>inc.bash</td>\n<td>4.23198*10^(-6)</td>\n<td>5.03612*10^(-9)</td>\n<td>1.8443*10^(-3)</td>\n<td>4.70927*10^(-6)</td>\n<td>4.35801*10^(2)</td>\n</tr>\n</tbody>\n</table>\n<p>Analogicznie dla czasów włączania programów rysujemy drugi wykres</p>\n<pre><code>BarChart[Log[SortBy[nameABlist, #[[3]] &amp;][[All, 3]]],\n ChartStyle -&gt; &quot;DarkRainbow&quot;,\n ChartLegends -&gt; SortBy[nameABlist, #[[3]] &amp;][[All, 1]],\n AxesLabel -&gt; &quot;Log[b]&quot;]\n</code></pre>\n<p><a href=\"https://postimg.org/image/ll9o87qxr/\"><img src=\"https://s27.postimg.org/5zsco9ezn/speed2.png\" alt=\"speed2.png\" loading=\"lazy\"></a></p>\n<p>Tutaj też najlepsze wartości to najniższe. Wartość zerowa oznacza czas włączania równy 1 sekundzie.</p>\n<p>Poniżej ta sama tabela co poprzednio, ale posortowana po czasach włączania programu:</p>\n<table>\n<thead>\n<tr>\n<th>language</th>\n<th>one loop time [s]</th>\n<th>loop time error [s]</th>\n<th>launch time [s]</th>\n<th>launch time error [s]</th>\n<th>launch to loop ratio [s]</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>inc.c</td>\n<td>3.53343*10^(-10)</td>\n<td>1.01268*10^(-12)</td>\n<td>1.37686*10^(-3)</td>\n<td>3.62949*10^(-6)</td>\n<td>3.89666*10^(6)</td>\n</tr>\n<tr>\n<td>inc.p</td>\n<td>3.69329*10^(-10)</td>\n<td>2.36513*10^(-12)</td>\n<td>1.37772*10^(-3)</td>\n<td>4.0445*10^(-6)</td>\n<td>3.73033*10^(6)</td>\n</tr>\n<tr>\n<td>inc.cpp</td>\n<td>3.5061*10^(-10)</td>\n<td>1.41184*10^(-12)</td>\n<td>1.38989*10^(-3)</td>\n<td>5.77246*10^(-6)</td>\n<td>3.9642*10^(6)</td>\n</tr>\n<tr>\n<td>inc.f95</td>\n<td>3.50468*10^(-10)</td>\n<td>1.07954*10^(-12)</td>\n<td>1.72753*10^(-3)</td>\n<td>5.04969*10^(-6)</td>\n<td>4.92921*10^(6)</td>\n</tr>\n<tr>\n<td>inc.bash</td>\n<td>4.23198*10^(-6)</td>\n<td>5.03612*10^(-9)</td>\n<td>1.8443*10^(-3)</td>\n<td>4.70927*10^(-6)</td>\n<td>4.35801*10^(2)</td>\n</tr>\n<tr>\n<td>inc.perl</td>\n<td>4.24243*10^(-8)</td>\n<td>1.23231*10^(-10)</td>\n<td>2.15686*10^(-3)</td>\n<td>4.64159*10^(-6)</td>\n<td>5.08403*10^(4)</td>\n</tr>\n<tr>\n<td>inc.sql.sh</td>\n<td>2.24287*10^(-6)</td>\n<td>4.28608*10^(-9)</td>\n<td>5.33614*10^(-3)</td>\n<td>1.34152*10^(-5)</td>\n<td>2.37916*10^(3)</td>\n</tr>\n<tr>\n<td>inc.python</td>\n<td>6.29119*10^(-8)</td>\n<td>1.69606*10^(-10)</td>\n<td>1.02831*10^(-2)</td>\n<td>1.5976*10^(-5)</td>\n<td>1.63452*10^(5)</td>\n</tr>\n<tr>\n<td>inc.cs</td>\n<td>1.59136*10^(-7)</td>\n<td>5.1884*10^(-10)</td>\n<td>1.06194*10^(-2)</td>\n<td>2.41509*10^(-5)</td>\n<td>6.67321*10^(4)</td>\n</tr>\n<tr>\n<td>inc.php</td>\n<td>8.89544*10^(-9)</td>\n<td>2.62779*10^(-11)</td>\n<td>2.13014*10^(-2)</td>\n<td>3.08575*10^(-5)</td>\n<td>2.39464*10^(6)</td>\n</tr>\n<tr>\n<td>inc.rb</td>\n<td>3.64662*10^(-8)</td>\n<td>1.2021*10^(-10)</td>\n<td>3.40208*10^(-2)</td>\n<td>4.46364*10^(-5)</td>\n<td>9.32938*10^(5)</td>\n</tr>\n<tr>\n<td>inc.js</td>\n<td>6.14158*10^(-8)</td>\n<td>2.27239*10^(-10)</td>\n<td>4.14627*10^(-2)</td>\n<td>6.47284*10^(-5)</td>\n<td>6.75115*10^(5)</td>\n</tr>\n<tr>\n<td>inc.java</td>\n<td>3.55209*10^(-10)</td>\n<td>1.25794*10^(-12)</td>\n<td>5.70852*10^(-2)</td>\n<td>6.74846*10^(-5)</td>\n<td>1.60709*10^(8)</td>\n</tr>\n<tr>\n<td>inc.r</td>\n<td>7.28671*10^(-7)</td>\n<td>2.11159*10^(-9)</td>\n<td>1.20264*10^(-1)</td>\n<td>1.79633*10^(-4)</td>\n<td>1.65045*10^(5)</td>\n</tr>\n<tr>\n<td>inc.wl</td>\n<td>4.87908*10^(-7)</td>\n<td>1.24762*10^(-9)</td>\n<td>1.91462*10^(-1)</td>\n<td>2.2833*10^(-4)</td>\n<td>3.92415*10^(5)</td>\n</tr>\n<tr>\n<td>inc.m.sh</td>\n<td>2.69198*10^(-9)</td>\n<td>2.10845*10^(-11)</td>\n<td>5.28642</td>\n<td>4.69114*10^(-2)</td>\n<td>1.96377*10^(9)</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"ciekawostki\">Ciekawostki</h2>\n<p>Podczas prowadzenia niektórych testów zdarzało się, że zmiany w kodzie, czy sposobie kompilacji bardzo istotnie wpłynęły na wyniki, mimo, że teoretycznie, każdy program miał robić to samo: puste pętle.</p>\n<p>Pierwszy przykład to zmiana sposobu przebiegania pętli</p>\n<h3 id=\"ram-vs-procesor\">RAM vs Procesor</h3>\n<p>Mamy dwie możliwości przebiegania po zakresie od 1 do n. Pierwsza to zacząć od 1 i zwiększać ją o jeden co chwilę sprawdzając czy doszliśmy już do n, czy nie. Drugi, to stworzyć tablicę od 1 do n, załadować ją do pamięci RAM i wykonać ciało pętli dla każdej z tych liczb z pamięci.</p>\n<p>Pierwsza metoda, bardziej konserwatywna jest typową konstrukcją pętli, jaką chciałem testować. Jednak, ta druga, okazuje się być bardziej wydajna dla rozmiarów tablic, które mieszczą się nam w pamięci operacyjnej. Prezentuję na przykładzie języka <code>R</code>, jak zmiana sposobu wykonywania pętli wpłynęła na szybkość jej wykonywania.</p>\n<p>Oto wycinek <code>git diff</code> pokazujący, jak zmienił się kod źródłowy:</p>\n<p><a href=\"https://postimg.org/image/rffk61izj/\"><img src=\"https://s27.postimg.org/jzgak8vab/image.png\" alt=\"r.png\" loading=\"lazy\"></a></p>\n<p>Widzimy, że zamieniliśmy pętlę ładującą wszystko do RAM, na iterującą co jeden ze sprawdzaniem warunku co krok. Poniżej dodaję kod do wykonania stosownego wykresu:</p>\n<pre><code>gitr = SQLExecute[conn,\n   &quot;SELECT git FROM log WHERE name='inc.r' GROUP BY git&quot;];\ndr = SQLExecute[conn,\n     &quot;SELECT size,time FROM log WHERE name='inc.r' AND git='&quot; &lt;&gt;\n      ToString[#] &lt;&gt; &quot;'&quot;] &amp; /@ Flatten[gitr];\nListLogLogPlot[{Flatten[dr[[#]] &amp; /@ Range[4], 1], dr[[5]]},\n  PlotRange -&gt; Full,\n  PlotLabel -&gt; &quot;Differencies in loop time for inc.r&quot;,\n  BaseStyle -&gt; {FontSize -&gt; 14}, ImageSize -&gt; 800,\n  PlotLegends -&gt;\n   Placed[SwatchLegend[{&quot;while loop&quot;, &quot;for in loop&quot;},\n     LegendMarkerSize -&gt; {30, 30}], {0.3, 0.75}]]\n</code></pre>\n<p><a href=\"https://postimg.org/image/hvakxcp0n/\"><img src=\"https://s23.postimg.org/9d14t0ii3/diff_loop.png\" alt=\"diff_loop.png\" loading=\"lazy\"></a></p>\n<p>Widzimy tutaj ogromną przewagę pętli <code>For in</code>. Kiedy spojrzymy na tabelę:</p>\n<p><a href=\"https://postimg.org/image/5op4nf84x/\"><img src=\"https://s24.postimg.org/73qpc5985/loop_type.png\" alt=\"loop_type.png\" loading=\"lazy\"></a></p>\n<p>Okazuje się być ona 22 krotna. To znaczy: w języku <code>R</code>, jeśli starczy nam pamięci RAM, to pusta pętla <code>for in</code> wykona się 22 razy szybciej niż pętla <code>while</code>. Podobne jakościowo rezultaty dostajemy w języku <code>python</code>, a intuicja podpowiada, że należy ten wniosek rozszerzyć na inne języki, w których istnieją konstrukcję pętli, które najpierw ładują zakres do RAM, a potem po nim przebiegają.</p>\n<p>Ostatecznie, żeby wyrównać szanse, w końcowej wersji wykorzystałem pętlę iterującą.</p>\n<h3 id=\"optymalizacja-kompilacji\">Optymalizacja kompilacji</h3>\n<p>Ktoś przyzwyczajony do wysokopoziomowych języków, szczególnie interpretowanych, mógł by pomyśleć: &quot;kompilacje jak kompilacje, nic ciekawego&quot;. Okazuje się jednak, że sposób w jaki kompilujemy program może drastycznie zmienić jego wydajność.</p>\n<h4 id=\"pascal\">Pascal</h4>\n<p>Przyjrzymy się uważniej linijce programu <code>inc.bash</code> zawierającej kompilację pascala.</p>\n<pre><code class=\"language-bash\">fpc -O2 inc/inc.p -o&quot;$TMP/p&quot; -Tlinux &amp;&gt;/dev/null\n</code></pre>\n<p>Znajduje się tu flaga <code>-O2</code>, która sporo zmienia. Włącza ona analizator przepływu danych asemblera. On z kolei umożliwia procedurze eliminacji wspólnych pod-wyrażeń, na usunięcie niepotrzebnych przeładowań rejestru wartościami, które już zawierał. Więcej o falgach optymalizujących kompilację Pascala można przeczytać w <a href=\"http://www.math.uni-leipzig.de/pool/tuts/FreePascal/prog/node12.html\">dokumentacji</a>.</p>\n<p>Wpływ tej flagi można zobaczyć na tym wykresie:</p>\n<p><a href=\"https://postimg.org/image/690frqi19/\"><img src=\"https://s30.postimg.org/h8ln3c8gh/compilation.png\" alt=\"compilation.png\" loading=\"lazy\"></a></p>\n<p>A liczbowe wyniki analizy w tabeli poniżej</p>\n<p><a href=\"https://postimg.org/image/gkdnzppzj/\"><img src=\"https://s27.postimg.org/ajfz2n3df/compilation.png\" alt=\"compilation.png\" loading=\"lazy\"></a></p>\n<p>Można z niej wyczytać, że tylko dzięki usunięciu niepotrzebnych przeładowań rejestru program przyśpieszył 5.6 raza. Inaczej ujmując - trzy znaki w komendzie kompilacyjnej <code>-O2</code> przyśpieszyły program kilkukrotnie.</p>\n<h4 id=\"c\">C++</h4>\n<p>W przypadku <code>c++</code> sytuacja jest nawet bardziej złożona. Podobnie jak w Pascalu mamy do wyboru różne flagi mające różne zastosowania. Ostatecznie zdecydowaliśmy się, że wydajność <code>c++</code> najlepiej odda zastosowanie <code>-O1</code>.</p>\n<pre><code class=\"language-bash\">g++ -O1 -o &quot;$TMP/cpp&quot; 'inc/inc.cpp';\n</code></pre>\n<p>Z <a href=\"https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html\">dokumentacji</a> kompilatora wynika, że dzięki niej kompilator próbuje zredukować wielkość kodu i czas wykonywania, ale nie stosuje tych optymalizacji, które mogły by zająć więcej czasu.</p>\n<p>Było to dla mnie dużym zaskoczeniem, ale kiedy stosowałem głębszą optymalizację, to znaczy flagi <code>-O2</code>, <code>-O3</code> i <code>-Ofast</code>, okazywało się, że pętla jest całkowicie pomijana. Czas wykonywania programu spadał do rzędu tysięcznych, czasem setnych sekundy, a więc całkowicie zlewał się z szumem i był niezależny od parametru, jaki wstawiałem. Myślałem, że sytuację popraw wykorzystanie zmiennych zapisywanych, nie na 8 bajtach, tylko na 16. Okazało się, że pętle po zmiennych typu <code>uint128_t</code> z biblioteki <code>boost/multiprecision/cpp_int.hpp</code> również są pomijane. Dopiero po użyciu zmiennych zapisywanych na 32 bajtach kompilator nie radził sobie z wycięciem pustej pętli z kodu programu. Jednak taki test był dla <code>c++</code> dość nieuczciwy, bo żaden inny język nie dochodził nigdy do takich zakresów. Architektura procesora w moim laptopie (x86_64) świetnie nadaje się do liczb 8 bajtowych - 64bitowych. Używanie liczb 256 bitowych nawet przy najwyższym stopniu optymalizacji kompilacji nie dawało tak dobrych efektów jak <code>-O1</code> dla liczby 64 bitowej (unsigned long long int).</p>\n<p>Dla porównania wyników jakie dała flaga <code>-O1</code> oraz jej brak załączam wykres</p>\n<p><a href=\"https://postimg.org/image/i9e2gvq5z/\"><img src=\"https://s23.postimg.org/r4ewreeyj/cpp_optimization.png\" alt=\"cpp_optimization.png\" loading=\"lazy\"></a></p>\n<p>Oraz tabelę</p>\n<table>\n<thead>\n<tr>\n<th>language and parametes</th>\n<th>one loop time [s]</th>\n<th>loop time error [s]</th>\n<th>launch time [s]</th>\n<th>launch time error [s]</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>c++ -O1 optimization</td>\n<td>3.50722*10^(-10)</td>\n<td>1.43966*10^(-12)</td>\n<td>1.38984*10^(-3)</td>\n<td>5.808*10^(-6)</td>\n</tr>\n<tr>\n<td>c++ no optimization</td>\n<td>2.54525*10^(-9)</td>\n<td>9.24271*10^(-12)</td>\n<td>1.30566*10^(-3)</td>\n<td>2.83328*10^(-6)</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"fortran\">Fortran</h4>\n<p>Tutaj też flaga optymalizująca znacznie wpływa na wyniki. Podobnie jak wcześniej, najlepiej oddaje się szybkość pustych pętli dzięki fladze <code>-O1</code>.</p>\n<p><a href=\"https://postimg.org/image/q7l6502r7/\"><img src=\"https://s29.postimg.org/dg6zyhszb/f_optimization.png\" alt=\"f_optimization.png\" loading=\"lazy\"></a></p>\n<table>\n<thead>\n<tr>\n<th>language</th>\n<th>one loop time [s]</th>\n<th>loop time error [s]</th>\n<th>launch time [s]</th>\n<th>launch time error [s]</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>f -O1 optimization</td>\n<td>3.50474*10^(-10)</td>\n<td>1.0804*10^(-12)</td>\n<td>1.72753*10^(-3)</td>\n<td>5.05088*10^(-6)</td>\n</tr>\n<tr>\n<td>f no optimization</td>\n<td>3.07201*10^(-9)</td>\n<td>1.12286*10^(-11)</td>\n<td>1.63708*10^(-3)</td>\n<td>3.55385*10^(-6)</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"spos%C3%B3b-pomiaru-czasu\">Sposób pomiaru czasu</h3>\n<p>Do pomiaru czasu wykonywania skryptu wykorzystywaliśmy dwie metody. Pierwsza to</p>\n<pre><code class=\"language-bash\">/usr/bin/time -o &quot;$TMP/time&quot; -f &quot;%e&quot; $comm $size &amp;&gt; /dev/null; #oryfinally %U instead %e\ntime=&quot;$(cat &quot;$TMP/time&quot; 2&gt; /dev/null)&quot;;\n</code></pre>\n<p>Druga to:</p>\n<pre><code class=\"language-bash\">time=`bash util/timing.sh $comm $size`\n</code></pre>\n<p>gdzie plik <code>util/timing.sh</code> zawierał poniższy kod</p>\n<pre><code class=\"language-bash\">#!/usr/bin/env bash\nSTART=$(date +%s.%N)\n# do something #######################\n\n&quot;$@&quot; &amp;&gt; /dev/null\n\n#######################################\nEND=$(date +%s.%N)\nDIFF=$( echo &quot;scale=6; (${END} - ${START})*1/1&quot; | bc )\necho &quot;${DIFF}&quot;\n</code></pre>\n<p>Który sprawdzał aktualny czas, wykonywał podaną instrukcję i ponownie sprawdzał aktualny czas. Następnie za pomocą programu <code>bc</code> obliczał różnicę między tymi czasami i zwracał ją z dokładnością do mikrosekund.</p>\n<p>Zaletą pierwszej metody była prostota, mniejsza ilość kodu. Z resztą narzędzie <code>usr/bin/time</code> jest dedykowanym narzędziem do pomiarów czasu skryptów w systemie <code>linux</code>. Zaletą drugiej metody była wyższa precyzja (mikro vs setne sekundy). Oczywiście mimo wykorzystania 6 cyfr po przecinku, zamiast dwóch, precyzja nie sięgała ona tak głęboko, ale przy bardzo szybkich programach pozwoliła mierzyć czas startowania programów z błędem pomiarowym niższym, niż ten czas.</p>\n<p>Żeby dać tym metodom równe szanse włączyłem pętle w języku <code>bash</code>, które średnio trwały około 4.19 sekundy. Jest to wystarczająco długo, aby ograniczenie liczby cyfr wyników nie stało się kluczowe i wystarczająco krótko, żeby można było powtórzyć pomiar wiele razy. Wyniki zestawiłem na poniższym histogramie:</p>\n<p><a href=\"https://postimg.org/image/wuuhagvov/\"><img src=\"https://s27.postimg.org/pev7oo7zn/paired_Histogram_Timing.png\" alt=\"pairedHistogramTiming.png\" loading=\"lazy\"></a></p>\n<p>oraz w tabeli</p>\n<table>\n<thead>\n<tr>\n<th>method</th>\n<th>time [s]</th>\n<th>standard dev [s]</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>uti/timing.sh</td>\n<td>4.200</td>\n<td>0.117</td>\n</tr>\n<tr>\n<td>/usr/bin/time -f &quot;%e&quot;</td>\n<td>4.178</td>\n<td>0.119</td>\n</tr>\n</tbody>\n</table>\n<p>Widać, że zmiana metody pomiaru z <code>/usr/bin/time</code> na <code>util/timing.sh</code> nie wymaga kasowania poprzednich wyników. Seria pomiarowe z <code>/usr/bin/time</code> i tak nie dotyczyła wyników o czasach poniżej <code>0.4 sec</code> bo przy błędzie rzędu <code>0.1</code> i zakresie 2 liczb po przecinku nie miało to sensu.  Warto zwrócić uwagę na to, że rozkład czasów potrzebnych na wykonanie programu jest podobny do tego, jaki miał rozkład czasu selektów po indeksowanym kluczu w bazie danych.</p>\n<h3 id=\"testy\">Testy</h3>\n<p>Jeśli wrócili byśmy do opisu instalacji, to zobaczyli byśmy, że ostatnia linia pliku <code>install.sh</code> odpowiada za pobranie biblioteki <a href=\"http://ssb.stsci.edu/testing/shunit2/shunit2.html\"><code>shunit2</code></a>.</p>\n<pre><code class=\"language-bash\">curl -L &quot;https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/shunit2/shunit2-2.1.6.tgz&quot; | tar zx\n</code></pre>\n<p>Zastosowaliśmy ją w skrypcie testującym, które kod pokazuję poniżej</p>\n<blockquote>\n<p><code>test.sh</code></p>\n</blockquote>\n<pre><code class=\"language-bash\">#!/usr/bin/env bash\n\n# args: min, mix, file - function check if\n# all numbers in file are in range (min,max)\nfunction columnInRange\n{\n    min=&quot;$1&quot;;\n    max=&quot;$2&quot;;\n\n    cat | while read n\n    do\n        echo $n;\n        assertTrue '[ 1 -eq $(echo $min&quot;&lt;&quot;$n | bc -l) ]'\n        assertTrue '[ 1 -eq $(echo $n&quot;&lt;&quot;$max | bc -l) ]'\n    done\n}\n</code></pre>\n<p>Zaczynamy od definiowania funkcji pomocniczej, która przyjmuje dwa parametry i strumień danych. Sprawdza ona czy strumień zawiera liczby z zakresu określonego przez te parametry. Za sprawdzenie odpowiadają funkcje <code>assertTrue</code>.</p>\n<p>Druga funkcja pomocnicza wykonuje dzielenie przez siebie wybranych kolumn z pary plików.</p>\n<pre><code class=\"language-bash\"># args: col, method and parameter for 1 file, method and parameter for 2 file\n# function print ratio of given column form two files &quot;log/out.[method][parameter].log\n# col number | meaning\n# 3          | size\n# 4          | time\n# 5          | speed\nfunction ratioOfColumns\n{\n    col=&quot;$1&quot;;\n\n    awk -F &quot;|&quot; 'FNR==NR{a[FNR] = $'$col'; next} {if(/inc/) printf &quot;%12.6f\\n&quot;, $'$col'/a[FNR]}' \\\n        log/out.$2.log log/out.$3.log\n}\n</code></pre>\n<p>Na tą chwilę wygląda to dość enigmatycznie, ale pliki te w założeniu mają odpowiadać temu, co <code>inc.bash</code> wyświetla w konsoli. Zakres parametru <code>$1</code> to <code>3</code>,<code>4</code>,<code>5</code>, a dostępne wartości <code>$2</code> i <code>$3</code> to <code>l1</code>, <code>l2</code>, <code>t1</code> i <code>t2</code>. Odpowiedź na pytanie skąd biorą się tepliki zawarta jest w kolejnej funkcji:</p>\n<pre><code class=\"language-bash\">oneTimeSetUp() {\n\n    for n in 1 2\n    do\n        for method in &quot;l&quot; &quot;t&quot;\n        do\n              bash inc.bash -$method $n | tee log/out.$method$n.log\n        done\n    done\n}\n</code></pre>\n<p>Która zgodnie z dokumentacją <code>shunit2</code> wykonana zostaje na samym początku testowania. Odpoiwada ona za wywołanie programu <code>inc.bash</code> cztery razy ze wszystkimi kombinacjami parametrów <code>-l</code> i <code>-t</code> oraz liczb <code>1</code> i <code>2</code> a następnie przekierowanie wyjścia do odpowiednio nazwanych plików.</p>\n<p>Kolejna funkcja wykona się po zakończeniu testowania - posprząta po testach.</p>\n<pre><code class=\"language-bash\">oneTimeTearDown() {\n    rm -rf log/out.*.log\n}\n</code></pre>\n<p>Możemy przejść do właściwych funkjci zawierających testy:</p>\n<pre><code class=\"language-bash\"># in database there are 16 columns of parameters\ntest_parameters_are_proporly_estimated()\n{\n    infile=$(grep inc config/parameters.csv | wc -l);\n    inbase=$(sqlite3 log/log.db &quot;SELECT count(*) FROM result WHERE a&gt;ea and b&gt;eb&quot;);\n    echo $infile;\n    echo $inbase;\n    assertEquals $infile $inbase;\n}\n</code></pre>\n<p>Pierwszy z testów sprawdza, czy plik <code>config/parameters.csv</code> został poprawnie załadowany do bazy przez skrypt <code>util/parameters_load.pl</code>.</p>\n<pre><code class=\"language-bash\"># ratio of loops for 2 sec to 1 sec is between 1.9 and 2.1\ntest_ratio_of_loops_in_proper_range()\n{\n     ratioOfColumns 3 t1 t2 | columnInRange 1.95 2.2\n}\n</code></pre>\n<p>Kolejny test bierze stosunek ilości pętli dla 2 sekund i 1 sekundy. Intuicyjnie czujemy, że powinien być on bliski dwójki, ale dopuszczamy odstępstwa w granicach błędu pomiarowego.</p>\n<pre><code class=\"language-bash\"># ratio of time for test with 2 sec and 1 sec should be near to 2\ntest_ratio_of_time_should_be_near_2_for_time_based_test()\n{\n    ratioOfColumns 4 t1 t2 | columnInRange 1.5 4;\n}\n</code></pre>\n<p>Następny test określa stosunek czasów dla programu zakładającego wykonywanie w 2 sekundy do 1 sekundy. Gdyby środowisko było idealne, to ten stosunek powinien wynosić dwa. jednak ponieważ na <code>gitlabie</code> moc obliczeniowa przydzielana runnerom jest dość niestabilna, pozwalamy na dużą granicę błędu pomiarowego.</p>\n<pre><code class=\"language-bash\"># ratio of time for test with 2 and 1 loop should be near to 1\ntest_ratio_of_time_should_be_near_1_for_loop_based_test()\n{\n    ratioOfColumns 4 l1 l2 | columnInRange 0.4 1.8;\n}\n</code></pre>\n<p>Podobnie jest dla czasu wykonywania jednej i dwóch pętli. Stosunek tych czasów powinien być bliski jedności, ponieważ czas wykonywania pętli jest rzędy wielkości niższy od czasu włączania programu. Jednak i tutaj dopuszczamy duże różnice związane ze zmiennością dostępnej mocy obliczeniowej.</p>\n<pre><code class=\"language-bash\"># any free language (without matlab and mathematica) start in time small than 0.2 sec\ntest_start_no_longer_than_150_milisecond()\n{\n    # time of programs for 1 loop\n    awk '/inc/ {print $6}' log/out.l1.log | columnInRange 0.001 0.15;\n}\n</code></pre>\n<p>Kolejny test sprawdza, czy wszystkie programy startują szybciej niż w 0.15 sec i wolniej niż 1 milisekundę.</p>\n<pre><code class=\"language-bash\"># ratio of speed for time based test should be near to 1\ntest_speed_should_be_not_dependent_from_loops_in_limit()\n{\n    ratioOfColumns 5 t1 t2 | columnInRange 0.5 1.4;\n}\n</code></pre>\n<p>Następny dotyczy czasów długich w porównaniu z czasem włączania programu, a 1-2 sekund za takie można uznać i wymaga aby stosunek prędokości wykonywania pętli dla tych czasów był bliski jedności, a więc nie zmieniał się wraz z czasem.</p>\n<pre><code class=\"language-bash\"># ratio of speed for 2 and 1 loop should be near to 2\ntest_ratio_of_speed_for_small_loop_number_in_proper_range()\n{\n    ratioOfColumns 5 l1 l2 | columnInRange 1.1 7.0;\n}\n</code></pre>\n<p>Zupełnie odwrotnie dla 1-2 pętli, jeśli czas jest prawie taki sam, to mierzona prędkość powinna być prawie dwa razy wyższa dla 2 pętli niż dla jednej. Nie możemy jednak mierzyć tego zbyt dokładnie, ponieważ czasy wykonywania programów dla tak niewielkich ilości pętli są zwykle bliskie błędom pomiarowym.</p>\n<pre><code class=\"language-bash\">test_ratio_of_speed_for_1_and_2_loops_form_database()\n{\n    for n in 1 2\n    do\n        sqlite3 log/log.db &quot;SELECT name, avg(size/time) as speed FROM \\\n            log WHERE size=&quot;$n&quot; AND name!='inc.m.sh' AND name!='inc.wl' GROUP BY name&quot; \\\n            &gt; log/out.l$n.speed.log\n    done\n\n    ratioOfColumns 2 l1.speed l2.speed | columnInRange 1.1 7.0;\n}\n</code></pre>\n<p>Ostatni test powtarza to samo co poprzedni, ale tym razem wydobywa dane z bazy, a nie konsoli.</p>\n<pre><code class=\"language-bash\">. shunit2-2.1.6/src/shunit2\n</code></pre>\n<p>Jako ostatnią linię skryptu testującego dołączamy zgodnie z dokumentacją program <code>sh2unit</code>.</p>\n<h3 id=\"ci%C4%85g%C5%82a-integracja\">Ciągła integracja</h3>\n<p>Na sam koniec opiszę proces ciągłej integracji, który wdrożyłem w tym projekcie. Ciągła integracja jest to wykonywanie instalacji i testów automatycznych przy każdym <code>pushu</code> na serwer z repozytorium. Możemy do tego wykorzystywać różne narzędzia. Ja zdecydowałem się na <a href=\"https://about.gitlab.com/gitlab-ci/\"><code>gitlab-ci</code></a>.</p>\n<p>Składnia pliku z instrukcjami dla runnera jest podobna do tej z <a href=\"https://docs.travis-ci.com/\">travisa</a>. Zaczyna się od wybrania obrazu dystrybucji na której uruchamiany testy:</p>\n<pre><code class=\"language-yml\">## Select image from https://hub.docker.com/_/php/\nimage: ubuntu:16.10\n</code></pre>\n<p>Następnie podpinamy serwisy, które mogły by być instalowane ręcznie, ale dla uproszczenia przygotowano je w formie gotowych do wpięcia komponentów:</p>\n<pre><code class=\"language-yml\">services:\n- mysql:8\n- php:7\n</code></pre>\n<p>Definiujemy zmienne wykorzystywane do łączenia z bazą danych:</p>\n<pre><code class=\"language-yml\">variables:\n  # Configure mysql service (https://hub.docker.com/_/mysql/)\n  MYSQL_DATABASE: inc\n  MYSQL_ROOT_PASSWORD: pass\n</code></pre>\n<p>Określamy zestaw instrukcji do wykonania przed testami:</p>\n<pre><code class=\"language-yml\">before_script:\n- bash install.sh\n- perl util/parameters_load.pl\n- export MYSQL_PWD=$MYSQL_ROOT_PASSWORD;\n- export MYSQL_HOST=&quot;mysql&quot;;\n- echo &quot;SELECT 'OK';&quot; | mysql --user=root &quot;$MYSQL_DATABASE&quot;\n\n# local variables\n#  https://dev.mysql.com/doc/refman/5.7/en/environment-variables.html\n</code></pre>\n<p>W ich skład wchodzi instalacja naszych zależności, ładowanie parametrów, eksportowanie zmiennych środowiskowych do łączenia z bazą i prosty test na połączenie.</p>\n<p>Główna część, czyli testowanie zawarte jest w poniższym fragmencie kodu;</p>\n<pre><code class=\"language-yml\">test:\n  image: mysql\n  image: php\n  script:\n  - bash test.sh\n</code></pre>\n<p>Żeby przetestować kod lokalnie wykonujemy komendę:</p>\n<pre><code class=\"language-bash\">sudo gitlab-ci-multi-runner exec docker test\n</code></pre>\n<p>To już wszystko. Mam nadzieję, że ten artykuł uświadomił Ci, że wybór języka może mieć ogromne znaczenie dla wydajności oraz przybliżył Ci historię kilku z nich. Jednak najważniejsze, że ten kod został przygotowany tak, aby łatwo było go rozszerzyć o pomiary dotyczące zadań jak na przykład zapis do pliku, albo wykonywanie całkowania numerycznego. Jeśli będziesz zainteresowany rozwijaniem tego softu daj znać, mam parę koncepcji, w którą stronę można by rozwinąć ten projekt.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f3a8e2fb35425592d0bbc",
            "plaintext": "Opis projektu\nNie wiem, jakie są wasze wymarzone prezenty gwiazdkowe, ale moim jest kawałek\nciekawego kodu. I właśnie taki prezent dostałem około półtora miesiąca temu.\n\nMój przyjaciel wysłał mi w e-mailu Kod źródłowy programu\n[https://www.dropbox.com/s/s9dy1jabkzxzls6/loopspeed.zip?dl=1], który mierzył\nczasy wykonywania pustych pętli w czterech różnych językach programowania.\nDopisałem testy dla dwunastu innych języków, lekko zautomatyzowałem testowanie i\nprzeanalizowałem wyniki.\n\nW tym wpisie pokażę jak wyglądają i jak szybko działają programy wykonujące\npuste pętle językach:\n\n * Matlab,\n * Bash,\n * SQL,\n * Mathematica,\n * C#,\n * JavaScript,\n * Python,\n * Ruby,\n * Perl,\n * R,\n * Php,\n * Fortran 95,\n * C++,\n * C,\n * Pascal\n * Java.\n\nDo logowania danych wykorzystamy plik tekstowy oraz silnik bazodanowy SQLite.\nAnalizę danych przeprowadzimy w programie Mathematica.\n\nInstalacja\nZ automatyzacją instalacji serwera bazy danych mysql zawsze wiążą się pewne\nproblemy jak konieczność podawania hasła\n[http://stackoverflow.com/questions/7739645/install-mysql-on-ubuntu-without-password-prompt] \nalbo zmieniania zakresu lokacji\n[http://askubuntu.com/questions/766334/cant-login-as-mysql-user-root-from-normal-user-account-in-ubuntu-16-04] \nz których można łączyć się z bazą jako root. Dlatego nie umieściłem instalacji\nserwera mysql w pliku install.sh. Jeśli nie masz serwera bazy danych, zainstaluj\ngo ręcznie:\n\nsudo apt-get install -y mysql-server mysql-client\n\n\nNiestety, a raczej niestety dla mnie, od kilku miesięcy świeżo zainstalowany\nserwer MySQL nie pozwala już domyślnie logować się komendą mysql -u root,\nzamiast tego wymaga sudo mysql -u root. Jest to zrozumiałe ze względów\nbezpieczeństwa i na pewno pomaga na serwerach produkcyjnych, ale z drugiej\nstrony jest to niewygodne przy bawieniu się kodem w domu. Jeśli twój komputer to\nmaszyna lokalna i tak jak ja nie chcesz używać sudo do każdego łączenia z bazą z \nbasha, możesz wykonać następujący manewr\n[http://stackoverflow.com/questions/38098505/mysql-works-with-sudo-but-without-not-ubuntu-16-04-mysql-5-7-12-0ubuntu1-1]\n:\n\nsudo mysql -u root\nDROP USER 'root'@'localhost';\nCREATE USER 'root'@'%' IDENTIFIED BY '';\nGRANT ALL PRIVILEGES ON *.* TO 'root'@'%';\nFLUSH PRIVILEGES;\nexit\n\n\nw ten sposób przywrócisz mysql -u root jako działającą metodę łączenia się z\nbazą. Prezentowany tutaj program używa właśnie takiej metody - to znaczy bez \nsudo.\n\nJeśli nie chcesz zmieniać ustawień bazy danych zawsze możesz użyć zmiennych\nśrodowiskowych\n[https://dev.mysql.com/doc/refman/5.7/en/environment-variables.html].\n\nexport MYSQL_PWD=<your password to mysql server>\nexport MYSQL_HOST=localhost;\n\n\nNie jest to rozwiązanie, które należy stosować na serwerach produkcyjnych,\nnatomiast świetnie nadaje się na maszyny lokalne, bo jest wygodne.\n\nŻeby sprawdzić, czy Twoja konfiguracja bazy jest poprawna wykonaj komendę:\n\nmysql --user=root \"$MYSQL_DATABASE\" -e \"SELECT 'OK' as 'state'\"\n\n\nJeśli zobaczysz\n\n+-------+\n| state |\n+-------+\n| OK    |\n+-------+\n\n\nto reszta instalacji jest jeszcze prostsza.\n\nInstalację projektu na czystym Ubuntu 16.04.1 LTS wymaga wpisania trzech komend:\n\nsudo apt-get install git\ngit clone --depth=1 http://gitlab.com/gustawdaniel/loopspeed && cd loopspeed\nsudo bash install.sh\nperl util/parameters_load.pl\n\n\nJest to pierwszy wpis z repozytorium na gitlabie a nie githubie. Nie jest to\nprzypadek, lecz zasługa świetnego narzędzia do ciągłej integracji - gitlab-ci,\nktóre omówię na samym końcu.\n\nTeraz przyjrzymy się skryptom: instalacyjnemu i ładującemu parametry.\n\nSkrypt instalacyjny install.sh wykonuje aktualizację listy dostępnych paczek i\ninstalację wymaganych kompilatorów i interpreterów języków:\n\n#!/usr/bin/env bash\n\napt-get update -y\napt-get install -y php\napt-get install -y python default-jdk g++ mono-mcs gfortran fp-compiler r-base nodejs-legacy ruby\n\n\ndorzuca do tego kilka programów, które wykorzystujemy\n\napt-get install -y sqlite3 bc git mysql-client curl\n\n\noraz paczki perla, których używamy głównie do komunikacji z bazą danych SQLite\n\napt-get install -y libtext-csv-perl libdbi-perl libdbd-sqlite3-perl\n\n\nNastępnie tworzy bazę do przechowywania wyników pomiarów oraz wyliczonych na ich\npodstawie parametrów:\n\nsqlite3 log/log.db \\\n\"create table IF NOT EXISTS log (\n    id INTEGER PRIMARY KEY,\n    name VARCHAR(255),\n    size UNSIGNED INTEGER,\n    time DECIMAL(12,6),\n    git CHAR(41)\n);\"\n\nsqlite3 log/log.db \\\n\"create table result (\n    name varchar(255),\n    a real,\n    b real,\n    ea real,\n    eb real\n);\"\n\n\nI na koniec instalator pobiera bibliotekę do testowania kodu pisanego w bashu - \nshunit2.\n\ncurl -L \"https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/shunit2/shunit2-2.1.6.tgz\" | tar zx\n\n\nDrugim skryptem który wykonaliśmy był\n\n> util/parameters_load.pl\n\n\n#!/usr/bin/perl -w\n\nuse v5.10;\nuse strict;\nuse warnings;\nuse autodie;\n\nuse Text::CSV_XS;\nuse DBI;\n\nmy $dbh = DBI->connect(\n    \"dbi:SQLite:log/log.db\", \"\", \"\",\n    {\n        RaiseError => 1, AutoCommit => 0\n    }\n);\n\n$dbh->do(\"DELETE FROM result\");\n\n# Using bind parameters avoids having to recompile the statement every time\nmy $sth = $dbh->prepare(<<'SQL');\nINSERT INTO result\n       (name, a,     b,     ea,    eb)\nVALUES (?,    ?,     ?,     ?,     ?)\nSQL\n\nmy $csv = Text::CSV_XS->new or die;\nopen my $fh, \"<\", \"config/parameters.csv\";\nwhile(my $row = $csv->getline($fh)) {\n    $sth->execute(@$row);\n}\n$csv->eof;\nclose $fh;\n\n$sth->finish;\n$dbh->commit;\n\n\nJego zadaniem jest przeniesienie zawartości pliku tekstowego \nconfig/parameters.csv do tabeli result bazy danych log/log.db. Przenoszone dane\ndotyczą szacowanych czasów wykonywania pętli i zostały wyliczone z wyników\nprzeprowadzonych wcześniej pomiarów.\n\nDwa z języków, które testowałem - Matlab i Mathematica - wymagają\nzainstalowanego licencjonowanego oprogramowania. Co prawda, studenci mają zwykle\nte licencje dzięki uczelniom, ale ze względu na to, że jest licencjonowane,\ntesty dla tych języków są domyślnie wyłączone.\n\nFramework\nNasz program do testowania pustych pętli ma następującą strukturę katalogów:\n\n├── config\n│   ├── list.txt\n│   └── parameters.csv\n├── inc\n│   ├── def.sql\n│   ├── inc.bash\n│   ├── inc.c\n│   ├── inc.cpp\n│   ├── inc.cs\n│   ├── inc.f95\n│   ├── inc.java\n│   ├── inc.js\n│   ├── inc.m.sh\n│   ├── inc.p\n│   ├── inc.perl\n│   ├── inc.php\n│   ├── inc.python\n│   ├── inc.r\n│   ├── inc.rb\n│   ├── inc.sql.sh\n│   └── inc.wl\n├── util\n│   ├── generate_parameters.wl\n│   ├── parameters_load.pl\n│   ├── text_to_sqlite.pl\n│   ├── timing_methods.sh\n│   └── timing.sh\n├── log\n│   ├── log.db\n│   ├── results_timing_methods.log\n│   └── results.log\n├── install.sh\n├── analysis.nb\n├── inc.bash\n├── test.sh\n├── README.md\n└── .gitlab-ci.yml\n\n\nKatalog config zawiera pliki pomocnicze z ustawieniami. Pierwszym z nich jest\nlista parametrów dla których będziemy wykonywać serie testowe config/list.txt -\nzwykły plik tekstowy z liczbami całkowitymi w kolejnych liniach. Drugim\noszacowane wartości parametrów określających szybkość wykonywania pustych pętli \nconfig/parameteres.csv.\n\nW inc znajduje się 16 plików odpowiadających za testowanie pętli oraz jeden do\ndefiniowania procedury w MySQL, która dopiero, kiedy zostanie wywołana wywołana\nbędzie wykonywać pętle.\n\nW util umieściłem narzędzia pomocnicze, które pozwalały mi na przerzucanie\ndanych z pliku tekstowego do bazy SQLite, oraz mierzenie różnic między wynikami\ndwóch metod pomiaru czasu trwania programu. Jest tam też skrypt do dopasowywania\nmodelu i tworzenia pliku config/parameters.csv, oraz skrypt do ładowania tych\nparametrów do bazy danych sqlite. Wykorzystanie plików tekstowych do logowania\nwyników pomiarów jest z jednej strony związane z rozwijaniem tego softu. Pliki\ntekstowe były stosowane zanim przeszedłem na silnik bazodanowy. Z drugiej strony\nnie chciałem zaśmiecać bazy danymi pomiarowymi, których nie byłem pewien, więc\njeśli istniało ryzyko, że program, który testuję będzie działał źle - na\nprzykład kiedy spodziewałem się, że wyjdę poza zakres danego typu liczbowego -\nwyłączałem logowanie do bazy i posługiwałem się tylko plikiem. Jeśli wszystko\nbyło ok, mogłem bez problemu załączyć nowe wyniki do uzyskanych wcześniej.\n\nKatalog log służy do przechowywania plików tekstowych oraz bazy danych SQLite.\nPlik result.log zawiera kopię danych, które trafiają do bazy danych, \nresults_timing_methods.log przechowuje wyniki pomiarów czasu. Podczas testowania\nw tym katalogu pojawiają się na czas testów inne pliki z logami.\n\nPoza tym projekt zawiera:\n\n * install.sh - skrypt instalacyjny (omówiłem go w poprzednim paragrafie),\n * inc.bash - bazowy skrypt do robienia pomiarów czasu trwania pustych pętli,\n * analysis.nb - notebook programu Mathematica. Służył on do badania wyników.\n * test.sh - skrypt do testowania działania inc.bash oraz innych elementów\n   projektu.\n\nDzięki takiej strukturze jesteśmy w stanie bez problemu dodawać nowe języki\nprogramowania. Trzymanie w bazie numeru rewizji pozwala nam również sprawdzać,\njak różne instrukcje spełniające teoretycznie tą samą funkcjonalność (np: for vs \nwhile) różnią się od siebie wydajnością.\n\nDataflow\nPrzepływ danych w programie posiada wbudowane sprzężenie zwrotne. Z jednej\nstrony inc.bash testuje pętle za pomocą parametrów wyliczonych z modelu za\npomocą util/generate_parameters.wl, z drugiej strony, żeby móc dopasować model\ndo danych, musieliśmy je najpierw dostać właśnie uruchamiając inc.bash.\n\nPatrząc na wykres przepływu danych łatwo znajdziemy zamknięte koło, które mam na\nmyśli.\n\n [https://postimg.org/image/mrfbkb5d7/]\n\nJest to klasyczny problem, co było pierwsze, jajko czy kura? Pierwszy był model\nteoretyczny, który określił co warto mierzyć czy dane doświadczalne, dzięki\nktórym możemy go zgadnąć? Tak jak w biologicznym odpowiedniku, tak tutaj\nodpowiedzią jest ewolucja. Początkowo każdy z programów inc.i, (gdzie i jest\nnumerem testowanego języka programowania) był włączany ręcznie. Z jedną pętlą.\nPóźniej z tysiącem, milionem, miliardem. Kiedy widziałem, że wykonuje się dłużej\nniż kilka sekund obniżałem liczbę pętli, kiedy krócej niż sekundę podnosiłem ją.\nDążyłem do tego, żeby ręcznie znaleźć liczbę pętli odpowiadającą miej więcej 4-5\nsekund wykonywania programu. Tak uzyskiwałem pierwsze wartości parametrów, które\njeszcze wtedy były wpisywane ręcznie do kodu programu inc.bash. Dzięki temu\nuwspólniłem skalę dla wszystkich z wyjątkiem języka Matlab, którego\ninicjalizacja trwała 5 sekund z kawałkiem. Dla Matlaba robiłem oddzielną serię\npomiarową zanim go wyczułem. Dane z tego typu testów trafiały do pliku \nresults.log, ale o tym czy przenosić je do log.db decydowałem na podstawie\nzdrowego rozsądku, w jednym przypadku zdarzyło się, że dla jednego z języków\nczasy rosły wraz z liczbą pętli $size do pewnego momentu, a zaczęły trzymać się\nstałego poziomu. Okazało się, że zakresy zmiennych nie wystarczają do\npomieszczenia liczby iteracji i jest ona po prostu rzutowana na mniejszą\nwartość. Były przypadki (python oraz r) gdzie brakowało pamięci RAM, bo pętla \nfor zamiast inkrementować skalarny wskaźnik była skonstruowana tak, że ładowała\ndo pamięci operacyjnej całą tablicę, po której później przebiegała. Ogólnie\nrzecz biorąc, nie dało by się zupełnie zautomatyzować testów na tym etapie. W\nniektórych językach trzeba było zmieniać typy, na przykład w Pascalu zwykły Int \nnie wystarczył i trzeba było stosować QWord, analogicznie w C# typ Int32 był\nzmieniany na UInt64. Podsumowując: początkowo model istniał tylko w mojej\ngłowie. Na początku nie było analysis.nb ani list.txt, inc.bash zawierał\nzakodowane na sztywno przybliżone szybkości pętli i nie miał tylu opcji, z\nktórymi można było go włączać.\n\nKiedy results.log rozrósł się, a ja zrozumiałem, że testowanie w stronę\nkrótszych czasów jest nieopłacalne bo generuje za dużo błędu pomiarowego, a w\nstronę dłuższych czasów nieopłacalne, bo nie wnosi żadnych nowych efektów, wtedy\npowstał program text_to_sqlite.pl do konwertowania pliku tekstowego do postaci\nwierszy w bazie danych. Zrezygnowałem z zapisywania zmiennej $speed - szybkości\npętli, jako, że dzięki silnikowi bazodanowemu jej wyliczanie było prostsze,\nuznałem natomiast, że jeśli wprowadzam zmiany w programach inc.i, to w danych\nmoże pojawić się bałagan. Żeby móc wykrywać, z jakiej wersji programu pochodzą\ndane zapisy dodałem zmienną $git z numerem rewizji. Wtedy powstał notebook \nanalysis.nb i z jego pomocą wyliczyłem parametry do bash.inc z większą\ndokładnością. Zaplanowałem też serię pomiarową list.txt która wykładniczo\nrozrzedzała się dla rosnących czasów pomiarów. Na koniec obliczanie parametrów\nprzeniosłem do skryptu util/generate_parameters.wl, dopisałem \nutil/parameters_load.pl do ich konwersji do bazy sqlite i podłączyłem te dane do \ninc.bash. Dzięki modelowi mogłem wyliczyć ile czasu będzie trwał jaki pomiar. W\nten sposób obieg danych zamknął się. Model zaczął wyznaczać optymalne punkty\npomiarowe, a uzyskiwane dane zaczęły płynąć w coraz bardziej zautomatyzowany i\nzracjonalizowany sposób.\n\nJądro programu\nKiedy wiemy już co jak działa i do czego służy obejrzymy kod programu inc.bash.\nProgram zaczyna się od funkcji odpowiedzialnej za wyświetlanie okna pomocy.\n\n> inc.bash\n\n\n#! /bin/bash\n\nshow_help() {\ncat << EOF\nUsage: bash inc.bash [-a](-f|-l) (single_number|-f file_with_numbers_in_lines)\n\n    -h          display this help and exit\n    -a          all programs enable, enable this only if you have\n                license on Mathematica and Matlab.\n    -t          time based mode of calculations. You assign number\n                of seconds for each program. Programs goes equally.\n    -l          line based mode of calculations. You assign number\n                of lines executed by loop. Good mode for debug.\n    -f file     load numbers of seconds (-t) or loops (-l) from file,\n                default config/list.txt\nEOF\n}\n\n\nWidzimy, że posiada on kilka flag, z których możemy korzystać. Pierwszą znich\njest -a służąca do wykonywania testów z wykorzystaniem oprogramowania\nkomercyjnego: matlab i mathematica. Domyślnie jest to wyłączone, żeby program\nbył dostępny bez konieczności ich instalowania. Następnie mamy do wyboru -t i -l \nodpowiadających za sposób wyznaczania ilości pętli. W opcji -t użytkownik\nwyznacza czas w sekundach jaki ma zająć wykonywanie każdego z badanych programów \ninc/inc.i, na podstawie tego czasu i parametrów wyznaczonych wcześniej przez \nutil/generate_parameters.wl określane są liczby pętli dla każdego z nich. Opcja \n-l pozwala na pomiar dokładnej ilości pętli jakie chcemy wykonać. Na koniec\nokreślamy liczbowo ilość oczekiwanych sekund lub wykonywanych pętli albo za\npomocą flagi -f ładujemy plik z serią pomiarową. Następnie program stosuje\nbardzo ciekawy mechanizm czyszczenia po sobie niezależnie od sposobu w jaki ma\nzostać zamknięty.\n\nfunction onExit {\n\t[ ! -z \"$TMP\" ] && \\\n\t[   -d \"$TMP\" ] && \\\n\trm -Rf \"$TMP\";\n\trm -f inc.class;\n\texit;\n}\n\n\nZastosowano tutaj ciekawą składnię z flagami -z i -d. Dokumentacja basha\n[http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html] wyjaśnia, że\nlokalizacja wskazywana przez zmienną $TMP ma zostać usunięta jeśli zmienna $TMP \ncoś w ogóle zawiera i jeśli wskazuje na katalog. Kolejna linia to usunięcie\npliku pochodzącego z kompilacji javy, który nie trafił do $TMP tylko dlatego, że\nnie potrafiłem go tam wrzucić.\n\nFunkcja onExit wykona się przy zamykaniu programu, co będzie zaznaczone później.\nTeraz przyjrzymy się funkcji test - kompletującej wszystkie dane, wykonującej\ntesty i wysyłającej dane do bazy oraz pliku. Jest to centralny punkt całego\nsystemu, odpowiada ona za uwspólnienie interfejsu wszystkich programów.\n\nfunction test {\n\tname=\"$1\";\n\tsize=\"$2\";\n\tcomm=\"${@:3}\"\n\n\nPrzyjmuje ona na wejściu trzy lub więcej parametrów. Pierwszy to nazwa: zwykle \ninc.<rozszerzenie języka> np: inc.c lub inc.js. Nie jest ona w żaden sposób\npowiązana ani z lokalizacją pliku źródłowego, ani wykonywalnego. W zasadzie\nmogła by być dowolna. Przyjąłem jednak konwencję, że nazywa się tak jak plik\nźródłowy. Drugi parametr to liczba pętli jaka ma zostać wykonana $size. Kolejne\nparametry, niezależnie od ich ilości wrzucane są do zmiennej $comm - jest to\nkomenda do włączenia programu, ale bez liczby pętli.\n\n    [ $size -le 0 ] && return;\n\n\nPo zabezpieczeniu się, że liczba pętli nie może być ujemna funkcja test może\nwykonywać pomiar czasu.\n\n    time=`bash util/timing.sh $comm $size`\n\techo $name,$size,$time,$GIT\t\\\n\t    | tee -a log/results.log \\\n\t    | awk -F ',' '{printf \"| %-12s | %15s | %12.6f s | %19.2f |\\n\", $1, $2, $3, $2/$3;}'\n\n\nWidzimy, że wykorzystuje do tego program util/timing.sh podając mu komendę do\nwykonania wraz z liczbą pętli. Wynik działania programu timing.sh przekazywany\njest do zmiennej time. Następnie nazwa, ilość tętli, czas i numer rewizji\nwysyłane są do pliku log/results.log oraz a nazwa, ilość pętli, czas i szybkość\nwyświetlane na ekranie. Numer rewizji znajduje się w globalnej zmiennej GIT i\nbędzie zdefiniowany później. Ten sam zestaw danych, który zapisany było do pliku \nlog/resutls.log trafia do bazy danych.\n\n     sqlite3 log/log.db  \"insert into log (name,size,time,git) values ('$name',$size,$time,'$GIT');\"\n}\n\n\nKolejna funkcja służy głównie uporządkowaniu kodu programu i zostanie wywołana\ntylko raz bez żadnych parametrów.\n\nfunction compile {\n    g++ -O1 -o \"$TMP/cpp\" 'inc/inc.cpp';\n    gcc -O1 -o \"$TMP/c\"   'inc/inc.c';\n    mcs -out:\"$TMP/cs.exe\" inc/inc.cs\n    javac 'inc/inc.java' -d .;\n    mysql -u root < inc/def.sql;\n    f95 -O1 -o \"$TMP/f\" inc/inc.f95\n    fpc -O2 inc/inc.p -o\"$TMP/p\" -Tlinux &>/dev/null\n}\n\n\nWykonuje ona kompilacje języków które tego wymagają. Czas kompilacji nie jest\nnigdzie mierzony.\n\nZupełnie inaczej jest z funkcją calculate obliczającą ilość pętli która ma się\nwykonać. Ta funkcja będzie wykonywana przy każdym pojedynczym teście. Jej\ndziałanie uzależnione jest od wartości zmiennej globalnej $timeMode. Jeśli\nwłączamy program z flagą -l to $timeMode=0 i funkcja zwróci nam swój pierwszy\nargument oraz wartość liczbową zmiennej globalnej $POW. Jedynym argumentem tej\nfunkcji jest nazwa języka - u nas zapisywana jako inc.<rozszerzeie>. Zmienna \n$POW odpowiada liczbie którą podajemy do programu niezależnie czy robimy to za\njego nazwą, czy jest to jedna z liczb z pliku jaki wrzucamy za flagą -f. Jeśli\nprogram działa z flagą -t to za pomocą programu awk wyliczamy liczbę pętli ze\nwzoru (pow-b)/a gdzie pow jest czasem w sekundach, natomiast b oraz a są\nparametrami dopasowania prostej. Nasze a i b to w programie elementy tablicy\nasocjacyjnej, którą będziemy niedługo definiować.\n\n# number of loops for given languages in dependence from $timeMode\nfunction calculate {\n\n    if [[ \"$timeMode\" -eq \"1\"  ]]; then\n        echo $1 ${a[$1]} ${b[$1]} $POW | awk '{ printf \"%s %.0f\\n\", $1, ($4-$3)/$2 }';\n    else # linemode for debug\n        echo $1 $[1*POW];\n    fi\n}\n\n\nTymczasem przyjżymy się funkcji odpowiedzialnej za testowanie całego zbioru\nprogramów dla danego parametru $POW.\n\nfunction testbundle {\n    [ \"$allPrograms\" -eq \"1\" ] && test    $(calculate inc.m.sh    )    bash    inc/inc.m.sh; # long time of setup about 5 sec\n    test    $(calculate inc.bash    )    bash    inc/inc.bash;\n    test    $(calculate inc.sql.sh  )    bash    inc/inc.sql.sh;\n    [ \"$allPrograms\" -eq \"1\" ] && test    $(calculate inc.wl      )    MathematicaScript -script inc/inc.wl;\n    test    $(calculate inc.r       )    Rscript inc/inc.r;\n    test    $(calculate inc.cs      )    mono    \"$TMP/cs.exe\";\n    test    $(calculate inc.js      )    node    inc/inc.js;\n    test    $(calculate inc.python  )    python  inc/inc.python;\n    test    $(calculate inc.rb      )    ruby    inc/inc.rb;\n    test    $(calculate inc.pl      )    perl    inc/inc.pl;\n    test    $(calculate inc.php     )    php     inc/inc.php;\n    test    $(calculate inc.f95     )    \"/$TMP/f\";\n    test    $(calculate inc.cpp     )    \"$TMP/cpp\";\n    test    $(calculate inc.c       )    \"$TMP/c\";\n    test    $(calculate inc.p       )    \"$TMP/p\";\n    test    $(calculate inc.java    )    java inc;\n}\n\n\nWidzimy, że sprawdza ona wartość zmiennej $allPrograms powiązanej z flagą -a,\nżeby włączać testy mathematica i matlab tylko jeśli ustawiono tą flagę. Poza tym\nwykonuje ona bardzo powtarzalny schemat - dla każdego programu włącza funkcję \ntest. Za dwa pierwsze parametry - nazwę i liczbę pętli podstawia wynik funkcji \ncalculate, wszystkie pozostałe są zwijane do komendy odpalającej testowany\nprogram.\n\nDo wyjaśnienia pozostaje jeszcze - skąd wzięły się tablice asocjacyjne\nparametrami. Za ich utworzenie odpowiada funkcja loadParams.\n\nfunction loadParams {\nsource <(sqlite3 log/log.db \"select name, a from result\" |\n         awk -F '|' '{printf(\"a[%s]=%s;\\n\",$1,$2);}')\n\nsource <(sqlite3 log/log.db \"select name, b from result\" |\n         awk -F '|' '{printf(\"b[%s]=%s;\\n\",$1,$2);}')\n}\n\n\nStosowana tu składnia z wykorzystaniem source jest bardzo niezalecana w\nprzypadku danych pochodzących od użytkowników. Tutaj jednak dane sami generujemy\ni uznałem, że jest to najłatwiejszy sposób na zdefiniowanie tych tablic. Source \nodpowiada za wykonanie kodu, który dostaje, a dostaje przetworzone do postaci\nnp: a[inc.bash]=4.231982349e-06 wyniki zapytań do tabeli z parametrami.\n\nLogika skryptu jest dość przewidywalna. Zaczyn się od przejścia do katalogu\ngdzie zlokalizowany jest skrypt. Następnie ustawiamy coś w rodzaju nasłuchu na\nzdarzenia SIGINT, SIGTERM i EXIT. Oznacza to, że jeśli będziemy chcieli wyłączyć\nprogram zanim skończy działać, to po sobie posprząta.\n\ncd \"$(dirname \"${BASH_SOURCE[0]}\")\";\ntrap onExit SIGINT SIGTERM EXIT;\n\n\nJeśli zastanawiasz się, co tu jest do sprzątania, to kolejna linijka stanowi\nodpowiedź na Twoje pytanie. Tworzymy w niej katalog tymczasowy do przechowywania\nskompilowanych wersji programów i wstawiamy jego lokalizację do zmiennej $TMP.\n\nTMP=\"$(mktemp -d)\";\n\n\nDo zmiennej globalnej $GIT przypisujemy aktualny numer rewizji.\n\nGIT=`git rev-parse HEAD`;\n\n\nTworzymy tablice asocjacyjne a oraz b\n\ndeclare -A a\ndeclare -A b\n\n\nI ustawiamy domyślne wartości wszystkich falg oraz zmiennych.\n\nallPrograms=0; # if all programs should be tested? Default: no, because licence is not free.\nconfigFile='config/list.txt';\ntimeMode=1;\nfileMode=0;\n\n\nW pętli while przetwarzamy wszystkie danej wprowadzone przez użytkownika.\n\nwhile getopts hatlf opt; do\n    case $opt in\n        h)\n            show_help\n            exit 0\n            ;;\n        a)  allPrograms=$((allPrograms+1))\n            ;;\n        t)  timeMode=1;\n            ;;\n        l)  timeMode=0;\n            ;;\n        f)  configFile=${2:-${configFile}}; fileMode=1;\n            ;;\n        *)\n            show_help >&2\n            exit 1\n            ;;\n    esac\ndone\nshift \"$((OPTIND-1))\" # Shift off the options and optional --.\n\n\nPo wychwyceniu wszystkich opcji przechwytujemy jeszcze parametr określający\nliczbę pętli lub sekund. Ładujemy parametry do tablic asocjacyjnych i\nkompilujemy programy.\n\nPOW=${1:-4};\nloadParams;\ncompile\n\n\nWyświetalmy przyjazne elementy interfejsu użytkownika z nagłówkami tabeli.\n\necho '+--------------+-----------------+----------------+---------------------+';\necho '|     File     |      Size       |      Time      |        Speed        |';\necho '+--------------+-----------------+----------------+---------------------+';\n\n\n\nWykonujemy testowanie odpowiednią liczbę razy.\n\nif [[ \"$fileMode\" -eq \"1\" ]]; then\n   while IFS='' read -r POW || [[ -n \"$POW\" ]]; do\n      testbundle;\n   done < ${1:-${configFile}}\nelse\n  testbundle;\nfi\n\n\nI kończymy program domknięciem tabeli.\n\necho '+--------------+-----------------+----------------+---------------------+';\n\n\nSkrypty usprawniające przepływ danych\nZ czasem zwiększania ilości danych i testowania nowych zakresów pojawiła się\npotrzeba automatyzacji procesu przepływu danych. Służy do tego kilka poniższych\nskryptów.\n\nDo przerzucania tekstowych wyników pomiarów do bazy danych służy program:\n\n> util/text_to_sqlite.pl\n\n\n#!/usr/bin/perl -w\nuse warnings FATAL => 'all';\nuse DBI;\nuse strict;\n#https://mailliststock.wordpress.com/2007/03/01/sqlite-examples-with-bash-perl-and-python/\nmy $db = DBI->connect(\"dbi:SQLite:log/log.db\", \"\", \"\",{RaiseError => 1, AutoCommit => 1});\n\n\nmy $filename =  $ARGV[0] || 'log/results.log';\n\n\nPo nagłówkach mamy tutaj zmienną $db przechowującą połączenie z bazą i $filename \npobierającą argument z linii komend z domyślą wartością ustawioną na lokalizację\npliku z logami. Takie ustawienie zmiennych dawało elastyczność, a jednocześnie\nnie wymagało wpisywania parametrów w najbardziej powtarzalnych sytuacjach.\nNastępnie program otwierał plik:\n\nopen( my $fh => $filename) || die \"Cannot open $filename: $!\";\n\n\ni iterując po jego liniach zapisywał odpowiednio przekształcone rekordy do bazy:\n\nwhile(my $line = <$fh>) {\n        my @row = split(\",\",$line);\n        $db->do(\"INSERT INTO log (name,size,time,git) values ('\".$row[0].\"',$row[1],$row[2],'$row[3]');\");\n}\nclose($fh);\n\n\nAnaliza\nZdarzało nam się na tym blogu analizować dane. Schemat jest prosty. Łączymy się\nz bazą. Wyciągamy dane do zmiennej, dopasowujemy model, na koniec rysujemy\nwykresy lub eksportujemy wyniki obliczeń.\n\nOmówimy teraz skrypt który przekształca wyniki pomiarów na parametry modelu.\n\n> util/generate_parameters.wl\n\n\n(*MathematicaScript -script util/generate_parameters.wl*)\n\nNeeds[\"DatabaseLink`\"]\nconn = OpenSQLConnection[\n  JDBC[\"SQLite\", $InitialDirectory <> \"/log/log.db\"]];\n\nPrint[\"Conection with database established...\"];\n\n\nSkrypt zaczyna pracę od połączenia do bazy. Robi to za pomocą dwóch linii kodu.\nPierwsza z nich to importowanie paczki. Druga zapisuje do zmiennej conn nowe\npołączenie realizowane za pomocą interfejsu JDBC. Zmienna $InitialDirectory \nzwraca lokalizację z której startujemy, a znaki <> są operatorem konkatenacji\nstringów. W ten sposób JDBC przyjmuje tu tylko dwa argumenty: nazwę silnika\nbazodanowego i lokalizację pliku z bazą.\n\nPierwsze zapytanie do bazy wyciąga listę języków jakich używamy.\n\nlist = Flatten[\n  SQLExecute[conn, \"SELECT name FROM log GROUP BY name\"]];\n\n\nZa wykonanie zapytania na połączeniu conn odpowiada SQLExecute. Komenda Flatten \nsłuży spłaszczeniu tablicy, która w przeciwnym wypadku była by tablicą tablic.\nJest to związane z tym, że jeśli wybieramy więcej niż jeden atrybut to tablica\ndwuwymiarowa jest bardziej naturalnym sposobem reprezentacji wyniku zapytania.\nWidać to dobrze na przykładzie kolejnego zapytania, a raczej całej serii zapytań\nwykonywanych wewnątrz instrukcji Table:\n\ndata = Table[{i,\n  SQLExecute[conn,\n    \"SELECT size,time FROM log WHERE name='\" <> ToString[i] <>\n        \"'\"]}, {i, list}];\n\nPrint[\"Data extracted from database...\"];\n\n\nTutaj do zmiennej data zapisujemy tablicę, która iterując po wyciągniętej\nwcześniej liście języków każdy swój element układa w dwuelementowa tablicę.\nPierwszy z nich jest właśnie tą nazwą, drugi jest tablicą par zmiennych size i \ntime, czyli liczb pętli i czasów wykonywania odpowiadających danemu językowi.\n\nKolejny \"oneliner\" odpowiada za modelowanie:\n\nnlm = NonlinearModelFit[Log[data[[#, 2]]],\n  Log[Exp[a] Exp[x] + b^2], {a, b}, x] & /@ Range[list // Length];\n\nPrint[\"Nonlienear models calculated...\"];\n\n\nPierwsza linijka dopasowuje modele dla wszystkich języków za jednym razem.\nRozłożymy ją na czynniki pierwsze.\n\nZacznijmy od najbardziej tajemniczych znaczków, czyli składni f[#]&/@{1,2,3} .\nZnaki a/@b oznaczają mapowanie, czyli zastosowanie operacji a do elementów\npierwszego poziomu tablicy b. Znak # oznacza slot na włożenie danych, a & jest\nznacznikiem informującym, że to co nastąpi później będzie wkładane do slotów.\nTak więc f[#]&[a] jest tym samym co f[a]. Ostatecznie f[#]&/@{1,2,3} jest\nrównoważne {f[1],f[2],f[3]}. Wielkość list//Length to długość zmiennej list. W\nnaszym przypadku 16. Funkcja Range tworzy tablicę od jedności do swojego\nargumentu. Dlatego Range[list//Length] będzie tablicą od 1 do 16. Więc te liczby\nkolejno będziemy wkładać do slotu oznaczonego # w wyrażeniu NonlinearModelFit.\n\nNonlinearModelFit jest funkcją języka Mathematica odpowiadającą za dopasowywanie\nmodelu do danych, oraz zwracanie dodatkowych informacji związanych na przykład z\nbłędami pomiarowymi.\n\nJej pierwszym argumentem jest zbiór danych. W naszym przypadku zlogarytmowana\nlista par czasów i rozmiarów pętli. Działa tu zasada: \"logarytm tablicy to\ntablica logarytmów\".\n\nDrugi argument to model danych jaki dopasowujemy. U nas Log[Exp[a] Exp[x] + b^2]\n. Choć na pierwszy rzut oka, tak nie wygląda, jest to prosta Ax+B tylko w\nzmienionym układzie współrzędnych. Spójrzmy na to tak. Do x i y dopasowywali\nbyśmy prostą y=Ax+B, Jeśli zlogarytmujemy obie strony to mamy log(y)=log(A\nexp(log(x))+B), dane, do jakich dopasowujemy to {Log[x], Log[y]}, więc\ntymczasowo nazywająć log(x)=X i log(y)=Y dostajemy wyrażenie Y = log(A exp(X) +\nB) dla danych X,Y. Jednak ponieważ nasze A jest bardzo małe, a B zawsze\ndodatnie, wprowadzamy oznaczenia A=exp(a) oraz B=b^2. Teraz a może mieć\nnaturalne rzędy wielkości - tak lubiane przez metody numeryczne, a na b nie\nnarzucamy żadnych ograniczeń dotyczących znaku - metody numeryczne skaczą ze\nszczęścia, kiedy widzą takie podstawienia. Od teraz będziemy operować zmiennymi \na i b mając na myśli, że A i B możemy z nich łatwo obliczyć.\n\nTrzeci argument NonlinearModelFit to lista stopni swobody, a czwarty nazwany po\nprostu x odpowiada naszemu dużemu X czyli logarytmowi z liczby powtórzeń pętli.\n\nCały zbiór dopasowanych modeli został zapisany w zmiennej nlm. Czas wydobyć z\nniego parametry, które chcemy zapisać do pliku. Odpowiada za to kod:\n\nnameABlist = {list[[#]],\n  Exp[a],\n  b^2,\n  Exp[a]*nlm[[#]][\"ParameterErrors\"][[1]],\n  Abs[2*b]*nlm[[#]][\"ParameterErrors\"][[2]]} /. nlm[[#, 1, 2]] & /@\n    Range[Length[list]];\n\nPrint[\"Parameters extracted from models...\"];\n\n\nTworzona przez niego tablica nameABList jest prostokątną macierzą o wymiarach 5\nkolumn na 16 wierszy. Ponownie wykorzystujemy mapowanie z przebieganiem po\nzakresie wskaźników odpowiadających językom /@Range[Length[list]]. Za list[[#]] \nzostaje wstawiona nazwa języka, dwie kolejne wielkości dzięki znacznikowi /. są\npodstawiane z modelu nlm. Dwie ostatnie to błędy pomiarowe odpowiednio\nprzeskalowane w związku ze zmianą układu współrzędnych.\n\nNa samym końcu wysyłamy naszą macierz do pliku:\n\nExport[$InitialDirectory <> \"/config/parameters.csv\",\n  SetPrecision[nameABlist, 10]];\n\nPrint[\"Parameters saved to file. Process finished correctly.\"];\nExit[];\n\n\nWyniki\nDla każdego języka omówimy wyniki. Zamiast podawać ilość wykonywanych pętli na\nsekundę, na wykresach prezentujemy jej logarytm a, jako łatwiejszy do\nporównywania. A zamiast czasu włączania programu odpowiadającemu jednemu\nwykonaniu pętli jego pierwiastek b. Do wyrysowania wykresów zastosowaliśmy\nnastępujący kod z pliku analysisi.nb\n\nDo prezentacji wyników wykorzystamy interfejs zrozumiały dla człowieka, czyli\nwykresy. Za ich wyświetlenie odpowiada poniższy fragment programu analysis.nb.\n\nDo[Module[{img, bands},\n  bands[x_] =\n   nlm[[i]][\"SinglePredictionBands\", ConfidenceLevel -> .99];\n  img = Show[{ListLogLogPlot[{data[[i, 2]]}, PlotRange -> Full,\n      PlotLabel -> data[[i, 1]], ImageSize -> 800,\n      BaseStyle -> {FontSize -> 15},\n      FrameLabel -> {\"$size [number of loops]\", \"$time [sec]\"},\n      Frame -> True, PlotStyle -> {Lighter[Red]},\n      PlotLegends ->\n       Placed[SwatchLegend[{\"Experimental data\"},\n         LegendMarkerSize -> {30, 30}], {0.3, 0.85}]],\n     LogLogPlot[{Exp[nlm[[i]][Log[x]]], Exp[bands[Log[x]]]}, {x, 1,\n       10^13}, PlotLegends ->\n       Placed[SwatchLegend[{nlm[[i]][\n           \"ParameterConfidenceIntervalTable\"]},\n         LegendMarkerSize -> {1, 1}], {0.3, 0.75}]]}];\n  Print[img];\n  Export[\"inc_\" <> ToString[list[[i]]] <> \".png\", img];\n  ], {i, list // Length}]\n\n\nFunkcja Do wykonuje swój pierwszy argument iterując po i od 1 do liczby badanych\njęzyków programowania. Module z jednej strony porządkuje kod zbierając go w\njedną niepodzielną całość, z drugiej pozwala nie zaśmiecać głównego programu\nzmiennymi lokalnymi do przechowywania wykresów (img) i linii granicznych (bands\n). Owe linie graniczne to możliwie najkrótszy i najdłuższy czas wykonywania\nokreślonej ilości pętli przy założonym przedziale ufności. Nie wchodząc już w\nszczegóły, które związane głównie z formatowaniem nie są tak ciekawe: img \nzawiera wykres. Funkcja Print wyświetla go na ekranie a Export zapisuje do\npliku.\n\nBash\nJęzyk powłok bash [https://pl.wikipedia.org/wiki/Bash] powstał w 1987 roku,\nczyli 4 lata przed powstaniem pierwszego jądra Linuxa. Obecnie jest używany\ngłównie do wykonywania operacji związanych z systemem operacyjnym Linux, mimo,\nże Linux i Bash mogą istnieć bez siebie. Jest to język interpretowany i z tego\nwzględu nie jest zoptymalizowany pod wykonywanie obliczeń. Kod wykonujący puste\npętle wygląda tak:\n\n#! /bin/bash\n\ni=0;\nmax=$1;\n\nwhile [[ $i -le $max ]];\ndo\n\ti=$[i+1];\ndone\n\n\nA oto wyniki pomiarów czasu:\n\n [https://postimg.org/image/6tnjwy8yv/]\n\nW naszym teście wypadł najsłabiej, jeśli chodzi o ilość wykonywanych pętli na\njednostkę czasu, ale spośród wszystkich języków interpretowanych jest pierwszy,\njeśli chodzi o czas włączania. Nie ustępuje jednak bardzo pod tym względem\njęzykom kompilowanym.\n\nMatlab\nMatlab [https://pl.wikipedia.org/wiki/MATLAB] jest językiem zaprojektowanym do\nobliczeń macierzowych. Jego historia sięga 1980 roku. Początkowo napisany w\nFortranie miał ułatwić studentom obliczenia macierzowe, trzy lata później\nprzepisany w c i systematycznie rozbudowywany o nowe funkcjonalności stał się\njednym z najpopularniejszych języków stosowanych przez naukowców szczególnie w\nzastosowaniach związanych z obliczeniami numerycznymi.\n\nMatlab nie ma wygodnego interfejsu konsolowego. Żeby przekazać mu zmienną\nmusieliśmy sklejać kod interpretowany w Matlabie za pomocą basha.\n\n#!/usr/bin/env bash\n\nread -r -d '' VAR << EOM\nfor c = 1:$1\n%  disp(c)\nend\nEOM\n\necho \"$VAR\" | matlab -nodesktop -nosplash 1>/dev/null\n\n\n [https://postimg.org/image/dxr64v2ih/]\n\nJeśli chodzi o szybkość wykonywania jednej pętli to Matlab poradził sobie\nnajlepiej w kategorii języków interpretowanych (z wyjątkiem javy, która jest\ntakim hybrydowym rozwiązaniem). Opłacił to jednak potwornie długim czasem\nwłączania sięgającym 5 sekund. Jest to znacznie dłuższy czas niż zabierany na\nktórąkolwiek z kompilacji. Matlab jest dobry, ale do dużych rzeczy, w przeciwnym\nwypadku nie opłaca się go włączać, ponieważ przez te 5 sekund bash wykonał by\nmilion pętli, a typowe skryptowe języki do 100 milionów.\n\nMySQL\nSam MySQL [https://pl.wikipedia.org/wiki/MySQL] jest raczej systemem do\nzarządzania bazą danych niż językiem. Język to SQL, ale ze względu na różnice w\nimplementacjach silników bazodanowych wolałem podkreślić MySQL, niż zostawić SQL\n. Tak czy inaczej silniki bazodanowe, jak i język zapytań do baz danych nie były\ntworzone z myślą o inkrementacji zmiennych i sprawdzaniu warunków. Można by\npowiedzieć, że procedury i instrukcje sterujące to raczej dodatek, który pomaga\nograniczyć ilość zapytań niż główna funkcjonalność baz danych. Należy pamiętać,\nże taka mikro-optymalizacja na tym poziomie nie ma sensu, ponieważ najbardziej\nkosztowne czasowo operacje znajdują się w selektach i trzymaniu spójności danych\nprzy update/delete/insert.\n\nDo mysql również nie da się łatwo przekazać parametru z konsoli jako wartości\npodanej po nazwie programu. Użyliśmy następującego konektora\n\n#!/usr/bin/env bash\n\nmysql -u root inc -e \"CALL inc_loop($1)\";\n\n\nA procedura inc_loop definiowana była w ten sposób:\n\nCREATE DATABASE IF NOT EXISTS inc;\nuse inc;\n\nDROP PROCEDURE IF EXISTS inc_loop;\n\nDELIMITER $$\nCREATE PROCEDURE inc_loop(IN n INT)\n BEGIN\n DECLARE _n INT DEFAULT 0;\n\n WHILE _n <= n DO\n SET  _n = _n + 1;\n END WHILE;\n\n END$$\nDELIMITER ;\n\n\n [https://postimg.org/image/cwzkd2k4x/]\n\nZ tego względu MySQL w tym zestawieniu zajmuje miejsce drugie od końca. Należy\njednak przyznać, że prawdziwe wąskie gardło baz danych - czas łączenia uplasował\nsię na umiarkowanie dobrej pozycji pośród języków skryptowych: między perlem a \npythonem.\n\nWolfram Language - Mathematica\nMathematica jest programem. Wolfram Language\n[https://en.wikipedia.org/wiki/Wolfram_Language] językiem w jakim piszemy w tym\nprogramie. Język ten sięga historią roku 1988, został zaprojektowany z myślą o\nalgebrze symbolicznej. Obecnie ma bardzo szerokie możliwości związane z\nwszelkiego rodzaju obliczeniami. Ustępuje Matlabowi w temacie wydajności\nprzetwarzania macierzy i numeryki, nadrabia wygodą i bardziej intuicyjną\nreprezentacją danych.\n\nW porównaniu z dwoma poprzednikami, kod programu inc.wl jest bardzo prosty\n\nnum  = ToExpression[$ScriptCommandLine[[2]]];\nFor[i = 0, i < num, i++];\nExit[];\n\n\n [https://postimg.org/image/75u6kbynz/]\n\nW tym teście Mathematica poradziła sobie słabo lokując się w kategorii szybkości\npętli na 4 miejscu od końca, a w kontekście szybkości włączania na 2 od końca.\n\nC#\nJęzyk C# [https://pl.wikipedia.org/wiki/C_Sharp] powstał w 2000 i aktualnie jest\nwciąż rozwijany. Ma w sobie wiele cech języków Object Pascal, Delphi, C++ i Java\n. Do działania wymaga mono, lub innego środowiska uruchomieniowego. Kompiluje\nsię nie do kodu binarnego, ale do kodu pośredniego. Niestety nie udało mi się\nzoptymalizować jego kompilacji tak jak dla Pascala, C, C++ i Fortrana. Jeśli\nznasz się na tym, proszę o komentarz, lub kontakt w tej sprawie.\n\nSam program wygląda rzeczywiście podobnie do swoich pierwowzorów.\n\nusing System;\npublic class Program\n{\n    public static void Main(string[] args)\n    {\n        for (ulong i = 1; i <= UInt64.Parse(args[0]); i++)\n        {}\n    }\n}\n\n\n [https://postimg.org/image/zanm37hzt/]\n\nSzybkość włączania jest umiarkowania, a szybkość pojedynczej pętli plasuje język\nna umiarkowanie słabej pozycji - 6 od końca.\n\nJS\nJavaScript [https://pl.wikipedia.org/wiki/JavaScript] z pewnością wielu ludziom\nmyli się z Javą. Teraz się to wydaje zabawne, ale mi też się na początku mylił.\nNic dziwnego, bo w 1995, kiedy język powstał nazwę wzięto od Javy, żeby\nJavaScript miał lepszy marketing. Tak naprawdę nie mają ze sobą wiele wspólnego.\nObecnie jest to żywy wciąż rozwijany język, który zainspirował i bardzo\nspopularyzował funkcyjny styl programowania. Za jego sprawą w wielu innych\njęzykach pojawiły się tak zwane funkcje lambda, których składnia w ES6 została\nskrócona, tak, że nazywa się je strzałkowymi\n[http://shebang.pl/artykuly/es6-funkcje-strzalkowe/].\n\nKod źródłowy jest całkiem przyjemny i wygląda tak:\n\nvar max=process.argv[2];\nfor(var i=0;i<=max;i++){}\n\n\n [https://postimg.org/image/ixhjof2g7/]\n\nW przeciwieństwie do C#, JavaScript jest umiarkowanie słaby jeśli chodzi o\nszybkość włączania, ale z szybkością pętli radzi sobie już lepiej - jak typowy\njęzyk skryptowy.\n\nPython\nPython [https://pl.wikipedia.org/wiki/Python] pojawił się w roku 1991. Jest\njęzykiem ogólnego przeznaczenia, którego głównymi cechami są: sztywne wcięcia a\nwiec czytelna i klarowna składnia. Jest też dość zwięzły i stanowi bardzo ważną\nalternatywę dla perla. Jest bardzo popularny w środowisku naukowym.\n\n#!/usr/bin/python\n\nimport sys\n\nmax=int(sys.argv[1]);\n\ncount = 0\nwhile (count < max):\n   count = count + 1\n\n\nOd razu zaznaczę, że ten kod da się napisać krócej i wykonać szybciej używając\npętli for in, ale ma ona zupełnie inną mechanikę działania - tworzy tablicę\nliczb z podanego zakresu, wrzuca całą tablicę do pamięci i ją przegląda. Więcej\no tym piszę na końcu w dziale RAM vs Procesor. Pozbycie się zmiennej max i\nnapisanie\n\nwhile (count < int(sys.argv[1])):\n\n\nwydłużyło by czas wykonywania kilkukrotnie.\n\n [https://postimg.org/image/ka4ppsf7h/]\n\nMimo, że python jest jednym z wolniejszych języków skryptowych, różnice te są na\ntyle małe, że można uczciwie przyznać, że mieści się dokładnie na środku\nrankingu. Ilość kodu nie jest przerażająca, a krzywa nauki? Jak dla mnie ciężko\nmówić o krzywej nauki w przypadku tego języka. Można w nim pisać, nawet go nie\numiejąc, po prostu zgadując jak coś powinno być napisane. Jest to bardzo\nintuicyjny język o rozsądnej wydajności w większości przypadków.\n\nRuby\nRuby [https://pl.wikipedia.org/wiki/Ruby_(j%C4%99zyk_programowania)] jest\nstosunkowo młody, jak na język. Pierwsze wydanie ujrzało światło dzienne w 1995.\nJest to dynamicznie typowany, obiektowy, interpretowany język popularny głównie\nw stanach. Jego znaczenie wzrosło po wydaniu frameworku Ruby on Rails -\nprzeznaczonego do tworzenia aplikacji internetowych, ale widziałem Ruby w innych\nzastosowaniach od analizy danych giełdowych po platformę do blogowania -\njekylla.\n\nW tym języku, nie miałem okazji dużo pisać, ale kod wygląda dość przyjemnie\n\nfor i in (1 .. ARGV[0].to_i)\nend\n\n\nZaskakujące, że ta składnia, wcale nie zamula pamięci RAM nawet przy bardzo\ndużych tablicach ani nie powoduje problemów jakie w pythonie powoduje nie\nutworzenie zmiennej max. Składnia jest więc znacznie lepsza.\n\n [https://postimg.org/image/dwvu8gvrd/]\n\nNatomiast wyniki są średnie. Przy czym ruby raczej włącza się wolniej a działa\nszybciej na tle innych języków interpretowanych.\n\nPerl\nPerl [https://pl.wikipedia.org/wiki/Perl] pochodzi miej więcej z tych czasów co\nbash (1987). Jest to język o bardzo gęstej składni. Programista w nim traktowany\njest raczej jak artysta niż rzemieślnik. Język pozwala na tworzenie zarówno\nczystego i krótkiego kodu, jak i nieczytelnej plątaniny znaków. W wielu\nrozwiązaniach został wyparty przez Pythona przez to, że jest trudniejszy w nauce\noraz paradoksalnie bardziej elastyczny.\n\nJego kod źródłowy stanowi świetnym przykładem ten sam program, można napisać\ntak:\n\n#!/usr/bin/perl\n\nfor(my $i=0;$i<=$ARGV[0];$i++){}\n\n\na można tak:\n\nfor(;$_<=$ARGV[0];$_++){}\n\n\nDziałanie będzie identyczne.\n\n [https://postimg.org/image/engw1t32v/]\n\nWyniki nie są niespodzianką. Włączanie się jest najszybsze z języków\nskryptowych. Czas wykonywania pojedynczej pętli umiarkowany.\n\nR\nR [https://pl.wikipedia.org/wiki/R_(j%C4%99zyk_programowania)] jest środowiskiem\ndo obliczeń statystycznych. W całym tym zestawieniu sporo jest języków\npowiązanych z matematyką, bo sam się nią lubię zajmować. R szczególnie często\nwystępuje w kontekście bioinformatyki.\n\nCechy charakterystyczne to: strzałki do przypisywania wartości i podobnie jak w\nMatlabie ogromna łatwość operowania na macierzach i wektorach.\n\nargs <- commandArgs(trailingOnly = TRUE)\n\nx <- 0\nwhile(x < as.numeric(args)) {\n    x <- x+1;\n}\n\n\n [https://postimg.org/image/izmjh2kzn/]\n\nPodobnie jak Wolfram Language, tak i tan wysoko poziomowy język o specjalizacji\nsprofilowanej na testowanie hipotez statystycznych i prowadzenie badań poradził\nsobie słabo w tym teście. Zarówno pod względem szybkości pętli jak i\nuruchamiania zajął trzecią pozycję od końca.\n\nPhp\nJęzyk Php [https://pl.wikipedia.org/wiki/PHP] pojawił się w roku 1995, jako\njęzyk do generowania stron internetowych. I choć można pisać backend webowy w\ninnych językach, trzeba przyznać, że PHP radzi sobie z tym zadaniem całkiem\ndobrze. Oczywiście, wielkim serwisom opłaca się kompilowanie backendu, ale w\nabsolutnej większości zastosowań PHP stanowi świetny kompromis między wygodą\njęzyka interpretowanego a wydajnością.\n\nKod php wygląda standardowo i intuicyjne\n\n<?php\n\n$max = (int)$argv[1];\n\nfor($i=0; $i<$max; $i++);\n\n\n [https://postimg.org/image/ywsw96k7d/]\n\nJego wydajność w tym teście oceniam bardzo pozytywnie. Szybkość włączania była\nśrednia, a w kategorii szybkości wykonania jednej pętli poradził sobie jako\njeden z najlepszych języków interpretowanych. Dał się wyprzedzić jedynie\nMatlabowi.\n\nFortran 95\nFortan [https://pl.wikipedia.org/wiki/Fortran] jest językiem z czasów tak\nwczesnych, że aż ciężko sobie wyobrazić, jak wtedy programowano (1957 rok), ale\nbyły to jeszcze czasy kart perforowanych, bo pierwszy komputer z klawiaturą\npowstał dopiero w 1960. Dzięki bogatemu zestawowi bibliotek do obliczeń\nmacierzowych, bardzo dobrze zoptymalizowanemu kompilatorowi,\nwielo-platformowości i dobremu wsparciu obliczeń równoległych Fortran jest wciąż\nszeroko używany w środowisku inżynierskim i naukowym, w szczególności tam, gdzie\nnumeryka jest szczególnie ciężka - w fizyce, symulacjach, modelowaniu ośrodków\nciągłych.\n\nZe składni języka widać, że typowanie jest statyczne, rzutowanie wykonywane za\npomocą instrukcji read, natomiast sama pętla ma już przyjemną składnię.\nSubiektywnie kojarzy mi się z językiem ruby.\n\nPROGRAM loop_argument_times\n  INTEGER(16) :: i, range\n  CHARACTER(len=32) :: arg\n\n  CALL get_command_argument(1, arg)\n  read( arg, '(i16)' ) range\n\n  do  i = 1, range\n  end do\n\nEND PROGRAM\n\n\n [https://postimg.org/image/4u9m2pr1b/]\n\nWyniki fortrana zasługują na wyjątkowe uznanie. W szybkości wykonywania pętli\nzajął pierwsze miejsce, a szybkości włączania czwarte. Warto wspomnieć, że jego\ntwórcy dołożyli bardzo dużo pracy do optymalizacji kompilatora ponieważ obawiali\nsię, że w przeciwnym wypadku nikt nie będzie go używać i wszyscy będą pisać w\nasemblerze.\n\nC++\nC++ [https://pl.wikipedia.org/wiki/C%2B%2B] pojawił się w 1983 jako rozszerzenie\njęzyka c o obiektowe mechanizmy abstrakcji danych i silną statyczną kontrolę\ntypów. W latach 90 stał się najbardziej popularnym językiem ogólnego\nprzeznaczenia. Jest to pierwszy język jakiego się uczyłem, w gimnazjum, kiedy po\npodłączeniu internetu w domu, z przekory chciałem pokazać rodzicom, że gry\nsieciowe nie zniszczą mi dzieciństwa. Później wiele razy c++ zaspokajał moją\nciekawość dotyczącą symulowania układów fizycznych i do czasu poznania języka \nMathematica był głównym narzędziem do robienia numeryki.\n\n#include <cstdlib>\nint main(int argc, char *argv[])\n{\n\tunsigned long long int i;\n\tunsigned long long int max = strtoul(argv[1], NULL, 0);\n\tfor(i=0; i<max; i++);\n\treturn 0;\n}\n\n\n [https://postimg.org/image/n5cxrid5p/]\n\nJak przystało na język kompilowany ogólnego przeznaczenie c++ staje na podium w\nobu rankingach. Uruchamia się jako trzeci, wykonuje pętle jako drugi najszybszy\njęzyk w zestawieniu.\n\nC\nHistoria języka C [https://pl.wikipedia.org/wiki/C_(j%C4%99zyk_programowania)] \nsięga roku 1972, wywodzi się on z języka B\n[https://pl.wikipedia.org/wiki/B_(j%C4%99zyk_programowania)] współtworzonego\nprzez twórcę C - Dennisa Ritchiego. B natomiast wywodzi się z BCPL\n[https://pl.wikipedia.org/wiki/BCPL] - zapomnianego już języka, który jednak\nwywarł ogromny wpływ na to jak dzisiaj kodujemy. To długa i ciekawa historia,\nale, żeby dygresja nie poszła zbyt daleko wrócę do C. Został zaprojektowany do\nprogramowania systemów operacyjnych i zadań dzisiaj uważanych za niskopoziomowe.\n\nC++ różni się od C głównie obiektowością, więc nie zobaczymy tego na przykładzie\nkodu źródłowego, gdzie jedyną zmianą jest użyta biblioteka.\n\n#include <stdlib.h>\n\nint main(int argc, char *argv[])\n{\n\tunsigned long long int i;\n\tunsigned long long int max = strtoul(argv[1], NULL, 0);\n\n\tfor(i=0; i<max; i++);\n\treturn 0;\n}\n\n\n [https://postimg.org/image/71q65aglt/]\n\nWyniki testu pokazują, że C jest na trzecim miejscu pod względem szybkości pętli\nustępując C++ tylko o 1%, ale zajmuje pierwsze miejsca w klasyfikacji szybkości\nuruchamiania wyprzedzając Pascala o około 1‰.\n\nPascal\nO wilku mowa. To znaczy o Pascalu\n[https://pl.wikipedia.org/wiki/Pascal_(j%C4%99zyk_programowania)] - języku,\nktóry powstał w 1970 roku i w przeciwieństwie do C, nie udostępniał mechanizmów\nniskopoziomowych, lecz został zaprojektowany do tworzenia strukturalnych\naplikacji.\n\nMi osobiście z Pascalem kojarzy się przeciążanie operatorów, bo mimo, że jest to\nmożliwe również w innych językach, pierwszy raz w życiu przeciążałem operator\ndodawania i mnożenia macieży właśnie w Pascalu.\n\nSam kod przypomina mi nieco fortrana. Kiedy się go uczyliśmy, profesor który\nobjaśniał jego składnię mówił, że nie będziemy go używać, ale będziemy\nprogramować w innych językach tak jak w nim. Na przykładzie tego kodu widać, że \nPascal wymaga definiowania zmiennych przed rozpoczęciem wykonywania logiki.\nPrzyznaję, faktycznie tak piszę dziś we wszystkich języakch skryptowych, jeśli\nchcę używać zmiennych globalnych.\n\nprogram Project1;\n\nUses sysutils;\n\n{$mode objfpc}\n\nvar\n  I,r: QWord;\nbegin\n\n  r:=StrToQWord(ParamStr(1));\n\n  for I := 1 to r do\nend.\n\n\n [https://postimg.org/image/n78yprgfb/]\n\nPascal zajął piąte miejsce w szybkości wykonywania pętli i drugie w kategorii\nszbykości startowania programu.\n\nJava\nJava [https://pl.wikipedia.org/wiki/Java] jest młodym językiem na tle kilku\nostatnio omawianych. Powstała w 1995. Swój sukces zawdzięcza bardzo bardzo\ndobrej obsłudze błędów i wyjątków oraz niezależności od systemu na jakim\nuruchamiamy platformę java. Korporacje kochają ją za to, że można w niej pisać\nbezpieczne, dobrze zabezpieczone aplikacje w rozproszonej strukturze sieciowej\nbez szczególnego dbania o systemy operacyjne poszczególnych maszyn.\n\npublic class inc {\n    public static void main(String[] args) {\n\tlong max=Long.parseLong(args[0]);\n\tfor (long i = max; i >= 0; i--) {\n\t}\n    }\n}\n\n\n [https://postimg.org/image/6gjud1edt/]\n\nJava zajęła czwarte miejsce pod względem szybkości pętli ustępując liderowi\njedynie o 1-2%, ale jej włączanie trwało około 40 razy dłużej niż programów z\nczołówki rankingu. W kategorii szybkości włączania java była czwarta od końca.\n\nPodsumowanie\nNa koniec załączam wykres porównujący czas trwania pojedyńczej pętli w każdym\njęzyku wykonany za w pliku analysis.nb\n\nBarChart[Log[SortBy[nameABlist, #[[2]] &][[All, 2]]],\n ChartStyle -> \"DarkRainbow\",\n ChartLegends -> SortBy[nameABlist, #[[2]] &][[All, 1]],\n AxesLabel -> \"Log[a]\"]\n\n\n [https://postimg.org/image/4t81fwugb/]\n\nWykres ma skalę logarytmiczną, im niższa wartość tym lepiej.\n\nJeśli jesteś ciekaw dokładnych wyników poniżej prezentuję tabelę.\n\nlanguageone loop time [s]loop time error [s]launch time [s]launch time error [s]\nlaunch to loop ratio [s]inc.f953.50468*10^(-10)1.07954*10^(-12)1.72753*10^(-3)\n5.04969*10^(-6)4.92921*10^(6)inc.cpp3.5061*10^(-10)1.41184*10^(-12)\n1.38989*10^(-3)5.77246*10^(-6)3.9642*10^(6)inc.c3.53343*10^(-10)1.01268*10^(-12)\n1.37686*10^(-3)3.62949*10^(-6)3.89666*10^(6)inc.java3.55209*10^(-10)\n1.25794*10^(-12)5.70852*10^(-2)6.74846*10^(-5)1.60709*10^(8)inc.p\n3.69329*10^(-10)2.36513*10^(-12)1.37772*10^(-3)4.0445*10^(-6)3.73033*10^(6)\ninc.m.sh2.69198*10^(-9)2.10845*10^(-11)5.286424.69114*10^(-2)1.96377*10^(9)\ninc.php8.89544*10^(-9)2.62779*10^(-11)2.13014*10^(-2)3.08575*10^(-5)\n2.39464*10^(6)inc.rb3.64662*10^(-8)1.2021*10^(-10)3.40208*10^(-2)4.46364*10^(-5)\n9.32938*10^(5)inc.perl4.24243*10^(-8)1.23231*10^(-10)2.15686*10^(-3)\n4.64159*10^(-6)5.08403*10^(4)inc.js6.14158*10^(-8)2.27239*10^(-10)\n4.14627*10^(-2)6.47284*10^(-5)6.75115*10^(5)inc.python6.29119*10^(-8)\n1.69606*10^(-10)1.02831*10^(-2)1.5976*10^(-5)1.63452*10^(5)inc.cs1.59136*10^(-7)\n5.1884*10^(-10)1.06194*10^(-2)2.41509*10^(-5)6.67321*10^(4)inc.wl4.87908*10^(-7)\n1.24762*10^(-9)1.91462*10^(-1)2.2833*10^(-4)3.92415*10^(5)inc.r7.28671*10^(-7)\n2.11159*10^(-9)1.20264*10^(-1)1.79633*10^(-4)1.65045*10^(5)inc.sql.sh\n2.24287*10^(-6)4.28608*10^(-9)5.33614*10^(-3)1.34152*10^(-5)2.37916*10^(3)\ninc.bash4.23198*10^(-6)5.03612*10^(-9)1.8443*10^(-3)4.70927*10^(-6)\n4.35801*10^(2)Analogicznie dla czasów włączania programów rysujemy drugi wykres\n\nBarChart[Log[SortBy[nameABlist, #[[3]] &][[All, 3]]],\n ChartStyle -> \"DarkRainbow\",\n ChartLegends -> SortBy[nameABlist, #[[3]] &][[All, 1]],\n AxesLabel -> \"Log[b]\"]\n\n\n [https://postimg.org/image/ll9o87qxr/]\n\nTutaj też najlepsze wartości to najniższe. Wartość zerowa oznacza czas włączania\nrówny 1 sekundzie.\n\nPoniżej ta sama tabela co poprzednio, ale posortowana po czasach włączania\nprogramu:\n\nlanguageone loop time [s]loop time error [s]launch time [s]launch time error [s]\nlaunch to loop ratio [s]inc.c3.53343*10^(-10)1.01268*10^(-12)1.37686*10^(-3)\n3.62949*10^(-6)3.89666*10^(6)inc.p3.69329*10^(-10)2.36513*10^(-12)\n1.37772*10^(-3)4.0445*10^(-6)3.73033*10^(6)inc.cpp3.5061*10^(-10)\n1.41184*10^(-12)1.38989*10^(-3)5.77246*10^(-6)3.9642*10^(6)inc.f95\n3.50468*10^(-10)1.07954*10^(-12)1.72753*10^(-3)5.04969*10^(-6)4.92921*10^(6)\ninc.bash4.23198*10^(-6)5.03612*10^(-9)1.8443*10^(-3)4.70927*10^(-6)\n4.35801*10^(2)inc.perl4.24243*10^(-8)1.23231*10^(-10)2.15686*10^(-3)\n4.64159*10^(-6)5.08403*10^(4)inc.sql.sh2.24287*10^(-6)4.28608*10^(-9)\n5.33614*10^(-3)1.34152*10^(-5)2.37916*10^(3)inc.python6.29119*10^(-8)\n1.69606*10^(-10)1.02831*10^(-2)1.5976*10^(-5)1.63452*10^(5)inc.cs1.59136*10^(-7)\n5.1884*10^(-10)1.06194*10^(-2)2.41509*10^(-5)6.67321*10^(4)inc.php\n8.89544*10^(-9)2.62779*10^(-11)2.13014*10^(-2)3.08575*10^(-5)2.39464*10^(6)\ninc.rb3.64662*10^(-8)1.2021*10^(-10)3.40208*10^(-2)4.46364*10^(-5)9.32938*10^(5)\ninc.js6.14158*10^(-8)2.27239*10^(-10)4.14627*10^(-2)6.47284*10^(-5)\n6.75115*10^(5)inc.java3.55209*10^(-10)1.25794*10^(-12)5.70852*10^(-2)\n6.74846*10^(-5)1.60709*10^(8)inc.r7.28671*10^(-7)2.11159*10^(-9)1.20264*10^(-1)\n1.79633*10^(-4)1.65045*10^(5)inc.wl4.87908*10^(-7)1.24762*10^(-9)1.91462*10^(-1)\n2.2833*10^(-4)3.92415*10^(5)inc.m.sh2.69198*10^(-9)2.10845*10^(-11)5.28642\n4.69114*10^(-2)1.96377*10^(9)Ciekawostki\nPodczas prowadzenia niektórych testów zdarzało się, że zmiany w kodzie, czy\nsposobie kompilacji bardzo istotnie wpłynęły na wyniki, mimo, że teoretycznie,\nkażdy program miał robić to samo: puste pętle.\n\nPierwszy przykład to zmiana sposobu przebiegania pętli\n\nRAM vs Procesor\nMamy dwie możliwości przebiegania po zakresie od 1 do n. Pierwsza to zacząć od 1\ni zwiększać ją o jeden co chwilę sprawdzając czy doszliśmy już do n, czy nie.\nDrugi, to stworzyć tablicę od 1 do n, załadować ją do pamięci RAM i wykonać\nciało pętli dla każdej z tych liczb z pamięci.\n\nPierwsza metoda, bardziej konserwatywna jest typową konstrukcją pętli, jaką\nchciałem testować. Jednak, ta druga, okazuje się być bardziej wydajna dla\nrozmiarów tablic, które mieszczą się nam w pamięci operacyjnej. Prezentuję na\nprzykładzie języka R, jak zmiana sposobu wykonywania pętli wpłynęła na szybkość\njej wykonywania.\n\nOto wycinek git diff pokazujący, jak zmienił się kod źródłowy:\n\n [https://postimg.org/image/rffk61izj/]\n\nWidzimy, że zamieniliśmy pętlę ładującą wszystko do RAM, na iterującą co jeden\nze sprawdzaniem warunku co krok. Poniżej dodaję kod do wykonania stosownego\nwykresu:\n\ngitr = SQLExecute[conn,\n   \"SELECT git FROM log WHERE name='inc.r' GROUP BY git\"];\ndr = SQLExecute[conn,\n     \"SELECT size,time FROM log WHERE name='inc.r' AND git='\" <>\n      ToString[#] <> \"'\"] & /@ Flatten[gitr];\nListLogLogPlot[{Flatten[dr[[#]] & /@ Range[4], 1], dr[[5]]},\n  PlotRange -> Full,\n  PlotLabel -> \"Differencies in loop time for inc.r\",\n  BaseStyle -> {FontSize -> 14}, ImageSize -> 800,\n  PlotLegends ->\n   Placed[SwatchLegend[{\"while loop\", \"for in loop\"},\n     LegendMarkerSize -> {30, 30}], {0.3, 0.75}]]\n\n\n [https://postimg.org/image/hvakxcp0n/]\n\nWidzimy tutaj ogromną przewagę pętli For in. Kiedy spojrzymy na tabelę:\n\n [https://postimg.org/image/5op4nf84x/]\n\nOkazuje się być ona 22 krotna. To znaczy: w języku R, jeśli starczy nam pamięci\nRAM, to pusta pętla for in wykona się 22 razy szybciej niż pętla while. Podobne\njakościowo rezultaty dostajemy w języku python, a intuicja podpowiada, że należy\nten wniosek rozszerzyć na inne języki, w których istnieją konstrukcję pętli,\nktóre najpierw ładują zakres do RAM, a potem po nim przebiegają.\n\nOstatecznie, żeby wyrównać szanse, w końcowej wersji wykorzystałem pętlę\niterującą.\n\nOptymalizacja kompilacji\nKtoś przyzwyczajony do wysokopoziomowych języków, szczególnie interpretowanych,\nmógł by pomyśleć: \"kompilacje jak kompilacje, nic ciekawego\". Okazuje się\njednak, że sposób w jaki kompilujemy program może drastycznie zmienić jego\nwydajność.\n\nPascal\nPrzyjrzymy się uważniej linijce programu inc.bash zawierającej kompilację\npascala.\n\nfpc -O2 inc/inc.p -o\"$TMP/p\" -Tlinux &>/dev/null\n\n\nZnajduje się tu flaga -O2, która sporo zmienia. Włącza ona analizator przepływu\ndanych asemblera. On z kolei umożliwia procedurze eliminacji wspólnych\npod-wyrażeń, na usunięcie niepotrzebnych przeładowań rejestru wartościami, które\njuż zawierał. Więcej o falgach optymalizujących kompilację Pascala można\nprzeczytać w dokumentacji\n[http://www.math.uni-leipzig.de/pool/tuts/FreePascal/prog/node12.html].\n\nWpływ tej flagi można zobaczyć na tym wykresie:\n\n [https://postimg.org/image/690frqi19/]\n\nA liczbowe wyniki analizy w tabeli poniżej\n\n [https://postimg.org/image/gkdnzppzj/]\n\nMożna z niej wyczytać, że tylko dzięki usunięciu niepotrzebnych przeładowań\nrejestru program przyśpieszył 5.6 raza. Inaczej ujmując - trzy znaki w komendzie\nkompilacyjnej -O2 przyśpieszyły program kilkukrotnie.\n\nC++\nW przypadku c++ sytuacja jest nawet bardziej złożona. Podobnie jak w Pascalu\nmamy do wyboru różne flagi mające różne zastosowania. Ostatecznie zdecydowaliśmy\nsię, że wydajność c++ najlepiej odda zastosowanie -O1.\n\ng++ -O1 -o \"$TMP/cpp\" 'inc/inc.cpp';\n\n\nZ dokumentacji [https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html] \nkompilatora wynika, że dzięki niej kompilator próbuje zredukować wielkość kodu i\nczas wykonywania, ale nie stosuje tych optymalizacji, które mogły by zająć\nwięcej czasu.\n\nByło to dla mnie dużym zaskoczeniem, ale kiedy stosowałem głębszą optymalizację,\nto znaczy flagi -O2, -O3 i -Ofast, okazywało się, że pętla jest całkowicie\npomijana. Czas wykonywania programu spadał do rzędu tysięcznych, czasem setnych\nsekundy, a więc całkowicie zlewał się z szumem i był niezależny od parametru,\njaki wstawiałem. Myślałem, że sytuację popraw wykorzystanie zmiennych\nzapisywanych, nie na 8 bajtach, tylko na 16. Okazało się, że pętle po zmiennych\ntypu uint128_t z biblioteki boost/multiprecision/cpp_int.hpp również są\npomijane. Dopiero po użyciu zmiennych zapisywanych na 32 bajtach kompilator nie\nradził sobie z wycięciem pustej pętli z kodu programu. Jednak taki test był dla \nc++ dość nieuczciwy, bo żaden inny język nie dochodził nigdy do takich zakresów.\nArchitektura procesora w moim laptopie (x86_64) świetnie nadaje się do liczb 8\nbajtowych - 64bitowych. Używanie liczb 256 bitowych nawet przy najwyższym\nstopniu optymalizacji kompilacji nie dawało tak dobrych efektów jak -O1 dla\nliczby 64 bitowej (unsigned long long int).\n\nDla porównania wyników jakie dała flaga -O1 oraz jej brak załączam wykres\n\n [https://postimg.org/image/i9e2gvq5z/]\n\nOraz tabelę\n\nlanguage and parametesone loop time [s]loop time error [s]launch time [s]launch\ntime error [s]c++ -O1 optimization3.50722*10^(-10)1.43966*10^(-12)\n1.38984*10^(-3)5.808*10^(-6)c++ no optimization2.54525*10^(-9)9.24271*10^(-12)\n1.30566*10^(-3)2.83328*10^(-6)Fortran\nTutaj też flaga optymalizująca znacznie wpływa na wyniki. Podobnie jak\nwcześniej, najlepiej oddaje się szybkość pustych pętli dzięki fladze -O1.\n\n [https://postimg.org/image/q7l6502r7/]\n\nlanguageone loop time [s]loop time error [s]launch time [s]launch time error [s]\nf -O1 optimization3.50474*10^(-10)1.0804*10^(-12)1.72753*10^(-3)5.05088*10^(-6)f\nno optimization3.07201*10^(-9)1.12286*10^(-11)1.63708*10^(-3)3.55385*10^(-6)\nSposób pomiaru czasu\nDo pomiaru czasu wykonywania skryptu wykorzystywaliśmy dwie metody. Pierwsza to\n\n/usr/bin/time -o \"$TMP/time\" -f \"%e\" $comm $size &> /dev/null; #oryfinally %U instead %e\ntime=\"$(cat \"$TMP/time\" 2> /dev/null)\";\n\n\nDruga to:\n\ntime=`bash util/timing.sh $comm $size`\n\n\ngdzie plik util/timing.sh zawierał poniższy kod\n\n#!/usr/bin/env bash\nSTART=$(date +%s.%N)\n# do something #######################\n\n\"$@\" &> /dev/null\n\n#######################################\nEND=$(date +%s.%N)\nDIFF=$( echo \"scale=6; (${END} - ${START})*1/1\" | bc )\necho \"${DIFF}\"\n\n\nKtóry sprawdzał aktualny czas, wykonywał podaną instrukcję i ponownie sprawdzał\naktualny czas. Następnie za pomocą programu bc obliczał różnicę między tymi\nczasami i zwracał ją z dokładnością do mikrosekund.\n\nZaletą pierwszej metody była prostota, mniejsza ilość kodu. Z resztą narzędzie \nusr/bin/time jest dedykowanym narzędziem do pomiarów czasu skryptów w systemie \nlinux. Zaletą drugiej metody była wyższa precyzja (mikro vs setne sekundy).\nOczywiście mimo wykorzystania 6 cyfr po przecinku, zamiast dwóch, precyzja nie\nsięgała ona tak głęboko, ale przy bardzo szybkich programach pozwoliła mierzyć\nczas startowania programów z błędem pomiarowym niższym, niż ten czas.\n\nŻeby dać tym metodom równe szanse włączyłem pętle w języku bash, które średnio\ntrwały około 4.19 sekundy. Jest to wystarczająco długo, aby ograniczenie liczby\ncyfr wyników nie stało się kluczowe i wystarczająco krótko, żeby można było\npowtórzyć pomiar wiele razy. Wyniki zestawiłem na poniższym histogramie:\n\n [https://postimg.org/image/wuuhagvov/]\n\noraz w tabeli\n\nmethodtime [s]standard dev [s]uti/timing.sh4.2000.117/usr/bin/time -f \"%e\"4.178\n0.119Widać, że zmiana metody pomiaru z /usr/bin/time na util/timing.sh nie wymaga\nkasowania poprzednich wyników. Seria pomiarowe z /usr/bin/time i tak nie\ndotyczyła wyników o czasach poniżej 0.4 sec bo przy błędzie rzędu 0.1 i zakresie\n2 liczb po przecinku nie miało to sensu. Warto zwrócić uwagę na to, że rozkład\nczasów potrzebnych na wykonanie programu jest podobny do tego, jaki miał rozkład\nczasu selektów po indeksowanym kluczu w bazie danych.\n\nTesty\nJeśli wrócili byśmy do opisu instalacji, to zobaczyli byśmy, że ostatnia linia\npliku install.sh odpowiada za pobranie biblioteki shunit2\n[http://ssb.stsci.edu/testing/shunit2/shunit2.html].\n\ncurl -L \"https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/shunit2/shunit2-2.1.6.tgz\" | tar zx\n\n\nZastosowaliśmy ją w skrypcie testującym, które kod pokazuję poniżej\n\n> test.sh\n\n\n#!/usr/bin/env bash\n\n# args: min, mix, file - function check if\n# all numbers in file are in range (min,max)\nfunction columnInRange\n{\n    min=\"$1\";\n    max=\"$2\";\n\n    cat | while read n\n    do\n        echo $n;\n        assertTrue '[ 1 -eq $(echo $min\"<\"$n | bc -l) ]'\n        assertTrue '[ 1 -eq $(echo $n\"<\"$max | bc -l) ]'\n    done\n}\n\n\nZaczynamy od definiowania funkcji pomocniczej, która przyjmuje dwa parametry i\nstrumień danych. Sprawdza ona czy strumień zawiera liczby z zakresu określonego\nprzez te parametry. Za sprawdzenie odpowiadają funkcje assertTrue.\n\nDruga funkcja pomocnicza wykonuje dzielenie przez siebie wybranych kolumn z pary\nplików.\n\n# args: col, method and parameter for 1 file, method and parameter for 2 file\n# function print ratio of given column form two files \"log/out.[method][parameter].log\n# col number | meaning\n# 3          | size\n# 4          | time\n# 5          | speed\nfunction ratioOfColumns\n{\n    col=\"$1\";\n\n    awk -F \"|\" 'FNR==NR{a[FNR] = $'$col'; next} {if(/inc/) printf \"%12.6f\\n\", $'$col'/a[FNR]}' \\\n        log/out.$2.log log/out.$3.log\n}\n\n\nNa tą chwilę wygląda to dość enigmatycznie, ale pliki te w założeniu mają\nodpowiadać temu, co inc.bash wyświetla w konsoli. Zakres parametru $1 to 3,4,5,\na dostępne wartości $2 i $3 to l1, l2, t1 i t2. Odpowiedź na pytanie skąd biorą\nsię tepliki zawarta jest w kolejnej funkcji:\n\noneTimeSetUp() {\n\n    for n in 1 2\n    do\n        for method in \"l\" \"t\"\n        do\n              bash inc.bash -$method $n | tee log/out.$method$n.log\n        done\n    done\n}\n\n\nKtóra zgodnie z dokumentacją shunit2 wykonana zostaje na samym początku\ntestowania. Odpoiwada ona za wywołanie programu inc.bash cztery razy ze\nwszystkimi kombinacjami parametrów -l i -t oraz liczb 1 i 2 a następnie\nprzekierowanie wyjścia do odpowiednio nazwanych plików.\n\nKolejna funkcja wykona się po zakończeniu testowania - posprząta po testach.\n\noneTimeTearDown() {\n    rm -rf log/out.*.log\n}\n\n\nMożemy przejść do właściwych funkjci zawierających testy:\n\n# in database there are 16 columns of parameters\ntest_parameters_are_proporly_estimated()\n{\n    infile=$(grep inc config/parameters.csv | wc -l);\n    inbase=$(sqlite3 log/log.db \"SELECT count(*) FROM result WHERE a>ea and b>eb\");\n    echo $infile;\n    echo $inbase;\n    assertEquals $infile $inbase;\n}\n\n\nPierwszy z testów sprawdza, czy plik config/parameters.csv został poprawnie\nzaładowany do bazy przez skrypt util/parameters_load.pl.\n\n# ratio of loops for 2 sec to 1 sec is between 1.9 and 2.1\ntest_ratio_of_loops_in_proper_range()\n{\n     ratioOfColumns 3 t1 t2 | columnInRange 1.95 2.2\n}\n\n\nKolejny test bierze stosunek ilości pętli dla 2 sekund i 1 sekundy. Intuicyjnie\nczujemy, że powinien być on bliski dwójki, ale dopuszczamy odstępstwa w\ngranicach błędu pomiarowego.\n\n# ratio of time for test with 2 sec and 1 sec should be near to 2\ntest_ratio_of_time_should_be_near_2_for_time_based_test()\n{\n    ratioOfColumns 4 t1 t2 | columnInRange 1.5 4;\n}\n\n\nNastępny test określa stosunek czasów dla programu zakładającego wykonywanie w 2\nsekundy do 1 sekundy. Gdyby środowisko było idealne, to ten stosunek powinien\nwynosić dwa. jednak ponieważ na gitlabie moc obliczeniowa przydzielana runnerom\njest dość niestabilna, pozwalamy na dużą granicę błędu pomiarowego.\n\n# ratio of time for test with 2 and 1 loop should be near to 1\ntest_ratio_of_time_should_be_near_1_for_loop_based_test()\n{\n    ratioOfColumns 4 l1 l2 | columnInRange 0.4 1.8;\n}\n\n\nPodobnie jest dla czasu wykonywania jednej i dwóch pętli. Stosunek tych czasów\npowinien być bliski jedności, ponieważ czas wykonywania pętli jest rzędy\nwielkości niższy od czasu włączania programu. Jednak i tutaj dopuszczamy duże\nróżnice związane ze zmiennością dostępnej mocy obliczeniowej.\n\n# any free language (without matlab and mathematica) start in time small than 0.2 sec\ntest_start_no_longer_than_150_milisecond()\n{\n    # time of programs for 1 loop\n    awk '/inc/ {print $6}' log/out.l1.log | columnInRange 0.001 0.15;\n}\n\n\nKolejny test sprawdza, czy wszystkie programy startują szybciej niż w 0.15 sec i\nwolniej niż 1 milisekundę.\n\n# ratio of speed for time based test should be near to 1\ntest_speed_should_be_not_dependent_from_loops_in_limit()\n{\n    ratioOfColumns 5 t1 t2 | columnInRange 0.5 1.4;\n}\n\n\nNastępny dotyczy czasów długich w porównaniu z czasem włączania programu, a 1-2\nsekund za takie można uznać i wymaga aby stosunek prędokości wykonywania pętli\ndla tych czasów był bliski jedności, a więc nie zmieniał się wraz z czasem.\n\n# ratio of speed for 2 and 1 loop should be near to 2\ntest_ratio_of_speed_for_small_loop_number_in_proper_range()\n{\n    ratioOfColumns 5 l1 l2 | columnInRange 1.1 7.0;\n}\n\n\nZupełnie odwrotnie dla 1-2 pętli, jeśli czas jest prawie taki sam, to mierzona\nprędkość powinna być prawie dwa razy wyższa dla 2 pętli niż dla jednej. Nie\nmożemy jednak mierzyć tego zbyt dokładnie, ponieważ czasy wykonywania programów\ndla tak niewielkich ilości pętli są zwykle bliskie błędom pomiarowym.\n\ntest_ratio_of_speed_for_1_and_2_loops_form_database()\n{\n    for n in 1 2\n    do\n        sqlite3 log/log.db \"SELECT name, avg(size/time) as speed FROM \\\n            log WHERE size=\"$n\" AND name!='inc.m.sh' AND name!='inc.wl' GROUP BY name\" \\\n            > log/out.l$n.speed.log\n    done\n\n    ratioOfColumns 2 l1.speed l2.speed | columnInRange 1.1 7.0;\n}\n\n\nOstatni test powtarza to samo co poprzedni, ale tym razem wydobywa dane z bazy,\na nie konsoli.\n\n. shunit2-2.1.6/src/shunit2\n\n\nJako ostatnią linię skryptu testującego dołączamy zgodnie z dokumentacją program \nsh2unit.\n\nCiągła integracja\nNa sam koniec opiszę proces ciągłej integracji, który wdrożyłem w tym projekcie.\nCiągła integracja jest to wykonywanie instalacji i testów automatycznych przy\nkażdym pushu na serwer z repozytorium. Możemy do tego wykorzystywać różne\nnarzędzia. Ja zdecydowałem się na gitlab-ci\n[https://about.gitlab.com/gitlab-ci/].\n\nSkładnia pliku z instrukcjami dla runnera jest podobna do tej z travisa\n[https://docs.travis-ci.com/]. Zaczyna się od wybrania obrazu dystrybucji na\nktórej uruchamiany testy:\n\n## Select image from https://hub.docker.com/_/php/\nimage: ubuntu:16.10\n\n\nNastępnie podpinamy serwisy, które mogły by być instalowane ręcznie, ale dla\nuproszczenia przygotowano je w formie gotowych do wpięcia komponentów:\n\nservices:\n- mysql:8\n- php:7\n\n\nDefiniujemy zmienne wykorzystywane do łączenia z bazą danych:\n\nvariables:\n  # Configure mysql service (https://hub.docker.com/_/mysql/)\n  MYSQL_DATABASE: inc\n  MYSQL_ROOT_PASSWORD: pass\n\n\nOkreślamy zestaw instrukcji do wykonania przed testami:\n\nbefore_script:\n- bash install.sh\n- perl util/parameters_load.pl\n- export MYSQL_PWD=$MYSQL_ROOT_PASSWORD;\n- export MYSQL_HOST=\"mysql\";\n- echo \"SELECT 'OK';\" | mysql --user=root \"$MYSQL_DATABASE\"\n\n# local variables\n#  https://dev.mysql.com/doc/refman/5.7/en/environment-variables.html\n\n\nW ich skład wchodzi instalacja naszych zależności, ładowanie parametrów,\neksportowanie zmiennych środowiskowych do łączenia z bazą i prosty test na\npołączenie.\n\nGłówna część, czyli testowanie zawarte jest w poniższym fragmencie kodu;\n\ntest:\n  image: mysql\n  image: php\n  script:\n  - bash test.sh\n\n\nŻeby przetestować kod lokalnie wykonujemy komendę:\n\nsudo gitlab-ci-multi-runner exec docker test\n\n\nTo już wszystko. Mam nadzieję, że ten artykuł uświadomił Ci, że wybór języka\nmoże mieć ogromne znaczenie dla wydajności oraz przybliżył Ci historię kilku z\nnich. Jednak najważniejsze, że ten kod został przygotowany tak, aby łatwo było\ngo rozszerzyć o pomiary dotyczące zadań jak na przykład zapis do pliku, albo\nwykonywanie całkowania numerycznego. Jeśli będziesz zainteresowany rozwijaniem\ntego softu daj znać, mam parę koncepcji, w którą stronę można by rozwinąć ten\nprojekt.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:33:18.000Z",
            "updated_at": "2021-04-20T20:33:48.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f3ae92fb35425592d0bc6",
            "uuid": "e5d41ab6-92b5-4cbf-ac46-839797ab23aa",
            "title": "Pomiar ilości tekstu i kodu w moich wpisach",
            "slug": "pomiar-ilosci-tekstu-i-kodu-w-moich-wpisach",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Opis projektu\\n\\nZe czystej ciekawości chciałem sprawdzić jaką część moich wpisów stanowi tekst, a jaką kod źródłowy. Napisałem program, który to udzielił mi odpowiedzi na to pytanie.\\n\\nCały projekt jest napisany w perlu i składa się z jednego 21 liniowego pliku.\\n\\n## Instalacja\\n\\nInstalujemy zależności:\\n\\n```bash\\nsudo apt-get install wget cpanminus\\nsudo cpanm install HTML::TagParser\\nsudo cpanm install URI::Fetch\\n```\\n\\nPobieramy kod źródłowy z gist\\n\\n```bash\\n wget https://gist.githubusercontent.com/gustawdaniel/a4bb55473e8e4399a5b087f1979e78d0/raw/3427bbd1f6b68c75e0481eaee0fc6f466db8af6d/count_text_and_code.pl -O count_text_and_code.pl\\n```\\n\\nI gotowe.\\n\\n## Działanie\\n\\nPo włączeniu program drukuje nam na ekranie tabelę z liczbą znaków w tekstach (text), liczbą znaków prezentowanych kodów źródłowych (code) oraz tytułami wpisów (title).\\n\\n{% include video.html url='https://www.dropbox.com/s/bh4n1ko7ygfu3ko/10.mp4?dl=1' webm='https://www.dropbox.com/s/9ngx754jsj9wzxj/10.webm?dl=1' %}\\n\\n\\n## Kod źródłowy\\n\\nKod tego programu jest dość mocno skondensowany. Zaczyna się od załadowania bibliotek:\\n\\n```perl\\n#!/usr/bin/env perl\\n\\nuse warnings;\\nuse strict;\\n\\nuse HTML::TagParser;\\n```\\n\\nPóźniej następuje deklaracja zmiennych\\n\\n```perl\\nmy $url = 'https://blog.gustawdaniel.pl';\\nmy @tags = (\\\"h1 h2 h3 h4 li p\\\",\\\"pre\\\");\\n```\\n\\nPierwsza z nich to lokalizacja strony głównej tego bloga. Druga zawiera listę tagów traktowanych jako tekst (h1 h2 h3 h4 li p) oraz tagów traktowanych jako kod (pre).\\n\\nCzęść wykonywalna skryptu rozpoczyna się rysowaniem nagłówka tabeli z wynikami\\n\\n```perl\\nprint \\\"|     text |     code | title \\\\n\\\";\\n```\\n\\nTutaj kończy się wstęp i zaczyna magia. Kolejna linia pobiera zawartość strony głównej bloga, wyciąga z niej wszystkie elementy z tagiem `h2` i zapisuje do tablicy.\\n\\n```perl\\nmy @list = HTML::TagParser->new( $url )->getElementsByTagName( \\\"h2\\\" );\\n```\\n\\nZajmujemy się tagiem `h2` ponieważ na stronie głównej bloga wszystkie linki do wpisów znajdują się wewnątrz takiego tagu.\\n\\n[![scr2.png](https://s1.postimg.org/fb5elwfgv/scr2.png)](https://postimg.org/image/r09e9v6ff/)\\n\\nNaturalnym kolejnym krokiem jest przebiegnięcie pętlą po tej liście:\\n\\n```perl\\nforeach my $elem ( @list ) {\\n```\\n\\nWewnątrz pętli wyciągamy wartość atrybutu `href` dla pierwszego dziecka elementu `h2` ze strony głównej. Dołączamy ją do adresu bloga - `$url` i ponownie ściągamy całą zawartość metodą `new` obiektu `TagParser`. Pobraną treść zapisujemy do zmiennej `$post`.\\n\\n```perl\\n    my $post = HTML::TagParser->new( $url.$elem->firstChild()->getAttribute( \\\"href\\\" ) );\\n```\\n\\nZa chwilę go przetworzymy, ale przed przejściem do kolejnej części programu inicjalizujemy dwuelementową tablicę wewnątrz której będziemy przechowywać tekst oraz kod wyciągnięty z posta.\\n\\n```perl\\n    my @str = (\\\"\\\",\\\"\\\");\\n```\\n\\nWchodzimy do kolejnego poziomu pętli, która iteruje właśnie po tych dwóch elementach. To znaczy, że dla `$i=0` wyciągamy teksty, a dla `$i=1` interesuje nas zliczanie ilości kodu źródłowego.\\n\\n```perl\\n    foreach my $i ( (0,1) ) {\\n```\\n\\nTaką elastyczność wyboru aktualnie zliczanych elementów dostajemy dzięki zdefiniowanej wcześniej zmiennej `@tags`. Teraz wybieramy jej pierwszy element i funkcją `split` przekształcamy go na tablicę zawierającą tagi. Funkcja `map` pozwala nam wykonać wybranie listy elementów po tagu dla każdego z wyodrębnionych tagów. Ostatecznie wszystkie te elementy trafiają do wspólnej tablicy `@elements`.\\n\\n```perl\\n        my @elements = map {$post->getElementsByTagName($_)} split / /, $tags[$i];\\n```\\n\\nŻeby wydobyć z nich tekst wykorzystamy metodę `innerText` i prostym mapowaniem oraz rzutowaniem tablicy na string wyciągniemy szukane teksty.\\n\\n```perl\\n        $str[$i] = join(\\\"\\\",map {$_->innerText} @elements);\\n```\\n\\nMożemy na tym zakończyć ciało pętli po indeksach (0,1)\\n\\n```perl\\n    }\\n```\\n\\nZostało nam już tylko obliczenie ilości znaków i wydrukowanie wyników - jedna linia kodu:\\n\\n```perl\\n    printf(\\\"| %8d | %8d | %-60s \\\\n\\\", (map {$str[$_] =~ y===c} (0,1)), $elem->innerText);\\n```\\n\\nNa sam koniec zamykamy pętlę po postach.\\n\\n```perl\\n}\\n```\\n\\nDziałanie programu jest gwarantowane do momentu zmiany organizacji linków na stronie głównej w kodzie `html`.\\n\\n## Podsumowanie\\n\\nWyniki są pomiarów przedstawia poniższy screen:\\n\\n[![screen.png](https://s11.postimg.org/niq06o56r/screen.png)](https://postimg.org/image/o88sj15q7/)\\n\\nJest to jeden z najkrótszych wpisów. Jest to też jeden z najkrótszych kodów źródłowych. Właśnie gęstość składni w perlu jest moim zdaniem jedną z największych zalet tego pięknego języka.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"opis-projektu\">Opis projektu</h2>\n<p>Ze czystej ciekawości chciałem sprawdzić jaką część moich wpisów stanowi tekst, a jaką kod źródłowy. Napisałem program, który to udzielił mi odpowiedzi na to pytanie.</p>\n<p>Cały projekt jest napisany w perlu i składa się z jednego 21 liniowego pliku.</p>\n<h2 id=\"instalacja\">Instalacja</h2>\n<p>Instalujemy zależności:</p>\n<pre><code class=\"language-bash\">sudo apt-get install wget cpanminus\nsudo cpanm install HTML::TagParser\nsudo cpanm install URI::Fetch\n</code></pre>\n<p>Pobieramy kod źródłowy z gist</p>\n<pre><code class=\"language-bash\"> wget https://gist.githubusercontent.com/gustawdaniel/a4bb55473e8e4399a5b087f1979e78d0/raw/3427bbd1f6b68c75e0481eaee0fc6f466db8af6d/count_text_and_code.pl -O count_text_and_code.pl\n</code></pre>\n<p>I gotowe.</p>\n<h2 id=\"dzia%C5%82anie\">Działanie</h2>\n<p>Po włączeniu program drukuje nam na ekranie tabelę z liczbą znaków w tekstach (text), liczbą znaków prezentowanych kodów źródłowych (code) oraz tytułami wpisów (title).</p>\n<p>{% include video.html url='<a href=\"https://www.dropbox.com/s/bh4n1ko7ygfu3ko/10.mp4?dl=1\">https://www.dropbox.com/s/bh4n1ko7ygfu3ko/10.mp4?dl=1</a>' webm='<a href=\"https://www.dropbox.com/s/9ngx754jsj9wzxj/10.webm?dl=1\">https://www.dropbox.com/s/9ngx754jsj9wzxj/10.webm?dl=1</a>' %}</p>\n<h2 id=\"kod-%C5%BAr%C3%B3d%C5%82owy\">Kod źródłowy</h2>\n<p>Kod tego programu jest dość mocno skondensowany. Zaczyna się od załadowania bibliotek:</p>\n<pre><code class=\"language-perl\">#!/usr/bin/env perl\n\nuse warnings;\nuse strict;\n\nuse HTML::TagParser;\n</code></pre>\n<p>Później następuje deklaracja zmiennych</p>\n<pre><code class=\"language-perl\">my $url = 'https://blog.gustawdaniel.pl';\nmy @tags = (&quot;h1 h2 h3 h4 li p&quot;,&quot;pre&quot;);\n</code></pre>\n<p>Pierwsza z nich to lokalizacja strony głównej tego bloga. Druga zawiera listę tagów traktowanych jako tekst (h1 h2 h3 h4 li p) oraz tagów traktowanych jako kod (pre).</p>\n<p>Część wykonywalna skryptu rozpoczyna się rysowaniem nagłówka tabeli z wynikami</p>\n<pre><code class=\"language-perl\">print &quot;|     text |     code | title \\n&quot;;\n</code></pre>\n<p>Tutaj kończy się wstęp i zaczyna magia. Kolejna linia pobiera zawartość strony głównej bloga, wyciąga z niej wszystkie elementy z tagiem <code>h2</code> i zapisuje do tablicy.</p>\n<pre><code class=\"language-perl\">my @list = HTML::TagParser-&gt;new( $url )-&gt;getElementsByTagName( &quot;h2&quot; );\n</code></pre>\n<p>Zajmujemy się tagiem <code>h2</code> ponieważ na stronie głównej bloga wszystkie linki do wpisów znajdują się wewnątrz takiego tagu.</p>\n<p><a href=\"https://postimg.org/image/r09e9v6ff/\"><img src=\"https://s1.postimg.org/fb5elwfgv/scr2.png\" alt=\"scr2.png\" loading=\"lazy\"></a></p>\n<p>Naturalnym kolejnym krokiem jest przebiegnięcie pętlą po tej liście:</p>\n<pre><code class=\"language-perl\">foreach my $elem ( @list ) {\n</code></pre>\n<p>Wewnątrz pętli wyciągamy wartość atrybutu <code>href</code> dla pierwszego dziecka elementu <code>h2</code> ze strony głównej. Dołączamy ją do adresu bloga - <code>$url</code> i ponownie ściągamy całą zawartość metodą <code>new</code> obiektu <code>TagParser</code>. Pobraną treść zapisujemy do zmiennej <code>$post</code>.</p>\n<pre><code class=\"language-perl\">    my $post = HTML::TagParser-&gt;new( $url.$elem-&gt;firstChild()-&gt;getAttribute( &quot;href&quot; ) );\n</code></pre>\n<p>Za chwilę go przetworzymy, ale przed przejściem do kolejnej części programu inicjalizujemy dwuelementową tablicę wewnątrz której będziemy przechowywać tekst oraz kod wyciągnięty z posta.</p>\n<pre><code class=\"language-perl\">    my @str = (&quot;&quot;,&quot;&quot;);\n</code></pre>\n<p>Wchodzimy do kolejnego poziomu pętli, która iteruje właśnie po tych dwóch elementach. To znaczy, że dla <code>$i=0</code> wyciągamy teksty, a dla <code>$i=1</code> interesuje nas zliczanie ilości kodu źródłowego.</p>\n<pre><code class=\"language-perl\">    foreach my $i ( (0,1) ) {\n</code></pre>\n<p>Taką elastyczność wyboru aktualnie zliczanych elementów dostajemy dzięki zdefiniowanej wcześniej zmiennej <code>@tags</code>. Teraz wybieramy jej pierwszy element i funkcją <code>split</code> przekształcamy go na tablicę zawierającą tagi. Funkcja <code>map</code> pozwala nam wykonać wybranie listy elementów po tagu dla każdego z wyodrębnionych tagów. Ostatecznie wszystkie te elementy trafiają do wspólnej tablicy <code>@elements</code>.</p>\n<pre><code class=\"language-perl\">        my @elements = map {$post-&gt;getElementsByTagName($_)} split / /, $tags[$i];\n</code></pre>\n<p>Żeby wydobyć z nich tekst wykorzystamy metodę <code>innerText</code> i prostym mapowaniem oraz rzutowaniem tablicy na string wyciągniemy szukane teksty.</p>\n<pre><code class=\"language-perl\">        $str[$i] = join(&quot;&quot;,map {$_-&gt;innerText} @elements);\n</code></pre>\n<p>Możemy na tym zakończyć ciało pętli po indeksach (0,1)</p>\n<pre><code class=\"language-perl\">    }\n</code></pre>\n<p>Zostało nam już tylko obliczenie ilości znaków i wydrukowanie wyników - jedna linia kodu:</p>\n<pre><code class=\"language-perl\">    printf(&quot;| %8d | %8d | %-60s \\n&quot;, (map {$str[$_] =~ y===c} (0,1)), $elem-&gt;innerText);\n</code></pre>\n<p>Na sam koniec zamykamy pętlę po postach.</p>\n<pre><code class=\"language-perl\">}\n</code></pre>\n<p>Działanie programu jest gwarantowane do momentu zmiany organizacji linków na stronie głównej w kodzie <code>html</code>.</p>\n<h2 id=\"podsumowanie\">Podsumowanie</h2>\n<p>Wyniki są pomiarów przedstawia poniższy screen:</p>\n<p><a href=\"https://postimg.org/image/o88sj15q7/\"><img src=\"https://s11.postimg.org/niq06o56r/screen.png\" alt=\"screen.png\" loading=\"lazy\"></a></p>\n<p>Jest to jeden z najkrótszych wpisów. Jest to też jeden z najkrótszych kodów źródłowych. Właśnie gęstość składni w perlu jest moim zdaniem jedną z największych zalet tego pięknego języka.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f3ae92fb35425592d0bc6",
            "plaintext": "Opis projektu\nZe czystej ciekawości chciałem sprawdzić jaką część moich wpisów stanowi tekst,\na jaką kod źródłowy. Napisałem program, który to udzielił mi odpowiedzi na to\npytanie.\n\nCały projekt jest napisany w perlu i składa się z jednego 21 liniowego pliku.\n\nInstalacja\nInstalujemy zależności:\n\nsudo apt-get install wget cpanminus\nsudo cpanm install HTML::TagParser\nsudo cpanm install URI::Fetch\n\n\nPobieramy kod źródłowy z gist\n\n wget https://gist.githubusercontent.com/gustawdaniel/a4bb55473e8e4399a5b087f1979e78d0/raw/3427bbd1f6b68c75e0481eaee0fc6f466db8af6d/count_text_and_code.pl -O count_text_and_code.pl\n\n\nI gotowe.\n\nDziałanie\nPo włączeniu program drukuje nam na ekranie tabelę z liczbą znaków w tekstach\n(text), liczbą znaków prezentowanych kodów źródłowych (code) oraz tytułami\nwpisów (title).\n\n{% include video.html url='https://www.dropbox.com/s/bh4n1ko7ygfu3ko/10.mp4?dl=1\n' webm='https://www.dropbox.com/s/9ngx754jsj9wzxj/10.webm?dl=1' %}\n\nKod źródłowy\nKod tego programu jest dość mocno skondensowany. Zaczyna się od załadowania\nbibliotek:\n\n#!/usr/bin/env perl\n\nuse warnings;\nuse strict;\n\nuse HTML::TagParser;\n\n\nPóźniej następuje deklaracja zmiennych\n\nmy $url = 'https://blog.gustawdaniel.pl';\nmy @tags = (\"h1 h2 h3 h4 li p\",\"pre\");\n\n\nPierwsza z nich to lokalizacja strony głównej tego bloga. Druga zawiera listę\ntagów traktowanych jako tekst (h1 h2 h3 h4 li p) oraz tagów traktowanych jako\nkod (pre).\n\nCzęść wykonywalna skryptu rozpoczyna się rysowaniem nagłówka tabeli z wynikami\n\nprint \"|     text |     code | title \\n\";\n\n\nTutaj kończy się wstęp i zaczyna magia. Kolejna linia pobiera zawartość strony\ngłównej bloga, wyciąga z niej wszystkie elementy z tagiem h2 i zapisuje do\ntablicy.\n\nmy @list = HTML::TagParser->new( $url )->getElementsByTagName( \"h2\" );\n\n\nZajmujemy się tagiem h2 ponieważ na stronie głównej bloga wszystkie linki do\nwpisów znajdują się wewnątrz takiego tagu.\n\n [https://postimg.org/image/r09e9v6ff/]\n\nNaturalnym kolejnym krokiem jest przebiegnięcie pętlą po tej liście:\n\nforeach my $elem ( @list ) {\n\n\nWewnątrz pętli wyciągamy wartość atrybutu href dla pierwszego dziecka elementu \nh2 ze strony głównej. Dołączamy ją do adresu bloga - $url i ponownie ściągamy\ncałą zawartość metodą new obiektu TagParser. Pobraną treść zapisujemy do\nzmiennej $post.\n\n    my $post = HTML::TagParser->new( $url.$elem->firstChild()->getAttribute( \"href\" ) );\n\n\nZa chwilę go przetworzymy, ale przed przejściem do kolejnej części programu\ninicjalizujemy dwuelementową tablicę wewnątrz której będziemy przechowywać tekst\noraz kod wyciągnięty z posta.\n\n    my @str = (\"\",\"\");\n\n\nWchodzimy do kolejnego poziomu pętli, która iteruje właśnie po tych dwóch\nelementach. To znaczy, że dla $i=0 wyciągamy teksty, a dla $i=1 interesuje nas\nzliczanie ilości kodu źródłowego.\n\n    foreach my $i ( (0,1) ) {\n\n\nTaką elastyczność wyboru aktualnie zliczanych elementów dostajemy dzięki\nzdefiniowanej wcześniej zmiennej @tags. Teraz wybieramy jej pierwszy element i\nfunkcją split przekształcamy go na tablicę zawierającą tagi. Funkcja map pozwala\nnam wykonać wybranie listy elementów po tagu dla każdego z wyodrębnionych tagów.\nOstatecznie wszystkie te elementy trafiają do wspólnej tablicy @elements.\n\n        my @elements = map {$post->getElementsByTagName($_)} split / /, $tags[$i];\n\n\nŻeby wydobyć z nich tekst wykorzystamy metodę innerText i prostym mapowaniem\noraz rzutowaniem tablicy na string wyciągniemy szukane teksty.\n\n        $str[$i] = join(\"\",map {$_->innerText} @elements);\n\n\nMożemy na tym zakończyć ciało pętli po indeksach (0,1)\n\n    }\n\n\nZostało nam już tylko obliczenie ilości znaków i wydrukowanie wyników - jedna\nlinia kodu:\n\n    printf(\"| %8d | %8d | %-60s \\n\", (map {$str[$_] =~ y===c} (0,1)), $elem->innerText);\n\n\nNa sam koniec zamykamy pętlę po postach.\n\n}\n\n\nDziałanie programu jest gwarantowane do momentu zmiany organizacji linków na\nstronie głównej w kodzie html.\n\nPodsumowanie\nWyniki są pomiarów przedstawia poniższy screen:\n\n [https://postimg.org/image/o88sj15q7/]\n\nJest to jeden z najkrótszych wpisów. Jest to też jeden z najkrótszych kodów\nźródłowych. Właśnie gęstość składni w perlu jest moim zdaniem jedną z\nnajwiększych zalet tego pięknego języka.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:34:49.000Z",
            "updated_at": "2021-04-20T20:35:08.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f3b3b2fb35425592d0bce",
            "uuid": "e609546a-6c83-4336-ad49-f709eea64a06",
            "title": "Aplikacja z FOSUserBundle i API Google Maps",
            "slug": "aplikacja-z-fosuserbundle-i-api-google-maps",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Opis projektu\\n\\nJest to projekt napisany jako jedna z funkcjonalności podczas mojej współpracy z `Smartselect`. Najzabawniejsze jest to, że był to mój pierwszy kontakt z `FOSUserBundle`, `Api Google Maps` i obiektem `navigator`. Kiedy go pisałem nie znałem `JavaScriptu`. Mimo, że przed publikacją kod wymagał odrobiny odświeżenia i dokładnego oddzielenie od innych funkcjonalności całej aplikacji, okazało się, że nie było to trudne i w tym wpisie przedstawiłem jak plik po pliku zbudować go od zera.\\n\\nZ wpisu dowiesz się jak zainstalować, skonfigurować i nadpisywać `FOSUserBundle` - najpopularniejszą paczkę do obsługi użytkowników w `Symfony`. Stworzymy kilka widoków związanych z logowaniem, rejestracją, zarządzaniem kontem, resetowaniem hasła i tak dalej. Jeśli lubisz front, to przez większość tego wpisu będziesz czuł się jak ryba w wodzie. Do backendu zejdziemy przy logice aplikacji, czyli wykorzystywaniu `API Google Maps` do tłumaczenia tekstowych adresów, albo współrzędnych na encje naszej bazy danych. Nie zabraknie Ajaxa, zobaczymy jak obiekt `navigator` pozwala nam dostać się do połorzenia przeglądarki oraz jak pogodzić twiga i JavaScript w jednym froncie.\\n\\nDziałanie aplikacji możesz zobaczyć na poniższym video:\"}],[\"html\",{\"html\":\"<video src=\\\"https://www.dropbox.com/s/nv29p3jsqscjqlv/9.ogv?dl=1\\\" controls></video>\"}],[\"markdown\",{\"markdown\":\"Skład kodu źródłowego to:\\n\\n```\\nPHP 69.7% HTML 20.9% CSS 5.8% ApacheConf 3.1% JavaScript 0.5%\\n```\\n\\n## Instalacja\\n\\nSą dwa sposoby stawiania nowego projektu Symfony: [instalacja od zera](http://symfony.com/doc/current/best_practices/creating-the-project.html) oraz klonowanie z githuba.\\n\\nJeśli chcesz zainstalowawć projekt najprostszym możliwym sposobem, możesz pobrać go z [githuba](https://github.com/gustawdaniel/geo_local)\\ni zainstalować go zgodnie z instrukcją z `README.md`.\\n\\n\\nW tym wpisie pokażę jak instalować projekt od zera. Możesz nie zaglądać do mojego repo i wykonując wszystkie komendy i tworząc poniższe pliki powinienneś otrzymać praktycznie to samo. Jedyne różnice będą polagać na tym, że na blogu dla większej przjejrzystości nie umieściłem kilku i tak nie używanych widoków jak panel admina czy kontakt.\\n\\nWracając do instalacji. Jeśli chcesz instalować od zera to dokumentacja Symfony zaleca użycie jej instalatora.\\n\\n```\\nsymfony new geo_local && cd geo_local\\n```\\n\\n## FosUserBundle\\n\\nBędziemy chcieli stworzyć użytkowników. W tym celu wykorzystamy jedną z najpopularniejszych paczek - [FOSUserBundle](https://symfony.com/doc/master/bundles/FOSUserBundle/index.html).\\n\\n```\\ncomposer require friendsofsymfony/user-bundle \\\"~2.0@dev\\\"\\n```\\n\\nŻeby ją wykorzystać musimy zarejestrować ją a jądrze aplikacji poprzez dodanie elementu: `new FOS\\\\UserBundle\\\\FOSUserBundle()` do tablicy `$bundles` w pliku `app/AppKernel.php`.\\n\\nNastępnie rozszerzamy klasę `BaseUser` żeby móc modyfikować klasę opisującą Użytkowników (zakładam, że będziemy korzystać z mysql, dla innych silników baz danych konfiguracja może wyglądać trochę inaczej):\\n\\n```php\\n<?php\\n\\nnamespace AppBundle\\\\Entity;\\n\\nuse FOS\\\\UserBundle\\\\Model\\\\User as BaseUser;\\nuse Doctrine\\\\ORM\\\\Mapping as ORM;\\n\\n/**\\n * @ORM\\\\Entity\\n * @ORM\\\\Table(name=\\\"users\\\")\\n */\\nclass User extends BaseUser\\n{\\n    /**\\n     * @ORM\\\\Id\\n     * @ORM\\\\Column(type=\\\"integer\\\")\\n     * @ORM\\\\GeneratedValue(strategy=\\\"AUTO\\\")\\n     */\\n    protected $id;\\n\\n    public function __construct()\\n    {\\n        parent::__construct();\\n        // your own logic\\n    }\\n}\\n```\\n\\nZmieniamy zawartość pliku: `app/config/security.yml`\\n\\n```yml\\nsecurity:\\n    encoders:    \\n        FOS\\\\UserBundle\\\\Model\\\\UserInterface: bcrypt\\n\\n    role_hierarchy:\\n        ROLE_ADMIN:       ROLE_USER\\n        ROLE_SUPER_ADMIN: ROLE_ADMIN\\n\\n    providers:\\n        fos_userbundle:\\n            id: fos_user.user_provider.username\\n\\n    firewalls:\\n        main:\\n            pattern: ^/\\n            form_login:\\n                provider: fos_userbundle\\n                csrf_token_generator: security.csrf.token_manager\\n                # if you are using Symfony < 2.8, use the following config instead:\\n                # csrf_provider: form.csrf_provider\\n\\n            logout:       true\\n            anonymous:    true\\n\\n    access_control:\\n        - { path: ^/login$, role: IS_AUTHENTICATED_ANONYMOUSLY }\\n        - { path: ^/register, role: IS_AUTHENTICATED_ANONYMOUSLY }\\n        - { path: ^/resetting, role: IS_AUTHENTICATED_ANONYMOUSLY }\\n        - { path: ^/admin/, role: ROLE_ADMIN }\\n```\\n\\nNa koniec w pliku `app/config/config.yml` odkomentowujemy linię zawierającą wpis `#translator:      { fallbacks: [\\\"%locale%\\\"] }`. I na końcu dodajemy:\\n\\n```yml\\nfos_user:\\n    db_driver: orm\\n    firewall_name: main\\n    user_class: AppBundle\\\\Entity\\\\User\\n```\\n\\nPowinniśmy też dodać dwie linie do routingu `app/config/routing.yml`:\\n\\n```yml\\nfos_user:\\n    resource: \\\"@FOSUserBundle/Resources/config/routing/all.xml\\\"\\n```\\n\\nŻeby wszystko działało powinniśmy jeszcze ustawić sobie parametry połączenia z bazą danych. W moim przypadku sprowadza się to do ustawienia: wpisu `database_name: geo_local` w plikach: `app/config/parameters.yml` i `app/config/parameters.yml.dist`.\\n\\nTworzymy bazę danych i potrzebne tabele za pomocą komend:\\n\\n```bash\\nphp bin/console doctrine:database:create\\nphp bin/console doctrine:schema:update --force\\n```\\n\\nTeraz wszystko powinno działać. Mam na myśli, że po uruchomieniu serwera komendą `php bin/console server:run` i wpisaniu w przeglądarkę adresu `127.0.0.1:8000/login` zobaczymy coś takiego:\\n\\n![domyślny_login_fos_user_bundle](http://i.imgur.com/cCUzKD4.png)\"}],[\"markdown\",{\"markdown\":\"### Nadpisywanie zachowania FOSUserBundle\\n\\nMamy teraz dwa problemy, pierwszy, że nie wygląda to ładnie, drugi, że chcemy zamiast `username` używać `email`, a po zalogowaniu chcemy dodać nasze własne przekierowanie. Zaczniemy od logiki, a front zostawimy na później.\\n\\n#### Zastąpienie `username` przez `e-mail`\\n\\nBardzo czytelną instrukcję pozbywania się pola `username` można znaleźć na [stacku](http://stackoverflow.com/questions/8832916/remove-replace-the-username-field-with-email-using-fosuserbundle-in-symfony2). W klasie `User` nadpisujemy setter dla pola e-mail.\\n\\n```php?start_inline=1\\npublic function setEmail($email)\\n{\\n    $email = is_null($email) ? '' : $email;\\n    parent::setEmail($email);\\n    $this->setUsername($email);\\n\\n    return $this;\\n}\\n```\\n\\nNie podążymy jednak za tą instrukcję zbyt dosłownie, dlatego, że w oficjalnej dokumentacji można wyczytać między wierszami lepszy sposób. Wspomagając się dokumentacją [nadpisywania formularzy](http://symfony.com/doc/master/bundles/FOSUserBundle/overriding_forms.html), tworzymy plik `src/AppBundle/Form/RegistrationType.php` który nadpisze nam domyśny formularz rejestracji. Przy rejestracji chcemy wymagać od użytkownika tylko jednego hasła, dlatego upieczemy dwie pieczenie na jednym ogniu nadpisując ten formulaż. Oto treść pliku:\\n\\n```php\\n<?php\\nnamespace AppBundle\\\\Form;\\n\\nuse Symfony\\\\Component\\\\Form\\\\AbstractType;\\nuse Symfony\\\\Component\\\\Form\\\\FormBuilderInterface;\\nuse Symfony\\\\Component\\\\Form\\\\Extension\\\\Core\\\\Type\\\\PasswordType;\\n\\nclass RegistrationType extends AbstractType\\n{\\n    public function buildForm(FormBuilderInterface $builder, array $options)\\n    {\\n        $builder->remove('username')\\n            ->remove('plainPassword')\\n            ->add('plainPassword',PasswordType::class);\\n    }\\n\\n    public function getParent()\\n    {\\n        return 'FOS\\\\UserBundle\\\\Form\\\\Type\\\\RegistrationFormType';\\n    }\\n\\n    public function getBlockPrefix()\\n    {\\n        return 'app_user_registration';\\n    }\\n}\\n```\\n\\nUsuwając i dodając hasło pozbywamy się dość ciekawej i zaawansowanej sztuczki z powtarzaniem tego pola, jaką stosuje `FOSUserBundle`. Analogicznie nadpisujemy edycję profilu `src/AppBundle/Type/ProfileType.php`:\\n\\n```php\\n<?php\\nnamespace AppBundle\\\\Form;\\n\\nuse Symfony\\\\Component\\\\Form\\\\AbstractType;\\nuse Symfony\\\\Component\\\\Form\\\\FormBuilderInterface;\\n\\nclass ProfileType extends AbstractType\\n{\\n    public function buildForm(FormBuilderInterface $builder, array $options)\\n    {\\n        $builder->remove('username');\\n    }\\n\\n    public function getParent()\\n    {\\n        return 'FOS\\\\UserBundle\\\\Form\\\\Type\\\\ProfileFormType';\\n    }\\n\\n    public function getBlockPrefix()\\n    {\\n        return 'app_user_profile';\\n    }\\n}\\n```\\n\\nRejestrujemy nasze formularze jako usługi modyfikując plik `app/config/services.yml`:\\n\\n```yml\\nservices:\\n    app.form.registration:\\n        class: AppBundle\\\\Form\\\\RegistrationType\\n        tags:\\n            - { name: form.type, alias: app_user_registration }\\n    app.form.profile:\\n        class: AppBundle\\\\Form\\\\ProfileType\\n        tags:\\n            - { name: form.type, alias: app_user_profile }\\n```\\n\\nNa końcu w konfiguracji paczki ustawiamy nasze formularze jako te, które mają nadpisać domyślne.\\n\\n```yml\\nfos_user:\\n    db_driver: orm\\n    firewall_name: main\\n    user_class: AppBundle\\\\Entity\\\\User\\n    registration:\\n        form:\\n            type: AppBundle\\\\Form\\\\RegistrationType\\n    profile:\\n        form:\\n            type: AppBundle\\\\Form\\\\ProfileType\\n```\\n\\nNie ruszamy w ogóle walidacji. Należy pamiętać, że [link](http://stackoverflow.com/questions/8832916/remove-replace-the-username-field-with-email-using-fosuserbundle-in-symfony2) z instrukcją odnosił się do wersji 2 Symfony, a w naszym projekcie używamy 3.\"}],[\"markdown\",{\"markdown\":\"#### Przekierowanie po logowaniu\\n\\nDomyślnie po zalogowaniu `FOSUserBundle` przekierowuje nas do profilu użytkownika. Jest to logiczne, ale nie praktyczne w naszym przypadku. Główna funkcjonalność aplikacji nie będzie polegała na zmienianiu swojego e-maila i hasła. Zamiast tego chcemy przekierować użytkownika do ścieżki nazywanej `homepage`, a dopiero jej kontroler będzie wysyłał zalogowanych do panelu z miejscami, a nie zalogowanych do strony informacyjnej. Żeby po zalogowaniu móc przekierować użytkownika do `homepage` wykonamy następujące zmiany: dodamy plik `src/AppBundle/Security/LoginSuccessHandler.php` o treści:\\n\\n```php\\n<?php\\nnamespace AppBundle\\\\Security;\\n\\nuse Symfony\\\\Component\\\\Security\\\\Http\\\\Authentication\\\\AuthenticationSuccessHandlerInterface;\\nuse Symfony\\\\Component\\\\Security\\\\Core\\\\Authentication\\\\Token\\\\TokenInterface;\\nuse Symfony\\\\Component\\\\Security\\\\Core\\\\Authorization\\\\AuthorizationChecker;\\nuse Symfony\\\\Component\\\\HttpFoundation\\\\Request;\\nuse Symfony\\\\Component\\\\HttpFoundation\\\\RedirectResponse;\\nuse Symfony\\\\Component\\\\Routing\\\\Router;\\n\\nclass LoginSuccessHandler implements AuthenticationSuccessHandlerInterface {\\n\\n    protected $router;\\n    protected $authorizationChecker;\\n\\n    public function __construct(Router $router, AuthorizationChecker $authorizationChecker) {\\n        $this->router = $router;\\n        $this->authorizationChecker = $authorizationChecker;\\n    }\\n\\n    public function onAuthenticationSuccess(Request $request, TokenInterface $token) {\\n        return new RedirectResponse($this->router->generate('homepage'));\\n    }\\n}\\n```\\n\\nW serwisach (`app/config/services.yml`) powinniśmy dodać usługę:\\n\\n```yml\\n    authentication.handler.login_success_handler:\\n        class:  AppBundle\\\\Security\\\\LoginSuccessHandler\\n        arguments:  ['@router', '@security.authorization_checker']\\n```\\n\\nPowinniśmy dodać parametr `success_handler` do pliku `app/config/security.yml`\\n\\n```yml\\n    firewalls:\\n        main:\\n            pattern: ^/\\n            form_login:\\n                provider: fos_userbundle\\n                csrf_token_generator: security.csrf.token_manager\\n                success_handler: authentication.handler.login_success_handler\\n```\\n\\n### Nadpisanie wyglądu FOSUserBundle\\n\\nTeraz mając odpowiednią ilość pól w formularzu możemy zmienić wygląd, tak, żeby nie straszył, i nie powodował koszmarów u użytkowników. Listę ścieżek jakimi powinniśmy się zająć wyświetlimy komendą:\\n\\n```bash\\nphp bin/console debug:router | grep fos_user\\n```\\n\\nNajprostszą metodą nadpisania domyślnego wyglądu jest wykonanie następującej komendy.\\n\\n```bash\\nmkdir -p app/Resources/FOSUserBundle/views && cp -r vendor/friendsofsymfony/user-bundle/Resources/views/* \\\"$_\\\"\\n```\"}],[\"markdown\",{\"markdown\":\"#### Dodawanie zewnętrznych bibliotek\\n\\nZainstalujemy teraz biblioteki frontowe i dodamy nasze własne style oraz skrypty.\\n Żeby nie było problemów z cache twiga, wyłączymy go w trybie deweloperskim dodając do pliku `app/config/config_dev.yml` linie:\\n\\n```yml\\ntwig:\\n    cache: false\\n```\\n\\nTwożymy plik `.bowerrc` o treści:\\n\\n```json\\n{\\n  \\\"directory\\\": \\\"web/bower_components/\\\"\\n}\\n```\\n\\nInicjalizujemy bowera komendą:\\n\\n```\\nbower init\\n```\\n\\nInstalujemy bootstrapa 3, animate.css, components-font-awesome, jQuery i iCheck - małą bibliotekę opartą na jQuery do wyświetlania efektów związanych z zaznaczaniem pól formularzy i checkboxów:\\n\\n```\\nbower install --save bootstrap#^3.3.7 animate.css#^3.5.2 components-font-awesome#^4.7.0 iCheck#^1.0.2 jquery#^3.1.1\\n```\\n\\nDo `.gitignore` dodajemy linie:\\n\\n```\\n/.idea\\n/web/bower_components\\n```\\n\\nNie jestem dobrym frontowcem, dlatego kupuję fronty. Tak było i w tym przypadku. CSS, który załączam kupiłem na stronie\\n[wrapbootstrap.com](https://wrapbootstrap.com/theme/eternity-forms-WB0G8810G). Wyciąłem z niego połowę nie wykorzystywanej\\nfunkcjonalności i zmieniłem linki do skinów `iCheck`. Umieściłem plik `css` w lokacji `src/AppBundle/Resources/public/css/forms.css`.\\n\\n```css\\n.eternity-form-modal {\\n  background-color: #707d85;\\n}\\n.eternity-form {\\n  font-family: 'Roboto', 'PT Sans', sans-serif;\\n  font-weight: 300;\\n  color: #95a5a6;\\n}\\n.eternity-form h1,\\n.eternity-form h2,\\n.eternity-form h3,\\n.eternity-form h4,\\n.eternity-form h5,\\n.eternity-form h6 {\\n  font-family: 'Roboto', 'PT Sans', sans-serif;\\n  font-weight: 300;\\n}\\n.eternity-form .login-form-section,\\n.eternity-form .forgot-password-section {\\n  width: 100%;\\n  max-width: 360px;\\n  margin: 0 auto;\\n}\\n.eternity-form .login-content,\\n.eternity-form .forgot-password-section,\\n.eternity-form .reg-content {\\n  background-color: white;\\n  -o-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  -ms-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  -moz-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  -webkit-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n}\\n.eternity-form .section-title {\\n  padding: 10px 20px;\\n  background-color: white;\\n}\\n.eternity-form .section-title h3 {\\n  color: #3498db;\\n}\\n.eternity-form .textbox-wrap {\\n  padding: 20px 20px 20px 15px;\\n  border-left: 5px solid transparent;\\n  -moz-transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\\n  -o-transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\\n  -webkit-transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\\n  transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\\n}\\n.eternity-form .textbox-wrap .input-group {\\n  border: 1px solid #e0e0e0;\\n  background-color: #ffffff;\\n}\\n.eternity-form .textbox-wrap .input-group .input-group-addon,\\n.eternity-form .textbox-wrap .input-group input,\\n.eternity-form .textbox-wrap .input-group .form-control {\\n  background-color: transparent;\\n  border: none;\\n}\\n.eternity-form .textbox-wrap .input-group input,\\n.eternity-form .textbox-wrap .input-group .form-control,\\n.eternity-form .textbox-wrap .input-group input:focus,\\n.eternity-form .textbox-wrap .input-group .form-control:focus {\\n  box-shadow: none;\\n  outline: none;\\n}\\n.eternity-form .textbox-wrap .input-group i {\\n  color: #cccccc;\\n}\\n.eternity-form .textbox-wrap.focused {\\n  border-left-color: #3498db;\\n  background-color: #f0f0f0;\\n  -o-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\\n  -ms-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\\n  -moz-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\\n  -webkit-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\\n  box-shadow: inset 0 0 3px rgba(0,0,0,.1);\\n}\\n.eternity-form .green-btn,\\n.eternity-form .green-btn:hover,\\n.eternity-form .blue-btn {\\n  background-color: #2ecc71;\\n  border: none;\\n}\\n.eternity-form .blue-btn,\\n.eternity-form .blue-btn:hover {\\n  background-color: #2980b9;\\n}\\n.eternity-form .login-form-action {\\n  padding: 15px 20px 30px 20px;\\n}\\n.eternity-form input[type=\\\"checkbox\\\"] {\\n  width: 30px;\\n}\\n.eternity-form .blue {\\n  color: #3498db;\\n}\\n.eternity-form .green {\\n  color: #2ecc71;\\n}\\n.eternity-form .login-form-links {\\n  padding: 20px;\\n  margin-top: 5px;\\n  -o-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\\n  -ms-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\\n  -moz-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\\n  -webkit-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\\n  box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\\n  background-color: white;\\n}\\n.eternity-form .login-form-links a.blue:hover,\\n.eternity-form .login-form-links a a.blue:focus {\\n  color: #3498db;\\n  text-decoration: underline;\\n}\\n.eternity-form .login-form-links a.green:hover,\\n.eternity-form .login-form-links a a.green:focus {\\n  color: #2ecc71;\\n  text-decoration: underline;\\n}\\n.eternity-form .forget-form-action {\\n  padding: 20px;\\n}\\n.eternity-form .registration-form-section {\\n  max-width: 620px;\\n  margin: 0 auto;\\n  width: 100%;\\n}\\n.eternity-form .reg-header {\\n  -o-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  -ms-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  -moz-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  -webkit-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n}\\n.eternity-form .registration-left-section {\\n  padding-left: 0;\\n  padding-right: 2px;\\n}\\n.eternity-form .registration-right-section {\\n  padding-left: 2px;\\n  padding-right: 0;\\n}\\n.eternity-form .reg-content {\\n  margin-top: 5px;\\n  padding: 20px 0;\\n}\\n.eternity-form .registration-form-action {\\n  margin-top: 5px;\\n  padding: 20px;\\n  -o-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  -ms-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  -moz-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  -webkit-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\\n  background-color: white;\\n}\\n.eternity-form .custom-checkbox {\\n  float: left;\\n}\\n.eternity-form .checkbox {\\n  display: inline-block;\\n  padding-left: 1px;\\n  margin-top: 7px;\\n  margin-bottom: 0;\\n}\\n.eternity-form .checkbox-text {\\n  line-height: 24px;\\n  padding-left: 5px;\\n}\\n.eternity-form .form-control:-moz-placeholder {\\n  font-weight: 300;\\n}\\n.eternity-form .form-control::-moz-placeholder {\\n  font-weight: 300;\\n}\\n.eternity-form .form-control:-ms-input-placeholder {\\n  font-weight: 300;\\n}\\n.eternity-form .form-control::-webkit-input-placeholder {\\n  font-weight: 300;\\n}\\n\\n.eternity-form .checkbox label {\\n  font-weight: 300;\\n}\\n\\n.eternity-form .icheckbox_square-blue {\\n  display: block;\\n  margin: 0;\\n  padding: 0;\\n  width: 22px;\\n  height: 22px;\\n  /*background: url(../img/blue.png) no-repeat;*/\\n  background: url(\\\"../../../bower_components/iCheck/skins/square/blue.png\\\") no-repeat;\\n  border: none;\\n  cursor: pointer;\\n}\\n.eternity-form .icheckbox_square-blue {\\n  background-position: 0 0;\\n}\\n.eternity-form .icheckbox_square-blue.hover {\\n  background-position: -24px 0;\\n}\\n.eternity-form .icheckbox_square-blue.checked {\\n  background-position: -48px 0;\\n}\\n.eternity-form .icheckbox_square-blue.disabled {\\n  background-position: -72px 0;\\n  cursor: default;\\n}\\n.eternity-form .icheckbox_square-blue.checked.disabled {\\n  background-position: -96px 0;\\n}\\n\\n@media only screen and (-webkit-min-device-pixel-ratio: 1.5), only screen and (-moz-min-device-pixel-ratio: 1.5), only screen and (-o-min-device-pixel-ratio: 3/2), only screen and (min-device-pixel-ratio: 1.5) {\\n  .eternity-form .icheckbox_square-blue {\\n    background-image: url(\\\"../../../bower_components/iCheck/skins/square/blue@2x.png\\\");\\n    -webkit-background-size: 240px 24px;\\n    background-size: 240px 24px;\\n  }\\n}\\n@media (max-width: 767px) {\\n  .eternity-form .registration-left-section {\\n    padding-right: 0;\\n  }\\n  .eternity-form .registration-right-section {\\n    padding-left: 0;\\n  }\\n}\\n@media (max-width: 380px) {\\n  .eternity-form .blue-btn,\\n  .eternity-form .green-btn {\\n    font-size: .8em;\\n  }\\n}\\n```\\n\\nPotrzebujemy jeszcze jednego skryptu - `src/AppBundle/Resources/public/js/iCheck-config.js` jest to konfiguracja wtyczki `iCheck` służącej do interaktywnego podświetlania aktywnych pól formularz:\\n\\n```js\\n    $(function () {\\n\\n        //Custom Checkbox For Light Theme\\n        $(\\\"input\\\").iCheck({\\n            checkboxClass: 'icheckbox_square-blue',\\n            increaseArea: '20%'\\n        });\\n\\n        //Custom Checkbox For Dark Theme\\n        $(\\\".dark input\\\").iCheck({\\n            checkboxClass: 'icheckbox_polaris',\\n            increaseArea: '20%'\\n        });\\n\\n        //TextBox Focus Event\\n        $(\\\".form-control\\\").focus(function () {\\n            $(this).closest(\\\".textbox-wrap\\\").addClass(\\\"focused\\\");\\n        }).blur(function () {\\n            $(this).closest(\\\".textbox-wrap\\\").removeClass(\\\"focused\\\");\\n        });\\n\\n    });\\n```\\n\\n Linkujemy go z katalogiem `web` komendą\\n\\n```\\nphp bin/console assets:install --symlink\\n```\\n\\nNie jest to najlepsza dostępna metoda. Lepszą jest zastosowanie `gulpa`, ale jest najprostsza. Przy trzech kilku plikach styli i skryptów i kilku zewnętrznych bibliotekach brak konkatenacji i minifikacji nie jest niczym strasznym. Oczywiście tworzenie pliku ze stylami bezpośrednio w katalogu web jest prostsze, ale niepoprawne.\\n\\nOstatnią rzeczą jaka została nam do zrobienia jest dodanie bootstrapowych formularzy jako domyślnych dla twiga, w pliku `app/config/config.yml` dodajemy linie:\\n\\n```yml\\ntwig:\\n    form_themes:\\n        - 'bootstrap_3_layout.html.twig'\\n```\\n\\n#### Szablon bazowy\"}],[\"code\",{\"code\":\"<!DOCTYPE html>\\n<html>\\n<head>\\n    <meta charset=\\\"UTF-8\\\"/>\\n    <title>{% block title %}Welcome!{% endblock %}</title>\\n    <link rel=\\\"icon\\\" type=\\\"image/x-icon\\\" href=\\\"{{ asset('favicon.ico') }}\\\"/>\\n    <meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1\\\">\\n    {% block meta %}{% endblock %} {% block stylesheets %}       <!-- Bootstrap 3 CSS -->\\n    <link rel=\\\"stylesheet\\\" href=\\\"{{ asset('bower_components/bootstrap/dist/css/bootstrap.min.css') }}\\\">\\n    <!-- Eternity Login , Registration & Forgot Password Forms CSS -->\\n    <link href=\\\"{{ asset('bundles/app/css/forms.css') }}\\\" rel=\\\"stylesheet\\\"/>\\n    {% endblock %}\\n</head>\\n\\n<body> {% block body %}\\n<nav class=\\\"navbar navbar-default\\\">\\n    <div class=\\\"container\\\">\\n        <div class=\\\"navbar-header\\\">\\n            <button type=\\\"button\\\" class=\\\"navbar-toggle collapsed\\\" data-toggle=\\\"collapse\\\" data-target=\\\"#navbar\\\"\\n                    aria-expanded=\\\"false\\\" aria-controls=\\\"navbar\\\"><span class=\\\"sr-only\\\">Toggle navigation</span>\\n                <span class=\\\"icon-bar\\\"></span>\\n                <span class=\\\"icon-bar\\\"></span>\\n                <span class=\\\"icon-bar\\\"></span>\\n            </button>\\n\\n            <div class=\\\"{% if app.request.attributes.get('_route') == 'homepage' %}active{% endif %}\\\">\\n                <a class=\\\"navbar-brand\\\" href=\\\"{{ url('homepage') }}\\\">Places</a>\\n            </div>\\n\\n        </div>\\n        <!-- Collect the nav links, forms, and other content for toggling -->\\n        <div class=\\\"collapse navbar-collapse\\\" id=\\\"navbar\\\">\\n            <ul class=\\\"nav navbar-nav navbar-right\\\"> {% if app.user %}\\n\\n                <li class=\\\"{% if app.request.attributes.get('_route') == 'fos_user_profile_show' %}list-group-item-info{% endif %}\\\">\\n                    <a href=\\\"{{ url('fos_user_profile_show') }}\\\" data-toggle=\\\"tooltip\\\"\\n                       data-placement=\\\"bottom\\\"\\n                       title=\\\"{{ 'layout.logged_in_as'|trans({'%username%': app.user.username}, 'FOSUserBundle') }}\\\">\\n                        My Acconut\\n                    </a>\\n                </li>\\n\\n                <li><a href=\\\"{{ url('fos_user_security_logout') }}\\\">Logout</a></li>\\n                {% else %}\\n                <li class=\\\"{% if app.request.attributes.get('_route') == 'fos_user_security_login' %}active{% endif %}\\\">\\n                    <a href=\\\"{{ url('fos_user_security_login') }}\\\">Login</a>\\n                </li>\\n\\n                <li class=\\\"list-group-item-info {% if app.request.attributes.get('_route') == 'fos_user_registration_register' %}active{% endif %}\\\">\\n                    <a href=\\\"{{ url('fos_user_registration_register') }}\\\">Register</a>\\n                </li>\\n                {% endif %}\\n            </ul>\\n\\n        </div><!-- /.navbar-collapse -->\\n    </div><!-- /.container-fluid -->\\n</nav>\\n{% endblock %} {% block javascripts %}\\n<script src=\\\"{{ asset('bower_components/jquery/dist/jquery.min.js') }}\\\"></script>\\n\\n<script src=\\\"{{ asset('bower_components/bootstrap/dist/js/bootstrap.min.js') }}\\\"></script>\\n{% endblock %}\\n</body>\\n</html>\",\"language\":\"html\"}],[\"markdown\",{\"markdown\":\"Co my tu mamy? Jest `viewport` - strona działa na urządzeniach mobilnych. Podpinamy style, które mają się znaleźć wszędzie - bootstrap i forms. Dodaliśmy skrypty - jQuery i bootstrap. Nie ma tu potrzeby ładownia skryptów typu `iCheck` alby styli jak `animate.css` jeśli nie każda strona będzie ich potrzebować. Nie chcemy przecież zirytować użytkownika ciągłym animowaniem wszystkiego, tylko ucieszyć go animacjami przy logowaniu lub rejestracji - to wystarczy. Tag `<body>` zawiera jedynie pasek nawigacji. Nawigacja jednak posiada logikę odpowiadającą za wyświetlanie nie zalogowanemu użytkownikowi pól \\\"login\\\" i \\\"rejestracja\\\", a zalogowanemu \\\"moje konto\\\" i \\\"wyloguj\\\".\\n\\n#### Layout dla FOSUserBundle\\n\\nTeraz przyjrzymy się plikowi `app/Resources/FOSUserBundle/layout.html.twig` - czyli szablonowi, który dziedziczy z `base` i jest jednocześnie rodzicem dla wszystkiego co będziemy nadpisywali w `FOSUserBundle`:\\n\\n```twig\\n{% extends '::base.html.twig' %}\\n\\n{% block title %}{% endblock %}\\n\\n{% block body %}\\n    {{ parent() }}\\n    {% block fos_user_content %}{% endblock fos_user_content %}\\n{%  endblock %}\\n\\n{% block stylesheets %}\\n    {{ parent() }}\\n\\n    <!-- Animations CSS -->\\n    <link rel=\\\"stylesheet\\\" href=\\\"{{ asset('bower_components/animate.css/animate.min.css') }}\\\">\\n\\n    <!-- Font Icons -->\\n    <link href=\\\"https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\\\" rel=\\\"stylesheet\\\" integrity=\\\"sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN\\\" crossorigin=\\\"anonymous\\\">\\n\\n    <!-- Google Web Fonts -->\\n    <link href='http://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>\\n\\n    <style>\\n        .eternity-form {\\n            margin-top: 6vh;\\n        }\\n\\n        .width-min-300px {\\n            width: 100%;\\n            max-width: 300px;\\n        }\\n    </style>\\n{% endblock %}\\n\\n{% block javascripts %}\\n    {{ parent() }}\\n    <!-- Custom Checkbox PLugin -->\\n    <script src=\\\"{{ asset('bower_components/iCheck/icheck.min.js') }}\\\"></script>\\n\\n    <!-- For Initializing Checkbox And Focus Event For Textbox -->\\n    <script src=\\\"{{ asset('bundles/app/js/iCheck-config.js') }}\\\"></script>\\n{% endblock %}\\n```\\n\\nW tym pliku dodaliśmy style i skrypty potrzebne tylko przy obsłudze użytkownika oraz podpięliśmy blok `fos_user_content` bezpośrednio pod nawigacją zapisaną w `base.html.twig`.\\n\\n#### Login\\n\\nPlik `app/Resources/FOSUserBundle/views/Security/login.html.twig` pozostawiamy praktycznie nie zmieniony, dodjemy jedynie tytuł:\\n\\n```twig\\n{% extends \\\"@FOSUser/layout.html.twig\\\" %}\\n\\n{% block fos_user_content %}\\n    {{ include('@FOSUser/Security/login_content.html.twig') }}\\n{% endblock fos_user_content %}\\n\\n{% block title %}Login Form{% endblock %}\\n```\\n\\nDużo więcej kodu zostało dodanego w pliku `app/Resources/FOSUserBundle/views/Security/login_content.html.twig`\\n\\n```twig\\n{% trans_default_domain 'FOSUserBundle' %}\\n\\n<div class=\\\"container eternity-form\\\">\\n    <div class=\\\"login-form-section\\\">\\n        <div class=\\\"login-content animated zoomIn\\\">\\n            <form action=\\\"{{ path(\\\"fos_user_security_check\\\") }}\\\" method=\\\"post\\\">\\n                {% if csrf_token %}\\n                    <input type=\\\"hidden\\\" name=\\\"_csrf_token\\\" value=\\\"{{ csrf_token }}\\\" />\\n                {% endif %}\\n                <div class=\\\"section-title\\\">\\n                    <h3>LogIn to your Account</h3>\\n                </div>\\n                <div class=\\\"textbox-wrap\\\">\\n                    <div class=\\\"input-group\\\">\\n                        <span class=\\\"input-group-addon \\\"><i class=\\\"fa fa-user\\\" aria-hidden=\\\"true\\\"></i></span>\\n                        <input type=\\\"email\\\" id=\\\"username\\\" name=\\\"_username\\\" value=\\\"{{ last_username }}\\\"\\n                               required=\\\"required\\\" class=\\\"form-control\\\" placeholder=\\\"{{ 'form.email'|trans }}\\\" />\\n                    </div>\\n                </div>\\n                <div class=\\\"textbox-wrap\\\">\\n                    <div class=\\\"input-group\\\">\\n                        <span class=\\\"input-group-addon \\\"><i class=\\\"fa fa-key\\\" aria-hidden=\\\"true\\\"></i></span>\\n                        <input type=\\\"password\\\" id=\\\"password\\\" name=\\\"_password\\\" required=\\\"required\\\" class=\\\"form-control \\\" placeholder=\\\"{{ 'security.login.password'|trans }}\\\"/>\\n                    </div>\\n                </div>\\n                <div class=\\\"login-form-action clearfix\\\">\\n                    <div class=\\\"checkbox pull-left\\\">\\n                        <div class=\\\"custom-checkbox\\\">\\n                            <input type=\\\"checkbox\\\" id=\\\"remember_me\\\" name=\\\"_remember_me\\\" value=\\\"on\\\" checked />\\n                        </div>\\n                        <span class=\\\"checkbox-text pull-left\\\">&nbsp;{{ 'security.login.remember_me'|trans }}</span>\\n                    </div>\\n                    <button type=\\\"submit\\\" id=\\\"_submit\\\" name=\\\"_submit\\\" class=\\\"btn btn-success pull-right green-btn\\\">LogIn &nbsp;<i class=\\\"fa fa-chevron-right\\\" aria-hidden=\\\"true\\\"></i></button>\\n                </div>\\n            </form>\\n        </div>\\n\\n        {% if error %}\\n            <div class=\\\"login-form-links link1 animated fadeInUpBig text-danger\\\">\\n                <h4>Error</h4>\\n                <p>\\n                    {{ error.messageKey|trans(error.messageData, 'security') }}\\n                </p>\\n            </div>\\n        {% endif %}\\n\\n        <div class=\\\"login-form-links link1 animated fadeInLeftBig\\\">\\n            <h4 class=\\\"blue\\\">Don't have an Account?</h4>\\n            <span>No worry</span>\\n            <a href=\\\"{{ path('fos_user_registration_register') }}\\\" class=\\\"blue\\\">Click Here</a>\\n            <span>to Register</span>\\n        </div>\\n        <div class=\\\"login-form-links link2 animated fadeInRightBig\\\">\\n            <h4 class=\\\"green\\\">Forget your Password?</h4>\\n            <span>Dont worry</span>\\n            <a href=\\\"{{ path('fos_user_resetting_request') }}\\\" class=\\\"green\\\">Click Here</a>\\n            <span>to Get New One</span>\\n        </div>\\n    </div>\\n</div>\\n```\\n\\n\\n\\nJednak, jest to tylko front - formularz logowania i dwa linki w twigu. A ponieważ o frontach obraz mówi więcej niż tysiąc słów więc zamiast go opisywać wklejam screen:\\n\\n![login](http://i.imgur.com/avrKaZd.png)\\n\\n#### Rejestracja\\n\\nRejstracja wygląda podobnie.\\nPlik: `app/Resources/FOSUserBundle/views/Registration/register.html.twig`\\n\\n```twig\\n{% extends \\\"@FOSUser/layout.html.twig\\\" %}\\n\\n{% block fos_user_content %}\\n{% include \\\"@FOSUser/Registration/register_content.html.twig\\\" %}\\n{% endblock fos_user_content %}\\n\\n{% block title %}Register{% endblock %}\\n```\\n\\nPlik: `app/Resources/FOSUserBundle/views/Registration/register_content.html.twig`\\n\\n```twig\\n{% trans_default_domain 'FOSUserBundle' %}\\n\\n<div class=\\\"container eternity-form\\\">\\n    <div class=\\\"registration-form-section\\\">\\n            {{ form_start(form, {'method': 'post', 'action': path('fos_user_registration_register'), 'attr': {'class': 'fos_user_registration_register'}}) }}\\n\\n            <div class=\\\"section-title reg-header animated fadeInDown\\\">\\n                <h3>Get your Account Here </h3>\\n\\n            </div>\\n            <div class=\\\"clearfix\\\">\\n                <div class=\\\"col-sm-6 registration-left-section  animated fadeInRightBig\\\">\\n                    <div class=\\\"reg-content\\\">\\n                        <div class=\\\"textbox-wrap\\\">\\n                            <div class=\\\"input-group\\\">\\n                                <span class=\\\"input-group-addon \\\"><i class=\\\"fa fa-user\\\" aria-hidden=\\\"true\\\"></i></span>\\n                                {{ form_widget(form.email, {'attr': {'placeholder': 'Email'}}) }}\\n                            </div>\\n                        </div>\\n                    </div>\\n                </div>\\n                <div class=\\\"col-sm-6 registration-right-section animated fadeInLeftBig\\\">\\n                    <div class=\\\"reg-content\\\">\\n                        <div class=\\\"textbox-wrap\\\">\\n                            <div class=\\\"input-group\\\">\\n                                <span class=\\\"input-group-addon \\\"><i class=\\\"fa fa-key\\\" aria-hidden=\\\"true\\\"></i></span>\\n                                {{ form_widget(form.plainPassword, {'attr': {'placeholder': 'Password'}}) }}\\n                            </div>\\n                        </div>\\n                    </div>\\n                </div>\\n            </div>\\n            <div class=\\\"registration-form-action clearfix animated fadeInUp\\\">\\n                <a href=\\\"{{ path('fos_user_security_login') }}\\\" class=\\\"btn btn-success pull-left blue-btn \\\">\\n                    <i class=\\\"fa fa-chevron-left\\\"></i>&nbsp; &nbsp;Back To Login\\n                </a>\\n                <button type=\\\"submit\\\" class=\\\"btn btn-success pull-right green-btn \\\">Register Now &nbsp; <i class=\\\"fa fa-chevron-right\\\"></i></button>\\n            </div>\\n        {{ form_end(form) }}\\n    </div>\\n</div>\\n```\\n\\nEfekt:\\n\\n![register](http://i.imgur.com/i9BZooS.png)\\n\\nJeśli rejestracja przebiega pomyślnie, gratulujemy użytkonikowi komunikatem z pliku: `app/Resources/FOSUserBundle/views/Registration/confirmed.html.twig`\\n\\n```twig\\n{% extends \\\"@FOSUser/layout.html.twig\\\" %}\\n\\n{% trans_default_domain 'FOSUserBundle' %}\\n\\n{% block fos_user_content %}\\n    <div class=\\\"container eternity-form\\\">\\n        <div class=\\\"section-title reg-header\\\">\\n            <h3>Registration finished correctly</h3>\\n            <div>\\n                <p>{{ 'registration.confirmed'|trans({'%username%': user.username}) }}</p>\\n                {% if targetUrl %}\\n                    <p><a href=\\\"{{ targetUrl }}\\\">{{ 'registration.back'|trans }}</a></p>\\n                {% endif %}\\n            </div>\\n            <a href=\\\"{{ path('homepage') }}\\\" class=\\\"btn btn-info width-min-300px\\\">Let's start</a>\\n        </div>\\n    </div>\\n{% endblock fos_user_content %}\\n```\\n\\nKtóry prezentuje się tak:\\n\\n![confirm](http://i.imgur.com/8v1SLZ1.png)\\n\\n#### Resetowanie hasła\\n\\nJeśli posiadający konto użytkownik zapomni hasła, może je wysłać na swój e-mail (jeśli w `app/config/parameters.yml` są odpowiednie parametry umożliwiające wysłanie e-maila) za pomocą formularza, którego kod znajduje się w pliku `app/Resources/FOSUserBundle/views/Resetting/request_content.html.twig`\\n\\n```twig\\n{% trans_default_domain 'FOSUserBundle' %}\\n\\n<div class=\\\"container eternity-form\\\">\\n    <div class=\\\"forgot-password-section animated bounceInLeft\\\">\\n        <div class=\\\"section-title\\\">\\n            <h3>Forget Password</h3>\\n        </div>\\n        <div class=\\\"forgot-content\\\">\\n            <form action=\\\"{{ path('fos_user_resetting_send_email') }}\\\" method=\\\"POST\\\" class=\\\"fos_user_resetting_request\\\">\\n                <div class=\\\"textbox-wrap\\\">\\n                    <div class=\\\"input-group\\\">\\n                        <span class=\\\"input-group-addon \\\"><i class=\\\"fa fa-envelope\\\"></i></span>\\n                        <input type=\\\"email\\\" class=\\\"form-control\\\" id=\\\"username\\\" name=\\\"username\\\" required=\\\"required\\\" placeholder=\\\"Email Id\\\"/>\\n\\n                    </div>\\n                </div>\\n                <div class=\\\"forget-form-action clearfix\\\">\\n                    <a href=\\\"{{ path('fos_user_security_login') }}\\\" class=\\\"btn btn-success pull-left blue-btn\\\"><i class=\\\"fa fa-chevron-left\\\"></i>&nbsp;&nbsp;Back  </a>\\n                    <button type=\\\"submit\\\" class=\\\"btn btn-success pull-right green-btn\\\">Submit &nbsp;&nbsp; <i class=\\\"fa fa-chevron-right\\\"></i></button>\\n                </div>\\n            </form>\\n        </div>\\n    </div>\\n</div>\\n```\\n\\nFormularz wygląda tak:\\n\\n![reset](http://i.imgur.com/XfCorCh.png)\\n\\nZa to co pojawi się na ekranie po wpisaniu e-maila odpowiada plik: `app/Resources/FOSUserBundle/views/Resetting/check_email.html.twig` o treści\\n\\n```twig\\n{% extends \\\"@FOSUser/layout.html.twig\\\" %}\\n\\n{% trans_default_domain 'FOSUserBundle' %}\\n\\n{% block fos_user_content %}\\n    <div class=\\\"container eternity-form\\\">\\n        <div class=\\\"section-title reg-header\\\">\\n            <h3>Check Email</h3>\\n            <div class=\\\"fos_user_user_show\\\">\\n                <p>{{ 'resetting.check_email'|trans({'%tokenLifetime%': tokenLifetime})|nl2br }}\\n                </p>\\n            </div>\\n        </div>\\n    </div>\\n{% endblock %}\\n```\\n\\nktóry prezentuje się tak:\\n\\n![check](http://i.imgur.com/hZy5ERk.png)\\n\\nW e-mailu mamy link zmiany hasła. Szablon twiga znajduje się w pliku:  `app/Resources/FOSUserBundle/views/Resetting/reset_content.html.twig` i ma kod:\\n\\n```twig\\n{% trans_default_domain 'FOSUserBundle' %}\\n\\n<div class=\\\"container eternity-form\\\">\\n    <div class=\\\"forgot-password-section section-title reg-header\\\">\\n        <div class=\\\"section-title\\\">\\n            <h3>Reset Password</h3>\\n        </div>\\n        {{ form_start(form, { 'action': path('fos_user_resetting_reset', {'token': token}), 'attr': { 'class': 'fos_user_resetting_reset' } }) }}\\n        {{ form_widget(form) }}\\n        <div>\\n            <input type=\\\"submit\\\" class=\\\"btn btn-danger btn-block\\\" value=\\\"{{ 'resetting.reset.submit'|trans }}\\\" />\\n        </div>\\n        {{ form_end(form) }}\\n    </div>\\n</div>\\n```\\n\\nFormularz zmiany hasła tak:\\n\\n![](http://i.imgur.com/N7Ot9V6.png)\\n\\n#### Panel użytkownika\\n\\nJeśli jako zalogowany użytkownik wybierzemy `MyAccount` z menu, zostaniemy przekierowani do widoku konta. Jego html generowany jest z pliku `app/Resources/FOSUserBundle/views/Profile/show_content.html.twig`\\n\\n```twig\\n{% trans_default_domain 'FOSUserBundle' %}\\n\\n<div class=\\\"container eternity-form\\\">\\n    <div class=\\\"section-title reg-header\\\">\\n        <h3>User Profile</h3>\\n        <div class=\\\"fos_user_user_show\\\">\\n            <p>{{ 'profile.show.username'|trans }}: {{ user.username }}</p>\\n            <p>{{ 'profile.show.email'|trans }}: {{ user.email }}</p>\\n            <a href=\\\"{{ path('homepage') }}\\\" class=\\\"btn btn-primary\\\">Edit Places</a>\\n            <a href=\\\"{{ path('fos_user_profile_edit') }}\\\" class=\\\"btn btn-info\\\">Edit Profile</a>\\n            <a href=\\\"{{ path('fos_user_change_password') }}\\\" class=\\\"btn btn-success\\\">Change Password</a>\\n        </div>\\n    </div>\\n</div>\\n```\\n\\ni wygląda tak:\\n\\n![profile](http://i.imgur.com/jwR8Nlg.png)\\n\\nPrzycisk `Edit Places` będzie prowadził do głównej funkcjonalności aplikacji. Jednak żeby dokończyć to co związane z `FOSUserBundle` pokażemy teraz edycję profilu i zmanę hasła. Edycja profilu: `app/Resources/FOSUserBundle/views/Profile/edit_content.html.twig`\\n\\n```twig\\n{% trans_default_domain 'FOSUserBundle' %}\\n\\n<div class=\\\"container eternity-form\\\">\\n\\n    {{ form_start(form, { 'action': path('fos_user_profile_edit'), 'attr': { 'class': 'fos_user_profile_edit' } }) }}\\n\\n    <div class=\\\"section-title reg-header\\\">\\n        <h3>Edit Profile</h3>\\n        <div>\\n            {{ form_widget(form) }}\\n        </div>\\n    </div>\\n\\n    <div class=\\\"registration-form-action clearfix\\\">\\n        <div>\\n            <a href=\\\"{{ path('fos_user_profile_show') }}\\\" class=\\\"btn btn-success pull-left blue-btn \\\">\\n                <i class=\\\"fa fa-chevron-left\\\"></i>&nbsp; &nbsp;Back To Profile\\n            </a>\\n            <button type=\\\"submit\\\" class=\\\"btn btn-success pull-right green-btn \\\">{{ 'profile.edit.submit'|trans }} &nbsp; <i class=\\\"fa fa-chevron-right\\\"></i></button>\\n        </div>\\n    </div>\\n    {{ form_end(form) }}\\n</div>\\n```\\n\\n![edit](http://i.imgur.com/QVWyPri.png)\\n\\nCały formularz sprowadza się do jednego pola - `email`, ponieważ jest to jedyna własność jaką chcemy nadawać użytkownikowi.\\n\\nZmiana hasła ma szablon w pliku `app/Resources/FOSUserBundle/views/ChangePassword/change_password_content.html.twig`\\n\\n```html\\n{% trans_default_domain 'FOSUserBundle' %}\\n\\n<div class=\\\"container eternity-form\\\">\\n    <div class=\\\"section-title reg-header\\\">\\n        <h3>User Profile</h3>\\n        <div class=\\\"fos_user_user_show\\\">\\n            {{ form_start(form, { 'action': path('fos_user_change_password'), 'attr': { 'class': 'fos_user_change_password' } }) }}\\n            {{ form_widget(form) }}\\n            <div>\\n                <input type=\\\"submit\\\" class=\\\"btn btn-danger btn-block\\\" value=\\\"{{ 'change_password.submit'|trans }}\\\" />\\n            </div>\\n            {{ form_end(form) }}\\n        </div>\\n    </div>\\n</div>\\n```\\n\\n![password](http://i.imgur.com/cQkQC91.png)\\n\\nSą to wszystkie zmiany jakie zrobiłem, żeby dostosować `FOSUserBundle` do swoich wymagań. W `app/Resources/FOSUserBundle` Są pliki, których nie zmieniałem, na przykład cały katalog `Group`, który jest związany z interakcjami między użytkonikami, ale ta funkcjonalność nie jest przez nas wykorzystywana. Zostawiłem równiż e-mail do resetu hasła, który bez grafik wygląda tak:\\n\\n![reset](http://i.imgur.com/zksqsDt.png)\\n\\nAle w przypadku e-maila jest to jak najbardziej dopuszczalne.\"}],[\"markdown\",{\"markdown\":\"## AppBundle\\n\\nKiedy mamy już działającą obsługę użytkowników, warto było by dać im ciekawą funkcjonalność. Żeby zachować balans między rozbudowaną aplikacją, a dobrym przykładem postawimy następujące wymagania przed logiką biznesową aplikacji:\\n\\n+ Użytkownik może dodać dowolną liczbę miejsc do swojego konta\\n+ Miejsca wybiera się wpisując je w formulażu lub używając geolokalizacji\\n+ Dane miejsce może zostać odłączone od konta, ale nie zniknie z bazy\\n+ Do danego miejsca może być przypisanych dowolnie wielu użytkowników\\n+ Zarządanie miejscami (dodawanie, usównie, lokalizowanie) nie przeładowuje strony\\n\\n### Baza danych (Model)\\n\\nZaczniemy od przygotowania bazy. Chcemy dodać w niej tablelę z miejscami oraz utowrzyć relację wiele do wielu między nią a tabelą `users`. Tworzymy plik `src/AppBundle/Entity/Place.php` w którym definiujemy klasę odpowiadającą za reprezentowanie miejsc. Standardowo zaczynamy od własności\\n\\n```php\\n<?php\\n\\nnamespace AppBundle\\\\Entity;\\n\\nuse Doctrine\\\\ORM\\\\Mapping as ORM;\\nuse Doctrine\\\\Common\\\\Collections\\\\ArrayCollection;\\n\\n/**\\n * @ORM\\\\Entity\\n * @ORM\\\\Table(name=\\\"places\\\")\\n */\\nclass Place\\n{\\n    /**\\n     * @ORM\\\\Id\\n     * @ORM\\\\Column(type=\\\"integer\\\")\\n     * @ORM\\\\GeneratedValue(strategy=\\\"AUTO\\\")\\n     */\\n    protected $id;\\n\\n    /**\\n     * @ORM\\\\Column(name=\\\"google_id\\\", type=\\\"string\\\", nullable=true)\\n     */\\n    private $googleId;\\n\\n    /**\\n    * @ORM\\\\ManyToMany(targetEntity=\\\"User\\\", inversedBy=\\\"places\\\")\\n    * @ORM\\\\JoinTable(name=\\\"users_places\\\")\\n    */\\n    private $users;\\n\\n    /** @ORM\\\\Column(name=\\\"formatted_address\\\", type=\\\"string\\\", nullable=true)  */\\n    protected $formattedAddress;\\n\\n    /** @ORM\\\\Column(name=\\\"lon\\\", type=\\\"float\\\", precision=9, nullable=true)  */\\n    protected $lon;\\n\\n    /** @ORM\\\\Column(name=\\\"lat\\\", type=\\\"float\\\", precision=9, nullable=true)  */\\n    protected $lat;\\n\\n    /** @ORM\\\\Column(name=\\\"add_at\\\",type=\\\"datetime\\\") */\\n    protected $add_at;\\n\\n    /** @ORM\\\\Column(name=\\\"street_number\\\",type=\\\"string\\\", nullable=true) */\\n    protected $streetNumber;\\n\\n    /** @ORM\\\\Column(name=\\\"route\\\",type=\\\"string\\\", nullable=true) */\\n    protected $route;\\n\\n    /** @ORM\\\\Column(name=\\\"sublocalityLevel1\\\",type=\\\"string\\\", nullable=true) */\\n    protected $sublocalityLevel1;\\n\\n    /** @ORM\\\\Column(name=\\\"locality\\\",type=\\\"string\\\", nullable=true) */\\n    protected $locality;\\n\\n    /** @ORM\\\\Column(name=\\\"administrative_area_level_2\\\",type=\\\"string\\\", nullable=true) */\\n    protected $administrativeAreaLevel2;\\n\\n    /** @ORM\\\\Column(name=\\\"administrative_area_level_1\\\",type=\\\"string\\\", nullable=true) */\\n    protected $administrativeAreaLevel1;\\n\\n    /** @ORM\\\\Column(name=\\\"country\\\",type=\\\"string\\\", nullable=true) */\\n    protected $country;\\n```\\n\\nPoza standardowymi własnościami dotyczącymy lokalizacji mamy tu własność `$users`. W bazie danych będzie odpowiadała ona występowaniu tabeli `users_places` z identyfikatorami użytkownika i miejsca. Wymagać to będzie jeszcze paru zmian w klasie `User`, ale o tym później. Teraz przejrzymy metody klasy `Place`.\\n\\n```php?start_inline=1\\n    public function __construct() {\\n        $this->users = new ArrayCollection();\\n        $this->setAddAt(new \\\\DateTime(\\\"now\\\"));\\n    }\\n```\\n\\nKonstruktor ustawia datę dodania miejsca oraz zmienną `$users` jako `ArrayCollection`. Jest to obiekt podobny do zwykłej tablicy, ale ma kilka metod wygodnych dla stosowania go jako zbiór obiektów. Mamy też geter i setter dla `$googleId`:\\n\\n```php?start_inline=1\\n    /**\\n     * @return mixed\\n     */\\n    public function getGoogleId()\\n    {\\n        return $this->googleId;\\n    }\\n\\n    /**\\n     * @param mixed $googleId\\n     */\\n    public function setGoogleId($googleId)\\n    {\\n        $this->googleId = $googleId;\\n    }\\n```\\n\\nDo operowani na zmiennej `$users` mamy trzy metody.\\n\\n```php?start_inline=1\\n    /**\\n     * @return mixed\\n     */\\n    public function getUsers()\\n    {\\n        return $this->users;\\n    }\\n\\n    /**\\n     * @param mixed $user\\n     */\\n    public function addUsers(User $user)\\n    {\\n        if (!$this->users->contains($user))\\n        {\\n            $this->users->add($user);\\n        }\\n    }\\n\\n    public function removeUser(User $user)\\n    {\\n        $this->users->removeElement($user);\\n    }\\n```\\n\\nWidać jak korzystamy tu z zalet `ArrayCollection`, gdyby `$users` było zwykłą tablicą, te operacje wyglądały by nieco mniej zgrabnie.\\n\\nKolejnymi metodami są pary getterów i setterów dla adresu: `$formattedAddress`, współrzędnych `$lon`, `$lat` i czasu dodania adresu do bazy `$addAt`:\\n\\n```php?start_inline=1\\n    /**\\n     * @return mixed\\n     */\\n    public function getFormattedAddress()\\n    {\\n        return $this->formattedAddress;\\n    }\\n\\n    /**\\n     * @param mixed $formattedAddress\\n     */\\n    public function setFormattedAddress($formattedAddress)\\n    {\\n        $this->formattedAddress = $formattedAddress;\\n    }\\n\\n    /**\\n     * @return mixed\\n     */\\n    public function getLon()\\n    {\\n        return $this->lon;\\n    }\\n\\n    /**\\n     * @param mixed $lon\\n     */\\n    public function setLon($lon)\\n    {\\n        $this->lon = $lon;\\n    }\\n\\n    /**\\n     * @return mixed\\n     */\\n    public function getLat()\\n    {\\n        return $this->lat;\\n    }\\n\\n    /**\\n     * @param mixed $lat\\n     */\\n    public function setLat($lat)\\n    {\\n        $this->lat = $lat;\\n    }\\n\\n    /**\\n     * @return mixed\\n     */\\n    public function getAddAt()\\n    {\\n        return $this->add_at;\\n    }\\n\\n    /**\\n     * @param mixed $add_at\\n     */\\n    public function setAddAt($add_at)\\n    {\\n        $this->add_at = $add_at;\\n    }\\n```\\n\\nDla pozostałych parametrów nie będziemy stosować już pary getter, setter. Z powodu ich ustrukturyzowanego występowania w api google maps, z którego będziemy korzystać ustawimy jeden setter dla nich wszystkich. Gettery nie będą nam potrzebne więc metody do obsługi pozostałych parametów wyglądają następująco:\\n\\n```php?start_inline=1\\n    public function getParams()\\n    {\\n        return [\\n            \\\"country\\\",\\n            \\\"administrative_area_level_1\\\",\\n            \\\"administrative_area_level_2\\\",\\n            \\\"locality\\\",\\n            \\\"sublocality_level_1\\\",\\n            \\\"route\\\",\\n            \\\"street_number\\\"\\n        ];\\n    }\\n\\n    public function setParam($name,$value)\\n    {\\n        if(in_array($name,$this->getParams())){\\n            $name = lcfirst(str_replace(' ', '', ucwords(str_replace('_', ' ', $name))));//camelcase\\n            $this->$name  = $value;\\n        }\\n    }\\n```\\n\\nPierwsza z nich zwraca listę nazw obsługiwanych przez drugą metodę, te nazwy można jako `string` podstawić jako `$name`. Funkcja zaczynająca się od `lcfirst` odpowiada za zmianę notacji z `a_b` na `aB`, czyli usówa podkreślenia i zmienia małe litery po podkreśleniach na duże.\\n\\nZostała nam jeszcze jedna metoda - do rzutowania obiektu na string.\\n\\n```php?start_inline=1\\n    public function __toString()\\n    {\\n        return json_encode([\\\"id\\\"=>$this->getGoogleId(),\\\"address\\\"=>$this->getFormattedAddress()],JSON_UNESCAPED_UNICODE);\\n    }\\n}\\n```\\n\\nŻeby tabela łącząca została poprawnie dodana wprowadzimy teraz zmiany w klasie `User` i dodamy do pliku `src/AppBundle/Entity/User.php` linie:\\n\\n```php?start_inline=1\\nuse Doctrine\\\\Common\\\\Collections\\\\ArrayCollection;\\n\\n(...)\\n\\n    /**\\n     * @ORM\\\\ManyToMany(targetEntity=\\\"Place\\\", mappedBy=\\\"users\\\", cascade={\\\"persist\\\"})\\n     */\\n    private $places;\\n\\n    /**\\n     * @return mixed\\n     */\\n    public function getPlaces()\\n    {\\n        return $this->places->toArray();\\n    }\\n\\n\\n    public function removePlace(Place $place)\\n    {\\n        $this->places->remove($place);\\n    }\\n\\n    /**\\n     * @param mixed $place\\n     */\\n    public function addPlace(Place $place)\\n    {\\n        if (!$this->places->contains($place))\\n        {\\n            $this->places->add($place);\\n        }\\n    }\\n\\n    public function __construct()\\n    {\\n        parent::__construct();\\n        $this->places = new ArrayCollection();\\n    }\\n\\n```\\n\\nMożemy teraz zregenerować bazę danych komendą:\\n\\n```\\nphp bin/console doctrine:schema:update --force\\n```\\n\\nNa koniec załączam wizualizację schematu bazy\\n\\n![database](http://i.imgur.com/jfjLAoV.png)\\n\\n\\n### Logika serwera (Kontroler)\\n\\nMamy model. Teraz kontrolery. Na końcu zrobimy widoki. W defaultowym kontrolerze (`src/AppBundle/Controller/DefaultController`) ustawimy przekierowanie zalogowanych użytkowników do ścieżki z miejscami:\\n\\n```php?start_inline=1\\n    /**\\n     * @Route(\\\"/\\\", name=\\\"homepage\\\")\\n     */\\n    public function indexAction(Request $request)\\n    {\\n        if($this->getUser()){\\n            return $this->redirectToRoute('places');\\n        }\\n        return $this->render('default/index.html.twig', []);\\n    }\\n```\\n\\nTo wszystko jeśli chodzi o defaultową logikę.\\nW kontrolerze `src/AppBundle/Controller/PlacesController` będzie znacznie więcej logiki. Oto metoda\\ndo wyświetlania ścieżki `places`, do której chcemy przekierowywać logowanych użytkowników.\\n\\n```php\\n<?php\\nnamespace AppBundle\\\\Controller;\\n\\nuse Symfony\\\\Bundle\\\\FrameworkBundle\\\\Controller\\\\Controller;\\nuse Sensio\\\\Bundle\\\\FrameworkExtraBundle\\\\Configuration\\\\Route;\\nuse Sensio\\\\Bundle\\\\FrameworkExtraBundle\\\\Configuration\\\\Method;\\nuse Symfony\\\\Component\\\\HttpFoundation\\\\Request;\\nuse Symfony\\\\Component\\\\HttpFoundation\\\\Response;\\nuse AppBundle\\\\Entity\\\\Place;\\nuse AppBundle\\\\Form\\\\PlaceType;\\nuse Symfony\\\\Component\\\\HttpFoundation\\\\JsonResponse;\\n\\nClass PlacesController extends Controller\\n{\\n    /**\\n     * @Route(\\\"/profile/places\\\", name=\\\"places\\\")\\n     * @Method(\\\"GET\\\")\\n     * @return Response\\n     */\\n    public function editPlacesAction()\\n    {\\n        if(!$this->getUser()){\\n            return $this->redirectToRoute('fos_user_security_login');\\n        }\\n\\n        $place = new Place();\\n        $places = $this->getUser()->getPlaces();\\n        $form = $this->createForm(PlaceType::class, $place);\\n\\n        return $this->render(':places:places.html.twig', array(\\n            'places' => $places,\\n            'form' => $form->createView(),\\n        ));\\n    }\\n```\\n\\nZanim przejdziemy dalej zwrócę uwagę na dwie rzeczy - pierwsza to brak obsługi formularza i przyjmowania requestów. Tworzymy tutaj formularz, wysyłamy go do Twiga, ale nie będziemy go odbierać tutaj. Jego obsługą zajmie się JavaScript. Druga rzecz to sama klasa `PlaceType` została ona tutaj zastosowana, chociaż jeszcze je nie defniowaliśmy. Zrobię małą dygresję i pokażę kod tej klasy. Jest on umieszczony w pliku `src/AppBundle/Form/PlaceType.php`\\n\\n```php\\n<?php\\n\\nnamespace AppBundle\\\\Form;\\n\\nuse Symfony\\\\Component\\\\Form\\\\AbstractType;\\nuse Symfony\\\\Component\\\\Form\\\\FormBuilderInterface;\\nuse Symfony\\\\Component\\\\Form\\\\Extension\\\\Core\\\\Type\\\\TextType;\\nuse Symfony\\\\Component\\\\Form\\\\FormTypeInterface;\\nuse Symfony\\\\Component\\\\OptionsResolver\\\\OptionsResolver;\\n\\nclass PlaceType extends AbstractType implements FormTypeInterface\\n{\\n    public function buildForm(FormBuilderInterface $builder, array $options)\\n    {\\n        $builder->add('formatted_address', TextType::class, array('label' => false));\\n    }\\n\\n    public function configureOptions(OptionsResolver $resolver)\\n    {\\n        $resolver->setDefaults(array(\\n            'data_class' => 'AppBundle\\\\Entity\\\\Place',\\n        ));\\n    }\\n}\\n```\\n\\nZ php na nasze: ta klasa odpowada z to, że formularz, który reprezentuje ma jedno pole. Wracamy teraz do kontrolera `src/AppBundle/Form/PlaceType.php`. Kolejna metoda będzie odpowiadała za zapisywanie miejsca do bazy danych\\n\\n```php?start_inline=1\\n    /**\\n     * @Route(\\\"/profile/ajax_geo_save\\\", name=\\\"ajax_geo_save\\\")\\n     * @Route(\\\"/profile/ajax_geo_save/{debug}\\\")\\n     * @Method(\\\"POST\\\")\\n     */\\n    public function ajaxGeoSave(Request $request, $debug=null)\\n    {\\n        $content = $request->getContent();\\n        $params = json_decode($content, true);\\n\\n        $formattedAddress = $params['formatted_address'];\\n        $address = $this->getAddress($formattedAddress);\\n\\n        if($debug==\\\"debug\\\") { return new JsonResponse($address); }\\n\\n        $place = $this->getPlace($address);\\n\\n        // these lines persist user relation with place, not only place\\n        $em = $this->getDoctrine()->getManager();\\n        $em->persist($place);\\n        $em->flush();\\n\\n        return new JsonResponse($address, 201);\\n    }\\n```\\n\\n\"}],[\"markdown\",{\"markdown\":\"Można ją wywołać z parametrem `debug` w ścieżce, ale nie trzeba. Działanie metody jest następujące: pobiera ona zawartość requestu do zmiennej `$content`, do zmiennej `$params` zapisuje tablicę odpowiadającą treści requestu, do zmiennej `$formattedAddress` zapisujemy wartość odpowiadającą kluczowi `formatted_address`. Jest to dokładnie to co powinno zostać wysłane przez formularz definiowany klasą `PlaceType` prezentowaną przed chwilą.\\n\\nTeraz linia `$address = $this->getAddress($formattedAddress);` robi bardzo ważną rzecz. Wysyła request do API Google w celu przetłumaczenia tego co wpisał użytkownik na to co Google rozumie jako lokalizację, którą prawdopodobnie miał na myśli. Do metody `getAddress` jeszcze przejdziemy, ale teraz dokończę omawianie metody `ajaxGeoSave`. Otrzymany adres jest tablicą. Jeśli metodę włączono z parametrem `debug` to zostaje on zwrócony jako `JSON` z kodem HTTP 200 i dalsza część metody nie jest wykonywana. W przeciwnym wypadku, czyli w sytuacji zwyczajnego użycia  wywołujemy metodę `getPlace`, która transformuje nam tablicę `$address` do obiektu `$place`. Trzy kolejne linie to zapis do bazy. Na końcu zwracamy `$address` jak z metodzie z parametrem `debug`, ale ponieważ wykonaliśmy poprawny zapis do bazy, zmieniamy kod HTTP na 201.\\n\\nMamy tu więc dwie ważne transformacje danych - z tego co wpisał użytkownik na tablicę z danymi adresowymi od Google, oraz z tablicy na naszą strukturę danych - klasę `Place`.\\n\\nMoże jednak tak się zdarzyć, że użytkownikowi nie che się pisać swojego adresu, albo zgubił się i nie wie gdzie jest. W takim wypadku możemy wykorzystać metodę `geolocation` obiektu `navigator` dostępnego w `javascript`. Zwraca ona współrzędne geograficzne. Chcieli byśmy tłumaczyć je na adres czytelny dla człowieka. Do tego posłuży druga metoda kontrolera:\\n\\n```php?start_inline=1\\n    /**\\n     * @Route(\\\"/profile/ajax_geo_location\\\", name=\\\"ajax_geo_location\\\")\\n     * @param Request $request\\n     * @Method(\\\"GET\\\")\\n     * @return JsonResponse\\n     */\\n    public function ajaxGeoLocation(Request $request)\\n    {\\n        $lon = $request->get('lon');\\n        $lat = $request->get('lat');\\n\\n        $address = $this->getAddress([$lat,$lon]);// get address from coords\\n\\n        return new JsonResponse($address);\\n    }\\n```\\n\\nJej struktura jest bardzo przejrzysta. Pobieramy dane z requesta, wykonujemy transformację metodą `getAddress`, zwracamy tablicę z adresem. Należy zauważyć, że tym razem `getAddress` przyjmuję tablicę a nie string. Mimo to działa poprawnie, ponieważ w zależności od tego co dostała metoda `getAddress` wykonuje nieco inną logikę dostosowaną zarówno do tekstowych adresów jak i par współrzędnych.   \\n\\nKolejna metoda wiąże się ze smutnym eventem jakim jest usunięcie adresu przez użytkownika.\\n\\n```php?start_inline=1\\n    /**\\n     * @Route(\\\"/profile/ajax_geo_delete/{googleId}\\\", name=\\\"ajax_geo_delete\\\")\\n     * @Method(\\\"DELETE\\\")\\n     * @param googleId\\n     * @return JsonResponse\\n     */\\n    public function ajaxGeoDelete($googleId)\\n    {\\n        $place = $this->getDoctrine()->getRepository(\\\"AppBundle:Place\\\")->findOneBy(array(\\n            'googleId' => $googleId\\n        ));\\n\\n        if(!$place) { return new JsonResponse([\\\"error\\\"=>\\\"Place Not Found\\\"],404); }\\n\\n        $address = $this->getAddress($place->getFormattedAddress());\\n\\n        $place->removeUser($this->getUser());\\n        $em = $this->getDoctrine()->getManager();\\n        $em->persist($place);\\n        $em->flush();\\n\\n        return new JsonResponse($address,204);\\n    }\\n```\\n\\nAdres jest wyszukiwany po `googleId`. Jeśli nie zostanie znaleziony odsyłamy błąd `404`, jeśli zostanie, to usunięte zostaje jedynie łącznie między użytkownikiem a miejscem, natomiast miejsce cały zostaje w bazie nawet jeśli nie będzie już połączone z żadnym użytkownikiem.\\n\\nNajwyższy czas na zaprezentowanie pierwszego z transformatorów danych - metody `getAddress`\\n\\n```php?start_inline=1\\n    /**\\n     * @param $data\\n     * @return array\\n     * @throws \\\\Exception\\n     */\\n    public function getAddress($data)\\n    {\\n        if(is_string($data)){\\n            $address = str_replace(\\\" \\\", \\\"+\\\", $data); // replace all the white space with \\\"+\\\" sign to match with google search pattern\\n            $url = \\\"http://maps.google.com/maps/api/geocode/json?sensor=false&address=$address\\\";\\n        } elseif (is_array($data) && count($data)) {\\n            $url = \\\"http://maps.googleapis.com/maps/api/geocode/json?latlng=$data[0],$data[1]&sensor=false\\\";\\n        } else {\\n            throw new \\\\Exception(\\\"Incorrect args, put string or array with lat and lon\\\");\\n        }\\n\\n        $response = file_get_contents($url);\\n        $json = json_decode($response, TRUE); //generate array object from the response from the web\\n        return $json['results'][0];\\n    }\\n```\\n\\nTa metoda sprawdza czy dostała współrzędne czy tekstowy adres i w zależności od tego przygotowuje trochę inny `$url`. Następnie za pomocą najprostszego requestu `file_get_contents`  odbiera to co odpowie Google, wycina to co nie potrzebne i odsyła dalej.\\n\\nMyślę, że to dobry moment, żeby pokazać do dokładnie jest odsyłane. Wykonamy request do `ajax_geo_save` z parametrem `debug`, żeby zobaczyć jak wygląda `json` na wyjściu tej metody.\\n\\n![api1](http://i.imgur.com/My3cMbW.png)\\n![api2](http://i.imgur.com/88vr0jN.png)\\n\\nWidać, że `formatted_address`, `place_id` oraz współrzędne mają tu dobrze określone miejsce, ale pozostałe własności adresu zostały spakowane do jednej tablicy `address_components` i są tagowane za pomocą typów, które mogą występować po kilka, ale niektórych może też wcale nie być. Do przetwarzania tej tablicy do postaci zgodnej z naszym modelem danych służy ostatnia metoda, którą zaprezentuję: `getPlace`\\n\\n```php?start_inline=1\\n    /**\\n     * @param array $address\\n     * @return mixed\\n     */\\n    public function getPlace($address)\\n    {\\n        $place = $this->getDoctrine()->getRepository(\\\"AppBundle:Place\\\")->findOneBy(array(\\n            'googleId' => $address['place_id']\\n        ));\\n                if($place === null)\\n        {\\n            $place = new Place();\\n\\n            $place->setGoogleId($address['place_id']);\\n            $place->setLat($address['geometry']['location']['lat']);\\n            $place->setLon($address['geometry']['location']['lng']);\\n            $place->setFormattedAddress($address['formatted_address']);\\n```\\n\\nNa początku sprawdzamy czy dany adres już znajduje się w naszej bazie. Jeśli tak, to możemy pominąć całe transformowanie, dodamy do niego aktualnego użytkownika i wystarczy. Załóżmy jednak, że to nowy adres. W takim przypadku powinniśmy w pierwszej kolejności ustawić mu `google_id`, współrzędne, oraz jego sformatowaną postać. Następnie zajmiemy się otagowanymi składowymi adresu.\\n\\n```php?start_inline=1\\n            $params = $place->getParams();\\n\\n            foreach($address[\\\"address_components\\\"] as $component){\\n                foreach($params as $paramId => $param){\\n                    if(in_array($param,$component[\\\"types\\\"])){\\n                        $place->setParam($param,$component[\\\"long_name\\\"]);\\n                        unset($params[$paramId]);\\n                    }\\n                }\\n            }\\n        }\\n```\\n\\nBędziemy je wyciągać w podwójnej pętli. Po komponentach adresu oraz po parametrach jakich szukamy. Jeśli jakiś parametr zostanie znaleziony, zapiszemy właściwość i usuniemy go z tablicy parametrów, tak, żeby nie nabijał pustych pętli.\\n\\n```php?start_inline=1\\n        $place->addUsers($this->getUser());\\n\\n        return $place;\\n    }\\n}\\n```\\n\\nNa koniec niezależnie od tego, czy tworzyliśmy nowe miejsce, czy też wzięliśmy je z bazy, dołączamy do miejsca obecnego użytkownika. Jeśli zastanawia cię dlaczego nie sprawdzam czy ten użytkownik jest już dodany, to odpowiedź jest prosta. Sprawdzam, ale na poziomie metody dostępnej w `ArrayCollection` w encji a nie kontrolerze.\\n\\n\\n\\n### Widoki\\n\\nBardzo dużą część widoków już przerobiliśmy. Zostały nam jeszcze dwa. Pierwszy z nich to strona główna dla niezalogowanych użytkowników. Strona po prostu informuje do czego jest aplikacja. Widok znajduje się w pliku `app/Resources/views/default/index.html.twig`, ma kod\\n\\n```twig\\n{% extends 'base.html.twig' %}\\n\\n{% block body %}\\n    {{ parent() }}\\n\\n\\n    <div class=\\\"container eternity-form\\\">\\n        <div class=\\\"section-title reg-header\\\">\\n            <h3>Places</h3>\\n            <p>App to collect your addresses</p>\\n\\n        </div>\\n    </div>\\n{% endblock %}\\n```\\n\\ni wygląda tak:\\n\\n![olaces](http://i.imgur.com/7mkjpKI.png)\\n\\nCiekawszym widokiem jest widok miejsc. Umieściliśmy go w pliku `app/Resources/views/places/places.html.twig`\\n\\nJego kod html jest dość prosty:\\n\\n```twig\\n{% extends 'base.html.twig' %}\\n\\n{% block body %}\\n    {{ parent() }}\\n\\n    <div class=\\\"container eternity-form\\\">\\n        <div class=\\\"section-title reg-header\\\">\\n            <h3>Update your address</h3>\\n\\n            <br>\\n            <p id=\\\"info\\\"></p>\\n\\n            <div class=\\\"list\\\">\\n            {% for place in places %}\\n                <div data-id=\\\"{{ place.googleId }}\\\" class=\\\"btn-group place-elem\\\" role=\\\"group\\\">\\n                    <button type=\\\"button\\\" class=\\\"place-name btn btn-default\\\">{{ place.formattedAddress }}</button>\\n                    <button type=\\\"button\\\" class=\\\"place-delete btn btn-danger delete\\\">Delete</button>\\n                </div>\\n            {% endfor %}\\n            </div>\\n\\n            <div class=\\\"input-group\\\">\\n                <input name=\\\"formatted_address\\\" type=\\\"text\\\" class=\\\"form-control\\\" placeholder=\\\"Type your location...\\\">\\n                <span class=\\\"input-group-btn place-padding-bottom\\\">\\n                    <button id=\\\"my_location\\\" class=\\\"btn btn-info\\\">Check my location</button>\\n                    <button id=\\\"save_location\\\" class=\\\"btn btn-default\\\">Save location</button>\\n                </span>\\n            </div>\\n        </div>\\n    </div>\\n{% endblock %}\\n```\\n\\nWarto zwrócić uwagę na to jak sprawnie będą uzupełniały się tutaj metody zarządzania widokiem po stronie serwera (pętla w twigu) oraz po stronie klienta. Od momentu wygenerowania początkowego widoku wszystkie zmiany robi już `javascript`.\\n\\nWidok wyposażony jest w swój styl, który zaciąga rozszerzając blok `stylesheets`\\n\\n```twig\\n{% block stylesheets %}\\n    {{ parent() }}\\n    <link href=\\\"{{ asset('bundles/app/css/place.css') }}\\\" rel=\\\"stylesheet\\\" />\\n{% endblock %}\\n```\\n\\nStyl znajduje się w pliku `src/AppBundle/Resources/public/css/place.css` i ma tylko 4 reguł:\\n\\n```css\\n.place-name {\\n    width: 74%;\\n}\\n\\n.place-delete {\\n    width: 26%;\\n}\\n\\n.place-padding-bottom{\\n    padding-bottom: 30px;\\n}\\n\\n.place-elem {\\n    padding-bottom: 5px;\\n    width: 100%;\\n}\\n```\\n\\nJeśli piszę w `css` to zwykle ograniczam się do takiego właśnie minimalizmu. Co innego z `javascriptem`. W widoku (`app/Resources/views/places/places.html.twig`) jest go objętościowo więcej niż `html`. Spełnia on następujące zadania:\\n\\n```js\\n{% block javascripts %}\\n{{ parent() }}\\n\\n<script>\\n    var places = [];\\n    {% for place in places %}\\n    places.push({{ place|raw }});\\n    {% endfor %}\\n```\\n\\nPrzy ładowaniu strony zapisuje do JavaScriptowej zmiennej `places` tablicę z tekstowymi reprezentacjami obiektów `Place` przekazanych do twigowej zmiennej. Będą nam one potrzebne do unikania duplikacji treści. Dzięki temu rozwiązaniu mamy stan aplikacji w zmiennej oraz na ekranie jednocześnie.\\n\\nNastępnie robię to co zawsze robię rozpoczynając skrypt\\n\\n```js\\n    var info = document.getElementById(\\\"info\\\");\\n    var area = document.getElementsByClassName(\\\"section-title\\\")[0];\\n    var list = document.getElementsByClassName(\\\"list\\\")[0];\\n```\\n\\nidentyfikuję potrzebne elementy za pomocą selektorów. Później robię to co zawsze robię w skryptach po identyfikacji elementów.\\n\\n```js\\n    area.addEventListener('click',function(e){\\n       if(e.target.id=='my_location'){\\n           getLocation();\\n       } else if(e.target.id=='save_location') {\\n           saveLocation();\\n       } else if(e.target.classList.contains('delete')){\\n           deleteLocation(e.target.parentNode.dataset.id);\\n       }\\n    });\\n```\\n\\nDodaję jeden (staram się zwykle dodawać tylko jeden) listener, w którym przyporządkowują akcje wykrytym eventom. Mamy tu do wyboru trzy akcje: sprawdzenie lokacji za pomocą obiektu `navigarot` przeglądarki, zapisanie i usunięcie lokacji.\\n\\nZa obsługę `navigatora` odpowiada poniższy kod.\\n\\n```js\\n    function getLocation() {\\n        if (navigator.geolocation) {\\n            navigator.geolocation.getCurrentPosition(showPosition);\\n        } else {\\n            info.innerHTML = \\\"Geolocation is not supported by this browser.\\\";\\n        }\\n    }\\n```\\n\\nJeśli użytkownik wyrazi zgodę na dostęp do jego lokalizacji, jest ona przekazywana do funkcji `showPosition`.\\n\\n```js\\n    function showPosition(position) {\\n        $.ajax({\\n            url: \\\"{{ path('ajax_geo_location') }}\\\",\\n            method: \\\"GET\\\",\\n            data: {\\n                lat: position.coords.latitude,\\n                lon: position.coords.longitude\\n            },\\n            success: function(msg){\\n                $(\\\"#my_location\\\").html('Position obtained');\\n                $(\\\"input[name=formatted_address]\\\").val(msg['formatted_address']);\\n            }});\\n    }\\n```\\n\\nTa funkcja z kolei wysyła odpowiedni request i wypełnia pole formularza sformatowanym adresem odpowiadającym współrzędnych przeglądarki.\\n\\nZapisanie lokacji - czyli wysłanie formularza realizowane jest przez kolejną funkcję:\\n\\n```js\\n    function saveLocation(){\\n        $.post('{{ path('ajax_geo_save') }}',\\n                JSON.stringify({formatted_address: $(\\\"input[name=formatted_address]\\\").val()})\\n        ).done(function(res){\\n\\n        if(places.filter(function(obj) {return obj.id == res.place_id}).length){\\n            return;\\n        }\\n\\n        places.push({'id':res.place_id,'addess':res.formatted_address});\\n        list.innerHTML += '<div data-id=\\\"'+res.place_id+'\\\" class=\\\"btn-group place-elem\\\" role=\\\"group\\\">\\\\\\n            <button type=\\\"button\\\" class=\\\"place-name btn btn-default\\\">'+res.formatted_address+'</button>\\\\\\n            <button type=\\\"button\\\" class=\\\"place-delete btn btn-danger delete\\\">Delete</button>\\\\\\n            </div>';\\n        });\\n    }\\n```\\n\\nJej działanie zaczyna się od wysłania requestu POST z treścią formularza. Jeśli otrzymamy odpowiedź, sprawdzamy czy miejsce jest już przypisane do użytkownika filtrując tablicę `places`. Jeśli tak, nic więcej nie robimy. Jeśli nie było, to dodajemy je do tablicy `places` i do listy miejsc dołączamy lokację za pomocą składni `.innerHTML +=`. Są do tego metody polegające na traktowaniu htmla jako drzewa DOM, ale są one efektywne jeśli są stosowane w szerszym kontekście. W tym przypadku metoda doklejenia treści mimo, że mniej elegancka została wybrana ze względu na większą prostotę.\\n\\nOstatnia metoda odpowiada za usunięcie miejsca z listy miejsc użytkownika.\\n\\n```js\\n    function deleteLocation(googleId){\\n        var route = \\\"{{ path('ajax_geo_delete',{'googleId':'PLACEHOLDER'}) }}\\\";\\n        $.ajax({\\n            url: route.replace(\\\"PLACEHOLDER\\\",googleId),\\n            method: \\\"DELETE\\\"\\n        });\\n        places = places.filter(function( obj ) {\\n            return obj.id !== googleId;\\n        });\\n        list.querySelector(\\\"[data-id='\\\"+googleId+\\\"']\\\").outerHTML='';\\n    }\\n</script>\\n{% endblock %}\\n```\\n\\nTutaj odwrotnie niż przy zapisywaniu, usuwamy element z tablicy `places` i czyścimy `HTML` odpowiadający miejscu, które usuwamy. Na koniec dodajemy screen z przykładowego użytkowania:\\n\\n![](http://i.imgur.com/YwW9q5l.png)\\n\\nTo cały kod źródłowy. Nie ma tutaj testów, nie ma DoctrineFixturesBundle, nie ma panelu admina, nie ma gulpa.\\n Przede wszystkim jednak nie ma miejsca. Z tego względu wszystkie wspomniane rzeczy zostały wycięte.\\n Ten wpis i tak jest chyba najdłuższym jaki napisałem. Jego celem nie było przedstawianie kompleksowej aplikacji\\n tylko przykładu zastosowania FOSUserBundle.\\n\\nMam nadzieję, że komuś pomoże to przy wdrażaniu tej znakomitej paczki w swoim projekcie. Jak zwykle czekam na waszą krytykę,\\npytania oraz wskazówki, co mogę poprawić.\"}]],\"markups\":[[\"code\"]],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[10,5],[1,\"p\",[[0,[],0,\"Zaczniemy od dostosowania wyglądu loginu. Login będzie dziedziczył z \"],[0,[0],1,\"layout.html.twig\"],[0,[],0,\" z FOSUserBundle, a ten będzie dziedziczył z \"],[0,[0],1,\"base.html.twig\"],[0,[],0,\". Żeby więc budować dom od fundamentów, nie od dachu, przyjrzymy się bazowemu szablonowi - \"],[0,[0],1,\"app/Resources/views/base.html.twig\"],[0,[],0,\".\"]]],[10,6],[10,7],[10,8],[10,9],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"opis-projektu\">Opis projektu</h2>\n<p>Jest to projekt napisany jako jedna z funkcjonalności podczas mojej współpracy z <code>Smartselect</code>. Najzabawniejsze jest to, że był to mój pierwszy kontakt z <code>FOSUserBundle</code>, <code>Api Google Maps</code> i obiektem <code>navigator</code>. Kiedy go pisałem nie znałem <code>JavaScriptu</code>. Mimo, że przed publikacją kod wymagał odrobiny odświeżenia i dokładnego oddzielenie od innych funkcjonalności całej aplikacji, okazało się, że nie było to trudne i w tym wpisie przedstawiłem jak plik po pliku zbudować go od zera.</p>\n<p>Z wpisu dowiesz się jak zainstalować, skonfigurować i nadpisywać <code>FOSUserBundle</code> - najpopularniejszą paczkę do obsługi użytkowników w <code>Symfony</code>. Stworzymy kilka widoków związanych z logowaniem, rejestracją, zarządzaniem kontem, resetowaniem hasła i tak dalej. Jeśli lubisz front, to przez większość tego wpisu będziesz czuł się jak ryba w wodzie. Do backendu zejdziemy przy logice aplikacji, czyli wykorzystywaniu <code>API Google Maps</code> do tłumaczenia tekstowych adresów, albo współrzędnych na encje naszej bazy danych. Nie zabraknie Ajaxa, zobaczymy jak obiekt <code>navigator</code> pozwala nam dostać się do połorzenia przeglądarki oraz jak pogodzić twiga i JavaScript w jednym froncie.</p>\n<p>Działanie aplikacji możesz zobaczyć na poniższym video:</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: html--><video src=\"https://www.dropbox.com/s/nv29p3jsqscjqlv/9.ogv?dl=1\" controls></video><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>Skład kodu źródłowego to:</p>\n<pre><code>PHP 69.7% HTML 20.9% CSS 5.8% ApacheConf 3.1% JavaScript 0.5%\n</code></pre>\n<h2 id=\"instalacja\">Instalacja</h2>\n<p>Są dwa sposoby stawiania nowego projektu Symfony: <a href=\"http://symfony.com/doc/current/best_practices/creating-the-project.html\">instalacja od zera</a> oraz klonowanie z githuba.</p>\n<p>Jeśli chcesz zainstalowawć projekt najprostszym możliwym sposobem, możesz pobrać go z <a href=\"https://github.com/gustawdaniel/geo_local\">githuba</a><br>\ni zainstalować go zgodnie z instrukcją z <code>README.md</code>.</p>\n<p>W tym wpisie pokażę jak instalować projekt od zera. Możesz nie zaglądać do mojego repo i wykonując wszystkie komendy i tworząc poniższe pliki powinienneś otrzymać praktycznie to samo. Jedyne różnice będą polagać na tym, że na blogu dla większej przjejrzystości nie umieściłem kilku i tak nie używanych widoków jak panel admina czy kontakt.</p>\n<p>Wracając do instalacji. Jeśli chcesz instalować od zera to dokumentacja Symfony zaleca użycie jej instalatora.</p>\n<pre><code>symfony new geo_local &amp;&amp; cd geo_local\n</code></pre>\n<h2 id=\"fosuserbundle\">FosUserBundle</h2>\n<p>Będziemy chcieli stworzyć użytkowników. W tym celu wykorzystamy jedną z najpopularniejszych paczek - <a href=\"https://symfony.com/doc/master/bundles/FOSUserBundle/index.html\">FOSUserBundle</a>.</p>\n<pre><code>composer require friendsofsymfony/user-bundle &quot;~2.0@dev&quot;\n</code></pre>\n<p>Żeby ją wykorzystać musimy zarejestrować ją a jądrze aplikacji poprzez dodanie elementu: <code>new FOS\\UserBundle\\FOSUserBundle()</code> do tablicy <code>$bundles</code> w pliku <code>app/AppKernel.php</code>.</p>\n<p>Następnie rozszerzamy klasę <code>BaseUser</code> żeby móc modyfikować klasę opisującą Użytkowników (zakładam, że będziemy korzystać z mysql, dla innych silników baz danych konfiguracja może wyglądać trochę inaczej):</p>\n<pre><code class=\"language-php\">&lt;?php\n\nnamespace AppBundle\\Entity;\n\nuse FOS\\UserBundle\\Model\\User as BaseUser;\nuse Doctrine\\ORM\\Mapping as ORM;\n\n/**\n * @ORM\\Entity\n * @ORM\\Table(name=&quot;users&quot;)\n */\nclass User extends BaseUser\n{\n    /**\n     * @ORM\\Id\n     * @ORM\\Column(type=&quot;integer&quot;)\n     * @ORM\\GeneratedValue(strategy=&quot;AUTO&quot;)\n     */\n    protected $id;\n\n    public function __construct()\n    {\n        parent::__construct();\n        // your own logic\n    }\n}\n</code></pre>\n<p>Zmieniamy zawartość pliku: <code>app/config/security.yml</code></p>\n<pre><code class=\"language-yml\">security:\n    encoders:    \n        FOS\\UserBundle\\Model\\UserInterface: bcrypt\n\n    role_hierarchy:\n        ROLE_ADMIN:       ROLE_USER\n        ROLE_SUPER_ADMIN: ROLE_ADMIN\n\n    providers:\n        fos_userbundle:\n            id: fos_user.user_provider.username\n\n    firewalls:\n        main:\n            pattern: ^/\n            form_login:\n                provider: fos_userbundle\n                csrf_token_generator: security.csrf.token_manager\n                # if you are using Symfony &lt; 2.8, use the following config instead:\n                # csrf_provider: form.csrf_provider\n\n            logout:       true\n            anonymous:    true\n\n    access_control:\n        - { path: ^/login$, role: IS_AUTHENTICATED_ANONYMOUSLY }\n        - { path: ^/register, role: IS_AUTHENTICATED_ANONYMOUSLY }\n        - { path: ^/resetting, role: IS_AUTHENTICATED_ANONYMOUSLY }\n        - { path: ^/admin/, role: ROLE_ADMIN }\n</code></pre>\n<p>Na koniec w pliku <code>app/config/config.yml</code> odkomentowujemy linię zawierającą wpis <code>#translator:      { fallbacks: [&quot;%locale%&quot;] }</code>. I na końcu dodajemy:</p>\n<pre><code class=\"language-yml\">fos_user:\n    db_driver: orm\n    firewall_name: main\n    user_class: AppBundle\\Entity\\User\n</code></pre>\n<p>Powinniśmy też dodać dwie linie do routingu <code>app/config/routing.yml</code>:</p>\n<pre><code class=\"language-yml\">fos_user:\n    resource: &quot;@FOSUserBundle/Resources/config/routing/all.xml&quot;\n</code></pre>\n<p>Żeby wszystko działało powinniśmy jeszcze ustawić sobie parametry połączenia z bazą danych. W moim przypadku sprowadza się to do ustawienia: wpisu <code>database_name: geo_local</code> w plikach: <code>app/config/parameters.yml</code> i <code>app/config/parameters.yml.dist</code>.</p>\n<p>Tworzymy bazę danych i potrzebne tabele za pomocą komend:</p>\n<pre><code class=\"language-bash\">php bin/console doctrine:database:create\nphp bin/console doctrine:schema:update --force\n</code></pre>\n<p>Teraz wszystko powinno działać. Mam na myśli, że po uruchomieniu serwera komendą <code>php bin/console server:run</code> i wpisaniu w przeglądarkę adresu <code>127.0.0.1:8000/login</code> zobaczymy coś takiego:</p>\n<p><img src=\"http://i.imgur.com/cCUzKD4.png\" alt=\"domyślny_login_fos_user_bundle\" loading=\"lazy\"></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id=\"nadpisywanie-zachowania-fosuserbundle\">Nadpisywanie zachowania FOSUserBundle</h3>\n<p>Mamy teraz dwa problemy, pierwszy, że nie wygląda to ładnie, drugi, że chcemy zamiast <code>username</code> używać <code>email</code>, a po zalogowaniu chcemy dodać nasze własne przekierowanie. Zaczniemy od logiki, a front zostawimy na później.</p>\n<h4 id=\"zast%C4%85pienie-username-przez-e-mail\">Zastąpienie <code>username</code> przez <code>e-mail</code></h4>\n<p>Bardzo czytelną instrukcję pozbywania się pola <code>username</code> można znaleźć na <a href=\"http://stackoverflow.com/questions/8832916/remove-replace-the-username-field-with-email-using-fosuserbundle-in-symfony2\">stacku</a>. W klasie <code>User</code> nadpisujemy setter dla pola e-mail.</p>\n<pre><code class=\"language-php?start_inline=1\">public function setEmail($email)\n{\n    $email = is_null($email) ? '' : $email;\n    parent::setEmail($email);\n    $this-&gt;setUsername($email);\n\n    return $this;\n}\n</code></pre>\n<p>Nie podążymy jednak za tą instrukcję zbyt dosłownie, dlatego, że w oficjalnej dokumentacji można wyczytać między wierszami lepszy sposób. Wspomagając się dokumentacją <a href=\"http://symfony.com/doc/master/bundles/FOSUserBundle/overriding_forms.html\">nadpisywania formularzy</a>, tworzymy plik <code>src/AppBundle/Form/RegistrationType.php</code> który nadpisze nam domyśny formularz rejestracji. Przy rejestracji chcemy wymagać od użytkownika tylko jednego hasła, dlatego upieczemy dwie pieczenie na jednym ogniu nadpisując ten formulaż. Oto treść pliku:</p>\n<pre><code class=\"language-php\">&lt;?php\nnamespace AppBundle\\Form;\n\nuse Symfony\\Component\\Form\\AbstractType;\nuse Symfony\\Component\\Form\\FormBuilderInterface;\nuse Symfony\\Component\\Form\\Extension\\Core\\Type\\PasswordType;\n\nclass RegistrationType extends AbstractType\n{\n    public function buildForm(FormBuilderInterface $builder, array $options)\n    {\n        $builder-&gt;remove('username')\n            -&gt;remove('plainPassword')\n            -&gt;add('plainPassword',PasswordType::class);\n    }\n\n    public function getParent()\n    {\n        return 'FOS\\UserBundle\\Form\\Type\\RegistrationFormType';\n    }\n\n    public function getBlockPrefix()\n    {\n        return 'app_user_registration';\n    }\n}\n</code></pre>\n<p>Usuwając i dodając hasło pozbywamy się dość ciekawej i zaawansowanej sztuczki z powtarzaniem tego pola, jaką stosuje <code>FOSUserBundle</code>. Analogicznie nadpisujemy edycję profilu <code>src/AppBundle/Type/ProfileType.php</code>:</p>\n<pre><code class=\"language-php\">&lt;?php\nnamespace AppBundle\\Form;\n\nuse Symfony\\Component\\Form\\AbstractType;\nuse Symfony\\Component\\Form\\FormBuilderInterface;\n\nclass ProfileType extends AbstractType\n{\n    public function buildForm(FormBuilderInterface $builder, array $options)\n    {\n        $builder-&gt;remove('username');\n    }\n\n    public function getParent()\n    {\n        return 'FOS\\UserBundle\\Form\\Type\\ProfileFormType';\n    }\n\n    public function getBlockPrefix()\n    {\n        return 'app_user_profile';\n    }\n}\n</code></pre>\n<p>Rejestrujemy nasze formularze jako usługi modyfikując plik <code>app/config/services.yml</code>:</p>\n<pre><code class=\"language-yml\">services:\n    app.form.registration:\n        class: AppBundle\\Form\\RegistrationType\n        tags:\n            - { name: form.type, alias: app_user_registration }\n    app.form.profile:\n        class: AppBundle\\Form\\ProfileType\n        tags:\n            - { name: form.type, alias: app_user_profile }\n</code></pre>\n<p>Na końcu w konfiguracji paczki ustawiamy nasze formularze jako te, które mają nadpisać domyślne.</p>\n<pre><code class=\"language-yml\">fos_user:\n    db_driver: orm\n    firewall_name: main\n    user_class: AppBundle\\Entity\\User\n    registration:\n        form:\n            type: AppBundle\\Form\\RegistrationType\n    profile:\n        form:\n            type: AppBundle\\Form\\ProfileType\n</code></pre>\n<p>Nie ruszamy w ogóle walidacji. Należy pamiętać, że <a href=\"http://stackoverflow.com/questions/8832916/remove-replace-the-username-field-with-email-using-fosuserbundle-in-symfony2\">link</a> z instrukcją odnosił się do wersji 2 Symfony, a w naszym projekcie używamy 3.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"przekierowanie-po-logowaniu\">Przekierowanie po logowaniu</h4>\n<p>Domyślnie po zalogowaniu <code>FOSUserBundle</code> przekierowuje nas do profilu użytkownika. Jest to logiczne, ale nie praktyczne w naszym przypadku. Główna funkcjonalność aplikacji nie będzie polegała na zmienianiu swojego e-maila i hasła. Zamiast tego chcemy przekierować użytkownika do ścieżki nazywanej <code>homepage</code>, a dopiero jej kontroler będzie wysyłał zalogowanych do panelu z miejscami, a nie zalogowanych do strony informacyjnej. Żeby po zalogowaniu móc przekierować użytkownika do <code>homepage</code> wykonamy następujące zmiany: dodamy plik <code>src/AppBundle/Security/LoginSuccessHandler.php</code> o treści:</p>\n<pre><code class=\"language-php\">&lt;?php\nnamespace AppBundle\\Security;\n\nuse Symfony\\Component\\Security\\Http\\Authentication\\AuthenticationSuccessHandlerInterface;\nuse Symfony\\Component\\Security\\Core\\Authentication\\Token\\TokenInterface;\nuse Symfony\\Component\\Security\\Core\\Authorization\\AuthorizationChecker;\nuse Symfony\\Component\\HttpFoundation\\Request;\nuse Symfony\\Component\\HttpFoundation\\RedirectResponse;\nuse Symfony\\Component\\Routing\\Router;\n\nclass LoginSuccessHandler implements AuthenticationSuccessHandlerInterface {\n\n    protected $router;\n    protected $authorizationChecker;\n\n    public function __construct(Router $router, AuthorizationChecker $authorizationChecker) {\n        $this-&gt;router = $router;\n        $this-&gt;authorizationChecker = $authorizationChecker;\n    }\n\n    public function onAuthenticationSuccess(Request $request, TokenInterface $token) {\n        return new RedirectResponse($this-&gt;router-&gt;generate('homepage'));\n    }\n}\n</code></pre>\n<p>W serwisach (<code>app/config/services.yml</code>) powinniśmy dodać usługę:</p>\n<pre><code class=\"language-yml\">    authentication.handler.login_success_handler:\n        class:  AppBundle\\Security\\LoginSuccessHandler\n        arguments:  ['@router', '@security.authorization_checker']\n</code></pre>\n<p>Powinniśmy dodać parametr <code>success_handler</code> do pliku <code>app/config/security.yml</code></p>\n<pre><code class=\"language-yml\">    firewalls:\n        main:\n            pattern: ^/\n            form_login:\n                provider: fos_userbundle\n                csrf_token_generator: security.csrf.token_manager\n                success_handler: authentication.handler.login_success_handler\n</code></pre>\n<h3 id=\"nadpisanie-wygl%C4%85du-fosuserbundle\">Nadpisanie wyglądu FOSUserBundle</h3>\n<p>Teraz mając odpowiednią ilość pól w formularzu możemy zmienić wygląd, tak, żeby nie straszył, i nie powodował koszmarów u użytkowników. Listę ścieżek jakimi powinniśmy się zająć wyświetlimy komendą:</p>\n<pre><code class=\"language-bash\">php bin/console debug:router | grep fos_user\n</code></pre>\n<p>Najprostszą metodą nadpisania domyślnego wyglądu jest wykonanie następującej komendy.</p>\n<pre><code class=\"language-bash\">mkdir -p app/Resources/FOSUserBundle/views &amp;&amp; cp -r vendor/friendsofsymfony/user-bundle/Resources/views/* &quot;$_&quot;\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"dodawanie-zewn%C4%99trznych-bibliotek\">Dodawanie zewnętrznych bibliotek</h4>\n<p>Zainstalujemy teraz biblioteki frontowe i dodamy nasze własne style oraz skrypty.<br>\nŻeby nie było problemów z cache twiga, wyłączymy go w trybie deweloperskim dodając do pliku <code>app/config/config_dev.yml</code> linie:</p>\n<pre><code class=\"language-yml\">twig:\n    cache: false\n</code></pre>\n<p>Twożymy plik <code>.bowerrc</code> o treści:</p>\n<pre><code class=\"language-json\">{\n  &quot;directory&quot;: &quot;web/bower_components/&quot;\n}\n</code></pre>\n<p>Inicjalizujemy bowera komendą:</p>\n<pre><code>bower init\n</code></pre>\n<p>Instalujemy bootstrapa 3, animate.css, components-font-awesome, jQuery i iCheck - małą bibliotekę opartą na jQuery do wyświetlania efektów związanych z zaznaczaniem pól formularzy i checkboxów:</p>\n<pre><code>bower install --save bootstrap#^3.3.7 animate.css#^3.5.2 components-font-awesome#^4.7.0 iCheck#^1.0.2 jquery#^3.1.1\n</code></pre>\n<p>Do <code>.gitignore</code> dodajemy linie:</p>\n<pre><code>/.idea\n/web/bower_components\n</code></pre>\n<p>Nie jestem dobrym frontowcem, dlatego kupuję fronty. Tak było i w tym przypadku. CSS, który załączam kupiłem na stronie<br>\n<a href=\"https://wrapbootstrap.com/theme/eternity-forms-WB0G8810G\">wrapbootstrap.com</a>. Wyciąłem z niego połowę nie wykorzystywanej<br>\nfunkcjonalności i zmieniłem linki do skinów <code>iCheck</code>. Umieściłem plik <code>css</code> w lokacji <code>src/AppBundle/Resources/public/css/forms.css</code>.</p>\n<pre><code class=\"language-css\">.eternity-form-modal {\n  background-color: #707d85;\n}\n.eternity-form {\n  font-family: 'Roboto', 'PT Sans', sans-serif;\n  font-weight: 300;\n  color: #95a5a6;\n}\n.eternity-form h1,\n.eternity-form h2,\n.eternity-form h3,\n.eternity-form h4,\n.eternity-form h5,\n.eternity-form h6 {\n  font-family: 'Roboto', 'PT Sans', sans-serif;\n  font-weight: 300;\n}\n.eternity-form .login-form-section,\n.eternity-form .forgot-password-section {\n  width: 100%;\n  max-width: 360px;\n  margin: 0 auto;\n}\n.eternity-form .login-content,\n.eternity-form .forgot-password-section,\n.eternity-form .reg-content {\n  background-color: white;\n  -o-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -ms-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -moz-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -webkit-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n}\n.eternity-form .section-title {\n  padding: 10px 20px;\n  background-color: white;\n}\n.eternity-form .section-title h3 {\n  color: #3498db;\n}\n.eternity-form .textbox-wrap {\n  padding: 20px 20px 20px 15px;\n  border-left: 5px solid transparent;\n  -moz-transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\n  -o-transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\n  -webkit-transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\n  transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\n}\n.eternity-form .textbox-wrap .input-group {\n  border: 1px solid #e0e0e0;\n  background-color: #ffffff;\n}\n.eternity-form .textbox-wrap .input-group .input-group-addon,\n.eternity-form .textbox-wrap .input-group input,\n.eternity-form .textbox-wrap .input-group .form-control {\n  background-color: transparent;\n  border: none;\n}\n.eternity-form .textbox-wrap .input-group input,\n.eternity-form .textbox-wrap .input-group .form-control,\n.eternity-form .textbox-wrap .input-group input:focus,\n.eternity-form .textbox-wrap .input-group .form-control:focus {\n  box-shadow: none;\n  outline: none;\n}\n.eternity-form .textbox-wrap .input-group i {\n  color: #cccccc;\n}\n.eternity-form .textbox-wrap.focused {\n  border-left-color: #3498db;\n  background-color: #f0f0f0;\n  -o-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\n  -ms-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\n  -moz-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\n  -webkit-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\n  box-shadow: inset 0 0 3px rgba(0,0,0,.1);\n}\n.eternity-form .green-btn,\n.eternity-form .green-btn:hover,\n.eternity-form .blue-btn {\n  background-color: #2ecc71;\n  border: none;\n}\n.eternity-form .blue-btn,\n.eternity-form .blue-btn:hover {\n  background-color: #2980b9;\n}\n.eternity-form .login-form-action {\n  padding: 15px 20px 30px 20px;\n}\n.eternity-form input[type=&quot;checkbox&quot;] {\n  width: 30px;\n}\n.eternity-form .blue {\n  color: #3498db;\n}\n.eternity-form .green {\n  color: #2ecc71;\n}\n.eternity-form .login-form-links {\n  padding: 20px;\n  margin-top: 5px;\n  -o-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\n  -ms-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\n  -moz-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\n  -webkit-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\n  box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\n  background-color: white;\n}\n.eternity-form .login-form-links a.blue:hover,\n.eternity-form .login-form-links a a.blue:focus {\n  color: #3498db;\n  text-decoration: underline;\n}\n.eternity-form .login-form-links a.green:hover,\n.eternity-form .login-form-links a a.green:focus {\n  color: #2ecc71;\n  text-decoration: underline;\n}\n.eternity-form .forget-form-action {\n  padding: 20px;\n}\n.eternity-form .registration-form-section {\n  max-width: 620px;\n  margin: 0 auto;\n  width: 100%;\n}\n.eternity-form .reg-header {\n  -o-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -ms-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -moz-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -webkit-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n}\n.eternity-form .registration-left-section {\n  padding-left: 0;\n  padding-right: 2px;\n}\n.eternity-form .registration-right-section {\n  padding-left: 2px;\n  padding-right: 0;\n}\n.eternity-form .reg-content {\n  margin-top: 5px;\n  padding: 20px 0;\n}\n.eternity-form .registration-form-action {\n  margin-top: 5px;\n  padding: 20px;\n  -o-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -ms-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -moz-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -webkit-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  background-color: white;\n}\n.eternity-form .custom-checkbox {\n  float: left;\n}\n.eternity-form .checkbox {\n  display: inline-block;\n  padding-left: 1px;\n  margin-top: 7px;\n  margin-bottom: 0;\n}\n.eternity-form .checkbox-text {\n  line-height: 24px;\n  padding-left: 5px;\n}\n.eternity-form .form-control:-moz-placeholder {\n  font-weight: 300;\n}\n.eternity-form .form-control::-moz-placeholder {\n  font-weight: 300;\n}\n.eternity-form .form-control:-ms-input-placeholder {\n  font-weight: 300;\n}\n.eternity-form .form-control::-webkit-input-placeholder {\n  font-weight: 300;\n}\n\n.eternity-form .checkbox label {\n  font-weight: 300;\n}\n\n.eternity-form .icheckbox_square-blue {\n  display: block;\n  margin: 0;\n  padding: 0;\n  width: 22px;\n  height: 22px;\n  /*background: url(../img/blue.png) no-repeat;*/\n  background: url(&quot;../../../bower_components/iCheck/skins/square/blue.png&quot;) no-repeat;\n  border: none;\n  cursor: pointer;\n}\n.eternity-form .icheckbox_square-blue {\n  background-position: 0 0;\n}\n.eternity-form .icheckbox_square-blue.hover {\n  background-position: -24px 0;\n}\n.eternity-form .icheckbox_square-blue.checked {\n  background-position: -48px 0;\n}\n.eternity-form .icheckbox_square-blue.disabled {\n  background-position: -72px 0;\n  cursor: default;\n}\n.eternity-form .icheckbox_square-blue.checked.disabled {\n  background-position: -96px 0;\n}\n\n@media only screen and (-webkit-min-device-pixel-ratio: 1.5), only screen and (-moz-min-device-pixel-ratio: 1.5), only screen and (-o-min-device-pixel-ratio: 3/2), only screen and (min-device-pixel-ratio: 1.5) {\n  .eternity-form .icheckbox_square-blue {\n    background-image: url(&quot;../../../bower_components/iCheck/skins/square/blue@2x.png&quot;);\n    -webkit-background-size: 240px 24px;\n    background-size: 240px 24px;\n  }\n}\n@media (max-width: 767px) {\n  .eternity-form .registration-left-section {\n    padding-right: 0;\n  }\n  .eternity-form .registration-right-section {\n    padding-left: 0;\n  }\n}\n@media (max-width: 380px) {\n  .eternity-form .blue-btn,\n  .eternity-form .green-btn {\n    font-size: .8em;\n  }\n}\n</code></pre>\n<p>Potrzebujemy jeszcze jednego skryptu - <code>src/AppBundle/Resources/public/js/iCheck-config.js</code> jest to konfiguracja wtyczki <code>iCheck</code> służącej do interaktywnego podświetlania aktywnych pól formularz:</p>\n<pre><code class=\"language-js\">    $(function () {\n\n        //Custom Checkbox For Light Theme\n        $(&quot;input&quot;).iCheck({\n            checkboxClass: 'icheckbox_square-blue',\n            increaseArea: '20%'\n        });\n\n        //Custom Checkbox For Dark Theme\n        $(&quot;.dark input&quot;).iCheck({\n            checkboxClass: 'icheckbox_polaris',\n            increaseArea: '20%'\n        });\n\n        //TextBox Focus Event\n        $(&quot;.form-control&quot;).focus(function () {\n            $(this).closest(&quot;.textbox-wrap&quot;).addClass(&quot;focused&quot;);\n        }).blur(function () {\n            $(this).closest(&quot;.textbox-wrap&quot;).removeClass(&quot;focused&quot;);\n        });\n\n    });\n</code></pre>\n<p>Linkujemy go z katalogiem <code>web</code> komendą</p>\n<pre><code>php bin/console assets:install --symlink\n</code></pre>\n<p>Nie jest to najlepsza dostępna metoda. Lepszą jest zastosowanie <code>gulpa</code>, ale jest najprostsza. Przy trzech kilku plikach styli i skryptów i kilku zewnętrznych bibliotekach brak konkatenacji i minifikacji nie jest niczym strasznym. Oczywiście tworzenie pliku ze stylami bezpośrednio w katalogu web jest prostsze, ale niepoprawne.</p>\n<p>Ostatnią rzeczą jaka została nam do zrobienia jest dodanie bootstrapowych formularzy jako domyślnych dla twiga, w pliku <code>app/config/config.yml</code> dodajemy linie:</p>\n<pre><code class=\"language-yml\">twig:\n    form_themes:\n        - 'bootstrap_3_layout.html.twig'\n</code></pre>\n<h4 id=\"szablon-bazowy\">Szablon bazowy</h4>\n<!--kg-card-end: markdown--><p>Zaczniemy od dostosowania wyglądu loginu. Login będzie dziedziczył z <code>layout.html.twig</code> z FOSUserBundle, a ten będzie dziedziczył z <code>base.html.twig</code>. Żeby więc budować dom od fundamentów, nie od dachu, przyjrzymy się bazowemu szablonowi - <code>app/Resources/views/base.html.twig</code>.</p><pre><code class=\"language-html\">&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"/&gt;\n    &lt;title&gt;{% block title %}Welcome!{% endblock %}&lt;/title&gt;\n    &lt;link rel=\"icon\" type=\"image/x-icon\" href=\"{{ asset('favicon.ico') }}\"/&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    {% block meta %}{% endblock %} {% block stylesheets %}       &lt;!-- Bootstrap 3 CSS --&gt;\n    &lt;link rel=\"stylesheet\" href=\"{{ asset('bower_components/bootstrap/dist/css/bootstrap.min.css') }}\"&gt;\n    &lt;!-- Eternity Login , Registration &amp; Forgot Password Forms CSS --&gt;\n    &lt;link href=\"{{ asset('bundles/app/css/forms.css') }}\" rel=\"stylesheet\"/&gt;\n    {% endblock %}\n&lt;/head&gt;\n\n&lt;body&gt; {% block body %}\n&lt;nav class=\"navbar navbar-default\"&gt;\n    &lt;div class=\"container\"&gt;\n        &lt;div class=\"navbar-header\"&gt;\n            &lt;button type=\"button\" class=\"navbar-toggle collapsed\" data-toggle=\"collapse\" data-target=\"#navbar\"\n                    aria-expanded=\"false\" aria-controls=\"navbar\"&gt;&lt;span class=\"sr-only\"&gt;Toggle navigation&lt;/span&gt;\n                &lt;span class=\"icon-bar\"&gt;&lt;/span&gt;\n                &lt;span class=\"icon-bar\"&gt;&lt;/span&gt;\n                &lt;span class=\"icon-bar\"&gt;&lt;/span&gt;\n            &lt;/button&gt;\n\n            &lt;div class=\"{% if app.request.attributes.get('_route') == 'homepage' %}active{% endif %}\"&gt;\n                &lt;a class=\"navbar-brand\" href=\"{{ url('homepage') }}\"&gt;Places&lt;/a&gt;\n            &lt;/div&gt;\n\n        &lt;/div&gt;\n        &lt;!-- Collect the nav links, forms, and other content for toggling --&gt;\n        &lt;div class=\"collapse navbar-collapse\" id=\"navbar\"&gt;\n            &lt;ul class=\"nav navbar-nav navbar-right\"&gt; {% if app.user %}\n\n                &lt;li class=\"{% if app.request.attributes.get('_route') == 'fos_user_profile_show' %}list-group-item-info{% endif %}\"&gt;\n                    &lt;a href=\"{{ url('fos_user_profile_show') }}\" data-toggle=\"tooltip\"\n                       data-placement=\"bottom\"\n                       title=\"{{ 'layout.logged_in_as'|trans({'%username%': app.user.username}, 'FOSUserBundle') }}\"&gt;\n                        My Acconut\n                    &lt;/a&gt;\n                &lt;/li&gt;\n\n                &lt;li&gt;&lt;a href=\"{{ url('fos_user_security_logout') }}\"&gt;Logout&lt;/a&gt;&lt;/li&gt;\n                {% else %}\n                &lt;li class=\"{% if app.request.attributes.get('_route') == 'fos_user_security_login' %}active{% endif %}\"&gt;\n                    &lt;a href=\"{{ url('fos_user_security_login') }}\"&gt;Login&lt;/a&gt;\n                &lt;/li&gt;\n\n                &lt;li class=\"list-group-item-info {% if app.request.attributes.get('_route') == 'fos_user_registration_register' %}active{% endif %}\"&gt;\n                    &lt;a href=\"{{ url('fos_user_registration_register') }}\"&gt;Register&lt;/a&gt;\n                &lt;/li&gt;\n                {% endif %}\n            &lt;/ul&gt;\n\n        &lt;/div&gt;&lt;!-- /.navbar-collapse --&gt;\n    &lt;/div&gt;&lt;!-- /.container-fluid --&gt;\n&lt;/nav&gt;\n{% endblock %} {% block javascripts %}\n&lt;script src=\"{{ asset('bower_components/jquery/dist/jquery.min.js') }}\"&gt;&lt;/script&gt;\n\n&lt;script src=\"{{ asset('bower_components/bootstrap/dist/js/bootstrap.min.js') }}\"&gt;&lt;/script&gt;\n{% endblock %}\n&lt;/body&gt;\n&lt;/html&gt;</code></pre><!--kg-card-begin: markdown--><p>Co my tu mamy? Jest <code>viewport</code> - strona działa na urządzeniach mobilnych. Podpinamy style, które mają się znaleźć wszędzie - bootstrap i forms. Dodaliśmy skrypty - jQuery i bootstrap. Nie ma tu potrzeby ładownia skryptów typu <code>iCheck</code> alby styli jak <code>animate.css</code> jeśli nie każda strona będzie ich potrzebować. Nie chcemy przecież zirytować użytkownika ciągłym animowaniem wszystkiego, tylko ucieszyć go animacjami przy logowaniu lub rejestracji - to wystarczy. Tag <code>&lt;body&gt;</code> zawiera jedynie pasek nawigacji. Nawigacja jednak posiada logikę odpowiadającą za wyświetlanie nie zalogowanemu użytkownikowi pól &quot;login&quot; i &quot;rejestracja&quot;, a zalogowanemu &quot;moje konto&quot; i &quot;wyloguj&quot;.</p>\n<h4 id=\"layout-dla-fosuserbundle\">Layout dla FOSUserBundle</h4>\n<p>Teraz przyjrzymy się plikowi <code>app/Resources/FOSUserBundle/layout.html.twig</code> - czyli szablonowi, który dziedziczy z <code>base</code> i jest jednocześnie rodzicem dla wszystkiego co będziemy nadpisywali w <code>FOSUserBundle</code>:</p>\n<pre><code class=\"language-twig\">{% extends '::base.html.twig' %}\n\n{% block title %}{% endblock %}\n\n{% block body %}\n    {{ parent() }}\n    {% block fos_user_content %}{% endblock fos_user_content %}\n{%  endblock %}\n\n{% block stylesheets %}\n    {{ parent() }}\n\n    &lt;!-- Animations CSS --&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;{{ asset('bower_components/animate.css/animate.min.css') }}&quot;&gt;\n\n    &lt;!-- Font Icons --&gt;\n    &lt;link href=&quot;https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css&quot; rel=&quot;stylesheet&quot; integrity=&quot;sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN&quot; crossorigin=&quot;anonymous&quot;&gt;\n\n    &lt;!-- Google Web Fonts --&gt;\n    &lt;link href='http://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'&gt;\n\n    &lt;style&gt;\n        .eternity-form {\n            margin-top: 6vh;\n        }\n\n        .width-min-300px {\n            width: 100%;\n            max-width: 300px;\n        }\n    &lt;/style&gt;\n{% endblock %}\n\n{% block javascripts %}\n    {{ parent() }}\n    &lt;!-- Custom Checkbox PLugin --&gt;\n    &lt;script src=&quot;{{ asset('bower_components/iCheck/icheck.min.js') }}&quot;&gt;&lt;/script&gt;\n\n    &lt;!-- For Initializing Checkbox And Focus Event For Textbox --&gt;\n    &lt;script src=&quot;{{ asset('bundles/app/js/iCheck-config.js') }}&quot;&gt;&lt;/script&gt;\n{% endblock %}\n</code></pre>\n<p>W tym pliku dodaliśmy style i skrypty potrzebne tylko przy obsłudze użytkownika oraz podpięliśmy blok <code>fos_user_content</code> bezpośrednio pod nawigacją zapisaną w <code>base.html.twig</code>.</p>\n<h4 id=\"login\">Login</h4>\n<p>Plik <code>app/Resources/FOSUserBundle/views/Security/login.html.twig</code> pozostawiamy praktycznie nie zmieniony, dodjemy jedynie tytuł:</p>\n<pre><code class=\"language-twig\">{% extends &quot;@FOSUser/layout.html.twig&quot; %}\n\n{% block fos_user_content %}\n    {{ include('@FOSUser/Security/login_content.html.twig') }}\n{% endblock fos_user_content %}\n\n{% block title %}Login Form{% endblock %}\n</code></pre>\n<p>Dużo więcej kodu zostało dodanego w pliku <code>app/Resources/FOSUserBundle/views/Security/login_content.html.twig</code></p>\n<pre><code class=\"language-twig\">{% trans_default_domain 'FOSUserBundle' %}\n\n&lt;div class=&quot;container eternity-form&quot;&gt;\n    &lt;div class=&quot;login-form-section&quot;&gt;\n        &lt;div class=&quot;login-content animated zoomIn&quot;&gt;\n            &lt;form action=&quot;{{ path(&quot;fos_user_security_check&quot;) }}&quot; method=&quot;post&quot;&gt;\n                {% if csrf_token %}\n                    &lt;input type=&quot;hidden&quot; name=&quot;_csrf_token&quot; value=&quot;{{ csrf_token }}&quot; /&gt;\n                {% endif %}\n                &lt;div class=&quot;section-title&quot;&gt;\n                    &lt;h3&gt;LogIn to your Account&lt;/h3&gt;\n                &lt;/div&gt;\n                &lt;div class=&quot;textbox-wrap&quot;&gt;\n                    &lt;div class=&quot;input-group&quot;&gt;\n                        &lt;span class=&quot;input-group-addon &quot;&gt;&lt;i class=&quot;fa fa-user&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/span&gt;\n                        &lt;input type=&quot;email&quot; id=&quot;username&quot; name=&quot;_username&quot; value=&quot;{{ last_username }}&quot;\n                               required=&quot;required&quot; class=&quot;form-control&quot; placeholder=&quot;{{ 'form.email'|trans }}&quot; /&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n                &lt;div class=&quot;textbox-wrap&quot;&gt;\n                    &lt;div class=&quot;input-group&quot;&gt;\n                        &lt;span class=&quot;input-group-addon &quot;&gt;&lt;i class=&quot;fa fa-key&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/span&gt;\n                        &lt;input type=&quot;password&quot; id=&quot;password&quot; name=&quot;_password&quot; required=&quot;required&quot; class=&quot;form-control &quot; placeholder=&quot;{{ 'security.login.password'|trans }}&quot;/&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n                &lt;div class=&quot;login-form-action clearfix&quot;&gt;\n                    &lt;div class=&quot;checkbox pull-left&quot;&gt;\n                        &lt;div class=&quot;custom-checkbox&quot;&gt;\n                            &lt;input type=&quot;checkbox&quot; id=&quot;remember_me&quot; name=&quot;_remember_me&quot; value=&quot;on&quot; checked /&gt;\n                        &lt;/div&gt;\n                        &lt;span class=&quot;checkbox-text pull-left&quot;&gt;&amp;nbsp;{{ 'security.login.remember_me'|trans }}&lt;/span&gt;\n                    &lt;/div&gt;\n                    &lt;button type=&quot;submit&quot; id=&quot;_submit&quot; name=&quot;_submit&quot; class=&quot;btn btn-success pull-right green-btn&quot;&gt;LogIn &amp;nbsp;&lt;i class=&quot;fa fa-chevron-right&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/button&gt;\n                &lt;/div&gt;\n            &lt;/form&gt;\n        &lt;/div&gt;\n\n        {% if error %}\n            &lt;div class=&quot;login-form-links link1 animated fadeInUpBig text-danger&quot;&gt;\n                &lt;h4&gt;Error&lt;/h4&gt;\n                &lt;p&gt;\n                    {{ error.messageKey|trans(error.messageData, 'security') }}\n                &lt;/p&gt;\n            &lt;/div&gt;\n        {% endif %}\n\n        &lt;div class=&quot;login-form-links link1 animated fadeInLeftBig&quot;&gt;\n            &lt;h4 class=&quot;blue&quot;&gt;Don't have an Account?&lt;/h4&gt;\n            &lt;span&gt;No worry&lt;/span&gt;\n            &lt;a href=&quot;{{ path('fos_user_registration_register') }}&quot; class=&quot;blue&quot;&gt;Click Here&lt;/a&gt;\n            &lt;span&gt;to Register&lt;/span&gt;\n        &lt;/div&gt;\n        &lt;div class=&quot;login-form-links link2 animated fadeInRightBig&quot;&gt;\n            &lt;h4 class=&quot;green&quot;&gt;Forget your Password?&lt;/h4&gt;\n            &lt;span&gt;Dont worry&lt;/span&gt;\n            &lt;a href=&quot;{{ path('fos_user_resetting_request') }}&quot; class=&quot;green&quot;&gt;Click Here&lt;/a&gt;\n            &lt;span&gt;to Get New One&lt;/span&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>\n<p>Jednak, jest to tylko front - formularz logowania i dwa linki w twigu. A ponieważ o frontach obraz mówi więcej niż tysiąc słów więc zamiast go opisywać wklejam screen:</p>\n<p><img src=\"http://i.imgur.com/avrKaZd.png\" alt=\"login\" loading=\"lazy\"></p>\n<h4 id=\"rejestracja\">Rejestracja</h4>\n<p>Rejstracja wygląda podobnie.<br>\nPlik: <code>app/Resources/FOSUserBundle/views/Registration/register.html.twig</code></p>\n<pre><code class=\"language-twig\">{% extends &quot;@FOSUser/layout.html.twig&quot; %}\n\n{% block fos_user_content %}\n{% include &quot;@FOSUser/Registration/register_content.html.twig&quot; %}\n{% endblock fos_user_content %}\n\n{% block title %}Register{% endblock %}\n</code></pre>\n<p>Plik: <code>app/Resources/FOSUserBundle/views/Registration/register_content.html.twig</code></p>\n<pre><code class=\"language-twig\">{% trans_default_domain 'FOSUserBundle' %}\n\n&lt;div class=&quot;container eternity-form&quot;&gt;\n    &lt;div class=&quot;registration-form-section&quot;&gt;\n            {{ form_start(form, {'method': 'post', 'action': path('fos_user_registration_register'), 'attr': {'class': 'fos_user_registration_register'}}) }}\n\n            &lt;div class=&quot;section-title reg-header animated fadeInDown&quot;&gt;\n                &lt;h3&gt;Get your Account Here &lt;/h3&gt;\n\n            &lt;/div&gt;\n            &lt;div class=&quot;clearfix&quot;&gt;\n                &lt;div class=&quot;col-sm-6 registration-left-section  animated fadeInRightBig&quot;&gt;\n                    &lt;div class=&quot;reg-content&quot;&gt;\n                        &lt;div class=&quot;textbox-wrap&quot;&gt;\n                            &lt;div class=&quot;input-group&quot;&gt;\n                                &lt;span class=&quot;input-group-addon &quot;&gt;&lt;i class=&quot;fa fa-user&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/span&gt;\n                                {{ form_widget(form.email, {'attr': {'placeholder': 'Email'}}) }}\n                            &lt;/div&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n                &lt;div class=&quot;col-sm-6 registration-right-section animated fadeInLeftBig&quot;&gt;\n                    &lt;div class=&quot;reg-content&quot;&gt;\n                        &lt;div class=&quot;textbox-wrap&quot;&gt;\n                            &lt;div class=&quot;input-group&quot;&gt;\n                                &lt;span class=&quot;input-group-addon &quot;&gt;&lt;i class=&quot;fa fa-key&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/span&gt;\n                                {{ form_widget(form.plainPassword, {'attr': {'placeholder': 'Password'}}) }}\n                            &lt;/div&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n            &lt;div class=&quot;registration-form-action clearfix animated fadeInUp&quot;&gt;\n                &lt;a href=&quot;{{ path('fos_user_security_login') }}&quot; class=&quot;btn btn-success pull-left blue-btn &quot;&gt;\n                    &lt;i class=&quot;fa fa-chevron-left&quot;&gt;&lt;/i&gt;&amp;nbsp; &amp;nbsp;Back To Login\n                &lt;/a&gt;\n                &lt;button type=&quot;submit&quot; class=&quot;btn btn-success pull-right green-btn &quot;&gt;Register Now &amp;nbsp; &lt;i class=&quot;fa fa-chevron-right&quot;&gt;&lt;/i&gt;&lt;/button&gt;\n            &lt;/div&gt;\n        {{ form_end(form) }}\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>\n<p>Efekt:</p>\n<p><img src=\"http://i.imgur.com/i9BZooS.png\" alt=\"register\" loading=\"lazy\"></p>\n<p>Jeśli rejestracja przebiega pomyślnie, gratulujemy użytkonikowi komunikatem z pliku: <code>app/Resources/FOSUserBundle/views/Registration/confirmed.html.twig</code></p>\n<pre><code class=\"language-twig\">{% extends &quot;@FOSUser/layout.html.twig&quot; %}\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n{% block fos_user_content %}\n    &lt;div class=&quot;container eternity-form&quot;&gt;\n        &lt;div class=&quot;section-title reg-header&quot;&gt;\n            &lt;h3&gt;Registration finished correctly&lt;/h3&gt;\n            &lt;div&gt;\n                &lt;p&gt;{{ 'registration.confirmed'|trans({'%username%': user.username}) }}&lt;/p&gt;\n                {% if targetUrl %}\n                    &lt;p&gt;&lt;a href=&quot;{{ targetUrl }}&quot;&gt;{{ 'registration.back'|trans }}&lt;/a&gt;&lt;/p&gt;\n                {% endif %}\n            &lt;/div&gt;\n            &lt;a href=&quot;{{ path('homepage') }}&quot; class=&quot;btn btn-info width-min-300px&quot;&gt;Let's start&lt;/a&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n{% endblock fos_user_content %}\n</code></pre>\n<p>Który prezentuje się tak:</p>\n<p><img src=\"http://i.imgur.com/8v1SLZ1.png\" alt=\"confirm\" loading=\"lazy\"></p>\n<h4 id=\"resetowanie-has%C5%82a\">Resetowanie hasła</h4>\n<p>Jeśli posiadający konto użytkownik zapomni hasła, może je wysłać na swój e-mail (jeśli w <code>app/config/parameters.yml</code> są odpowiednie parametry umożliwiające wysłanie e-maila) za pomocą formularza, którego kod znajduje się w pliku <code>app/Resources/FOSUserBundle/views/Resetting/request_content.html.twig</code></p>\n<pre><code class=\"language-twig\">{% trans_default_domain 'FOSUserBundle' %}\n\n&lt;div class=&quot;container eternity-form&quot;&gt;\n    &lt;div class=&quot;forgot-password-section animated bounceInLeft&quot;&gt;\n        &lt;div class=&quot;section-title&quot;&gt;\n            &lt;h3&gt;Forget Password&lt;/h3&gt;\n        &lt;/div&gt;\n        &lt;div class=&quot;forgot-content&quot;&gt;\n            &lt;form action=&quot;{{ path('fos_user_resetting_send_email') }}&quot; method=&quot;POST&quot; class=&quot;fos_user_resetting_request&quot;&gt;\n                &lt;div class=&quot;textbox-wrap&quot;&gt;\n                    &lt;div class=&quot;input-group&quot;&gt;\n                        &lt;span class=&quot;input-group-addon &quot;&gt;&lt;i class=&quot;fa fa-envelope&quot;&gt;&lt;/i&gt;&lt;/span&gt;\n                        &lt;input type=&quot;email&quot; class=&quot;form-control&quot; id=&quot;username&quot; name=&quot;username&quot; required=&quot;required&quot; placeholder=&quot;Email Id&quot;/&gt;\n\n                    &lt;/div&gt;\n                &lt;/div&gt;\n                &lt;div class=&quot;forget-form-action clearfix&quot;&gt;\n                    &lt;a href=&quot;{{ path('fos_user_security_login') }}&quot; class=&quot;btn btn-success pull-left blue-btn&quot;&gt;&lt;i class=&quot;fa fa-chevron-left&quot;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;Back  &lt;/a&gt;\n                    &lt;button type=&quot;submit&quot; class=&quot;btn btn-success pull-right green-btn&quot;&gt;Submit &amp;nbsp;&amp;nbsp; &lt;i class=&quot;fa fa-chevron-right&quot;&gt;&lt;/i&gt;&lt;/button&gt;\n                &lt;/div&gt;\n            &lt;/form&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>\n<p>Formularz wygląda tak:</p>\n<p><img src=\"http://i.imgur.com/XfCorCh.png\" alt=\"reset\" loading=\"lazy\"></p>\n<p>Za to co pojawi się na ekranie po wpisaniu e-maila odpowiada plik: <code>app/Resources/FOSUserBundle/views/Resetting/check_email.html.twig</code> o treści</p>\n<pre><code class=\"language-twig\">{% extends &quot;@FOSUser/layout.html.twig&quot; %}\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n{% block fos_user_content %}\n    &lt;div class=&quot;container eternity-form&quot;&gt;\n        &lt;div class=&quot;section-title reg-header&quot;&gt;\n            &lt;h3&gt;Check Email&lt;/h3&gt;\n            &lt;div class=&quot;fos_user_user_show&quot;&gt;\n                &lt;p&gt;{{ 'resetting.check_email'|trans({'%tokenLifetime%': tokenLifetime})|nl2br }}\n                &lt;/p&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n{% endblock %}\n</code></pre>\n<p>który prezentuje się tak:</p>\n<p><img src=\"http://i.imgur.com/hZy5ERk.png\" alt=\"check\" loading=\"lazy\"></p>\n<p>W e-mailu mamy link zmiany hasła. Szablon twiga znajduje się w pliku:  <code>app/Resources/FOSUserBundle/views/Resetting/reset_content.html.twig</code> i ma kod:</p>\n<pre><code class=\"language-twig\">{% trans_default_domain 'FOSUserBundle' %}\n\n&lt;div class=&quot;container eternity-form&quot;&gt;\n    &lt;div class=&quot;forgot-password-section section-title reg-header&quot;&gt;\n        &lt;div class=&quot;section-title&quot;&gt;\n            &lt;h3&gt;Reset Password&lt;/h3&gt;\n        &lt;/div&gt;\n        {{ form_start(form, { 'action': path('fos_user_resetting_reset', {'token': token}), 'attr': { 'class': 'fos_user_resetting_reset' } }) }}\n        {{ form_widget(form) }}\n        &lt;div&gt;\n            &lt;input type=&quot;submit&quot; class=&quot;btn btn-danger btn-block&quot; value=&quot;{{ 'resetting.reset.submit'|trans }}&quot; /&gt;\n        &lt;/div&gt;\n        {{ form_end(form) }}\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>\n<p>Formularz zmiany hasła tak:</p>\n<p><img src=\"http://i.imgur.com/N7Ot9V6.png\" alt=\"\" loading=\"lazy\"></p>\n<h4 id=\"panel-u%C5%BCytkownika\">Panel użytkownika</h4>\n<p>Jeśli jako zalogowany użytkownik wybierzemy <code>MyAccount</code> z menu, zostaniemy przekierowani do widoku konta. Jego html generowany jest z pliku <code>app/Resources/FOSUserBundle/views/Profile/show_content.html.twig</code></p>\n<pre><code class=\"language-twig\">{% trans_default_domain 'FOSUserBundle' %}\n\n&lt;div class=&quot;container eternity-form&quot;&gt;\n    &lt;div class=&quot;section-title reg-header&quot;&gt;\n        &lt;h3&gt;User Profile&lt;/h3&gt;\n        &lt;div class=&quot;fos_user_user_show&quot;&gt;\n            &lt;p&gt;{{ 'profile.show.username'|trans }}: {{ user.username }}&lt;/p&gt;\n            &lt;p&gt;{{ 'profile.show.email'|trans }}: {{ user.email }}&lt;/p&gt;\n            &lt;a href=&quot;{{ path('homepage') }}&quot; class=&quot;btn btn-primary&quot;&gt;Edit Places&lt;/a&gt;\n            &lt;a href=&quot;{{ path('fos_user_profile_edit') }}&quot; class=&quot;btn btn-info&quot;&gt;Edit Profile&lt;/a&gt;\n            &lt;a href=&quot;{{ path('fos_user_change_password') }}&quot; class=&quot;btn btn-success&quot;&gt;Change Password&lt;/a&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>\n<p>i wygląda tak:</p>\n<p><img src=\"http://i.imgur.com/jwR8Nlg.png\" alt=\"profile\" loading=\"lazy\"></p>\n<p>Przycisk <code>Edit Places</code> będzie prowadził do głównej funkcjonalności aplikacji. Jednak żeby dokończyć to co związane z <code>FOSUserBundle</code> pokażemy teraz edycję profilu i zmanę hasła. Edycja profilu: <code>app/Resources/FOSUserBundle/views/Profile/edit_content.html.twig</code></p>\n<pre><code class=\"language-twig\">{% trans_default_domain 'FOSUserBundle' %}\n\n&lt;div class=&quot;container eternity-form&quot;&gt;\n\n    {{ form_start(form, { 'action': path('fos_user_profile_edit'), 'attr': { 'class': 'fos_user_profile_edit' } }) }}\n\n    &lt;div class=&quot;section-title reg-header&quot;&gt;\n        &lt;h3&gt;Edit Profile&lt;/h3&gt;\n        &lt;div&gt;\n            {{ form_widget(form) }}\n        &lt;/div&gt;\n    &lt;/div&gt;\n\n    &lt;div class=&quot;registration-form-action clearfix&quot;&gt;\n        &lt;div&gt;\n            &lt;a href=&quot;{{ path('fos_user_profile_show') }}&quot; class=&quot;btn btn-success pull-left blue-btn &quot;&gt;\n                &lt;i class=&quot;fa fa-chevron-left&quot;&gt;&lt;/i&gt;&amp;nbsp; &amp;nbsp;Back To Profile\n            &lt;/a&gt;\n            &lt;button type=&quot;submit&quot; class=&quot;btn btn-success pull-right green-btn &quot;&gt;{{ 'profile.edit.submit'|trans }} &amp;nbsp; &lt;i class=&quot;fa fa-chevron-right&quot;&gt;&lt;/i&gt;&lt;/button&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n    {{ form_end(form) }}\n&lt;/div&gt;\n</code></pre>\n<p><img src=\"http://i.imgur.com/QVWyPri.png\" alt=\"edit\" loading=\"lazy\"></p>\n<p>Cały formularz sprowadza się do jednego pola - <code>email</code>, ponieważ jest to jedyna własność jaką chcemy nadawać użytkownikowi.</p>\n<p>Zmiana hasła ma szablon w pliku <code>app/Resources/FOSUserBundle/views/ChangePassword/change_password_content.html.twig</code></p>\n<pre><code class=\"language-html\">{% trans_default_domain 'FOSUserBundle' %}\n\n&lt;div class=&quot;container eternity-form&quot;&gt;\n    &lt;div class=&quot;section-title reg-header&quot;&gt;\n        &lt;h3&gt;User Profile&lt;/h3&gt;\n        &lt;div class=&quot;fos_user_user_show&quot;&gt;\n            {{ form_start(form, { 'action': path('fos_user_change_password'), 'attr': { 'class': 'fos_user_change_password' } }) }}\n            {{ form_widget(form) }}\n            &lt;div&gt;\n                &lt;input type=&quot;submit&quot; class=&quot;btn btn-danger btn-block&quot; value=&quot;{{ 'change_password.submit'|trans }}&quot; /&gt;\n            &lt;/div&gt;\n            {{ form_end(form) }}\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>\n<p><img src=\"http://i.imgur.com/cQkQC91.png\" alt=\"password\" loading=\"lazy\"></p>\n<p>Są to wszystkie zmiany jakie zrobiłem, żeby dostosować <code>FOSUserBundle</code> do swoich wymagań. W <code>app/Resources/FOSUserBundle</code> Są pliki, których nie zmieniałem, na przykład cały katalog <code>Group</code>, który jest związany z interakcjami między użytkonikami, ale ta funkcjonalność nie jest przez nas wykorzystywana. Zostawiłem równiż e-mail do resetu hasła, który bez grafik wygląda tak:</p>\n<p><img src=\"http://i.imgur.com/zksqsDt.png\" alt=\"reset\" loading=\"lazy\"></p>\n<p>Ale w przypadku e-maila jest to jak najbardziej dopuszczalne.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"appbundle\">AppBundle</h2>\n<p>Kiedy mamy już działającą obsługę użytkowników, warto było by dać im ciekawą funkcjonalność. Żeby zachować balans między rozbudowaną aplikacją, a dobrym przykładem postawimy następujące wymagania przed logiką biznesową aplikacji:</p>\n<ul>\n<li>Użytkownik może dodać dowolną liczbę miejsc do swojego konta</li>\n<li>Miejsca wybiera się wpisując je w formulażu lub używając geolokalizacji</li>\n<li>Dane miejsce może zostać odłączone od konta, ale nie zniknie z bazy</li>\n<li>Do danego miejsca może być przypisanych dowolnie wielu użytkowników</li>\n<li>Zarządanie miejscami (dodawanie, usównie, lokalizowanie) nie przeładowuje strony</li>\n</ul>\n<h3 id=\"baza-danych-model\">Baza danych (Model)</h3>\n<p>Zaczniemy od przygotowania bazy. Chcemy dodać w niej tablelę z miejscami oraz utowrzyć relację wiele do wielu między nią a tabelą <code>users</code>. Tworzymy plik <code>src/AppBundle/Entity/Place.php</code> w którym definiujemy klasę odpowiadającą za reprezentowanie miejsc. Standardowo zaczynamy od własności</p>\n<pre><code class=\"language-php\">&lt;?php\n\nnamespace AppBundle\\Entity;\n\nuse Doctrine\\ORM\\Mapping as ORM;\nuse Doctrine\\Common\\Collections\\ArrayCollection;\n\n/**\n * @ORM\\Entity\n * @ORM\\Table(name=&quot;places&quot;)\n */\nclass Place\n{\n    /**\n     * @ORM\\Id\n     * @ORM\\Column(type=&quot;integer&quot;)\n     * @ORM\\GeneratedValue(strategy=&quot;AUTO&quot;)\n     */\n    protected $id;\n\n    /**\n     * @ORM\\Column(name=&quot;google_id&quot;, type=&quot;string&quot;, nullable=true)\n     */\n    private $googleId;\n\n    /**\n    * @ORM\\ManyToMany(targetEntity=&quot;User&quot;, inversedBy=&quot;places&quot;)\n    * @ORM\\JoinTable(name=&quot;users_places&quot;)\n    */\n    private $users;\n\n    /** @ORM\\Column(name=&quot;formatted_address&quot;, type=&quot;string&quot;, nullable=true)  */\n    protected $formattedAddress;\n\n    /** @ORM\\Column(name=&quot;lon&quot;, type=&quot;float&quot;, precision=9, nullable=true)  */\n    protected $lon;\n\n    /** @ORM\\Column(name=&quot;lat&quot;, type=&quot;float&quot;, precision=9, nullable=true)  */\n    protected $lat;\n\n    /** @ORM\\Column(name=&quot;add_at&quot;,type=&quot;datetime&quot;) */\n    protected $add_at;\n\n    /** @ORM\\Column(name=&quot;street_number&quot;,type=&quot;string&quot;, nullable=true) */\n    protected $streetNumber;\n\n    /** @ORM\\Column(name=&quot;route&quot;,type=&quot;string&quot;, nullable=true) */\n    protected $route;\n\n    /** @ORM\\Column(name=&quot;sublocalityLevel1&quot;,type=&quot;string&quot;, nullable=true) */\n    protected $sublocalityLevel1;\n\n    /** @ORM\\Column(name=&quot;locality&quot;,type=&quot;string&quot;, nullable=true) */\n    protected $locality;\n\n    /** @ORM\\Column(name=&quot;administrative_area_level_2&quot;,type=&quot;string&quot;, nullable=true) */\n    protected $administrativeAreaLevel2;\n\n    /** @ORM\\Column(name=&quot;administrative_area_level_1&quot;,type=&quot;string&quot;, nullable=true) */\n    protected $administrativeAreaLevel1;\n\n    /** @ORM\\Column(name=&quot;country&quot;,type=&quot;string&quot;, nullable=true) */\n    protected $country;\n</code></pre>\n<p>Poza standardowymi własnościami dotyczącymy lokalizacji mamy tu własność <code>$users</code>. W bazie danych będzie odpowiadała ona występowaniu tabeli <code>users_places</code> z identyfikatorami użytkownika i miejsca. Wymagać to będzie jeszcze paru zmian w klasie <code>User</code>, ale o tym później. Teraz przejrzymy metody klasy <code>Place</code>.</p>\n<pre><code class=\"language-php?start_inline=1\">    public function __construct() {\n        $this-&gt;users = new ArrayCollection();\n        $this-&gt;setAddAt(new \\DateTime(&quot;now&quot;));\n    }\n</code></pre>\n<p>Konstruktor ustawia datę dodania miejsca oraz zmienną <code>$users</code> jako <code>ArrayCollection</code>. Jest to obiekt podobny do zwykłej tablicy, ale ma kilka metod wygodnych dla stosowania go jako zbiór obiektów. Mamy też geter i setter dla <code>$googleId</code>:</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @return mixed\n     */\n    public function getGoogleId()\n    {\n        return $this-&gt;googleId;\n    }\n\n    /**\n     * @param mixed $googleId\n     */\n    public function setGoogleId($googleId)\n    {\n        $this-&gt;googleId = $googleId;\n    }\n</code></pre>\n<p>Do operowani na zmiennej <code>$users</code> mamy trzy metody.</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @return mixed\n     */\n    public function getUsers()\n    {\n        return $this-&gt;users;\n    }\n\n    /**\n     * @param mixed $user\n     */\n    public function addUsers(User $user)\n    {\n        if (!$this-&gt;users-&gt;contains($user))\n        {\n            $this-&gt;users-&gt;add($user);\n        }\n    }\n\n    public function removeUser(User $user)\n    {\n        $this-&gt;users-&gt;removeElement($user);\n    }\n</code></pre>\n<p>Widać jak korzystamy tu z zalet <code>ArrayCollection</code>, gdyby <code>$users</code> było zwykłą tablicą, te operacje wyglądały by nieco mniej zgrabnie.</p>\n<p>Kolejnymi metodami są pary getterów i setterów dla adresu: <code>$formattedAddress</code>, współrzędnych <code>$lon</code>, <code>$lat</code> i czasu dodania adresu do bazy <code>$addAt</code>:</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @return mixed\n     */\n    public function getFormattedAddress()\n    {\n        return $this-&gt;formattedAddress;\n    }\n\n    /**\n     * @param mixed $formattedAddress\n     */\n    public function setFormattedAddress($formattedAddress)\n    {\n        $this-&gt;formattedAddress = $formattedAddress;\n    }\n\n    /**\n     * @return mixed\n     */\n    public function getLon()\n    {\n        return $this-&gt;lon;\n    }\n\n    /**\n     * @param mixed $lon\n     */\n    public function setLon($lon)\n    {\n        $this-&gt;lon = $lon;\n    }\n\n    /**\n     * @return mixed\n     */\n    public function getLat()\n    {\n        return $this-&gt;lat;\n    }\n\n    /**\n     * @param mixed $lat\n     */\n    public function setLat($lat)\n    {\n        $this-&gt;lat = $lat;\n    }\n\n    /**\n     * @return mixed\n     */\n    public function getAddAt()\n    {\n        return $this-&gt;add_at;\n    }\n\n    /**\n     * @param mixed $add_at\n     */\n    public function setAddAt($add_at)\n    {\n        $this-&gt;add_at = $add_at;\n    }\n</code></pre>\n<p>Dla pozostałych parametrów nie będziemy stosować już pary getter, setter. Z powodu ich ustrukturyzowanego występowania w api google maps, z którego będziemy korzystać ustawimy jeden setter dla nich wszystkich. Gettery nie będą nam potrzebne więc metody do obsługi pozostałych parametów wyglądają następująco:</p>\n<pre><code class=\"language-php?start_inline=1\">    public function getParams()\n    {\n        return [\n            &quot;country&quot;,\n            &quot;administrative_area_level_1&quot;,\n            &quot;administrative_area_level_2&quot;,\n            &quot;locality&quot;,\n            &quot;sublocality_level_1&quot;,\n            &quot;route&quot;,\n            &quot;street_number&quot;\n        ];\n    }\n\n    public function setParam($name,$value)\n    {\n        if(in_array($name,$this-&gt;getParams())){\n            $name = lcfirst(str_replace(' ', '', ucwords(str_replace('_', ' ', $name))));//camelcase\n            $this-&gt;$name  = $value;\n        }\n    }\n</code></pre>\n<p>Pierwsza z nich zwraca listę nazw obsługiwanych przez drugą metodę, te nazwy można jako <code>string</code> podstawić jako <code>$name</code>. Funkcja zaczynająca się od <code>lcfirst</code> odpowiada za zmianę notacji z <code>a_b</code> na <code>aB</code>, czyli usówa podkreślenia i zmienia małe litery po podkreśleniach na duże.</p>\n<p>Została nam jeszcze jedna metoda - do rzutowania obiektu na string.</p>\n<pre><code class=\"language-php?start_inline=1\">    public function __toString()\n    {\n        return json_encode([&quot;id&quot;=&gt;$this-&gt;getGoogleId(),&quot;address&quot;=&gt;$this-&gt;getFormattedAddress()],JSON_UNESCAPED_UNICODE);\n    }\n}\n</code></pre>\n<p>Żeby tabela łącząca została poprawnie dodana wprowadzimy teraz zmiany w klasie <code>User</code> i dodamy do pliku <code>src/AppBundle/Entity/User.php</code> linie:</p>\n<pre><code class=\"language-php?start_inline=1\">use Doctrine\\Common\\Collections\\ArrayCollection;\n\n(...)\n\n    /**\n     * @ORM\\ManyToMany(targetEntity=&quot;Place&quot;, mappedBy=&quot;users&quot;, cascade={&quot;persist&quot;})\n     */\n    private $places;\n\n    /**\n     * @return mixed\n     */\n    public function getPlaces()\n    {\n        return $this-&gt;places-&gt;toArray();\n    }\n\n\n    public function removePlace(Place $place)\n    {\n        $this-&gt;places-&gt;remove($place);\n    }\n\n    /**\n     * @param mixed $place\n     */\n    public function addPlace(Place $place)\n    {\n        if (!$this-&gt;places-&gt;contains($place))\n        {\n            $this-&gt;places-&gt;add($place);\n        }\n    }\n\n    public function __construct()\n    {\n        parent::__construct();\n        $this-&gt;places = new ArrayCollection();\n    }\n\n</code></pre>\n<p>Możemy teraz zregenerować bazę danych komendą:</p>\n<pre><code>php bin/console doctrine:schema:update --force\n</code></pre>\n<p>Na koniec załączam wizualizację schematu bazy</p>\n<p><img src=\"http://i.imgur.com/jfjLAoV.png\" alt=\"database\" loading=\"lazy\"></p>\n<h3 id=\"logika-serwera-kontroler\">Logika serwera (Kontroler)</h3>\n<p>Mamy model. Teraz kontrolery. Na końcu zrobimy widoki. W defaultowym kontrolerze (<code>src/AppBundle/Controller/DefaultController</code>) ustawimy przekierowanie zalogowanych użytkowników do ścieżki z miejscami:</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @Route(&quot;/&quot;, name=&quot;homepage&quot;)\n     */\n    public function indexAction(Request $request)\n    {\n        if($this-&gt;getUser()){\n            return $this-&gt;redirectToRoute('places');\n        }\n        return $this-&gt;render('default/index.html.twig', []);\n    }\n</code></pre>\n<p>To wszystko jeśli chodzi o defaultową logikę.<br>\nW kontrolerze <code>src/AppBundle/Controller/PlacesController</code> będzie znacznie więcej logiki. Oto metoda<br>\ndo wyświetlania ścieżki <code>places</code>, do której chcemy przekierowywać logowanych użytkowników.</p>\n<pre><code class=\"language-php\">&lt;?php\nnamespace AppBundle\\Controller;\n\nuse Symfony\\Bundle\\FrameworkBundle\\Controller\\Controller;\nuse Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route;\nuse Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Method;\nuse Symfony\\Component\\HttpFoundation\\Request;\nuse Symfony\\Component\\HttpFoundation\\Response;\nuse AppBundle\\Entity\\Place;\nuse AppBundle\\Form\\PlaceType;\nuse Symfony\\Component\\HttpFoundation\\JsonResponse;\n\nClass PlacesController extends Controller\n{\n    /**\n     * @Route(&quot;/profile/places&quot;, name=&quot;places&quot;)\n     * @Method(&quot;GET&quot;)\n     * @return Response\n     */\n    public function editPlacesAction()\n    {\n        if(!$this-&gt;getUser()){\n            return $this-&gt;redirectToRoute('fos_user_security_login');\n        }\n\n        $place = new Place();\n        $places = $this-&gt;getUser()-&gt;getPlaces();\n        $form = $this-&gt;createForm(PlaceType::class, $place);\n\n        return $this-&gt;render(':places:places.html.twig', array(\n            'places' =&gt; $places,\n            'form' =&gt; $form-&gt;createView(),\n        ));\n    }\n</code></pre>\n<p>Zanim przejdziemy dalej zwrócę uwagę na dwie rzeczy - pierwsza to brak obsługi formularza i przyjmowania requestów. Tworzymy tutaj formularz, wysyłamy go do Twiga, ale nie będziemy go odbierać tutaj. Jego obsługą zajmie się JavaScript. Druga rzecz to sama klasa <code>PlaceType</code> została ona tutaj zastosowana, chociaż jeszcze je nie defniowaliśmy. Zrobię małą dygresję i pokażę kod tej klasy. Jest on umieszczony w pliku <code>src/AppBundle/Form/PlaceType.php</code></p>\n<pre><code class=\"language-php\">&lt;?php\n\nnamespace AppBundle\\Form;\n\nuse Symfony\\Component\\Form\\AbstractType;\nuse Symfony\\Component\\Form\\FormBuilderInterface;\nuse Symfony\\Component\\Form\\Extension\\Core\\Type\\TextType;\nuse Symfony\\Component\\Form\\FormTypeInterface;\nuse Symfony\\Component\\OptionsResolver\\OptionsResolver;\n\nclass PlaceType extends AbstractType implements FormTypeInterface\n{\n    public function buildForm(FormBuilderInterface $builder, array $options)\n    {\n        $builder-&gt;add('formatted_address', TextType::class, array('label' =&gt; false));\n    }\n\n    public function configureOptions(OptionsResolver $resolver)\n    {\n        $resolver-&gt;setDefaults(array(\n            'data_class' =&gt; 'AppBundle\\Entity\\Place',\n        ));\n    }\n}\n</code></pre>\n<p>Z php na nasze: ta klasa odpowada z to, że formularz, który reprezentuje ma jedno pole. Wracamy teraz do kontrolera <code>src/AppBundle/Form/PlaceType.php</code>. Kolejna metoda będzie odpowiadała za zapisywanie miejsca do bazy danych</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @Route(&quot;/profile/ajax_geo_save&quot;, name=&quot;ajax_geo_save&quot;)\n     * @Route(&quot;/profile/ajax_geo_save/{debug}&quot;)\n     * @Method(&quot;POST&quot;)\n     */\n    public function ajaxGeoSave(Request $request, $debug=null)\n    {\n        $content = $request-&gt;getContent();\n        $params = json_decode($content, true);\n\n        $formattedAddress = $params['formatted_address'];\n        $address = $this-&gt;getAddress($formattedAddress);\n\n        if($debug==&quot;debug&quot;) { return new JsonResponse($address); }\n\n        $place = $this-&gt;getPlace($address);\n\n        // these lines persist user relation with place, not only place\n        $em = $this-&gt;getDoctrine()-&gt;getManager();\n        $em-&gt;persist($place);\n        $em-&gt;flush();\n\n        return new JsonResponse($address, 201);\n    }\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Można ją wywołać z parametrem <code>debug</code> w ścieżce, ale nie trzeba. Działanie metody jest następujące: pobiera ona zawartość requestu do zmiennej <code>$content</code>, do zmiennej <code>$params</code> zapisuje tablicę odpowiadającą treści requestu, do zmiennej <code>$formattedAddress</code> zapisujemy wartość odpowiadającą kluczowi <code>formatted_address</code>. Jest to dokładnie to co powinno zostać wysłane przez formularz definiowany klasą <code>PlaceType</code> prezentowaną przed chwilą.</p>\n<p>Teraz linia <code>$address = $this-&gt;getAddress($formattedAddress);</code> robi bardzo ważną rzecz. Wysyła request do API Google w celu przetłumaczenia tego co wpisał użytkownik na to co Google rozumie jako lokalizację, którą prawdopodobnie miał na myśli. Do metody <code>getAddress</code> jeszcze przejdziemy, ale teraz dokończę omawianie metody <code>ajaxGeoSave</code>. Otrzymany adres jest tablicą. Jeśli metodę włączono z parametrem <code>debug</code> to zostaje on zwrócony jako <code>JSON</code> z kodem HTTP 200 i dalsza część metody nie jest wykonywana. W przeciwnym wypadku, czyli w sytuacji zwyczajnego użycia  wywołujemy metodę <code>getPlace</code>, która transformuje nam tablicę <code>$address</code> do obiektu <code>$place</code>. Trzy kolejne linie to zapis do bazy. Na końcu zwracamy <code>$address</code> jak z metodzie z parametrem <code>debug</code>, ale ponieważ wykonaliśmy poprawny zapis do bazy, zmieniamy kod HTTP na 201.</p>\n<p>Mamy tu więc dwie ważne transformacje danych - z tego co wpisał użytkownik na tablicę z danymi adresowymi od Google, oraz z tablicy na naszą strukturę danych - klasę <code>Place</code>.</p>\n<p>Może jednak tak się zdarzyć, że użytkownikowi nie che się pisać swojego adresu, albo zgubił się i nie wie gdzie jest. W takim wypadku możemy wykorzystać metodę <code>geolocation</code> obiektu <code>navigator</code> dostępnego w <code>javascript</code>. Zwraca ona współrzędne geograficzne. Chcieli byśmy tłumaczyć je na adres czytelny dla człowieka. Do tego posłuży druga metoda kontrolera:</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @Route(&quot;/profile/ajax_geo_location&quot;, name=&quot;ajax_geo_location&quot;)\n     * @param Request $request\n     * @Method(&quot;GET&quot;)\n     * @return JsonResponse\n     */\n    public function ajaxGeoLocation(Request $request)\n    {\n        $lon = $request-&gt;get('lon');\n        $lat = $request-&gt;get('lat');\n\n        $address = $this-&gt;getAddress([$lat,$lon]);// get address from coords\n\n        return new JsonResponse($address);\n    }\n</code></pre>\n<p>Jej struktura jest bardzo przejrzysta. Pobieramy dane z requesta, wykonujemy transformację metodą <code>getAddress</code>, zwracamy tablicę z adresem. Należy zauważyć, że tym razem <code>getAddress</code> przyjmuję tablicę a nie string. Mimo to działa poprawnie, ponieważ w zależności od tego co dostała metoda <code>getAddress</code> wykonuje nieco inną logikę dostosowaną zarówno do tekstowych adresów jak i par współrzędnych.</p>\n<p>Kolejna metoda wiąże się ze smutnym eventem jakim jest usunięcie adresu przez użytkownika.</p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @Route(&quot;/profile/ajax_geo_delete/{googleId}&quot;, name=&quot;ajax_geo_delete&quot;)\n     * @Method(&quot;DELETE&quot;)\n     * @param googleId\n     * @return JsonResponse\n     */\n    public function ajaxGeoDelete($googleId)\n    {\n        $place = $this-&gt;getDoctrine()-&gt;getRepository(&quot;AppBundle:Place&quot;)-&gt;findOneBy(array(\n            'googleId' =&gt; $googleId\n        ));\n\n        if(!$place) { return new JsonResponse([&quot;error&quot;=&gt;&quot;Place Not Found&quot;],404); }\n\n        $address = $this-&gt;getAddress($place-&gt;getFormattedAddress());\n\n        $place-&gt;removeUser($this-&gt;getUser());\n        $em = $this-&gt;getDoctrine()-&gt;getManager();\n        $em-&gt;persist($place);\n        $em-&gt;flush();\n\n        return new JsonResponse($address,204);\n    }\n</code></pre>\n<p>Adres jest wyszukiwany po <code>googleId</code>. Jeśli nie zostanie znaleziony odsyłamy błąd <code>404</code>, jeśli zostanie, to usunięte zostaje jedynie łącznie między użytkownikiem a miejscem, natomiast miejsce cały zostaje w bazie nawet jeśli nie będzie już połączone z żadnym użytkownikiem.</p>\n<p>Najwyższy czas na zaprezentowanie pierwszego z transformatorów danych - metody <code>getAddress</code></p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @param $data\n     * @return array\n     * @throws \\Exception\n     */\n    public function getAddress($data)\n    {\n        if(is_string($data)){\n            $address = str_replace(&quot; &quot;, &quot;+&quot;, $data); // replace all the white space with &quot;+&quot; sign to match with google search pattern\n            $url = &quot;http://maps.google.com/maps/api/geocode/json?sensor=false&amp;address=$address&quot;;\n        } elseif (is_array($data) &amp;&amp; count($data)) {\n            $url = &quot;http://maps.googleapis.com/maps/api/geocode/json?latlng=$data[0],$data[1]&amp;sensor=false&quot;;\n        } else {\n            throw new \\Exception(&quot;Incorrect args, put string or array with lat and lon&quot;);\n        }\n\n        $response = file_get_contents($url);\n        $json = json_decode($response, TRUE); //generate array object from the response from the web\n        return $json['results'][0];\n    }\n</code></pre>\n<p>Ta metoda sprawdza czy dostała współrzędne czy tekstowy adres i w zależności od tego przygotowuje trochę inny <code>$url</code>. Następnie za pomocą najprostszego requestu <code>file_get_contents</code>  odbiera to co odpowie Google, wycina to co nie potrzebne i odsyła dalej.</p>\n<p>Myślę, że to dobry moment, żeby pokazać do dokładnie jest odsyłane. Wykonamy request do <code>ajax_geo_save</code> z parametrem <code>debug</code>, żeby zobaczyć jak wygląda <code>json</code> na wyjściu tej metody.</p>\n<p><img src=\"http://i.imgur.com/My3cMbW.png\" alt=\"api1\" loading=\"lazy\"><br>\n<img src=\"http://i.imgur.com/88vr0jN.png\" alt=\"api2\" loading=\"lazy\"></p>\n<p>Widać, że <code>formatted_address</code>, <code>place_id</code> oraz współrzędne mają tu dobrze określone miejsce, ale pozostałe własności adresu zostały spakowane do jednej tablicy <code>address_components</code> i są tagowane za pomocą typów, które mogą występować po kilka, ale niektórych może też wcale nie być. Do przetwarzania tej tablicy do postaci zgodnej z naszym modelem danych służy ostatnia metoda, którą zaprezentuję: <code>getPlace</code></p>\n<pre><code class=\"language-php?start_inline=1\">    /**\n     * @param array $address\n     * @return mixed\n     */\n    public function getPlace($address)\n    {\n        $place = $this-&gt;getDoctrine()-&gt;getRepository(&quot;AppBundle:Place&quot;)-&gt;findOneBy(array(\n            'googleId' =&gt; $address['place_id']\n        ));\n                if($place === null)\n        {\n            $place = new Place();\n\n            $place-&gt;setGoogleId($address['place_id']);\n            $place-&gt;setLat($address['geometry']['location']['lat']);\n            $place-&gt;setLon($address['geometry']['location']['lng']);\n            $place-&gt;setFormattedAddress($address['formatted_address']);\n</code></pre>\n<p>Na początku sprawdzamy czy dany adres już znajduje się w naszej bazie. Jeśli tak, to możemy pominąć całe transformowanie, dodamy do niego aktualnego użytkownika i wystarczy. Załóżmy jednak, że to nowy adres. W takim przypadku powinniśmy w pierwszej kolejności ustawić mu <code>google_id</code>, współrzędne, oraz jego sformatowaną postać. Następnie zajmiemy się otagowanymi składowymi adresu.</p>\n<pre><code class=\"language-php?start_inline=1\">            $params = $place-&gt;getParams();\n\n            foreach($address[&quot;address_components&quot;] as $component){\n                foreach($params as $paramId =&gt; $param){\n                    if(in_array($param,$component[&quot;types&quot;])){\n                        $place-&gt;setParam($param,$component[&quot;long_name&quot;]);\n                        unset($params[$paramId]);\n                    }\n                }\n            }\n        }\n</code></pre>\n<p>Będziemy je wyciągać w podwójnej pętli. Po komponentach adresu oraz po parametrach jakich szukamy. Jeśli jakiś parametr zostanie znaleziony, zapiszemy właściwość i usuniemy go z tablicy parametrów, tak, żeby nie nabijał pustych pętli.</p>\n<pre><code class=\"language-php?start_inline=1\">        $place-&gt;addUsers($this-&gt;getUser());\n\n        return $place;\n    }\n}\n</code></pre>\n<p>Na koniec niezależnie od tego, czy tworzyliśmy nowe miejsce, czy też wzięliśmy je z bazy, dołączamy do miejsca obecnego użytkownika. Jeśli zastanawia cię dlaczego nie sprawdzam czy ten użytkownik jest już dodany, to odpowiedź jest prosta. Sprawdzam, ale na poziomie metody dostępnej w <code>ArrayCollection</code> w encji a nie kontrolerze.</p>\n<h3 id=\"widoki\">Widoki</h3>\n<p>Bardzo dużą część widoków już przerobiliśmy. Zostały nam jeszcze dwa. Pierwszy z nich to strona główna dla niezalogowanych użytkowników. Strona po prostu informuje do czego jest aplikacja. Widok znajduje się w pliku <code>app/Resources/views/default/index.html.twig</code>, ma kod</p>\n<pre><code class=\"language-twig\">{% extends 'base.html.twig' %}\n\n{% block body %}\n    {{ parent() }}\n\n\n    &lt;div class=&quot;container eternity-form&quot;&gt;\n        &lt;div class=&quot;section-title reg-header&quot;&gt;\n            &lt;h3&gt;Places&lt;/h3&gt;\n            &lt;p&gt;App to collect your addresses&lt;/p&gt;\n\n        &lt;/div&gt;\n    &lt;/div&gt;\n{% endblock %}\n</code></pre>\n<p>i wygląda tak:</p>\n<p><img src=\"http://i.imgur.com/7mkjpKI.png\" alt=\"olaces\" loading=\"lazy\"></p>\n<p>Ciekawszym widokiem jest widok miejsc. Umieściliśmy go w pliku <code>app/Resources/views/places/places.html.twig</code></p>\n<p>Jego kod html jest dość prosty:</p>\n<pre><code class=\"language-twig\">{% extends 'base.html.twig' %}\n\n{% block body %}\n    {{ parent() }}\n\n    &lt;div class=&quot;container eternity-form&quot;&gt;\n        &lt;div class=&quot;section-title reg-header&quot;&gt;\n            &lt;h3&gt;Update your address&lt;/h3&gt;\n\n            &lt;br&gt;\n            &lt;p id=&quot;info&quot;&gt;&lt;/p&gt;\n\n            &lt;div class=&quot;list&quot;&gt;\n            {% for place in places %}\n                &lt;div data-id=&quot;{{ place.googleId }}&quot; class=&quot;btn-group place-elem&quot; role=&quot;group&quot;&gt;\n                    &lt;button type=&quot;button&quot; class=&quot;place-name btn btn-default&quot;&gt;{{ place.formattedAddress }}&lt;/button&gt;\n                    &lt;button type=&quot;button&quot; class=&quot;place-delete btn btn-danger delete&quot;&gt;Delete&lt;/button&gt;\n                &lt;/div&gt;\n            {% endfor %}\n            &lt;/div&gt;\n\n            &lt;div class=&quot;input-group&quot;&gt;\n                &lt;input name=&quot;formatted_address&quot; type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;Type your location...&quot;&gt;\n                &lt;span class=&quot;input-group-btn place-padding-bottom&quot;&gt;\n                    &lt;button id=&quot;my_location&quot; class=&quot;btn btn-info&quot;&gt;Check my location&lt;/button&gt;\n                    &lt;button id=&quot;save_location&quot; class=&quot;btn btn-default&quot;&gt;Save location&lt;/button&gt;\n                &lt;/span&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n{% endblock %}\n</code></pre>\n<p>Warto zwrócić uwagę na to jak sprawnie będą uzupełniały się tutaj metody zarządzania widokiem po stronie serwera (pętla w twigu) oraz po stronie klienta. Od momentu wygenerowania początkowego widoku wszystkie zmiany robi już <code>javascript</code>.</p>\n<p>Widok wyposażony jest w swój styl, który zaciąga rozszerzając blok <code>stylesheets</code></p>\n<pre><code class=\"language-twig\">{% block stylesheets %}\n    {{ parent() }}\n    &lt;link href=&quot;{{ asset('bundles/app/css/place.css') }}&quot; rel=&quot;stylesheet&quot; /&gt;\n{% endblock %}\n</code></pre>\n<p>Styl znajduje się w pliku <code>src/AppBundle/Resources/public/css/place.css</code> i ma tylko 4 reguł:</p>\n<pre><code class=\"language-css\">.place-name {\n    width: 74%;\n}\n\n.place-delete {\n    width: 26%;\n}\n\n.place-padding-bottom{\n    padding-bottom: 30px;\n}\n\n.place-elem {\n    padding-bottom: 5px;\n    width: 100%;\n}\n</code></pre>\n<p>Jeśli piszę w <code>css</code> to zwykle ograniczam się do takiego właśnie minimalizmu. Co innego z <code>javascriptem</code>. W widoku (<code>app/Resources/views/places/places.html.twig</code>) jest go objętościowo więcej niż <code>html</code>. Spełnia on następujące zadania:</p>\n<pre><code class=\"language-js\">{% block javascripts %}\n{{ parent() }}\n\n&lt;script&gt;\n    var places = [];\n    {% for place in places %}\n    places.push({{ place|raw }});\n    {% endfor %}\n</code></pre>\n<p>Przy ładowaniu strony zapisuje do JavaScriptowej zmiennej <code>places</code> tablicę z tekstowymi reprezentacjami obiektów <code>Place</code> przekazanych do twigowej zmiennej. Będą nam one potrzebne do unikania duplikacji treści. Dzięki temu rozwiązaniu mamy stan aplikacji w zmiennej oraz na ekranie jednocześnie.</p>\n<p>Następnie robię to co zawsze robię rozpoczynając skrypt</p>\n<pre><code class=\"language-js\">    var info = document.getElementById(&quot;info&quot;);\n    var area = document.getElementsByClassName(&quot;section-title&quot;)[0];\n    var list = document.getElementsByClassName(&quot;list&quot;)[0];\n</code></pre>\n<p>identyfikuję potrzebne elementy za pomocą selektorów. Później robię to co zawsze robię w skryptach po identyfikacji elementów.</p>\n<pre><code class=\"language-js\">    area.addEventListener('click',function(e){\n       if(e.target.id=='my_location'){\n           getLocation();\n       } else if(e.target.id=='save_location') {\n           saveLocation();\n       } else if(e.target.classList.contains('delete')){\n           deleteLocation(e.target.parentNode.dataset.id);\n       }\n    });\n</code></pre>\n<p>Dodaję jeden (staram się zwykle dodawać tylko jeden) listener, w którym przyporządkowują akcje wykrytym eventom. Mamy tu do wyboru trzy akcje: sprawdzenie lokacji za pomocą obiektu <code>navigarot</code> przeglądarki, zapisanie i usunięcie lokacji.</p>\n<p>Za obsługę <code>navigatora</code> odpowiada poniższy kod.</p>\n<pre><code class=\"language-js\">    function getLocation() {\n        if (navigator.geolocation) {\n            navigator.geolocation.getCurrentPosition(showPosition);\n        } else {\n            info.innerHTML = &quot;Geolocation is not supported by this browser.&quot;;\n        }\n    }\n</code></pre>\n<p>Jeśli użytkownik wyrazi zgodę na dostęp do jego lokalizacji, jest ona przekazywana do funkcji <code>showPosition</code>.</p>\n<pre><code class=\"language-js\">    function showPosition(position) {\n        $.ajax({\n            url: &quot;{{ path('ajax_geo_location') }}&quot;,\n            method: &quot;GET&quot;,\n            data: {\n                lat: position.coords.latitude,\n                lon: position.coords.longitude\n            },\n            success: function(msg){\n                $(&quot;#my_location&quot;).html('Position obtained');\n                $(&quot;input[name=formatted_address]&quot;).val(msg['formatted_address']);\n            }});\n    }\n</code></pre>\n<p>Ta funkcja z kolei wysyła odpowiedni request i wypełnia pole formularza sformatowanym adresem odpowiadającym współrzędnych przeglądarki.</p>\n<p>Zapisanie lokacji - czyli wysłanie formularza realizowane jest przez kolejną funkcję:</p>\n<pre><code class=\"language-js\">    function saveLocation(){\n        $.post('{{ path('ajax_geo_save') }}',\n                JSON.stringify({formatted_address: $(&quot;input[name=formatted_address]&quot;).val()})\n        ).done(function(res){\n\n        if(places.filter(function(obj) {return obj.id == res.place_id}).length){\n            return;\n        }\n\n        places.push({'id':res.place_id,'addess':res.formatted_address});\n        list.innerHTML += '&lt;div data-id=&quot;'+res.place_id+'&quot; class=&quot;btn-group place-elem&quot; role=&quot;group&quot;&gt;\\\n            &lt;button type=&quot;button&quot; class=&quot;place-name btn btn-default&quot;&gt;'+res.formatted_address+'&lt;/button&gt;\\\n            &lt;button type=&quot;button&quot; class=&quot;place-delete btn btn-danger delete&quot;&gt;Delete&lt;/button&gt;\\\n            &lt;/div&gt;';\n        });\n    }\n</code></pre>\n<p>Jej działanie zaczyna się od wysłania requestu POST z treścią formularza. Jeśli otrzymamy odpowiedź, sprawdzamy czy miejsce jest już przypisane do użytkownika filtrując tablicę <code>places</code>. Jeśli tak, nic więcej nie robimy. Jeśli nie było, to dodajemy je do tablicy <code>places</code> i do listy miejsc dołączamy lokację za pomocą składni <code>.innerHTML +=</code>. Są do tego metody polegające na traktowaniu htmla jako drzewa DOM, ale są one efektywne jeśli są stosowane w szerszym kontekście. W tym przypadku metoda doklejenia treści mimo, że mniej elegancka została wybrana ze względu na większą prostotę.</p>\n<p>Ostatnia metoda odpowiada za usunięcie miejsca z listy miejsc użytkownika.</p>\n<pre><code class=\"language-js\">    function deleteLocation(googleId){\n        var route = &quot;{{ path('ajax_geo_delete',{'googleId':'PLACEHOLDER'}) }}&quot;;\n        $.ajax({\n            url: route.replace(&quot;PLACEHOLDER&quot;,googleId),\n            method: &quot;DELETE&quot;\n        });\n        places = places.filter(function( obj ) {\n            return obj.id !== googleId;\n        });\n        list.querySelector(&quot;[data-id='&quot;+googleId+&quot;']&quot;).outerHTML='';\n    }\n&lt;/script&gt;\n{% endblock %}\n</code></pre>\n<p>Tutaj odwrotnie niż przy zapisywaniu, usuwamy element z tablicy <code>places</code> i czyścimy <code>HTML</code> odpowiadający miejscu, które usuwamy. Na koniec dodajemy screen z przykładowego użytkowania:</p>\n<p><img src=\"http://i.imgur.com/YwW9q5l.png\" alt=\"\" loading=\"lazy\"></p>\n<p>To cały kod źródłowy. Nie ma tutaj testów, nie ma DoctrineFixturesBundle, nie ma panelu admina, nie ma gulpa.<br>\nPrzede wszystkim jednak nie ma miejsca. Z tego względu wszystkie wspomniane rzeczy zostały wycięte.<br>\nTen wpis i tak jest chyba najdłuższym jaki napisałem. Jego celem nie było przedstawianie kompleksowej aplikacji<br>\ntylko przykładu zastosowania FOSUserBundle.</p>\n<p>Mam nadzieję, że komuś pomoże to przy wdrażaniu tej znakomitej paczki w swoim projekcie. Jak zwykle czekam na waszą krytykę,<br>\npytania oraz wskazówki, co mogę poprawić.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f3b3b2fb35425592d0bce",
            "plaintext": "Opis projektu\nJest to projekt napisany jako jedna z funkcjonalności podczas mojej współpracy z \nSmartselect. Najzabawniejsze jest to, że był to mój pierwszy kontakt z \nFOSUserBundle, Api Google Maps i obiektem navigator. Kiedy go pisałem nie znałem \nJavaScriptu. Mimo, że przed publikacją kod wymagał odrobiny odświeżenia i\ndokładnego oddzielenie od innych funkcjonalności całej aplikacji, okazało się,\nże nie było to trudne i w tym wpisie przedstawiłem jak plik po pliku zbudować go\nod zera.\n\nZ wpisu dowiesz się jak zainstalować, skonfigurować i nadpisywać FOSUserBundle -\nnajpopularniejszą paczkę do obsługi użytkowników w Symfony. Stworzymy kilka\nwidoków związanych z logowaniem, rejestracją, zarządzaniem kontem, resetowaniem\nhasła i tak dalej. Jeśli lubisz front, to przez większość tego wpisu będziesz\nczuł się jak ryba w wodzie. Do backendu zejdziemy przy logice aplikacji, czyli\nwykorzystywaniu API Google Maps do tłumaczenia tekstowych adresów, albo\nwspółrzędnych na encje naszej bazy danych. Nie zabraknie Ajaxa, zobaczymy jak\nobiekt navigator pozwala nam dostać się do połorzenia przeglądarki oraz jak\npogodzić twiga i JavaScript w jednym froncie.\n\nDziałanie aplikacji możesz zobaczyć na poniższym video:\n\nSkład kodu źródłowego to:\n\nPHP 69.7% HTML 20.9% CSS 5.8% ApacheConf 3.1% JavaScript 0.5%\n\n\nInstalacja\nSą dwa sposoby stawiania nowego projektu Symfony: instalacja od zera\n[http://symfony.com/doc/current/best_practices/creating-the-project.html] oraz\nklonowanie z githuba.\n\nJeśli chcesz zainstalowawć projekt najprostszym możliwym sposobem, możesz pobrać\ngo z githuba [https://github.com/gustawdaniel/geo_local]\ni zainstalować go zgodnie z instrukcją z README.md.\n\nW tym wpisie pokażę jak instalować projekt od zera. Możesz nie zaglądać do\nmojego repo i wykonując wszystkie komendy i tworząc poniższe pliki powinienneś\notrzymać praktycznie to samo. Jedyne różnice będą polagać na tym, że na blogu\ndla większej przjejrzystości nie umieściłem kilku i tak nie używanych widoków\njak panel admina czy kontakt.\n\nWracając do instalacji. Jeśli chcesz instalować od zera to dokumentacja Symfony\nzaleca użycie jej instalatora.\n\nsymfony new geo_local && cd geo_local\n\n\nFosUserBundle\nBędziemy chcieli stworzyć użytkowników. W tym celu wykorzystamy jedną z\nnajpopularniejszych paczek - FOSUserBundle\n[https://symfony.com/doc/master/bundles/FOSUserBundle/index.html].\n\ncomposer require friendsofsymfony/user-bundle \"~2.0@dev\"\n\n\nŻeby ją wykorzystać musimy zarejestrować ją a jądrze aplikacji poprzez dodanie\nelementu: new FOS\\UserBundle\\FOSUserBundle() do tablicy $bundles w pliku \napp/AppKernel.php.\n\nNastępnie rozszerzamy klasę BaseUser żeby móc modyfikować klasę opisującą\nUżytkowników (zakładam, że będziemy korzystać z mysql, dla innych silników baz\ndanych konfiguracja może wyglądać trochę inaczej):\n\n<?php\n\nnamespace AppBundle\\Entity;\n\nuse FOS\\UserBundle\\Model\\User as BaseUser;\nuse Doctrine\\ORM\\Mapping as ORM;\n\n/**\n * @ORM\\Entity\n * @ORM\\Table(name=\"users\")\n */\nclass User extends BaseUser\n{\n    /**\n     * @ORM\\Id\n     * @ORM\\Column(type=\"integer\")\n     * @ORM\\GeneratedValue(strategy=\"AUTO\")\n     */\n    protected $id;\n\n    public function __construct()\n    {\n        parent::__construct();\n        // your own logic\n    }\n}\n\n\nZmieniamy zawartość pliku: app/config/security.yml\n\nsecurity:\n    encoders:    \n        FOS\\UserBundle\\Model\\UserInterface: bcrypt\n\n    role_hierarchy:\n        ROLE_ADMIN:       ROLE_USER\n        ROLE_SUPER_ADMIN: ROLE_ADMIN\n\n    providers:\n        fos_userbundle:\n            id: fos_user.user_provider.username\n\n    firewalls:\n        main:\n            pattern: ^/\n            form_login:\n                provider: fos_userbundle\n                csrf_token_generator: security.csrf.token_manager\n                # if you are using Symfony < 2.8, use the following config instead:\n                # csrf_provider: form.csrf_provider\n\n            logout:       true\n            anonymous:    true\n\n    access_control:\n        - { path: ^/login$, role: IS_AUTHENTICATED_ANONYMOUSLY }\n        - { path: ^/register, role: IS_AUTHENTICATED_ANONYMOUSLY }\n        - { path: ^/resetting, role: IS_AUTHENTICATED_ANONYMOUSLY }\n        - { path: ^/admin/, role: ROLE_ADMIN }\n\n\nNa koniec w pliku app/config/config.yml odkomentowujemy linię zawierającą wpis \n#translator: { fallbacks: [\"%locale%\"] }. I na końcu dodajemy:\n\nfos_user:\n    db_driver: orm\n    firewall_name: main\n    user_class: AppBundle\\Entity\\User\n\n\nPowinniśmy też dodać dwie linie do routingu app/config/routing.yml:\n\nfos_user:\n    resource: \"@FOSUserBundle/Resources/config/routing/all.xml\"\n\n\nŻeby wszystko działało powinniśmy jeszcze ustawić sobie parametry połączenia z\nbazą danych. W moim przypadku sprowadza się to do ustawienia: wpisu \ndatabase_name: geo_local w plikach: app/config/parameters.yml i \napp/config/parameters.yml.dist.\n\nTworzymy bazę danych i potrzebne tabele za pomocą komend:\n\nphp bin/console doctrine:database:create\nphp bin/console doctrine:schema:update --force\n\n\nTeraz wszystko powinno działać. Mam na myśli, że po uruchomieniu serwera komendą \nphp bin/console server:run i wpisaniu w przeglądarkę adresu 127.0.0.1:8000/login \nzobaczymy coś takiego:\n\n\n\nNadpisywanie zachowania FOSUserBundle\nMamy teraz dwa problemy, pierwszy, że nie wygląda to ładnie, drugi, że chcemy\nzamiast username używać email, a po zalogowaniu chcemy dodać nasze własne\nprzekierowanie. Zaczniemy od logiki, a front zostawimy na później.\n\nZastąpienie username przez e-mail\nBardzo czytelną instrukcję pozbywania się pola username można znaleźć na stacku\n[http://stackoverflow.com/questions/8832916/remove-replace-the-username-field-with-email-using-fosuserbundle-in-symfony2]\n. W klasie User nadpisujemy setter dla pola e-mail.\n\npublic function setEmail($email)\n{\n    $email = is_null($email) ? '' : $email;\n    parent::setEmail($email);\n    $this->setUsername($email);\n\n    return $this;\n}\n\n\nNie podążymy jednak za tą instrukcję zbyt dosłownie, dlatego, że w oficjalnej\ndokumentacji można wyczytać między wierszami lepszy sposób. Wspomagając się\ndokumentacją nadpisywania formularzy\n[http://symfony.com/doc/master/bundles/FOSUserBundle/overriding_forms.html],\ntworzymy plik src/AppBundle/Form/RegistrationType.php który nadpisze nam domyśny\nformularz rejestracji. Przy rejestracji chcemy wymagać od użytkownika tylko\njednego hasła, dlatego upieczemy dwie pieczenie na jednym ogniu nadpisując ten\nformulaż. Oto treść pliku:\n\n<?php\nnamespace AppBundle\\Form;\n\nuse Symfony\\Component\\Form\\AbstractType;\nuse Symfony\\Component\\Form\\FormBuilderInterface;\nuse Symfony\\Component\\Form\\Extension\\Core\\Type\\PasswordType;\n\nclass RegistrationType extends AbstractType\n{\n    public function buildForm(FormBuilderInterface $builder, array $options)\n    {\n        $builder->remove('username')\n            ->remove('plainPassword')\n            ->add('plainPassword',PasswordType::class);\n    }\n\n    public function getParent()\n    {\n        return 'FOS\\UserBundle\\Form\\Type\\RegistrationFormType';\n    }\n\n    public function getBlockPrefix()\n    {\n        return 'app_user_registration';\n    }\n}\n\n\nUsuwając i dodając hasło pozbywamy się dość ciekawej i zaawansowanej sztuczki z\npowtarzaniem tego pola, jaką stosuje FOSUserBundle. Analogicznie nadpisujemy\nedycję profilu src/AppBundle/Type/ProfileType.php:\n\n<?php\nnamespace AppBundle\\Form;\n\nuse Symfony\\Component\\Form\\AbstractType;\nuse Symfony\\Component\\Form\\FormBuilderInterface;\n\nclass ProfileType extends AbstractType\n{\n    public function buildForm(FormBuilderInterface $builder, array $options)\n    {\n        $builder->remove('username');\n    }\n\n    public function getParent()\n    {\n        return 'FOS\\UserBundle\\Form\\Type\\ProfileFormType';\n    }\n\n    public function getBlockPrefix()\n    {\n        return 'app_user_profile';\n    }\n}\n\n\nRejestrujemy nasze formularze jako usługi modyfikując plik \napp/config/services.yml:\n\nservices:\n    app.form.registration:\n        class: AppBundle\\Form\\RegistrationType\n        tags:\n            - { name: form.type, alias: app_user_registration }\n    app.form.profile:\n        class: AppBundle\\Form\\ProfileType\n        tags:\n            - { name: form.type, alias: app_user_profile }\n\n\nNa końcu w konfiguracji paczki ustawiamy nasze formularze jako te, które mają\nnadpisać domyślne.\n\nfos_user:\n    db_driver: orm\n    firewall_name: main\n    user_class: AppBundle\\Entity\\User\n    registration:\n        form:\n            type: AppBundle\\Form\\RegistrationType\n    profile:\n        form:\n            type: AppBundle\\Form\\ProfileType\n\n\nNie ruszamy w ogóle walidacji. Należy pamiętać, że link\n[http://stackoverflow.com/questions/8832916/remove-replace-the-username-field-with-email-using-fosuserbundle-in-symfony2] \nz instrukcją odnosił się do wersji 2 Symfony, a w naszym projekcie używamy 3.\n\nPrzekierowanie po logowaniu\nDomyślnie po zalogowaniu FOSUserBundle przekierowuje nas do profilu użytkownika.\nJest to logiczne, ale nie praktyczne w naszym przypadku. Główna funkcjonalność\naplikacji nie będzie polegała na zmienianiu swojego e-maila i hasła. Zamiast\ntego chcemy przekierować użytkownika do ścieżki nazywanej homepage, a dopiero\njej kontroler będzie wysyłał zalogowanych do panelu z miejscami, a nie\nzalogowanych do strony informacyjnej. Żeby po zalogowaniu móc przekierować\nużytkownika do homepage wykonamy następujące zmiany: dodamy plik \nsrc/AppBundle/Security/LoginSuccessHandler.php o treści:\n\n<?php\nnamespace AppBundle\\Security;\n\nuse Symfony\\Component\\Security\\Http\\Authentication\\AuthenticationSuccessHandlerInterface;\nuse Symfony\\Component\\Security\\Core\\Authentication\\Token\\TokenInterface;\nuse Symfony\\Component\\Security\\Core\\Authorization\\AuthorizationChecker;\nuse Symfony\\Component\\HttpFoundation\\Request;\nuse Symfony\\Component\\HttpFoundation\\RedirectResponse;\nuse Symfony\\Component\\Routing\\Router;\n\nclass LoginSuccessHandler implements AuthenticationSuccessHandlerInterface {\n\n    protected $router;\n    protected $authorizationChecker;\n\n    public function __construct(Router $router, AuthorizationChecker $authorizationChecker) {\n        $this->router = $router;\n        $this->authorizationChecker = $authorizationChecker;\n    }\n\n    public function onAuthenticationSuccess(Request $request, TokenInterface $token) {\n        return new RedirectResponse($this->router->generate('homepage'));\n    }\n}\n\n\nW serwisach (app/config/services.yml) powinniśmy dodać usługę:\n\n    authentication.handler.login_success_handler:\n        class:  AppBundle\\Security\\LoginSuccessHandler\n        arguments:  ['@router', '@security.authorization_checker']\n\n\nPowinniśmy dodać parametr success_handler do pliku app/config/security.yml\n\n    firewalls:\n        main:\n            pattern: ^/\n            form_login:\n                provider: fos_userbundle\n                csrf_token_generator: security.csrf.token_manager\n                success_handler: authentication.handler.login_success_handler\n\n\nNadpisanie wyglądu FOSUserBundle\nTeraz mając odpowiednią ilość pól w formularzu możemy zmienić wygląd, tak, żeby\nnie straszył, i nie powodował koszmarów u użytkowników. Listę ścieżek jakimi\npowinniśmy się zająć wyświetlimy komendą:\n\nphp bin/console debug:router | grep fos_user\n\n\nNajprostszą metodą nadpisania domyślnego wyglądu jest wykonanie następującej\nkomendy.\n\nmkdir -p app/Resources/FOSUserBundle/views && cp -r vendor/friendsofsymfony/user-bundle/Resources/views/* \"$_\"\n\n\nDodawanie zewnętrznych bibliotek\nZainstalujemy teraz biblioteki frontowe i dodamy nasze własne style oraz\nskrypty.\nŻeby nie było problemów z cache twiga, wyłączymy go w trybie deweloperskim\ndodając do pliku app/config/config_dev.yml linie:\n\ntwig:\n    cache: false\n\n\nTwożymy plik .bowerrc o treści:\n\n{\n  \"directory\": \"web/bower_components/\"\n}\n\n\nInicjalizujemy bowera komendą:\n\nbower init\n\n\nInstalujemy bootstrapa 3, animate.css, components-font-awesome, jQuery i iCheck\n- małą bibliotekę opartą na jQuery do wyświetlania efektów związanych z\nzaznaczaniem pól formularzy i checkboxów:\n\nbower install --save bootstrap#^3.3.7 animate.css#^3.5.2 components-font-awesome#^4.7.0 iCheck#^1.0.2 jquery#^3.1.1\n\n\nDo .gitignore dodajemy linie:\n\n/.idea\n/web/bower_components\n\n\nNie jestem dobrym frontowcem, dlatego kupuję fronty. Tak było i w tym przypadku.\nCSS, który załączam kupiłem na stronie\nwrapbootstrap.com [https://wrapbootstrap.com/theme/eternity-forms-WB0G8810G].\nWyciąłem z niego połowę nie wykorzystywanej\nfunkcjonalności i zmieniłem linki do skinów iCheck. Umieściłem plik css w\nlokacji src/AppBundle/Resources/public/css/forms.css.\n\n.eternity-form-modal {\n  background-color: #707d85;\n}\n.eternity-form {\n  font-family: 'Roboto', 'PT Sans', sans-serif;\n  font-weight: 300;\n  color: #95a5a6;\n}\n.eternity-form h1,\n.eternity-form h2,\n.eternity-form h3,\n.eternity-form h4,\n.eternity-form h5,\n.eternity-form h6 {\n  font-family: 'Roboto', 'PT Sans', sans-serif;\n  font-weight: 300;\n}\n.eternity-form .login-form-section,\n.eternity-form .forgot-password-section {\n  width: 100%;\n  max-width: 360px;\n  margin: 0 auto;\n}\n.eternity-form .login-content,\n.eternity-form .forgot-password-section,\n.eternity-form .reg-content {\n  background-color: white;\n  -o-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -ms-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -moz-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -webkit-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n}\n.eternity-form .section-title {\n  padding: 10px 20px;\n  background-color: white;\n}\n.eternity-form .section-title h3 {\n  color: #3498db;\n}\n.eternity-form .textbox-wrap {\n  padding: 20px 20px 20px 15px;\n  border-left: 5px solid transparent;\n  -moz-transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\n  -o-transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\n  -webkit-transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\n  transition: border-left-color 0.5s, box-shadow 0.5s, background-color 0.5s;\n}\n.eternity-form .textbox-wrap .input-group {\n  border: 1px solid #e0e0e0;\n  background-color: #ffffff;\n}\n.eternity-form .textbox-wrap .input-group .input-group-addon,\n.eternity-form .textbox-wrap .input-group input,\n.eternity-form .textbox-wrap .input-group .form-control {\n  background-color: transparent;\n  border: none;\n}\n.eternity-form .textbox-wrap .input-group input,\n.eternity-form .textbox-wrap .input-group .form-control,\n.eternity-form .textbox-wrap .input-group input:focus,\n.eternity-form .textbox-wrap .input-group .form-control:focus {\n  box-shadow: none;\n  outline: none;\n}\n.eternity-form .textbox-wrap .input-group i {\n  color: #cccccc;\n}\n.eternity-form .textbox-wrap.focused {\n  border-left-color: #3498db;\n  background-color: #f0f0f0;\n  -o-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\n  -ms-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\n  -moz-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\n  -webkit-box-shadow: inset 0 0 3px rgba(0,0,0,.1);\n  box-shadow: inset 0 0 3px rgba(0,0,0,.1);\n}\n.eternity-form .green-btn,\n.eternity-form .green-btn:hover,\n.eternity-form .blue-btn {\n  background-color: #2ecc71;\n  border: none;\n}\n.eternity-form .blue-btn,\n.eternity-form .blue-btn:hover {\n  background-color: #2980b9;\n}\n.eternity-form .login-form-action {\n  padding: 15px 20px 30px 20px;\n}\n.eternity-form input[type=\"checkbox\"] {\n  width: 30px;\n}\n.eternity-form .blue {\n  color: #3498db;\n}\n.eternity-form .green {\n  color: #2ecc71;\n}\n.eternity-form .login-form-links {\n  padding: 20px;\n  margin-top: 5px;\n  -o-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\n  -ms-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\n  -moz-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\n  -webkit-box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\n  box-shadow: 0 0 4px rgba(0, 0, 0, 0.4);\n  background-color: white;\n}\n.eternity-form .login-form-links a.blue:hover,\n.eternity-form .login-form-links a a.blue:focus {\n  color: #3498db;\n  text-decoration: underline;\n}\n.eternity-form .login-form-links a.green:hover,\n.eternity-form .login-form-links a a.green:focus {\n  color: #2ecc71;\n  text-decoration: underline;\n}\n.eternity-form .forget-form-action {\n  padding: 20px;\n}\n.eternity-form .registration-form-section {\n  max-width: 620px;\n  margin: 0 auto;\n  width: 100%;\n}\n.eternity-form .reg-header {\n  -o-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -ms-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -moz-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -webkit-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n}\n.eternity-form .registration-left-section {\n  padding-left: 0;\n  padding-right: 2px;\n}\n.eternity-form .registration-right-section {\n  padding-left: 2px;\n  padding-right: 0;\n}\n.eternity-form .reg-content {\n  margin-top: 5px;\n  padding: 20px 0;\n}\n.eternity-form .registration-form-action {\n  margin-top: 5px;\n  padding: 20px;\n  -o-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -ms-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -moz-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  -webkit-box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  box-shadow: 0 0 3px rgba(0, 0, 0, 0.3);\n  background-color: white;\n}\n.eternity-form .custom-checkbox {\n  float: left;\n}\n.eternity-form .checkbox {\n  display: inline-block;\n  padding-left: 1px;\n  margin-top: 7px;\n  margin-bottom: 0;\n}\n.eternity-form .checkbox-text {\n  line-height: 24px;\n  padding-left: 5px;\n}\n.eternity-form .form-control:-moz-placeholder {\n  font-weight: 300;\n}\n.eternity-form .form-control::-moz-placeholder {\n  font-weight: 300;\n}\n.eternity-form .form-control:-ms-input-placeholder {\n  font-weight: 300;\n}\n.eternity-form .form-control::-webkit-input-placeholder {\n  font-weight: 300;\n}\n\n.eternity-form .checkbox label {\n  font-weight: 300;\n}\n\n.eternity-form .icheckbox_square-blue {\n  display: block;\n  margin: 0;\n  padding: 0;\n  width: 22px;\n  height: 22px;\n  /*background: url(../img/blue.png) no-repeat;*/\n  background: url(\"../../../bower_components/iCheck/skins/square/blue.png\") no-repeat;\n  border: none;\n  cursor: pointer;\n}\n.eternity-form .icheckbox_square-blue {\n  background-position: 0 0;\n}\n.eternity-form .icheckbox_square-blue.hover {\n  background-position: -24px 0;\n}\n.eternity-form .icheckbox_square-blue.checked {\n  background-position: -48px 0;\n}\n.eternity-form .icheckbox_square-blue.disabled {\n  background-position: -72px 0;\n  cursor: default;\n}\n.eternity-form .icheckbox_square-blue.checked.disabled {\n  background-position: -96px 0;\n}\n\n@media only screen and (-webkit-min-device-pixel-ratio: 1.5), only screen and (-moz-min-device-pixel-ratio: 1.5), only screen and (-o-min-device-pixel-ratio: 3/2), only screen and (min-device-pixel-ratio: 1.5) {\n  .eternity-form .icheckbox_square-blue {\n    background-image: url(\"../../../bower_components/iCheck/skins/square/blue@2x.png\");\n    -webkit-background-size: 240px 24px;\n    background-size: 240px 24px;\n  }\n}\n@media (max-width: 767px) {\n  .eternity-form .registration-left-section {\n    padding-right: 0;\n  }\n  .eternity-form .registration-right-section {\n    padding-left: 0;\n  }\n}\n@media (max-width: 380px) {\n  .eternity-form .blue-btn,\n  .eternity-form .green-btn {\n    font-size: .8em;\n  }\n}\n\n\nPotrzebujemy jeszcze jednego skryptu - \nsrc/AppBundle/Resources/public/js/iCheck-config.js jest to konfiguracja wtyczki \niCheck służącej do interaktywnego podświetlania aktywnych pól formularz:\n\n    $(function () {\n\n        //Custom Checkbox For Light Theme\n        $(\"input\").iCheck({\n            checkboxClass: 'icheckbox_square-blue',\n            increaseArea: '20%'\n        });\n\n        //Custom Checkbox For Dark Theme\n        $(\".dark input\").iCheck({\n            checkboxClass: 'icheckbox_polaris',\n            increaseArea: '20%'\n        });\n\n        //TextBox Focus Event\n        $(\".form-control\").focus(function () {\n            $(this).closest(\".textbox-wrap\").addClass(\"focused\");\n        }).blur(function () {\n            $(this).closest(\".textbox-wrap\").removeClass(\"focused\");\n        });\n\n    });\n\n\nLinkujemy go z katalogiem web komendą\n\nphp bin/console assets:install --symlink\n\n\nNie jest to najlepsza dostępna metoda. Lepszą jest zastosowanie gulpa, ale jest\nnajprostsza. Przy trzech kilku plikach styli i skryptów i kilku zewnętrznych\nbibliotekach brak konkatenacji i minifikacji nie jest niczym strasznym.\nOczywiście tworzenie pliku ze stylami bezpośrednio w katalogu web jest prostsze,\nale niepoprawne.\n\nOstatnią rzeczą jaka została nam do zrobienia jest dodanie bootstrapowych\nformularzy jako domyślnych dla twiga, w pliku app/config/config.yml dodajemy\nlinie:\n\ntwig:\n    form_themes:\n        - 'bootstrap_3_layout.html.twig'\n\n\nSzablon bazowy\nZaczniemy od dostosowania wyglądu loginu. Login będzie dziedziczył z \nlayout.html.twig z FOSUserBundle, a ten będzie dziedziczył z base.html.twig.\nŻeby więc budować dom od fundamentów, nie od dachu, przyjrzymy się bazowemu\nszablonowi - app/Resources/views/base.html.twig.\n\n<!DOCTYPE html>\n<html>\n<head>\n    <meta charset=\"UTF-8\"/>\n    <title>{% block title %}Welcome!{% endblock %}</title>\n    <link rel=\"icon\" type=\"image/x-icon\" href=\"{{ asset('favicon.ico') }}\"/>\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n    {% block meta %}{% endblock %} {% block stylesheets %}       <!-- Bootstrap 3 CSS -->\n    <link rel=\"stylesheet\" href=\"{{ asset('bower_components/bootstrap/dist/css/bootstrap.min.css') }}\">\n    <!-- Eternity Login , Registration & Forgot Password Forms CSS -->\n    <link href=\"{{ asset('bundles/app/css/forms.css') }}\" rel=\"stylesheet\"/>\n    {% endblock %}\n</head>\n\n<body> {% block body %}\n<nav class=\"navbar navbar-default\">\n    <div class=\"container\">\n        <div class=\"navbar-header\">\n            <button type=\"button\" class=\"navbar-toggle collapsed\" data-toggle=\"collapse\" data-target=\"#navbar\"\n                    aria-expanded=\"false\" aria-controls=\"navbar\"><span class=\"sr-only\">Toggle navigation</span>\n                <span class=\"icon-bar\"></span>\n                <span class=\"icon-bar\"></span>\n                <span class=\"icon-bar\"></span>\n            </button>\n\n            <div class=\"{% if app.request.attributes.get('_route') == 'homepage' %}active{% endif %}\">\n                <a class=\"navbar-brand\" href=\"{{ url('homepage') }}\">Places</a>\n            </div>\n\n        </div>\n        <!-- Collect the nav links, forms, and other content for toggling -->\n        <div class=\"collapse navbar-collapse\" id=\"navbar\">\n            <ul class=\"nav navbar-nav navbar-right\"> {% if app.user %}\n\n                <li class=\"{% if app.request.attributes.get('_route') == 'fos_user_profile_show' %}list-group-item-info{% endif %}\">\n                    <a href=\"{{ url('fos_user_profile_show') }}\" data-toggle=\"tooltip\"\n                       data-placement=\"bottom\"\n                       title=\"{{ 'layout.logged_in_as'|trans({'%username%': app.user.username}, 'FOSUserBundle') }}\">\n                        My Acconut\n                    </a>\n                </li>\n\n                <li><a href=\"{{ url('fos_user_security_logout') }}\">Logout</a></li>\n                {% else %}\n                <li class=\"{% if app.request.attributes.get('_route') == 'fos_user_security_login' %}active{% endif %}\">\n                    <a href=\"{{ url('fos_user_security_login') }}\">Login</a>\n                </li>\n\n                <li class=\"list-group-item-info {% if app.request.attributes.get('_route') == 'fos_user_registration_register' %}active{% endif %}\">\n                    <a href=\"{{ url('fos_user_registration_register') }}\">Register</a>\n                </li>\n                {% endif %}\n            </ul>\n\n        </div><!-- /.navbar-collapse -->\n    </div><!-- /.container-fluid -->\n</nav>\n{% endblock %} {% block javascripts %}\n<script src=\"{{ asset('bower_components/jquery/dist/jquery.min.js') }}\"></script>\n\n<script src=\"{{ asset('bower_components/bootstrap/dist/js/bootstrap.min.js') }}\"></script>\n{% endblock %}\n</body>\n</html>\n\nCo my tu mamy? Jest viewport - strona działa na urządzeniach mobilnych.\nPodpinamy style, które mają się znaleźć wszędzie - bootstrap i forms. Dodaliśmy\nskrypty - jQuery i bootstrap. Nie ma tu potrzeby ładownia skryptów typu iCheck \nalby styli jak animate.css jeśli nie każda strona będzie ich potrzebować. Nie\nchcemy przecież zirytować użytkownika ciągłym animowaniem wszystkiego, tylko\nucieszyć go animacjami przy logowaniu lub rejestracji - to wystarczy. Tag <body> \nzawiera jedynie pasek nawigacji. Nawigacja jednak posiada logikę odpowiadającą\nza wyświetlanie nie zalogowanemu użytkownikowi pól \"login\" i \"rejestracja\", a\nzalogowanemu \"moje konto\" i \"wyloguj\".\n\nLayout dla FOSUserBundle\nTeraz przyjrzymy się plikowi app/Resources/FOSUserBundle/layout.html.twig -\nczyli szablonowi, który dziedziczy z base i jest jednocześnie rodzicem dla\nwszystkiego co będziemy nadpisywali w FOSUserBundle:\n\n{% extends '::base.html.twig' %}\n\n{% block title %}{% endblock %}\n\n{% block body %}\n    {{ parent() }}\n    {% block fos_user_content %}{% endblock fos_user_content %}\n{%  endblock %}\n\n{% block stylesheets %}\n    {{ parent() }}\n\n    <!-- Animations CSS -->\n    <link rel=\"stylesheet\" href=\"{{ asset('bower_components/animate.css/animate.min.css') }}\">\n\n    <!-- Font Icons -->\n    <link href=\"https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\" rel=\"stylesheet\" integrity=\"sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN\" crossorigin=\"anonymous\">\n\n    <!-- Google Web Fonts -->\n    <link href='http://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>\n\n    <style>\n        .eternity-form {\n            margin-top: 6vh;\n        }\n\n        .width-min-300px {\n            width: 100%;\n            max-width: 300px;\n        }\n    </style>\n{% endblock %}\n\n{% block javascripts %}\n    {{ parent() }}\n    <!-- Custom Checkbox PLugin -->\n    <script src=\"{{ asset('bower_components/iCheck/icheck.min.js') }}\"></script>\n\n    <!-- For Initializing Checkbox And Focus Event For Textbox -->\n    <script src=\"{{ asset('bundles/app/js/iCheck-config.js') }}\"></script>\n{% endblock %}\n\n\nW tym pliku dodaliśmy style i skrypty potrzebne tylko przy obsłudze użytkownika\noraz podpięliśmy blok fos_user_content bezpośrednio pod nawigacją zapisaną w \nbase.html.twig.\n\nLogin\nPlik app/Resources/FOSUserBundle/views/Security/login.html.twig pozostawiamy\npraktycznie nie zmieniony, dodjemy jedynie tytuł:\n\n{% extends \"@FOSUser/layout.html.twig\" %}\n\n{% block fos_user_content %}\n    {{ include('@FOSUser/Security/login_content.html.twig') }}\n{% endblock fos_user_content %}\n\n{% block title %}Login Form{% endblock %}\n\n\nDużo więcej kodu zostało dodanego w pliku \napp/Resources/FOSUserBundle/views/Security/login_content.html.twig\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n<div class=\"container eternity-form\">\n    <div class=\"login-form-section\">\n        <div class=\"login-content animated zoomIn\">\n            <form action=\"{{ path(\"fos_user_security_check\") }}\" method=\"post\">\n                {% if csrf_token %}\n                    <input type=\"hidden\" name=\"_csrf_token\" value=\"{{ csrf_token }}\" />\n                {% endif %}\n                <div class=\"section-title\">\n                    <h3>LogIn to your Account</h3>\n                </div>\n                <div class=\"textbox-wrap\">\n                    <div class=\"input-group\">\n                        <span class=\"input-group-addon \"><i class=\"fa fa-user\" aria-hidden=\"true\"></i></span>\n                        <input type=\"email\" id=\"username\" name=\"_username\" value=\"{{ last_username }}\"\n                               required=\"required\" class=\"form-control\" placeholder=\"{{ 'form.email'|trans }}\" />\n                    </div>\n                </div>\n                <div class=\"textbox-wrap\">\n                    <div class=\"input-group\">\n                        <span class=\"input-group-addon \"><i class=\"fa fa-key\" aria-hidden=\"true\"></i></span>\n                        <input type=\"password\" id=\"password\" name=\"_password\" required=\"required\" class=\"form-control \" placeholder=\"{{ 'security.login.password'|trans }}\"/>\n                    </div>\n                </div>\n                <div class=\"login-form-action clearfix\">\n                    <div class=\"checkbox pull-left\">\n                        <div class=\"custom-checkbox\">\n                            <input type=\"checkbox\" id=\"remember_me\" name=\"_remember_me\" value=\"on\" checked />\n                        </div>\n                        <span class=\"checkbox-text pull-left\">&nbsp;{{ 'security.login.remember_me'|trans }}</span>\n                    </div>\n                    <button type=\"submit\" id=\"_submit\" name=\"_submit\" class=\"btn btn-success pull-right green-btn\">LogIn &nbsp;<i class=\"fa fa-chevron-right\" aria-hidden=\"true\"></i></button>\n                </div>\n            </form>\n        </div>\n\n        {% if error %}\n            <div class=\"login-form-links link1 animated fadeInUpBig text-danger\">\n                <h4>Error</h4>\n                <p>\n                    {{ error.messageKey|trans(error.messageData, 'security') }}\n                </p>\n            </div>\n        {% endif %}\n\n        <div class=\"login-form-links link1 animated fadeInLeftBig\">\n            <h4 class=\"blue\">Don't have an Account?</h4>\n            <span>No worry</span>\n            <a href=\"{{ path('fos_user_registration_register') }}\" class=\"blue\">Click Here</a>\n            <span>to Register</span>\n        </div>\n        <div class=\"login-form-links link2 animated fadeInRightBig\">\n            <h4 class=\"green\">Forget your Password?</h4>\n            <span>Dont worry</span>\n            <a href=\"{{ path('fos_user_resetting_request') }}\" class=\"green\">Click Here</a>\n            <span>to Get New One</span>\n        </div>\n    </div>\n</div>\n\n\nJednak, jest to tylko front - formularz logowania i dwa linki w twigu. A\nponieważ o frontach obraz mówi więcej niż tysiąc słów więc zamiast go opisywać\nwklejam screen:\n\n\n\nRejestracja\nRejstracja wygląda podobnie.\nPlik: app/Resources/FOSUserBundle/views/Registration/register.html.twig\n\n{% extends \"@FOSUser/layout.html.twig\" %}\n\n{% block fos_user_content %}\n{% include \"@FOSUser/Registration/register_content.html.twig\" %}\n{% endblock fos_user_content %}\n\n{% block title %}Register{% endblock %}\n\n\nPlik: app/Resources/FOSUserBundle/views/Registration/register_content.html.twig\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n<div class=\"container eternity-form\">\n    <div class=\"registration-form-section\">\n            {{ form_start(form, {'method': 'post', 'action': path('fos_user_registration_register'), 'attr': {'class': 'fos_user_registration_register'}}) }}\n\n            <div class=\"section-title reg-header animated fadeInDown\">\n                <h3>Get your Account Here </h3>\n\n            </div>\n            <div class=\"clearfix\">\n                <div class=\"col-sm-6 registration-left-section  animated fadeInRightBig\">\n                    <div class=\"reg-content\">\n                        <div class=\"textbox-wrap\">\n                            <div class=\"input-group\">\n                                <span class=\"input-group-addon \"><i class=\"fa fa-user\" aria-hidden=\"true\"></i></span>\n                                {{ form_widget(form.email, {'attr': {'placeholder': 'Email'}}) }}\n                            </div>\n                        </div>\n                    </div>\n                </div>\n                <div class=\"col-sm-6 registration-right-section animated fadeInLeftBig\">\n                    <div class=\"reg-content\">\n                        <div class=\"textbox-wrap\">\n                            <div class=\"input-group\">\n                                <span class=\"input-group-addon \"><i class=\"fa fa-key\" aria-hidden=\"true\"></i></span>\n                                {{ form_widget(form.plainPassword, {'attr': {'placeholder': 'Password'}}) }}\n                            </div>\n                        </div>\n                    </div>\n                </div>\n            </div>\n            <div class=\"registration-form-action clearfix animated fadeInUp\">\n                <a href=\"{{ path('fos_user_security_login') }}\" class=\"btn btn-success pull-left blue-btn \">\n                    <i class=\"fa fa-chevron-left\"></i>&nbsp; &nbsp;Back To Login\n                </a>\n                <button type=\"submit\" class=\"btn btn-success pull-right green-btn \">Register Now &nbsp; <i class=\"fa fa-chevron-right\"></i></button>\n            </div>\n        {{ form_end(form) }}\n    </div>\n</div>\n\n\nEfekt:\n\n\n\nJeśli rejestracja przebiega pomyślnie, gratulujemy użytkonikowi komunikatem z\npliku: app/Resources/FOSUserBundle/views/Registration/confirmed.html.twig\n\n{% extends \"@FOSUser/layout.html.twig\" %}\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n{% block fos_user_content %}\n    <div class=\"container eternity-form\">\n        <div class=\"section-title reg-header\">\n            <h3>Registration finished correctly</h3>\n            <div>\n                <p>{{ 'registration.confirmed'|trans({'%username%': user.username}) }}</p>\n                {% if targetUrl %}\n                    <p><a href=\"{{ targetUrl }}\">{{ 'registration.back'|trans }}</a></p>\n                {% endif %}\n            </div>\n            <a href=\"{{ path('homepage') }}\" class=\"btn btn-info width-min-300px\">Let's start</a>\n        </div>\n    </div>\n{% endblock fos_user_content %}\n\n\nKtóry prezentuje się tak:\n\n\n\nResetowanie hasła\nJeśli posiadający konto użytkownik zapomni hasła, może je wysłać na swój e-mail\n(jeśli w app/config/parameters.yml są odpowiednie parametry umożliwiające\nwysłanie e-maila) za pomocą formularza, którego kod znajduje się w pliku \napp/Resources/FOSUserBundle/views/Resetting/request_content.html.twig\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n<div class=\"container eternity-form\">\n    <div class=\"forgot-password-section animated bounceInLeft\">\n        <div class=\"section-title\">\n            <h3>Forget Password</h3>\n        </div>\n        <div class=\"forgot-content\">\n            <form action=\"{{ path('fos_user_resetting_send_email') }}\" method=\"POST\" class=\"fos_user_resetting_request\">\n                <div class=\"textbox-wrap\">\n                    <div class=\"input-group\">\n                        <span class=\"input-group-addon \"><i class=\"fa fa-envelope\"></i></span>\n                        <input type=\"email\" class=\"form-control\" id=\"username\" name=\"username\" required=\"required\" placeholder=\"Email Id\"/>\n\n                    </div>\n                </div>\n                <div class=\"forget-form-action clearfix\">\n                    <a href=\"{{ path('fos_user_security_login') }}\" class=\"btn btn-success pull-left blue-btn\"><i class=\"fa fa-chevron-left\"></i>&nbsp;&nbsp;Back  </a>\n                    <button type=\"submit\" class=\"btn btn-success pull-right green-btn\">Submit &nbsp;&nbsp; <i class=\"fa fa-chevron-right\"></i></button>\n                </div>\n            </form>\n        </div>\n    </div>\n</div>\n\n\nFormularz wygląda tak:\n\n\n\nZa to co pojawi się na ekranie po wpisaniu e-maila odpowiada plik: \napp/Resources/FOSUserBundle/views/Resetting/check_email.html.twig o treści\n\n{% extends \"@FOSUser/layout.html.twig\" %}\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n{% block fos_user_content %}\n    <div class=\"container eternity-form\">\n        <div class=\"section-title reg-header\">\n            <h3>Check Email</h3>\n            <div class=\"fos_user_user_show\">\n                <p>{{ 'resetting.check_email'|trans({'%tokenLifetime%': tokenLifetime})|nl2br }}\n                </p>\n            </div>\n        </div>\n    </div>\n{% endblock %}\n\n\nktóry prezentuje się tak:\n\n\n\nW e-mailu mamy link zmiany hasła. Szablon twiga znajduje się w pliku: \napp/Resources/FOSUserBundle/views/Resetting/reset_content.html.twig i ma kod:\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n<div class=\"container eternity-form\">\n    <div class=\"forgot-password-section section-title reg-header\">\n        <div class=\"section-title\">\n            <h3>Reset Password</h3>\n        </div>\n        {{ form_start(form, { 'action': path('fos_user_resetting_reset', {'token': token}), 'attr': { 'class': 'fos_user_resetting_reset' } }) }}\n        {{ form_widget(form) }}\n        <div>\n            <input type=\"submit\" class=\"btn btn-danger btn-block\" value=\"{{ 'resetting.reset.submit'|trans }}\" />\n        </div>\n        {{ form_end(form) }}\n    </div>\n</div>\n\n\nFormularz zmiany hasła tak:\n\n\n\nPanel użytkownika\nJeśli jako zalogowany użytkownik wybierzemy MyAccount z menu, zostaniemy\nprzekierowani do widoku konta. Jego html generowany jest z pliku \napp/Resources/FOSUserBundle/views/Profile/show_content.html.twig\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n<div class=\"container eternity-form\">\n    <div class=\"section-title reg-header\">\n        <h3>User Profile</h3>\n        <div class=\"fos_user_user_show\">\n            <p>{{ 'profile.show.username'|trans }}: {{ user.username }}</p>\n            <p>{{ 'profile.show.email'|trans }}: {{ user.email }}</p>\n            <a href=\"{{ path('homepage') }}\" class=\"btn btn-primary\">Edit Places</a>\n            <a href=\"{{ path('fos_user_profile_edit') }}\" class=\"btn btn-info\">Edit Profile</a>\n            <a href=\"{{ path('fos_user_change_password') }}\" class=\"btn btn-success\">Change Password</a>\n        </div>\n    </div>\n</div>\n\n\ni wygląda tak:\n\n\n\nPrzycisk Edit Places będzie prowadził do głównej funkcjonalności aplikacji.\nJednak żeby dokończyć to co związane z FOSUserBundle pokażemy teraz edycję\nprofilu i zmanę hasła. Edycja profilu: \napp/Resources/FOSUserBundle/views/Profile/edit_content.html.twig\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n<div class=\"container eternity-form\">\n\n    {{ form_start(form, { 'action': path('fos_user_profile_edit'), 'attr': { 'class': 'fos_user_profile_edit' } }) }}\n\n    <div class=\"section-title reg-header\">\n        <h3>Edit Profile</h3>\n        <div>\n            {{ form_widget(form) }}\n        </div>\n    </div>\n\n    <div class=\"registration-form-action clearfix\">\n        <div>\n            <a href=\"{{ path('fos_user_profile_show') }}\" class=\"btn btn-success pull-left blue-btn \">\n                <i class=\"fa fa-chevron-left\"></i>&nbsp; &nbsp;Back To Profile\n            </a>\n            <button type=\"submit\" class=\"btn btn-success pull-right green-btn \">{{ 'profile.edit.submit'|trans }} &nbsp; <i class=\"fa fa-chevron-right\"></i></button>\n        </div>\n    </div>\n    {{ form_end(form) }}\n</div>\n\n\n\n\nCały formularz sprowadza się do jednego pola - email, ponieważ jest to jedyna\nwłasność jaką chcemy nadawać użytkownikowi.\n\nZmiana hasła ma szablon w pliku \napp/Resources/FOSUserBundle/views/ChangePassword/change_password_content.html.twig\n\n{% trans_default_domain 'FOSUserBundle' %}\n\n<div class=\"container eternity-form\">\n    <div class=\"section-title reg-header\">\n        <h3>User Profile</h3>\n        <div class=\"fos_user_user_show\">\n            {{ form_start(form, { 'action': path('fos_user_change_password'), 'attr': { 'class': 'fos_user_change_password' } }) }}\n            {{ form_widget(form) }}\n            <div>\n                <input type=\"submit\" class=\"btn btn-danger btn-block\" value=\"{{ 'change_password.submit'|trans }}\" />\n            </div>\n            {{ form_end(form) }}\n        </div>\n    </div>\n</div>\n\n\n\n\nSą to wszystkie zmiany jakie zrobiłem, żeby dostosować FOSUserBundle do swoich\nwymagań. W app/Resources/FOSUserBundle Są pliki, których nie zmieniałem, na\nprzykład cały katalog Group, który jest związany z interakcjami między\nużytkonikami, ale ta funkcjonalność nie jest przez nas wykorzystywana.\nZostawiłem równiż e-mail do resetu hasła, który bez grafik wygląda tak:\n\n\n\nAle w przypadku e-maila jest to jak najbardziej dopuszczalne.\n\nAppBundle\nKiedy mamy już działającą obsługę użytkowników, warto było by dać im ciekawą\nfunkcjonalność. Żeby zachować balans między rozbudowaną aplikacją, a dobrym\nprzykładem postawimy następujące wymagania przed logiką biznesową aplikacji:\n\n * Użytkownik może dodać dowolną liczbę miejsc do swojego konta\n * Miejsca wybiera się wpisując je w formulażu lub używając geolokalizacji\n * Dane miejsce może zostać odłączone od konta, ale nie zniknie z bazy\n * Do danego miejsca może być przypisanych dowolnie wielu użytkowników\n * Zarządanie miejscami (dodawanie, usównie, lokalizowanie) nie przeładowuje\n   strony\n\nBaza danych (Model)\nZaczniemy od przygotowania bazy. Chcemy dodać w niej tablelę z miejscami oraz\nutowrzyć relację wiele do wielu między nią a tabelą users. Tworzymy plik \nsrc/AppBundle/Entity/Place.php w którym definiujemy klasę odpowiadającą za\nreprezentowanie miejsc. Standardowo zaczynamy od własności\n\n<?php\n\nnamespace AppBundle\\Entity;\n\nuse Doctrine\\ORM\\Mapping as ORM;\nuse Doctrine\\Common\\Collections\\ArrayCollection;\n\n/**\n * @ORM\\Entity\n * @ORM\\Table(name=\"places\")\n */\nclass Place\n{\n    /**\n     * @ORM\\Id\n     * @ORM\\Column(type=\"integer\")\n     * @ORM\\GeneratedValue(strategy=\"AUTO\")\n     */\n    protected $id;\n\n    /**\n     * @ORM\\Column(name=\"google_id\", type=\"string\", nullable=true)\n     */\n    private $googleId;\n\n    /**\n    * @ORM\\ManyToMany(targetEntity=\"User\", inversedBy=\"places\")\n    * @ORM\\JoinTable(name=\"users_places\")\n    */\n    private $users;\n\n    /** @ORM\\Column(name=\"formatted_address\", type=\"string\", nullable=true)  */\n    protected $formattedAddress;\n\n    /** @ORM\\Column(name=\"lon\", type=\"float\", precision=9, nullable=true)  */\n    protected $lon;\n\n    /** @ORM\\Column(name=\"lat\", type=\"float\", precision=9, nullable=true)  */\n    protected $lat;\n\n    /** @ORM\\Column(name=\"add_at\",type=\"datetime\") */\n    protected $add_at;\n\n    /** @ORM\\Column(name=\"street_number\",type=\"string\", nullable=true) */\n    protected $streetNumber;\n\n    /** @ORM\\Column(name=\"route\",type=\"string\", nullable=true) */\n    protected $route;\n\n    /** @ORM\\Column(name=\"sublocalityLevel1\",type=\"string\", nullable=true) */\n    protected $sublocalityLevel1;\n\n    /** @ORM\\Column(name=\"locality\",type=\"string\", nullable=true) */\n    protected $locality;\n\n    /** @ORM\\Column(name=\"administrative_area_level_2\",type=\"string\", nullable=true) */\n    protected $administrativeAreaLevel2;\n\n    /** @ORM\\Column(name=\"administrative_area_level_1\",type=\"string\", nullable=true) */\n    protected $administrativeAreaLevel1;\n\n    /** @ORM\\Column(name=\"country\",type=\"string\", nullable=true) */\n    protected $country;\n\n\nPoza standardowymi własnościami dotyczącymy lokalizacji mamy tu własność $users.\nW bazie danych będzie odpowiadała ona występowaniu tabeli users_places z\nidentyfikatorami użytkownika i miejsca. Wymagać to będzie jeszcze paru zmian w\nklasie User, ale o tym później. Teraz przejrzymy metody klasy Place.\n\n    public function __construct() {\n        $this->users = new ArrayCollection();\n        $this->setAddAt(new \\DateTime(\"now\"));\n    }\n\n\nKonstruktor ustawia datę dodania miejsca oraz zmienną $users jako \nArrayCollection. Jest to obiekt podobny do zwykłej tablicy, ale ma kilka metod\nwygodnych dla stosowania go jako zbiór obiektów. Mamy też geter i setter dla \n$googleId:\n\n    /**\n     * @return mixed\n     */\n    public function getGoogleId()\n    {\n        return $this->googleId;\n    }\n\n    /**\n     * @param mixed $googleId\n     */\n    public function setGoogleId($googleId)\n    {\n        $this->googleId = $googleId;\n    }\n\n\nDo operowani na zmiennej $users mamy trzy metody.\n\n    /**\n     * @return mixed\n     */\n    public function getUsers()\n    {\n        return $this->users;\n    }\n\n    /**\n     * @param mixed $user\n     */\n    public function addUsers(User $user)\n    {\n        if (!$this->users->contains($user))\n        {\n            $this->users->add($user);\n        }\n    }\n\n    public function removeUser(User $user)\n    {\n        $this->users->removeElement($user);\n    }\n\n\nWidać jak korzystamy tu z zalet ArrayCollection, gdyby $users było zwykłą\ntablicą, te operacje wyglądały by nieco mniej zgrabnie.\n\nKolejnymi metodami są pary getterów i setterów dla adresu: $formattedAddress,\nwspółrzędnych $lon, $lat i czasu dodania adresu do bazy $addAt:\n\n    /**\n     * @return mixed\n     */\n    public function getFormattedAddress()\n    {\n        return $this->formattedAddress;\n    }\n\n    /**\n     * @param mixed $formattedAddress\n     */\n    public function setFormattedAddress($formattedAddress)\n    {\n        $this->formattedAddress = $formattedAddress;\n    }\n\n    /**\n     * @return mixed\n     */\n    public function getLon()\n    {\n        return $this->lon;\n    }\n\n    /**\n     * @param mixed $lon\n     */\n    public function setLon($lon)\n    {\n        $this->lon = $lon;\n    }\n\n    /**\n     * @return mixed\n     */\n    public function getLat()\n    {\n        return $this->lat;\n    }\n\n    /**\n     * @param mixed $lat\n     */\n    public function setLat($lat)\n    {\n        $this->lat = $lat;\n    }\n\n    /**\n     * @return mixed\n     */\n    public function getAddAt()\n    {\n        return $this->add_at;\n    }\n\n    /**\n     * @param mixed $add_at\n     */\n    public function setAddAt($add_at)\n    {\n        $this->add_at = $add_at;\n    }\n\n\nDla pozostałych parametrów nie będziemy stosować już pary getter, setter. Z\npowodu ich ustrukturyzowanego występowania w api google maps, z którego będziemy\nkorzystać ustawimy jeden setter dla nich wszystkich. Gettery nie będą nam\npotrzebne więc metody do obsługi pozostałych parametów wyglądają następująco:\n\n    public function getParams()\n    {\n        return [\n            \"country\",\n            \"administrative_area_level_1\",\n            \"administrative_area_level_2\",\n            \"locality\",\n            \"sublocality_level_1\",\n            \"route\",\n            \"street_number\"\n        ];\n    }\n\n    public function setParam($name,$value)\n    {\n        if(in_array($name,$this->getParams())){\n            $name = lcfirst(str_replace(' ', '', ucwords(str_replace('_', ' ', $name))));//camelcase\n            $this->$name  = $value;\n        }\n    }\n\n\nPierwsza z nich zwraca listę nazw obsługiwanych przez drugą metodę, te nazwy\nmożna jako string podstawić jako $name. Funkcja zaczynająca się od lcfirst \nodpowiada za zmianę notacji z a_b na aB, czyli usówa podkreślenia i zmienia małe\nlitery po podkreśleniach na duże.\n\nZostała nam jeszcze jedna metoda - do rzutowania obiektu na string.\n\n    public function __toString()\n    {\n        return json_encode([\"id\"=>$this->getGoogleId(),\"address\"=>$this->getFormattedAddress()],JSON_UNESCAPED_UNICODE);\n    }\n}\n\n\nŻeby tabela łącząca została poprawnie dodana wprowadzimy teraz zmiany w klasie \nUser i dodamy do pliku src/AppBundle/Entity/User.php linie:\n\nuse Doctrine\\Common\\Collections\\ArrayCollection;\n\n(...)\n\n    /**\n     * @ORM\\ManyToMany(targetEntity=\"Place\", mappedBy=\"users\", cascade={\"persist\"})\n     */\n    private $places;\n\n    /**\n     * @return mixed\n     */\n    public function getPlaces()\n    {\n        return $this->places->toArray();\n    }\n\n\n    public function removePlace(Place $place)\n    {\n        $this->places->remove($place);\n    }\n\n    /**\n     * @param mixed $place\n     */\n    public function addPlace(Place $place)\n    {\n        if (!$this->places->contains($place))\n        {\n            $this->places->add($place);\n        }\n    }\n\n    public function __construct()\n    {\n        parent::__construct();\n        $this->places = new ArrayCollection();\n    }\n\n\n\nMożemy teraz zregenerować bazę danych komendą:\n\nphp bin/console doctrine:schema:update --force\n\n\nNa koniec załączam wizualizację schematu bazy\n\n\n\nLogika serwera (Kontroler)\nMamy model. Teraz kontrolery. Na końcu zrobimy widoki. W defaultowym kontrolerze\n(src/AppBundle/Controller/DefaultController) ustawimy przekierowanie\nzalogowanych użytkowników do ścieżki z miejscami:\n\n    /**\n     * @Route(\"/\", name=\"homepage\")\n     */\n    public function indexAction(Request $request)\n    {\n        if($this->getUser()){\n            return $this->redirectToRoute('places');\n        }\n        return $this->render('default/index.html.twig', []);\n    }\n\n\nTo wszystko jeśli chodzi o defaultową logikę.\nW kontrolerze src/AppBundle/Controller/PlacesController będzie znacznie więcej\nlogiki. Oto metoda\ndo wyświetlania ścieżki places, do której chcemy przekierowywać logowanych\nużytkowników.\n\n<?php\nnamespace AppBundle\\Controller;\n\nuse Symfony\\Bundle\\FrameworkBundle\\Controller\\Controller;\nuse Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route;\nuse Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Method;\nuse Symfony\\Component\\HttpFoundation\\Request;\nuse Symfony\\Component\\HttpFoundation\\Response;\nuse AppBundle\\Entity\\Place;\nuse AppBundle\\Form\\PlaceType;\nuse Symfony\\Component\\HttpFoundation\\JsonResponse;\n\nClass PlacesController extends Controller\n{\n    /**\n     * @Route(\"/profile/places\", name=\"places\")\n     * @Method(\"GET\")\n     * @return Response\n     */\n    public function editPlacesAction()\n    {\n        if(!$this->getUser()){\n            return $this->redirectToRoute('fos_user_security_login');\n        }\n\n        $place = new Place();\n        $places = $this->getUser()->getPlaces();\n        $form = $this->createForm(PlaceType::class, $place);\n\n        return $this->render(':places:places.html.twig', array(\n            'places' => $places,\n            'form' => $form->createView(),\n        ));\n    }\n\n\nZanim przejdziemy dalej zwrócę uwagę na dwie rzeczy - pierwsza to brak obsługi\nformularza i przyjmowania requestów. Tworzymy tutaj formularz, wysyłamy go do\nTwiga, ale nie będziemy go odbierać tutaj. Jego obsługą zajmie się JavaScript.\nDruga rzecz to sama klasa PlaceType została ona tutaj zastosowana, chociaż\njeszcze je nie defniowaliśmy. Zrobię małą dygresję i pokażę kod tej klasy. Jest\non umieszczony w pliku src/AppBundle/Form/PlaceType.php\n\n<?php\n\nnamespace AppBundle\\Form;\n\nuse Symfony\\Component\\Form\\AbstractType;\nuse Symfony\\Component\\Form\\FormBuilderInterface;\nuse Symfony\\Component\\Form\\Extension\\Core\\Type\\TextType;\nuse Symfony\\Component\\Form\\FormTypeInterface;\nuse Symfony\\Component\\OptionsResolver\\OptionsResolver;\n\nclass PlaceType extends AbstractType implements FormTypeInterface\n{\n    public function buildForm(FormBuilderInterface $builder, array $options)\n    {\n        $builder->add('formatted_address', TextType::class, array('label' => false));\n    }\n\n    public function configureOptions(OptionsResolver $resolver)\n    {\n        $resolver->setDefaults(array(\n            'data_class' => 'AppBundle\\Entity\\Place',\n        ));\n    }\n}\n\n\nZ php na nasze: ta klasa odpowada z to, że formularz, który reprezentuje ma\njedno pole. Wracamy teraz do kontrolera src/AppBundle/Form/PlaceType.php.\nKolejna metoda będzie odpowiadała za zapisywanie miejsca do bazy danych\n\n    /**\n     * @Route(\"/profile/ajax_geo_save\", name=\"ajax_geo_save\")\n     * @Route(\"/profile/ajax_geo_save/{debug}\")\n     * @Method(\"POST\")\n     */\n    public function ajaxGeoSave(Request $request, $debug=null)\n    {\n        $content = $request->getContent();\n        $params = json_decode($content, true);\n\n        $formattedAddress = $params['formatted_address'];\n        $address = $this->getAddress($formattedAddress);\n\n        if($debug==\"debug\") { return new JsonResponse($address); }\n\n        $place = $this->getPlace($address);\n\n        // these lines persist user relation with place, not only place\n        $em = $this->getDoctrine()->getManager();\n        $em->persist($place);\n        $em->flush();\n\n        return new JsonResponse($address, 201);\n    }\n\n\nMożna ją wywołać z parametrem debug w ścieżce, ale nie trzeba. Działanie metody\njest następujące: pobiera ona zawartość requestu do zmiennej $content, do\nzmiennej $params zapisuje tablicę odpowiadającą treści requestu, do zmiennej \n$formattedAddress zapisujemy wartość odpowiadającą kluczowi formatted_address.\nJest to dokładnie to co powinno zostać wysłane przez formularz definiowany klasą \nPlaceType prezentowaną przed chwilą.\n\nTeraz linia $address = $this->getAddress($formattedAddress); robi bardzo ważną\nrzecz. Wysyła request do API Google w celu przetłumaczenia tego co wpisał\nużytkownik na to co Google rozumie jako lokalizację, którą prawdopodobnie miał\nna myśli. Do metody getAddress jeszcze przejdziemy, ale teraz dokończę omawianie\nmetody ajaxGeoSave. Otrzymany adres jest tablicą. Jeśli metodę włączono z\nparametrem debug to zostaje on zwrócony jako JSON z kodem HTTP 200 i dalsza\nczęść metody nie jest wykonywana. W przeciwnym wypadku, czyli w sytuacji\nzwyczajnego użycia wywołujemy metodę getPlace, która transformuje nam tablicę \n$address do obiektu $place. Trzy kolejne linie to zapis do bazy. Na końcu\nzwracamy $address jak z metodzie z parametrem debug, ale ponieważ wykonaliśmy\npoprawny zapis do bazy, zmieniamy kod HTTP na 201.\n\nMamy tu więc dwie ważne transformacje danych - z tego co wpisał użytkownik na\ntablicę z danymi adresowymi od Google, oraz z tablicy na naszą strukturę danych\n- klasę Place.\n\nMoże jednak tak się zdarzyć, że użytkownikowi nie che się pisać swojego adresu,\nalbo zgubił się i nie wie gdzie jest. W takim wypadku możemy wykorzystać metodę \ngeolocation obiektu navigator dostępnego w javascript. Zwraca ona współrzędne\ngeograficzne. Chcieli byśmy tłumaczyć je na adres czytelny dla człowieka. Do\ntego posłuży druga metoda kontrolera:\n\n    /**\n     * @Route(\"/profile/ajax_geo_location\", name=\"ajax_geo_location\")\n     * @param Request $request\n     * @Method(\"GET\")\n     * @return JsonResponse\n     */\n    public function ajaxGeoLocation(Request $request)\n    {\n        $lon = $request->get('lon');\n        $lat = $request->get('lat');\n\n        $address = $this->getAddress([$lat,$lon]);// get address from coords\n\n        return new JsonResponse($address);\n    }\n\n\nJej struktura jest bardzo przejrzysta. Pobieramy dane z requesta, wykonujemy\ntransformację metodą getAddress, zwracamy tablicę z adresem. Należy zauważyć, że\ntym razem getAddress przyjmuję tablicę a nie string. Mimo to działa poprawnie,\nponieważ w zależności od tego co dostała metoda getAddress wykonuje nieco inną\nlogikę dostosowaną zarówno do tekstowych adresów jak i par współrzędnych.\n\nKolejna metoda wiąże się ze smutnym eventem jakim jest usunięcie adresu przez\nużytkownika.\n\n    /**\n     * @Route(\"/profile/ajax_geo_delete/{googleId}\", name=\"ajax_geo_delete\")\n     * @Method(\"DELETE\")\n     * @param googleId\n     * @return JsonResponse\n     */\n    public function ajaxGeoDelete($googleId)\n    {\n        $place = $this->getDoctrine()->getRepository(\"AppBundle:Place\")->findOneBy(array(\n            'googleId' => $googleId\n        ));\n\n        if(!$place) { return new JsonResponse([\"error\"=>\"Place Not Found\"],404); }\n\n        $address = $this->getAddress($place->getFormattedAddress());\n\n        $place->removeUser($this->getUser());\n        $em = $this->getDoctrine()->getManager();\n        $em->persist($place);\n        $em->flush();\n\n        return new JsonResponse($address,204);\n    }\n\n\nAdres jest wyszukiwany po googleId. Jeśli nie zostanie znaleziony odsyłamy błąd \n404, jeśli zostanie, to usunięte zostaje jedynie łącznie między użytkownikiem a\nmiejscem, natomiast miejsce cały zostaje w bazie nawet jeśli nie będzie już\npołączone z żadnym użytkownikiem.\n\nNajwyższy czas na zaprezentowanie pierwszego z transformatorów danych - metody \ngetAddress\n\n    /**\n     * @param $data\n     * @return array\n     * @throws \\Exception\n     */\n    public function getAddress($data)\n    {\n        if(is_string($data)){\n            $address = str_replace(\" \", \"+\", $data); // replace all the white space with \"+\" sign to match with google search pattern\n            $url = \"http://maps.google.com/maps/api/geocode/json?sensor=false&address=$address\";\n        } elseif (is_array($data) && count($data)) {\n            $url = \"http://maps.googleapis.com/maps/api/geocode/json?latlng=$data[0],$data[1]&sensor=false\";\n        } else {\n            throw new \\Exception(\"Incorrect args, put string or array with lat and lon\");\n        }\n\n        $response = file_get_contents($url);\n        $json = json_decode($response, TRUE); //generate array object from the response from the web\n        return $json['results'][0];\n    }\n\n\nTa metoda sprawdza czy dostała współrzędne czy tekstowy adres i w zależności od\ntego przygotowuje trochę inny $url. Następnie za pomocą najprostszego requestu \nfile_get_contents odbiera to co odpowie Google, wycina to co nie potrzebne i\nodsyła dalej.\n\nMyślę, że to dobry moment, żeby pokazać do dokładnie jest odsyłane. Wykonamy\nrequest do ajax_geo_save z parametrem debug, żeby zobaczyć jak wygląda json na\nwyjściu tej metody.\n\n\n\n\nWidać, że formatted_address, place_id oraz współrzędne mają tu dobrze określone\nmiejsce, ale pozostałe własności adresu zostały spakowane do jednej tablicy \naddress_components i są tagowane za pomocą typów, które mogą występować po\nkilka, ale niektórych może też wcale nie być. Do przetwarzania tej tablicy do\npostaci zgodnej z naszym modelem danych służy ostatnia metoda, którą\nzaprezentuję: getPlace\n\n    /**\n     * @param array $address\n     * @return mixed\n     */\n    public function getPlace($address)\n    {\n        $place = $this->getDoctrine()->getRepository(\"AppBundle:Place\")->findOneBy(array(\n            'googleId' => $address['place_id']\n        ));\n                if($place === null)\n        {\n            $place = new Place();\n\n            $place->setGoogleId($address['place_id']);\n            $place->setLat($address['geometry']['location']['lat']);\n            $place->setLon($address['geometry']['location']['lng']);\n            $place->setFormattedAddress($address['formatted_address']);\n\n\nNa początku sprawdzamy czy dany adres już znajduje się w naszej bazie. Jeśli\ntak, to możemy pominąć całe transformowanie, dodamy do niego aktualnego\nużytkownika i wystarczy. Załóżmy jednak, że to nowy adres. W takim przypadku\npowinniśmy w pierwszej kolejności ustawić mu google_id, współrzędne, oraz jego\nsformatowaną postać. Następnie zajmiemy się otagowanymi składowymi adresu.\n\n            $params = $place->getParams();\n\n            foreach($address[\"address_components\"] as $component){\n                foreach($params as $paramId => $param){\n                    if(in_array($param,$component[\"types\"])){\n                        $place->setParam($param,$component[\"long_name\"]);\n                        unset($params[$paramId]);\n                    }\n                }\n            }\n        }\n\n\nBędziemy je wyciągać w podwójnej pętli. Po komponentach adresu oraz po\nparametrach jakich szukamy. Jeśli jakiś parametr zostanie znaleziony, zapiszemy\nwłaściwość i usuniemy go z tablicy parametrów, tak, żeby nie nabijał pustych\npętli.\n\n        $place->addUsers($this->getUser());\n\n        return $place;\n    }\n}\n\n\nNa koniec niezależnie od tego, czy tworzyliśmy nowe miejsce, czy też wzięliśmy\nje z bazy, dołączamy do miejsca obecnego użytkownika. Jeśli zastanawia cię\ndlaczego nie sprawdzam czy ten użytkownik jest już dodany, to odpowiedź jest\nprosta. Sprawdzam, ale na poziomie metody dostępnej w ArrayCollection w encji a\nnie kontrolerze.\n\nWidoki\nBardzo dużą część widoków już przerobiliśmy. Zostały nam jeszcze dwa. Pierwszy z\nnich to strona główna dla niezalogowanych użytkowników. Strona po prostu\ninformuje do czego jest aplikacja. Widok znajduje się w pliku \napp/Resources/views/default/index.html.twig, ma kod\n\n{% extends 'base.html.twig' %}\n\n{% block body %}\n    {{ parent() }}\n\n\n    <div class=\"container eternity-form\">\n        <div class=\"section-title reg-header\">\n            <h3>Places</h3>\n            <p>App to collect your addresses</p>\n\n        </div>\n    </div>\n{% endblock %}\n\n\ni wygląda tak:\n\n\n\nCiekawszym widokiem jest widok miejsc. Umieściliśmy go w pliku \napp/Resources/views/places/places.html.twig\n\nJego kod html jest dość prosty:\n\n{% extends 'base.html.twig' %}\n\n{% block body %}\n    {{ parent() }}\n\n    <div class=\"container eternity-form\">\n        <div class=\"section-title reg-header\">\n            <h3>Update your address</h3>\n\n            <br>\n            <p id=\"info\"></p>\n\n            <div class=\"list\">\n            {% for place in places %}\n                <div data-id=\"{{ place.googleId }}\" class=\"btn-group place-elem\" role=\"group\">\n                    <button type=\"button\" class=\"place-name btn btn-default\">{{ place.formattedAddress }}</button>\n                    <button type=\"button\" class=\"place-delete btn btn-danger delete\">Delete</button>\n                </div>\n            {% endfor %}\n            </div>\n\n            <div class=\"input-group\">\n                <input name=\"formatted_address\" type=\"text\" class=\"form-control\" placeholder=\"Type your location...\">\n                <span class=\"input-group-btn place-padding-bottom\">\n                    <button id=\"my_location\" class=\"btn btn-info\">Check my location</button>\n                    <button id=\"save_location\" class=\"btn btn-default\">Save location</button>\n                </span>\n            </div>\n        </div>\n    </div>\n{% endblock %}\n\n\nWarto zwrócić uwagę na to jak sprawnie będą uzupełniały się tutaj metody\nzarządzania widokiem po stronie serwera (pętla w twigu) oraz po stronie klienta.\nOd momentu wygenerowania początkowego widoku wszystkie zmiany robi już \njavascript.\n\nWidok wyposażony jest w swój styl, który zaciąga rozszerzając blok stylesheets\n\n{% block stylesheets %}\n    {{ parent() }}\n    <link href=\"{{ asset('bundles/app/css/place.css') }}\" rel=\"stylesheet\" />\n{% endblock %}\n\n\nStyl znajduje się w pliku src/AppBundle/Resources/public/css/place.css i ma\ntylko 4 reguł:\n\n.place-name {\n    width: 74%;\n}\n\n.place-delete {\n    width: 26%;\n}\n\n.place-padding-bottom{\n    padding-bottom: 30px;\n}\n\n.place-elem {\n    padding-bottom: 5px;\n    width: 100%;\n}\n\n\nJeśli piszę w css to zwykle ograniczam się do takiego właśnie minimalizmu. Co\ninnego z javascriptem. W widoku (app/Resources/views/places/places.html.twig)\njest go objętościowo więcej niż html. Spełnia on następujące zadania:\n\n{% block javascripts %}\n{{ parent() }}\n\n<script>\n    var places = [];\n    {% for place in places %}\n    places.push({{ place|raw }});\n    {% endfor %}\n\n\nPrzy ładowaniu strony zapisuje do JavaScriptowej zmiennej places tablicę z\ntekstowymi reprezentacjami obiektów Place przekazanych do twigowej zmiennej.\nBędą nam one potrzebne do unikania duplikacji treści. Dzięki temu rozwiązaniu\nmamy stan aplikacji w zmiennej oraz na ekranie jednocześnie.\n\nNastępnie robię to co zawsze robię rozpoczynając skrypt\n\n    var info = document.getElementById(\"info\");\n    var area = document.getElementsByClassName(\"section-title\")[0];\n    var list = document.getElementsByClassName(\"list\")[0];\n\n\nidentyfikuję potrzebne elementy za pomocą selektorów. Później robię to co zawsze\nrobię w skryptach po identyfikacji elementów.\n\n    area.addEventListener('click',function(e){\n       if(e.target.id=='my_location'){\n           getLocation();\n       } else if(e.target.id=='save_location') {\n           saveLocation();\n       } else if(e.target.classList.contains('delete')){\n           deleteLocation(e.target.parentNode.dataset.id);\n       }\n    });\n\n\nDodaję jeden (staram się zwykle dodawać tylko jeden) listener, w którym\nprzyporządkowują akcje wykrytym eventom. Mamy tu do wyboru trzy akcje:\nsprawdzenie lokacji za pomocą obiektu navigarot przeglądarki, zapisanie i\nusunięcie lokacji.\n\nZa obsługę navigatora odpowiada poniższy kod.\n\n    function getLocation() {\n        if (navigator.geolocation) {\n            navigator.geolocation.getCurrentPosition(showPosition);\n        } else {\n            info.innerHTML = \"Geolocation is not supported by this browser.\";\n        }\n    }\n\n\nJeśli użytkownik wyrazi zgodę na dostęp do jego lokalizacji, jest ona\nprzekazywana do funkcji showPosition.\n\n    function showPosition(position) {\n        $.ajax({\n            url: \"{{ path('ajax_geo_location') }}\",\n            method: \"GET\",\n            data: {\n                lat: position.coords.latitude,\n                lon: position.coords.longitude\n            },\n            success: function(msg){\n                $(\"#my_location\").html('Position obtained');\n                $(\"input[name=formatted_address]\").val(msg['formatted_address']);\n            }});\n    }\n\n\nTa funkcja z kolei wysyła odpowiedni request i wypełnia pole formularza\nsformatowanym adresem odpowiadającym współrzędnych przeglądarki.\n\nZapisanie lokacji - czyli wysłanie formularza realizowane jest przez kolejną\nfunkcję:\n\n    function saveLocation(){\n        $.post('{{ path('ajax_geo_save') }}',\n                JSON.stringify({formatted_address: $(\"input[name=formatted_address]\").val()})\n        ).done(function(res){\n\n        if(places.filter(function(obj) {return obj.id == res.place_id}).length){\n            return;\n        }\n\n        places.push({'id':res.place_id,'addess':res.formatted_address});\n        list.innerHTML += '<div data-id=\"'+res.place_id+'\" class=\"btn-group place-elem\" role=\"group\">\\\n            <button type=\"button\" class=\"place-name btn btn-default\">'+res.formatted_address+'</button>\\\n            <button type=\"button\" class=\"place-delete btn btn-danger delete\">Delete</button>\\\n            </div>';\n        });\n    }\n\n\nJej działanie zaczyna się od wysłania requestu POST z treścią formularza. Jeśli\notrzymamy odpowiedź, sprawdzamy czy miejsce jest już przypisane do użytkownika\nfiltrując tablicę places. Jeśli tak, nic więcej nie robimy. Jeśli nie było, to\ndodajemy je do tablicy places i do listy miejsc dołączamy lokację za pomocą\nskładni .innerHTML +=. Są do tego metody polegające na traktowaniu htmla jako\ndrzewa DOM, ale są one efektywne jeśli są stosowane w szerszym kontekście. W tym\nprzypadku metoda doklejenia treści mimo, że mniej elegancka została wybrana ze\nwzględu na większą prostotę.\n\nOstatnia metoda odpowiada za usunięcie miejsca z listy miejsc użytkownika.\n\n    function deleteLocation(googleId){\n        var route = \"{{ path('ajax_geo_delete',{'googleId':'PLACEHOLDER'}) }}\";\n        $.ajax({\n            url: route.replace(\"PLACEHOLDER\",googleId),\n            method: \"DELETE\"\n        });\n        places = places.filter(function( obj ) {\n            return obj.id !== googleId;\n        });\n        list.querySelector(\"[data-id='\"+googleId+\"']\").outerHTML='';\n    }\n</script>\n{% endblock %}\n\n\nTutaj odwrotnie niż przy zapisywaniu, usuwamy element z tablicy places i\nczyścimy HTML odpowiadający miejscu, które usuwamy. Na koniec dodajemy screen z\nprzykładowego użytkowania:\n\n\n\nTo cały kod źródłowy. Nie ma tutaj testów, nie ma DoctrineFixturesBundle, nie ma\npanelu admina, nie ma gulpa.\nPrzede wszystkim jednak nie ma miejsca. Z tego względu wszystkie wspomniane\nrzeczy zostały wycięte.\nTen wpis i tak jest chyba najdłuższym jaki napisałem. Jego celem nie było\nprzedstawianie kompleksowej aplikacji\ntylko przykładu zastosowania FOSUserBundle.\n\nMam nadzieję, że komuś pomoże to przy wdrażaniu tej znakomitej paczki w swoim\nprojekcie. Jak zwykle czekam na waszą krytykę,\npytania oraz wskazówki, co mogę poprawić.",
            "feature_image": "__GHOST_URL__/content/images/2021/06/symfony.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:36:11.000Z",
            "updated_at": "2021-06-22T09:23:37.000Z",
            "published_at": "2021-05-18T20:50:00.000Z",
            "custom_excerpt": "Prosta apka integrująca fos user bundle z google maps. Serwis pozwala na logowanie, rejestrację oraz zapisywanie swojej listy lokalizacji walidowanych przez api od google. ",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f3ced2fb35425592d0be9",
            "uuid": "97acc070-e4cd-4a01-988c-9501dd4c0e6b",
            "title": "Snake game in JavaScript (part 1 - objects)",
            "slug": "snake-game-in-javascript-part-1-objects",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## About project\\n\\nThis tutorial shows how to write Snake Game in \\nJavaScript. It require basic knowledge about objects\\nand methods of arrays. In first part we are going to\\nbe able to display map, snake and allow snake to move\\nin chosen direction. This code will be not playable\\nversion of game, but I decided to depart this project\\nto fragments because of highest educational value of\\npresenting process of building code, not only final\\nresult.\\n\\nIf you are interested in final result you can\\ndownload it from \\n[github](https://github.com/gustawdaniel/snake_js/releases/tag/v0.1).\\n\\nIf you want to write code line by line together lets \\nstart typing following these chapters.\\n\\n## Map.\\n\\nIn this section we will se how to generate map for \\nsnake.\\n\\n### Server setup\\n\\n> Commits\\n> 23d7da5a511855efd8e01da219af045d037dba93..26816daa5de0bd3c5203ca61d3b616ac003cfe39\\n\\nWe starting from creating `index.html`. It can be \\nempty or filled by simple text. I started from this\\none:\\n\\n```html\\n<html>\\n<head>\\n    <title>Snake - game dedicated for Sylwia Daniecka - my girlfriend!</title>\\n</head>\\n<body>\\n    <h1>I love Sylwia <3</h1>\\n</body>\\n</html>\\n```\\n\\nTo serve this document I installed `http-server` using\\nyarn. I typed:\\n\\n    yarn init\\n\\nand press `Enter` such many times as needed. After \\nthis i used commad:\\n\\n    yarn add http-server\\n\\nThese command are responsible for shape of file\\n\\n> package.json\\n\\n```json\\n{\\n  \\\"name\\\": \\\"snake_js\\\",\\n  \\\"version\\\": \\\"1.0.0\\\",\\n  \\\"main\\\": \\\"index.js\\\",\\n  \\\"repository\\\": \\\"git@github.com:gustawdaniel/snake_js.git\\\",\\n  \\\"author\\\": \\\"Daniel Gustaw <gustaw.daniel@gmail.com>\\\",\\n  \\\"license\\\": \\\"MIT\\\",\\n  \\\"dependencies\\\": {\\n    \\\"http-server\\\": \\\"^0.11.1\\\"\\n  }\\n}\\n```\\n\\nFinally I write docs about starting project\\n\\n```markdown\\n# snake_js\\nSnake game written in javascript using objects. \\n\\n# Instaltion\\n\\nTo install dependencies\\n\\n    yarn install\\n\\nTo run\\n\\n    node node_modules/http-server/bin/http-server \\n```\\n\\n### Map generation\\n\\n> Commits\\n> 26816daa5de0bd3c5203ca61d3b616ac003cfe39..87dbf6d8162dde68ab137ddee78dcb975413d104\\n\\nWe will use `jquery` so we should type in console\\n\\n    yarn add jquery\\n\\nNow we place div with id `map` and append script and\\nstyle from external files in `index.html`\\n\\n> index.html\\n\\n```diff\\n <html>\\n <head>\\n     <title>Snake - game dedicated for Sylwia Daniecka - my girlfriend!</title>\\n+    <link rel=\\\"stylesheet\\\" href=\\\"css/style.css\\\">\\n </head>\\n <body>\\n     <h1>I love Sylwia <3</h1>\\n+    <hr>\\n+    <h4>TODO:</h4>\\n+    <ol>\\n+        <li style=\\\"text-decoration: line-through\\\">Add map</li>\\n+        <li>Add snake</li>\\n+        <li>Add events</li>\\n+    </ol>\\n+    <hr>\\n+    <main>\\n+        <div id=\\\"map\\\"></div>\\n+    </main>\\n+    <script src=\\\"node_modules/jquery/dist/jquery.min.js\\\"></script>\\n+    <script src=\\\"js/app.js\\\"></script>\\n </body>\\n </html>\\n```\\n\\nWe are interested creating script that iterate over \\nsize of map and place for example 10 rows with\\n10 rectangles in each. This script will be placed\\nin anonymous function in `js/app.js`\\n\\n> js/app.js\\n\\n```js\\n(function () {\\n\\n    const config = {\\n        mapWidth: 10,\\n        mapHeight: 10\\n    };\\n\\n    let map = {\\n        width: config.mapWidth,\\n        height: config.mapHeight,\\n        init: function () {\\n            let mapDiv = $('#map');\\n            for(let i=0; i<this.height; i++) {\\n                console.log(i);\\n                let rowDiv =$('<div>', {class: \\\"row\\\"});\\n                console.log(rowDiv);\\n                for(let j=0; j<this.width; j++) {\\n                    rowDiv.append($('<div>',{class:\\\"rect\\\", \\\"data-x\\\":i, \\\"data-y\\\":j}));\\n                }\\n                mapDiv.append(rowDiv);\\n            }\\n        }\\n    };\\n\\n    map.init();\\n\\n    \\n})();\\n```\\n\\nThis script create divs with class `rect` and place\\nit into divs with class `row` that are placed into\\nexisting dive with id `map`.\\n\\nThese all divs have zero height so we should define\\nstyle for him.\\n\\n> css/style.css\\n\\n```css\\n.rect {\\n    width: 30px;\\n    height: 30px;\\n    background-color: #dca6d1;\\n    display: inline-block;\\n    margin: 2px;\\n}\\n```\\n\\nMap should look like this:\\n\\n[![Zrzut_ekranu_z_2018-02-21_11-05-20.png](https://s17.postimg.org/wilseqtgv/Zrzut_ekranu_z_2018-02-21_11-05-20.png)](https://postimg.org/image/ajfdrjcmj/)\\n\\n## Snake\\n\\n> Commit\\n> d50265a3a5adca92bfe7d5139c0e519e72d853dc..87dbf6d8162dde68ab137ddee78dcb975413d104\\n\\nTo add snake we should chose his color. In constant `config` responsible for\\nglobal configuration we describing color of snake.\\n\\n> js/app.js\\n\\n```diff\\n@@ -2,7 +2,8 @@\\n \\n     const config = {\\n         mapWidth: 10,\\n         mapHeight: 10,\\n+        snakeColor: \\\"#8165f3\\\"\\n     };\\n \\n     let map = {\\n```\\n\\nNow se want to create object of snake. We have to define his initial shape,\\niterate over his all parts (coordinates) and change background-color of\\ndives with this coordinates. Fortunately we added to divs with class `rect`\\nattributes `data-x` and `data-y` that will help in searching proper elements.\\n\\n> js/app.js\\n\\n```diff\\n@@ -22,7 +23,17 @@\\n         }\\n     };\\n \\n+    let snake = {\\n+        body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\\n+        draw: function() {\\n+            this.body.forEach(function (part) {\\n+                $(`div.rect[data-x=\\\"${part.x}\\\"][data-y=\\\"${part.y}\\\"]`).css('background-color',config.snakeColor);\\n+            })\\n+        }\\n+    };\\n+\\n     map.init();\\n+    snake.draw();\\n \\n     \\n })();\\n```\\n\\nFinally we can proudly check these changes in todo list in index.html adding\\nto text-decoration property `line-through`\\n\\n> index.html\\n\\n```diff\\n@@ -9,7 +9,7 @@\\n     <h4>TODO:</h4>\\n     <ol>\\n         <li style=\\\"text-decoration: line-through\\\">Add map</li>\\n-        <li>Add snake</li>\\n+        <li style=\\\"text-decoration: line-through\\\">Add snake</li>\\n         <li>Add events</li>\\n     </ol>\\n     <hr>\\n```\\n\\nOur ma should look like this\\n\\n[![Zrzut_ekranu_z_2018-02-21_11-16-02.png](https://s17.postimg.org/4708hnju7/Zrzut_ekranu_z_2018-02-21_11-16-02.png)](https://postimg.org/image/wwn4eanu3/)\\n\\n## Move and events\\n\\n> Commit\\n> ae194969e7d2a555c9dc7ed2fb57c81b56775b62..d50265a3a5adca92bfe7d5139c0e519e72d853dc\\n\\nIt is time to add dynamics for our snake.\\n\\nWe start from adding counter to show how many turns have our game.\\n\\n> index.html\\n\\n```diff\\n     </ol>\\n     <hr>\\n+    <header>\\n+        <p class=\\\"counter\\\">0</p>\\n+    </header>\\n     <main>\\n         <div id=\\\"map\\\"></div>\\n     </main>\\n```\\n\\nAnd style for this element\\n\\n> css/style.css\\n\\n```diff\\n+.counter {\\n+    text-align: right;\\n+    border: 1px solid black;\\n+    padding: 7px;\\n+ }\\n```\\n\\nNow we come back to logic. Firstly we will need color of map, and \\ntime of one rund in our configuration. Second value is measured in\\nmilliseconds\\n\\n> js/app.js\\n\\n```diff\\n@@ -3,7 +3,9 @@\\n     const config = {\\n         mapWidth: 10,\\n         mapHeight: 10,\\n-        snakeColor: \\\"#8165f3\\\"\\n+        snakeColor: \\\"#8165f3\\\",\\n+        mapColor: \\\"#dca6d1\\\",\\n+        roundTime: 1000\\n     };\\n \\n     let map = {\\n```\\n\\nNext we want to add method move to snake object that remove his tail and \\nadd his head in chosen direction in relate to current head.\\n\\n> js/app.js\\n\\n```diff\\n@@ -25,15 +25,64 @@\\n \\n     let snake = {\\n         body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\\n         draw: function() {\\n             this.body.forEach(function (part) {\\n                 $(`div.rect[data-x=\\\"${part.x}\\\"][data-y=\\\"${part.y}\\\"]`).css\\n('background-color',config.snakeColor);\\n             })\\n+        },\\n+        move: function (direction) {\\n+            let head = Object.assign({}, this.body[0]);\\n```\\n\\nIn function move we assign new head to variable head cloning current head. Simple\\nequality would not copy variable but only create reference to the same cell of memory.\\n\\n> js/app.js\\n\\n```diff\\n+            switch (direction) {\\n+                case \\\"up\\\":\\n+                    head.x = head.x -1; break;\\n+                case \\\"down\\\":\\n+                    head.x = head.x + 1; break;\\n+                case \\\"left\\\":\\n+                    head.y = head.y - 1; break;\\n+                case \\\"right\\\":\\n+                    head.y = head.y + 1; break;\\n+            }\\n```\\n\\nNext in dependence of direction we change coordinates. It can be misleading\\nbut x means height and increasing in down direction.\\n\\n> js/app.js\\n\\n```diff\\n+            this.body.unshift(head);\\n+            $(`div.rect[data-x=\\\"${head.x}\\\"][data-y=\\\"${head.y}\\\"]`)\\n+                .css('background-color',config.snakeColor);\\n+            let mapCoordinates  = this.body.pop();\\n+            $(`div.rect[data-x=\\\"${mapCoordinates.x}\\\"][data-y=\\\"${mapCoordinates.y}\\\"]`)\\n+                .css('background-color',config.mapColor);\\n+\\n+        }\\n+    };\\n```\\n\\nFinally we append new head to body by `unshift`, add snake color to this field,\\nremove tail by `pop` function and add map color to this coordinate.\\n\\nNow we want to call move function in interval and allow user to change direction. \\nWe need new object - game.\\n\\n> js/app.js\\n\\n```diff\\n+    let game = {\\n+        counter: 0,\\n+        direction: 'right', // right, left, up, down\\n+        run: function () {\\n+            snake.move(this.direction);\\n+        },\\n```\\n\\nOur game should have property with current direction of snake and counter\\nwith number of turns. Function run of game contains now move of snake.\\n\\nWhen game will start we will call `init` method of game.\\n\\n```diff\\n+        init: function () {\\n+            map.init();\\n+            snake.draw();\\n+            setInterval(() => {\\n+                this.counter ++;\\n+                $('.counter').text(this.counter);\\n+                this.run();\\n+            },config.roundTime);\\n```\\n\\nInit of game means init of map, drawing snake and set interval that \\nincrease counter, update it on view, and call run method that move snake.\\n\\nIf snake would have the same direction all time, it could be end, but we\\nwant to allow user change direction of snake by pressing arrows on keyboard,\\nfor this purpose after defining time interval we defining event listener\\nfor `keypress` that will change direction of snake.\\n\\n> js/app.js\\n\\n```diff\\n+            document.addEventListener('keypress',(e) => {\\n+                console.log(e.key);\\n+                switch (e.key) {\\n+                    case \\\"ArrowUp\\\":\\n+                        this.direction = this.direction === \\\"down\\\" ? this.direction : \\\"up\\\"; break;\\n+                    case \\\"ArrowDown\\\":\\n+                        this.direction = this.direction === \\\"up\\\" ? this.direction : \\\"down\\\"; break;\\n+                    case \\\"ArrowLeft\\\":\\n+                        this.direction = this.direction === \\\"right\\\" ? this.direction : \\\"left\\\"; break;\\n+                    case \\\"ArrowRight\\\":\\n+                        this.direction = this.direction === \\\"left\\\" ? this.direction : \\\"right\\\"; break;\\n+                }\\n+            })\\n         }\\n     };\\n \\n-    map.init();\\n-    snake.drow();\\n+    game.init();\\n```\\n\\n[![Zrzut_ekranu_z_2018-02-21_11-20-20.png](https://s17.postimg.org/83dkdw4wf/Zrzut_ekranu_z_2018-02-21_11-20-20.png)](https://postimg.org/image/mmkpfay17/)\\n\\n## Summary\\n\\nWe can now move snake in map. It is can penetrate the walls and himself.\\nThere is no apples for eating, but as it was mentioned. It is not final product\\nbut first pre release that present rather educational than functional value.\\n\\nBelow I present plans about future releases.\\n\\n<h5>v0.1</h5>\\n <ol>\\n     <li style=\\\"text-decoration: line-through\\\">Add map</li>\\n     <li style=\\\"text-decoration: line-through\\\">Add snake</li>\\n     <li style=\\\"text-decoration: line-through\\\">Add events</li>\\n </ol>\\n<h5>v0.2</h5>\\n<ol>\\n    <li>Add apples</li>\\n    <li>Add boundaries</li>\\n    <li>Add scores</li>\\n</ol>\\n<h5>Future (proposed)</h5>\\n<ol>\\n    <li>Add bad apples</li>\\n    <li>Add two players</li>\\n    <li>Add network gaming</li>\\n</ol>\\n\\n\\nYou can propose your own features if you want and add them as comments or\\nissues in github repository. I hope you learned something valuable reading\\nthis tutorial.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"about-project\">About project</h2>\n<p>This tutorial shows how to write Snake Game in<br>\nJavaScript. It require basic knowledge about objects<br>\nand methods of arrays. In first part we are going to<br>\nbe able to display map, snake and allow snake to move<br>\nin chosen direction. This code will be not playable<br>\nversion of game, but I decided to depart this project<br>\nto fragments because of highest educational value of<br>\npresenting process of building code, not only final<br>\nresult.</p>\n<p>If you are interested in final result you can<br>\ndownload it from<br>\n<a href=\"https://github.com/gustawdaniel/snake_js/releases/tag/v0.1\">github</a>.</p>\n<p>If you want to write code line by line together lets<br>\nstart typing following these chapters.</p>\n<h2 id=\"map\">Map.</h2>\n<p>In this section we will se how to generate map for<br>\nsnake.</p>\n<h3 id=\"server-setup\">Server setup</h3>\n<blockquote>\n<p>Commits<br>\n23d7da5a511855efd8e01da219af045d037dba93..26816daa5de0bd3c5203ca61d3b616ac003cfe39</p>\n</blockquote>\n<p>We starting from creating <code>index.html</code>. It can be<br>\nempty or filled by simple text. I started from this<br>\none:</p>\n<pre><code class=\"language-html\">&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Snake - game dedicated for Sylwia Daniecka - my girlfriend!&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;I love Sylwia &lt;3&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>To serve this document I installed <code>http-server</code> using<br>\nyarn. I typed:</p>\n<pre><code>yarn init\n</code></pre>\n<p>and press <code>Enter</code> such many times as needed. After<br>\nthis i used commad:</p>\n<pre><code>yarn add http-server\n</code></pre>\n<p>These command are responsible for shape of file</p>\n<blockquote>\n<p>package.json</p>\n</blockquote>\n<pre><code class=\"language-json\">{\n  &quot;name&quot;: &quot;snake_js&quot;,\n  &quot;version&quot;: &quot;1.0.0&quot;,\n  &quot;main&quot;: &quot;index.js&quot;,\n  &quot;repository&quot;: &quot;git@github.com:gustawdaniel/snake_js.git&quot;,\n  &quot;author&quot;: &quot;Daniel Gustaw &lt;gustaw.daniel@gmail.com&gt;&quot;,\n  &quot;license&quot;: &quot;MIT&quot;,\n  &quot;dependencies&quot;: {\n    &quot;http-server&quot;: &quot;^0.11.1&quot;\n  }\n}\n</code></pre>\n<p>Finally I write docs about starting project</p>\n<pre><code class=\"language-markdown\"># snake_js\nSnake game written in javascript using objects. \n\n# Instaltion\n\nTo install dependencies\n\n    yarn install\n\nTo run\n\n    node node_modules/http-server/bin/http-server \n</code></pre>\n<h3 id=\"map-generation\">Map generation</h3>\n<blockquote>\n<p>Commits<br>\n26816daa5de0bd3c5203ca61d3b616ac003cfe39..87dbf6d8162dde68ab137ddee78dcb975413d104</p>\n</blockquote>\n<p>We will use <code>jquery</code> so we should type in console</p>\n<pre><code>yarn add jquery\n</code></pre>\n<p>Now we place div with id <code>map</code> and append script and<br>\nstyle from external files in <code>index.html</code></p>\n<blockquote>\n<p>index.html</p>\n</blockquote>\n<pre><code class=\"language-diff\"> &lt;html&gt;\n &lt;head&gt;\n     &lt;title&gt;Snake - game dedicated for Sylwia Daniecka - my girlfriend!&lt;/title&gt;\n+    &lt;link rel=&quot;stylesheet&quot; href=&quot;css/style.css&quot;&gt;\n &lt;/head&gt;\n &lt;body&gt;\n     &lt;h1&gt;I love Sylwia &lt;3&lt;/h1&gt;\n+    &lt;hr&gt;\n+    &lt;h4&gt;TODO:&lt;/h4&gt;\n+    &lt;ol&gt;\n+        &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add map&lt;/li&gt;\n+        &lt;li&gt;Add snake&lt;/li&gt;\n+        &lt;li&gt;Add events&lt;/li&gt;\n+    &lt;/ol&gt;\n+    &lt;hr&gt;\n+    &lt;main&gt;\n+        &lt;div id=&quot;map&quot;&gt;&lt;/div&gt;\n+    &lt;/main&gt;\n+    &lt;script src=&quot;node_modules/jquery/dist/jquery.min.js&quot;&gt;&lt;/script&gt;\n+    &lt;script src=&quot;js/app.js&quot;&gt;&lt;/script&gt;\n &lt;/body&gt;\n &lt;/html&gt;\n</code></pre>\n<p>We are interested creating script that iterate over<br>\nsize of map and place for example 10 rows with<br>\n10 rectangles in each. This script will be placed<br>\nin anonymous function in <code>js/app.js</code></p>\n<blockquote>\n<p>js/app.js</p>\n</blockquote>\n<pre><code class=\"language-js\">(function () {\n\n    const config = {\n        mapWidth: 10,\n        mapHeight: 10\n    };\n\n    let map = {\n        width: config.mapWidth,\n        height: config.mapHeight,\n        init: function () {\n            let mapDiv = $('#map');\n            for(let i=0; i&lt;this.height; i++) {\n                console.log(i);\n                let rowDiv =$('&lt;div&gt;', {class: &quot;row&quot;});\n                console.log(rowDiv);\n                for(let j=0; j&lt;this.width; j++) {\n                    rowDiv.append($('&lt;div&gt;',{class:&quot;rect&quot;, &quot;data-x&quot;:i, &quot;data-y&quot;:j}));\n                }\n                mapDiv.append(rowDiv);\n            }\n        }\n    };\n\n    map.init();\n\n    \n})();\n</code></pre>\n<p>This script create divs with class <code>rect</code> and place<br>\nit into divs with class <code>row</code> that are placed into<br>\nexisting dive with id <code>map</code>.</p>\n<p>These all divs have zero height so we should define<br>\nstyle for him.</p>\n<blockquote>\n<p>css/style.css</p>\n</blockquote>\n<pre><code class=\"language-css\">.rect {\n    width: 30px;\n    height: 30px;\n    background-color: #dca6d1;\n    display: inline-block;\n    margin: 2px;\n}\n</code></pre>\n<p>Map should look like this:</p>\n<p><a href=\"https://postimg.org/image/ajfdrjcmj/\"><img src=\"https://s17.postimg.org/wilseqtgv/Zrzut_ekranu_z_2018-02-21_11-05-20.png\" alt=\"Zrzut_ekranu_z_2018-02-21_11-05-20.png\" loading=\"lazy\"></a></p>\n<h2 id=\"snake\">Snake</h2>\n<blockquote>\n<p>Commit<br>\nd50265a3a5adca92bfe7d5139c0e519e72d853dc..87dbf6d8162dde68ab137ddee78dcb975413d104</p>\n</blockquote>\n<p>To add snake we should chose his color. In constant <code>config</code> responsible for<br>\nglobal configuration we describing color of snake.</p>\n<blockquote>\n<p>js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -2,7 +2,8 @@\n \n     const config = {\n         mapWidth: 10,\n         mapHeight: 10,\n+        snakeColor: &quot;#8165f3&quot;\n     };\n \n     let map = {\n</code></pre>\n<p>Now se want to create object of snake. We have to define his initial shape,<br>\niterate over his all parts (coordinates) and change background-color of<br>\ndives with this coordinates. Fortunately we added to divs with class <code>rect</code><br>\nattributes <code>data-x</code> and <code>data-y</code> that will help in searching proper elements.</p>\n<blockquote>\n<p>js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -22,7 +23,17 @@\n         }\n     };\n \n+    let snake = {\n+        body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\n+        draw: function() {\n+            this.body.forEach(function (part) {\n+                $(`div.rect[data-x=&quot;${part.x}&quot;][data-y=&quot;${part.y}&quot;]`).css('background-color',config.snakeColor);\n+            })\n+        }\n+    };\n+\n     map.init();\n+    snake.draw();\n \n     \n })();\n</code></pre>\n<p>Finally we can proudly check these changes in todo list in index.html adding<br>\nto text-decoration property <code>line-through</code></p>\n<blockquote>\n<p>index.html</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -9,7 +9,7 @@\n     &lt;h4&gt;TODO:&lt;/h4&gt;\n     &lt;ol&gt;\n         &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add map&lt;/li&gt;\n-        &lt;li&gt;Add snake&lt;/li&gt;\n+        &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add snake&lt;/li&gt;\n         &lt;li&gt;Add events&lt;/li&gt;\n     &lt;/ol&gt;\n     &lt;hr&gt;\n</code></pre>\n<p>Our ma should look like this</p>\n<p><a href=\"https://postimg.org/image/wwn4eanu3/\"><img src=\"https://s17.postimg.org/4708hnju7/Zrzut_ekranu_z_2018-02-21_11-16-02.png\" alt=\"Zrzut_ekranu_z_2018-02-21_11-16-02.png\" loading=\"lazy\"></a></p>\n<h2 id=\"move-and-events\">Move and events</h2>\n<blockquote>\n<p>Commit<br>\nae194969e7d2a555c9dc7ed2fb57c81b56775b62..d50265a3a5adca92bfe7d5139c0e519e72d853dc</p>\n</blockquote>\n<p>It is time to add dynamics for our snake.</p>\n<p>We start from adding counter to show how many turns have our game.</p>\n<blockquote>\n<p>index.html</p>\n</blockquote>\n<pre><code class=\"language-diff\">     &lt;/ol&gt;\n     &lt;hr&gt;\n+    &lt;header&gt;\n+        &lt;p class=&quot;counter&quot;&gt;0&lt;/p&gt;\n+    &lt;/header&gt;\n     &lt;main&gt;\n         &lt;div id=&quot;map&quot;&gt;&lt;/div&gt;\n     &lt;/main&gt;\n</code></pre>\n<p>And style for this element</p>\n<blockquote>\n<p>css/style.css</p>\n</blockquote>\n<pre><code class=\"language-diff\">+.counter {\n+    text-align: right;\n+    border: 1px solid black;\n+    padding: 7px;\n+ }\n</code></pre>\n<p>Now we come back to logic. Firstly we will need color of map, and<br>\ntime of one rund in our configuration. Second value is measured in<br>\nmilliseconds</p>\n<blockquote>\n<p>js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -3,7 +3,9 @@\n     const config = {\n         mapWidth: 10,\n         mapHeight: 10,\n-        snakeColor: &quot;#8165f3&quot;\n+        snakeColor: &quot;#8165f3&quot;,\n+        mapColor: &quot;#dca6d1&quot;,\n+        roundTime: 1000\n     };\n \n     let map = {\n</code></pre>\n<p>Next we want to add method move to snake object that remove his tail and<br>\nadd his head in chosen direction in relate to current head.</p>\n<blockquote>\n<p>js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -25,15 +25,64 @@\n \n     let snake = {\n         body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\n         draw: function() {\n             this.body.forEach(function (part) {\n                 $(`div.rect[data-x=&quot;${part.x}&quot;][data-y=&quot;${part.y}&quot;]`).css\n('background-color',config.snakeColor);\n             })\n+        },\n+        move: function (direction) {\n+            let head = Object.assign({}, this.body[0]);\n</code></pre>\n<p>In function move we assign new head to variable head cloning current head. Simple<br>\nequality would not copy variable but only create reference to the same cell of memory.</p>\n<blockquote>\n<p>js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">+            switch (direction) {\n+                case &quot;up&quot;:\n+                    head.x = head.x -1; break;\n+                case &quot;down&quot;:\n+                    head.x = head.x + 1; break;\n+                case &quot;left&quot;:\n+                    head.y = head.y - 1; break;\n+                case &quot;right&quot;:\n+                    head.y = head.y + 1; break;\n+            }\n</code></pre>\n<p>Next in dependence of direction we change coordinates. It can be misleading<br>\nbut x means height and increasing in down direction.</p>\n<blockquote>\n<p>js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">+            this.body.unshift(head);\n+            $(`div.rect[data-x=&quot;${head.x}&quot;][data-y=&quot;${head.y}&quot;]`)\n+                .css('background-color',config.snakeColor);\n+            let mapCoordinates  = this.body.pop();\n+            $(`div.rect[data-x=&quot;${mapCoordinates.x}&quot;][data-y=&quot;${mapCoordinates.y}&quot;]`)\n+                .css('background-color',config.mapColor);\n+\n+        }\n+    };\n</code></pre>\n<p>Finally we append new head to body by <code>unshift</code>, add snake color to this field,<br>\nremove tail by <code>pop</code> function and add map color to this coordinate.</p>\n<p>Now we want to call move function in interval and allow user to change direction.<br>\nWe need new object - game.</p>\n<blockquote>\n<p>js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">+    let game = {\n+        counter: 0,\n+        direction: 'right', // right, left, up, down\n+        run: function () {\n+            snake.move(this.direction);\n+        },\n</code></pre>\n<p>Our game should have property with current direction of snake and counter<br>\nwith number of turns. Function run of game contains now move of snake.</p>\n<p>When game will start we will call <code>init</code> method of game.</p>\n<pre><code class=\"language-diff\">+        init: function () {\n+            map.init();\n+            snake.draw();\n+            setInterval(() =&gt; {\n+                this.counter ++;\n+                $('.counter').text(this.counter);\n+                this.run();\n+            },config.roundTime);\n</code></pre>\n<p>Init of game means init of map, drawing snake and set interval that<br>\nincrease counter, update it on view, and call run method that move snake.</p>\n<p>If snake would have the same direction all time, it could be end, but we<br>\nwant to allow user change direction of snake by pressing arrows on keyboard,<br>\nfor this purpose after defining time interval we defining event listener<br>\nfor <code>keypress</code> that will change direction of snake.</p>\n<blockquote>\n<p>js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">+            document.addEventListener('keypress',(e) =&gt; {\n+                console.log(e.key);\n+                switch (e.key) {\n+                    case &quot;ArrowUp&quot;:\n+                        this.direction = this.direction === &quot;down&quot; ? this.direction : &quot;up&quot;; break;\n+                    case &quot;ArrowDown&quot;:\n+                        this.direction = this.direction === &quot;up&quot; ? this.direction : &quot;down&quot;; break;\n+                    case &quot;ArrowLeft&quot;:\n+                        this.direction = this.direction === &quot;right&quot; ? this.direction : &quot;left&quot;; break;\n+                    case &quot;ArrowRight&quot;:\n+                        this.direction = this.direction === &quot;left&quot; ? this.direction : &quot;right&quot;; break;\n+                }\n+            })\n         }\n     };\n \n-    map.init();\n-    snake.drow();\n+    game.init();\n</code></pre>\n<p><a href=\"https://postimg.org/image/mmkpfay17/\"><img src=\"https://s17.postimg.org/83dkdw4wf/Zrzut_ekranu_z_2018-02-21_11-20-20.png\" alt=\"Zrzut_ekranu_z_2018-02-21_11-20-20.png\" loading=\"lazy\"></a></p>\n<h2 id=\"summary\">Summary</h2>\n<p>We can now move snake in map. It is can penetrate the walls and himself.<br>\nThere is no apples for eating, but as it was mentioned. It is not final product<br>\nbut first pre release that present rather educational than functional value.</p>\n<p>Below I present plans about future releases.</p>\n<h5>v0.1</h5>\n <ol>\n     <li style=\"text-decoration: line-through\">Add map</li>\n     <li style=\"text-decoration: line-through\">Add snake</li>\n     <li style=\"text-decoration: line-through\">Add events</li>\n </ol>\n<h5>v0.2</h5>\n<ol>\n    <li>Add apples</li>\n    <li>Add boundaries</li>\n    <li>Add scores</li>\n</ol>\n<h5>Future (proposed)</h5>\n<ol>\n    <li>Add bad apples</li>\n    <li>Add two players</li>\n    <li>Add network gaming</li>\n</ol>\n<p>You can propose your own features if you want and add them as comments or<br>\nissues in github repository. I hope you learned something valuable reading<br>\nthis tutorial.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f3ced2fb35425592d0be9",
            "plaintext": "About project\nThis tutorial shows how to write Snake Game in\nJavaScript. It require basic knowledge about objects\nand methods of arrays. In first part we are going to\nbe able to display map, snake and allow snake to move\nin chosen direction. This code will be not playable\nversion of game, but I decided to depart this project\nto fragments because of highest educational value of\npresenting process of building code, not only final\nresult.\n\nIf you are interested in final result you can\ndownload it from\ngithub [https://github.com/gustawdaniel/snake_js/releases/tag/v0.1].\n\nIf you want to write code line by line together lets\nstart typing following these chapters.\n\nMap.\nIn this section we will se how to generate map for\nsnake.\n\nServer setup\n> Commits\n23d7da5a511855efd8e01da219af045d037dba93..26816daa5de0bd3c5203ca61d3b616ac003cfe39\n\n\nWe starting from creating index.html. It can be\nempty or filled by simple text. I started from this\none:\n\n<html>\n<head>\n    <title>Snake - game dedicated for Sylwia Daniecka - my girlfriend!</title>\n</head>\n<body>\n    <h1>I love Sylwia <3</h1>\n</body>\n</html>\n\n\nTo serve this document I installed http-server using\nyarn. I typed:\n\nyarn init\n\n\nand press Enter such many times as needed. After\nthis i used commad:\n\nyarn add http-server\n\n\nThese command are responsible for shape of file\n\n> package.json\n\n\n{\n  \"name\": \"snake_js\",\n  \"version\": \"1.0.0\",\n  \"main\": \"index.js\",\n  \"repository\": \"git@github.com:gustawdaniel/snake_js.git\",\n  \"author\": \"Daniel Gustaw <gustaw.daniel@gmail.com>\",\n  \"license\": \"MIT\",\n  \"dependencies\": {\n    \"http-server\": \"^0.11.1\"\n  }\n}\n\n\nFinally I write docs about starting project\n\n# snake_js\nSnake game written in javascript using objects. \n\n# Instaltion\n\nTo install dependencies\n\n    yarn install\n\nTo run\n\n    node node_modules/http-server/bin/http-server \n\n\nMap generation\n> Commits\n26816daa5de0bd3c5203ca61d3b616ac003cfe39..87dbf6d8162dde68ab137ddee78dcb975413d104\n\n\nWe will use jquery so we should type in console\n\nyarn add jquery\n\n\nNow we place div with id map and append script and\nstyle from external files in index.html\n\n> index.html\n\n\n <html>\n <head>\n     <title>Snake - game dedicated for Sylwia Daniecka - my girlfriend!</title>\n+    <link rel=\"stylesheet\" href=\"css/style.css\">\n </head>\n <body>\n     <h1>I love Sylwia <3</h1>\n+    <hr>\n+    <h4>TODO:</h4>\n+    <ol>\n+        <li style=\"text-decoration: line-through\">Add map</li>\n+        <li>Add snake</li>\n+        <li>Add events</li>\n+    </ol>\n+    <hr>\n+    <main>\n+        <div id=\"map\"></div>\n+    </main>\n+    <script src=\"node_modules/jquery/dist/jquery.min.js\"></script>\n+    <script src=\"js/app.js\"></script>\n </body>\n </html>\n\n\nWe are interested creating script that iterate over\nsize of map and place for example 10 rows with\n10 rectangles in each. This script will be placed\nin anonymous function in js/app.js\n\n> js/app.js\n\n\n(function () {\n\n    const config = {\n        mapWidth: 10,\n        mapHeight: 10\n    };\n\n    let map = {\n        width: config.mapWidth,\n        height: config.mapHeight,\n        init: function () {\n            let mapDiv = $('#map');\n            for(let i=0; i<this.height; i++) {\n                console.log(i);\n                let rowDiv =$('<div>', {class: \"row\"});\n                console.log(rowDiv);\n                for(let j=0; j<this.width; j++) {\n                    rowDiv.append($('<div>',{class:\"rect\", \"data-x\":i, \"data-y\":j}));\n                }\n                mapDiv.append(rowDiv);\n            }\n        }\n    };\n\n    map.init();\n\n    \n})();\n\n\nThis script create divs with class rect and place\nit into divs with class row that are placed into\nexisting dive with id map.\n\nThese all divs have zero height so we should define\nstyle for him.\n\n> css/style.css\n\n\n.rect {\n    width: 30px;\n    height: 30px;\n    background-color: #dca6d1;\n    display: inline-block;\n    margin: 2px;\n}\n\n\nMap should look like this:\n\n [https://postimg.org/image/ajfdrjcmj/]\n\nSnake\n> Commit\nd50265a3a5adca92bfe7d5139c0e519e72d853dc..87dbf6d8162dde68ab137ddee78dcb975413d104\n\n\nTo add snake we should chose his color. In constant config responsible for\nglobal configuration we describing color of snake.\n\n> js/app.js\n\n\n@@ -2,7 +2,8 @@\n \n     const config = {\n         mapWidth: 10,\n         mapHeight: 10,\n+        snakeColor: \"#8165f3\"\n     };\n \n     let map = {\n\n\nNow se want to create object of snake. We have to define his initial shape,\niterate over his all parts (coordinates) and change background-color of\ndives with this coordinates. Fortunately we added to divs with class rect\nattributes data-x and data-y that will help in searching proper elements.\n\n> js/app.js\n\n\n@@ -22,7 +23,17 @@\n         }\n     };\n \n+    let snake = {\n+        body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\n+        draw: function() {\n+            this.body.forEach(function (part) {\n+                $(`div.rect[data-x=\"${part.x}\"][data-y=\"${part.y}\"]`).css('background-color',config.snakeColor);\n+            })\n+        }\n+    };\n+\n     map.init();\n+    snake.draw();\n \n     \n })();\n\n\nFinally we can proudly check these changes in todo list in index.html adding\nto text-decoration property line-through\n\n> index.html\n\n\n@@ -9,7 +9,7 @@\n     <h4>TODO:</h4>\n     <ol>\n         <li style=\"text-decoration: line-through\">Add map</li>\n-        <li>Add snake</li>\n+        <li style=\"text-decoration: line-through\">Add snake</li>\n         <li>Add events</li>\n     </ol>\n     <hr>\n\n\nOur ma should look like this\n\n [https://postimg.org/image/wwn4eanu3/]\n\nMove and events\n> Commit\nae194969e7d2a555c9dc7ed2fb57c81b56775b62..d50265a3a5adca92bfe7d5139c0e519e72d853dc\n\n\nIt is time to add dynamics for our snake.\n\nWe start from adding counter to show how many turns have our game.\n\n> index.html\n\n\n     </ol>\n     <hr>\n+    <header>\n+        <p class=\"counter\">0</p>\n+    </header>\n     <main>\n         <div id=\"map\"></div>\n     </main>\n\n\nAnd style for this element\n\n> css/style.css\n\n\n+.counter {\n+    text-align: right;\n+    border: 1px solid black;\n+    padding: 7px;\n+ }\n\n\nNow we come back to logic. Firstly we will need color of map, and\ntime of one rund in our configuration. Second value is measured in\nmilliseconds\n\n> js/app.js\n\n\n@@ -3,7 +3,9 @@\n     const config = {\n         mapWidth: 10,\n         mapHeight: 10,\n-        snakeColor: \"#8165f3\"\n+        snakeColor: \"#8165f3\",\n+        mapColor: \"#dca6d1\",\n+        roundTime: 1000\n     };\n \n     let map = {\n\n\nNext we want to add method move to snake object that remove his tail and\nadd his head in chosen direction in relate to current head.\n\n> js/app.js\n\n\n@@ -25,15 +25,64 @@\n \n     let snake = {\n         body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\n         draw: function() {\n             this.body.forEach(function (part) {\n                 $(`div.rect[data-x=\"${part.x}\"][data-y=\"${part.y}\"]`).css\n('background-color',config.snakeColor);\n             })\n+        },\n+        move: function (direction) {\n+            let head = Object.assign({}, this.body[0]);\n\n\nIn function move we assign new head to variable head cloning current head.\nSimple\nequality would not copy variable but only create reference to the same cell of\nmemory.\n\n> js/app.js\n\n\n+            switch (direction) {\n+                case \"up\":\n+                    head.x = head.x -1; break;\n+                case \"down\":\n+                    head.x = head.x + 1; break;\n+                case \"left\":\n+                    head.y = head.y - 1; break;\n+                case \"right\":\n+                    head.y = head.y + 1; break;\n+            }\n\n\nNext in dependence of direction we change coordinates. It can be misleading\nbut x means height and increasing in down direction.\n\n> js/app.js\n\n\n+            this.body.unshift(head);\n+            $(`div.rect[data-x=\"${head.x}\"][data-y=\"${head.y}\"]`)\n+                .css('background-color',config.snakeColor);\n+            let mapCoordinates  = this.body.pop();\n+            $(`div.rect[data-x=\"${mapCoordinates.x}\"][data-y=\"${mapCoordinates.y}\"]`)\n+                .css('background-color',config.mapColor);\n+\n+        }\n+    };\n\n\nFinally we append new head to body by unshift, add snake color to this field,\nremove tail by pop function and add map color to this coordinate.\n\nNow we want to call move function in interval and allow user to change\ndirection.\nWe need new object - game.\n\n> js/app.js\n\n\n+    let game = {\n+        counter: 0,\n+        direction: 'right', // right, left, up, down\n+        run: function () {\n+            snake.move(this.direction);\n+        },\n\n\nOur game should have property with current direction of snake and counter\nwith number of turns. Function run of game contains now move of snake.\n\nWhen game will start we will call init method of game.\n\n+        init: function () {\n+            map.init();\n+            snake.draw();\n+            setInterval(() => {\n+                this.counter ++;\n+                $('.counter').text(this.counter);\n+                this.run();\n+            },config.roundTime);\n\n\nInit of game means init of map, drawing snake and set interval that\nincrease counter, update it on view, and call run method that move snake.\n\nIf snake would have the same direction all time, it could be end, but we\nwant to allow user change direction of snake by pressing arrows on keyboard,\nfor this purpose after defining time interval we defining event listener\nfor keypress that will change direction of snake.\n\n> js/app.js\n\n\n+            document.addEventListener('keypress',(e) => {\n+                console.log(e.key);\n+                switch (e.key) {\n+                    case \"ArrowUp\":\n+                        this.direction = this.direction === \"down\" ? this.direction : \"up\"; break;\n+                    case \"ArrowDown\":\n+                        this.direction = this.direction === \"up\" ? this.direction : \"down\"; break;\n+                    case \"ArrowLeft\":\n+                        this.direction = this.direction === \"right\" ? this.direction : \"left\"; break;\n+                    case \"ArrowRight\":\n+                        this.direction = this.direction === \"left\" ? this.direction : \"right\"; break;\n+                }\n+            })\n         }\n     };\n \n-    map.init();\n-    snake.drow();\n+    game.init();\n\n\n [https://postimg.org/image/mmkpfay17/]\n\nSummary\nWe can now move snake in map. It is can penetrate the walls and himself.\nThere is no apples for eating, but as it was mentioned. It is not final product\nbut first pre release that present rather educational than functional value.\n\nBelow I present plans about future releases.\n\nv0.1\n 1. Add map\n 2. Add snake\n 3. Add events\n\nv0.2\n 1. Add apples\n 2. Add boundaries\n 3. Add scores\n\nFuture (proposed)\n 1. Add bad apples\n 2. Add two players\n 3. Add network gaming\n\nYou can propose your own features if you want and add them as comments or\nissues in github repository. I hope you learned something valuable reading\nthis tutorial.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:43:25.000Z",
            "updated_at": "2021-04-20T20:43:51.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f3d2b2fb35425592d0bf6",
            "uuid": "0a7c2d51-050d-4c03-b1c5-054f5fe5e6e5",
            "title": "Snake game in JavaScript (part 2 - events)",
            "slug": "snake-game-in-javascript-part-2-events",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## About project\\n\\nWe continuing our adventure with snake started at previous post. Now there is time to \\npresent pre release version 0.2 available on [github](https://github.com/gustawdaniel/snake_js/releases/tag/v0.2).\\n\\nWe will be continue from last commit from previous article to commit connected directly with release 0.2\\n\\n```bash\\ngit diff ae194969e7d2a555c9dc7ed2fb57c81b56775b62..5eb5cd18880be6db4e77f69f6fd3096912d8100e --stat\\n README.md     |   8 +++++\\n css/style.css |  25 ++++++++++++---\\n index.html    |  48 +++++++++++++++++++++++------\\n js/app.js     | 138 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++---------------\\n 4 files changed, 181 insertions(+), 38 deletions(-)\\n```\\n\\n## Changes out of Javascript\\n\\nFor the sake of simplicity I will present final state of files `index.html`, `README.md` and `css/style.css`.\\nNext we will focus on changes in `js/app.js` commit by commit. So because of pausing of game was added\\nit was documented and `REDAME.md` looks like this\\n\\n> README.md\\n\\n```\\n# snake_js\\nSnake game written in javascript using objects. \\n\\n\\n# Instaltion\\n\\nTo install dependencies\\n\\n    yarn install\\n\\nTo run\\n\\n    node node_modules/http-server/bin/http-server \\n\\n# Game\\n\\nTo game run\\n\\n    firefox localhost:8080\\n    \\nPres space to start and use arrows to control snake. \\n```\\n\\nWe reorganized `index.html` placing all description on the bottom of page.\\n\\n> index.html\\n\\n```html\\n<html>\\n<head>\\n    <title>Snake - game dedicated for Sylwia Dainecka - my girlfriend!</title>\\n    <link rel=\\\"stylesheet\\\" href=\\\"css/style.css\\\">\\n</head>\\n<body>\\n    <header>\\n        <h1>I love Sylwia <3</h1>\\n        <p>To start or pause press space</p>\\n        <!--<br>-->\\n        <p class=\\\"info center\\\"><span class=\\\"points\\\">0</span><span class=\\\"state\\\">PAUSED</span><span class=\\\"counter\\\">0</span></p>\\n    </header>\\n    <main>\\n        <div id=\\\"map\\\"></div>\\n    </main>\\n    <footer>\\n        <ul class=\\\"history\\\"></ul>\\n        <hr>\\n        <h4>TODO:</h4>\\n        <h5>v0.1</h5>\\n        <ol>\\n            <li style=\\\"text-decoration: line-through\\\">Add map</li>\\n            <li style=\\\"text-decoration: line-through\\\">Add snake</li>\\n            <li style=\\\"text-decoration: line-through\\\">Add events</li>\\n        </ol>\\n        <h5>v0.2</h5>\\n        <ol>\\n            <li style=\\\"text-decoration: line-through\\\">Add apples</li>\\n            <li style=\\\"text-decoration: line-through\\\">Add boundaries</li>\\n            <li style=\\\"text-decoration: line-through\\\">Add scores</li>\\n        </ol>\\n        <h5>Future (proposed)</h5>\\n        <ol>\\n            <li>Add bad apples</li>\\n            <li>Add two players</li>\\n            <li>Add network gaming</li>\\n            <li>Add tests</li>\\n            <li>Add CI</li>\\n            <li>Create snake as module</li>\\n            <li>Use sass instead of css</li>\\n            <li>Add webpack</li>\\n            <li>Add user account</li>\\n            <li>Fix bug connected with appearing simultaneously many apples</li>\\n            <li>Special color of head</li>\\n            <li>Fix bug connected with changes direction many time in one round that allow bump int snake with length 3</li>\\n            <li>Add login by google</li>\\n            <li>Make it mobile friendly</li>\\n        </ol>\\n    </footer>\\n    <script src=\\\"node_modules/jquery/dist/jquery.min.js\\\"></script>\\n    <script src=\\\"js/app.js\\\"></script>\\n</body>\\n</html>\\n```\\n\\nAs you can see on the list of proposed features I think there is potential to create multi player game.\\n\\nWe have only some lines of styles. It is result of one of assumptions of project - simplicity. This \\nexcludes using external libraries at this stage of development.\\n\\n> css/style.css\\n\\n```css\\n.rect {\\n    width: 30px;\\n    height: 30px;\\n    background-color: #dca6d1;\\n    display: inline-block;\\n    margin: 2px;\\n    /*border-radius: 4px;*/\\n    /*border: solid 1px #dc6f91;*/\\n}\\n\\nfooter {\\n    padding-top: 3vh;\\n}\\n\\n.info {\\n    border: 1px solid black;\\n    padding: 7px;\\n    text-align: center;\\n}\\n\\n.points {\\n    float: left;\\n}\\n\\n.counter {\\n    float: right;\\n}\\n\\nfooter ul.history:not(:empty) {\\n    border: 1px solid black;\\n    padding: 7px;\\n}\\n\\nfooter ul.history li {\\n    list-style: none;\\n}\\n```\\n\\n## Evolution of JavaScript logic\\n\\nNow we focus on small changes of JavaScript logic of game. \\n\\n### Apples \\n\\nWe start from creating apple when game is initialised\\n\\n> git diff ae194969e7d2a555c9dc7ed2fb57c81b56775b62..3056362ad24cf3523bb2931a992be45e41dbf58e js/app.js\\n\\n```diff\\n@@ -5,12 +5,23 @@\\n         mapHeight: 10,\\n         snakeColor: \\\"#8165f3\\\",\\n         mapColor: \\\"#dca6d1\\\",\\n+        appleColor: \\\"#dc5c61\\\",\\n         roundTime: 1000\\n     };\\n \\n     let map = {\\n         width: config.mapWidth,\\n         height: config.mapHeight,\\n+        apples: [],\\n+        addApple: function () {\\n+            let apple = {\\n+                x: Math.floor(Math.random() * this.width),\\n+                y: Math.floor(Math.random() * this.height)\\n+            };\\n+            this.apples.push(apple);\\n+            $(`div.rect[data-x=\\\"${apple.x}\\\"][data-y=\\\"${apple.y}\\\"]`).css('background-color',config.appleColor);\\n+            // console.log(this.apples);\\n+        },\\n         init: function () {\\n             let mapDiv = $('#map');\\n             for(let i=0; i<this.width; i++) {\\n@@ -20,6 +31,7 @@\\n                 }\\n                 mapDiv.append(rowDiv);\\n             }\\n+            this.addApple()\\n         }\\n     };\\n```\\n\\nBut there is one problem. Apple can be placed in body of snake. To prevent this catastrophe we\\nrandomizing apple position until it lands out of snake. We added also function for remove apple.\\n\\n> git diff 3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18 js/app.js\\n\\n```diff\\n@@ -18,9 +18,18 @@\\n                 x: Math.floor(Math.random() * this.width),\\n                 y: Math.floor(Math.random() * this.height)\\n             };\\n-            this.apples.push(apple);\\n-            $(`div.rect[data-x=\\\"${apple.x}\\\"][data-y=\\\"${apple.y}\\\"]`).css('background-color',config.appleColor);\\n-            // console.log(this.apples);\\n+            if(snake.containsCoordinates(apple)) { // apple is on snake  then repeat\\n+                console.log(\\\"appleOnSnake\\\");\\n+                this.addApple();\\n+            } else {\\n+                this.apples.push(apple);\\n+                $(`div.rect[data-x=\\\"${apple.x}\\\"][data-y=\\\"${apple.y}\\\"]`).css('background-color',config.appleColor);\\n+            }\\n+        },\\n+        removeApple: function (toRemove) {\\n+            this.apples = this.apples.filter((apple) => {\\n+                return apple.x !== toRemove.x && apple.y !== toRemove.y\\n+            });\\n         },\\n         init: function () {\\n             let mapDiv = $('#map');\\n```\\n\\nSnake gets number of his points and method to check if given coordinates belong to him.\\n\\n> git diff 3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18 js/app.js\\n\\n```diff\\n@@ -36,7 +45,12 @@\\n     };\\n \\n     let snake = {\\n+        points: 0,\\n         body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\\n+        containsCoordinates: function (inspected) {\\n+            return this.body.filter(function (part) {\\n+                return part.x === inspected.x && part.y === inspected.y }).length\\n+        },\\n         draw: function() {\\n             this.body.forEach(function (part) {\\n                 $(`div.rect[data-x=\\\"${part.x}\\\"][data-y=\\\"${part.y}\\\"]`).css('background-color',config.snakeColor);\\n```\\n\\nFinally we added eating apples to snake move function:\\n\\n> git diff 3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18 js/app.js\\n\\n```diff\\n@@ -57,10 +71,23 @@\\n             this.body.unshift(head);\\n             $(`div.rect[data-x=\\\"${head.x}\\\"][data-y=\\\"${head.y}\\\"]`)\\n                 .css('background-color',config.snakeColor);\\n-            let mapCoordinates  = this.body.pop();\\n-            $(`div.rect[data-x=\\\"${mapCoordinates.x}\\\"][data-y=\\\"${mapCoordinates.y}\\\"]`)\\n-                .css('background-color',config.mapColor);\\n-\\n+            if(!this.eatApple()) {\\n+                let mapCoordinates  = this.body.pop();\\n+                $(`div.rect[data-x=\\\"${mapCoordinates.x}\\\"][data-y=\\\"${mapCoordinates.y}\\\"]`)\\n+                    .css('background-color',config.mapColor);\\n+            }\\n+        },\\n+        eatApple: function () {\\n+            if(map.apples.filter((part) => {\\n+                return part.x === this.body[0].x && part.y === this.body[0].y }).length\\n+            ) {\\n+                this.points ++;\\n+                $('.points').text(this.points);\\n+                console.log(\\\"eatApple\\\");\\n+                map.removeApple(this.body[0]);\\n+                map.addApple();\\n+                return true;\\n+            }\\n         }\\n     };\\n```\\n\\nLast change in this step is shortening time of loop to add more dynamism to game.\\n\\n> git diff 3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18 js/app.js\\n\\n```diff\\n@@ -6,7 +6,7 @@\\n         snakeColor: \\\"#8165f3\\\",\\n         mapColor: \\\"#dca6d1\\\",\\n         appleColor: \\\"#dc5c61\\\",\\n-        roundTime: 1000\\n+        roundTime: 500\\n     };\\n```\\n\\n### Game Over \\n\\nNow we will make our game impossible to game. Earlier snake was immortal, now he dies after\\nalways after 6. Wee need this feature to see logs with scores and easily test game reset.\\n\\n> git diff faef0fa66dea476c761ebf45f87cf2742bcbed18..2e843cc0bf5c895bac529b60942baa3e94435939 js/app.js\\n\\n```diff\\n@@ -93,15 +97,20 @@\\n \\n     let game = {\\n         counter: 0,\\n-        direction: 'right', // right, left, up, down\\n+        direction: 'right', // right, left, up, down,\\n+        timeout: undefined,\\n         run: function () {\\n             snake.move(this.direction);\\n         },\\n         init: function () {\\n+            this.counter = 0;\\n             map.init();\\n-            snake.draw();\\n-            setInterval(() => {\\n+            snake.init();\\n+            this.timeout = setInterval(() => {\\n                 this.counter ++;\\n+                if(this.counter === 6) {\\n+                    this.gameOver();\\n+                }\\n                 $('.counter').text(this.counter);\\n                 this.run();\\n             },config.roundTime);\\n```\\n\\nIn main loop of game we setting counter to 0, draw snake, set interval and assign it to timeout\\nproperty. Finally when counter reach 6 we run function gameOver that is presented below\\n\\n> git diff faef0fa66dea476c761ebf45f87cf2742bcbed18..2e843cc0bf5c895bac529b60942baa3e94435939 js/app.js\\n\\n```diff\\n@@ -118,6 +127,15 @@\\n                         this.direction = this.direction === \\\"left\\\" ? this.direction : \\\"right\\\"; break;\\n                 }\\n             })\\n+        },\\n+        logResult: function () {\\n+            $('ul.history').prepend($(`<li>${performance.now().toFixed(2)} - ${snake.points} - ${this.counter} - ${(snake.points/this.counter).toFixed(4)}</li>`));\\n+        },\\n+        gameOver: function () {\\n+            clearInterval(this.timeout);\\n+            this.timeout = undefined;\\n+            this.logResult();\\n+            this.init();\\n         }\\n     };\\n```\\n\\nGame over run function `logResult` that save scores and some other statistics on the bottom of page in \\n`ul` with class `history`. We have now two bugs to fix after these changes: resetting of map and state\\nof snake. To fix these behaviour we can change script in following way\\n\\n> git diff faef0fa66dea476c761ebf45f87cf2742bcbed18..2e843cc0bf5c895bac529b60942baa3e94435939 js/app.js\\n\\n```diff\\n@@ -33,6 +32,7 @@\\n         },\\n         init: function () {\\n             let mapDiv = $('#map');\\n+            mapDiv.html(\\\"\\\");\\n             for(let i=0; i<this.width; i++) {\\n                 let rowDiv =$('<div>', {class: \\\"row\\\"});\\n                 for(let j=0; j<this.width; j++) {\\n@@ -46,7 +46,12 @@\\n \\n     let snake = {\\n         points: 0,\\n-        body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\\n+        body: [],\\n+        init: function () {\\n+            this.body = [{x:5,y:2},{x:4,y:2},{x:3,y:2}];\\n+            this.points = 0;\\n+            this.draw();\\n+        },\\n         containsCoordinates: function (inspected) {\\n             return this.body.filter(function (part) {\\n                 return part.x === inspected.x && part.y === inspected.y }).length\\n```\\n\\n### Boundaries detection\\n\\nIt is time to make game over more realistic. Game should be ended when snake goes out of map, not \\nafter 6 turns so we need function that check if snake is out of map:\\n\\n> git diff 2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd js/app.js\\n\\n```diff\\n@@ -30,6 +30,10 @@\\n                 return apple.x !== toRemove.x && apple.y !== toRemove.y\\n             });\\n         },\\n+        outOfMap: function (inspected) {\\n+            return inspected.x < 0 || inspected.x >= map.width\\n+                || inspected.y < 0 || inspected.y >= map.height;\\n+        },\\n         init: function () {\\n             let mapDiv = $('#map');\\n             mapDiv.html(\\\"\\\");\\n```\\n\\nWe want also reset scores after snake resurrection \\n\\n> git diff 2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd js/app.js\\n\\n```diff\\n@@ -50,6 +54,7 @@\\n         init: function () {\\n             this.body = [{x:5,y:2},{x:4,y:2},{x:3,y:2}];\\n             this.points = 0;\\n+            $('.points').text(this.points);\\n             this.draw();\\n         },\\n         containsCoordinates: function (inspected) {\\n```\\n\\nNow snake move can be continued if snake is not out of map or has not contains his head\\n\\n> git diff 2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd js/app.js\\n\\n```diff\\n@@ -73,13 +78,17 @@\\n                 case \\\"right\\\":\\n                     head.y = head.y + 1; break;\\n             }\\n-            this.body.unshift(head);\\n-            $(`div.rect[data-x=\\\"${head.x}\\\"][data-y=\\\"${head.y}\\\"]`)\\n-                .css('background-color',config.snakeColor);\\n-            if(!this.eatApple()) {\\n-                let mapCoordinates  = this.body.pop();\\n-                $(`div.rect[data-x=\\\"${mapCoordinates.x}\\\"][data-y=\\\"${mapCoordinates.y}\\\"]`)\\n-                    .css('background-color',config.mapColor);\\n+            if (map.outOfMap(head) || this.containsCoordinates(head)) {\\n+                game.gameOver();\\n+            } else {\\n+                this.body.unshift(head);\\n+                $(`div.rect[data-x=\\\"${head.x}\\\"][data-y=\\\"${head.y}\\\"]`)\\n+                    .css('background-color', config.snakeColor);\\n+                if (!this.eatApple()) {\\n+                    let mapCoordinates = this.body.pop();\\n+                    $(`div.rect[data-x=\\\"${mapCoordinates.x}\\\"][data-y=\\\"${mapCoordinates.y}\\\"]`)\\n+                        .css('background-color', config.mapColor);\\n+                }\\n             }\\n         },\\n         eatApple: function () {\\n```\\n\\nFinally we can remove 6 turns constrain of snake life and for debugging assign all objects to window\\n\\n> git diff 2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd js/app.js\\n\\n```diff\\n@@ -104,13 +113,11 @@\\n         },\\n         init: function () {\\n             this.counter = 0;\\n+            this.direction = 'right';\\n             map.init();\\n             snake.init();\\n             this.timeout = setInterval(() => {\\n                 this.counter ++;\\n-                if(this.counter === 6) {\\n-                    this.gameOver();\\n-                }\\n                 $('.counter').text(this.counter);\\n                 this.run();\\n             },config.roundTime);\\n@@ -141,5 +148,8 @@\\n \\n     game.init();\\n \\n-    \\n+    window.snake = snake;\\n+    window.map = map;\\n+    window.game = game;\\n+\\n })();\\n```\\n\\n### Pause\\n\\nGaming in snake all time without any break can be fatiguing. So our new feature will be state of pause.\\n\\n> git diff fda66af34beae7c28d0b064d95d2f3a15a00fbbd..bd87fd2ffa8f69e841fe553a7cd16b317ad771a8 js/app.js\\n\\n```diff\\n@@ -106,6 +106,7 @@\\n \\n     let game = {\\n         counter: 0,\\n+        state: 'paused', // paused, active\\n         direction: 'right', // right, left, up, down,\\n         timeout: undefined,\\n         run: function () {\\n@@ -114,15 +115,13 @@\\n         init: function () {\\n             this.counter = 0;\\n             this.direction = 'right';\\n+            this.state = 'paused';\\n+            $(\\\".state\\\").text(this.state.toUpperCase());\\n             map.init();\\n             snake.init();\\n-            this.timeout = setInterval(() => {\\n-                this.counter ++;\\n-                $('.counter').text(this.counter);\\n-                this.run();\\n-            },config.roundTime);\\n+\\n             document.addEventListener('keypress',(e) => {\\n-                console.log(e.key);\\n+                console.log({key: e.key, code: e.keyCode});\\n                 switch (e.key) {\\n                     case \\\"ArrowUp\\\":\\n                         this.direction = this.direction === \\\"down\\\" ? this.direction : \\\"up\\\"; break;\\n@@ -132,6 +131,16 @@\\n                         this.direction = this.direction === \\\"right\\\" ? this.direction : \\\"left\\\"; break;\\n                     case \\\"ArrowRight\\\":\\n                         this.direction = this.direction === \\\"left\\\" ? this.direction : \\\"right\\\"; break;\\n+                    case \\\"Enter\\\":\\n+                        if(this.state === 'paused') {\\n+                            this.state = 'active';\\n+                            $(\\\".state\\\").text(this.state.toUpperCase());\\n+                            this.timeout = setInterval(() => {\\n+                                this.counter ++;\\n+                                $('.counter').text(this.counter);\\n+                                this.run();\\n+                            },config.roundTime);\\n+                        }\\n                 }\\n             })\\n         },\\n```\\n\\nAs you can see we added state to game, moved stetting timeout to code executed after detection of ENTER,\\nso you have additional time to know game before start.\\n\\n### Prevent scrolling on keypress detection\\n\\nWhen we added list of features page is now long enough to be scrollable. Arrows has the same default\\nbehaviour like scrolling so to prevent this we added also this code\\n\\n> git diff bd87fd2ffa8f69e841fe553a7cd16b317ad771a8..d0776a2fd5fd26fcccc1664f9261fa19fc90c280 js/app.js\\n\\n```diff\\n@@ -142,6 +142,9 @@\\n                             },config.roundTime);\\n                         }\\n                 }\\n+                if([0, 32, 37, 38, 39, 40].indexOf(e.keyCode) > -1) {\\n+                    e.preventDefault();\\n+                }\\n             })\\n         },\\n         logResult: function () {\\n```\\n\\n### Prevent cheating by using pause to change direction\\n\\nNew feature sometimes means new problems. In our case pausing of game do not prevent to change direction\\nof snake, so can be used in unfairly way. To prevent this we should detect state of game and basing on\\nit allow or disallow to change direction. In this step we changed pause/active button to more intuitive -\\nSPACE instead of ENTER and replaced keyCode by key to make it more readable in detection of scrolling.\\n\\n> git diff d0776a2fd5fd26fcccc1664f9261fa19fc90c280..274a49d6556d8fa8cd4c3e4dc8f14e3c5f56d68b js/app.js\\n\\n```diff\\n@@ -44,6 +44,7 @@\\n                 }\\n                 mapDiv.append(rowDiv);\\n             }\\n+            snake.init();\\n             this.addApple()\\n         }\\n     };\\n@@ -118,20 +119,19 @@\\n             this.state = 'paused';\\n             $(\\\".state\\\").text(this.state.toUpperCase());\\n             map.init();\\n-            snake.init();\\n \\n             document.addEventListener('keypress',(e) => {\\n                 console.log({key: e.key, code: e.keyCode});\\n                 switch (e.key) {\\n                     case \\\"ArrowUp\\\":\\n-                        this.direction = this.direction === \\\"down\\\" ? this.direction : \\\"up\\\"; break;\\n+                        this.direction = this.direction === \\\"down\\\" || this.state === \\\"paused\\\" ? this.direction : \\\"up\\\"; break;\\n                     case \\\"ArrowDown\\\":\\n-                        this.direction = this.direction === \\\"up\\\" ? this.direction : \\\"down\\\"; break;\\n+                        this.direction = this.direction === \\\"up\\\" || this.state === \\\"paused\\\" ? this.direction : \\\"down\\\"; break;\\n                     case \\\"ArrowLeft\\\":\\n-                        this.direction = this.direction === \\\"right\\\" ? this.direction : \\\"left\\\"; break;\\n+                        this.direction = this.direction === \\\"right\\\" || this.state === \\\"paused\\\" ? this.direction : \\\"left\\\"; break;\\n                     case \\\"ArrowRight\\\":\\n-                        this.direction = this.direction === \\\"left\\\" ? this.direction : \\\"right\\\"; break;\\n-                    case \\\"Enter\\\":\\n+                        this.direction = this.direction === \\\"left\\\" || this.state === \\\"paused\\\" ? this.direction : \\\"right\\\"; break;\\n+                    case \\\" \\\":\\n                         if(this.state === 'paused') {\\n                             this.state = 'active';\\n                             $(\\\".state\\\").text(this.state.toUpperCase());\\n@@ -140,9 +140,15 @@\\n                                 $('.counter').text(this.counter);\\n                                 this.run();\\n                             },config.roundTime);\\n+                        } else {\\n+                            this.state = 'paused';\\n+                            $(\\\".state\\\").text(this.state.toUpperCase());\\n+                            clearInterval(this.timeout);\\n+                            this.timeout = undefined;\\n                         }\\n                 }\\n-                if([0, 32, 37, 38, 39, 40].indexOf(e.keyCode) > -1) {\\n+                if([\\\" \\\", \\\"ArrowUp\\\", \\\"ArrowDown\\\", \\\"ArrowLeft\\\", \\\"ArrowRight\\\"].indexOf(e.key) > -1) {\\n+                    console.log(\\\"CAT\\\",e);\\n                     e.preventDefault();\\n                 }\\n             })\\n```\\n\\n### Bug with listener fixing\\n\\nWe can detected second interesting bug. After any game over game add next event listeners. Code need some \\nrefactor. We moved setting listeners to independent method that is called in init but is not called in\\ncase of reset of game.\\n\\n> git diff 274a49d6556d8fa8cd4c3e4dc8f14e3c5f56d68b..cf7f8e7455f72ea0ec9cdd7c58c1b5bbf0872d9a js/app.js\\n\\n```diff\\n@@ -113,13 +113,7 @@\\n         run: function () {\\n             snake.move(this.direction);\\n         },\\n-        init: function () {\\n-            this.counter = 0;\\n-            this.direction = 'right';\\n-            this.state = 'paused';\\n-            $(\\\".state\\\").text(this.state.toUpperCase());\\n-            map.init();\\n-\\n+        setListeners: function () {\\n             document.addEventListener('keypress',(e) => {\\n                 console.log({key: e.key, code: e.keyCode});\\n                 switch (e.key) {\\n@@ -153,6 +147,17 @@\\n                 }\\n             })\\n         },\\n+        init: function () {\\n+            this.reset();\\n+            this.setListeners();\\n+        },\\n+        reset: function () {\\n+            this.counter = 0;\\n+            this.direction = 'right';\\n+            this.state = 'paused';\\n+            $(\\\".state\\\").text(this.state.toUpperCase());\\n+            map.init();\\n+        },\\n         logResult: function () {\\n             $('ul.history').prepend($(`<li>${performance.now().toFixed(2)} - ${snake.points} - ${this.counter} - ${(snake.points/this.counter).toFixed(4)}</li>`));\\n         },\\n@@ -160,7 +165,7 @@\\n             clearInterval(this.timeout);\\n             this.timeout = undefined;\\n             this.logResult();\\n-            this.init();\\n+            this.reset();\\n         }\\n     };\\n```\\n\\nThis is end of changes in JavaScript. Two next commits introduce changes in `README.md` and `index.html`\\nand these lines was presented in previous chapter.\\n\\nNow game is functional and can be used to have fun. I hope this differential manner of presentation\\nevolution of code has more educational value and will helpful for adepts of JavaScript.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"about-project\">About project</h2>\n<p>We continuing our adventure with snake started at previous post. Now there is time to<br>\npresent pre release version 0.2 available on <a href=\"https://github.com/gustawdaniel/snake_js/releases/tag/v0.2\">github</a>.</p>\n<p>We will be continue from last commit from previous article to commit connected directly with release 0.2</p>\n<pre><code class=\"language-bash\">git diff ae194969e7d2a555c9dc7ed2fb57c81b56775b62..5eb5cd18880be6db4e77f69f6fd3096912d8100e --stat\n README.md     |   8 +++++\n css/style.css |  25 ++++++++++++---\n index.html    |  48 +++++++++++++++++++++++------\n js/app.js     | 138 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++---------------\n 4 files changed, 181 insertions(+), 38 deletions(-)\n</code></pre>\n<h2 id=\"changes-out-of-javascript\">Changes out of Javascript</h2>\n<p>For the sake of simplicity I will present final state of files <code>index.html</code>, <code>README.md</code> and <code>css/style.css</code>.<br>\nNext we will focus on changes in <code>js/app.js</code> commit by commit. So because of pausing of game was added<br>\nit was documented and <code>REDAME.md</code> looks like this</p>\n<blockquote>\n<p>README.md</p>\n</blockquote>\n<pre><code># snake_js\nSnake game written in javascript using objects. \n\n\n# Instaltion\n\nTo install dependencies\n\n    yarn install\n\nTo run\n\n    node node_modules/http-server/bin/http-server \n\n# Game\n\nTo game run\n\n    firefox localhost:8080\n    \nPres space to start and use arrows to control snake. \n</code></pre>\n<p>We reorganized <code>index.html</code> placing all description on the bottom of page.</p>\n<blockquote>\n<p>index.html</p>\n</blockquote>\n<pre><code class=\"language-html\">&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Snake - game dedicated for Sylwia Dainecka - my girlfriend!&lt;/title&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;css/style.css&quot;&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;header&gt;\n        &lt;h1&gt;I love Sylwia &lt;3&lt;/h1&gt;\n        &lt;p&gt;To start or pause press space&lt;/p&gt;\n        &lt;!--&lt;br&gt;--&gt;\n        &lt;p class=&quot;info center&quot;&gt;&lt;span class=&quot;points&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;state&quot;&gt;PAUSED&lt;/span&gt;&lt;span class=&quot;counter&quot;&gt;0&lt;/span&gt;&lt;/p&gt;\n    &lt;/header&gt;\n    &lt;main&gt;\n        &lt;div id=&quot;map&quot;&gt;&lt;/div&gt;\n    &lt;/main&gt;\n    &lt;footer&gt;\n        &lt;ul class=&quot;history&quot;&gt;&lt;/ul&gt;\n        &lt;hr&gt;\n        &lt;h4&gt;TODO:&lt;/h4&gt;\n        &lt;h5&gt;v0.1&lt;/h5&gt;\n        &lt;ol&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add map&lt;/li&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add snake&lt;/li&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add events&lt;/li&gt;\n        &lt;/ol&gt;\n        &lt;h5&gt;v0.2&lt;/h5&gt;\n        &lt;ol&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add apples&lt;/li&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add boundaries&lt;/li&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add scores&lt;/li&gt;\n        &lt;/ol&gt;\n        &lt;h5&gt;Future (proposed)&lt;/h5&gt;\n        &lt;ol&gt;\n            &lt;li&gt;Add bad apples&lt;/li&gt;\n            &lt;li&gt;Add two players&lt;/li&gt;\n            &lt;li&gt;Add network gaming&lt;/li&gt;\n            &lt;li&gt;Add tests&lt;/li&gt;\n            &lt;li&gt;Add CI&lt;/li&gt;\n            &lt;li&gt;Create snake as module&lt;/li&gt;\n            &lt;li&gt;Use sass instead of css&lt;/li&gt;\n            &lt;li&gt;Add webpack&lt;/li&gt;\n            &lt;li&gt;Add user account&lt;/li&gt;\n            &lt;li&gt;Fix bug connected with appearing simultaneously many apples&lt;/li&gt;\n            &lt;li&gt;Special color of head&lt;/li&gt;\n            &lt;li&gt;Fix bug connected with changes direction many time in one round that allow bump int snake with length 3&lt;/li&gt;\n            &lt;li&gt;Add login by google&lt;/li&gt;\n            &lt;li&gt;Make it mobile friendly&lt;/li&gt;\n        &lt;/ol&gt;\n    &lt;/footer&gt;\n    &lt;script src=&quot;node_modules/jquery/dist/jquery.min.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;js/app.js&quot;&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>As you can see on the list of proposed features I think there is potential to create multi player game.</p>\n<p>We have only some lines of styles. It is result of one of assumptions of project - simplicity. This<br>\nexcludes using external libraries at this stage of development.</p>\n<blockquote>\n<p>css/style.css</p>\n</blockquote>\n<pre><code class=\"language-css\">.rect {\n    width: 30px;\n    height: 30px;\n    background-color: #dca6d1;\n    display: inline-block;\n    margin: 2px;\n    /*border-radius: 4px;*/\n    /*border: solid 1px #dc6f91;*/\n}\n\nfooter {\n    padding-top: 3vh;\n}\n\n.info {\n    border: 1px solid black;\n    padding: 7px;\n    text-align: center;\n}\n\n.points {\n    float: left;\n}\n\n.counter {\n    float: right;\n}\n\nfooter ul.history:not(:empty) {\n    border: 1px solid black;\n    padding: 7px;\n}\n\nfooter ul.history li {\n    list-style: none;\n}\n</code></pre>\n<h2 id=\"evolution-of-javascript-logic\">Evolution of JavaScript logic</h2>\n<p>Now we focus on small changes of JavaScript logic of game.</p>\n<h3 id=\"apples\">Apples</h3>\n<p>We start from creating apple when game is initialised</p>\n<blockquote>\n<p>git diff ae194969e7d2a555c9dc7ed2fb57c81b56775b62..3056362ad24cf3523bb2931a992be45e41dbf58e js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -5,12 +5,23 @@\n         mapHeight: 10,\n         snakeColor: &quot;#8165f3&quot;,\n         mapColor: &quot;#dca6d1&quot;,\n+        appleColor: &quot;#dc5c61&quot;,\n         roundTime: 1000\n     };\n \n     let map = {\n         width: config.mapWidth,\n         height: config.mapHeight,\n+        apples: [],\n+        addApple: function () {\n+            let apple = {\n+                x: Math.floor(Math.random() * this.width),\n+                y: Math.floor(Math.random() * this.height)\n+            };\n+            this.apples.push(apple);\n+            $(`div.rect[data-x=&quot;${apple.x}&quot;][data-y=&quot;${apple.y}&quot;]`).css('background-color',config.appleColor);\n+            // console.log(this.apples);\n+        },\n         init: function () {\n             let mapDiv = $('#map');\n             for(let i=0; i&lt;this.width; i++) {\n@@ -20,6 +31,7 @@\n                 }\n                 mapDiv.append(rowDiv);\n             }\n+            this.addApple()\n         }\n     };\n</code></pre>\n<p>But there is one problem. Apple can be placed in body of snake. To prevent this catastrophe we<br>\nrandomizing apple position until it lands out of snake. We added also function for remove apple.</p>\n<blockquote>\n<p>git diff 3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18 js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -18,9 +18,18 @@\n                 x: Math.floor(Math.random() * this.width),\n                 y: Math.floor(Math.random() * this.height)\n             };\n-            this.apples.push(apple);\n-            $(`div.rect[data-x=&quot;${apple.x}&quot;][data-y=&quot;${apple.y}&quot;]`).css('background-color',config.appleColor);\n-            // console.log(this.apples);\n+            if(snake.containsCoordinates(apple)) { // apple is on snake  then repeat\n+                console.log(&quot;appleOnSnake&quot;);\n+                this.addApple();\n+            } else {\n+                this.apples.push(apple);\n+                $(`div.rect[data-x=&quot;${apple.x}&quot;][data-y=&quot;${apple.y}&quot;]`).css('background-color',config.appleColor);\n+            }\n+        },\n+        removeApple: function (toRemove) {\n+            this.apples = this.apples.filter((apple) =&gt; {\n+                return apple.x !== toRemove.x &amp;&amp; apple.y !== toRemove.y\n+            });\n         },\n         init: function () {\n             let mapDiv = $('#map');\n</code></pre>\n<p>Snake gets number of his points and method to check if given coordinates belong to him.</p>\n<blockquote>\n<p>git diff 3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18 js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -36,7 +45,12 @@\n     };\n \n     let snake = {\n+        points: 0,\n         body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\n+        containsCoordinates: function (inspected) {\n+            return this.body.filter(function (part) {\n+                return part.x === inspected.x &amp;&amp; part.y === inspected.y }).length\n+        },\n         draw: function() {\n             this.body.forEach(function (part) {\n                 $(`div.rect[data-x=&quot;${part.x}&quot;][data-y=&quot;${part.y}&quot;]`).css('background-color',config.snakeColor);\n</code></pre>\n<p>Finally we added eating apples to snake move function:</p>\n<blockquote>\n<p>git diff 3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18 js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -57,10 +71,23 @@\n             this.body.unshift(head);\n             $(`div.rect[data-x=&quot;${head.x}&quot;][data-y=&quot;${head.y}&quot;]`)\n                 .css('background-color',config.snakeColor);\n-            let mapCoordinates  = this.body.pop();\n-            $(`div.rect[data-x=&quot;${mapCoordinates.x}&quot;][data-y=&quot;${mapCoordinates.y}&quot;]`)\n-                .css('background-color',config.mapColor);\n-\n+            if(!this.eatApple()) {\n+                let mapCoordinates  = this.body.pop();\n+                $(`div.rect[data-x=&quot;${mapCoordinates.x}&quot;][data-y=&quot;${mapCoordinates.y}&quot;]`)\n+                    .css('background-color',config.mapColor);\n+            }\n+        },\n+        eatApple: function () {\n+            if(map.apples.filter((part) =&gt; {\n+                return part.x === this.body[0].x &amp;&amp; part.y === this.body[0].y }).length\n+            ) {\n+                this.points ++;\n+                $('.points').text(this.points);\n+                console.log(&quot;eatApple&quot;);\n+                map.removeApple(this.body[0]);\n+                map.addApple();\n+                return true;\n+            }\n         }\n     };\n</code></pre>\n<p>Last change in this step is shortening time of loop to add more dynamism to game.</p>\n<blockquote>\n<p>git diff 3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18 js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -6,7 +6,7 @@\n         snakeColor: &quot;#8165f3&quot;,\n         mapColor: &quot;#dca6d1&quot;,\n         appleColor: &quot;#dc5c61&quot;,\n-        roundTime: 1000\n+        roundTime: 500\n     };\n</code></pre>\n<h3 id=\"game-over\">Game Over</h3>\n<p>Now we will make our game impossible to game. Earlier snake was immortal, now he dies after<br>\nalways after 6. Wee need this feature to see logs with scores and easily test game reset.</p>\n<blockquote>\n<p>git diff faef0fa66dea476c761ebf45f87cf2742bcbed18..2e843cc0bf5c895bac529b60942baa3e94435939 js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -93,15 +97,20 @@\n \n     let game = {\n         counter: 0,\n-        direction: 'right', // right, left, up, down\n+        direction: 'right', // right, left, up, down,\n+        timeout: undefined,\n         run: function () {\n             snake.move(this.direction);\n         },\n         init: function () {\n+            this.counter = 0;\n             map.init();\n-            snake.draw();\n-            setInterval(() =&gt; {\n+            snake.init();\n+            this.timeout = setInterval(() =&gt; {\n                 this.counter ++;\n+                if(this.counter === 6) {\n+                    this.gameOver();\n+                }\n                 $('.counter').text(this.counter);\n                 this.run();\n             },config.roundTime);\n</code></pre>\n<p>In main loop of game we setting counter to 0, draw snake, set interval and assign it to timeout<br>\nproperty. Finally when counter reach 6 we run function gameOver that is presented below</p>\n<blockquote>\n<p>git diff faef0fa66dea476c761ebf45f87cf2742bcbed18..2e843cc0bf5c895bac529b60942baa3e94435939 js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -118,6 +127,15 @@\n                         this.direction = this.direction === &quot;left&quot; ? this.direction : &quot;right&quot;; break;\n                 }\n             })\n+        },\n+        logResult: function () {\n+            $('ul.history').prepend($(`&lt;li&gt;${performance.now().toFixed(2)} - ${snake.points} - ${this.counter} - ${(snake.points/this.counter).toFixed(4)}&lt;/li&gt;`));\n+        },\n+        gameOver: function () {\n+            clearInterval(this.timeout);\n+            this.timeout = undefined;\n+            this.logResult();\n+            this.init();\n         }\n     };\n</code></pre>\n<p>Game over run function <code>logResult</code> that save scores and some other statistics on the bottom of page in<br>\n<code>ul</code> with class <code>history</code>. We have now two bugs to fix after these changes: resetting of map and state<br>\nof snake. To fix these behaviour we can change script in following way</p>\n<blockquote>\n<p>git diff faef0fa66dea476c761ebf45f87cf2742bcbed18..2e843cc0bf5c895bac529b60942baa3e94435939 js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -33,6 +32,7 @@\n         },\n         init: function () {\n             let mapDiv = $('#map');\n+            mapDiv.html(&quot;&quot;);\n             for(let i=0; i&lt;this.width; i++) {\n                 let rowDiv =$('&lt;div&gt;', {class: &quot;row&quot;});\n                 for(let j=0; j&lt;this.width; j++) {\n@@ -46,7 +46,12 @@\n \n     let snake = {\n         points: 0,\n-        body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\n+        body: [],\n+        init: function () {\n+            this.body = [{x:5,y:2},{x:4,y:2},{x:3,y:2}];\n+            this.points = 0;\n+            this.draw();\n+        },\n         containsCoordinates: function (inspected) {\n             return this.body.filter(function (part) {\n                 return part.x === inspected.x &amp;&amp; part.y === inspected.y }).length\n</code></pre>\n<h3 id=\"boundaries-detection\">Boundaries detection</h3>\n<p>It is time to make game over more realistic. Game should be ended when snake goes out of map, not<br>\nafter 6 turns so we need function that check if snake is out of map:</p>\n<blockquote>\n<p>git diff 2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -30,6 +30,10 @@\n                 return apple.x !== toRemove.x &amp;&amp; apple.y !== toRemove.y\n             });\n         },\n+        outOfMap: function (inspected) {\n+            return inspected.x &lt; 0 || inspected.x &gt;= map.width\n+                || inspected.y &lt; 0 || inspected.y &gt;= map.height;\n+        },\n         init: function () {\n             let mapDiv = $('#map');\n             mapDiv.html(&quot;&quot;);\n</code></pre>\n<p>We want also reset scores after snake resurrection</p>\n<blockquote>\n<p>git diff 2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -50,6 +54,7 @@\n         init: function () {\n             this.body = [{x:5,y:2},{x:4,y:2},{x:3,y:2}];\n             this.points = 0;\n+            $('.points').text(this.points);\n             this.draw();\n         },\n         containsCoordinates: function (inspected) {\n</code></pre>\n<p>Now snake move can be continued if snake is not out of map or has not contains his head</p>\n<blockquote>\n<p>git diff 2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -73,13 +78,17 @@\n                 case &quot;right&quot;:\n                     head.y = head.y + 1; break;\n             }\n-            this.body.unshift(head);\n-            $(`div.rect[data-x=&quot;${head.x}&quot;][data-y=&quot;${head.y}&quot;]`)\n-                .css('background-color',config.snakeColor);\n-            if(!this.eatApple()) {\n-                let mapCoordinates  = this.body.pop();\n-                $(`div.rect[data-x=&quot;${mapCoordinates.x}&quot;][data-y=&quot;${mapCoordinates.y}&quot;]`)\n-                    .css('background-color',config.mapColor);\n+            if (map.outOfMap(head) || this.containsCoordinates(head)) {\n+                game.gameOver();\n+            } else {\n+                this.body.unshift(head);\n+                $(`div.rect[data-x=&quot;${head.x}&quot;][data-y=&quot;${head.y}&quot;]`)\n+                    .css('background-color', config.snakeColor);\n+                if (!this.eatApple()) {\n+                    let mapCoordinates = this.body.pop();\n+                    $(`div.rect[data-x=&quot;${mapCoordinates.x}&quot;][data-y=&quot;${mapCoordinates.y}&quot;]`)\n+                        .css('background-color', config.mapColor);\n+                }\n             }\n         },\n         eatApple: function () {\n</code></pre>\n<p>Finally we can remove 6 turns constrain of snake life and for debugging assign all objects to window</p>\n<blockquote>\n<p>git diff 2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -104,13 +113,11 @@\n         },\n         init: function () {\n             this.counter = 0;\n+            this.direction = 'right';\n             map.init();\n             snake.init();\n             this.timeout = setInterval(() =&gt; {\n                 this.counter ++;\n-                if(this.counter === 6) {\n-                    this.gameOver();\n-                }\n                 $('.counter').text(this.counter);\n                 this.run();\n             },config.roundTime);\n@@ -141,5 +148,8 @@\n \n     game.init();\n \n-    \n+    window.snake = snake;\n+    window.map = map;\n+    window.game = game;\n+\n })();\n</code></pre>\n<h3 id=\"pause\">Pause</h3>\n<p>Gaming in snake all time without any break can be fatiguing. So our new feature will be state of pause.</p>\n<blockquote>\n<p>git diff fda66af34beae7c28d0b064d95d2f3a15a00fbbd..bd87fd2ffa8f69e841fe553a7cd16b317ad771a8 js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -106,6 +106,7 @@\n \n     let game = {\n         counter: 0,\n+        state: 'paused', // paused, active\n         direction: 'right', // right, left, up, down,\n         timeout: undefined,\n         run: function () {\n@@ -114,15 +115,13 @@\n         init: function () {\n             this.counter = 0;\n             this.direction = 'right';\n+            this.state = 'paused';\n+            $(&quot;.state&quot;).text(this.state.toUpperCase());\n             map.init();\n             snake.init();\n-            this.timeout = setInterval(() =&gt; {\n-                this.counter ++;\n-                $('.counter').text(this.counter);\n-                this.run();\n-            },config.roundTime);\n+\n             document.addEventListener('keypress',(e) =&gt; {\n-                console.log(e.key);\n+                console.log({key: e.key, code: e.keyCode});\n                 switch (e.key) {\n                     case &quot;ArrowUp&quot;:\n                         this.direction = this.direction === &quot;down&quot; ? this.direction : &quot;up&quot;; break;\n@@ -132,6 +131,16 @@\n                         this.direction = this.direction === &quot;right&quot; ? this.direction : &quot;left&quot;; break;\n                     case &quot;ArrowRight&quot;:\n                         this.direction = this.direction === &quot;left&quot; ? this.direction : &quot;right&quot;; break;\n+                    case &quot;Enter&quot;:\n+                        if(this.state === 'paused') {\n+                            this.state = 'active';\n+                            $(&quot;.state&quot;).text(this.state.toUpperCase());\n+                            this.timeout = setInterval(() =&gt; {\n+                                this.counter ++;\n+                                $('.counter').text(this.counter);\n+                                this.run();\n+                            },config.roundTime);\n+                        }\n                 }\n             })\n         },\n</code></pre>\n<p>As you can see we added state to game, moved stetting timeout to code executed after detection of ENTER,<br>\nso you have additional time to know game before start.</p>\n<h3 id=\"prevent-scrolling-on-keypress-detection\">Prevent scrolling on keypress detection</h3>\n<p>When we added list of features page is now long enough to be scrollable. Arrows has the same default<br>\nbehaviour like scrolling so to prevent this we added also this code</p>\n<blockquote>\n<p>git diff bd87fd2ffa8f69e841fe553a7cd16b317ad771a8..d0776a2fd5fd26fcccc1664f9261fa19fc90c280 js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -142,6 +142,9 @@\n                             },config.roundTime);\n                         }\n                 }\n+                if([0, 32, 37, 38, 39, 40].indexOf(e.keyCode) &gt; -1) {\n+                    e.preventDefault();\n+                }\n             })\n         },\n         logResult: function () {\n</code></pre>\n<h3 id=\"prevent-cheating-by-using-pause-to-change-direction\">Prevent cheating by using pause to change direction</h3>\n<p>New feature sometimes means new problems. In our case pausing of game do not prevent to change direction<br>\nof snake, so can be used in unfairly way. To prevent this we should detect state of game and basing on<br>\nit allow or disallow to change direction. In this step we changed pause/active button to more intuitive -<br>\nSPACE instead of ENTER and replaced keyCode by key to make it more readable in detection of scrolling.</p>\n<blockquote>\n<p>git diff d0776a2fd5fd26fcccc1664f9261fa19fc90c280..274a49d6556d8fa8cd4c3e4dc8f14e3c5f56d68b js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -44,6 +44,7 @@\n                 }\n                 mapDiv.append(rowDiv);\n             }\n+            snake.init();\n             this.addApple()\n         }\n     };\n@@ -118,20 +119,19 @@\n             this.state = 'paused';\n             $(&quot;.state&quot;).text(this.state.toUpperCase());\n             map.init();\n-            snake.init();\n \n             document.addEventListener('keypress',(e) =&gt; {\n                 console.log({key: e.key, code: e.keyCode});\n                 switch (e.key) {\n                     case &quot;ArrowUp&quot;:\n-                        this.direction = this.direction === &quot;down&quot; ? this.direction : &quot;up&quot;; break;\n+                        this.direction = this.direction === &quot;down&quot; || this.state === &quot;paused&quot; ? this.direction : &quot;up&quot;; break;\n                     case &quot;ArrowDown&quot;:\n-                        this.direction = this.direction === &quot;up&quot; ? this.direction : &quot;down&quot;; break;\n+                        this.direction = this.direction === &quot;up&quot; || this.state === &quot;paused&quot; ? this.direction : &quot;down&quot;; break;\n                     case &quot;ArrowLeft&quot;:\n-                        this.direction = this.direction === &quot;right&quot; ? this.direction : &quot;left&quot;; break;\n+                        this.direction = this.direction === &quot;right&quot; || this.state === &quot;paused&quot; ? this.direction : &quot;left&quot;; break;\n                     case &quot;ArrowRight&quot;:\n-                        this.direction = this.direction === &quot;left&quot; ? this.direction : &quot;right&quot;; break;\n-                    case &quot;Enter&quot;:\n+                        this.direction = this.direction === &quot;left&quot; || this.state === &quot;paused&quot; ? this.direction : &quot;right&quot;; break;\n+                    case &quot; &quot;:\n                         if(this.state === 'paused') {\n                             this.state = 'active';\n                             $(&quot;.state&quot;).text(this.state.toUpperCase());\n@@ -140,9 +140,15 @@\n                                 $('.counter').text(this.counter);\n                                 this.run();\n                             },config.roundTime);\n+                        } else {\n+                            this.state = 'paused';\n+                            $(&quot;.state&quot;).text(this.state.toUpperCase());\n+                            clearInterval(this.timeout);\n+                            this.timeout = undefined;\n                         }\n                 }\n-                if([0, 32, 37, 38, 39, 40].indexOf(e.keyCode) &gt; -1) {\n+                if([&quot; &quot;, &quot;ArrowUp&quot;, &quot;ArrowDown&quot;, &quot;ArrowLeft&quot;, &quot;ArrowRight&quot;].indexOf(e.key) &gt; -1) {\n+                    console.log(&quot;CAT&quot;,e);\n                     e.preventDefault();\n                 }\n             })\n</code></pre>\n<h3 id=\"bug-with-listener-fixing\">Bug with listener fixing</h3>\n<p>We can detected second interesting bug. After any game over game add next event listeners. Code need some<br>\nrefactor. We moved setting listeners to independent method that is called in init but is not called in<br>\ncase of reset of game.</p>\n<blockquote>\n<p>git diff 274a49d6556d8fa8cd4c3e4dc8f14e3c5f56d68b..cf7f8e7455f72ea0ec9cdd7c58c1b5bbf0872d9a js/app.js</p>\n</blockquote>\n<pre><code class=\"language-diff\">@@ -113,13 +113,7 @@\n         run: function () {\n             snake.move(this.direction);\n         },\n-        init: function () {\n-            this.counter = 0;\n-            this.direction = 'right';\n-            this.state = 'paused';\n-            $(&quot;.state&quot;).text(this.state.toUpperCase());\n-            map.init();\n-\n+        setListeners: function () {\n             document.addEventListener('keypress',(e) =&gt; {\n                 console.log({key: e.key, code: e.keyCode});\n                 switch (e.key) {\n@@ -153,6 +147,17 @@\n                 }\n             })\n         },\n+        init: function () {\n+            this.reset();\n+            this.setListeners();\n+        },\n+        reset: function () {\n+            this.counter = 0;\n+            this.direction = 'right';\n+            this.state = 'paused';\n+            $(&quot;.state&quot;).text(this.state.toUpperCase());\n+            map.init();\n+        },\n         logResult: function () {\n             $('ul.history').prepend($(`&lt;li&gt;${performance.now().toFixed(2)} - ${snake.points} - ${this.counter} - ${(snake.points/this.counter).toFixed(4)}&lt;/li&gt;`));\n         },\n@@ -160,7 +165,7 @@\n             clearInterval(this.timeout);\n             this.timeout = undefined;\n             this.logResult();\n-            this.init();\n+            this.reset();\n         }\n     };\n</code></pre>\n<p>This is end of changes in JavaScript. Two next commits introduce changes in <code>README.md</code> and <code>index.html</code><br>\nand these lines was presented in previous chapter.</p>\n<p>Now game is functional and can be used to have fun. I hope this differential manner of presentation<br>\nevolution of code has more educational value and will helpful for adepts of JavaScript.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f3d2b2fb35425592d0bf6",
            "plaintext": "About project\nWe continuing our adventure with snake started at previous post. Now there is\ntime to\npresent pre release version 0.2 available on github\n[https://github.com/gustawdaniel/snake_js/releases/tag/v0.2].\n\nWe will be continue from last commit from previous article to commit connected\ndirectly with release 0.2\n\ngit diff ae194969e7d2a555c9dc7ed2fb57c81b56775b62..5eb5cd18880be6db4e77f69f6fd3096912d8100e --stat\n README.md     |   8 +++++\n css/style.css |  25 ++++++++++++---\n index.html    |  48 +++++++++++++++++++++++------\n js/app.js     | 138 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++---------------\n 4 files changed, 181 insertions(+), 38 deletions(-)\n\n\nChanges out of Javascript\nFor the sake of simplicity I will present final state of files index.html, \nREADME.md and css/style.css.\nNext we will focus on changes in js/app.js commit by commit. So because of\npausing of game was added\nit was documented and REDAME.md looks like this\n\n> README.md\n\n\n# snake_js\nSnake game written in javascript using objects. \n\n\n# Instaltion\n\nTo install dependencies\n\n    yarn install\n\nTo run\n\n    node node_modules/http-server/bin/http-server \n\n# Game\n\nTo game run\n\n    firefox localhost:8080\n    \nPres space to start and use arrows to control snake. \n\n\nWe reorganized index.html placing all description on the bottom of page.\n\n> index.html\n\n\n<html>\n<head>\n    <title>Snake - game dedicated for Sylwia Dainecka - my girlfriend!</title>\n    <link rel=\"stylesheet\" href=\"css/style.css\">\n</head>\n<body>\n    <header>\n        <h1>I love Sylwia <3</h1>\n        <p>To start or pause press space</p>\n        <!--<br>-->\n        <p class=\"info center\"><span class=\"points\">0</span><span class=\"state\">PAUSED</span><span class=\"counter\">0</span></p>\n    </header>\n    <main>\n        <div id=\"map\"></div>\n    </main>\n    <footer>\n        <ul class=\"history\"></ul>\n        <hr>\n        <h4>TODO:</h4>\n        <h5>v0.1</h5>\n        <ol>\n            <li style=\"text-decoration: line-through\">Add map</li>\n            <li style=\"text-decoration: line-through\">Add snake</li>\n            <li style=\"text-decoration: line-through\">Add events</li>\n        </ol>\n        <h5>v0.2</h5>\n        <ol>\n            <li style=\"text-decoration: line-through\">Add apples</li>\n            <li style=\"text-decoration: line-through\">Add boundaries</li>\n            <li style=\"text-decoration: line-through\">Add scores</li>\n        </ol>\n        <h5>Future (proposed)</h5>\n        <ol>\n            <li>Add bad apples</li>\n            <li>Add two players</li>\n            <li>Add network gaming</li>\n            <li>Add tests</li>\n            <li>Add CI</li>\n            <li>Create snake as module</li>\n            <li>Use sass instead of css</li>\n            <li>Add webpack</li>\n            <li>Add user account</li>\n            <li>Fix bug connected with appearing simultaneously many apples</li>\n            <li>Special color of head</li>\n            <li>Fix bug connected with changes direction many time in one round that allow bump int snake with length 3</li>\n            <li>Add login by google</li>\n            <li>Make it mobile friendly</li>\n        </ol>\n    </footer>\n    <script src=\"node_modules/jquery/dist/jquery.min.js\"></script>\n    <script src=\"js/app.js\"></script>\n</body>\n</html>\n\n\nAs you can see on the list of proposed features I think there is potential to\ncreate multi player game.\n\nWe have only some lines of styles. It is result of one of assumptions of project\n- simplicity. This\nexcludes using external libraries at this stage of development.\n\n> css/style.css\n\n\n.rect {\n    width: 30px;\n    height: 30px;\n    background-color: #dca6d1;\n    display: inline-block;\n    margin: 2px;\n    /*border-radius: 4px;*/\n    /*border: solid 1px #dc6f91;*/\n}\n\nfooter {\n    padding-top: 3vh;\n}\n\n.info {\n    border: 1px solid black;\n    padding: 7px;\n    text-align: center;\n}\n\n.points {\n    float: left;\n}\n\n.counter {\n    float: right;\n}\n\nfooter ul.history:not(:empty) {\n    border: 1px solid black;\n    padding: 7px;\n}\n\nfooter ul.history li {\n    list-style: none;\n}\n\n\nEvolution of JavaScript logic\nNow we focus on small changes of JavaScript logic of game.\n\nApples\nWe start from creating apple when game is initialised\n\n> git diff\nae194969e7d2a555c9dc7ed2fb57c81b56775b62..3056362ad24cf3523bb2931a992be45e41dbf58e\njs/app.js\n\n\n@@ -5,12 +5,23 @@\n         mapHeight: 10,\n         snakeColor: \"#8165f3\",\n         mapColor: \"#dca6d1\",\n+        appleColor: \"#dc5c61\",\n         roundTime: 1000\n     };\n \n     let map = {\n         width: config.mapWidth,\n         height: config.mapHeight,\n+        apples: [],\n+        addApple: function () {\n+            let apple = {\n+                x: Math.floor(Math.random() * this.width),\n+                y: Math.floor(Math.random() * this.height)\n+            };\n+            this.apples.push(apple);\n+            $(`div.rect[data-x=\"${apple.x}\"][data-y=\"${apple.y}\"]`).css('background-color',config.appleColor);\n+            // console.log(this.apples);\n+        },\n         init: function () {\n             let mapDiv = $('#map');\n             for(let i=0; i<this.width; i++) {\n@@ -20,6 +31,7 @@\n                 }\n                 mapDiv.append(rowDiv);\n             }\n+            this.addApple()\n         }\n     };\n\n\nBut there is one problem. Apple can be placed in body of snake. To prevent this\ncatastrophe we\nrandomizing apple position until it lands out of snake. We added also function\nfor remove apple.\n\n> git diff\n3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18\njs/app.js\n\n\n@@ -18,9 +18,18 @@\n                 x: Math.floor(Math.random() * this.width),\n                 y: Math.floor(Math.random() * this.height)\n             };\n-            this.apples.push(apple);\n-            $(`div.rect[data-x=\"${apple.x}\"][data-y=\"${apple.y}\"]`).css('background-color',config.appleColor);\n-            // console.log(this.apples);\n+            if(snake.containsCoordinates(apple)) { // apple is on snake  then repeat\n+                console.log(\"appleOnSnake\");\n+                this.addApple();\n+            } else {\n+                this.apples.push(apple);\n+                $(`div.rect[data-x=\"${apple.x}\"][data-y=\"${apple.y}\"]`).css('background-color',config.appleColor);\n+            }\n+        },\n+        removeApple: function (toRemove) {\n+            this.apples = this.apples.filter((apple) => {\n+                return apple.x !== toRemove.x && apple.y !== toRemove.y\n+            });\n         },\n         init: function () {\n             let mapDiv = $('#map');\n\n\nSnake gets number of his points and method to check if given coordinates belong\nto him.\n\n> git diff\n3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18\njs/app.js\n\n\n@@ -36,7 +45,12 @@\n     };\n \n     let snake = {\n+        points: 0,\n         body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\n+        containsCoordinates: function (inspected) {\n+            return this.body.filter(function (part) {\n+                return part.x === inspected.x && part.y === inspected.y }).length\n+        },\n         draw: function() {\n             this.body.forEach(function (part) {\n                 $(`div.rect[data-x=\"${part.x}\"][data-y=\"${part.y}\"]`).css('background-color',config.snakeColor);\n\n\nFinally we added eating apples to snake move function:\n\n> git diff\n3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18\njs/app.js\n\n\n@@ -57,10 +71,23 @@\n             this.body.unshift(head);\n             $(`div.rect[data-x=\"${head.x}\"][data-y=\"${head.y}\"]`)\n                 .css('background-color',config.snakeColor);\n-            let mapCoordinates  = this.body.pop();\n-            $(`div.rect[data-x=\"${mapCoordinates.x}\"][data-y=\"${mapCoordinates.y}\"]`)\n-                .css('background-color',config.mapColor);\n-\n+            if(!this.eatApple()) {\n+                let mapCoordinates  = this.body.pop();\n+                $(`div.rect[data-x=\"${mapCoordinates.x}\"][data-y=\"${mapCoordinates.y}\"]`)\n+                    .css('background-color',config.mapColor);\n+            }\n+        },\n+        eatApple: function () {\n+            if(map.apples.filter((part) => {\n+                return part.x === this.body[0].x && part.y === this.body[0].y }).length\n+            ) {\n+                this.points ++;\n+                $('.points').text(this.points);\n+                console.log(\"eatApple\");\n+                map.removeApple(this.body[0]);\n+                map.addApple();\n+                return true;\n+            }\n         }\n     };\n\n\nLast change in this step is shortening time of loop to add more dynamism to\ngame.\n\n> git diff\n3056362ad24cf3523bb2931a992be45e41dbf58e..faef0fa66dea476c761ebf45f87cf2742bcbed18\njs/app.js\n\n\n@@ -6,7 +6,7 @@\n         snakeColor: \"#8165f3\",\n         mapColor: \"#dca6d1\",\n         appleColor: \"#dc5c61\",\n-        roundTime: 1000\n+        roundTime: 500\n     };\n\n\nGame Over\nNow we will make our game impossible to game. Earlier snake was immortal, now he\ndies after\nalways after 6. Wee need this feature to see logs with scores and easily test\ngame reset.\n\n> git diff\nfaef0fa66dea476c761ebf45f87cf2742bcbed18..2e843cc0bf5c895bac529b60942baa3e94435939\njs/app.js\n\n\n@@ -93,15 +97,20 @@\n \n     let game = {\n         counter: 0,\n-        direction: 'right', // right, left, up, down\n+        direction: 'right', // right, left, up, down,\n+        timeout: undefined,\n         run: function () {\n             snake.move(this.direction);\n         },\n         init: function () {\n+            this.counter = 0;\n             map.init();\n-            snake.draw();\n-            setInterval(() => {\n+            snake.init();\n+            this.timeout = setInterval(() => {\n                 this.counter ++;\n+                if(this.counter === 6) {\n+                    this.gameOver();\n+                }\n                 $('.counter').text(this.counter);\n                 this.run();\n             },config.roundTime);\n\n\nIn main loop of game we setting counter to 0, draw snake, set interval and\nassign it to timeout\nproperty. Finally when counter reach 6 we run function gameOver that is\npresented below\n\n> git diff\nfaef0fa66dea476c761ebf45f87cf2742bcbed18..2e843cc0bf5c895bac529b60942baa3e94435939\njs/app.js\n\n\n@@ -118,6 +127,15 @@\n                         this.direction = this.direction === \"left\" ? this.direction : \"right\"; break;\n                 }\n             })\n+        },\n+        logResult: function () {\n+            $('ul.history').prepend($(`<li>${performance.now().toFixed(2)} - ${snake.points} - ${this.counter} - ${(snake.points/this.counter).toFixed(4)}</li>`));\n+        },\n+        gameOver: function () {\n+            clearInterval(this.timeout);\n+            this.timeout = undefined;\n+            this.logResult();\n+            this.init();\n         }\n     };\n\n\nGame over run function logResult that save scores and some other statistics on\nthe bottom of page in\nul with class history. We have now two bugs to fix after these changes:\nresetting of map and state\nof snake. To fix these behaviour we can change script in following way\n\n> git diff\nfaef0fa66dea476c761ebf45f87cf2742bcbed18..2e843cc0bf5c895bac529b60942baa3e94435939\njs/app.js\n\n\n@@ -33,6 +32,7 @@\n         },\n         init: function () {\n             let mapDiv = $('#map');\n+            mapDiv.html(\"\");\n             for(let i=0; i<this.width; i++) {\n                 let rowDiv =$('<div>', {class: \"row\"});\n                 for(let j=0; j<this.width; j++) {\n@@ -46,7 +46,12 @@\n \n     let snake = {\n         points: 0,\n-        body: [{x:5,y:2},{x:4,y:2},{x:3,y:2}],\n+        body: [],\n+        init: function () {\n+            this.body = [{x:5,y:2},{x:4,y:2},{x:3,y:2}];\n+            this.points = 0;\n+            this.draw();\n+        },\n         containsCoordinates: function (inspected) {\n             return this.body.filter(function (part) {\n                 return part.x === inspected.x && part.y === inspected.y }).length\n\n\nBoundaries detection\nIt is time to make game over more realistic. Game should be ended when snake\ngoes out of map, not\nafter 6 turns so we need function that check if snake is out of map:\n\n> git diff\n2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd\njs/app.js\n\n\n@@ -30,6 +30,10 @@\n                 return apple.x !== toRemove.x && apple.y !== toRemove.y\n             });\n         },\n+        outOfMap: function (inspected) {\n+            return inspected.x < 0 || inspected.x >= map.width\n+                || inspected.y < 0 || inspected.y >= map.height;\n+        },\n         init: function () {\n             let mapDiv = $('#map');\n             mapDiv.html(\"\");\n\n\nWe want also reset scores after snake resurrection\n\n> git diff\n2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd\njs/app.js\n\n\n@@ -50,6 +54,7 @@\n         init: function () {\n             this.body = [{x:5,y:2},{x:4,y:2},{x:3,y:2}];\n             this.points = 0;\n+            $('.points').text(this.points);\n             this.draw();\n         },\n         containsCoordinates: function (inspected) {\n\n\nNow snake move can be continued if snake is not out of map or has not contains\nhis head\n\n> git diff\n2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd\njs/app.js\n\n\n@@ -73,13 +78,17 @@\n                 case \"right\":\n                     head.y = head.y + 1; break;\n             }\n-            this.body.unshift(head);\n-            $(`div.rect[data-x=\"${head.x}\"][data-y=\"${head.y}\"]`)\n-                .css('background-color',config.snakeColor);\n-            if(!this.eatApple()) {\n-                let mapCoordinates  = this.body.pop();\n-                $(`div.rect[data-x=\"${mapCoordinates.x}\"][data-y=\"${mapCoordinates.y}\"]`)\n-                    .css('background-color',config.mapColor);\n+            if (map.outOfMap(head) || this.containsCoordinates(head)) {\n+                game.gameOver();\n+            } else {\n+                this.body.unshift(head);\n+                $(`div.rect[data-x=\"${head.x}\"][data-y=\"${head.y}\"]`)\n+                    .css('background-color', config.snakeColor);\n+                if (!this.eatApple()) {\n+                    let mapCoordinates = this.body.pop();\n+                    $(`div.rect[data-x=\"${mapCoordinates.x}\"][data-y=\"${mapCoordinates.y}\"]`)\n+                        .css('background-color', config.mapColor);\n+                }\n             }\n         },\n         eatApple: function () {\n\n\nFinally we can remove 6 turns constrain of snake life and for debugging assign\nall objects to window\n\n> git diff\n2e843cc0bf5c895bac529b60942baa3e94435939..fda66af34beae7c28d0b064d95d2f3a15a00fbbd\njs/app.js\n\n\n@@ -104,13 +113,11 @@\n         },\n         init: function () {\n             this.counter = 0;\n+            this.direction = 'right';\n             map.init();\n             snake.init();\n             this.timeout = setInterval(() => {\n                 this.counter ++;\n-                if(this.counter === 6) {\n-                    this.gameOver();\n-                }\n                 $('.counter').text(this.counter);\n                 this.run();\n             },config.roundTime);\n@@ -141,5 +148,8 @@\n \n     game.init();\n \n-    \n+    window.snake = snake;\n+    window.map = map;\n+    window.game = game;\n+\n })();\n\n\nPause\nGaming in snake all time without any break can be fatiguing. So our new feature\nwill be state of pause.\n\n> git diff\nfda66af34beae7c28d0b064d95d2f3a15a00fbbd..bd87fd2ffa8f69e841fe553a7cd16b317ad771a8\njs/app.js\n\n\n@@ -106,6 +106,7 @@\n \n     let game = {\n         counter: 0,\n+        state: 'paused', // paused, active\n         direction: 'right', // right, left, up, down,\n         timeout: undefined,\n         run: function () {\n@@ -114,15 +115,13 @@\n         init: function () {\n             this.counter = 0;\n             this.direction = 'right';\n+            this.state = 'paused';\n+            $(\".state\").text(this.state.toUpperCase());\n             map.init();\n             snake.init();\n-            this.timeout = setInterval(() => {\n-                this.counter ++;\n-                $('.counter').text(this.counter);\n-                this.run();\n-            },config.roundTime);\n+\n             document.addEventListener('keypress',(e) => {\n-                console.log(e.key);\n+                console.log({key: e.key, code: e.keyCode});\n                 switch (e.key) {\n                     case \"ArrowUp\":\n                         this.direction = this.direction === \"down\" ? this.direction : \"up\"; break;\n@@ -132,6 +131,16 @@\n                         this.direction = this.direction === \"right\" ? this.direction : \"left\"; break;\n                     case \"ArrowRight\":\n                         this.direction = this.direction === \"left\" ? this.direction : \"right\"; break;\n+                    case \"Enter\":\n+                        if(this.state === 'paused') {\n+                            this.state = 'active';\n+                            $(\".state\").text(this.state.toUpperCase());\n+                            this.timeout = setInterval(() => {\n+                                this.counter ++;\n+                                $('.counter').text(this.counter);\n+                                this.run();\n+                            },config.roundTime);\n+                        }\n                 }\n             })\n         },\n\n\nAs you can see we added state to game, moved stetting timeout to code executed\nafter detection of ENTER,\nso you have additional time to know game before start.\n\nPrevent scrolling on keypress detection\nWhen we added list of features page is now long enough to be scrollable. Arrows\nhas the same default\nbehaviour like scrolling so to prevent this we added also this code\n\n> git diff\nbd87fd2ffa8f69e841fe553a7cd16b317ad771a8..d0776a2fd5fd26fcccc1664f9261fa19fc90c280\njs/app.js\n\n\n@@ -142,6 +142,9 @@\n                             },config.roundTime);\n                         }\n                 }\n+                if([0, 32, 37, 38, 39, 40].indexOf(e.keyCode) > -1) {\n+                    e.preventDefault();\n+                }\n             })\n         },\n         logResult: function () {\n\n\nPrevent cheating by using pause to change direction\nNew feature sometimes means new problems. In our case pausing of game do not\nprevent to change direction\nof snake, so can be used in unfairly way. To prevent this we should detect state\nof game and basing on\nit allow or disallow to change direction. In this step we changed pause/active\nbutton to more intuitive -\nSPACE instead of ENTER and replaced keyCode by key to make it more readable in\ndetection of scrolling.\n\n> git diff\nd0776a2fd5fd26fcccc1664f9261fa19fc90c280..274a49d6556d8fa8cd4c3e4dc8f14e3c5f56d68b\njs/app.js\n\n\n@@ -44,6 +44,7 @@\n                 }\n                 mapDiv.append(rowDiv);\n             }\n+            snake.init();\n             this.addApple()\n         }\n     };\n@@ -118,20 +119,19 @@\n             this.state = 'paused';\n             $(\".state\").text(this.state.toUpperCase());\n             map.init();\n-            snake.init();\n \n             document.addEventListener('keypress',(e) => {\n                 console.log({key: e.key, code: e.keyCode});\n                 switch (e.key) {\n                     case \"ArrowUp\":\n-                        this.direction = this.direction === \"down\" ? this.direction : \"up\"; break;\n+                        this.direction = this.direction === \"down\" || this.state === \"paused\" ? this.direction : \"up\"; break;\n                     case \"ArrowDown\":\n-                        this.direction = this.direction === \"up\" ? this.direction : \"down\"; break;\n+                        this.direction = this.direction === \"up\" || this.state === \"paused\" ? this.direction : \"down\"; break;\n                     case \"ArrowLeft\":\n-                        this.direction = this.direction === \"right\" ? this.direction : \"left\"; break;\n+                        this.direction = this.direction === \"right\" || this.state === \"paused\" ? this.direction : \"left\"; break;\n                     case \"ArrowRight\":\n-                        this.direction = this.direction === \"left\" ? this.direction : \"right\"; break;\n-                    case \"Enter\":\n+                        this.direction = this.direction === \"left\" || this.state === \"paused\" ? this.direction : \"right\"; break;\n+                    case \" \":\n                         if(this.state === 'paused') {\n                             this.state = 'active';\n                             $(\".state\").text(this.state.toUpperCase());\n@@ -140,9 +140,15 @@\n                                 $('.counter').text(this.counter);\n                                 this.run();\n                             },config.roundTime);\n+                        } else {\n+                            this.state = 'paused';\n+                            $(\".state\").text(this.state.toUpperCase());\n+                            clearInterval(this.timeout);\n+                            this.timeout = undefined;\n                         }\n                 }\n-                if([0, 32, 37, 38, 39, 40].indexOf(e.keyCode) > -1) {\n+                if([\" \", \"ArrowUp\", \"ArrowDown\", \"ArrowLeft\", \"ArrowRight\"].indexOf(e.key) > -1) {\n+                    console.log(\"CAT\",e);\n                     e.preventDefault();\n                 }\n             })\n\n\nBug with listener fixing\nWe can detected second interesting bug. After any game over game add next event\nlisteners. Code need some\nrefactor. We moved setting listeners to independent method that is called in\ninit but is not called in\ncase of reset of game.\n\n> git diff\n274a49d6556d8fa8cd4c3e4dc8f14e3c5f56d68b..cf7f8e7455f72ea0ec9cdd7c58c1b5bbf0872d9a\njs/app.js\n\n\n@@ -113,13 +113,7 @@\n         run: function () {\n             snake.move(this.direction);\n         },\n-        init: function () {\n-            this.counter = 0;\n-            this.direction = 'right';\n-            this.state = 'paused';\n-            $(\".state\").text(this.state.toUpperCase());\n-            map.init();\n-\n+        setListeners: function () {\n             document.addEventListener('keypress',(e) => {\n                 console.log({key: e.key, code: e.keyCode});\n                 switch (e.key) {\n@@ -153,6 +147,17 @@\n                 }\n             })\n         },\n+        init: function () {\n+            this.reset();\n+            this.setListeners();\n+        },\n+        reset: function () {\n+            this.counter = 0;\n+            this.direction = 'right';\n+            this.state = 'paused';\n+            $(\".state\").text(this.state.toUpperCase());\n+            map.init();\n+        },\n         logResult: function () {\n             $('ul.history').prepend($(`<li>${performance.now().toFixed(2)} - ${snake.points} - ${this.counter} - ${(snake.points/this.counter).toFixed(4)}</li>`));\n         },\n@@ -160,7 +165,7 @@\n             clearInterval(this.timeout);\n             this.timeout = undefined;\n             this.logResult();\n-            this.init();\n+            this.reset();\n         }\n     };\n\n\nThis is end of changes in JavaScript. Two next commits introduce changes in \nREADME.md and index.html\nand these lines was presented in previous chapter.\n\nNow game is functional and can be used to have fun. I hope this differential\nmanner of presentation\nevolution of code has more educational value and will helpful for adepts of\nJavaScript.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:44:27.000Z",
            "updated_at": "2021-04-20T20:45:02.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f3db82fb35425592d0c01",
            "uuid": "f4a861bb-d201-463a-8d9e-d87d356b4d8b",
            "title": "Snake game in JavaScript (part 3 - Vue)",
            "slug": "snake-game-in-javascript-part-3-vue",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## About project\\n\\nWhat is better than playing in snake? Playing in snake with friends. Now there is time to present\\nversion of game for two players that use one computer. First player use arrows, second `WSAD`.\\n\\nThis is the same game like before but project was totally refactored. Code was divided into ES6 modules,\\ndependency of jQuery of Zepto was removed and replaced by Vue. Finally instead of snake we now have\\ncollection of snakes. \\n\\nAs you can see below practically all code was rewritten so there is no sense to use differential presentation\\nof changes.\\n\\n```bash\\ngit diff 5eb5cd18880be6db4e77f69f6fd3096912d8100e..e48d9ba1200c70867317957bd22f4e8e6e37b4e8 --stat\\n .gitignore                      |   3 +-\\n README.md                       |  17 ++++---\\n css/style.css                   |  44 ++++++++++++----\\n index.html                      |  52 +++----------------\\n js/app.js                       | 178 -----------------------------------------------------------------\\n package.json                    |  31 ++++++++++--\\n src/App.vue                     |  28 +++++++++++\\n src/Event.js                    |   3 ++\\n src/components/Footer.vue       |  45 +++++++++++++++++\\n src/components/Header.vue       |  16 ++++++\\n src/components/Main.vue         |  74 +++++++++++++++++++++++++++\\n src/components/main/Board.vue   |  66 ++++++++++++++++++++++++\\n src/components/main/Results.vue |  40 +++++++++++++++\\n src/components/main/State.vue   |  25 +++++++++\\n src/game/Board.js               |  54 ++++++++++++++++++++\\n src/game/Config.js              |   5 ++\\n src/game/Game.js                |  26 ++++++++++\\n src/game/Snake.js               |  97 +++++++++++++++++++++++++++++++++++\\n src/main.js                     |   7 +++\\n webpack.config.js               |  78 +++++++++++++++++++++++++++++\\n yarn.lock                       | 129 -----------------------------------------------\\n 21 files changed, 644 insertions(+), 374 deletions(-)\\n```\\n\\nYou can download this 0.3 pre release from [github](https://github.com/gustawdaniel/snake_js/releases/tag/v0.3).\\n\\n## Code presentation\\n\\nProject is organised in the following files\\n\\n```\\n.\\n├── css\\n│   └── style.css\\n├── index.html\\n├── LICENSE\\n├── package.json\\n├── README.md\\n├── src\\n│   ├── App.vue\\n│   ├── components\\n│   │   ├── Footer.vue\\n│   │   ├── Header.vue\\n│   │   ├── main\\n│   │   │   ├── Board.vue\\n│   │   │   ├── Results.vue\\n│   │   │   └── State.vue\\n│   │   └── Main.vue\\n│   ├── Event.js\\n│   ├── game\\n│   │   ├── Board.js\\n│   │   ├── Config.js\\n│   │   ├── Game.js\\n│   │   └── Snake.js\\n│   └── main.js\\n└── webpack.config.js\\n```\\n\\nWe presents also statistics of code lines number\\n\\n```\\ncloc $(git ls-files)\\n      20 text files.\\n      20 unique files.                              \\n      11 files ignored.\\n\\n-------------------------------------------------------------------------------\\nLanguage                     files          blank        comment           code\\n-------------------------------------------------------------------------------\\nJavascript                       7             25              2            243\\nCSS                              1              9              0             49\\nHTML                             1              3              0             10\\n-------------------------------------------------------------------------------\\nSUM:                             9             37              2            302\\n-------------------------------------------------------------------------------\\n```\\n\\n## Index and styles\\n\\nLets start from `css`. We removed colors form JavaScript config and now colors are defined in CSS\\nand cant displaying of snake or apple on map is controlled by classes, not inline styles. We introduced\\nalso some flex rules. If you do not know flex, I strongly recommend to learn it. Flex fixes many\\nproblems that css with position absolute/relative has. \\n\\n> css/style.css\\n\\n```css\\n#map .row {\\n    text-align: center;\\n}\\n\\n.rect {\\n    width: 30px;\\n    height: 30px;\\n    background-color: #dca6d1;\\n    display: inline-block;\\n    margin: 2px;\\n}\\n\\n.rect.out-map {\\n    background-color: #c1d0dc;\\n}\\n.rect.snake-0 {\\n    background-color: #8165f3;\\n}\\n.rect.snake-1 {\\n    background-color: #eff36a;\\n}\\n.rect.apple {\\n    background-color: #97dcd5;\\n}\\n\\n.info {\\n    border: 1px solid black;\\n    padding: 7px;\\n    margin-bottom: 1em;\\n    text-align: center;\\n    justify-content: space-between;\\n    display: flex;\\n}\\n\\nmain .logs {\\n    display: flex;\\n    justify-content: space-evenly;\\n}\\n\\nmain .logs tr.best{\\n    background-color: whitesmoke;\\n}\\n\\nmain .logs tr.best td.points{\\n    font-weight: bold;\\n}\\n\\nmain .history {\\n    border: 1px solid black;\\n    padding: 7px;\\n    margin: 2vh 5px 0 5px;\\n    width: 100%;\\n\\n}\\n\\nmain .history table {\\n    width: 100%;\\n}\\n```\\n\\nNow because of we applied Vue, `index.html` is much smaller.\\n\\n> index.html\\n\\n```html\\n<html>\\n<head>\\n    <title>Snake - game dedicated for Sylwia Daniecka!</title>\\n    <link rel=\\\"stylesheet\\\" href=\\\"css/style.css\\\">\\n</head>\\n<body>\\n\\n    <div id=\\\"app\\\"></div>\\n\\n    <script src=\\\"dist/build.js\\\"></script>\\n\\n</body>\\n</html>\\n```\\n\\nWe do not have file `dist/build.js` in this project but it is builded by webpack. You can see in Readme\\nthat to run project we use now `npm run dev` command. It is more standard.\\n\\n> README.md\\n\\n```\\n# snake_js\\nSnake game written in javascript using objects. \\n\\n\\n# Instaltion\\n\\n    # install dependencies\\n    yarn\\n\\n    # serve with hot reload at localhost:8080\\n    npm run dev\\n\\n    # build for production with minification\\n    npm run build\\n\\n# Game\\n\\nTo game run\\n\\n    firefox localhost:8080\\n    \\nPres space to start and use arrows to control snake first snake or `WSAD` to control second one. \\n\\n[![Zrzut_ekranu_z_2018-02-18_04-36-10.png](https://i.imgur.com/fnkcp2e.png)](https://i.imgur.com/fnkcp2e.png)\\n```\\n\\nWhat means `npm run dev`? We can see it in `package.json` file\\n\\n> package.json\\n\\n```json\\n{\\n  \\\"name\\\": \\\"snake_js\\\",\\n  \\\"description\\\": \\\"Simple javascript snake game.\\\",\\n  \\\"version\\\": \\\"0.3.0\\\",\\n  \\\"main\\\": \\\"index.js\\\",\\n  \\\"repository\\\": \\\"git@github.com:gustawdaniel/snake_js.git\\\",\\n  \\\"author\\\": \\\"Daniel Gustaw <gustaw.daniel@gmail.com>\\\",\\n  \\\"license\\\": \\\"MIT\\\",\\n  \\\"private\\\": true,\\n  \\\"scripts\\\": {\\n    \\\"dev\\\": \\\"cross-env NODE_ENV=development webpack-dev-server --open --hot\\\",\\n    \\\"build\\\": \\\"cross-env NODE_ENV=production webpack --progress --hide-modules\\\"\\n  },\\n  \\\"dependencies\\\": {\\n    \\\"vue\\\": \\\"^2.5.11\\\"\\n  },\\n  \\\"browserslist\\\": [\\n    \\\"> 1%\\\",\\n    \\\"last 2 versions\\\",\\n    \\\"not ie <= 8\\\"\\n  ],\\n  \\\"devDependencies\\\": {\\n    \\\"babel-core\\\": \\\"^6.26.0\\\",\\n    \\\"babel-loader\\\": \\\"^7.1.2\\\",\\n    \\\"babel-preset-env\\\": \\\"^1.6.0\\\",\\n    \\\"babel-preset-stage-3\\\": \\\"^6.24.1\\\",\\n    \\\"cross-env\\\": \\\"^5.0.5\\\",\\n    \\\"css-loader\\\": \\\"^0.28.7\\\",\\n    \\\"file-loader\\\": \\\"^1.1.4\\\",\\n    \\\"imports-loader\\\": \\\"^0.8.0\\\",\\n    \\\"live-server\\\": \\\"^1.2.0\\\",\\n    \\\"vue-loader\\\": \\\"^13.0.5\\\",\\n    \\\"vue-template-compiler\\\": \\\"^2.4.4\\\",\\n    \\\"webpack\\\": \\\"^3.6.0\\\",\\n    \\\"webpack-dev-server\\\": \\\"^2.9.1\\\"\\n  }\\n}\\n```\\n\\nYou can see that this is hot reload webpack dev server with environmental variable NODE_ENV set as `development`.\\nWe come back to webpack configuration later. Now I would like to mention about last basic static file that\\nwas added to project - LICENCE. I decided to use MIT Licence.\\n\\n## ES6 modules\\n\\nOld file `js/app.js` is now divided into for files `src/game/Board.js`, `src/game/Config.js`, `src/game/Game.js`\\nand `src/game/Snake.js`.\\n\\n### Config\\n\\nConfig is simplified. We removed colors from this file. Time again is shorted from half second to 200 ms.\\n\\n> src/game/Config.js\\n\\n```js\\nexport default {\\n    mapWidth: 10,\\n    mapHeight: 10,\\n    roundTime: 200\\n};\\n```\\n\\n### Snake\\n\\nSnake absorbed some game methods. For example game over for single player was mor connected with\\nstate of game, but now it is game over for given snake and do not breaks game of his competitor.\\n\\nSnake gets also new `class` world from `ES6` and real constructor. There are also footpring from\\nprevious version (method init) but it shows advantage of Vue - progressive approach that allows \\nbut not forces applying Vue methods of update frontend.\\n\\nLast change is connected with logging. Any snake has his own array of logs, so logs was ealier\\nonly in html, without connection with data model, now logs are stored in data model and are\\nassigned to snake, not to all game.\\n\\n> src/game/Snake.js\"}],[\"code\",{\"code\":\"import config from './Config';\\nimport Board from './Board';\\nimport game from './Game';\\n\\nexport default class Snake {\\n    constructor(index,body,direction) {\\n        this.index = index;\\n        this.points = 0;\\n        this.body = body;\\n        this.direction = direction; // right, left, up, down,\\n        this.inGame = false; // check if snake goes to game area, when snake fail hi is out of game, when enter to game area hi is in game\\n        this.age = 0; // TODO increment snake age\\n        this.initialConfig = {\\n            body: body.slice(),\\n            direction: direction\\n        };\\n        this.logs = [];\\n    }\\n\\n    init() {\\n        this.draw();\\n    }\\n\\n    containsCoordinates(inspected) {\\n        return this.body.filter(function (part) {\\n            return part.x === inspected.x && part.y === inspected.y }).length\\n    }\\n\\n    draw() {\\n        this.body.forEach((part) => {\\n            document.querySelector(`div.rect[data-x=\\\"${part.x}\\\"][data-y=\\\"${part.y}\\\"]`).classList.add(`snake-${this.index}`);\\n        })\\n    }\\n\\n    move(direction) {\\n        let head = Object.assign({}, this.body[0]);\\n        switch (direction) {\\n            case \\\"up\\\":\\n                head.x = head.x -1; break;\\n            case \\\"down\\\":\\n                head.x = head.x + 1; break;\\n            case \\\"left\\\":\\n                head.y = head.y - 1; break;\\n            case \\\"right\\\":\\n                head.y = head.y + 1; break;\\n        }\\n        if (Board.outOfExtendedMap(head) || this.inGame && (Board.outOfMap(head) || this.containsCoordinates(head))) {\\n            this.gameOver();\\n        } else {\\n            if(!this.inGame && !Board.outOfMap(head)) { this.inGame = true; }\\n\\n            this.body.unshift(head);\\n            document.querySelector(`div.rect[data-x=\\\"${head.x}\\\"][data-y=\\\"${head.y}\\\"]`).classList.add(`snake-${this.index}`);\\n            if (!this.eatApple()) {\\n                let mapCoordinates = this.body.pop();\\n                document.querySelector(`div.rect[data-x=\\\"${mapCoordinates.x}\\\"][data-y=\\\"${mapCoordinates.y}\\\"]`)\\n                    .classList.remove(`snake-${this.index}`);\\n            }\\n        }\\n    }\\n\\n    eatApple() {\\n        if(game.map.apples.filter((part) => {\\n            return part.x === this.body[0].x && part.y === this.body[0].y }).length\\n        ) {\\n\\n            this.points ++;\\n            game.map.removeApple(this.body[0]);\\n            game.map.addApple();\\n            return true;\\n        }\\n    }\\n\\n    gameOver() {\\n        game.map.clearPositions(this.body);\\n        this.logResult();\\n        this.age = 0;\\n        this.points = 0;\\n        this.inGame = false;\\n        this.body = this.initialConfig.body.slice(); // fastest way of cloning array https://stackoverflow.com/questions/3978492/javascript-fastest-way-to-duplicate-an-array-slice-vs-for-loop\\n        this.direction =  this.initialConfig.direction;\\n\\n        this.body.forEach(el => document.querySelector(`div.rect[data-x=\\\"${el.x}\\\"][data-y=\\\"${el.y}\\\"]`).classList.add(`snake-${this.index}`));\\n    }\\n\\n    logResult() {\\n\\n        if(this.inGame) {\\n            this.logs.unshift({\\n                now: performance.now().toFixed(2),\\n                points: this.points,\\n                age: this.age,\\n                counter: game.counter\\n            });\\n        }\\n    }\\n};\",\"language\":\"javascript\"}],[\"markdown\",{\"markdown\":\"### Board\\n\\nBoard lost some of his responsibility. For example displaying apples are totally out of this code. In\\nBoard object we only adding apples or removing them. For communication with layer of view, there is\\nresponsible Vue. \\n\\nBut because of two snakes will play together map changed schape. Now it is divided into game area 10x10\\nand on the left area of spawn first snake, finally on the right area of spawn second snake.\\n\\n> src/game/Board.js\\n\\n```js\\nimport config from './Config';\\nimport game from './Game';\\n\\nexport default class Board {\\n    constructor() {\\n        this.width = config.mapWidth;\\n        this.height = config.mapHeight;\\n        this.apples = [];\\n    }\\n\\n    addApple() {\\n        let apple = {\\n            x: Math.floor(Math.random() * this.width),\\n            y: Math.floor(Math.random() * this.height)\\n        };\\n       if(game.snakes[0].containsCoordinates(apple) || game.snakes[1].containsCoordinates(apple)) { // apple is on snake  then repeat\\n           this.addApple();\\n       } else {\\n           this.apples.push(apple);\\n       }\\n    }\\n\\n    removeApple(toRemove) {\\n\\n        this.apples = this.apples.filter((apple) => {\\n            return apple.x !== toRemove.x && apple.y !== toRemove.y\\n        });\\n    }\\n\\n    static outOfMap(inspected) {\\n        return inspected.x < 0 || inspected.x >= config.mapWidth\\n            || inspected.y < 0 || inspected.y >= config.mapHeight;\\n    }\\n\\n    static outOfExtendedMap(inspected) {\\n        return inspected.x < 0 || inspected.x >= config.mapWidth\\n            || inspected.y < 0-3 || inspected.y >= config.mapHeight+3;\\n    }\\n\\n    clearPositions(positions) {\\n        positions.forEach(position => {\\n            const el = document.querySelector(`div.rect[data-x=\\\"${position.x}\\\"][data-y=\\\"${position.y}\\\"]`);\\n            el.classList.remove('snake-0');\\n            el.classList.remove('snake-1');\\n        });\\n    }\\n\\n    init() {\\n        console.log(game.snakes[0]);\\n        game.snakes[0].init();\\n        game.snakes[1].init();\\n        this.addApple()\\n    }\\n}\\n```\\n\\n### Game\\n\\nGame object is extremely simplified. All logic connected with event handling is delegated to Vue component.\\nGame over is placed in Snake instances. In this case all program always use one instance of game so we do \\nnot need use `new` keyword. Game defines two snakes and give then in constructor initial parameters. \\n\\n```js\\nimport Snake from './Snake';\\nimport Board from './Board';\\n\\nexport default {\\n    counter: 0,\\n    timeout: undefined,\\n    snakes: [\\n        new Snake(0,[{x:9,y:-3}],\\\"up\\\"), // ,{x:8,y:-3},{x:7,y:-3}\\n        new Snake(1,[{x:0,y:12}],\\\"down\\\") // ,{x:1,y:12},{x:2,y:12}\\n    ],\\n    map: new Board(),\\n    state: \\\"paused\\\",\\n    run: function () {\\n       this.snakes[0].move(this.snakes[0].direction);\\n       this.snakes[1].move(this.snakes[1].direction);\\n    },\\n    init: function () {\\n        this.reset();\\n    },\\n    reset: function () {\\n        this.counter = 0;\\n        this.state = 'paused';\\n        this.map.init();\\n    }\\n};\\n```\\n\\n## Vue\\n\\nNow there is time to present role of Vue framework in this project. Entry point for webpack is selected as\\n`cat src/main.js` so I will start from this file\\n\\n> cat src/main.js\\n\\n```js\\nimport Vue from 'vue'\\nimport App from './App.vue'\\n\\nnew Vue({\\n    el: '#app',\\n    render: h => h(App)\\n});\\n```\\n\\nIf you rememver `package.json` Vue is only dependency in production environment. We import them and use\\nto create new Vue instance connected with `#app` element from `index.html` and we see that there rendered\\ncomponent `App`\\n\\n> src/App.vue\\n\\n```html\\n<template>\\n\\n    <div id=\\\"app\\\">\\n\\n        <Header></Header>\\n\\n        <Main></Main>\\n\\n        <Footer></Footer>\\n\\n    </div>\\n\\n</template>\\n\\n<script>\\n\\n    import Footer from './components/Footer.vue';\\n    import Header from './components/Header.vue';\\n    import Main from './components/Main.vue';\\n\\n    export default {\\n        name: 'app',\\n        components: {\\n            Header, Main, Footer\\n        }\\n    }\\n\\n</script>\\n```\\n\\nThis component only assembly components `Header`, `Main` and `Footer` and place them in one view.\\n\\nHeader is dedicated for inventor of this project\\n\\n> src/components/Header.vue\\n\\n```html\\n<template>\\n\\n    <header>\\n        <h1>I love Sylwia <3</h1>\\n        <p>To start or pause press space</p>\\n    </header>\\n\\n</template>\\n\\n<script>\\n\\n    export default {\\n        name: \\\"Header\\\"\\n    }\\n\\n</script>\\n```\\n\\nFooter contains change log and ideas to introduce in future.\\n\\n> src/components/Footer.vue \\n\\n```html\\n<template>\\n    <footer>\\n        <hr>\\n        <h4>Future (proposed)</h4>\\n        <ol>\\n            <li><strong>Add network gaming</strong></li>\\n            <li>Use sass instead of css</li>\\n            <li>Add CI</li>\\n            <li>Add bad apples</li>\\n            <li>Add tests</li>\\n            <li>Add user account</li>\\n            <li>Special color of head</li>\\n            <li>Fix bug connected with changes direction many time in one round that allow bump int snake with length 3</li>\\n            <li>Add login by google</li>\\n            <li>Add sounds</li>\\n            <li>Make it mobile friendly (how to swipe when we have two snakes?)</li>\\n            <li>Fix bug connected with appearing simultaneously many apples (probably fixed)</li>\\n        </ol>\\n        <h4>Change Log</h4>\\n        <h5>v0.3</h5>\\n        <ol>\\n            <li style=\\\"text-decoration: line-through\\\">Add webpack</li>\\n            <li style=\\\"text-decoration: line-through\\\">Create snake as module</li>\\n            <li style=\\\"text-decoration: line-through\\\">Add two players</li>\\n        </ol>\\n        <h5>v0.2</h5>\\n        <ol>\\n            <li style=\\\"text-decoration: line-through\\\">Add apples</li>\\n            <li style=\\\"text-decoration: line-through\\\">Add boundaries</li>\\n            <li style=\\\"text-decoration: line-through\\\">Add scores</li>\\n        </ol>\\n        <h5>v0.1</h5>\\n        <ol>\\n            <li style=\\\"text-decoration: line-through\\\">Add map</li>\\n            <li style=\\\"text-decoration: line-through\\\">Add snake</li>\\n            <li style=\\\"text-decoration: line-through\\\">Add events</li>\\n        </ol>\\n    </footer>\\n</template>\\n\\n<script>\\n    export default {\\n        name: 'Footer'\\n    }\\n</script>\\n```\\n\\nSo most interesting is `Main`. Main again contains three childrens but has also some logic. When main is\\nmounted there is executed method `game.init()`, when is created event listeners are added. Now for 9, not\\n5 buttons. Pause is still allowed.\\n\\n> src/components/Main.vue\\n\\n```html\\n<template>\\n    <main>\\n        <State></State>\\n        <Board></Board>\\n        <Results></Results>\\n    </main>\\n</template>\\n\\n<script>\\n\\n    import State from './main/State.vue'\\n    import Board from './main/Board.vue'\\n    import Results from './main/Results.vue'\\n    import Event from '../Event';\\n\\n    import game from '../game/Game';\\n    import config from '../game/Config';\\n\\n    export default {\\n        name: \\\"Main\\\",\\n        data() {\\n            return {\\n                game\\n            }\\n        },\\n        mounted() {\\n            game.init();\\n        },\\n        components: {\\n            State, Board, Results\\n        },\\n        created() {\\n            window.addEventListener('keydown', (e) => {\\n                console.log({key: e.key, code: e.keyCode});\\n                switch (e.key) {\\n                    case \\\"ArrowUp\\\":\\n                        game.snakes[0].direction = game.snakes[0].direction === \\\"down\\\" || game.state === \\\"paused\\\" ? game.snakes[0].direction : \\\"up\\\"; break;\\n                    case \\\"ArrowDown\\\":\\n                        game.snakes[0].direction = game.snakes[0].direction === \\\"up\\\" || game.state === \\\"paused\\\" ? game.snakes[0].direction : \\\"down\\\"; break;\\n                    case \\\"ArrowLeft\\\":\\n                        game.snakes[0].direction = game.snakes[0].direction === \\\"right\\\" || game.state === \\\"paused\\\" ? game.snakes[0].direction : \\\"left\\\"; break;\\n                    case \\\"ArrowRight\\\":\\n                        game.snakes[0].direction = game.snakes[0].direction === \\\"left\\\" || game.state === \\\"paused\\\" ? game.snakes[0].direction : \\\"right\\\"; break;\\n                    case \\\"w\\\":\\n                        game.snakes[1].direction = game.snakes[1].direction === \\\"down\\\" || game.state === \\\"paused\\\" ? game.snakes[1].direction : \\\"up\\\"; break;\\n                    case \\\"s\\\":\\n                        game.snakes[1].direction = game.snakes[1].direction === \\\"up\\\" || game.state === \\\"paused\\\" ? game.snakes[1].direction : \\\"down\\\"; break;\\n                    case \\\"a\\\":\\n                        game.snakes[1].direction = game.snakes[1].direction === \\\"right\\\" || game.state === \\\"paused\\\" ? game.snakes[1].direction : \\\"left\\\"; break;\\n                    case \\\"d\\\":\\n                        game.snakes[1].direction = game.snakes[1].direction === \\\"left\\\" || game.state === \\\"paused\\\" ? game.snakes[1].direction : \\\"right\\\"; break;\\n                    case \\\" \\\":\\n                        if(game.state === 'paused') {\\n                            game.state = 'active';\\n                            game.timeout = game.timeout || setInterval(() => {\\n                                game.counter ++;\\n                                game.snakes.forEach(s => s.age++);\\n                                game.run();\\n                            },config.roundTime);\\n                        } else {\\n                            game.state = 'paused';\\n                            clearInterval(game.timeout);\\n                            game.timeout = undefined;\\n                        }\\n                }\\n                if([\\\" \\\", \\\"ArrowUp\\\", \\\"ArrowDown\\\", \\\"ArrowLeft\\\", \\\"ArrowRight\\\"].indexOf(e.key) > -1) {\\n                    e.preventDefault();\\n                }\\n            });\\n        }\\n    };\\n\\n\\n</script>\\n```\\n\\nThere is also one interesing element `Event` - instance of vue used to proxy events between poorly related\\nVue components.\\n\\n> src/Event.js\\n\\n```js\\nimport Vue from 'vue';\\n\\nexport default Event = new Vue();\\n```\\n\\nCome back to `Main` and look into his children. Lets start from `State`. Now state is directly binded\\ninto view and updated on any change of game object - practically any turn.\\n\\n> src/components/main/State.vue\\n\\n```html\\n<template>\\n    <div class=\\\"info center\\\">\\n        <span>{{game.snakes[0].points}}<br>{{game.snakes[0].age}}</span>\\n        <span>{{state}}<br>{{game.counter}}</span>\\n        <span>{{game.snakes[1].points}}<br>{{game.snakes[1].age}}</span>\\n    </div>\\n</template>\\n\\n<script>\\n    import game from '../../game/Game';\\n\\n    export default {\\n        name: \\\"State\\\",\\n        data() {\\n            return {\\n                game\\n            }\\n        },\\n        computed: {\\n            state() {\\n                return game.state.toUpperCase();\\n            }\\n        }\\n    }\\n</script>\\n```\\n\\nBoard is more complicated. We create double loop to create `.rect` divs. We use `:ref` property to prevent\\nof searching these elements any time when changes are done.\\n\\n> src/components/main/Board.vue\\n\\n```html\\n<template>\\n    <div id=\\\"map\\\" v-if=\\\"show\\\">\\n        <div v-for=\\\"i in range('rows')\\\" class=\\\"row\\\">\\n            <div v-for=\\\"j in range('cols')\\\" class=\\\"rect\\\" :class=\\\"isOutMap(j)\\\" :data-x=\\\"i\\\" :data-y=\\\"j\\\" :ref=\\\"cordsToIndex(i,j)\\\"></div>\\n        </div>\\n    </div>\\n</template>\\n\\n<script>\\n\\n    import Event from '../../Event';\\n    import game from '../../game/Game';\\n\\n    export default {\\n        name: \\\"Board\\\",\\n        data() {\\n            return { show:true, game: game }\\n        },\\n        computed: {\\n            apples() {\\n                return this.game.map.apples;\\n            }\\n        },\\n        methods: {\\n            indexToCords(index) {\\n                return { x: index.splice(\\\"_\\\")[0], y: index.splice(\\\"_\\\")[1] };\\n            },\\n            cordsToIndex(i, j) {\\n                return `${i}_${j}`;\\n            },\\n            isOutMap(j) {\\n                return j<0 || j>=10 ? \\\"out-map\\\" : \\\"\\\";\\n            },\\n            range(direction) {\\n                if(direction === 'rows') {\\n                    return (new Array(10)).fill(1).map((e, i)=>{return i})\\n                } else if(direction === 'cols') {\\n                    return (new Array(10+6)).fill(1).map((e, i)=>{return i-3})\\n                } else {\\n                    throw new Error(\\\"not known direction, possible: rows and cols\\\");\\n                }\\n            },\\n            rerender(){\\n                this.show = false;\\n                this.$nextTick(() => {\\n                    this.show = true;\\n                    console.log('re-render start');\\n                    this.$nextTick(() => {\\n                        console.log('re-render end')\\n                    })\\n                })\\n            }\\n        },\\n        created: function () {\\n            Event.$on(\\\"reset_map\\\", () => {\\n                this.rerender();\\n            });\\n        },\\n        watch: {\\n            apples: function(n, o) {\\n                o.forEach(a => this.$refs[this.cordsToIndex(a.x,a.y)][0].classList.remove('apple'));\\n                n.forEach(a => this.$refs[this.cordsToIndex(a.x,a.y)][0].classList.add('apple'));\\n            }\\n        }\\n    }\\n</script>\\n```\\n\\nFinally last component - `Results.vue` that presents historical resluts of players and make bold best\\nscores of player.\\n\\n> src/components/main/Results.vue\\n\\n```html\\n<template>\\n\\n    <div class=\\\"logs\\\">\\n        <div v-for=\\\"list in logs\\\" class=\\\"history\\\">\\n            <table>\\n                <thead>\\n                    <tr><th>Age</th><th>Counter</th><th>Points</th><th>Time</th><th>Age/Points</th></tr>\\n                </thead>\\n                <tbody>\\n                    <tr v-for=\\\"log in list\\\" :class=\\\"best(list,log.points)\\\">\\n                        <td>{{log.age}}</td>\\n                        <td>{{log.counter}}</td>\\n                        <td class=\\\"points\\\">{{log.points}}</td>\\n                        <td>{{log.now}}</td>\\n                        <td v-text=\\\"(log.age / log.points).toFixed(2)\\\"></td>\\n                    </tr>\\n                </tbody>\\n            </table>\\n        </div>\\n    </div>\\n</template>\\n\\n<script>\\n    import game from '../../game/Game';\\n\\n    export default {\\n        name: \\\"Results\\\",\\n        data() {\\n            return {\\n                logs: game.snakes.map(s => s.logs)\\n            }\\n        },\\n        methods: {\\n            best(list, points) {\\n                console.log(\\\"LIST\\\",list, points);\\n                return Math.max(...(list.map(l => l.points))) === points ? \\\"best\\\" : \\\"\\\"\\n            }\\n        }\\n    }\\n</script>\\n```\\n\\nThere are presented all files from `src` directory. It is time to present method od building project \\nconfigured in `webpack.config.js`\\n\\n## Webpack\\n\\nWe use standard webpack proposed by Vue framework.\\n\\n```js\\nconst path = require('path');\\nconst webpack = require('webpack');\\n\\nmodule.exports = {\\n    entry: './src/main.js',\\n    output: {\\n        path: path.resolve(__dirname, './dist'),\\n        publicPath: '/dist/',\\n        filename: 'build.js'\\n    },\\n    module: {\\n        rules: [\\n            {\\n                test: /\\\\.css$/,\\n                use: [\\n                    'vue-style-loader',\\n                    'css-loader'\\n                ],\\n            },      {\\n                test: /\\\\.vue$/,\\n                loader: 'vue-loader',\\n                options: {\\n                    loaders: {\\n                    }\\n                    // other vue-loader options go here\\n                }\\n            },\\n            {\\n                test: /\\\\.js$/,\\n                loader: 'babel-loader',\\n                exclude: /node_modules/\\n            },\\n            {\\n                test: /\\\\.(png|jpg|gif|svg)$/,\\n                loader: 'file-loader',\\n                options: {\\n                    name: '[name].[ext]?[hash]'\\n                }\\n            }\\n        ]\\n    },\\n    resolve: {\\n        alias: {\\n            'vue$': 'vue/dist/vue.esm.js'\\n        },\\n        extensions: ['*', '.js', '.vue', '.json']\\n    },\\n    devServer: {\\n        historyApiFallback: true,\\n        noInfo: true,\\n        overlay: true\\n    },\\n    performance: {\\n        hints: false\\n    },\\n    devtool: '#eval-source-map'\\n};\\n\\nif (process.env.NODE_ENV === 'production') {\\n    module.exports.devtool = '#source-map';\\n    // http://vue-loader.vuejs.org/en/workflow/production.html\\n    module.exports.plugins = (module.exports.plugins || []).concat([\\n        new webpack.DefinePlugin({\\n            'process.env': {\\n                NODE_ENV: '\\\"production\\\"'\\n            }\\n        }),\\n        new webpack.optimize.UglifyJsPlugin({\\n            sourceMap: true,\\n            compress: {\\n                warnings: false\\n            }\\n        }),\\n        new webpack.LoaderOptionsPlugin({\\n            minimize: true\\n        })\\n    ])\\n}\\n```\\n\\nNow we can attach screen shot from game.\\n\\n[![Zrzut_ekranu_z_2018-02-18_04-36-10.png](https://i.imgur.com/fnkcp2e.png)](https://i.imgur.com/fnkcp2e.png)\\n\\nHappy eating apples. I hope next version will allow to real multiplayer network game. If do you think any\\nfeature out of this list\\n\\n<ol>\\n    <li><strong>Add network gaming</strong></li>\\n    <li>Use sass instead of css</li>\\n    <li>Add CI</li>\\n    <li>Add bad apples</li>\\n    <li>Add tests</li>\\n    <li>Add user account</li>\\n    <li>Special color of head</li>\\n    <li>Fix bug connected with changes direction many time in one round that allow bump int snake with length 3</li>\\n    <li>Add login by google</li>\\n    <li>Add sounds</li>\\n    <li>Make it mobile friendly (how to swipe when we have two snakes?)</li>\\n    <li>Fix bug connected with appearing simultaneously many apples (probably fixed)</li>\\n</ol>\\n\\n\\nwould be nice, please don't hesitate and add comment :D\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"about-project\">About project</h2>\n<p>What is better than playing in snake? Playing in snake with friends. Now there is time to present<br>\nversion of game for two players that use one computer. First player use arrows, second <code>WSAD</code>.</p>\n<p>This is the same game like before but project was totally refactored. Code was divided into ES6 modules,<br>\ndependency of jQuery of Zepto was removed and replaced by Vue. Finally instead of snake we now have<br>\ncollection of snakes.</p>\n<p>As you can see below practically all code was rewritten so there is no sense to use differential presentation<br>\nof changes.</p>\n<pre><code class=\"language-bash\">git diff 5eb5cd18880be6db4e77f69f6fd3096912d8100e..e48d9ba1200c70867317957bd22f4e8e6e37b4e8 --stat\n .gitignore                      |   3 +-\n README.md                       |  17 ++++---\n css/style.css                   |  44 ++++++++++++----\n index.html                      |  52 +++----------------\n js/app.js                       | 178 -----------------------------------------------------------------\n package.json                    |  31 ++++++++++--\n src/App.vue                     |  28 +++++++++++\n src/Event.js                    |   3 ++\n src/components/Footer.vue       |  45 +++++++++++++++++\n src/components/Header.vue       |  16 ++++++\n src/components/Main.vue         |  74 +++++++++++++++++++++++++++\n src/components/main/Board.vue   |  66 ++++++++++++++++++++++++\n src/components/main/Results.vue |  40 +++++++++++++++\n src/components/main/State.vue   |  25 +++++++++\n src/game/Board.js               |  54 ++++++++++++++++++++\n src/game/Config.js              |   5 ++\n src/game/Game.js                |  26 ++++++++++\n src/game/Snake.js               |  97 +++++++++++++++++++++++++++++++++++\n src/main.js                     |   7 +++\n webpack.config.js               |  78 +++++++++++++++++++++++++++++\n yarn.lock                       | 129 -----------------------------------------------\n 21 files changed, 644 insertions(+), 374 deletions(-)\n</code></pre>\n<p>You can download this 0.3 pre release from <a href=\"https://github.com/gustawdaniel/snake_js/releases/tag/v0.3\">github</a>.</p>\n<h2 id=\"code-presentation\">Code presentation</h2>\n<p>Project is organised in the following files</p>\n<pre><code>.\n├── css\n│   └── style.css\n├── index.html\n├── LICENSE\n├── package.json\n├── README.md\n├── src\n│   ├── App.vue\n│   ├── components\n│   │   ├── Footer.vue\n│   │   ├── Header.vue\n│   │   ├── main\n│   │   │   ├── Board.vue\n│   │   │   ├── Results.vue\n│   │   │   └── State.vue\n│   │   └── Main.vue\n│   ├── Event.js\n│   ├── game\n│   │   ├── Board.js\n│   │   ├── Config.js\n│   │   ├── Game.js\n│   │   └── Snake.js\n│   └── main.js\n└── webpack.config.js\n</code></pre>\n<p>We presents also statistics of code lines number</p>\n<pre><code>cloc $(git ls-files)\n      20 text files.\n      20 unique files.                              \n      11 files ignored.\n\n-------------------------------------------------------------------------------\nLanguage                     files          blank        comment           code\n-------------------------------------------------------------------------------\nJavascript                       7             25              2            243\nCSS                              1              9              0             49\nHTML                             1              3              0             10\n-------------------------------------------------------------------------------\nSUM:                             9             37              2            302\n-------------------------------------------------------------------------------\n</code></pre>\n<h2 id=\"index-and-styles\">Index and styles</h2>\n<p>Lets start from <code>css</code>. We removed colors form JavaScript config and now colors are defined in CSS<br>\nand cant displaying of snake or apple on map is controlled by classes, not inline styles. We introduced<br>\nalso some flex rules. If you do not know flex, I strongly recommend to learn it. Flex fixes many<br>\nproblems that css with position absolute/relative has.</p>\n<blockquote>\n<p>css/style.css</p>\n</blockquote>\n<pre><code class=\"language-css\">#map .row {\n    text-align: center;\n}\n\n.rect {\n    width: 30px;\n    height: 30px;\n    background-color: #dca6d1;\n    display: inline-block;\n    margin: 2px;\n}\n\n.rect.out-map {\n    background-color: #c1d0dc;\n}\n.rect.snake-0 {\n    background-color: #8165f3;\n}\n.rect.snake-1 {\n    background-color: #eff36a;\n}\n.rect.apple {\n    background-color: #97dcd5;\n}\n\n.info {\n    border: 1px solid black;\n    padding: 7px;\n    margin-bottom: 1em;\n    text-align: center;\n    justify-content: space-between;\n    display: flex;\n}\n\nmain .logs {\n    display: flex;\n    justify-content: space-evenly;\n}\n\nmain .logs tr.best{\n    background-color: whitesmoke;\n}\n\nmain .logs tr.best td.points{\n    font-weight: bold;\n}\n\nmain .history {\n    border: 1px solid black;\n    padding: 7px;\n    margin: 2vh 5px 0 5px;\n    width: 100%;\n\n}\n\nmain .history table {\n    width: 100%;\n}\n</code></pre>\n<p>Now because of we applied Vue, <code>index.html</code> is much smaller.</p>\n<blockquote>\n<p>index.html</p>\n</blockquote>\n<pre><code class=\"language-html\">&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Snake - game dedicated for Sylwia Daniecka!&lt;/title&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;css/style.css&quot;&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n    &lt;div id=&quot;app&quot;&gt;&lt;/div&gt;\n\n    &lt;script src=&quot;dist/build.js&quot;&gt;&lt;/script&gt;\n\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>We do not have file <code>dist/build.js</code> in this project but it is builded by webpack. You can see in Readme<br>\nthat to run project we use now <code>npm run dev</code> command. It is more standard.</p>\n<blockquote>\n<p>README.md</p>\n</blockquote>\n<pre><code># snake_js\nSnake game written in javascript using objects. \n\n\n# Instaltion\n\n    # install dependencies\n    yarn\n\n    # serve with hot reload at localhost:8080\n    npm run dev\n\n    # build for production with minification\n    npm run build\n\n# Game\n\nTo game run\n\n    firefox localhost:8080\n    \nPres space to start and use arrows to control snake first snake or `WSAD` to control second one. \n\n[![Zrzut_ekranu_z_2018-02-18_04-36-10.png](https://i.imgur.com/fnkcp2e.png)](https://i.imgur.com/fnkcp2e.png)\n</code></pre>\n<p>What means <code>npm run dev</code>? We can see it in <code>package.json</code> file</p>\n<blockquote>\n<p>package.json</p>\n</blockquote>\n<pre><code class=\"language-json\">{\n  &quot;name&quot;: &quot;snake_js&quot;,\n  &quot;description&quot;: &quot;Simple javascript snake game.&quot;,\n  &quot;version&quot;: &quot;0.3.0&quot;,\n  &quot;main&quot;: &quot;index.js&quot;,\n  &quot;repository&quot;: &quot;git@github.com:gustawdaniel/snake_js.git&quot;,\n  &quot;author&quot;: &quot;Daniel Gustaw &lt;gustaw.daniel@gmail.com&gt;&quot;,\n  &quot;license&quot;: &quot;MIT&quot;,\n  &quot;private&quot;: true,\n  &quot;scripts&quot;: {\n    &quot;dev&quot;: &quot;cross-env NODE_ENV=development webpack-dev-server --open --hot&quot;,\n    &quot;build&quot;: &quot;cross-env NODE_ENV=production webpack --progress --hide-modules&quot;\n  },\n  &quot;dependencies&quot;: {\n    &quot;vue&quot;: &quot;^2.5.11&quot;\n  },\n  &quot;browserslist&quot;: [\n    &quot;&gt; 1%&quot;,\n    &quot;last 2 versions&quot;,\n    &quot;not ie &lt;= 8&quot;\n  ],\n  &quot;devDependencies&quot;: {\n    &quot;babel-core&quot;: &quot;^6.26.0&quot;,\n    &quot;babel-loader&quot;: &quot;^7.1.2&quot;,\n    &quot;babel-preset-env&quot;: &quot;^1.6.0&quot;,\n    &quot;babel-preset-stage-3&quot;: &quot;^6.24.1&quot;,\n    &quot;cross-env&quot;: &quot;^5.0.5&quot;,\n    &quot;css-loader&quot;: &quot;^0.28.7&quot;,\n    &quot;file-loader&quot;: &quot;^1.1.4&quot;,\n    &quot;imports-loader&quot;: &quot;^0.8.0&quot;,\n    &quot;live-server&quot;: &quot;^1.2.0&quot;,\n    &quot;vue-loader&quot;: &quot;^13.0.5&quot;,\n    &quot;vue-template-compiler&quot;: &quot;^2.4.4&quot;,\n    &quot;webpack&quot;: &quot;^3.6.0&quot;,\n    &quot;webpack-dev-server&quot;: &quot;^2.9.1&quot;\n  }\n}\n</code></pre>\n<p>You can see that this is hot reload webpack dev server with environmental variable NODE_ENV set as <code>development</code>.<br>\nWe come back to webpack configuration later. Now I would like to mention about last basic static file that<br>\nwas added to project - LICENCE. I decided to use MIT Licence.</p>\n<h2 id=\"es6-modules\">ES6 modules</h2>\n<p>Old file <code>js/app.js</code> is now divided into for files <code>src/game/Board.js</code>, <code>src/game/Config.js</code>, <code>src/game/Game.js</code><br>\nand <code>src/game/Snake.js</code>.</p>\n<h3 id=\"config\">Config</h3>\n<p>Config is simplified. We removed colors from this file. Time again is shorted from half second to 200 ms.</p>\n<blockquote>\n<p>src/game/Config.js</p>\n</blockquote>\n<pre><code class=\"language-js\">export default {\n    mapWidth: 10,\n    mapHeight: 10,\n    roundTime: 200\n};\n</code></pre>\n<h3 id=\"snake\">Snake</h3>\n<p>Snake absorbed some game methods. For example game over for single player was mor connected with<br>\nstate of game, but now it is game over for given snake and do not breaks game of his competitor.</p>\n<p>Snake gets also new <code>class</code> world from <code>ES6</code> and real constructor. There are also footpring from<br>\nprevious version (method init) but it shows advantage of Vue - progressive approach that allows<br>\nbut not forces applying Vue methods of update frontend.</p>\n<p>Last change is connected with logging. Any snake has his own array of logs, so logs was ealier<br>\nonly in html, without connection with data model, now logs are stored in data model and are<br>\nassigned to snake, not to all game.</p>\n<blockquote>\n<p>src/game/Snake.js</p>\n</blockquote>\n<!--kg-card-end: markdown--><pre><code class=\"language-javascript\">import config from './Config';\nimport Board from './Board';\nimport game from './Game';\n\nexport default class Snake {\n    constructor(index,body,direction) {\n        this.index = index;\n        this.points = 0;\n        this.body = body;\n        this.direction = direction; // right, left, up, down,\n        this.inGame = false; // check if snake goes to game area, when snake fail hi is out of game, when enter to game area hi is in game\n        this.age = 0; // TODO increment snake age\n        this.initialConfig = {\n            body: body.slice(),\n            direction: direction\n        };\n        this.logs = [];\n    }\n\n    init() {\n        this.draw();\n    }\n\n    containsCoordinates(inspected) {\n        return this.body.filter(function (part) {\n            return part.x === inspected.x &amp;&amp; part.y === inspected.y }).length\n    }\n\n    draw() {\n        this.body.forEach((part) =&gt; {\n            document.querySelector(`div.rect[data-x=\"${part.x}\"][data-y=\"${part.y}\"]`).classList.add(`snake-${this.index}`);\n        })\n    }\n\n    move(direction) {\n        let head = Object.assign({}, this.body[0]);\n        switch (direction) {\n            case \"up\":\n                head.x = head.x -1; break;\n            case \"down\":\n                head.x = head.x + 1; break;\n            case \"left\":\n                head.y = head.y - 1; break;\n            case \"right\":\n                head.y = head.y + 1; break;\n        }\n        if (Board.outOfExtendedMap(head) || this.inGame &amp;&amp; (Board.outOfMap(head) || this.containsCoordinates(head))) {\n            this.gameOver();\n        } else {\n            if(!this.inGame &amp;&amp; !Board.outOfMap(head)) { this.inGame = true; }\n\n            this.body.unshift(head);\n            document.querySelector(`div.rect[data-x=\"${head.x}\"][data-y=\"${head.y}\"]`).classList.add(`snake-${this.index}`);\n            if (!this.eatApple()) {\n                let mapCoordinates = this.body.pop();\n                document.querySelector(`div.rect[data-x=\"${mapCoordinates.x}\"][data-y=\"${mapCoordinates.y}\"]`)\n                    .classList.remove(`snake-${this.index}`);\n            }\n        }\n    }\n\n    eatApple() {\n        if(game.map.apples.filter((part) =&gt; {\n            return part.x === this.body[0].x &amp;&amp; part.y === this.body[0].y }).length\n        ) {\n\n            this.points ++;\n            game.map.removeApple(this.body[0]);\n            game.map.addApple();\n            return true;\n        }\n    }\n\n    gameOver() {\n        game.map.clearPositions(this.body);\n        this.logResult();\n        this.age = 0;\n        this.points = 0;\n        this.inGame = false;\n        this.body = this.initialConfig.body.slice(); // fastest way of cloning array https://stackoverflow.com/questions/3978492/javascript-fastest-way-to-duplicate-an-array-slice-vs-for-loop\n        this.direction =  this.initialConfig.direction;\n\n        this.body.forEach(el =&gt; document.querySelector(`div.rect[data-x=\"${el.x}\"][data-y=\"${el.y}\"]`).classList.add(`snake-${this.index}`));\n    }\n\n    logResult() {\n\n        if(this.inGame) {\n            this.logs.unshift({\n                now: performance.now().toFixed(2),\n                points: this.points,\n                age: this.age,\n                counter: game.counter\n            });\n        }\n    }\n};</code></pre><!--kg-card-begin: markdown--><h3 id=\"board\">Board</h3>\n<p>Board lost some of his responsibility. For example displaying apples are totally out of this code. In<br>\nBoard object we only adding apples or removing them. For communication with layer of view, there is<br>\nresponsible Vue.</p>\n<p>But because of two snakes will play together map changed schape. Now it is divided into game area 10x10<br>\nand on the left area of spawn first snake, finally on the right area of spawn second snake.</p>\n<blockquote>\n<p>src/game/Board.js</p>\n</blockquote>\n<pre><code class=\"language-js\">import config from './Config';\nimport game from './Game';\n\nexport default class Board {\n    constructor() {\n        this.width = config.mapWidth;\n        this.height = config.mapHeight;\n        this.apples = [];\n    }\n\n    addApple() {\n        let apple = {\n            x: Math.floor(Math.random() * this.width),\n            y: Math.floor(Math.random() * this.height)\n        };\n       if(game.snakes[0].containsCoordinates(apple) || game.snakes[1].containsCoordinates(apple)) { // apple is on snake  then repeat\n           this.addApple();\n       } else {\n           this.apples.push(apple);\n       }\n    }\n\n    removeApple(toRemove) {\n\n        this.apples = this.apples.filter((apple) =&gt; {\n            return apple.x !== toRemove.x &amp;&amp; apple.y !== toRemove.y\n        });\n    }\n\n    static outOfMap(inspected) {\n        return inspected.x &lt; 0 || inspected.x &gt;= config.mapWidth\n            || inspected.y &lt; 0 || inspected.y &gt;= config.mapHeight;\n    }\n\n    static outOfExtendedMap(inspected) {\n        return inspected.x &lt; 0 || inspected.x &gt;= config.mapWidth\n            || inspected.y &lt; 0-3 || inspected.y &gt;= config.mapHeight+3;\n    }\n\n    clearPositions(positions) {\n        positions.forEach(position =&gt; {\n            const el = document.querySelector(`div.rect[data-x=&quot;${position.x}&quot;][data-y=&quot;${position.y}&quot;]`);\n            el.classList.remove('snake-0');\n            el.classList.remove('snake-1');\n        });\n    }\n\n    init() {\n        console.log(game.snakes[0]);\n        game.snakes[0].init();\n        game.snakes[1].init();\n        this.addApple()\n    }\n}\n</code></pre>\n<h3 id=\"game\">Game</h3>\n<p>Game object is extremely simplified. All logic connected with event handling is delegated to Vue component.<br>\nGame over is placed in Snake instances. In this case all program always use one instance of game so we do<br>\nnot need use <code>new</code> keyword. Game defines two snakes and give then in constructor initial parameters.</p>\n<pre><code class=\"language-js\">import Snake from './Snake';\nimport Board from './Board';\n\nexport default {\n    counter: 0,\n    timeout: undefined,\n    snakes: [\n        new Snake(0,[{x:9,y:-3}],&quot;up&quot;), // ,{x:8,y:-3},{x:7,y:-3}\n        new Snake(1,[{x:0,y:12}],&quot;down&quot;) // ,{x:1,y:12},{x:2,y:12}\n    ],\n    map: new Board(),\n    state: &quot;paused&quot;,\n    run: function () {\n       this.snakes[0].move(this.snakes[0].direction);\n       this.snakes[1].move(this.snakes[1].direction);\n    },\n    init: function () {\n        this.reset();\n    },\n    reset: function () {\n        this.counter = 0;\n        this.state = 'paused';\n        this.map.init();\n    }\n};\n</code></pre>\n<h2 id=\"vue\">Vue</h2>\n<p>Now there is time to present role of Vue framework in this project. Entry point for webpack is selected as<br>\n<code>cat src/main.js</code> so I will start from this file</p>\n<blockquote>\n<p>cat src/main.js</p>\n</blockquote>\n<pre><code class=\"language-js\">import Vue from 'vue'\nimport App from './App.vue'\n\nnew Vue({\n    el: '#app',\n    render: h =&gt; h(App)\n});\n</code></pre>\n<p>If you rememver <code>package.json</code> Vue is only dependency in production environment. We import them and use<br>\nto create new Vue instance connected with <code>#app</code> element from <code>index.html</code> and we see that there rendered<br>\ncomponent <code>App</code></p>\n<blockquote>\n<p>src/App.vue</p>\n</blockquote>\n<pre><code class=\"language-html\">&lt;template&gt;\n\n    &lt;div id=&quot;app&quot;&gt;\n\n        &lt;Header&gt;&lt;/Header&gt;\n\n        &lt;Main&gt;&lt;/Main&gt;\n\n        &lt;Footer&gt;&lt;/Footer&gt;\n\n    &lt;/div&gt;\n\n&lt;/template&gt;\n\n&lt;script&gt;\n\n    import Footer from './components/Footer.vue';\n    import Header from './components/Header.vue';\n    import Main from './components/Main.vue';\n\n    export default {\n        name: 'app',\n        components: {\n            Header, Main, Footer\n        }\n    }\n\n&lt;/script&gt;\n</code></pre>\n<p>This component only assembly components <code>Header</code>, <code>Main</code> and <code>Footer</code> and place them in one view.</p>\n<p>Header is dedicated for inventor of this project</p>\n<blockquote>\n<p>src/components/Header.vue</p>\n</blockquote>\n<pre><code class=\"language-html\">&lt;template&gt;\n\n    &lt;header&gt;\n        &lt;h1&gt;I love Sylwia &lt;3&lt;/h1&gt;\n        &lt;p&gt;To start or pause press space&lt;/p&gt;\n    &lt;/header&gt;\n\n&lt;/template&gt;\n\n&lt;script&gt;\n\n    export default {\n        name: &quot;Header&quot;\n    }\n\n&lt;/script&gt;\n</code></pre>\n<p>Footer contains change log and ideas to introduce in future.</p>\n<blockquote>\n<p>src/components/Footer.vue</p>\n</blockquote>\n<pre><code class=\"language-html\">&lt;template&gt;\n    &lt;footer&gt;\n        &lt;hr&gt;\n        &lt;h4&gt;Future (proposed)&lt;/h4&gt;\n        &lt;ol&gt;\n            &lt;li&gt;&lt;strong&gt;Add network gaming&lt;/strong&gt;&lt;/li&gt;\n            &lt;li&gt;Use sass instead of css&lt;/li&gt;\n            &lt;li&gt;Add CI&lt;/li&gt;\n            &lt;li&gt;Add bad apples&lt;/li&gt;\n            &lt;li&gt;Add tests&lt;/li&gt;\n            &lt;li&gt;Add user account&lt;/li&gt;\n            &lt;li&gt;Special color of head&lt;/li&gt;\n            &lt;li&gt;Fix bug connected with changes direction many time in one round that allow bump int snake with length 3&lt;/li&gt;\n            &lt;li&gt;Add login by google&lt;/li&gt;\n            &lt;li&gt;Add sounds&lt;/li&gt;\n            &lt;li&gt;Make it mobile friendly (how to swipe when we have two snakes?)&lt;/li&gt;\n            &lt;li&gt;Fix bug connected with appearing simultaneously many apples (probably fixed)&lt;/li&gt;\n        &lt;/ol&gt;\n        &lt;h4&gt;Change Log&lt;/h4&gt;\n        &lt;h5&gt;v0.3&lt;/h5&gt;\n        &lt;ol&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add webpack&lt;/li&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Create snake as module&lt;/li&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add two players&lt;/li&gt;\n        &lt;/ol&gt;\n        &lt;h5&gt;v0.2&lt;/h5&gt;\n        &lt;ol&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add apples&lt;/li&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add boundaries&lt;/li&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add scores&lt;/li&gt;\n        &lt;/ol&gt;\n        &lt;h5&gt;v0.1&lt;/h5&gt;\n        &lt;ol&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add map&lt;/li&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add snake&lt;/li&gt;\n            &lt;li style=&quot;text-decoration: line-through&quot;&gt;Add events&lt;/li&gt;\n        &lt;/ol&gt;\n    &lt;/footer&gt;\n&lt;/template&gt;\n\n&lt;script&gt;\n    export default {\n        name: 'Footer'\n    }\n&lt;/script&gt;\n</code></pre>\n<p>So most interesting is <code>Main</code>. Main again contains three childrens but has also some logic. When main is<br>\nmounted there is executed method <code>game.init()</code>, when is created event listeners are added. Now for 9, not<br>\n5 buttons. Pause is still allowed.</p>\n<blockquote>\n<p>src/components/Main.vue</p>\n</blockquote>\n<pre><code class=\"language-html\">&lt;template&gt;\n    &lt;main&gt;\n        &lt;State&gt;&lt;/State&gt;\n        &lt;Board&gt;&lt;/Board&gt;\n        &lt;Results&gt;&lt;/Results&gt;\n    &lt;/main&gt;\n&lt;/template&gt;\n\n&lt;script&gt;\n\n    import State from './main/State.vue'\n    import Board from './main/Board.vue'\n    import Results from './main/Results.vue'\n    import Event from '../Event';\n\n    import game from '../game/Game';\n    import config from '../game/Config';\n\n    export default {\n        name: &quot;Main&quot;,\n        data() {\n            return {\n                game\n            }\n        },\n        mounted() {\n            game.init();\n        },\n        components: {\n            State, Board, Results\n        },\n        created() {\n            window.addEventListener('keydown', (e) =&gt; {\n                console.log({key: e.key, code: e.keyCode});\n                switch (e.key) {\n                    case &quot;ArrowUp&quot;:\n                        game.snakes[0].direction = game.snakes[0].direction === &quot;down&quot; || game.state === &quot;paused&quot; ? game.snakes[0].direction : &quot;up&quot;; break;\n                    case &quot;ArrowDown&quot;:\n                        game.snakes[0].direction = game.snakes[0].direction === &quot;up&quot; || game.state === &quot;paused&quot; ? game.snakes[0].direction : &quot;down&quot;; break;\n                    case &quot;ArrowLeft&quot;:\n                        game.snakes[0].direction = game.snakes[0].direction === &quot;right&quot; || game.state === &quot;paused&quot; ? game.snakes[0].direction : &quot;left&quot;; break;\n                    case &quot;ArrowRight&quot;:\n                        game.snakes[0].direction = game.snakes[0].direction === &quot;left&quot; || game.state === &quot;paused&quot; ? game.snakes[0].direction : &quot;right&quot;; break;\n                    case &quot;w&quot;:\n                        game.snakes[1].direction = game.snakes[1].direction === &quot;down&quot; || game.state === &quot;paused&quot; ? game.snakes[1].direction : &quot;up&quot;; break;\n                    case &quot;s&quot;:\n                        game.snakes[1].direction = game.snakes[1].direction === &quot;up&quot; || game.state === &quot;paused&quot; ? game.snakes[1].direction : &quot;down&quot;; break;\n                    case &quot;a&quot;:\n                        game.snakes[1].direction = game.snakes[1].direction === &quot;right&quot; || game.state === &quot;paused&quot; ? game.snakes[1].direction : &quot;left&quot;; break;\n                    case &quot;d&quot;:\n                        game.snakes[1].direction = game.snakes[1].direction === &quot;left&quot; || game.state === &quot;paused&quot; ? game.snakes[1].direction : &quot;right&quot;; break;\n                    case &quot; &quot;:\n                        if(game.state === 'paused') {\n                            game.state = 'active';\n                            game.timeout = game.timeout || setInterval(() =&gt; {\n                                game.counter ++;\n                                game.snakes.forEach(s =&gt; s.age++);\n                                game.run();\n                            },config.roundTime);\n                        } else {\n                            game.state = 'paused';\n                            clearInterval(game.timeout);\n                            game.timeout = undefined;\n                        }\n                }\n                if([&quot; &quot;, &quot;ArrowUp&quot;, &quot;ArrowDown&quot;, &quot;ArrowLeft&quot;, &quot;ArrowRight&quot;].indexOf(e.key) &gt; -1) {\n                    e.preventDefault();\n                }\n            });\n        }\n    };\n\n\n&lt;/script&gt;\n</code></pre>\n<p>There is also one interesing element <code>Event</code> - instance of vue used to proxy events between poorly related<br>\nVue components.</p>\n<blockquote>\n<p>src/Event.js</p>\n</blockquote>\n<pre><code class=\"language-js\">import Vue from 'vue';\n\nexport default Event = new Vue();\n</code></pre>\n<p>Come back to <code>Main</code> and look into his children. Lets start from <code>State</code>. Now state is directly binded<br>\ninto view and updated on any change of game object - practically any turn.</p>\n<blockquote>\n<p>src/components/main/State.vue</p>\n</blockquote>\n<pre><code class=\"language-html\">&lt;template&gt;\n    &lt;div class=&quot;info center&quot;&gt;\n        &lt;span&gt;{{game.snakes[0].points}}&lt;br&gt;{{game.snakes[0].age}}&lt;/span&gt;\n        &lt;span&gt;{{state}}&lt;br&gt;{{game.counter}}&lt;/span&gt;\n        &lt;span&gt;{{game.snakes[1].points}}&lt;br&gt;{{game.snakes[1].age}}&lt;/span&gt;\n    &lt;/div&gt;\n&lt;/template&gt;\n\n&lt;script&gt;\n    import game from '../../game/Game';\n\n    export default {\n        name: &quot;State&quot;,\n        data() {\n            return {\n                game\n            }\n        },\n        computed: {\n            state() {\n                return game.state.toUpperCase();\n            }\n        }\n    }\n&lt;/script&gt;\n</code></pre>\n<p>Board is more complicated. We create double loop to create <code>.rect</code> divs. We use <code>:ref</code> property to prevent<br>\nof searching these elements any time when changes are done.</p>\n<blockquote>\n<p>src/components/main/Board.vue</p>\n</blockquote>\n<pre><code class=\"language-html\">&lt;template&gt;\n    &lt;div id=&quot;map&quot; v-if=&quot;show&quot;&gt;\n        &lt;div v-for=&quot;i in range('rows')&quot; class=&quot;row&quot;&gt;\n            &lt;div v-for=&quot;j in range('cols')&quot; class=&quot;rect&quot; :class=&quot;isOutMap(j)&quot; :data-x=&quot;i&quot; :data-y=&quot;j&quot; :ref=&quot;cordsToIndex(i,j)&quot;&gt;&lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/template&gt;\n\n&lt;script&gt;\n\n    import Event from '../../Event';\n    import game from '../../game/Game';\n\n    export default {\n        name: &quot;Board&quot;,\n        data() {\n            return { show:true, game: game }\n        },\n        computed: {\n            apples() {\n                return this.game.map.apples;\n            }\n        },\n        methods: {\n            indexToCords(index) {\n                return { x: index.splice(&quot;_&quot;)[0], y: index.splice(&quot;_&quot;)[1] };\n            },\n            cordsToIndex(i, j) {\n                return `${i}_${j}`;\n            },\n            isOutMap(j) {\n                return j&lt;0 || j&gt;=10 ? &quot;out-map&quot; : &quot;&quot;;\n            },\n            range(direction) {\n                if(direction === 'rows') {\n                    return (new Array(10)).fill(1).map((e, i)=&gt;{return i})\n                } else if(direction === 'cols') {\n                    return (new Array(10+6)).fill(1).map((e, i)=&gt;{return i-3})\n                } else {\n                    throw new Error(&quot;not known direction, possible: rows and cols&quot;);\n                }\n            },\n            rerender(){\n                this.show = false;\n                this.$nextTick(() =&gt; {\n                    this.show = true;\n                    console.log('re-render start');\n                    this.$nextTick(() =&gt; {\n                        console.log('re-render end')\n                    })\n                })\n            }\n        },\n        created: function () {\n            Event.$on(&quot;reset_map&quot;, () =&gt; {\n                this.rerender();\n            });\n        },\n        watch: {\n            apples: function(n, o) {\n                o.forEach(a =&gt; this.$refs[this.cordsToIndex(a.x,a.y)][0].classList.remove('apple'));\n                n.forEach(a =&gt; this.$refs[this.cordsToIndex(a.x,a.y)][0].classList.add('apple'));\n            }\n        }\n    }\n&lt;/script&gt;\n</code></pre>\n<p>Finally last component - <code>Results.vue</code> that presents historical resluts of players and make bold best<br>\nscores of player.</p>\n<blockquote>\n<p>src/components/main/Results.vue</p>\n</blockquote>\n<pre><code class=\"language-html\">&lt;template&gt;\n\n    &lt;div class=&quot;logs&quot;&gt;\n        &lt;div v-for=&quot;list in logs&quot; class=&quot;history&quot;&gt;\n            &lt;table&gt;\n                &lt;thead&gt;\n                    &lt;tr&gt;&lt;th&gt;Age&lt;/th&gt;&lt;th&gt;Counter&lt;/th&gt;&lt;th&gt;Points&lt;/th&gt;&lt;th&gt;Time&lt;/th&gt;&lt;th&gt;Age/Points&lt;/th&gt;&lt;/tr&gt;\n                &lt;/thead&gt;\n                &lt;tbody&gt;\n                    &lt;tr v-for=&quot;log in list&quot; :class=&quot;best(list,log.points)&quot;&gt;\n                        &lt;td&gt;{{log.age}}&lt;/td&gt;\n                        &lt;td&gt;{{log.counter}}&lt;/td&gt;\n                        &lt;td class=&quot;points&quot;&gt;{{log.points}}&lt;/td&gt;\n                        &lt;td&gt;{{log.now}}&lt;/td&gt;\n                        &lt;td v-text=&quot;(log.age / log.points).toFixed(2)&quot;&gt;&lt;/td&gt;\n                    &lt;/tr&gt;\n                &lt;/tbody&gt;\n            &lt;/table&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/template&gt;\n\n&lt;script&gt;\n    import game from '../../game/Game';\n\n    export default {\n        name: &quot;Results&quot;,\n        data() {\n            return {\n                logs: game.snakes.map(s =&gt; s.logs)\n            }\n        },\n        methods: {\n            best(list, points) {\n                console.log(&quot;LIST&quot;,list, points);\n                return Math.max(...(list.map(l =&gt; l.points))) === points ? &quot;best&quot; : &quot;&quot;\n            }\n        }\n    }\n&lt;/script&gt;\n</code></pre>\n<p>There are presented all files from <code>src</code> directory. It is time to present method od building project<br>\nconfigured in <code>webpack.config.js</code></p>\n<h2 id=\"webpack\">Webpack</h2>\n<p>We use standard webpack proposed by Vue framework.</p>\n<pre><code class=\"language-js\">const path = require('path');\nconst webpack = require('webpack');\n\nmodule.exports = {\n    entry: './src/main.js',\n    output: {\n        path: path.resolve(__dirname, './dist'),\n        publicPath: '/dist/',\n        filename: 'build.js'\n    },\n    module: {\n        rules: [\n            {\n                test: /\\.css$/,\n                use: [\n                    'vue-style-loader',\n                    'css-loader'\n                ],\n            },      {\n                test: /\\.vue$/,\n                loader: 'vue-loader',\n                options: {\n                    loaders: {\n                    }\n                    // other vue-loader options go here\n                }\n            },\n            {\n                test: /\\.js$/,\n                loader: 'babel-loader',\n                exclude: /node_modules/\n            },\n            {\n                test: /\\.(png|jpg|gif|svg)$/,\n                loader: 'file-loader',\n                options: {\n                    name: '[name].[ext]?[hash]'\n                }\n            }\n        ]\n    },\n    resolve: {\n        alias: {\n            'vue$': 'vue/dist/vue.esm.js'\n        },\n        extensions: ['*', '.js', '.vue', '.json']\n    },\n    devServer: {\n        historyApiFallback: true,\n        noInfo: true,\n        overlay: true\n    },\n    performance: {\n        hints: false\n    },\n    devtool: '#eval-source-map'\n};\n\nif (process.env.NODE_ENV === 'production') {\n    module.exports.devtool = '#source-map';\n    // http://vue-loader.vuejs.org/en/workflow/production.html\n    module.exports.plugins = (module.exports.plugins || []).concat([\n        new webpack.DefinePlugin({\n            'process.env': {\n                NODE_ENV: '&quot;production&quot;'\n            }\n        }),\n        new webpack.optimize.UglifyJsPlugin({\n            sourceMap: true,\n            compress: {\n                warnings: false\n            }\n        }),\n        new webpack.LoaderOptionsPlugin({\n            minimize: true\n        })\n    ])\n}\n</code></pre>\n<p>Now we can attach screen shot from game.</p>\n<p><a href=\"https://i.imgur.com/fnkcp2e.png\"><img src=\"https://i.imgur.com/fnkcp2e.png\" alt=\"Zrzut_ekranu_z_2018-02-18_04-36-10.png\" loading=\"lazy\"></a></p>\n<p>Happy eating apples. I hope next version will allow to real multiplayer network game. If do you think any<br>\nfeature out of this list</p>\n<ol>\n    <li><strong>Add network gaming</strong></li>\n    <li>Use sass instead of css</li>\n    <li>Add CI</li>\n    <li>Add bad apples</li>\n    <li>Add tests</li>\n    <li>Add user account</li>\n    <li>Special color of head</li>\n    <li>Fix bug connected with changes direction many time in one round that allow bump int snake with length 3</li>\n    <li>Add login by google</li>\n    <li>Add sounds</li>\n    <li>Make it mobile friendly (how to swipe when we have two snakes?)</li>\n    <li>Fix bug connected with appearing simultaneously many apples (probably fixed)</li>\n</ol>\n<p>would be nice, please don't hesitate and add comment :D</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f3db82fb35425592d0c01",
            "plaintext": "About project\nWhat is better than playing in snake? Playing in snake with friends. Now there\nis time to present\nversion of game for two players that use one computer. First player use arrows,\nsecond WSAD.\n\nThis is the same game like before but project was totally refactored. Code was\ndivided into ES6 modules,\ndependency of jQuery of Zepto was removed and replaced by Vue. Finally instead\nof snake we now have\ncollection of snakes.\n\nAs you can see below practically all code was rewritten so there is no sense to\nuse differential presentation\nof changes.\n\ngit diff 5eb5cd18880be6db4e77f69f6fd3096912d8100e..e48d9ba1200c70867317957bd22f4e8e6e37b4e8 --stat\n .gitignore                      |   3 +-\n README.md                       |  17 ++++---\n css/style.css                   |  44 ++++++++++++----\n index.html                      |  52 +++----------------\n js/app.js                       | 178 -----------------------------------------------------------------\n package.json                    |  31 ++++++++++--\n src/App.vue                     |  28 +++++++++++\n src/Event.js                    |   3 ++\n src/components/Footer.vue       |  45 +++++++++++++++++\n src/components/Header.vue       |  16 ++++++\n src/components/Main.vue         |  74 +++++++++++++++++++++++++++\n src/components/main/Board.vue   |  66 ++++++++++++++++++++++++\n src/components/main/Results.vue |  40 +++++++++++++++\n src/components/main/State.vue   |  25 +++++++++\n src/game/Board.js               |  54 ++++++++++++++++++++\n src/game/Config.js              |   5 ++\n src/game/Game.js                |  26 ++++++++++\n src/game/Snake.js               |  97 +++++++++++++++++++++++++++++++++++\n src/main.js                     |   7 +++\n webpack.config.js               |  78 +++++++++++++++++++++++++++++\n yarn.lock                       | 129 -----------------------------------------------\n 21 files changed, 644 insertions(+), 374 deletions(-)\n\n\nYou can download this 0.3 pre release from github\n[https://github.com/gustawdaniel/snake_js/releases/tag/v0.3].\n\nCode presentation\nProject is organised in the following files\n\n.\n├── css\n│   └── style.css\n├── index.html\n├── LICENSE\n├── package.json\n├── README.md\n├── src\n│   ├── App.vue\n│   ├── components\n│   │   ├── Footer.vue\n│   │   ├── Header.vue\n│   │   ├── main\n│   │   │   ├── Board.vue\n│   │   │   ├── Results.vue\n│   │   │   └── State.vue\n│   │   └── Main.vue\n│   ├── Event.js\n│   ├── game\n│   │   ├── Board.js\n│   │   ├── Config.js\n│   │   ├── Game.js\n│   │   └── Snake.js\n│   └── main.js\n└── webpack.config.js\n\n\nWe presents also statistics of code lines number\n\ncloc $(git ls-files)\n      20 text files.\n      20 unique files.                              \n      11 files ignored.\n\n-------------------------------------------------------------------------------\nLanguage                     files          blank        comment           code\n-------------------------------------------------------------------------------\nJavascript                       7             25              2            243\nCSS                              1              9              0             49\nHTML                             1              3              0             10\n-------------------------------------------------------------------------------\nSUM:                             9             37              2            302\n-------------------------------------------------------------------------------\n\n\nIndex and styles\nLets start from css. We removed colors form JavaScript config and now colors are\ndefined in CSS\nand cant displaying of snake or apple on map is controlled by classes, not\ninline styles. We introduced\nalso some flex rules. If you do not know flex, I strongly recommend to learn it.\nFlex fixes many\nproblems that css with position absolute/relative has.\n\n> css/style.css\n\n\n#map .row {\n    text-align: center;\n}\n\n.rect {\n    width: 30px;\n    height: 30px;\n    background-color: #dca6d1;\n    display: inline-block;\n    margin: 2px;\n}\n\n.rect.out-map {\n    background-color: #c1d0dc;\n}\n.rect.snake-0 {\n    background-color: #8165f3;\n}\n.rect.snake-1 {\n    background-color: #eff36a;\n}\n.rect.apple {\n    background-color: #97dcd5;\n}\n\n.info {\n    border: 1px solid black;\n    padding: 7px;\n    margin-bottom: 1em;\n    text-align: center;\n    justify-content: space-between;\n    display: flex;\n}\n\nmain .logs {\n    display: flex;\n    justify-content: space-evenly;\n}\n\nmain .logs tr.best{\n    background-color: whitesmoke;\n}\n\nmain .logs tr.best td.points{\n    font-weight: bold;\n}\n\nmain .history {\n    border: 1px solid black;\n    padding: 7px;\n    margin: 2vh 5px 0 5px;\n    width: 100%;\n\n}\n\nmain .history table {\n    width: 100%;\n}\n\n\nNow because of we applied Vue, index.html is much smaller.\n\n> index.html\n\n\n<html>\n<head>\n    <title>Snake - game dedicated for Sylwia Daniecka!</title>\n    <link rel=\"stylesheet\" href=\"css/style.css\">\n</head>\n<body>\n\n    <div id=\"app\"></div>\n\n    <script src=\"dist/build.js\"></script>\n\n</body>\n</html>\n\n\nWe do not have file dist/build.js in this project but it is builded by webpack.\nYou can see in Readme\nthat to run project we use now npm run dev command. It is more standard.\n\n> README.md\n\n\n# snake_js\nSnake game written in javascript using objects. \n\n\n# Instaltion\n\n    # install dependencies\n    yarn\n\n    # serve with hot reload at localhost:8080\n    npm run dev\n\n    # build for production with minification\n    npm run build\n\n# Game\n\nTo game run\n\n    firefox localhost:8080\n    \nPres space to start and use arrows to control snake first snake or `WSAD` to control second one. \n\n[![Zrzut_ekranu_z_2018-02-18_04-36-10.png](https://i.imgur.com/fnkcp2e.png)](https://i.imgur.com/fnkcp2e.png)\n\n\nWhat means npm run dev? We can see it in package.json file\n\n> package.json\n\n\n{\n  \"name\": \"snake_js\",\n  \"description\": \"Simple javascript snake game.\",\n  \"version\": \"0.3.0\",\n  \"main\": \"index.js\",\n  \"repository\": \"git@github.com:gustawdaniel/snake_js.git\",\n  \"author\": \"Daniel Gustaw <gustaw.daniel@gmail.com>\",\n  \"license\": \"MIT\",\n  \"private\": true,\n  \"scripts\": {\n    \"dev\": \"cross-env NODE_ENV=development webpack-dev-server --open --hot\",\n    \"build\": \"cross-env NODE_ENV=production webpack --progress --hide-modules\"\n  },\n  \"dependencies\": {\n    \"vue\": \"^2.5.11\"\n  },\n  \"browserslist\": [\n    \"> 1%\",\n    \"last 2 versions\",\n    \"not ie <= 8\"\n  ],\n  \"devDependencies\": {\n    \"babel-core\": \"^6.26.0\",\n    \"babel-loader\": \"^7.1.2\",\n    \"babel-preset-env\": \"^1.6.0\",\n    \"babel-preset-stage-3\": \"^6.24.1\",\n    \"cross-env\": \"^5.0.5\",\n    \"css-loader\": \"^0.28.7\",\n    \"file-loader\": \"^1.1.4\",\n    \"imports-loader\": \"^0.8.0\",\n    \"live-server\": \"^1.2.0\",\n    \"vue-loader\": \"^13.0.5\",\n    \"vue-template-compiler\": \"^2.4.4\",\n    \"webpack\": \"^3.6.0\",\n    \"webpack-dev-server\": \"^2.9.1\"\n  }\n}\n\n\nYou can see that this is hot reload webpack dev server with environmental\nvariable NODE_ENV set as development.\nWe come back to webpack configuration later. Now I would like to mention about\nlast basic static file that\nwas added to project - LICENCE. I decided to use MIT Licence.\n\nES6 modules\nOld file js/app.js is now divided into for files src/game/Board.js, \nsrc/game/Config.js, src/game/Game.js\nand src/game/Snake.js.\n\nConfig\nConfig is simplified. We removed colors from this file. Time again is shorted\nfrom half second to 200 ms.\n\n> src/game/Config.js\n\n\nexport default {\n    mapWidth: 10,\n    mapHeight: 10,\n    roundTime: 200\n};\n\n\nSnake\nSnake absorbed some game methods. For example game over for single player was\nmor connected with\nstate of game, but now it is game over for given snake and do not breaks game of\nhis competitor.\n\nSnake gets also new class world from ES6 and real constructor. There are also\nfootpring from\nprevious version (method init) but it shows advantage of Vue - progressive\napproach that allows\nbut not forces applying Vue methods of update frontend.\n\nLast change is connected with logging. Any snake has his own array of logs, so\nlogs was ealier\nonly in html, without connection with data model, now logs are stored in data\nmodel and are\nassigned to snake, not to all game.\n\n> src/game/Snake.js\n\n\nimport config from './Config';\nimport Board from './Board';\nimport game from './Game';\n\nexport default class Snake {\n    constructor(index,body,direction) {\n        this.index = index;\n        this.points = 0;\n        this.body = body;\n        this.direction = direction; // right, left, up, down,\n        this.inGame = false; // check if snake goes to game area, when snake fail hi is out of game, when enter to game area hi is in game\n        this.age = 0; // TODO increment snake age\n        this.initialConfig = {\n            body: body.slice(),\n            direction: direction\n        };\n        this.logs = [];\n    }\n\n    init() {\n        this.draw();\n    }\n\n    containsCoordinates(inspected) {\n        return this.body.filter(function (part) {\n            return part.x === inspected.x && part.y === inspected.y }).length\n    }\n\n    draw() {\n        this.body.forEach((part) => {\n            document.querySelector(`div.rect[data-x=\"${part.x}\"][data-y=\"${part.y}\"]`).classList.add(`snake-${this.index}`);\n        })\n    }\n\n    move(direction) {\n        let head = Object.assign({}, this.body[0]);\n        switch (direction) {\n            case \"up\":\n                head.x = head.x -1; break;\n            case \"down\":\n                head.x = head.x + 1; break;\n            case \"left\":\n                head.y = head.y - 1; break;\n            case \"right\":\n                head.y = head.y + 1; break;\n        }\n        if (Board.outOfExtendedMap(head) || this.inGame && (Board.outOfMap(head) || this.containsCoordinates(head))) {\n            this.gameOver();\n        } else {\n            if(!this.inGame && !Board.outOfMap(head)) { this.inGame = true; }\n\n            this.body.unshift(head);\n            document.querySelector(`div.rect[data-x=\"${head.x}\"][data-y=\"${head.y}\"]`).classList.add(`snake-${this.index}`);\n            if (!this.eatApple()) {\n                let mapCoordinates = this.body.pop();\n                document.querySelector(`div.rect[data-x=\"${mapCoordinates.x}\"][data-y=\"${mapCoordinates.y}\"]`)\n                    .classList.remove(`snake-${this.index}`);\n            }\n        }\n    }\n\n    eatApple() {\n        if(game.map.apples.filter((part) => {\n            return part.x === this.body[0].x && part.y === this.body[0].y }).length\n        ) {\n\n            this.points ++;\n            game.map.removeApple(this.body[0]);\n            game.map.addApple();\n            return true;\n        }\n    }\n\n    gameOver() {\n        game.map.clearPositions(this.body);\n        this.logResult();\n        this.age = 0;\n        this.points = 0;\n        this.inGame = false;\n        this.body = this.initialConfig.body.slice(); // fastest way of cloning array https://stackoverflow.com/questions/3978492/javascript-fastest-way-to-duplicate-an-array-slice-vs-for-loop\n        this.direction =  this.initialConfig.direction;\n\n        this.body.forEach(el => document.querySelector(`div.rect[data-x=\"${el.x}\"][data-y=\"${el.y}\"]`).classList.add(`snake-${this.index}`));\n    }\n\n    logResult() {\n\n        if(this.inGame) {\n            this.logs.unshift({\n                now: performance.now().toFixed(2),\n                points: this.points,\n                age: this.age,\n                counter: game.counter\n            });\n        }\n    }\n};\n\nBoard\nBoard lost some of his responsibility. For example displaying apples are totally\nout of this code. In\nBoard object we only adding apples or removing them. For communication with\nlayer of view, there is\nresponsible Vue.\n\nBut because of two snakes will play together map changed schape. Now it is\ndivided into game area 10x10\nand on the left area of spawn first snake, finally on the right area of spawn\nsecond snake.\n\n> src/game/Board.js\n\n\nimport config from './Config';\nimport game from './Game';\n\nexport default class Board {\n    constructor() {\n        this.width = config.mapWidth;\n        this.height = config.mapHeight;\n        this.apples = [];\n    }\n\n    addApple() {\n        let apple = {\n            x: Math.floor(Math.random() * this.width),\n            y: Math.floor(Math.random() * this.height)\n        };\n       if(game.snakes[0].containsCoordinates(apple) || game.snakes[1].containsCoordinates(apple)) { // apple is on snake  then repeat\n           this.addApple();\n       } else {\n           this.apples.push(apple);\n       }\n    }\n\n    removeApple(toRemove) {\n\n        this.apples = this.apples.filter((apple) => {\n            return apple.x !== toRemove.x && apple.y !== toRemove.y\n        });\n    }\n\n    static outOfMap(inspected) {\n        return inspected.x < 0 || inspected.x >= config.mapWidth\n            || inspected.y < 0 || inspected.y >= config.mapHeight;\n    }\n\n    static outOfExtendedMap(inspected) {\n        return inspected.x < 0 || inspected.x >= config.mapWidth\n            || inspected.y < 0-3 || inspected.y >= config.mapHeight+3;\n    }\n\n    clearPositions(positions) {\n        positions.forEach(position => {\n            const el = document.querySelector(`div.rect[data-x=\"${position.x}\"][data-y=\"${position.y}\"]`);\n            el.classList.remove('snake-0');\n            el.classList.remove('snake-1');\n        });\n    }\n\n    init() {\n        console.log(game.snakes[0]);\n        game.snakes[0].init();\n        game.snakes[1].init();\n        this.addApple()\n    }\n}\n\n\nGame\nGame object is extremely simplified. All logic connected with event handling is\ndelegated to Vue component.\nGame over is placed in Snake instances. In this case all program always use one\ninstance of game so we do\nnot need use new keyword. Game defines two snakes and give then in constructor\ninitial parameters.\n\nimport Snake from './Snake';\nimport Board from './Board';\n\nexport default {\n    counter: 0,\n    timeout: undefined,\n    snakes: [\n        new Snake(0,[{x:9,y:-3}],\"up\"), // ,{x:8,y:-3},{x:7,y:-3}\n        new Snake(1,[{x:0,y:12}],\"down\") // ,{x:1,y:12},{x:2,y:12}\n    ],\n    map: new Board(),\n    state: \"paused\",\n    run: function () {\n       this.snakes[0].move(this.snakes[0].direction);\n       this.snakes[1].move(this.snakes[1].direction);\n    },\n    init: function () {\n        this.reset();\n    },\n    reset: function () {\n        this.counter = 0;\n        this.state = 'paused';\n        this.map.init();\n    }\n};\n\n\nVue\nNow there is time to present role of Vue framework in this project. Entry point\nfor webpack is selected as\ncat src/main.js so I will start from this file\n\n> cat src/main.js\n\n\nimport Vue from 'vue'\nimport App from './App.vue'\n\nnew Vue({\n    el: '#app',\n    render: h => h(App)\n});\n\n\nIf you rememver package.json Vue is only dependency in production environment.\nWe import them and use\nto create new Vue instance connected with #app element from index.html and we\nsee that there rendered\ncomponent App\n\n> src/App.vue\n\n\n<template>\n\n    <div id=\"app\">\n\n        <Header></Header>\n\n        <Main></Main>\n\n        <Footer></Footer>\n\n    </div>\n\n</template>\n\n<script>\n\n    import Footer from './components/Footer.vue';\n    import Header from './components/Header.vue';\n    import Main from './components/Main.vue';\n\n    export default {\n        name: 'app',\n        components: {\n            Header, Main, Footer\n        }\n    }\n\n</script>\n\n\nThis component only assembly components Header, Main and Footer and place them\nin one view.\n\nHeader is dedicated for inventor of this project\n\n> src/components/Header.vue\n\n\n<template>\n\n    <header>\n        <h1>I love Sylwia <3</h1>\n        <p>To start or pause press space</p>\n    </header>\n\n</template>\n\n<script>\n\n    export default {\n        name: \"Header\"\n    }\n\n</script>\n\n\nFooter contains change log and ideas to introduce in future.\n\n> src/components/Footer.vue\n\n\n<template>\n    <footer>\n        <hr>\n        <h4>Future (proposed)</h4>\n        <ol>\n            <li><strong>Add network gaming</strong></li>\n            <li>Use sass instead of css</li>\n            <li>Add CI</li>\n            <li>Add bad apples</li>\n            <li>Add tests</li>\n            <li>Add user account</li>\n            <li>Special color of head</li>\n            <li>Fix bug connected with changes direction many time in one round that allow bump int snake with length 3</li>\n            <li>Add login by google</li>\n            <li>Add sounds</li>\n            <li>Make it mobile friendly (how to swipe when we have two snakes?)</li>\n            <li>Fix bug connected with appearing simultaneously many apples (probably fixed)</li>\n        </ol>\n        <h4>Change Log</h4>\n        <h5>v0.3</h5>\n        <ol>\n            <li style=\"text-decoration: line-through\">Add webpack</li>\n            <li style=\"text-decoration: line-through\">Create snake as module</li>\n            <li style=\"text-decoration: line-through\">Add two players</li>\n        </ol>\n        <h5>v0.2</h5>\n        <ol>\n            <li style=\"text-decoration: line-through\">Add apples</li>\n            <li style=\"text-decoration: line-through\">Add boundaries</li>\n            <li style=\"text-decoration: line-through\">Add scores</li>\n        </ol>\n        <h5>v0.1</h5>\n        <ol>\n            <li style=\"text-decoration: line-through\">Add map</li>\n            <li style=\"text-decoration: line-through\">Add snake</li>\n            <li style=\"text-decoration: line-through\">Add events</li>\n        </ol>\n    </footer>\n</template>\n\n<script>\n    export default {\n        name: 'Footer'\n    }\n</script>\n\n\nSo most interesting is Main. Main again contains three childrens but has also\nsome logic. When main is\nmounted there is executed method game.init(), when is created event listeners\nare added. Now for 9, not\n5 buttons. Pause is still allowed.\n\n> src/components/Main.vue\n\n\n<template>\n    <main>\n        <State></State>\n        <Board></Board>\n        <Results></Results>\n    </main>\n</template>\n\n<script>\n\n    import State from './main/State.vue'\n    import Board from './main/Board.vue'\n    import Results from './main/Results.vue'\n    import Event from '../Event';\n\n    import game from '../game/Game';\n    import config from '../game/Config';\n\n    export default {\n        name: \"Main\",\n        data() {\n            return {\n                game\n            }\n        },\n        mounted() {\n            game.init();\n        },\n        components: {\n            State, Board, Results\n        },\n        created() {\n            window.addEventListener('keydown', (e) => {\n                console.log({key: e.key, code: e.keyCode});\n                switch (e.key) {\n                    case \"ArrowUp\":\n                        game.snakes[0].direction = game.snakes[0].direction === \"down\" || game.state === \"paused\" ? game.snakes[0].direction : \"up\"; break;\n                    case \"ArrowDown\":\n                        game.snakes[0].direction = game.snakes[0].direction === \"up\" || game.state === \"paused\" ? game.snakes[0].direction : \"down\"; break;\n                    case \"ArrowLeft\":\n                        game.snakes[0].direction = game.snakes[0].direction === \"right\" || game.state === \"paused\" ? game.snakes[0].direction : \"left\"; break;\n                    case \"ArrowRight\":\n                        game.snakes[0].direction = game.snakes[0].direction === \"left\" || game.state === \"paused\" ? game.snakes[0].direction : \"right\"; break;\n                    case \"w\":\n                        game.snakes[1].direction = game.snakes[1].direction === \"down\" || game.state === \"paused\" ? game.snakes[1].direction : \"up\"; break;\n                    case \"s\":\n                        game.snakes[1].direction = game.snakes[1].direction === \"up\" || game.state === \"paused\" ? game.snakes[1].direction : \"down\"; break;\n                    case \"a\":\n                        game.snakes[1].direction = game.snakes[1].direction === \"right\" || game.state === \"paused\" ? game.snakes[1].direction : \"left\"; break;\n                    case \"d\":\n                        game.snakes[1].direction = game.snakes[1].direction === \"left\" || game.state === \"paused\" ? game.snakes[1].direction : \"right\"; break;\n                    case \" \":\n                        if(game.state === 'paused') {\n                            game.state = 'active';\n                            game.timeout = game.timeout || setInterval(() => {\n                                game.counter ++;\n                                game.snakes.forEach(s => s.age++);\n                                game.run();\n                            },config.roundTime);\n                        } else {\n                            game.state = 'paused';\n                            clearInterval(game.timeout);\n                            game.timeout = undefined;\n                        }\n                }\n                if([\" \", \"ArrowUp\", \"ArrowDown\", \"ArrowLeft\", \"ArrowRight\"].indexOf(e.key) > -1) {\n                    e.preventDefault();\n                }\n            });\n        }\n    };\n\n\n</script>\n\n\nThere is also one interesing element Event - instance of vue used to proxy\nevents between poorly related\nVue components.\n\n> src/Event.js\n\n\nimport Vue from 'vue';\n\nexport default Event = new Vue();\n\n\nCome back to Main and look into his children. Lets start from State. Now state\nis directly binded\ninto view and updated on any change of game object - practically any turn.\n\n> src/components/main/State.vue\n\n\n<template>\n    <div class=\"info center\">\n        <span>{{game.snakes[0].points}}<br>{{game.snakes[0].age}}</span>\n        <span>{{state}}<br>{{game.counter}}</span>\n        <span>{{game.snakes[1].points}}<br>{{game.snakes[1].age}}</span>\n    </div>\n</template>\n\n<script>\n    import game from '../../game/Game';\n\n    export default {\n        name: \"State\",\n        data() {\n            return {\n                game\n            }\n        },\n        computed: {\n            state() {\n                return game.state.toUpperCase();\n            }\n        }\n    }\n</script>\n\n\nBoard is more complicated. We create double loop to create .rect divs. We use \n:ref property to prevent\nof searching these elements any time when changes are done.\n\n> src/components/main/Board.vue\n\n\n<template>\n    <div id=\"map\" v-if=\"show\">\n        <div v-for=\"i in range('rows')\" class=\"row\">\n            <div v-for=\"j in range('cols')\" class=\"rect\" :class=\"isOutMap(j)\" :data-x=\"i\" :data-y=\"j\" :ref=\"cordsToIndex(i,j)\"></div>\n        </div>\n    </div>\n</template>\n\n<script>\n\n    import Event from '../../Event';\n    import game from '../../game/Game';\n\n    export default {\n        name: \"Board\",\n        data() {\n            return { show:true, game: game }\n        },\n        computed: {\n            apples() {\n                return this.game.map.apples;\n            }\n        },\n        methods: {\n            indexToCords(index) {\n                return { x: index.splice(\"_\")[0], y: index.splice(\"_\")[1] };\n            },\n            cordsToIndex(i, j) {\n                return `${i}_${j}`;\n            },\n            isOutMap(j) {\n                return j<0 || j>=10 ? \"out-map\" : \"\";\n            },\n            range(direction) {\n                if(direction === 'rows') {\n                    return (new Array(10)).fill(1).map((e, i)=>{return i})\n                } else if(direction === 'cols') {\n                    return (new Array(10+6)).fill(1).map((e, i)=>{return i-3})\n                } else {\n                    throw new Error(\"not known direction, possible: rows and cols\");\n                }\n            },\n            rerender(){\n                this.show = false;\n                this.$nextTick(() => {\n                    this.show = true;\n                    console.log('re-render start');\n                    this.$nextTick(() => {\n                        console.log('re-render end')\n                    })\n                })\n            }\n        },\n        created: function () {\n            Event.$on(\"reset_map\", () => {\n                this.rerender();\n            });\n        },\n        watch: {\n            apples: function(n, o) {\n                o.forEach(a => this.$refs[this.cordsToIndex(a.x,a.y)][0].classList.remove('apple'));\n                n.forEach(a => this.$refs[this.cordsToIndex(a.x,a.y)][0].classList.add('apple'));\n            }\n        }\n    }\n</script>\n\n\nFinally last component - Results.vue that presents historical resluts of players\nand make bold best\nscores of player.\n\n> src/components/main/Results.vue\n\n\n<template>\n\n    <div class=\"logs\">\n        <div v-for=\"list in logs\" class=\"history\">\n            <table>\n                <thead>\n                    <tr><th>Age</th><th>Counter</th><th>Points</th><th>Time</th><th>Age/Points</th></tr>\n                </thead>\n                <tbody>\n                    <tr v-for=\"log in list\" :class=\"best(list,log.points)\">\n                        <td>{{log.age}}</td>\n                        <td>{{log.counter}}</td>\n                        <td class=\"points\">{{log.points}}</td>\n                        <td>{{log.now}}</td>\n                        <td v-text=\"(log.age / log.points).toFixed(2)\"></td>\n                    </tr>\n                </tbody>\n            </table>\n        </div>\n    </div>\n</template>\n\n<script>\n    import game from '../../game/Game';\n\n    export default {\n        name: \"Results\",\n        data() {\n            return {\n                logs: game.snakes.map(s => s.logs)\n            }\n        },\n        methods: {\n            best(list, points) {\n                console.log(\"LIST\",list, points);\n                return Math.max(...(list.map(l => l.points))) === points ? \"best\" : \"\"\n            }\n        }\n    }\n</script>\n\n\nThere are presented all files from src directory. It is time to present method\nod building project\nconfigured in webpack.config.js\n\nWebpack\nWe use standard webpack proposed by Vue framework.\n\nconst path = require('path');\nconst webpack = require('webpack');\n\nmodule.exports = {\n    entry: './src/main.js',\n    output: {\n        path: path.resolve(__dirname, './dist'),\n        publicPath: '/dist/',\n        filename: 'build.js'\n    },\n    module: {\n        rules: [\n            {\n                test: /\\.css$/,\n                use: [\n                    'vue-style-loader',\n                    'css-loader'\n                ],\n            },      {\n                test: /\\.vue$/,\n                loader: 'vue-loader',\n                options: {\n                    loaders: {\n                    }\n                    // other vue-loader options go here\n                }\n            },\n            {\n                test: /\\.js$/,\n                loader: 'babel-loader',\n                exclude: /node_modules/\n            },\n            {\n                test: /\\.(png|jpg|gif|svg)$/,\n                loader: 'file-loader',\n                options: {\n                    name: '[name].[ext]?[hash]'\n                }\n            }\n        ]\n    },\n    resolve: {\n        alias: {\n            'vue$': 'vue/dist/vue.esm.js'\n        },\n        extensions: ['*', '.js', '.vue', '.json']\n    },\n    devServer: {\n        historyApiFallback: true,\n        noInfo: true,\n        overlay: true\n    },\n    performance: {\n        hints: false\n    },\n    devtool: '#eval-source-map'\n};\n\nif (process.env.NODE_ENV === 'production') {\n    module.exports.devtool = '#source-map';\n    // http://vue-loader.vuejs.org/en/workflow/production.html\n    module.exports.plugins = (module.exports.plugins || []).concat([\n        new webpack.DefinePlugin({\n            'process.env': {\n                NODE_ENV: '\"production\"'\n            }\n        }),\n        new webpack.optimize.UglifyJsPlugin({\n            sourceMap: true,\n            compress: {\n                warnings: false\n            }\n        }),\n        new webpack.LoaderOptionsPlugin({\n            minimize: true\n        })\n    ])\n}\n\n\nNow we can attach screen shot from game.\n\n [https://i.imgur.com/fnkcp2e.png]\n\nHappy eating apples. I hope next version will allow to real multiplayer network\ngame. If do you think any\nfeature out of this list\n\n 1.  Add network gaming\n 2.  Use sass instead of css\n 3.  Add CI\n 4.  Add bad apples\n 5.  Add tests\n 6.  Add user account\n 7.  Special color of head\n 8.  Fix bug connected with changes direction many time in one round that allow\n     bump int snake with length 3\n 9.  Add login by google\n 10. Add sounds\n 11. Make it mobile friendly (how to swipe when we have two snakes?)\n 12. Fix bug connected with appearing simultaneously many apples (probably\n     fixed)\n\nwould be nice, please don't hesitate and add comment :D",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:46:48.000Z",
            "updated_at": "2021-04-20T20:48:16.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f3ec02fb35425592d0c10",
            "uuid": "d499274f-5469-4985-873b-c44206f31e89",
            "title": "Badanie wydajności insertów mysql",
            "slug": "badanie-wydajnosci-insertow-mysql",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## Struktura bazy danych\\n\\nInteresuje nas przerzucanie danych między dwiema identycznymi tabelami, które mają powiązania przez więzy integralności referencyjnej z kilkoma mniejszymi tabelami. Nasza baza danych będzie więc przypominała pajęczynę, w której dwie duże tabele będą odnosić się `n` kluczami do `n` mniejszych nie powiązanych tabel. Główne tabela nazwiemy `main_1` i `main_2`, a mniejsze `minor_1`, `minor_2`, ... `minor_n`. Ponieważ obraz mówi więcej niż tysiąc słów załączam diagram hierarchiczny bazy:\\n\\n![struktura_hierarchiczna](http://i.imgur.com/8z63XFy.png)\\n\\nA dla wyjaśnienia, dlaczego początkowo wyobrażałem sobie tą bazę jak pajęczynę, prezentuję też diagram organiczny tej samej bazy.\\n\\n![struktura_organiczna](http://i.imgur.com/jaxTv9m.png)\\n\\nWłaściwie, to te duże tabele będą miały poważne problemy z optymalnością insertów dokładnie tak jak by było w sieci pająka...\\n\\nWracając do konkretów, ponieważ optymalność nie będzie testowana na mniejszych tabelach, nie dostaną one kluczy obcych, a więc to od nich zaczniemy stawianie bazy. Będą one zawierały tylko jedno pole - `id` będące ich kluczem głównym. Po ich utworzeniu będą tworzone tabele główne, i dopiero wtedy będziemy im dodawać klucze obce.\\n\\n## Tworzenie tabel\\n\\nKiedy kończyłem pisać wpis o [testowaniu selektów](http://blog.gustawdaniel.pl/2016/12/02/tesseract-ocr-i-testowanie-selekt%C3%B3w.html) za pomocą Behata, nie byłem zbyt zadowolony z pisania scenariuszy, które różniły się tylko liczbą atrybutów, lub warunków. Mimo, że bardzo wygodny dla osób nie technicznych, `Gherkin` nie dawał mi wystarczającej elastyczności. Podobnie czułem się [pisząc procedury](http://blog.gustawdaniel.pl/2016/12/08/testowanie-szybko%C5%9Bci-selekt%C3%B3w.html) w czystym `SQL`. Brak dziedziczenia sprawiał, że musiałem kopiować kod, a tego bardzo nie lubię.\\n\\nZupełnie inaczej jest tym razem. Całość kodu odpowiedzialnego za tworzenie całej tej bazy danych i wystawienie do tego prymitywnego, ale funkcjonalnego `API` mieści się w 100 liniach kodu. \\n\\nNaszą zabawę możemy zacząć od usunięcia katalogu `Resources` z `app/config`. Nasz kontroler będzie rozmawiał w `jsonie`, więc widoki nie będą nam potrzebne. Przechodzimy do edycji kontrolera. Zaczynamy od dołączenia bibliotek:\\n\\n> src/AppBundle/Controller/DefaultController.php\\n\\n```php\\n<?php\\n\\nnamespace AppBundle\\\\Controller;\\n\\nuse Sensio\\\\Bundle\\\\FrameworkExtraBundle\\\\Configuration\\\\Route;\\nuse Symfony\\\\Bundle\\\\FrameworkBundle\\\\Controller\\\\Controller;\\nuse Symfony\\\\Component\\\\HttpFoundation\\\\JsonResponse;\\nuse Doctrine\\\\DBAL\\\\Schema\\\\Schema;\\nuse Doctrine\\\\DBAL\\\\Schema\\\\Comparator;\\nuse Doctrine\\\\DBAL\\\\Schema\\\\Table;\\n```\\n\\nMamy tu `Route` odpowiadające za przypisywanie adnotacjom przy akcjach odpowiednich ścieżek w routingu. Jest `Controller`, który pozwala nam odnosić się do wszystkich najbardziej podstawowych funkcji `Symfony` przez `$this`. Następnie `JsonResponse` łączący działanie funkcji `json_decode` z jednoczesnym ustawianiem nagłówka na `application/json`. Trzy kolejne to paczki `Doctrine`, które odpowiednio tłumaczą jego `api` na `SQL` i dostarczają obiekty `Doctrine`.\\n\\nWewnątrz kontrolera będą istnieć dwie zmienne prywatne będące tablicami tabel `main` i `minor` oraz liczba określające ile tabel typu `minor` ma występować.\\n\\n```php\\nclass DefaultController extends Controller\\n{\\n    /**\\n     * @var Table[]\\n     */\\n    private $main, $minor;\\n\\n    private $N;\\n\\n    public function __construct()\\n    {\\n        $this->main = [];\\n        $this->minor = [];\\n        $this->N = 10;\\n    }\\n```\\n\\nKonstruktor ustawia `$minor` i `$main` jako puste tablice, a domyślną liczbę tabel na `10`. Klasa `Table` jest jednym z obiektów `doctrine`, które dopiero co załączyliśmy. Obsługę tej klasy zobaczymy za chwilę w funkcji tworzącej schemat jednej z tabel.\\n\\n```php\\n    /**\\n     * @param $schema Schema\\n     */\\n    private function appendMinorToSchema($schema)\\n    {\\n        for($i=1;$i<=$this->N;$i++) {\\n            $this->minor[$i] = $schema->createTable(\\\"minor_\\\".$i);\\n            $this->minor[$i]->addColumn(\\\"id\\\", \\\"integer\\\");\\n            $this->minor[$i]->setPrimaryKey(array(\\\"id\\\"));\\n        }\\n    }\\n```\\n\\nJak wspominałem wcześniej zaczynamy od tworzenia mniejszych tabel. Ponieważ ma być ich `N`, właśnie to tej wielkości ustawiona jest pętla. Wewnątrz do zmiennej zawierającej tabele `$minor` przypisujemy wynik metody `creteTable` na schemacie, który będzie podany jako argument. Schemat odpowiada temu jak `doctrine` rozumie strukturę bazy danych w ramach swoich własnych klas. Tworzonej tabeli przypisywany jest atrybut będący kluczem głównym. To wystarczy. Odrobinę bardziej złożoną logikę ma tworzenie dużych tabel.\\n\\n```php\\n    /**\\n     * @param $schema Schema\\n     */\\n    private function appendMainToSchema($schema)\\n    {\\n        for($i=1;$i<=2;$i++)\\n        {\\n            $this->main[$i] = $schema->createTable(\\\"main_\\\".$i);\\n            $this->main[$i]->addColumn(\\\"id\\\", \\\"integer\\\");\\n            for($j=1;$j<=$this->N;$j++)\\n            {\\n                $this->main[$i]->addColumn(\\\"minor_\\\".$j.\\\"_id\\\", \\\"integer\\\");\\n                $this->main[$i]->addForeignKeyConstraint($this->minor[$j], array(\\\"minor_\\\".$j.\\\"_id\\\"), array(\\\"id\\\"));\\n            }\\n            $this->main[$i]->setPrimaryKey(array(\\\"id\\\"));\\n        }\\n    }\\n```\\n\\nPonieważ są dwie, pętla główna przebiega tylko wartości `1` i `2`. Tak jak poprzednio do schematu dodawane są tabele, oraz kolumna o nazwie `id`, która zostanie u nas kluczem głównym. Nie dostała ona `auto_increment` bo będziemy ją ustawiać w zewnętrznym skrypcie. \\n\\nPo dodaniu bazowego atrybutu - `id` do tabeli rozpoczynamy pętlę po mniejszych tabelach, w której podpinamy kolumnę i przypisujemy jej więzy integralności referencyjnej. Na ustanawiamy `id` kluczem głównym.\\n\\nNa tym się kończy lista zmiennych i metod. Jak w zwykłych skryptach, przechodzimy do ciała programu.\\n\\n```php\\n    /**\\n     * @Route(\\\"/\\\", name=\\\"home\\\")\\n     * @Route(\\\"/do/{n}\\\")\\n     */\\n    public function indexAction($n=10,$action=\\\"do\\\")\\n    {\\n        if($n){ $this->N = $n; }\\n        $conn = $this->getDoctrine()->getConnection();\\n```\\n\\nRouting pozwala nam wybrać domyślną ścieżkę `/`, albo określić akcję i wybrać dla niej argument. Na tym etapie będziemy mieli dwie akcje - `show` i `do`. Show będzie jedynie wyświetlało kod `SQL` jaki trzeba wykonać, aby obecny stan bazy przekształcić do posiadającego `n` małych tabel, a `do` będzie nie tylko pokazywać, ale też wykonywać ten kod. Jak łatwo zgadnąć, `n` jest właśnie liczbą tabel i nadpisuje domyślne `10` z konstruktora. Na końcu tego kodu tworzymy połączenie z bazą danych i zapisujemy jego reprezentację do zmiennej `$conn`. Teraz przygotujemy schemat.\\n\\n```php\\n        $schema = new Schema();\\n\\n        $this->appendMinorToSchema($schema);\\n        $this->appendMainToSchema($schema);\\n```\\n\\nSchemat, czyli to jak `doctrine` rozumie strukturę bazy tworzymy w trzech linijkach. Czas porównać go z obecnym stanem bazy.\\n\\n```php\\n        $comparator = new Comparator();\\n        $queries = $comparator->compare($conn->getSchemaManager()->createSchema(), $schema)->toSql($conn->getDatabasePlatform());\\n\\n```\\n\\nDzięki obiektom `Comparator` oraz `ShemaManager` otrzymanie tablicy z zapytaniami `SQL` aktualizującymi naszą strukturę bazy mieści się w dwóch liniach. Zostało już tylko wykonanie tych zapytań, jeśli `action` ustawione jest na `do`.\\n\\n```php\\n        if($action==\\\"do\\\"){\\n            foreach($queries as $query) {\\n                $conn->prepare($query)->execute();\\n            }\\n        }\\n```\\n\\nDzięki metodom pozwalającym wykonywać czyste sqlowe zapytania nasze zadanie sprowadza się do wykonania pętli po nich. Możemy teraz zwrócić użytkownikowi jakiś sensowny komunikat.\\n\\n```php\\n        return new JsonResponse(\\n            [\\n                \\\"alter\\\"=>$queries,\\n            ]\\n        );\\n    }\\n}\\n```\\n\\nNajlepszy wydał mi się `json` z listą zapytań jakie należy wykonać, aby obecny stan bazy przekształcić do zadanego przez parametr `n`. Na koniec dołączam metodę `show`, która świetnie nadaje się do debugowania, ale nie pełni żadnej funkcji poza tym:\\n\\n```php\\n    /**\\n    * @Route(\\\"/show/{n}\\\")\\n    */\\n    public function showAction($n=10)\\n    {\\n        return $this->doAction($n,\\\"show\\\");\\n    }\\n```\\n\\nŻeby móc obsłużyć nasz kontroler postawimy serwer komendą.\\n\\n```bash\\nphp bin/console server:run\\n```\\n\\nI w drugim terminalu wyślemy request http, który wypełni nam bazę tabelami.\\n\\n```\\ntime http -b GET localhost:8000/do/10\\n```\\n\\nJego wykonanie trwało u mnie 3 sekundy, a odpowiedź wyglądała tak:\\n\\n![database_creation](http://i.imgur.com/NQVaaWB.png)\\n\\n## Wypełnianie bazy danymi\\n\\nNadszedł czas wypełnić bazę danymi. Dla małych tabel będą to liczby z przedziału od `1` do `L`. Dla dużych będziemy losować `N` liczb od `1` do `L`, które dodamy do kluczy obcych. Wartość `id` ustawimy na `auto_increment` ale nie z poziomu `sql` tylko przez zewnętrzny skrypt. Poza małymi tabelami wypełnimy tylko tabelę `main_1`, zostawiając `main_2` pustą. Przypominam, że chcemy przetestować klonowanie dużej tabli z dużą ilością kluczy obcych.\\n\\n### Tabele minor\\n\\nZaczniemy od wypełniania małych tabel. Podzielę ten proces na wypełnianie małych i dużej tabeli oddzielnie, ze względu na większą elastyczność takiego podejścia, a po części też dlatego, że da mi to lepszy wgląd w czasy wykonywania poszczególnych procesów. Małe tabele będziemy tworzyć za pomocą następującej akcji w `DefaultController`:\\n\\n```php\\n    /**\\n     * @Route(\\\"/minor/{n}/{l}\\\")\\n     */\\n    public function minorAction($n=10,$l=10)\\n    {\\n        $conn = $this->getDoctrine()->getConnection();\\n        for($i=1;$i<=$n;$i++){\\n            $conn->delete('minor_'.$i,[1=>1]);\\n            for($j=1;$j<=$l;$j++){\\n                $conn->insert('minor_'.$i, array('id' => $j));\\n            }\\n        }\\n        return new  JsonResponse(['n'=>$n, 'l'=>$l]);\\n    }\\n```\\n\\nJest ona wyjątkowo prosta, ale posiada jeden dość ciekawy hak. Chodzi o idempotentność. W metodzie `delete` obiektu `Connection` mamy nazwę tabeli a później tablicę `[1=>1]`. Jest to warunek który w instrukcji `DELETE FROM` występuje za `WHERE`. `1=1` jest zawsze prawdziwe i dlatego przed rozpoczęciem zapisu zostają usunięte zostają wszystkie elementy jednym zapytaniem. Żeby wywołać tą akcję wystarczy wpisać w konsoli:\\n\\n```bash\\ntime http -b GET localhost:8000/minor/10/10\\n```\\n\\nOdpowiedź którą zobaczymy będzie wyglądała tak:\\n\\n```json\\n{\\n    \\\"l\\\": \\\"10\\\", \\n    \\\"n\\\": \\\"10\\\"\\n}\\n```\\n\\n### Dodanie stałych\\n\\nMógł bym kontynuować dodawanie akcji, ale zacząłem martwić się zbytnią powtarzalnością wartości domyślnych. Zanim przejdziemy dalej wprowadzimy w kodzie następujące zmiany. Na początku kontrolera definiujemy stałe:\\n\\n```php\\n    const N = 10;\\n    const L = 10;\\n    const K = 1000;\\n```\\n\\nW konstruktorze ustawiamy `private $N` na:\\n\\n```php\\n        $this->N = self::N;\\n```\\n\\nZmieniamy domyślne wartości w definicjach akcji na następujące:\\n\\n```php\\n    public function doAction($n=self::N,$action=\\\"do\\\")\\n    public function showAction($n=self::N)\\n    public function minorAction($n=self::N,$l=self::L)\\n```\\n\\nDodajemy routingi bez parametrów, czyli \\n\\n```php\\n     * @Route(\\\"/show\\\")\\n```\\n\\nprzed ` * @Route(\\\"/minor/{n}/{l}\\\")` oraz \\n\\n```ph\\n     * @Route(\\\"/minor\\\")\\n```\\n\\nprzed `* @Route(\\\"/main/{n}/{l}/{k}\\\")`\\n\\n### Tabela main\\n\\nDo wypełnienia tabeli `main_1` wykorzystamy następujący kod\\n\\n```php\\n    /**\\n     * @Route(\\\"/main\\\")\\n     * @Route(\\\"/main/{n}/{l}/{k}\\\")\\n     * @Route(\\\"/main/{n}/{l}/{k0}/{k}\\\")\\n     */\\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1)\\n    {\\n        $conn = $this->getDoctrine()->getConnection();\\n        if($k0==1) { $conn->delete('main_1',[1=>1]); }\\n        for($i=$k0;$i<=$k;$i++){                // row in table main\\n            $content = ['id'=>$i];\\n            for($j=1;$j<=$n;$j++){            // foreign key of row\\n                $content['minor_'.$j.'_id'] = rand(1,$l);\\n            }\\n            $conn->insert('main_1', $content);\\n        }\\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\\n    }\\n```\\n\\nJest to akcja która nadaje się zarówno do czyszczenia, nadpisywania, jak i dopisywania do tabeli `main`. Tak duża ogólność została uzyskana dzięki dość ciekawemu routingowi. Zmienne `n` i `l` to odpowiednio liczba tabel typu `minor` oraz liczba ich wierszy. `k` jest maksymalnym indeksem `id` do którego będziemy wypełniać tabelę `main`. `k0` jest indeksem od którego zaczynamy. Jeśli wynosi on 1 lub nie jest podany, zawartość tabeli `main` zostanie skasowana przed dalszym zapisem. \\n\\nTo co się dzieje wewnątrz pętli jest dość przewidywalne. Tworzymy wartość `id` zgodnie z zapowiedzianym schematem (`auto_increment`), losujemy klucze obce, zapisujemy wiersz i przechodzimy dalej. Tej akcji można użyć na kilka sposobów. Na przykład żeby wypełnić tabelę `main_1` dziesięcioma wierszami wpiszemy:\\n\\n```\\ntime http -b GET localhost:8000/main/10/10/10\\n```\\n\\nJeśli chcemy ją wyczyścić:\\n\\n```\\ntime http -b GET localhost:8000/main/10/10/0\\n```\\n\\nTeraz możemy zapisać z powrotem 10 wierszy, ale rozbijając to na dwa kroki:\\n\\n```\\ntime http -b GET localhost:8000/main/10/10/1/5\\ntime http -b GET localhost:8000/main/10/10/6/10\\n```\\n\\nZanim wypełnimy tabelę `main_1` milionami wierszy należy zauważyć, że pierwszą przyczyną dla której szybkość wykonywania insertów jest niezadowalająca jest sprawdzanie poprawności więzów przy każdym zapisie. Celowo nie dodałem transakcji, żebyśmy mogli porównać szybkość wykonywania tego kodu z analogicznym otoczonym transakcją. Wyniki dla `100k` wierszy:\\n\\n| Bez transakcji | Z transakcją |\\n| -------------- | ------------ |\\n| 6m 41.672s     | 0m 57.804s   |\\n\\nTransakcje uzyskamy dzięki następującej modyfikacji ciała akcji `mainAction`:\\n\\n```php\\n        $conn = $this->getDoctrine()->getConnection();\\n        if($k0==1) { $conn->delete('main_1',[1=>1]); }\\n        $conn->beginTransaction();\\n        try{\\n            // loop over rows - exactly the same as before\\n            $conn->commit();\\n        } catch(\\\\Exception $e) {\\n            $conn->rollBack();\\n            throw $e;\\n        }\\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\\n```\\n\\n## Pomiary\\n\\nPonieważ nadszedł czas na wykonywanie pomiarów, warto było by stworzyć dla wyników kolejną tabelę nie połączoną z poprzednimi. Powinna ona zawierać czas, parametry i opis mierzonej funkcjonalności. Jednak dla czystości kodu oddzielimy część generującą tabele od wykonującej akcje. Zależy mi też na pogrupowaniu akcji ze względu na to czy stawiają bazę, czy dokonują na niej pomiarów. Oto nowa struktura katalogów jaką zastosujemy.\\n\\n![katalogi](http://i.imgur.com/HFAxvGJ.png)\\n\\nNasz model odpowiedzialny za tworzeniu schematu bazy będzie miał kod wycięty z prywatnych funkcji i własności `DefaultController` oraz jego konstruktora.\\n\\n> src/AppBundle/Model/SchemaGenerator.php\\n\\n```php\\n<?php\\n\\nnamespace AppBundle\\\\Model;\\n\\nuse AppBundle\\\\Controller\\\\BaseController;\\nuse Doctrine\\\\DBAL\\\\Schema\\\\Schema;\\nuse Doctrine\\\\DBAL\\\\Schema\\\\Table;\\n\\nclass SchemaGenerator\\n```\\n\\nNie zmieni się tam nic poza konstruktorem:\\n\\n```php\\n    public function __construct($n)\\n    {\\n        $this->main = [];\\n        $this->minor = [];\\n        $this->N = $n ? $n : BaseController::N;\\n    }\\n```\\n\\nUstawia on domyślnie `N` na wartość stałej z `BaseController`, albo na wartość podaną przy powoływaniu instancji obiektu. Jak wspomniałem, funkcje `appendMinorToSchema` i `appendMainToSchema` się nie zmieniają. Dochodzi za to funkcja `appendLogToSchema`:\\n\\n```php\\n    /**\\n     * @param $schema Schema\\n     */\\n    private function appendLogToSchema($schema)\\n    {\\n        $log = $schema->createTable(\\\"log\\\");\\n        $log->addColumn(\\\"id\\\", \\\"integer\\\",array(\\\"autoincrement\\\"=>true,\\\"unsigned\\\" => true));\\n        $log->addColumn(\\\"n\\\", \\\"smallint\\\",array(\\\"unsigned\\\" => true));\\n        $log->addColumn(\\\"l\\\", \\\"smallint\\\",array(\\\"unsigned\\\" => true));\\n        $log->addColumn(\\\"k0\\\", \\\"integer\\\",array(\\\"unsigned\\\" => true));\\n        $log->addColumn(\\\"k\\\", \\\"integer\\\",array(\\\"unsigned\\\" => true));\\n        $log->addColumn(\\\"execution_time\\\", \\\"float\\\");\\n        $log->addColumn(\\\"operation\\\", \\\"string\\\",array());\\n        $log->setPrimaryKey(array(\\\"id\\\"));\\n    }\\n```\\n\\nBędzie to tabela przechowująca wyniki pomiarów z parametrami. Wyposażymy nasz generator w jedną funkcję, która zbinduje poprzednie funkcje ze schematem i zwróci nam gotowy schemat.\\n\\n```php\\n    /**\\n     * @return Schema Schema\\n     */\\n    public function generate()\\n    {\\n        $schema=new Schema();\\n\\n        $this->appendMinorToSchema($schema);\\n        $this->appendMainToSchema($schema);\\n        $this->appendLogToSchema($schema);\\n\\n        return $schema;\\n    }\\n```\\n\\nTo wszystko, jeśli chodzi o model. Spójrzmy na kontroler bazowy.\\n\\n```php\\n<?php\\n\\nnamespace AppBundle\\\\Controller;\\n\\nuse Symfony\\\\Bundle\\\\FrameworkBundle\\\\Controller\\\\Controller;\\n\\nclass BaseController extends Controller\\n{\\n    const N = 10;\\n    const L = 10;\\n    const K = 1000;\\n}\\n```\\n\\nJest to nasz kontener na stałe. Sam nie wiem, czy w takim przypadku, nie lepiej było by tego nawet zrobić w parametrach `Symfony`. I pewnie tak zrobię, jeśli dla tego kontrolera nie pojawią się jakieś dodatkowe zastosowania. Tym czasem zostało nam jeszcze dostosowanie `DefaultController`. Przede wszystkim zmieniliśmy jego nazwę (nazwę pliku i klasy) na `PreparationController` aby lepiej odpowiadała jego funkcjonalności. W Metodzie `doAction` usunęliśmy ustawianie zmiennej prywatnej `N` w pierwszej instrukcji warunkowej. Wiąże się to z tym, że wycięliśmy też wszystkie zmienne i funkcje prywatne oraz konstruktor. Trzy linijkową generację schematu zastąpiliśmy linią:\\n\\n```php\\n        $schema = (new SchemaGenerator($n))->generate();\\n```\\n\\nNa koniec zwiększyliśmy jeszcze bardziej elastyczność metody `mainAction`, ze względu na to, że zainteresowało mnie jakie dokładnie różnice robi ustawianie transakcji przy jakich ilościach wierszy. Dodałem też numer tabeli `main` do routingu, jeśli chcaił bym nie ruszając dużej już wypełnionej tabeli, wykonywać testy na tej drugiej.\\n\\n```php\\n    /**\\n     * @Route(\\\"/main\\\")\\n     * @Route(\\\"/main/{n}/{l}/{k}\\\")\\n     * @Route(\\\"/main/{n}/{l}/{k0}/{k}\\\")\\n     * @Route(\\\"/main/{n}/{l}/{k0}/{k}/{main}/{transaction}\\\")\\n     */\\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1,$main=1,$transaction=true)\\n    {\\n        $conn = $this->getDoctrine()->getConnection();\\n        if($k0==1) { $conn->delete('main_'.$main,[1=>1]); }\\n        if($k>1e4) { \\n            set_time_limit(0);\\n            ini_set(\\\"max_execution_time\\\", 0); \\n        }\\n        if($transaction) {$conn->beginTransaction();}\\n        try{\\n            for($i=$k0;$i<=$k;$i++){                // row in table main\\n                $content = ['id'=>$i];\\n                for($j=1;$j<=$n;$j++){            // foreign key of row\\n                    $content['minor_'.$j.'_id'] = rand(1,$l);\\n                }\\n                $conn->insert('main_'.$main, $content);\\n            }\\n            if($transaction) {$conn->commit();}\\n        } catch(\\\\Exception $e) {\\n            if($transaction) {$conn->rollBack();}\\n            throw $e;\\n        }\\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\\n    }\\n```\\n\\nTe zmiany pozwalają zapisać wiersze do drugiej tabeli bez transakcji:\\n\\n```bash\\ntime http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/0\\n```\\n\\nLub z nimi\\n\\n```bash\\ntime http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/1\\n```\\n\\nDodaliśmy też ustawianie dłuższego czasu wykonywania jeśli ilość zapisywanych wierszy jest odpowiednio duża. \\n\\n### Hipotezy\\n\\nMamy już całkiem insteresujący zbiór zmiennych w naszym modelu. Możemy manipulować liczbą tabel typu `minor` - `N`, liczbą ich kluczy - `L`, ilością wierszy które wstawiamy `k-k0+1`  i numerem wiersza od którego zaczynamy `k0`. Możemy też wstawiać wiersze z wykorzystaniem lub bez użycia transakcji. Wadą naszego systemu pomiarowego jest narzut czasu związany z wykonywaniem `doctrine` i reszty `php`, zaletą elastyczność `api`, które wystawiliśmy. Jednak wadę o której wspomniałem jesteśmy w stanie łatwo wyeliminować wykonując odpowiednio długie pomiary. Przez długie mam na myśli długie w stosunku do czasu jaki zajmuje wykonanie kodu nie będącego bezpośrednio operacjami na bazie - łączenie, wczytywanie bibliotek itd. To zadanie od testowania selektów różni się tym, że mamy tu stosunkowo trudne, ale \\n\\n\\nTestując będziemy zmieniać liczbę małych tabel `n`, 1-63, liczbę ich kluczy `l` od 1-50, liczbę wstawianych wierszy `k` od `1` do `100`.\\n\\nInterfejs: nazwa_testu, n,l,k\\n\\n### Instalacja\\n\\nInstalacja składa się ze ściągnięcia repozytorium i wykonania skryptu instalacyjnego. W skrypcie należy zmienić parametry połączenia z bazą danych.\\n\\n    git clone https://github.com/gustawdaniel/test_inserts_performace --depth 1\\n    cd test_inserts_performace && bash install.sh\\n\\nJeśli po wykonaniu instalacji proces `jdb2/sda1-8` będzie zabierał prawie całe `I/O` (screen z `iotop`):\\n\\n[![iotop.png](https://s28.postimg.org/o333sq0xp/iotop.png)](https://postimg.org/image/wlcjx27g9/)\\n\\nmożemy go wyłączyć, ale wymaga to włączenia systemu w trybie bezpiecznym (`recovery mode`). Proces ten jest to tak zwany `journaling`.\\n\\n    umount /dev/sda1\\n    tune2fs -O ^has_journal /dev/sda1\\n\\nZwykłe kopiowanie\\n\\n    INSERT INTO major_2 SELECT * FROM major_1;\\n    Query OK, 1000000 rows affected (8 min 38,35 sec)\\n\\nMysqldump\\n\\n    time mysqldump -u root training major_1 > major_1.sql\\n\\nPliki generowane przez mysqldump zwykle są duże i nie warto ich oglądać w całości. Podobnie jak `head` służy do wyświetlania pierwszych linii pliku tak poniższym poleceniem wyświetlimy pierwsze znaki każdej linii.\\n\\n    awk '{print substr($0,1,210);}' major_1.sql\\n\\nPonieważ interesuje nas wrzucenie danych do tabeli major_2, więc chcemy wybrać tylko inserty i zmienić 1 na 2 w nazwie tabeli. W języku skryptowym `awk` tego typu zadania załatwia się jedną linią:\\n\\n    awk '/^INSERT/ {sub(\\\"_1\\\",\\\"_2\\\",$0); print $0;}' major_1.sql > major_2.sql\\n\\nTeraz możemy wykonać wrzut danych do bazy.\\n\\n## Instalacja\\n\\n```\\ngit clone http://github.com/gustawdaniel/test_inserts_performance\\ncd test_inserts_performance\\nbash install.sh\\n```\\n\\npaste Dropbox token\\n\\n```\\nbash bash/initialize.sh \\nphp app.php\\nbash bash/send.sh\\n```\\n\\nOn analysing machine\\n\\n```\\nmysql -u root training -e \\\"TRUNCATE log; TRUNCATE machine;\\\"\\nbash bash/get.sh\\n```\\n\\n\\n\\n\\n----------------------------------------------------------------\\n\\n> Written with [StackEdit](https://stackedit.io/).\\n\\n\\n# Testowanie szybkości insertów\\n\\n[toc]\\n\\n##Opis projektu\\n\\nProblemem, który omówimy tym razem będzie optymalizacja szybkości zapisu do bazy danych przy kilku warunkach. Zakładamy, że nasza tabela ma nałożone klucze a więc również indeksy. Wiemy, że dane które chcemy do niej zapisać są poprawne. Podczas zapisu tych danych na pewno nie jest wykonywany żaden inny zapis. \\n\\nJako, że dopiero zaczynam zabawę z większymi zbiorami danych, moje intuicje są oparte głównie na czytaniu dokumentacji i celem tego ćwiczenia jest wyrobienie sobie ilościowego wyczucia w tej materii. \\n\\n## Zastosowane technologie\\n\\nInaczej, niż przy testowaniu selektów, nie decyduję się tym razem na czystego `sql`. Zamiast tego wykorzystamy `doctrine` ze względu na jego mechanizm dziedziczenia, którego sam `sql` z tego co wiem nie oferuje. Poza tym pisanie procedur do testowania w `php` i wystawienie przez niego `api` wydaje mi się bardziej atrakcyjne niż liniowe pliki wykonywalne w `sql`.\\n\\nDo obsługi `doctrine` wykorzystamy `symfony` - genialnie napisany framework `php`. Trochę trudniejszy niż Laravel, ale z drugiej strony polecany do większych projektów, gdzie elastyczność i stabilność są bardzo ważne. Instalacja polega na wykonaniu komendy:\\n\\n```bash\\nsymfony new insert_test latest && cd insert_test\\n```\\n\\n Zaczniemy od konfiguracji i w pliku `app/config/parameters.yml` zmienimy `database_name` na `insert_test`. Bazę danych stawiamy komendą:\\n\\n```bash\\nphp bin/console doctrine:database:create\\n```\\n\\nJest pusta, dlatego teraz zajmiemy się jej wypełnianiem.\\n\\n## Struktura bazy danych\\n\\nInteresuje nas przerzucanie danych między dwiema identycznymi tabelami, które mają powiązania przez więzy integralności referencyjnej z kilkoma mniejszymi tabelami. Nasza baza danych będzie więc przypominała pajęczynę, w której dwie duże tabele będą odnosić się `n` kluczami do `n` mniejszych nie powiązanych tabel. Główne tabela nazwiemy `main_1` i `main_2`, a mniejsze `minor_1`, `minor_2`, ... `minor_n`. Ponieważ obraz mówi więcej niż tysiąc słów załączam diagram hierarchiczny bazy:\\n\\n![struktura_hierarchiczna](http://i.imgur.com/8z63XFy.png)\\n\\nA dla wyjaśnienia, dlaczego początkowo wyobrażałem sobie tą bazę jak pajęczynę, prezentuję też diagram organiczny tej samej bazy.\\n\\n![struktura_organiczna](http://i.imgur.com/jaxTv9m.png)\\n\\nWłaściwie, to te duże tabele będą miały poważne problemy z optymalnością insertów dokładnie tak jak by było w sieci pająka...\\n\\nWracając do konkretów, ponieważ optymalność nie będzie testowana na mniejszych tabelach, nie dostaną one kluczy obcych, a więc to od nich zaczniemy stawianie bazy. Będą one zawierały tylko jedno pole - `id` będące ich kluczem głównym. Po ich utworzeniu będą tworzone tabele główne, i dopiero wtedy będziemy im dodawać klucze obce.\\n\\n## Tworzenie tabel\\n\\nKiedy kończyłem pisać wpis o [testowaniu selektów](http://blog.gustawdaniel.pl/2016/12/02/tesseract-ocr-i-testowanie-selekt%C3%B3w.html) za pomocą Behata, nie byłem zbyt zadowolony z pisania scenariuszy, które różniły się tylko liczbą atrybutów, lub warunków. Mimo, że bardzo wygodny dla osób nie technicznych, `Gherkin` nie dawał mi wystarczającej elastyczności. Podobnie czułem się [pisząc procedury](http://blog.gustawdaniel.pl/2016/12/08/testowanie-szybko%C5%9Bci-selekt%C3%B3w.html) w czystym `SQL`. Brak dziedziczenia sprawiał, że musiałem kopiować kod, a tego bardzo nie lubię.\\n\\nZupełnie inaczej jest tym razem. Całość kodu odpowiedzialnego za tworzenie całej tej bazy danych i wystawienie do tego prymitywnego, ale funkcjonalnego `API` mieści się w 100 liniach kodu. \\n\\nNaszą zabawę możemy zacząć od usunięcia katalogu `Resources` z `app/config`. Nasz kontroler będzie rozmawiał w `jsonie`, więc widoki nie będą nam potrzebne. Przechodzimy do edycji kontrolera. Zaczynamy od dołączenia bibliotek:\\n\\n> src/AppBundle/Controller/DefaultController.php\\n\\n```php\\n<?php\\n\\nnamespace AppBundle\\\\Controller;\\n\\nuse Sensio\\\\Bundle\\\\FrameworkExtraBundle\\\\Configuration\\\\Route;\\nuse Symfony\\\\Bundle\\\\FrameworkBundle\\\\Controller\\\\Controller;\\nuse Symfony\\\\Component\\\\HttpFoundation\\\\JsonResponse;\\nuse Doctrine\\\\DBAL\\\\Schema\\\\Schema;\\nuse Doctrine\\\\DBAL\\\\Schema\\\\Comparator;\\nuse Doctrine\\\\DBAL\\\\Schema\\\\Table;\\n```\\n\\nMamy tu `Route` odpowiadające za przypisywanie adnotacjom przy akcjach odpowiednich ścieżek w routingu. Jest `Controller`, który pozwala nam odnosić się do wszystkich najbardziej podstawowych funkcji `Symfony` przez `$this`. Następnie `JsonResponse` łączący działanie funkcji `json_decode` z jednoczesnym ustawianiem nagłówka na `application/json`. Trzy kolejne to paczki `Doctrine`, które odpowiednio tłumaczą jego `api` na `SQL` i dostarczają obiekty `Doctrine`.\\n\\nWewnątrz kontrolera będą istnieć dwie zmienne prywatne będące tablicami tabel `main` i `minor` oraz liczba określające ile tabel typu `minor` ma występować.\\n\\n```php\\nclass DefaultController extends Controller\\n{\\n    /**\\n     * @var Table[]\\n     */\\n    private $main, $minor;\\n\\n    private $N;\\n\\n    public function __construct()\\n    {\\n        $this->main = [];\\n        $this->minor = [];\\n        $this->N = 10;\\n    }\\n```\\n\\nKonstruktor ustawia `$minor` i `$main` jako puste tablice, a domyślną liczbę tabel na `10`. Klasa `Table` jest jednym z obiektów `doctrine`, które dopiero co załączyliśmy. Obsługę tej klasy zobaczymy za chwilę w funkcji tworzącej schemat jednej z tabel.\\n\\n```php\\n    /**\\n     * @param $schema Schema\\n     */\\n    private function appendMinorToSchema($schema)\\n    {\\n        for($i=1;$i<=$this->N;$i++) {\\n            $this->minor[$i] = $schema->createTable(\\\"minor_\\\".$i);\\n            $this->minor[$i]->addColumn(\\\"id\\\", \\\"integer\\\");\\n            $this->minor[$i]->setPrimaryKey(array(\\\"id\\\"));\\n        }\\n    }\\n```\\n\\nJak wspominałem wcześniej zaczynamy od tworzenia mniejszych tabel. Ponieważ ma być ich `N`, właśnie to tej wielkości ustawiona jest pętla. Wewnątrz do zmiennej zawierającej tabele `$minor` przypisujemy wynik metody `creteTable` na schemacie, który będzie podany jako argument. Schemat odpowiada temu jak `doctrine` rozumie strukturę bazy danych w ramach swoich własnych klas. Tworzonej tabeli przypisywany jest atrybut będący kluczem głównym. To wystarczy. Odrobinę bardziej złożoną logikę ma tworzenie dużych tabel.\\n\\n```php\\n    /**\\n     * @param $schema Schema\\n     */\\n    private function appendMainToSchema($schema)\\n    {\\n        for($i=1;$i<=2;$i++)\\n        {\\n            $this->main[$i] = $schema->createTable(\\\"main_\\\".$i);\\n            $this->main[$i]->addColumn(\\\"id\\\", \\\"integer\\\");\\n            for($j=1;$j<=$this->N;$j++)\\n            {\\n                $this->main[$i]->addColumn(\\\"minor_\\\".$j.\\\"_id\\\", \\\"integer\\\");\\n                $this->main[$i]->addForeignKeyConstraint($this->minor[$j], array(\\\"minor_\\\".$j.\\\"_id\\\"), array(\\\"id\\\"));\\n            }\\n            $this->main[$i]->setPrimaryKey(array(\\\"id\\\"));\\n        }\\n    }\\n```\\n\\nPonieważ są dwie, pętla główna przebiega tylko wartości `1` i `2`. Tak jak poprzednio do schematu dodawane są tabele, oraz kolumna o nazwie `id`, która zostanie u nas kluczem głównym. Nie dostała ona `auto_increment` bo będziemy ją ustawiać w zewnętrznym skrypcie. \\n\\nPo dodaniu bazowego atrybutu - `id` do tabeli rozpoczynamy pętlę po mniejszych tabelach, w której podpinamy kolumnę i przypisujemy jej więzy integralności referencyjnej. Na ustanawiamy `id` kluczem głównym.\\n\\nNa tym się kończy lista zmiennych i metod. Jak w zwykłych skryptach, przechodzimy do ciała programu.\\n\\n```php\\n    /**\\n     * @Route(\\\"/\\\", name=\\\"home\\\")\\n     * @Route(\\\"/do/{n}\\\")\\n     */\\n    public function indexAction($n=10,$action=\\\"do\\\")\\n    {\\n        if($n){ $this->N = $n; }\\n        $conn = $this->getDoctrine()->getConnection();\\n```\\n\\nRouting pozwala nam wybrać domyślną ścieżkę `/`, albo określić akcję i wybrać dla niej argument. Na tym etapie będziemy mieli dwie akcje - `show` i `do`. Show będzie jedynie wyświetlało kod `SQL` jaki trzeba wykonać, aby obecny stan bazy przekształcić do posiadającego `n` małych tabel, a `do` będzie nie tylko pokazywać, ale też wykonywać ten kod. Jak łatwo zgadnąć, `n` jest właśnie liczbą tabel i nadpisuje domyślne `10` z konstruktora. Na końcu tego kodu tworzymy połączenie z bazą danych i zapisujemy jego reprezentację do zmiennej `$conn`. Teraz przygotujemy schemat.\\n\\n```php\\n        $schema = new Schema();\\n\\n        $this->appendMinorToSchema($schema);\\n        $this->appendMainToSchema($schema);\\n```\\n\\nSchemat, czyli to jak `doctrine` rozumie strukturę bazy tworzymy w trzech linijkach. Czas porównać go z obecnym stanem bazy.\\n\\n```php\\n        $comparator = new Comparator();\\n        $queries = $comparator->compare($conn->getSchemaManager()->createSchema(), $schema)->toSql($conn->getDatabasePlatform());\\n\\n```\\n\\nDzięki obiektom `Comparator` oraz `ShemaManager` otrzymanie tablicy z zapytaniami `SQL` aktualizującymi naszą strukturę bazy mieści się w dwóch liniach. Zostało już tylko wykonanie tych zapytań, jeśli `action` ustawione jest na `do`.\\n\\n```php\\n        if($action==\\\"do\\\"){\\n            foreach($queries as $query) {\\n                $conn->prepare($query)->execute();\\n            }\\n        }\\n```\\n\\nDzięki metodom pozwalającym wykonywać czyste sqlowe zapytania nasze zadanie sprowadza się do wykonania pętli po nich. Możemy teraz zwrócić użytkownikowi jakiś sensowny komunikat.\\n\\n```php\\n        return new JsonResponse(\\n            [\\n                \\\"alter\\\"=>$queries,\\n            ]\\n        );\\n    }\\n}\\n```\\n\\nNajlepszy wydał mi się `json` z listą zapytań jakie należy wykonać, aby obecny stan bazy przekształcić do zadanego przez parametr `n`. Na koniec dołączam metodę `show`, która świetnie nadaje się do debugowania, ale nie pełni żadnej funkcji poza tym:\\n\\n```php\\n    /**\\n    * @Route(\\\"/show/{n}\\\")\\n    */\\n    public function showAction($n=10)\\n    {\\n        return $this->doAction($n,\\\"show\\\");\\n    }\\n```\\n\\nŻeby móc obsłużyć nasz kontroler postawimy serwer komendą.\\n\\n```bash\\nphp bin/console server:run\\n```\\n\\nI w drugim terminalu wyślemy request http, który wypełni nam bazę tabelami.\\n\\n```\\ntime http -b GET localhost:8000/do/10\\n```\\n\\nJego wykonanie trwało u mnie 3 sekundy, a odpowiedź wyglądała tak:\\n\\n![database_creation](http://i.imgur.com/NQVaaWB.png)\\n\\n## Wypełnianie bazy danymi\\n\\nNadszedł czas wypełnić bazę danymi. Dla małych tabel będą to liczby z przedziału od `1` do `L`. Dla dużych będziemy losować `N` liczb od `1` do `L`, które dodamy do kluczy obcych. Wartość `id` ustawimy na `auto_increment` ale nie z poziomu `sql` tylko przez zewnętrzny skrypt. Poza małymi tabelami wypełnimy tylko tabelę `main_1`, zostawiając `main_2` pustą. Przypominam, że chcemy przetestować klonowanie dużej tabli z dużą ilością kluczy obcych.\\n\\n### Tabele minor\\n\\nZaczniemy od wypełniania małych tabel. Podzielę ten proces na wypełnianie małych i dużej tabeli oddzielnie, ze względu na większą elastyczność takiego podejścia, a po części też dlatego, że da mi to lepszy wgląd w czasy wykonywania poszczególnych procesów. Małe tabele będziemy tworzyć za pomocą następującej akcji w `DefaultController`:\\n\\n```php\\n    /**\\n     * @Route(\\\"/minor/{n}/{l}\\\")\\n     */\\n    public function minorAction($n=10,$l=10)\\n    {\\n        $conn = $this->getDoctrine()->getConnection();\\n        for($i=1;$i<=$n;$i++){\\n            $conn->delete('minor_'.$i,[1=>1]);\\n            for($j=1;$j<=$l;$j++){\\n                $conn->insert('minor_'.$i, array('id' => $j));\\n            }\\n        }\\n        return new  JsonResponse(['n'=>$n, 'l'=>$l]);\\n    }\\n```\\n\\nJest ona wyjątkowo prosta, ale posiada jeden dość ciekawy hak. Chodzi o idempotentność. W metodzie `delete` obiektu `Connection` mamy nazwę tabeli a później tablicę `[1=>1]`. Jest to warunek który w instrukcji `DELETE FROM` występuje za `WHERE`. `1=1` jest zawsze prawdziwe i dlatego przed rozpoczęciem zapisu zostają usunięte zostają wszystkie elementy jednym zapytaniem. Żeby wywołać tą akcję wystarczy wpisać w konsoli:\\n\\n```bash\\ntime http -b GET localhost:8000/minor/10/10\\n```\\n\\nOdpowiedź którą zobaczymy będzie wyglądała tak:\\n\\n```json\\n{\\n    \\\"l\\\": \\\"10\\\", \\n    \\\"n\\\": \\\"10\\\"\\n}\\n```\\n\\n### Dodanie stałych\\n\\nMógł bym kontynuować dodawanie akcji, ale zacząłem martwić się zbytnią powtarzalnością wartości domyślnych. Zanim przejdziemy dalej wprowadzimy w kodzie następujące zmiany. Na początku kontrolera definiujemy stałe:\\n\\n```php\\n    const N = 10;\\n    const L = 10;\\n    const K = 1000;\\n```\\n\\nW konstruktorze ustawiamy `private $N` na:\\n\\n```php\\n        $this->N = self::N;\\n```\\n\\nZmieniamy domyślne wartości w definicjach akcji na następujące:\\n\\n```php\\n    public function doAction($n=self::N,$action=\\\"do\\\")\\n    public function showAction($n=self::N)\\n    public function minorAction($n=self::N,$l=self::L)\\n```\\n\\nDodajemy routingi bez parametrów, czyli \\n\\n```php\\n     * @Route(\\\"/show\\\")\\n```\\n\\nprzed ` * @Route(\\\"/minor/{n}/{l}\\\")` oraz \\n\\n```ph\\n     * @Route(\\\"/minor\\\")\\n```\\n\\nprzed `* @Route(\\\"/main/{n}/{l}/{k}\\\")`\\n\\n### Tabela main\\n\\nDo wypełnienia tabeli `main_1` wykorzystamy następujący kod\\n\\n```php\\n    /**\\n     * @Route(\\\"/main\\\")\\n     * @Route(\\\"/main/{n}/{l}/{k}\\\")\\n     * @Route(\\\"/main/{n}/{l}/{k0}/{k}\\\")\\n     */\\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1)\\n    {\\n        $conn = $this->getDoctrine()->getConnection();\\n        if($k0==1) { $conn->delete('main_1',[1=>1]); }\\n        for($i=$k0;$i<=$k;$i++){                // row in table main\\n            $content = ['id'=>$i];\\n            for($j=1;$j<=$n;$j++){            // foreign key of row\\n                $content['minor_'.$j.'_id'] = rand(1,$l);\\n            }\\n            $conn->insert('main_1', $content);\\n        }\\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\\n    }\\n```\\n\\nJest to akcja która nadaje się zarówno do czyszczenia, nadpisywania, jak i dopisywania do tabeli `main`. Tak duża ogólność została uzyskana dzięki dość ciekawemu routingowi. Zmienne `n` i `l` to odpowiednio liczba tabel typu `minor` oraz liczba ich wierszy. `k` jest maksymalnym indeksem `id` do którego będziemy wypełniać tabelę `main`. `k0` jest indeksem od którego zaczynamy. Jeśli wynosi on 1 lub nie jest podany, zawartość tabeli `main` zostanie skasowana przed dalszym zapisem. \\n\\nTo co się dzieje wewnątrz pętli jest dość przewidywalne. Tworzymy wartość `id` zgodnie z zapowiedzianym schematem (`auto_increment`), losujemy klucze obce, zapisujemy wiersz i przechodzimy dalej. Tej akcji można użyć na kilka sposobów. Na przykład żeby wypełnić tabelę `main_1` dziesięcioma wierszami wpiszemy:\\n\\n```\\ntime http -b GET localhost:8000/main/10/10/10\\n```\\n\\nJeśli chcemy ją wyczyścić:\\n\\n```\\ntime http -b GET localhost:8000/main/10/10/0\\n```\\n\\nTeraz możemy zapisać z powrotem 10 wierszy, ale rozbijając to na dwa kroki:\\n\\n```\\ntime http -b GET localhost:8000/main/10/10/1/5\\ntime http -b GET localhost:8000/main/10/10/6/10\\n```\\n\\nZanim wypełnimy tabelę `main_1` milionami wierszy należy zauważyć, że pierwszą przyczyną dla której szybkość wykonywania insertów jest niezadowalająca jest sprawdzanie poprawności więzów przy każdym zapisie. Celowo nie dodałem transakcji, żebyśmy mogli porównać szybkość wykonywania tego kodu z analogicznym otoczonym transakcją. Wyniki dla `100k` wierszy:\\n\\n| Bez transakcji | Z transakcją |\\n| -------------- | ------------ |\\n| 6m 41.672s     | 0m 57.804s   |\\n\\nTransakcje uzyskamy dzięki następującej modyfikacji ciała akcji `mainAction`:\\n\\n```php\\n        $conn = $this->getDoctrine()->getConnection();\\n        if($k0==1) { $conn->delete('main_1',[1=>1]); }\\n        $conn->beginTransaction();\\n        try{\\n            // loop over rows - exactly the same as before\\n            $conn->commit();\\n        } catch(\\\\Exception $e) {\\n            $conn->rollBack();\\n            throw $e;\\n        }\\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\\n```\\n\\n## Pomiary\\n\\nPonieważ nadszedł czas na wykonywanie pomiarów, warto było by stworzyć dla wyników kolejną tabelę nie połączoną z poprzednimi. Powinna ona zawierać czas, parametry i opis mierzonej funkcjonalności. Jednak dla czystości kodu oddzielimy część generującą tabele od wykonującej akcje. Zależy mi też na pogrupowaniu akcji ze względu na to czy stawiają bazę, czy dokonują na niej pomiarów. Oto nowa struktura katalogów jaką zastosujemy.\\n\\n![katalogi](http://i.imgur.com/HFAxvGJ.png)\\n\\nNasz model odpowiedzialny za tworzeniu schematu bazy będzie miał kod wycięty z prywatnych funkcji i własności `DefaultController` oraz jego konstruktora.\\n\\n> src/AppBundle/Model/SchemaGenerator.php\\n\\n```php\\n<?php\\n\\nnamespace AppBundle\\\\Model;\\n\\nuse AppBundle\\\\Controller\\\\BaseController;\\nuse Doctrine\\\\DBAL\\\\Schema\\\\Schema;\\nuse Doctrine\\\\DBAL\\\\Schema\\\\Table;\\n\\nclass SchemaGenerator\\n```\\n\\nNie zmieni się tam nic poza konstruktorem:\\n\\n```php\\n    public function __construct($n)\\n    {\\n        $this->main = [];\\n        $this->minor = [];\\n        $this->N = $n ? $n : BaseController::N;\\n    }\\n```\\n\\nUstawia on domyślnie `N` na wartość stałej z `BaseController`, albo na wartość podaną przy powoływaniu instancji obiektu. Jak wspomniałem, funkcje `appendMinorToSchema` i `appendMainToSchema` się nie zmieniają. Dochodzi za to funkcja `appendLogToSchema`:\\n\\n```php\\n    /**\\n     * @param $schema Schema\\n     */\\n    private function appendLogToSchema($schema)\\n    {\\n        $log = $schema->createTable(\\\"log\\\");\\n        $log->addColumn(\\\"id\\\", \\\"integer\\\",array(\\\"autoincrement\\\"=>true,\\\"unsigned\\\" => true));\\n        $log->addColumn(\\\"n\\\", \\\"smallint\\\",array(\\\"unsigned\\\" => true));\\n        $log->addColumn(\\\"l\\\", \\\"smallint\\\",array(\\\"unsigned\\\" => true));\\n        $log->addColumn(\\\"k0\\\", \\\"integer\\\",array(\\\"unsigned\\\" => true));\\n        $log->addColumn(\\\"k\\\", \\\"integer\\\",array(\\\"unsigned\\\" => true));\\n        $log->addColumn(\\\"execution_time\\\", \\\"float\\\");\\n        $log->addColumn(\\\"operation\\\", \\\"string\\\",array());\\n        $log->setPrimaryKey(array(\\\"id\\\"));\\n    }\\n```\\n\\nBędzie to tabela przechowująca wyniki pomiarów z parametrami. Wyposażymy nasz generator w jedną funkcję, która zbinduje poprzednie funkcje ze schematem i zwróci nam gotowy schemat.\\n\\n```php\\n    /**\\n     * @return Schema Schema\\n     */\\n    public function generate()\\n    {\\n        $schema=new Schema();\\n\\n        $this->appendMinorToSchema($schema);\\n        $this->appendMainToSchema($schema);\\n        $this->appendLogToSchema($schema);\\n\\n        return $schema;\\n    }\\n```\\n\\nTo wszystko, jeśli chodzi o model. Spójrzmy na kontroler bazowy.\\n\\n```php\\n<?php\\n\\nnamespace AppBundle\\\\Controller;\\n\\nuse Symfony\\\\Bundle\\\\FrameworkBundle\\\\Controller\\\\Controller;\\n\\nclass BaseController extends Controller\\n{\\n    const N = 10;\\n    const L = 10;\\n    const K = 1000;\\n}\\n```\\n\\nJest to nasz kontener na stałe. Sam nie wiem, czy w takim przypadku, nie lepiej było by tego nawet zrobić w parametrach `Symfony`. I pewnie tak zrobię, jeśli dla tego kontrolera nie pojawią się jakieś dodatkowe zastosowania. Tym czasem zostało nam jeszcze dostosowanie `DefaultController`. Przede wszystkim zmieniliśmy jego nazwę (nazwę pliku i klasy) na `PreparationController` aby lepiej odpowiadała jego funkcjonalności. W Metodzie `doAction` usunęliśmy ustawianie zmiennej prywatnej `N` w pierwszej instrukcji warunkowej. Wiąże się to z tym, że wycięliśmy też wszystkie zmienne i funkcje prywatne oraz konstruktor. Trzy linijkową generację schematu zastąpiliśmy linią:\\n\\n```php\\n        $schema = (new SchemaGenerator($n))->generate();\\n```\\n\\nNa koniec zwiększyliśmy jeszcze bardziej elastyczność metody `mainAction`, ze względu na to, że zainteresowało mnie jakie dokładnie różnice robi ustawianie transakcji przy jakich ilościach wierszy. Dodałem też numer tabeli `main` do routingu, jeśli chcaił bym nie ruszając dużej już wypełnionej tabeli, wykonywać testy na tej drugiej.\\n\\n```php\\n    /**\\n     * @Route(\\\"/main\\\")\\n     * @Route(\\\"/main/{n}/{l}/{k}\\\")\\n     * @Route(\\\"/main/{n}/{l}/{k0}/{k}\\\")\\n     * @Route(\\\"/main/{n}/{l}/{k0}/{k}/{main}/{transaction}\\\")\\n     */\\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1,$main=1,$transaction=true)\\n    {\\n        $conn = $this->getDoctrine()->getConnection();\\n        if($k0==1) { $conn->delete('main_'.$main,[1=>1]); }\\n        if($k>1e4) { \\n            set_time_limit(0);\\n            ini_set(\\\"max_execution_time\\\", 0); \\n        }\\n        if($transaction) {$conn->beginTransaction();}\\n        try{\\n            for($i=$k0;$i<=$k;$i++){                // row in table main\\n                $content = ['id'=>$i];\\n                for($j=1;$j<=$n;$j++){            // foreign key of row\\n                    $content['minor_'.$j.'_id'] = rand(1,$l);\\n                }\\n                $conn->insert('main_'.$main, $content);\\n            }\\n            if($transaction) {$conn->commit();}\\n        } catch(\\\\Exception $e) {\\n            if($transaction) {$conn->rollBack();}\\n            throw $e;\\n        }\\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\\n    }\\n```\\n\\nTe zmiany pozwalają zapisać wiersze do drugiej tabeli bez transakcji:\\n\\n```bash\\ntime http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/0\\n```\\n\\nLub z nimi\\n\\n```bash\\ntime http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/1\\n```\"}],[\"markdown\",{\"markdown\":\"Dodaliśmy też ustawianie dłuższego czasu wykonywania jeśli ilość zapisywanych wierszy jest odpowiednio duża. \\n\\n### Hipotezy\\n\\nMamy już całkiem insteresujący zbiór zmiennych w naszym modelu. Możemy manipulować liczbą tabel typu `minor` - `N`, liczbą ich kluczy - `L`, ilością wierszy które wstawiamy `k-k0+1`  i numerem wiersza od którego zaczynamy `k0`. Możemy też wstawiać wiersze z wykorzystaniem lub bez użycia transakcji. Wadą naszego systemu pomiarowego jest narzut czasu związany z wykonywaniem `doctrine` i reszty `php`, zaletą elastyczność `api`, które wystawiliśmy. Jednak wadę o której wspomniałem jesteśmy w stanie łatwo wyeliminować wykonując odpowiednio długie pomiary. Przez długie mam na myśli długie w stosunku do czasu jaki zajmuje wykonanie kodu nie będącego bezpośrednio operacjami na bazie - łączenie, wczytywanie bibliotek itd. To zadanie od testowania selektów różni się tym, że mamy tu stosunkowo trudne, ale \\n\\n\\nTestując będziemy zmieniać liczbę małych tabel `n`, 1-63, liczbę ich kluczy `l` od 1-50, liczbę wstawianych wierszy `k` od `1` do `100`.\\n\\nInterfejs: nazwa_testu, n,l,k\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<!--kg-card-begin: markdown--><h2 id=\"struktura-bazy-danych\">Struktura bazy danych</h2>\n<p>Interesuje nas przerzucanie danych między dwiema identycznymi tabelami, które mają powiązania przez więzy integralności referencyjnej z kilkoma mniejszymi tabelami. Nasza baza danych będzie więc przypominała pajęczynę, w której dwie duże tabele będą odnosić się <code>n</code> kluczami do <code>n</code> mniejszych nie powiązanych tabel. Główne tabela nazwiemy <code>main_1</code> i <code>main_2</code>, a mniejsze <code>minor_1</code>, <code>minor_2</code>, ... <code>minor_n</code>. Ponieważ obraz mówi więcej niż tysiąc słów załączam diagram hierarchiczny bazy:</p>\n<p><img src=\"http://i.imgur.com/8z63XFy.png\" alt=\"struktura_hierarchiczna\" loading=\"lazy\"></p>\n<p>A dla wyjaśnienia, dlaczego początkowo wyobrażałem sobie tą bazę jak pajęczynę, prezentuję też diagram organiczny tej samej bazy.</p>\n<p><img src=\"http://i.imgur.com/jaxTv9m.png\" alt=\"struktura_organiczna\" loading=\"lazy\"></p>\n<p>Właściwie, to te duże tabele będą miały poważne problemy z optymalnością insertów dokładnie tak jak by było w sieci pająka...</p>\n<p>Wracając do konkretów, ponieważ optymalność nie będzie testowana na mniejszych tabelach, nie dostaną one kluczy obcych, a więc to od nich zaczniemy stawianie bazy. Będą one zawierały tylko jedno pole - <code>id</code> będące ich kluczem głównym. Po ich utworzeniu będą tworzone tabele główne, i dopiero wtedy będziemy im dodawać klucze obce.</p>\n<h2 id=\"tworzenie-tabel\">Tworzenie tabel</h2>\n<p>Kiedy kończyłem pisać wpis o <a href=\"http://blog.gustawdaniel.pl/2016/12/02/tesseract-ocr-i-testowanie-selekt%C3%B3w.html\">testowaniu selektów</a> za pomocą Behata, nie byłem zbyt zadowolony z pisania scenariuszy, które różniły się tylko liczbą atrybutów, lub warunków. Mimo, że bardzo wygodny dla osób nie technicznych, <code>Gherkin</code> nie dawał mi wystarczającej elastyczności. Podobnie czułem się <a href=\"http://blog.gustawdaniel.pl/2016/12/08/testowanie-szybko%C5%9Bci-selekt%C3%B3w.html\">pisząc procedury</a> w czystym <code>SQL</code>. Brak dziedziczenia sprawiał, że musiałem kopiować kod, a tego bardzo nie lubię.</p>\n<p>Zupełnie inaczej jest tym razem. Całość kodu odpowiedzialnego za tworzenie całej tej bazy danych i wystawienie do tego prymitywnego, ale funkcjonalnego <code>API</code> mieści się w 100 liniach kodu.</p>\n<p>Naszą zabawę możemy zacząć od usunięcia katalogu <code>Resources</code> z <code>app/config</code>. Nasz kontroler będzie rozmawiał w <code>jsonie</code>, więc widoki nie będą nam potrzebne. Przechodzimy do edycji kontrolera. Zaczynamy od dołączenia bibliotek:</p>\n<blockquote>\n<p>src/AppBundle/Controller/DefaultController.php</p>\n</blockquote>\n<pre><code class=\"language-php\">&lt;?php\n\nnamespace AppBundle\\Controller;\n\nuse Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route;\nuse Symfony\\Bundle\\FrameworkBundle\\Controller\\Controller;\nuse Symfony\\Component\\HttpFoundation\\JsonResponse;\nuse Doctrine\\DBAL\\Schema\\Schema;\nuse Doctrine\\DBAL\\Schema\\Comparator;\nuse Doctrine\\DBAL\\Schema\\Table;\n</code></pre>\n<p>Mamy tu <code>Route</code> odpowiadające za przypisywanie adnotacjom przy akcjach odpowiednich ścieżek w routingu. Jest <code>Controller</code>, który pozwala nam odnosić się do wszystkich najbardziej podstawowych funkcji <code>Symfony</code> przez <code>$this</code>. Następnie <code>JsonResponse</code> łączący działanie funkcji <code>json_decode</code> z jednoczesnym ustawianiem nagłówka na <code>application/json</code>. Trzy kolejne to paczki <code>Doctrine</code>, które odpowiednio tłumaczą jego <code>api</code> na <code>SQL</code> i dostarczają obiekty <code>Doctrine</code>.</p>\n<p>Wewnątrz kontrolera będą istnieć dwie zmienne prywatne będące tablicami tabel <code>main</code> i <code>minor</code> oraz liczba określające ile tabel typu <code>minor</code> ma występować.</p>\n<pre><code class=\"language-php\">class DefaultController extends Controller\n{\n    /**\n     * @var Table[]\n     */\n    private $main, $minor;\n\n    private $N;\n\n    public function __construct()\n    {\n        $this-&gt;main = [];\n        $this-&gt;minor = [];\n        $this-&gt;N = 10;\n    }\n</code></pre>\n<p>Konstruktor ustawia <code>$minor</code> i <code>$main</code> jako puste tablice, a domyślną liczbę tabel na <code>10</code>. Klasa <code>Table</code> jest jednym z obiektów <code>doctrine</code>, które dopiero co załączyliśmy. Obsługę tej klasy zobaczymy za chwilę w funkcji tworzącej schemat jednej z tabel.</p>\n<pre><code class=\"language-php\">    /**\n     * @param $schema Schema\n     */\n    private function appendMinorToSchema($schema)\n    {\n        for($i=1;$i&lt;=$this-&gt;N;$i++) {\n            $this-&gt;minor[$i] = $schema-&gt;createTable(&quot;minor_&quot;.$i);\n            $this-&gt;minor[$i]-&gt;addColumn(&quot;id&quot;, &quot;integer&quot;);\n            $this-&gt;minor[$i]-&gt;setPrimaryKey(array(&quot;id&quot;));\n        }\n    }\n</code></pre>\n<p>Jak wspominałem wcześniej zaczynamy od tworzenia mniejszych tabel. Ponieważ ma być ich <code>N</code>, właśnie to tej wielkości ustawiona jest pętla. Wewnątrz do zmiennej zawierającej tabele <code>$minor</code> przypisujemy wynik metody <code>creteTable</code> na schemacie, który będzie podany jako argument. Schemat odpowiada temu jak <code>doctrine</code> rozumie strukturę bazy danych w ramach swoich własnych klas. Tworzonej tabeli przypisywany jest atrybut będący kluczem głównym. To wystarczy. Odrobinę bardziej złożoną logikę ma tworzenie dużych tabel.</p>\n<pre><code class=\"language-php\">    /**\n     * @param $schema Schema\n     */\n    private function appendMainToSchema($schema)\n    {\n        for($i=1;$i&lt;=2;$i++)\n        {\n            $this-&gt;main[$i] = $schema-&gt;createTable(&quot;main_&quot;.$i);\n            $this-&gt;main[$i]-&gt;addColumn(&quot;id&quot;, &quot;integer&quot;);\n            for($j=1;$j&lt;=$this-&gt;N;$j++)\n            {\n                $this-&gt;main[$i]-&gt;addColumn(&quot;minor_&quot;.$j.&quot;_id&quot;, &quot;integer&quot;);\n                $this-&gt;main[$i]-&gt;addForeignKeyConstraint($this-&gt;minor[$j], array(&quot;minor_&quot;.$j.&quot;_id&quot;), array(&quot;id&quot;));\n            }\n            $this-&gt;main[$i]-&gt;setPrimaryKey(array(&quot;id&quot;));\n        }\n    }\n</code></pre>\n<p>Ponieważ są dwie, pętla główna przebiega tylko wartości <code>1</code> i <code>2</code>. Tak jak poprzednio do schematu dodawane są tabele, oraz kolumna o nazwie <code>id</code>, która zostanie u nas kluczem głównym. Nie dostała ona <code>auto_increment</code> bo będziemy ją ustawiać w zewnętrznym skrypcie.</p>\n<p>Po dodaniu bazowego atrybutu - <code>id</code> do tabeli rozpoczynamy pętlę po mniejszych tabelach, w której podpinamy kolumnę i przypisujemy jej więzy integralności referencyjnej. Na ustanawiamy <code>id</code> kluczem głównym.</p>\n<p>Na tym się kończy lista zmiennych i metod. Jak w zwykłych skryptach, przechodzimy do ciała programu.</p>\n<pre><code class=\"language-php\">    /**\n     * @Route(&quot;/&quot;, name=&quot;home&quot;)\n     * @Route(&quot;/do/{n}&quot;)\n     */\n    public function indexAction($n=10,$action=&quot;do&quot;)\n    {\n        if($n){ $this-&gt;N = $n; }\n        $conn = $this-&gt;getDoctrine()-&gt;getConnection();\n</code></pre>\n<p>Routing pozwala nam wybrać domyślną ścieżkę <code>/</code>, albo określić akcję i wybrać dla niej argument. Na tym etapie będziemy mieli dwie akcje - <code>show</code> i <code>do</code>. Show będzie jedynie wyświetlało kod <code>SQL</code> jaki trzeba wykonać, aby obecny stan bazy przekształcić do posiadającego <code>n</code> małych tabel, a <code>do</code> będzie nie tylko pokazywać, ale też wykonywać ten kod. Jak łatwo zgadnąć, <code>n</code> jest właśnie liczbą tabel i nadpisuje domyślne <code>10</code> z konstruktora. Na końcu tego kodu tworzymy połączenie z bazą danych i zapisujemy jego reprezentację do zmiennej <code>$conn</code>. Teraz przygotujemy schemat.</p>\n<pre><code class=\"language-php\">        $schema = new Schema();\n\n        $this-&gt;appendMinorToSchema($schema);\n        $this-&gt;appendMainToSchema($schema);\n</code></pre>\n<p>Schemat, czyli to jak <code>doctrine</code> rozumie strukturę bazy tworzymy w trzech linijkach. Czas porównać go z obecnym stanem bazy.</p>\n<pre><code class=\"language-php\">        $comparator = new Comparator();\n        $queries = $comparator-&gt;compare($conn-&gt;getSchemaManager()-&gt;createSchema(), $schema)-&gt;toSql($conn-&gt;getDatabasePlatform());\n\n</code></pre>\n<p>Dzięki obiektom <code>Comparator</code> oraz <code>ShemaManager</code> otrzymanie tablicy z zapytaniami <code>SQL</code> aktualizującymi naszą strukturę bazy mieści się w dwóch liniach. Zostało już tylko wykonanie tych zapytań, jeśli <code>action</code> ustawione jest na <code>do</code>.</p>\n<pre><code class=\"language-php\">        if($action==&quot;do&quot;){\n            foreach($queries as $query) {\n                $conn-&gt;prepare($query)-&gt;execute();\n            }\n        }\n</code></pre>\n<p>Dzięki metodom pozwalającym wykonywać czyste sqlowe zapytania nasze zadanie sprowadza się do wykonania pętli po nich. Możemy teraz zwrócić użytkownikowi jakiś sensowny komunikat.</p>\n<pre><code class=\"language-php\">        return new JsonResponse(\n            [\n                &quot;alter&quot;=&gt;$queries,\n            ]\n        );\n    }\n}\n</code></pre>\n<p>Najlepszy wydał mi się <code>json</code> z listą zapytań jakie należy wykonać, aby obecny stan bazy przekształcić do zadanego przez parametr <code>n</code>. Na koniec dołączam metodę <code>show</code>, która świetnie nadaje się do debugowania, ale nie pełni żadnej funkcji poza tym:</p>\n<pre><code class=\"language-php\">    /**\n    * @Route(&quot;/show/{n}&quot;)\n    */\n    public function showAction($n=10)\n    {\n        return $this-&gt;doAction($n,&quot;show&quot;);\n    }\n</code></pre>\n<p>Żeby móc obsłużyć nasz kontroler postawimy serwer komendą.</p>\n<pre><code class=\"language-bash\">php bin/console server:run\n</code></pre>\n<p>I w drugim terminalu wyślemy request http, który wypełni nam bazę tabelami.</p>\n<pre><code>time http -b GET localhost:8000/do/10\n</code></pre>\n<p>Jego wykonanie trwało u mnie 3 sekundy, a odpowiedź wyglądała tak:</p>\n<p><img src=\"http://i.imgur.com/NQVaaWB.png\" alt=\"database_creation\" loading=\"lazy\"></p>\n<h2 id=\"wype%C5%82nianie-bazy-danymi\">Wypełnianie bazy danymi</h2>\n<p>Nadszedł czas wypełnić bazę danymi. Dla małych tabel będą to liczby z przedziału od <code>1</code> do <code>L</code>. Dla dużych będziemy losować <code>N</code> liczb od <code>1</code> do <code>L</code>, które dodamy do kluczy obcych. Wartość <code>id</code> ustawimy na <code>auto_increment</code> ale nie z poziomu <code>sql</code> tylko przez zewnętrzny skrypt. Poza małymi tabelami wypełnimy tylko tabelę <code>main_1</code>, zostawiając <code>main_2</code> pustą. Przypominam, że chcemy przetestować klonowanie dużej tabli z dużą ilością kluczy obcych.</p>\n<h3 id=\"tabele-minor\">Tabele minor</h3>\n<p>Zaczniemy od wypełniania małych tabel. Podzielę ten proces na wypełnianie małych i dużej tabeli oddzielnie, ze względu na większą elastyczność takiego podejścia, a po części też dlatego, że da mi to lepszy wgląd w czasy wykonywania poszczególnych procesów. Małe tabele będziemy tworzyć za pomocą następującej akcji w <code>DefaultController</code>:</p>\n<pre><code class=\"language-php\">    /**\n     * @Route(&quot;/minor/{n}/{l}&quot;)\n     */\n    public function minorAction($n=10,$l=10)\n    {\n        $conn = $this-&gt;getDoctrine()-&gt;getConnection();\n        for($i=1;$i&lt;=$n;$i++){\n            $conn-&gt;delete('minor_'.$i,[1=&gt;1]);\n            for($j=1;$j&lt;=$l;$j++){\n                $conn-&gt;insert('minor_'.$i, array('id' =&gt; $j));\n            }\n        }\n        return new  JsonResponse(['n'=&gt;$n, 'l'=&gt;$l]);\n    }\n</code></pre>\n<p>Jest ona wyjątkowo prosta, ale posiada jeden dość ciekawy hak. Chodzi o idempotentność. W metodzie <code>delete</code> obiektu <code>Connection</code> mamy nazwę tabeli a później tablicę <code>[1=&gt;1]</code>. Jest to warunek który w instrukcji <code>DELETE FROM</code> występuje za <code>WHERE</code>. <code>1=1</code> jest zawsze prawdziwe i dlatego przed rozpoczęciem zapisu zostają usunięte zostają wszystkie elementy jednym zapytaniem. Żeby wywołać tą akcję wystarczy wpisać w konsoli:</p>\n<pre><code class=\"language-bash\">time http -b GET localhost:8000/minor/10/10\n</code></pre>\n<p>Odpowiedź którą zobaczymy będzie wyglądała tak:</p>\n<pre><code class=\"language-json\">{\n    &quot;l&quot;: &quot;10&quot;, \n    &quot;n&quot;: &quot;10&quot;\n}\n</code></pre>\n<h3 id=\"dodanie-sta%C5%82ych\">Dodanie stałych</h3>\n<p>Mógł bym kontynuować dodawanie akcji, ale zacząłem martwić się zbytnią powtarzalnością wartości domyślnych. Zanim przejdziemy dalej wprowadzimy w kodzie następujące zmiany. Na początku kontrolera definiujemy stałe:</p>\n<pre><code class=\"language-php\">    const N = 10;\n    const L = 10;\n    const K = 1000;\n</code></pre>\n<p>W konstruktorze ustawiamy <code>private $N</code> na:</p>\n<pre><code class=\"language-php\">        $this-&gt;N = self::N;\n</code></pre>\n<p>Zmieniamy domyślne wartości w definicjach akcji na następujące:</p>\n<pre><code class=\"language-php\">    public function doAction($n=self::N,$action=&quot;do&quot;)\n    public function showAction($n=self::N)\n    public function minorAction($n=self::N,$l=self::L)\n</code></pre>\n<p>Dodajemy routingi bez parametrów, czyli</p>\n<pre><code class=\"language-php\">     * @Route(&quot;/show&quot;)\n</code></pre>\n<p>przed <code> * @Route(&quot;/minor/{n}/{l}&quot;)</code> oraz</p>\n<pre><code class=\"language-ph\">     * @Route(&quot;/minor&quot;)\n</code></pre>\n<p>przed <code>* @Route(&quot;/main/{n}/{l}/{k}&quot;)</code></p>\n<h3 id=\"tabela-main\">Tabela main</h3>\n<p>Do wypełnienia tabeli <code>main_1</code> wykorzystamy następujący kod</p>\n<pre><code class=\"language-php\">    /**\n     * @Route(&quot;/main&quot;)\n     * @Route(&quot;/main/{n}/{l}/{k}&quot;)\n     * @Route(&quot;/main/{n}/{l}/{k0}/{k}&quot;)\n     */\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1)\n    {\n        $conn = $this-&gt;getDoctrine()-&gt;getConnection();\n        if($k0==1) { $conn-&gt;delete('main_1',[1=&gt;1]); }\n        for($i=$k0;$i&lt;=$k;$i++){                // row in table main\n            $content = ['id'=&gt;$i];\n            for($j=1;$j&lt;=$n;$j++){            // foreign key of row\n                $content['minor_'.$j.'_id'] = rand(1,$l);\n            }\n            $conn-&gt;insert('main_1', $content);\n        }\n        return new  JsonResponse(['n'=&gt;$n,'l'=&gt;$l,'k0'=&gt;$k0,'k'=&gt;$k]);\n    }\n</code></pre>\n<p>Jest to akcja która nadaje się zarówno do czyszczenia, nadpisywania, jak i dopisywania do tabeli <code>main</code>. Tak duża ogólność została uzyskana dzięki dość ciekawemu routingowi. Zmienne <code>n</code> i <code>l</code> to odpowiednio liczba tabel typu <code>minor</code> oraz liczba ich wierszy. <code>k</code> jest maksymalnym indeksem <code>id</code> do którego będziemy wypełniać tabelę <code>main</code>. <code>k0</code> jest indeksem od którego zaczynamy. Jeśli wynosi on 1 lub nie jest podany, zawartość tabeli <code>main</code> zostanie skasowana przed dalszym zapisem.</p>\n<p>To co się dzieje wewnątrz pętli jest dość przewidywalne. Tworzymy wartość <code>id</code> zgodnie z zapowiedzianym schematem (<code>auto_increment</code>), losujemy klucze obce, zapisujemy wiersz i przechodzimy dalej. Tej akcji można użyć na kilka sposobów. Na przykład żeby wypełnić tabelę <code>main_1</code> dziesięcioma wierszami wpiszemy:</p>\n<pre><code>time http -b GET localhost:8000/main/10/10/10\n</code></pre>\n<p>Jeśli chcemy ją wyczyścić:</p>\n<pre><code>time http -b GET localhost:8000/main/10/10/0\n</code></pre>\n<p>Teraz możemy zapisać z powrotem 10 wierszy, ale rozbijając to na dwa kroki:</p>\n<pre><code>time http -b GET localhost:8000/main/10/10/1/5\ntime http -b GET localhost:8000/main/10/10/6/10\n</code></pre>\n<p>Zanim wypełnimy tabelę <code>main_1</code> milionami wierszy należy zauważyć, że pierwszą przyczyną dla której szybkość wykonywania insertów jest niezadowalająca jest sprawdzanie poprawności więzów przy każdym zapisie. Celowo nie dodałem transakcji, żebyśmy mogli porównać szybkość wykonywania tego kodu z analogicznym otoczonym transakcją. Wyniki dla <code>100k</code> wierszy:</p>\n<table>\n<thead>\n<tr>\n<th>Bez transakcji</th>\n<th>Z transakcją</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>6m 41.672s</td>\n<td>0m 57.804s</td>\n</tr>\n</tbody>\n</table>\n<p>Transakcje uzyskamy dzięki następującej modyfikacji ciała akcji <code>mainAction</code>:</p>\n<pre><code class=\"language-php\">        $conn = $this-&gt;getDoctrine()-&gt;getConnection();\n        if($k0==1) { $conn-&gt;delete('main_1',[1=&gt;1]); }\n        $conn-&gt;beginTransaction();\n        try{\n            // loop over rows - exactly the same as before\n            $conn-&gt;commit();\n        } catch(\\Exception $e) {\n            $conn-&gt;rollBack();\n            throw $e;\n        }\n        return new  JsonResponse(['n'=&gt;$n,'l'=&gt;$l,'k0'=&gt;$k0,'k'=&gt;$k]);\n</code></pre>\n<h2 id=\"pomiary\">Pomiary</h2>\n<p>Ponieważ nadszedł czas na wykonywanie pomiarów, warto było by stworzyć dla wyników kolejną tabelę nie połączoną z poprzednimi. Powinna ona zawierać czas, parametry i opis mierzonej funkcjonalności. Jednak dla czystości kodu oddzielimy część generującą tabele od wykonującej akcje. Zależy mi też na pogrupowaniu akcji ze względu na to czy stawiają bazę, czy dokonują na niej pomiarów. Oto nowa struktura katalogów jaką zastosujemy.</p>\n<p><img src=\"http://i.imgur.com/HFAxvGJ.png\" alt=\"katalogi\" loading=\"lazy\"></p>\n<p>Nasz model odpowiedzialny za tworzeniu schematu bazy będzie miał kod wycięty z prywatnych funkcji i własności <code>DefaultController</code> oraz jego konstruktora.</p>\n<blockquote>\n<p>src/AppBundle/Model/SchemaGenerator.php</p>\n</blockquote>\n<pre><code class=\"language-php\">&lt;?php\n\nnamespace AppBundle\\Model;\n\nuse AppBundle\\Controller\\BaseController;\nuse Doctrine\\DBAL\\Schema\\Schema;\nuse Doctrine\\DBAL\\Schema\\Table;\n\nclass SchemaGenerator\n</code></pre>\n<p>Nie zmieni się tam nic poza konstruktorem:</p>\n<pre><code class=\"language-php\">    public function __construct($n)\n    {\n        $this-&gt;main = [];\n        $this-&gt;minor = [];\n        $this-&gt;N = $n ? $n : BaseController::N;\n    }\n</code></pre>\n<p>Ustawia on domyślnie <code>N</code> na wartość stałej z <code>BaseController</code>, albo na wartość podaną przy powoływaniu instancji obiektu. Jak wspomniałem, funkcje <code>appendMinorToSchema</code> i <code>appendMainToSchema</code> się nie zmieniają. Dochodzi za to funkcja <code>appendLogToSchema</code>:</p>\n<pre><code class=\"language-php\">    /**\n     * @param $schema Schema\n     */\n    private function appendLogToSchema($schema)\n    {\n        $log = $schema-&gt;createTable(&quot;log&quot;);\n        $log-&gt;addColumn(&quot;id&quot;, &quot;integer&quot;,array(&quot;autoincrement&quot;=&gt;true,&quot;unsigned&quot; =&gt; true));\n        $log-&gt;addColumn(&quot;n&quot;, &quot;smallint&quot;,array(&quot;unsigned&quot; =&gt; true));\n        $log-&gt;addColumn(&quot;l&quot;, &quot;smallint&quot;,array(&quot;unsigned&quot; =&gt; true));\n        $log-&gt;addColumn(&quot;k0&quot;, &quot;integer&quot;,array(&quot;unsigned&quot; =&gt; true));\n        $log-&gt;addColumn(&quot;k&quot;, &quot;integer&quot;,array(&quot;unsigned&quot; =&gt; true));\n        $log-&gt;addColumn(&quot;execution_time&quot;, &quot;float&quot;);\n        $log-&gt;addColumn(&quot;operation&quot;, &quot;string&quot;,array());\n        $log-&gt;setPrimaryKey(array(&quot;id&quot;));\n    }\n</code></pre>\n<p>Będzie to tabela przechowująca wyniki pomiarów z parametrami. Wyposażymy nasz generator w jedną funkcję, która zbinduje poprzednie funkcje ze schematem i zwróci nam gotowy schemat.</p>\n<pre><code class=\"language-php\">    /**\n     * @return Schema Schema\n     */\n    public function generate()\n    {\n        $schema=new Schema();\n\n        $this-&gt;appendMinorToSchema($schema);\n        $this-&gt;appendMainToSchema($schema);\n        $this-&gt;appendLogToSchema($schema);\n\n        return $schema;\n    }\n</code></pre>\n<p>To wszystko, jeśli chodzi o model. Spójrzmy na kontroler bazowy.</p>\n<pre><code class=\"language-php\">&lt;?php\n\nnamespace AppBundle\\Controller;\n\nuse Symfony\\Bundle\\FrameworkBundle\\Controller\\Controller;\n\nclass BaseController extends Controller\n{\n    const N = 10;\n    const L = 10;\n    const K = 1000;\n}\n</code></pre>\n<p>Jest to nasz kontener na stałe. Sam nie wiem, czy w takim przypadku, nie lepiej było by tego nawet zrobić w parametrach <code>Symfony</code>. I pewnie tak zrobię, jeśli dla tego kontrolera nie pojawią się jakieś dodatkowe zastosowania. Tym czasem zostało nam jeszcze dostosowanie <code>DefaultController</code>. Przede wszystkim zmieniliśmy jego nazwę (nazwę pliku i klasy) na <code>PreparationController</code> aby lepiej odpowiadała jego funkcjonalności. W Metodzie <code>doAction</code> usunęliśmy ustawianie zmiennej prywatnej <code>N</code> w pierwszej instrukcji warunkowej. Wiąże się to z tym, że wycięliśmy też wszystkie zmienne i funkcje prywatne oraz konstruktor. Trzy linijkową generację schematu zastąpiliśmy linią:</p>\n<pre><code class=\"language-php\">        $schema = (new SchemaGenerator($n))-&gt;generate();\n</code></pre>\n<p>Na koniec zwiększyliśmy jeszcze bardziej elastyczność metody <code>mainAction</code>, ze względu na to, że zainteresowało mnie jakie dokładnie różnice robi ustawianie transakcji przy jakich ilościach wierszy. Dodałem też numer tabeli <code>main</code> do routingu, jeśli chcaił bym nie ruszając dużej już wypełnionej tabeli, wykonywać testy na tej drugiej.</p>\n<pre><code class=\"language-php\">    /**\n     * @Route(&quot;/main&quot;)\n     * @Route(&quot;/main/{n}/{l}/{k}&quot;)\n     * @Route(&quot;/main/{n}/{l}/{k0}/{k}&quot;)\n     * @Route(&quot;/main/{n}/{l}/{k0}/{k}/{main}/{transaction}&quot;)\n     */\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1,$main=1,$transaction=true)\n    {\n        $conn = $this-&gt;getDoctrine()-&gt;getConnection();\n        if($k0==1) { $conn-&gt;delete('main_'.$main,[1=&gt;1]); }\n        if($k&gt;1e4) { \n            set_time_limit(0);\n            ini_set(&quot;max_execution_time&quot;, 0); \n        }\n        if($transaction) {$conn-&gt;beginTransaction();}\n        try{\n            for($i=$k0;$i&lt;=$k;$i++){                // row in table main\n                $content = ['id'=&gt;$i];\n                for($j=1;$j&lt;=$n;$j++){            // foreign key of row\n                    $content['minor_'.$j.'_id'] = rand(1,$l);\n                }\n                $conn-&gt;insert('main_'.$main, $content);\n            }\n            if($transaction) {$conn-&gt;commit();}\n        } catch(\\Exception $e) {\n            if($transaction) {$conn-&gt;rollBack();}\n            throw $e;\n        }\n        return new  JsonResponse(['n'=&gt;$n,'l'=&gt;$l,'k0'=&gt;$k0,'k'=&gt;$k]);\n    }\n</code></pre>\n<p>Te zmiany pozwalają zapisać wiersze do drugiej tabeli bez transakcji:</p>\n<pre><code class=\"language-bash\">time http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/0\n</code></pre>\n<p>Lub z nimi</p>\n<pre><code class=\"language-bash\">time http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/1\n</code></pre>\n<p>Dodaliśmy też ustawianie dłuższego czasu wykonywania jeśli ilość zapisywanych wierszy jest odpowiednio duża.</p>\n<h3 id=\"hipotezy\">Hipotezy</h3>\n<p>Mamy już całkiem insteresujący zbiór zmiennych w naszym modelu. Możemy manipulować liczbą tabel typu <code>minor</code> - <code>N</code>, liczbą ich kluczy - <code>L</code>, ilością wierszy które wstawiamy <code>k-k0+1</code>  i numerem wiersza od którego zaczynamy <code>k0</code>. Możemy też wstawiać wiersze z wykorzystaniem lub bez użycia transakcji. Wadą naszego systemu pomiarowego jest narzut czasu związany z wykonywaniem <code>doctrine</code> i reszty <code>php</code>, zaletą elastyczność <code>api</code>, które wystawiliśmy. Jednak wadę o której wspomniałem jesteśmy w stanie łatwo wyeliminować wykonując odpowiednio długie pomiary. Przez długie mam na myśli długie w stosunku do czasu jaki zajmuje wykonanie kodu nie będącego bezpośrednio operacjami na bazie - łączenie, wczytywanie bibliotek itd. To zadanie od testowania selektów różni się tym, że mamy tu stosunkowo trudne, ale</p>\n<p>Testując będziemy zmieniać liczbę małych tabel <code>n</code>, 1-63, liczbę ich kluczy <code>l</code> od 1-50, liczbę wstawianych wierszy <code>k</code> od <code>1</code> do <code>100</code>.</p>\n<p>Interfejs: nazwa_testu, n,l,k</p>\n<h3 id=\"instalacja\">Instalacja</h3>\n<p>Instalacja składa się ze ściągnięcia repozytorium i wykonania skryptu instalacyjnego. W skrypcie należy zmienić parametry połączenia z bazą danych.</p>\n<pre><code>git clone https://github.com/gustawdaniel/test_inserts_performace --depth 1\ncd test_inserts_performace &amp;&amp; bash install.sh\n</code></pre>\n<p>Jeśli po wykonaniu instalacji proces <code>jdb2/sda1-8</code> będzie zabierał prawie całe <code>I/O</code> (screen z <code>iotop</code>):</p>\n<p><a href=\"https://postimg.org/image/wlcjx27g9/\"><img src=\"https://s28.postimg.org/o333sq0xp/iotop.png\" alt=\"iotop.png\" loading=\"lazy\"></a></p>\n<p>możemy go wyłączyć, ale wymaga to włączenia systemu w trybie bezpiecznym (<code>recovery mode</code>). Proces ten jest to tak zwany <code>journaling</code>.</p>\n<pre><code>umount /dev/sda1\ntune2fs -O ^has_journal /dev/sda1\n</code></pre>\n<p>Zwykłe kopiowanie</p>\n<pre><code>INSERT INTO major_2 SELECT * FROM major_1;\nQuery OK, 1000000 rows affected (8 min 38,35 sec)\n</code></pre>\n<p>Mysqldump</p>\n<pre><code>time mysqldump -u root training major_1 &gt; major_1.sql\n</code></pre>\n<p>Pliki generowane przez mysqldump zwykle są duże i nie warto ich oglądać w całości. Podobnie jak <code>head</code> służy do wyświetlania pierwszych linii pliku tak poniższym poleceniem wyświetlimy pierwsze znaki każdej linii.</p>\n<pre><code>awk '{print substr($0,1,210);}' major_1.sql\n</code></pre>\n<p>Ponieważ interesuje nas wrzucenie danych do tabeli major_2, więc chcemy wybrać tylko inserty i zmienić 1 na 2 w nazwie tabeli. W języku skryptowym <code>awk</code> tego typu zadania załatwia się jedną linią:</p>\n<pre><code>awk '/^INSERT/ {sub(&quot;_1&quot;,&quot;_2&quot;,$0); print $0;}' major_1.sql &gt; major_2.sql\n</code></pre>\n<p>Teraz możemy wykonać wrzut danych do bazy.</p>\n<h2 id=\"instalacja\">Instalacja</h2>\n<pre><code>git clone http://github.com/gustawdaniel/test_inserts_performance\ncd test_inserts_performance\nbash install.sh\n</code></pre>\n<p>paste Dropbox token</p>\n<pre><code>bash bash/initialize.sh \nphp app.php\nbash bash/send.sh\n</code></pre>\n<p>On analysing machine</p>\n<pre><code>mysql -u root training -e &quot;TRUNCATE log; TRUNCATE machine;&quot;\nbash bash/get.sh\n</code></pre>\n<hr>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\">StackEdit</a>.</p>\n</blockquote>\n<h1 id=\"testowanie-szybko%C5%9Bci-insert%C3%B3w\">Testowanie szybkości insertów</h1>\n<p>[toc]</p>\n<h2 id=\"opis-projektu\">Opis projektu</h2>\n<p>Problemem, który omówimy tym razem będzie optymalizacja szybkości zapisu do bazy danych przy kilku warunkach. Zakładamy, że nasza tabela ma nałożone klucze a więc również indeksy. Wiemy, że dane które chcemy do niej zapisać są poprawne. Podczas zapisu tych danych na pewno nie jest wykonywany żaden inny zapis.</p>\n<p>Jako, że dopiero zaczynam zabawę z większymi zbiorami danych, moje intuicje są oparte głównie na czytaniu dokumentacji i celem tego ćwiczenia jest wyrobienie sobie ilościowego wyczucia w tej materii.</p>\n<h2 id=\"zastosowane-technologie\">Zastosowane technologie</h2>\n<p>Inaczej, niż przy testowaniu selektów, nie decyduję się tym razem na czystego <code>sql</code>. Zamiast tego wykorzystamy <code>doctrine</code> ze względu na jego mechanizm dziedziczenia, którego sam <code>sql</code> z tego co wiem nie oferuje. Poza tym pisanie procedur do testowania w <code>php</code> i wystawienie przez niego <code>api</code> wydaje mi się bardziej atrakcyjne niż liniowe pliki wykonywalne w <code>sql</code>.</p>\n<p>Do obsługi <code>doctrine</code> wykorzystamy <code>symfony</code> - genialnie napisany framework <code>php</code>. Trochę trudniejszy niż Laravel, ale z drugiej strony polecany do większych projektów, gdzie elastyczność i stabilność są bardzo ważne. Instalacja polega na wykonaniu komendy:</p>\n<pre><code class=\"language-bash\">symfony new insert_test latest &amp;&amp; cd insert_test\n</code></pre>\n<p>Zaczniemy od konfiguracji i w pliku <code>app/config/parameters.yml</code> zmienimy <code>database_name</code> na <code>insert_test</code>. Bazę danych stawiamy komendą:</p>\n<pre><code class=\"language-bash\">php bin/console doctrine:database:create\n</code></pre>\n<p>Jest pusta, dlatego teraz zajmiemy się jej wypełnianiem.</p>\n<h2 id=\"struktura-bazy-danych\">Struktura bazy danych</h2>\n<p>Interesuje nas przerzucanie danych między dwiema identycznymi tabelami, które mają powiązania przez więzy integralności referencyjnej z kilkoma mniejszymi tabelami. Nasza baza danych będzie więc przypominała pajęczynę, w której dwie duże tabele będą odnosić się <code>n</code> kluczami do <code>n</code> mniejszych nie powiązanych tabel. Główne tabela nazwiemy <code>main_1</code> i <code>main_2</code>, a mniejsze <code>minor_1</code>, <code>minor_2</code>, ... <code>minor_n</code>. Ponieważ obraz mówi więcej niż tysiąc słów załączam diagram hierarchiczny bazy:</p>\n<p><img src=\"http://i.imgur.com/8z63XFy.png\" alt=\"struktura_hierarchiczna\" loading=\"lazy\"></p>\n<p>A dla wyjaśnienia, dlaczego początkowo wyobrażałem sobie tą bazę jak pajęczynę, prezentuję też diagram organiczny tej samej bazy.</p>\n<p><img src=\"http://i.imgur.com/jaxTv9m.png\" alt=\"struktura_organiczna\" loading=\"lazy\"></p>\n<p>Właściwie, to te duże tabele będą miały poważne problemy z optymalnością insertów dokładnie tak jak by było w sieci pająka...</p>\n<p>Wracając do konkretów, ponieważ optymalność nie będzie testowana na mniejszych tabelach, nie dostaną one kluczy obcych, a więc to od nich zaczniemy stawianie bazy. Będą one zawierały tylko jedno pole - <code>id</code> będące ich kluczem głównym. Po ich utworzeniu będą tworzone tabele główne, i dopiero wtedy będziemy im dodawać klucze obce.</p>\n<h2 id=\"tworzenie-tabel\">Tworzenie tabel</h2>\n<p>Kiedy kończyłem pisać wpis o <a href=\"http://blog.gustawdaniel.pl/2016/12/02/tesseract-ocr-i-testowanie-selekt%C3%B3w.html\">testowaniu selektów</a> za pomocą Behata, nie byłem zbyt zadowolony z pisania scenariuszy, które różniły się tylko liczbą atrybutów, lub warunków. Mimo, że bardzo wygodny dla osób nie technicznych, <code>Gherkin</code> nie dawał mi wystarczającej elastyczności. Podobnie czułem się <a href=\"http://blog.gustawdaniel.pl/2016/12/08/testowanie-szybko%C5%9Bci-selekt%C3%B3w.html\">pisząc procedury</a> w czystym <code>SQL</code>. Brak dziedziczenia sprawiał, że musiałem kopiować kod, a tego bardzo nie lubię.</p>\n<p>Zupełnie inaczej jest tym razem. Całość kodu odpowiedzialnego za tworzenie całej tej bazy danych i wystawienie do tego prymitywnego, ale funkcjonalnego <code>API</code> mieści się w 100 liniach kodu.</p>\n<p>Naszą zabawę możemy zacząć od usunięcia katalogu <code>Resources</code> z <code>app/config</code>. Nasz kontroler będzie rozmawiał w <code>jsonie</code>, więc widoki nie będą nam potrzebne. Przechodzimy do edycji kontrolera. Zaczynamy od dołączenia bibliotek:</p>\n<blockquote>\n<p>src/AppBundle/Controller/DefaultController.php</p>\n</blockquote>\n<pre><code class=\"language-php\">&lt;?php\n\nnamespace AppBundle\\Controller;\n\nuse Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route;\nuse Symfony\\Bundle\\FrameworkBundle\\Controller\\Controller;\nuse Symfony\\Component\\HttpFoundation\\JsonResponse;\nuse Doctrine\\DBAL\\Schema\\Schema;\nuse Doctrine\\DBAL\\Schema\\Comparator;\nuse Doctrine\\DBAL\\Schema\\Table;\n</code></pre>\n<p>Mamy tu <code>Route</code> odpowiadające za przypisywanie adnotacjom przy akcjach odpowiednich ścieżek w routingu. Jest <code>Controller</code>, który pozwala nam odnosić się do wszystkich najbardziej podstawowych funkcji <code>Symfony</code> przez <code>$this</code>. Następnie <code>JsonResponse</code> łączący działanie funkcji <code>json_decode</code> z jednoczesnym ustawianiem nagłówka na <code>application/json</code>. Trzy kolejne to paczki <code>Doctrine</code>, które odpowiednio tłumaczą jego <code>api</code> na <code>SQL</code> i dostarczają obiekty <code>Doctrine</code>.</p>\n<p>Wewnątrz kontrolera będą istnieć dwie zmienne prywatne będące tablicami tabel <code>main</code> i <code>minor</code> oraz liczba określające ile tabel typu <code>minor</code> ma występować.</p>\n<pre><code class=\"language-php\">class DefaultController extends Controller\n{\n    /**\n     * @var Table[]\n     */\n    private $main, $minor;\n\n    private $N;\n\n    public function __construct()\n    {\n        $this-&gt;main = [];\n        $this-&gt;minor = [];\n        $this-&gt;N = 10;\n    }\n</code></pre>\n<p>Konstruktor ustawia <code>$minor</code> i <code>$main</code> jako puste tablice, a domyślną liczbę tabel na <code>10</code>. Klasa <code>Table</code> jest jednym z obiektów <code>doctrine</code>, które dopiero co załączyliśmy. Obsługę tej klasy zobaczymy za chwilę w funkcji tworzącej schemat jednej z tabel.</p>\n<pre><code class=\"language-php\">    /**\n     * @param $schema Schema\n     */\n    private function appendMinorToSchema($schema)\n    {\n        for($i=1;$i&lt;=$this-&gt;N;$i++) {\n            $this-&gt;minor[$i] = $schema-&gt;createTable(&quot;minor_&quot;.$i);\n            $this-&gt;minor[$i]-&gt;addColumn(&quot;id&quot;, &quot;integer&quot;);\n            $this-&gt;minor[$i]-&gt;setPrimaryKey(array(&quot;id&quot;));\n        }\n    }\n</code></pre>\n<p>Jak wspominałem wcześniej zaczynamy od tworzenia mniejszych tabel. Ponieważ ma być ich <code>N</code>, właśnie to tej wielkości ustawiona jest pętla. Wewnątrz do zmiennej zawierającej tabele <code>$minor</code> przypisujemy wynik metody <code>creteTable</code> na schemacie, który będzie podany jako argument. Schemat odpowiada temu jak <code>doctrine</code> rozumie strukturę bazy danych w ramach swoich własnych klas. Tworzonej tabeli przypisywany jest atrybut będący kluczem głównym. To wystarczy. Odrobinę bardziej złożoną logikę ma tworzenie dużych tabel.</p>\n<pre><code class=\"language-php\">    /**\n     * @param $schema Schema\n     */\n    private function appendMainToSchema($schema)\n    {\n        for($i=1;$i&lt;=2;$i++)\n        {\n            $this-&gt;main[$i] = $schema-&gt;createTable(&quot;main_&quot;.$i);\n            $this-&gt;main[$i]-&gt;addColumn(&quot;id&quot;, &quot;integer&quot;);\n            for($j=1;$j&lt;=$this-&gt;N;$j++)\n            {\n                $this-&gt;main[$i]-&gt;addColumn(&quot;minor_&quot;.$j.&quot;_id&quot;, &quot;integer&quot;);\n                $this-&gt;main[$i]-&gt;addForeignKeyConstraint($this-&gt;minor[$j], array(&quot;minor_&quot;.$j.&quot;_id&quot;), array(&quot;id&quot;));\n            }\n            $this-&gt;main[$i]-&gt;setPrimaryKey(array(&quot;id&quot;));\n        }\n    }\n</code></pre>\n<p>Ponieważ są dwie, pętla główna przebiega tylko wartości <code>1</code> i <code>2</code>. Tak jak poprzednio do schematu dodawane są tabele, oraz kolumna o nazwie <code>id</code>, która zostanie u nas kluczem głównym. Nie dostała ona <code>auto_increment</code> bo będziemy ją ustawiać w zewnętrznym skrypcie.</p>\n<p>Po dodaniu bazowego atrybutu - <code>id</code> do tabeli rozpoczynamy pętlę po mniejszych tabelach, w której podpinamy kolumnę i przypisujemy jej więzy integralności referencyjnej. Na ustanawiamy <code>id</code> kluczem głównym.</p>\n<p>Na tym się kończy lista zmiennych i metod. Jak w zwykłych skryptach, przechodzimy do ciała programu.</p>\n<pre><code class=\"language-php\">    /**\n     * @Route(&quot;/&quot;, name=&quot;home&quot;)\n     * @Route(&quot;/do/{n}&quot;)\n     */\n    public function indexAction($n=10,$action=&quot;do&quot;)\n    {\n        if($n){ $this-&gt;N = $n; }\n        $conn = $this-&gt;getDoctrine()-&gt;getConnection();\n</code></pre>\n<p>Routing pozwala nam wybrać domyślną ścieżkę <code>/</code>, albo określić akcję i wybrać dla niej argument. Na tym etapie będziemy mieli dwie akcje - <code>show</code> i <code>do</code>. Show będzie jedynie wyświetlało kod <code>SQL</code> jaki trzeba wykonać, aby obecny stan bazy przekształcić do posiadającego <code>n</code> małych tabel, a <code>do</code> będzie nie tylko pokazywać, ale też wykonywać ten kod. Jak łatwo zgadnąć, <code>n</code> jest właśnie liczbą tabel i nadpisuje domyślne <code>10</code> z konstruktora. Na końcu tego kodu tworzymy połączenie z bazą danych i zapisujemy jego reprezentację do zmiennej <code>$conn</code>. Teraz przygotujemy schemat.</p>\n<pre><code class=\"language-php\">        $schema = new Schema();\n\n        $this-&gt;appendMinorToSchema($schema);\n        $this-&gt;appendMainToSchema($schema);\n</code></pre>\n<p>Schemat, czyli to jak <code>doctrine</code> rozumie strukturę bazy tworzymy w trzech linijkach. Czas porównać go z obecnym stanem bazy.</p>\n<pre><code class=\"language-php\">        $comparator = new Comparator();\n        $queries = $comparator-&gt;compare($conn-&gt;getSchemaManager()-&gt;createSchema(), $schema)-&gt;toSql($conn-&gt;getDatabasePlatform());\n\n</code></pre>\n<p>Dzięki obiektom <code>Comparator</code> oraz <code>ShemaManager</code> otrzymanie tablicy z zapytaniami <code>SQL</code> aktualizującymi naszą strukturę bazy mieści się w dwóch liniach. Zostało już tylko wykonanie tych zapytań, jeśli <code>action</code> ustawione jest na <code>do</code>.</p>\n<pre><code class=\"language-php\">        if($action==&quot;do&quot;){\n            foreach($queries as $query) {\n                $conn-&gt;prepare($query)-&gt;execute();\n            }\n        }\n</code></pre>\n<p>Dzięki metodom pozwalającym wykonywać czyste sqlowe zapytania nasze zadanie sprowadza się do wykonania pętli po nich. Możemy teraz zwrócić użytkownikowi jakiś sensowny komunikat.</p>\n<pre><code class=\"language-php\">        return new JsonResponse(\n            [\n                &quot;alter&quot;=&gt;$queries,\n            ]\n        );\n    }\n}\n</code></pre>\n<p>Najlepszy wydał mi się <code>json</code> z listą zapytań jakie należy wykonać, aby obecny stan bazy przekształcić do zadanego przez parametr <code>n</code>. Na koniec dołączam metodę <code>show</code>, która świetnie nadaje się do debugowania, ale nie pełni żadnej funkcji poza tym:</p>\n<pre><code class=\"language-php\">    /**\n    * @Route(&quot;/show/{n}&quot;)\n    */\n    public function showAction($n=10)\n    {\n        return $this-&gt;doAction($n,&quot;show&quot;);\n    }\n</code></pre>\n<p>Żeby móc obsłużyć nasz kontroler postawimy serwer komendą.</p>\n<pre><code class=\"language-bash\">php bin/console server:run\n</code></pre>\n<p>I w drugim terminalu wyślemy request http, który wypełni nam bazę tabelami.</p>\n<pre><code>time http -b GET localhost:8000/do/10\n</code></pre>\n<p>Jego wykonanie trwało u mnie 3 sekundy, a odpowiedź wyglądała tak:</p>\n<p><img src=\"http://i.imgur.com/NQVaaWB.png\" alt=\"database_creation\" loading=\"lazy\"></p>\n<h2 id=\"wype%C5%82nianie-bazy-danymi\">Wypełnianie bazy danymi</h2>\n<p>Nadszedł czas wypełnić bazę danymi. Dla małych tabel będą to liczby z przedziału od <code>1</code> do <code>L</code>. Dla dużych będziemy losować <code>N</code> liczb od <code>1</code> do <code>L</code>, które dodamy do kluczy obcych. Wartość <code>id</code> ustawimy na <code>auto_increment</code> ale nie z poziomu <code>sql</code> tylko przez zewnętrzny skrypt. Poza małymi tabelami wypełnimy tylko tabelę <code>main_1</code>, zostawiając <code>main_2</code> pustą. Przypominam, że chcemy przetestować klonowanie dużej tabli z dużą ilością kluczy obcych.</p>\n<h3 id=\"tabele-minor\">Tabele minor</h3>\n<p>Zaczniemy od wypełniania małych tabel. Podzielę ten proces na wypełnianie małych i dużej tabeli oddzielnie, ze względu na większą elastyczność takiego podejścia, a po części też dlatego, że da mi to lepszy wgląd w czasy wykonywania poszczególnych procesów. Małe tabele będziemy tworzyć za pomocą następującej akcji w <code>DefaultController</code>:</p>\n<pre><code class=\"language-php\">    /**\n     * @Route(&quot;/minor/{n}/{l}&quot;)\n     */\n    public function minorAction($n=10,$l=10)\n    {\n        $conn = $this-&gt;getDoctrine()-&gt;getConnection();\n        for($i=1;$i&lt;=$n;$i++){\n            $conn-&gt;delete('minor_'.$i,[1=&gt;1]);\n            for($j=1;$j&lt;=$l;$j++){\n                $conn-&gt;insert('minor_'.$i, array('id' =&gt; $j));\n            }\n        }\n        return new  JsonResponse(['n'=&gt;$n, 'l'=&gt;$l]);\n    }\n</code></pre>\n<p>Jest ona wyjątkowo prosta, ale posiada jeden dość ciekawy hak. Chodzi o idempotentność. W metodzie <code>delete</code> obiektu <code>Connection</code> mamy nazwę tabeli a później tablicę <code>[1=&gt;1]</code>. Jest to warunek który w instrukcji <code>DELETE FROM</code> występuje za <code>WHERE</code>. <code>1=1</code> jest zawsze prawdziwe i dlatego przed rozpoczęciem zapisu zostają usunięte zostają wszystkie elementy jednym zapytaniem. Żeby wywołać tą akcję wystarczy wpisać w konsoli:</p>\n<pre><code class=\"language-bash\">time http -b GET localhost:8000/minor/10/10\n</code></pre>\n<p>Odpowiedź którą zobaczymy będzie wyglądała tak:</p>\n<pre><code class=\"language-json\">{\n    &quot;l&quot;: &quot;10&quot;, \n    &quot;n&quot;: &quot;10&quot;\n}\n</code></pre>\n<h3 id=\"dodanie-sta%C5%82ych\">Dodanie stałych</h3>\n<p>Mógł bym kontynuować dodawanie akcji, ale zacząłem martwić się zbytnią powtarzalnością wartości domyślnych. Zanim przejdziemy dalej wprowadzimy w kodzie następujące zmiany. Na początku kontrolera definiujemy stałe:</p>\n<pre><code class=\"language-php\">    const N = 10;\n    const L = 10;\n    const K = 1000;\n</code></pre>\n<p>W konstruktorze ustawiamy <code>private $N</code> na:</p>\n<pre><code class=\"language-php\">        $this-&gt;N = self::N;\n</code></pre>\n<p>Zmieniamy domyślne wartości w definicjach akcji na następujące:</p>\n<pre><code class=\"language-php\">    public function doAction($n=self::N,$action=&quot;do&quot;)\n    public function showAction($n=self::N)\n    public function minorAction($n=self::N,$l=self::L)\n</code></pre>\n<p>Dodajemy routingi bez parametrów, czyli</p>\n<pre><code class=\"language-php\">     * @Route(&quot;/show&quot;)\n</code></pre>\n<p>przed <code> * @Route(&quot;/minor/{n}/{l}&quot;)</code> oraz</p>\n<pre><code class=\"language-ph\">     * @Route(&quot;/minor&quot;)\n</code></pre>\n<p>przed <code>* @Route(&quot;/main/{n}/{l}/{k}&quot;)</code></p>\n<h3 id=\"tabela-main\">Tabela main</h3>\n<p>Do wypełnienia tabeli <code>main_1</code> wykorzystamy następujący kod</p>\n<pre><code class=\"language-php\">    /**\n     * @Route(&quot;/main&quot;)\n     * @Route(&quot;/main/{n}/{l}/{k}&quot;)\n     * @Route(&quot;/main/{n}/{l}/{k0}/{k}&quot;)\n     */\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1)\n    {\n        $conn = $this-&gt;getDoctrine()-&gt;getConnection();\n        if($k0==1) { $conn-&gt;delete('main_1',[1=&gt;1]); }\n        for($i=$k0;$i&lt;=$k;$i++){                // row in table main\n            $content = ['id'=&gt;$i];\n            for($j=1;$j&lt;=$n;$j++){            // foreign key of row\n                $content['minor_'.$j.'_id'] = rand(1,$l);\n            }\n            $conn-&gt;insert('main_1', $content);\n        }\n        return new  JsonResponse(['n'=&gt;$n,'l'=&gt;$l,'k0'=&gt;$k0,'k'=&gt;$k]);\n    }\n</code></pre>\n<p>Jest to akcja która nadaje się zarówno do czyszczenia, nadpisywania, jak i dopisywania do tabeli <code>main</code>. Tak duża ogólność została uzyskana dzięki dość ciekawemu routingowi. Zmienne <code>n</code> i <code>l</code> to odpowiednio liczba tabel typu <code>minor</code> oraz liczba ich wierszy. <code>k</code> jest maksymalnym indeksem <code>id</code> do którego będziemy wypełniać tabelę <code>main</code>. <code>k0</code> jest indeksem od którego zaczynamy. Jeśli wynosi on 1 lub nie jest podany, zawartość tabeli <code>main</code> zostanie skasowana przed dalszym zapisem.</p>\n<p>To co się dzieje wewnątrz pętli jest dość przewidywalne. Tworzymy wartość <code>id</code> zgodnie z zapowiedzianym schematem (<code>auto_increment</code>), losujemy klucze obce, zapisujemy wiersz i przechodzimy dalej. Tej akcji można użyć na kilka sposobów. Na przykład żeby wypełnić tabelę <code>main_1</code> dziesięcioma wierszami wpiszemy:</p>\n<pre><code>time http -b GET localhost:8000/main/10/10/10\n</code></pre>\n<p>Jeśli chcemy ją wyczyścić:</p>\n<pre><code>time http -b GET localhost:8000/main/10/10/0\n</code></pre>\n<p>Teraz możemy zapisać z powrotem 10 wierszy, ale rozbijając to na dwa kroki:</p>\n<pre><code>time http -b GET localhost:8000/main/10/10/1/5\ntime http -b GET localhost:8000/main/10/10/6/10\n</code></pre>\n<p>Zanim wypełnimy tabelę <code>main_1</code> milionami wierszy należy zauważyć, że pierwszą przyczyną dla której szybkość wykonywania insertów jest niezadowalająca jest sprawdzanie poprawności więzów przy każdym zapisie. Celowo nie dodałem transakcji, żebyśmy mogli porównać szybkość wykonywania tego kodu z analogicznym otoczonym transakcją. Wyniki dla <code>100k</code> wierszy:</p>\n<table>\n<thead>\n<tr>\n<th>Bez transakcji</th>\n<th>Z transakcją</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>6m 41.672s</td>\n<td>0m 57.804s</td>\n</tr>\n</tbody>\n</table>\n<p>Transakcje uzyskamy dzięki następującej modyfikacji ciała akcji <code>mainAction</code>:</p>\n<pre><code class=\"language-php\">        $conn = $this-&gt;getDoctrine()-&gt;getConnection();\n        if($k0==1) { $conn-&gt;delete('main_1',[1=&gt;1]); }\n        $conn-&gt;beginTransaction();\n        try{\n            // loop over rows - exactly the same as before\n            $conn-&gt;commit();\n        } catch(\\Exception $e) {\n            $conn-&gt;rollBack();\n            throw $e;\n        }\n        return new  JsonResponse(['n'=&gt;$n,'l'=&gt;$l,'k0'=&gt;$k0,'k'=&gt;$k]);\n</code></pre>\n<h2 id=\"pomiary\">Pomiary</h2>\n<p>Ponieważ nadszedł czas na wykonywanie pomiarów, warto było by stworzyć dla wyników kolejną tabelę nie połączoną z poprzednimi. Powinna ona zawierać czas, parametry i opis mierzonej funkcjonalności. Jednak dla czystości kodu oddzielimy część generującą tabele od wykonującej akcje. Zależy mi też na pogrupowaniu akcji ze względu na to czy stawiają bazę, czy dokonują na niej pomiarów. Oto nowa struktura katalogów jaką zastosujemy.</p>\n<p><img src=\"http://i.imgur.com/HFAxvGJ.png\" alt=\"katalogi\" loading=\"lazy\"></p>\n<p>Nasz model odpowiedzialny za tworzeniu schematu bazy będzie miał kod wycięty z prywatnych funkcji i własności <code>DefaultController</code> oraz jego konstruktora.</p>\n<blockquote>\n<p>src/AppBundle/Model/SchemaGenerator.php</p>\n</blockquote>\n<pre><code class=\"language-php\">&lt;?php\n\nnamespace AppBundle\\Model;\n\nuse AppBundle\\Controller\\BaseController;\nuse Doctrine\\DBAL\\Schema\\Schema;\nuse Doctrine\\DBAL\\Schema\\Table;\n\nclass SchemaGenerator\n</code></pre>\n<p>Nie zmieni się tam nic poza konstruktorem:</p>\n<pre><code class=\"language-php\">    public function __construct($n)\n    {\n        $this-&gt;main = [];\n        $this-&gt;minor = [];\n        $this-&gt;N = $n ? $n : BaseController::N;\n    }\n</code></pre>\n<p>Ustawia on domyślnie <code>N</code> na wartość stałej z <code>BaseController</code>, albo na wartość podaną przy powoływaniu instancji obiektu. Jak wspomniałem, funkcje <code>appendMinorToSchema</code> i <code>appendMainToSchema</code> się nie zmieniają. Dochodzi za to funkcja <code>appendLogToSchema</code>:</p>\n<pre><code class=\"language-php\">    /**\n     * @param $schema Schema\n     */\n    private function appendLogToSchema($schema)\n    {\n        $log = $schema-&gt;createTable(&quot;log&quot;);\n        $log-&gt;addColumn(&quot;id&quot;, &quot;integer&quot;,array(&quot;autoincrement&quot;=&gt;true,&quot;unsigned&quot; =&gt; true));\n        $log-&gt;addColumn(&quot;n&quot;, &quot;smallint&quot;,array(&quot;unsigned&quot; =&gt; true));\n        $log-&gt;addColumn(&quot;l&quot;, &quot;smallint&quot;,array(&quot;unsigned&quot; =&gt; true));\n        $log-&gt;addColumn(&quot;k0&quot;, &quot;integer&quot;,array(&quot;unsigned&quot; =&gt; true));\n        $log-&gt;addColumn(&quot;k&quot;, &quot;integer&quot;,array(&quot;unsigned&quot; =&gt; true));\n        $log-&gt;addColumn(&quot;execution_time&quot;, &quot;float&quot;);\n        $log-&gt;addColumn(&quot;operation&quot;, &quot;string&quot;,array());\n        $log-&gt;setPrimaryKey(array(&quot;id&quot;));\n    }\n</code></pre>\n<p>Będzie to tabela przechowująca wyniki pomiarów z parametrami. Wyposażymy nasz generator w jedną funkcję, która zbinduje poprzednie funkcje ze schematem i zwróci nam gotowy schemat.</p>\n<pre><code class=\"language-php\">    /**\n     * @return Schema Schema\n     */\n    public function generate()\n    {\n        $schema=new Schema();\n\n        $this-&gt;appendMinorToSchema($schema);\n        $this-&gt;appendMainToSchema($schema);\n        $this-&gt;appendLogToSchema($schema);\n\n        return $schema;\n    }\n</code></pre>\n<p>To wszystko, jeśli chodzi o model. Spójrzmy na kontroler bazowy.</p>\n<pre><code class=\"language-php\">&lt;?php\n\nnamespace AppBundle\\Controller;\n\nuse Symfony\\Bundle\\FrameworkBundle\\Controller\\Controller;\n\nclass BaseController extends Controller\n{\n    const N = 10;\n    const L = 10;\n    const K = 1000;\n}\n</code></pre>\n<p>Jest to nasz kontener na stałe. Sam nie wiem, czy w takim przypadku, nie lepiej było by tego nawet zrobić w parametrach <code>Symfony</code>. I pewnie tak zrobię, jeśli dla tego kontrolera nie pojawią się jakieś dodatkowe zastosowania. Tym czasem zostało nam jeszcze dostosowanie <code>DefaultController</code>. Przede wszystkim zmieniliśmy jego nazwę (nazwę pliku i klasy) na <code>PreparationController</code> aby lepiej odpowiadała jego funkcjonalności. W Metodzie <code>doAction</code> usunęliśmy ustawianie zmiennej prywatnej <code>N</code> w pierwszej instrukcji warunkowej. Wiąże się to z tym, że wycięliśmy też wszystkie zmienne i funkcje prywatne oraz konstruktor. Trzy linijkową generację schematu zastąpiliśmy linią:</p>\n<pre><code class=\"language-php\">        $schema = (new SchemaGenerator($n))-&gt;generate();\n</code></pre>\n<p>Na koniec zwiększyliśmy jeszcze bardziej elastyczność metody <code>mainAction</code>, ze względu na to, że zainteresowało mnie jakie dokładnie różnice robi ustawianie transakcji przy jakich ilościach wierszy. Dodałem też numer tabeli <code>main</code> do routingu, jeśli chcaił bym nie ruszając dużej już wypełnionej tabeli, wykonywać testy na tej drugiej.</p>\n<pre><code class=\"language-php\">    /**\n     * @Route(&quot;/main&quot;)\n     * @Route(&quot;/main/{n}/{l}/{k}&quot;)\n     * @Route(&quot;/main/{n}/{l}/{k0}/{k}&quot;)\n     * @Route(&quot;/main/{n}/{l}/{k0}/{k}/{main}/{transaction}&quot;)\n     */\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1,$main=1,$transaction=true)\n    {\n        $conn = $this-&gt;getDoctrine()-&gt;getConnection();\n        if($k0==1) { $conn-&gt;delete('main_'.$main,[1=&gt;1]); }\n        if($k&gt;1e4) { \n            set_time_limit(0);\n            ini_set(&quot;max_execution_time&quot;, 0); \n        }\n        if($transaction) {$conn-&gt;beginTransaction();}\n        try{\n            for($i=$k0;$i&lt;=$k;$i++){                // row in table main\n                $content = ['id'=&gt;$i];\n                for($j=1;$j&lt;=$n;$j++){            // foreign key of row\n                    $content['minor_'.$j.'_id'] = rand(1,$l);\n                }\n                $conn-&gt;insert('main_'.$main, $content);\n            }\n            if($transaction) {$conn-&gt;commit();}\n        } catch(\\Exception $e) {\n            if($transaction) {$conn-&gt;rollBack();}\n            throw $e;\n        }\n        return new  JsonResponse(['n'=&gt;$n,'l'=&gt;$l,'k0'=&gt;$k0,'k'=&gt;$k]);\n    }\n</code></pre>\n<p>Te zmiany pozwalają zapisać wiersze do drugiej tabeli bez transakcji:</p>\n<pre><code class=\"language-bash\">time http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/0\n</code></pre>\n<p>Lub z nimi</p>\n<pre><code class=\"language-bash\">time http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/1\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Dodaliśmy też ustawianie dłuższego czasu wykonywania jeśli ilość zapisywanych wierszy jest odpowiednio duża.</p>\n<h3 id=\"hipotezy\">Hipotezy</h3>\n<p>Mamy już całkiem insteresujący zbiór zmiennych w naszym modelu. Możemy manipulować liczbą tabel typu <code>minor</code> - <code>N</code>, liczbą ich kluczy - <code>L</code>, ilością wierszy które wstawiamy <code>k-k0+1</code>  i numerem wiersza od którego zaczynamy <code>k0</code>. Możemy też wstawiać wiersze z wykorzystaniem lub bez użycia transakcji. Wadą naszego systemu pomiarowego jest narzut czasu związany z wykonywaniem <code>doctrine</code> i reszty <code>php</code>, zaletą elastyczność <code>api</code>, które wystawiliśmy. Jednak wadę o której wspomniałem jesteśmy w stanie łatwo wyeliminować wykonując odpowiednio długie pomiary. Przez długie mam na myśli długie w stosunku do czasu jaki zajmuje wykonanie kodu nie będącego bezpośrednio operacjami na bazie - łączenie, wczytywanie bibliotek itd. To zadanie od testowania selektów różni się tym, że mamy tu stosunkowo trudne, ale</p>\n<p>Testując będziemy zmieniać liczbę małych tabel <code>n</code>, 1-63, liczbę ich kluczy <code>l</code> od 1-50, liczbę wstawianych wierszy <code>k</code> od <code>1</code> do <code>100</code>.</p>\n<p>Interfejs: nazwa_testu, n,l,k</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "607f3ec02fb35425592d0c10",
            "plaintext": "Struktura bazy danych\nInteresuje nas przerzucanie danych między dwiema identycznymi tabelami, które\nmają powiązania przez więzy integralności referencyjnej z kilkoma mniejszymi\ntabelami. Nasza baza danych będzie więc przypominała pajęczynę, w której dwie\nduże tabele będą odnosić się n kluczami do n mniejszych nie powiązanych tabel.\nGłówne tabela nazwiemy main_1 i main_2, a mniejsze minor_1, minor_2, ... minor_n\n. Ponieważ obraz mówi więcej niż tysiąc słów załączam diagram hierarchiczny\nbazy:\n\n\n\nA dla wyjaśnienia, dlaczego początkowo wyobrażałem sobie tą bazę jak pajęczynę,\nprezentuję też diagram organiczny tej samej bazy.\n\n\n\nWłaściwie, to te duże tabele będą miały poważne problemy z optymalnością\ninsertów dokładnie tak jak by było w sieci pająka...\n\nWracając do konkretów, ponieważ optymalność nie będzie testowana na mniejszych\ntabelach, nie dostaną one kluczy obcych, a więc to od nich zaczniemy stawianie\nbazy. Będą one zawierały tylko jedno pole - id będące ich kluczem głównym. Po\nich utworzeniu będą tworzone tabele główne, i dopiero wtedy będziemy im dodawać\nklucze obce.\n\nTworzenie tabel\nKiedy kończyłem pisać wpis o testowaniu selektów\n[http://blog.gustawdaniel.pl/2016/12/02/tesseract-ocr-i-testowanie-selekt%C3%B3w.html] \nza pomocą Behata, nie byłem zbyt zadowolony z pisania scenariuszy, które różniły\nsię tylko liczbą atrybutów, lub warunków. Mimo, że bardzo wygodny dla osób nie\ntechnicznych, Gherkin nie dawał mi wystarczającej elastyczności. Podobnie czułem\nsię pisząc procedury\n[http://blog.gustawdaniel.pl/2016/12/08/testowanie-szybko%C5%9Bci-selekt%C3%B3w.html] \nw czystym SQL. Brak dziedziczenia sprawiał, że musiałem kopiować kod, a tego\nbardzo nie lubię.\n\nZupełnie inaczej jest tym razem. Całość kodu odpowiedzialnego za tworzenie całej\ntej bazy danych i wystawienie do tego prymitywnego, ale funkcjonalnego API \nmieści się w 100 liniach kodu.\n\nNaszą zabawę możemy zacząć od usunięcia katalogu Resources z app/config. Nasz\nkontroler będzie rozmawiał w jsonie, więc widoki nie będą nam potrzebne.\nPrzechodzimy do edycji kontrolera. Zaczynamy od dołączenia bibliotek:\n\n> src/AppBundle/Controller/DefaultController.php\n\n\n<?php\n\nnamespace AppBundle\\Controller;\n\nuse Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route;\nuse Symfony\\Bundle\\FrameworkBundle\\Controller\\Controller;\nuse Symfony\\Component\\HttpFoundation\\JsonResponse;\nuse Doctrine\\DBAL\\Schema\\Schema;\nuse Doctrine\\DBAL\\Schema\\Comparator;\nuse Doctrine\\DBAL\\Schema\\Table;\n\n\nMamy tu Route odpowiadające za przypisywanie adnotacjom przy akcjach\nodpowiednich ścieżek w routingu. Jest Controller, który pozwala nam odnosić się\ndo wszystkich najbardziej podstawowych funkcji Symfony przez $this. Następnie \nJsonResponse łączący działanie funkcji json_decode z jednoczesnym ustawianiem\nnagłówka na application/json. Trzy kolejne to paczki Doctrine, które odpowiednio\ntłumaczą jego api na SQL i dostarczają obiekty Doctrine.\n\nWewnątrz kontrolera będą istnieć dwie zmienne prywatne będące tablicami tabel \nmain i minor oraz liczba określające ile tabel typu minor ma występować.\n\nclass DefaultController extends Controller\n{\n    /**\n     * @var Table[]\n     */\n    private $main, $minor;\n\n    private $N;\n\n    public function __construct()\n    {\n        $this->main = [];\n        $this->minor = [];\n        $this->N = 10;\n    }\n\n\nKonstruktor ustawia $minor i $main jako puste tablice, a domyślną liczbę tabel\nna 10. Klasa Table jest jednym z obiektów doctrine, które dopiero co\nzałączyliśmy. Obsługę tej klasy zobaczymy za chwilę w funkcji tworzącej schemat\njednej z tabel.\n\n    /**\n     * @param $schema Schema\n     */\n    private function appendMinorToSchema($schema)\n    {\n        for($i=1;$i<=$this->N;$i++) {\n            $this->minor[$i] = $schema->createTable(\"minor_\".$i);\n            $this->minor[$i]->addColumn(\"id\", \"integer\");\n            $this->minor[$i]->setPrimaryKey(array(\"id\"));\n        }\n    }\n\n\nJak wspominałem wcześniej zaczynamy od tworzenia mniejszych tabel. Ponieważ ma\nbyć ich N, właśnie to tej wielkości ustawiona jest pętla. Wewnątrz do zmiennej\nzawierającej tabele $minor przypisujemy wynik metody creteTable na schemacie,\nktóry będzie podany jako argument. Schemat odpowiada temu jak doctrine rozumie\nstrukturę bazy danych w ramach swoich własnych klas. Tworzonej tabeli\nprzypisywany jest atrybut będący kluczem głównym. To wystarczy. Odrobinę\nbardziej złożoną logikę ma tworzenie dużych tabel.\n\n    /**\n     * @param $schema Schema\n     */\n    private function appendMainToSchema($schema)\n    {\n        for($i=1;$i<=2;$i++)\n        {\n            $this->main[$i] = $schema->createTable(\"main_\".$i);\n            $this->main[$i]->addColumn(\"id\", \"integer\");\n            for($j=1;$j<=$this->N;$j++)\n            {\n                $this->main[$i]->addColumn(\"minor_\".$j.\"_id\", \"integer\");\n                $this->main[$i]->addForeignKeyConstraint($this->minor[$j], array(\"minor_\".$j.\"_id\"), array(\"id\"));\n            }\n            $this->main[$i]->setPrimaryKey(array(\"id\"));\n        }\n    }\n\n\nPonieważ są dwie, pętla główna przebiega tylko wartości 1 i 2. Tak jak\npoprzednio do schematu dodawane są tabele, oraz kolumna o nazwie id, która\nzostanie u nas kluczem głównym. Nie dostała ona auto_increment bo będziemy ją\nustawiać w zewnętrznym skrypcie.\n\nPo dodaniu bazowego atrybutu - id do tabeli rozpoczynamy pętlę po mniejszych\ntabelach, w której podpinamy kolumnę i przypisujemy jej więzy integralności\nreferencyjnej. Na ustanawiamy id kluczem głównym.\n\nNa tym się kończy lista zmiennych i metod. Jak w zwykłych skryptach,\nprzechodzimy do ciała programu.\n\n    /**\n     * @Route(\"/\", name=\"home\")\n     * @Route(\"/do/{n}\")\n     */\n    public function indexAction($n=10,$action=\"do\")\n    {\n        if($n){ $this->N = $n; }\n        $conn = $this->getDoctrine()->getConnection();\n\n\nRouting pozwala nam wybrać domyślną ścieżkę /, albo określić akcję i wybrać dla\nniej argument. Na tym etapie będziemy mieli dwie akcje - show i do. Show będzie\njedynie wyświetlało kod SQL jaki trzeba wykonać, aby obecny stan bazy\nprzekształcić do posiadającego n małych tabel, a do będzie nie tylko pokazywać,\nale też wykonywać ten kod. Jak łatwo zgadnąć, n jest właśnie liczbą tabel i\nnadpisuje domyślne 10 z konstruktora. Na końcu tego kodu tworzymy połączenie z\nbazą danych i zapisujemy jego reprezentację do zmiennej $conn. Teraz\nprzygotujemy schemat.\n\n        $schema = new Schema();\n\n        $this->appendMinorToSchema($schema);\n        $this->appendMainToSchema($schema);\n\n\nSchemat, czyli to jak doctrine rozumie strukturę bazy tworzymy w trzech\nlinijkach. Czas porównać go z obecnym stanem bazy.\n\n        $comparator = new Comparator();\n        $queries = $comparator->compare($conn->getSchemaManager()->createSchema(), $schema)->toSql($conn->getDatabasePlatform());\n\n\n\nDzięki obiektom Comparator oraz ShemaManager otrzymanie tablicy z zapytaniami \nSQL aktualizującymi naszą strukturę bazy mieści się w dwóch liniach. Zostało już\ntylko wykonanie tych zapytań, jeśli action ustawione jest na do.\n\n        if($action==\"do\"){\n            foreach($queries as $query) {\n                $conn->prepare($query)->execute();\n            }\n        }\n\n\nDzięki metodom pozwalającym wykonywać czyste sqlowe zapytania nasze zadanie\nsprowadza się do wykonania pętli po nich. Możemy teraz zwrócić użytkownikowi\njakiś sensowny komunikat.\n\n        return new JsonResponse(\n            [\n                \"alter\"=>$queries,\n            ]\n        );\n    }\n}\n\n\nNajlepszy wydał mi się json z listą zapytań jakie należy wykonać, aby obecny\nstan bazy przekształcić do zadanego przez parametr n. Na koniec dołączam metodę \nshow, która świetnie nadaje się do debugowania, ale nie pełni żadnej funkcji\npoza tym:\n\n    /**\n    * @Route(\"/show/{n}\")\n    */\n    public function showAction($n=10)\n    {\n        return $this->doAction($n,\"show\");\n    }\n\n\nŻeby móc obsłużyć nasz kontroler postawimy serwer komendą.\n\nphp bin/console server:run\n\n\nI w drugim terminalu wyślemy request http, który wypełni nam bazę tabelami.\n\ntime http -b GET localhost:8000/do/10\n\n\nJego wykonanie trwało u mnie 3 sekundy, a odpowiedź wyglądała tak:\n\n\n\nWypełnianie bazy danymi\nNadszedł czas wypełnić bazę danymi. Dla małych tabel będą to liczby z przedziału\nod 1 do L. Dla dużych będziemy losować N liczb od 1 do L, które dodamy do kluczy\nobcych. Wartość id ustawimy na auto_increment ale nie z poziomu sql tylko przez\nzewnętrzny skrypt. Poza małymi tabelami wypełnimy tylko tabelę main_1,\nzostawiając main_2 pustą. Przypominam, że chcemy przetestować klonowanie dużej\ntabli z dużą ilością kluczy obcych.\n\nTabele minor\nZaczniemy od wypełniania małych tabel. Podzielę ten proces na wypełnianie małych\ni dużej tabeli oddzielnie, ze względu na większą elastyczność takiego podejścia,\na po części też dlatego, że da mi to lepszy wgląd w czasy wykonywania\nposzczególnych procesów. Małe tabele będziemy tworzyć za pomocą następującej\nakcji w DefaultController:\n\n    /**\n     * @Route(\"/minor/{n}/{l}\")\n     */\n    public function minorAction($n=10,$l=10)\n    {\n        $conn = $this->getDoctrine()->getConnection();\n        for($i=1;$i<=$n;$i++){\n            $conn->delete('minor_'.$i,[1=>1]);\n            for($j=1;$j<=$l;$j++){\n                $conn->insert('minor_'.$i, array('id' => $j));\n            }\n        }\n        return new  JsonResponse(['n'=>$n, 'l'=>$l]);\n    }\n\n\nJest ona wyjątkowo prosta, ale posiada jeden dość ciekawy hak. Chodzi o\nidempotentność. W metodzie delete obiektu Connection mamy nazwę tabeli a później\ntablicę [1=>1]. Jest to warunek który w instrukcji DELETE FROM występuje za \nWHERE. 1=1 jest zawsze prawdziwe i dlatego przed rozpoczęciem zapisu zostają\nusunięte zostają wszystkie elementy jednym zapytaniem. Żeby wywołać tą akcję\nwystarczy wpisać w konsoli:\n\ntime http -b GET localhost:8000/minor/10/10\n\n\nOdpowiedź którą zobaczymy będzie wyglądała tak:\n\n{\n    \"l\": \"10\", \n    \"n\": \"10\"\n}\n\n\nDodanie stałych\nMógł bym kontynuować dodawanie akcji, ale zacząłem martwić się zbytnią\npowtarzalnością wartości domyślnych. Zanim przejdziemy dalej wprowadzimy w\nkodzie następujące zmiany. Na początku kontrolera definiujemy stałe:\n\n    const N = 10;\n    const L = 10;\n    const K = 1000;\n\n\nW konstruktorze ustawiamy private $N na:\n\n        $this->N = self::N;\n\n\nZmieniamy domyślne wartości w definicjach akcji na następujące:\n\n    public function doAction($n=self::N,$action=\"do\")\n    public function showAction($n=self::N)\n    public function minorAction($n=self::N,$l=self::L)\n\n\nDodajemy routingi bez parametrów, czyli\n\n     * @Route(\"/show\")\n\n\nprzed * @Route(\"/minor/{n}/{l}\") oraz\n\n     * @Route(\"/minor\")\n\n\nprzed * @Route(\"/main/{n}/{l}/{k}\")\n\nTabela main\nDo wypełnienia tabeli main_1 wykorzystamy następujący kod\n\n    /**\n     * @Route(\"/main\")\n     * @Route(\"/main/{n}/{l}/{k}\")\n     * @Route(\"/main/{n}/{l}/{k0}/{k}\")\n     */\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1)\n    {\n        $conn = $this->getDoctrine()->getConnection();\n        if($k0==1) { $conn->delete('main_1',[1=>1]); }\n        for($i=$k0;$i<=$k;$i++){                // row in table main\n            $content = ['id'=>$i];\n            for($j=1;$j<=$n;$j++){            // foreign key of row\n                $content['minor_'.$j.'_id'] = rand(1,$l);\n            }\n            $conn->insert('main_1', $content);\n        }\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\n    }\n\n\nJest to akcja która nadaje się zarówno do czyszczenia, nadpisywania, jak i\ndopisywania do tabeli main. Tak duża ogólność została uzyskana dzięki dość\nciekawemu routingowi. Zmienne n i l to odpowiednio liczba tabel typu minor oraz\nliczba ich wierszy. k jest maksymalnym indeksem id do którego będziemy wypełniać\ntabelę main. k0 jest indeksem od którego zaczynamy. Jeśli wynosi on 1 lub nie\njest podany, zawartość tabeli main zostanie skasowana przed dalszym zapisem.\n\nTo co się dzieje wewnątrz pętli jest dość przewidywalne. Tworzymy wartość id \nzgodnie z zapowiedzianym schematem (auto_increment), losujemy klucze obce,\nzapisujemy wiersz i przechodzimy dalej. Tej akcji można użyć na kilka sposobów.\nNa przykład żeby wypełnić tabelę main_1 dziesięcioma wierszami wpiszemy:\n\ntime http -b GET localhost:8000/main/10/10/10\n\n\nJeśli chcemy ją wyczyścić:\n\ntime http -b GET localhost:8000/main/10/10/0\n\n\nTeraz możemy zapisać z powrotem 10 wierszy, ale rozbijając to na dwa kroki:\n\ntime http -b GET localhost:8000/main/10/10/1/5\ntime http -b GET localhost:8000/main/10/10/6/10\n\n\nZanim wypełnimy tabelę main_1 milionami wierszy należy zauważyć, że pierwszą\nprzyczyną dla której szybkość wykonywania insertów jest niezadowalająca jest\nsprawdzanie poprawności więzów przy każdym zapisie. Celowo nie dodałem\ntransakcji, żebyśmy mogli porównać szybkość wykonywania tego kodu z analogicznym\notoczonym transakcją. Wyniki dla 100k wierszy:\n\nBez transakcjiZ transakcją6m 41.672s0m 57.804sTransakcje uzyskamy dzięki\nnastępującej modyfikacji ciała akcji mainAction:\n\n        $conn = $this->getDoctrine()->getConnection();\n        if($k0==1) { $conn->delete('main_1',[1=>1]); }\n        $conn->beginTransaction();\n        try{\n            // loop over rows - exactly the same as before\n            $conn->commit();\n        } catch(\\Exception $e) {\n            $conn->rollBack();\n            throw $e;\n        }\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\n\n\nPomiary\nPonieważ nadszedł czas na wykonywanie pomiarów, warto było by stworzyć dla\nwyników kolejną tabelę nie połączoną z poprzednimi. Powinna ona zawierać czas,\nparametry i opis mierzonej funkcjonalności. Jednak dla czystości kodu oddzielimy\nczęść generującą tabele od wykonującej akcje. Zależy mi też na pogrupowaniu\nakcji ze względu na to czy stawiają bazę, czy dokonują na niej pomiarów. Oto\nnowa struktura katalogów jaką zastosujemy.\n\n\n\nNasz model odpowiedzialny za tworzeniu schematu bazy będzie miał kod wycięty z\nprywatnych funkcji i własności DefaultController oraz jego konstruktora.\n\n> src/AppBundle/Model/SchemaGenerator.php\n\n\n<?php\n\nnamespace AppBundle\\Model;\n\nuse AppBundle\\Controller\\BaseController;\nuse Doctrine\\DBAL\\Schema\\Schema;\nuse Doctrine\\DBAL\\Schema\\Table;\n\nclass SchemaGenerator\n\n\nNie zmieni się tam nic poza konstruktorem:\n\n    public function __construct($n)\n    {\n        $this->main = [];\n        $this->minor = [];\n        $this->N = $n ? $n : BaseController::N;\n    }\n\n\nUstawia on domyślnie N na wartość stałej z BaseController, albo na wartość\npodaną przy powoływaniu instancji obiektu. Jak wspomniałem, funkcje \nappendMinorToSchema i appendMainToSchema się nie zmieniają. Dochodzi za to\nfunkcja appendLogToSchema:\n\n    /**\n     * @param $schema Schema\n     */\n    private function appendLogToSchema($schema)\n    {\n        $log = $schema->createTable(\"log\");\n        $log->addColumn(\"id\", \"integer\",array(\"autoincrement\"=>true,\"unsigned\" => true));\n        $log->addColumn(\"n\", \"smallint\",array(\"unsigned\" => true));\n        $log->addColumn(\"l\", \"smallint\",array(\"unsigned\" => true));\n        $log->addColumn(\"k0\", \"integer\",array(\"unsigned\" => true));\n        $log->addColumn(\"k\", \"integer\",array(\"unsigned\" => true));\n        $log->addColumn(\"execution_time\", \"float\");\n        $log->addColumn(\"operation\", \"string\",array());\n        $log->setPrimaryKey(array(\"id\"));\n    }\n\n\nBędzie to tabela przechowująca wyniki pomiarów z parametrami. Wyposażymy nasz\ngenerator w jedną funkcję, która zbinduje poprzednie funkcje ze schematem i\nzwróci nam gotowy schemat.\n\n    /**\n     * @return Schema Schema\n     */\n    public function generate()\n    {\n        $schema=new Schema();\n\n        $this->appendMinorToSchema($schema);\n        $this->appendMainToSchema($schema);\n        $this->appendLogToSchema($schema);\n\n        return $schema;\n    }\n\n\nTo wszystko, jeśli chodzi o model. Spójrzmy na kontroler bazowy.\n\n<?php\n\nnamespace AppBundle\\Controller;\n\nuse Symfony\\Bundle\\FrameworkBundle\\Controller\\Controller;\n\nclass BaseController extends Controller\n{\n    const N = 10;\n    const L = 10;\n    const K = 1000;\n}\n\n\nJest to nasz kontener na stałe. Sam nie wiem, czy w takim przypadku, nie lepiej\nbyło by tego nawet zrobić w parametrach Symfony. I pewnie tak zrobię, jeśli dla\ntego kontrolera nie pojawią się jakieś dodatkowe zastosowania. Tym czasem\nzostało nam jeszcze dostosowanie DefaultController. Przede wszystkim zmieniliśmy\njego nazwę (nazwę pliku i klasy) na PreparationController aby lepiej odpowiadała\njego funkcjonalności. W Metodzie doAction usunęliśmy ustawianie zmiennej\nprywatnej N w pierwszej instrukcji warunkowej. Wiąże się to z tym, że wycięliśmy\nteż wszystkie zmienne i funkcje prywatne oraz konstruktor. Trzy linijkową\ngenerację schematu zastąpiliśmy linią:\n\n        $schema = (new SchemaGenerator($n))->generate();\n\n\nNa koniec zwiększyliśmy jeszcze bardziej elastyczność metody mainAction, ze\nwzględu na to, że zainteresowało mnie jakie dokładnie różnice robi ustawianie\ntransakcji przy jakich ilościach wierszy. Dodałem też numer tabeli main do\nroutingu, jeśli chcaił bym nie ruszając dużej już wypełnionej tabeli, wykonywać\ntesty na tej drugiej.\n\n    /**\n     * @Route(\"/main\")\n     * @Route(\"/main/{n}/{l}/{k}\")\n     * @Route(\"/main/{n}/{l}/{k0}/{k}\")\n     * @Route(\"/main/{n}/{l}/{k0}/{k}/{main}/{transaction}\")\n     */\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1,$main=1,$transaction=true)\n    {\n        $conn = $this->getDoctrine()->getConnection();\n        if($k0==1) { $conn->delete('main_'.$main,[1=>1]); }\n        if($k>1e4) { \n            set_time_limit(0);\n            ini_set(\"max_execution_time\", 0); \n        }\n        if($transaction) {$conn->beginTransaction();}\n        try{\n            for($i=$k0;$i<=$k;$i++){                // row in table main\n                $content = ['id'=>$i];\n                for($j=1;$j<=$n;$j++){            // foreign key of row\n                    $content['minor_'.$j.'_id'] = rand(1,$l);\n                }\n                $conn->insert('main_'.$main, $content);\n            }\n            if($transaction) {$conn->commit();}\n        } catch(\\Exception $e) {\n            if($transaction) {$conn->rollBack();}\n            throw $e;\n        }\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\n    }\n\n\nTe zmiany pozwalają zapisać wiersze do drugiej tabeli bez transakcji:\n\ntime http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/0\n\n\nLub z nimi\n\ntime http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/1\n\n\nDodaliśmy też ustawianie dłuższego czasu wykonywania jeśli ilość zapisywanych\nwierszy jest odpowiednio duża.\n\nHipotezy\nMamy już całkiem insteresujący zbiór zmiennych w naszym modelu. Możemy\nmanipulować liczbą tabel typu minor - N, liczbą ich kluczy - L, ilością wierszy\nktóre wstawiamy k-k0+1 i numerem wiersza od którego zaczynamy k0. Możemy też\nwstawiać wiersze z wykorzystaniem lub bez użycia transakcji. Wadą naszego\nsystemu pomiarowego jest narzut czasu związany z wykonywaniem doctrine i reszty \nphp, zaletą elastyczność api, które wystawiliśmy. Jednak wadę o której\nwspomniałem jesteśmy w stanie łatwo wyeliminować wykonując odpowiednio długie\npomiary. Przez długie mam na myśli długie w stosunku do czasu jaki zajmuje\nwykonanie kodu nie będącego bezpośrednio operacjami na bazie - łączenie,\nwczytywanie bibliotek itd. To zadanie od testowania selektów różni się tym, że\nmamy tu stosunkowo trudne, ale\n\nTestując będziemy zmieniać liczbę małych tabel n, 1-63, liczbę ich kluczy l od\n1-50, liczbę wstawianych wierszy k od 1 do 100.\n\nInterfejs: nazwa_testu, n,l,k\n\nInstalacja\nInstalacja składa się ze ściągnięcia repozytorium i wykonania skryptu\ninstalacyjnego. W skrypcie należy zmienić parametry połączenia z bazą danych.\n\ngit clone https://github.com/gustawdaniel/test_inserts_performace --depth 1\ncd test_inserts_performace && bash install.sh\n\n\nJeśli po wykonaniu instalacji proces jdb2/sda1-8 będzie zabierał prawie całe I/O \n(screen z iotop):\n\n [https://postimg.org/image/wlcjx27g9/]\n\nmożemy go wyłączyć, ale wymaga to włączenia systemu w trybie bezpiecznym (\nrecovery mode). Proces ten jest to tak zwany journaling.\n\numount /dev/sda1\ntune2fs -O ^has_journal /dev/sda1\n\n\nZwykłe kopiowanie\n\nINSERT INTO major_2 SELECT * FROM major_1;\nQuery OK, 1000000 rows affected (8 min 38,35 sec)\n\n\nMysqldump\n\ntime mysqldump -u root training major_1 > major_1.sql\n\n\nPliki generowane przez mysqldump zwykle są duże i nie warto ich oglądać w\ncałości. Podobnie jak head służy do wyświetlania pierwszych linii pliku tak\nponiższym poleceniem wyświetlimy pierwsze znaki każdej linii.\n\nawk '{print substr($0,1,210);}' major_1.sql\n\n\nPonieważ interesuje nas wrzucenie danych do tabeli major_2, więc chcemy wybrać\ntylko inserty i zmienić 1 na 2 w nazwie tabeli. W języku skryptowym awk tego\ntypu zadania załatwia się jedną linią:\n\nawk '/^INSERT/ {sub(\"_1\",\"_2\",$0); print $0;}' major_1.sql > major_2.sql\n\n\nTeraz możemy wykonać wrzut danych do bazy.\n\nInstalacja\ngit clone http://github.com/gustawdaniel/test_inserts_performance\ncd test_inserts_performance\nbash install.sh\n\n\npaste Dropbox token\n\nbash bash/initialize.sh \nphp app.php\nbash bash/send.sh\n\n\nOn analysing machine\n\nmysql -u root training -e \"TRUNCATE log; TRUNCATE machine;\"\nbash bash/get.sh\n\n\n\n--------------------------------------------------------------------------------\n\n> Written with StackEdit [https://stackedit.io/].\n\n\nTestowanie szybkości insertów\n[toc]\n\nOpis projektu\nProblemem, który omówimy tym razem będzie optymalizacja szybkości zapisu do bazy\ndanych przy kilku warunkach. Zakładamy, że nasza tabela ma nałożone klucze a\nwięc również indeksy. Wiemy, że dane które chcemy do niej zapisać są poprawne.\nPodczas zapisu tych danych na pewno nie jest wykonywany żaden inny zapis.\n\nJako, że dopiero zaczynam zabawę z większymi zbiorami danych, moje intuicje są\noparte głównie na czytaniu dokumentacji i celem tego ćwiczenia jest wyrobienie\nsobie ilościowego wyczucia w tej materii.\n\nZastosowane technologie\nInaczej, niż przy testowaniu selektów, nie decyduję się tym razem na czystego \nsql. Zamiast tego wykorzystamy doctrine ze względu na jego mechanizm\ndziedziczenia, którego sam sql z tego co wiem nie oferuje. Poza tym pisanie\nprocedur do testowania w php i wystawienie przez niego api wydaje mi się\nbardziej atrakcyjne niż liniowe pliki wykonywalne w sql.\n\nDo obsługi doctrine wykorzystamy symfony - genialnie napisany framework php.\nTrochę trudniejszy niż Laravel, ale z drugiej strony polecany do większych\nprojektów, gdzie elastyczność i stabilność są bardzo ważne. Instalacja polega na\nwykonaniu komendy:\n\nsymfony new insert_test latest && cd insert_test\n\n\nZaczniemy od konfiguracji i w pliku app/config/parameters.yml zmienimy \ndatabase_name na insert_test. Bazę danych stawiamy komendą:\n\nphp bin/console doctrine:database:create\n\n\nJest pusta, dlatego teraz zajmiemy się jej wypełnianiem.\n\nStruktura bazy danych\nInteresuje nas przerzucanie danych między dwiema identycznymi tabelami, które\nmają powiązania przez więzy integralności referencyjnej z kilkoma mniejszymi\ntabelami. Nasza baza danych będzie więc przypominała pajęczynę, w której dwie\nduże tabele będą odnosić się n kluczami do n mniejszych nie powiązanych tabel.\nGłówne tabela nazwiemy main_1 i main_2, a mniejsze minor_1, minor_2, ... minor_n\n. Ponieważ obraz mówi więcej niż tysiąc słów załączam diagram hierarchiczny\nbazy:\n\n\n\nA dla wyjaśnienia, dlaczego początkowo wyobrażałem sobie tą bazę jak pajęczynę,\nprezentuję też diagram organiczny tej samej bazy.\n\n\n\nWłaściwie, to te duże tabele będą miały poważne problemy z optymalnością\ninsertów dokładnie tak jak by było w sieci pająka...\n\nWracając do konkretów, ponieważ optymalność nie będzie testowana na mniejszych\ntabelach, nie dostaną one kluczy obcych, a więc to od nich zaczniemy stawianie\nbazy. Będą one zawierały tylko jedno pole - id będące ich kluczem głównym. Po\nich utworzeniu będą tworzone tabele główne, i dopiero wtedy będziemy im dodawać\nklucze obce.\n\nTworzenie tabel\nKiedy kończyłem pisać wpis o testowaniu selektów\n[http://blog.gustawdaniel.pl/2016/12/02/tesseract-ocr-i-testowanie-selekt%C3%B3w.html] \nza pomocą Behata, nie byłem zbyt zadowolony z pisania scenariuszy, które różniły\nsię tylko liczbą atrybutów, lub warunków. Mimo, że bardzo wygodny dla osób nie\ntechnicznych, Gherkin nie dawał mi wystarczającej elastyczności. Podobnie czułem\nsię pisząc procedury\n[http://blog.gustawdaniel.pl/2016/12/08/testowanie-szybko%C5%9Bci-selekt%C3%B3w.html] \nw czystym SQL. Brak dziedziczenia sprawiał, że musiałem kopiować kod, a tego\nbardzo nie lubię.\n\nZupełnie inaczej jest tym razem. Całość kodu odpowiedzialnego za tworzenie całej\ntej bazy danych i wystawienie do tego prymitywnego, ale funkcjonalnego API \nmieści się w 100 liniach kodu.\n\nNaszą zabawę możemy zacząć od usunięcia katalogu Resources z app/config. Nasz\nkontroler będzie rozmawiał w jsonie, więc widoki nie będą nam potrzebne.\nPrzechodzimy do edycji kontrolera. Zaczynamy od dołączenia bibliotek:\n\n> src/AppBundle/Controller/DefaultController.php\n\n\n<?php\n\nnamespace AppBundle\\Controller;\n\nuse Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route;\nuse Symfony\\Bundle\\FrameworkBundle\\Controller\\Controller;\nuse Symfony\\Component\\HttpFoundation\\JsonResponse;\nuse Doctrine\\DBAL\\Schema\\Schema;\nuse Doctrine\\DBAL\\Schema\\Comparator;\nuse Doctrine\\DBAL\\Schema\\Table;\n\n\nMamy tu Route odpowiadające za przypisywanie adnotacjom przy akcjach\nodpowiednich ścieżek w routingu. Jest Controller, który pozwala nam odnosić się\ndo wszystkich najbardziej podstawowych funkcji Symfony przez $this. Następnie \nJsonResponse łączący działanie funkcji json_decode z jednoczesnym ustawianiem\nnagłówka na application/json. Trzy kolejne to paczki Doctrine, które odpowiednio\ntłumaczą jego api na SQL i dostarczają obiekty Doctrine.\n\nWewnątrz kontrolera będą istnieć dwie zmienne prywatne będące tablicami tabel \nmain i minor oraz liczba określające ile tabel typu minor ma występować.\n\nclass DefaultController extends Controller\n{\n    /**\n     * @var Table[]\n     */\n    private $main, $minor;\n\n    private $N;\n\n    public function __construct()\n    {\n        $this->main = [];\n        $this->minor = [];\n        $this->N = 10;\n    }\n\n\nKonstruktor ustawia $minor i $main jako puste tablice, a domyślną liczbę tabel\nna 10. Klasa Table jest jednym z obiektów doctrine, które dopiero co\nzałączyliśmy. Obsługę tej klasy zobaczymy za chwilę w funkcji tworzącej schemat\njednej z tabel.\n\n    /**\n     * @param $schema Schema\n     */\n    private function appendMinorToSchema($schema)\n    {\n        for($i=1;$i<=$this->N;$i++) {\n            $this->minor[$i] = $schema->createTable(\"minor_\".$i);\n            $this->minor[$i]->addColumn(\"id\", \"integer\");\n            $this->minor[$i]->setPrimaryKey(array(\"id\"));\n        }\n    }\n\n\nJak wspominałem wcześniej zaczynamy od tworzenia mniejszych tabel. Ponieważ ma\nbyć ich N, właśnie to tej wielkości ustawiona jest pętla. Wewnątrz do zmiennej\nzawierającej tabele $minor przypisujemy wynik metody creteTable na schemacie,\nktóry będzie podany jako argument. Schemat odpowiada temu jak doctrine rozumie\nstrukturę bazy danych w ramach swoich własnych klas. Tworzonej tabeli\nprzypisywany jest atrybut będący kluczem głównym. To wystarczy. Odrobinę\nbardziej złożoną logikę ma tworzenie dużych tabel.\n\n    /**\n     * @param $schema Schema\n     */\n    private function appendMainToSchema($schema)\n    {\n        for($i=1;$i<=2;$i++)\n        {\n            $this->main[$i] = $schema->createTable(\"main_\".$i);\n            $this->main[$i]->addColumn(\"id\", \"integer\");\n            for($j=1;$j<=$this->N;$j++)\n            {\n                $this->main[$i]->addColumn(\"minor_\".$j.\"_id\", \"integer\");\n                $this->main[$i]->addForeignKeyConstraint($this->minor[$j], array(\"minor_\".$j.\"_id\"), array(\"id\"));\n            }\n            $this->main[$i]->setPrimaryKey(array(\"id\"));\n        }\n    }\n\n\nPonieważ są dwie, pętla główna przebiega tylko wartości 1 i 2. Tak jak\npoprzednio do schematu dodawane są tabele, oraz kolumna o nazwie id, która\nzostanie u nas kluczem głównym. Nie dostała ona auto_increment bo będziemy ją\nustawiać w zewnętrznym skrypcie.\n\nPo dodaniu bazowego atrybutu - id do tabeli rozpoczynamy pętlę po mniejszych\ntabelach, w której podpinamy kolumnę i przypisujemy jej więzy integralności\nreferencyjnej. Na ustanawiamy id kluczem głównym.\n\nNa tym się kończy lista zmiennych i metod. Jak w zwykłych skryptach,\nprzechodzimy do ciała programu.\n\n    /**\n     * @Route(\"/\", name=\"home\")\n     * @Route(\"/do/{n}\")\n     */\n    public function indexAction($n=10,$action=\"do\")\n    {\n        if($n){ $this->N = $n; }\n        $conn = $this->getDoctrine()->getConnection();\n\n\nRouting pozwala nam wybrać domyślną ścieżkę /, albo określić akcję i wybrać dla\nniej argument. Na tym etapie będziemy mieli dwie akcje - show i do. Show będzie\njedynie wyświetlało kod SQL jaki trzeba wykonać, aby obecny stan bazy\nprzekształcić do posiadającego n małych tabel, a do będzie nie tylko pokazywać,\nale też wykonywać ten kod. Jak łatwo zgadnąć, n jest właśnie liczbą tabel i\nnadpisuje domyślne 10 z konstruktora. Na końcu tego kodu tworzymy połączenie z\nbazą danych i zapisujemy jego reprezentację do zmiennej $conn. Teraz\nprzygotujemy schemat.\n\n        $schema = new Schema();\n\n        $this->appendMinorToSchema($schema);\n        $this->appendMainToSchema($schema);\n\n\nSchemat, czyli to jak doctrine rozumie strukturę bazy tworzymy w trzech\nlinijkach. Czas porównać go z obecnym stanem bazy.\n\n        $comparator = new Comparator();\n        $queries = $comparator->compare($conn->getSchemaManager()->createSchema(), $schema)->toSql($conn->getDatabasePlatform());\n\n\n\nDzięki obiektom Comparator oraz ShemaManager otrzymanie tablicy z zapytaniami \nSQL aktualizującymi naszą strukturę bazy mieści się w dwóch liniach. Zostało już\ntylko wykonanie tych zapytań, jeśli action ustawione jest na do.\n\n        if($action==\"do\"){\n            foreach($queries as $query) {\n                $conn->prepare($query)->execute();\n            }\n        }\n\n\nDzięki metodom pozwalającym wykonywać czyste sqlowe zapytania nasze zadanie\nsprowadza się do wykonania pętli po nich. Możemy teraz zwrócić użytkownikowi\njakiś sensowny komunikat.\n\n        return new JsonResponse(\n            [\n                \"alter\"=>$queries,\n            ]\n        );\n    }\n}\n\n\nNajlepszy wydał mi się json z listą zapytań jakie należy wykonać, aby obecny\nstan bazy przekształcić do zadanego przez parametr n. Na koniec dołączam metodę \nshow, która świetnie nadaje się do debugowania, ale nie pełni żadnej funkcji\npoza tym:\n\n    /**\n    * @Route(\"/show/{n}\")\n    */\n    public function showAction($n=10)\n    {\n        return $this->doAction($n,\"show\");\n    }\n\n\nŻeby móc obsłużyć nasz kontroler postawimy serwer komendą.\n\nphp bin/console server:run\n\n\nI w drugim terminalu wyślemy request http, który wypełni nam bazę tabelami.\n\ntime http -b GET localhost:8000/do/10\n\n\nJego wykonanie trwało u mnie 3 sekundy, a odpowiedź wyglądała tak:\n\n\n\nWypełnianie bazy danymi\nNadszedł czas wypełnić bazę danymi. Dla małych tabel będą to liczby z przedziału\nod 1 do L. Dla dużych będziemy losować N liczb od 1 do L, które dodamy do kluczy\nobcych. Wartość id ustawimy na auto_increment ale nie z poziomu sql tylko przez\nzewnętrzny skrypt. Poza małymi tabelami wypełnimy tylko tabelę main_1,\nzostawiając main_2 pustą. Przypominam, że chcemy przetestować klonowanie dużej\ntabli z dużą ilością kluczy obcych.\n\nTabele minor\nZaczniemy od wypełniania małych tabel. Podzielę ten proces na wypełnianie małych\ni dużej tabeli oddzielnie, ze względu na większą elastyczność takiego podejścia,\na po części też dlatego, że da mi to lepszy wgląd w czasy wykonywania\nposzczególnych procesów. Małe tabele będziemy tworzyć za pomocą następującej\nakcji w DefaultController:\n\n    /**\n     * @Route(\"/minor/{n}/{l}\")\n     */\n    public function minorAction($n=10,$l=10)\n    {\n        $conn = $this->getDoctrine()->getConnection();\n        for($i=1;$i<=$n;$i++){\n            $conn->delete('minor_'.$i,[1=>1]);\n            for($j=1;$j<=$l;$j++){\n                $conn->insert('minor_'.$i, array('id' => $j));\n            }\n        }\n        return new  JsonResponse(['n'=>$n, 'l'=>$l]);\n    }\n\n\nJest ona wyjątkowo prosta, ale posiada jeden dość ciekawy hak. Chodzi o\nidempotentność. W metodzie delete obiektu Connection mamy nazwę tabeli a później\ntablicę [1=>1]. Jest to warunek który w instrukcji DELETE FROM występuje za \nWHERE. 1=1 jest zawsze prawdziwe i dlatego przed rozpoczęciem zapisu zostają\nusunięte zostają wszystkie elementy jednym zapytaniem. Żeby wywołać tą akcję\nwystarczy wpisać w konsoli:\n\ntime http -b GET localhost:8000/minor/10/10\n\n\nOdpowiedź którą zobaczymy będzie wyglądała tak:\n\n{\n    \"l\": \"10\", \n    \"n\": \"10\"\n}\n\n\nDodanie stałych\nMógł bym kontynuować dodawanie akcji, ale zacząłem martwić się zbytnią\npowtarzalnością wartości domyślnych. Zanim przejdziemy dalej wprowadzimy w\nkodzie następujące zmiany. Na początku kontrolera definiujemy stałe:\n\n    const N = 10;\n    const L = 10;\n    const K = 1000;\n\n\nW konstruktorze ustawiamy private $N na:\n\n        $this->N = self::N;\n\n\nZmieniamy domyślne wartości w definicjach akcji na następujące:\n\n    public function doAction($n=self::N,$action=\"do\")\n    public function showAction($n=self::N)\n    public function minorAction($n=self::N,$l=self::L)\n\n\nDodajemy routingi bez parametrów, czyli\n\n     * @Route(\"/show\")\n\n\nprzed * @Route(\"/minor/{n}/{l}\") oraz\n\n     * @Route(\"/minor\")\n\n\nprzed * @Route(\"/main/{n}/{l}/{k}\")\n\nTabela main\nDo wypełnienia tabeli main_1 wykorzystamy następujący kod\n\n    /**\n     * @Route(\"/main\")\n     * @Route(\"/main/{n}/{l}/{k}\")\n     * @Route(\"/main/{n}/{l}/{k0}/{k}\")\n     */\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1)\n    {\n        $conn = $this->getDoctrine()->getConnection();\n        if($k0==1) { $conn->delete('main_1',[1=>1]); }\n        for($i=$k0;$i<=$k;$i++){                // row in table main\n            $content = ['id'=>$i];\n            for($j=1;$j<=$n;$j++){            // foreign key of row\n                $content['minor_'.$j.'_id'] = rand(1,$l);\n            }\n            $conn->insert('main_1', $content);\n        }\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\n    }\n\n\nJest to akcja która nadaje się zarówno do czyszczenia, nadpisywania, jak i\ndopisywania do tabeli main. Tak duża ogólność została uzyskana dzięki dość\nciekawemu routingowi. Zmienne n i l to odpowiednio liczba tabel typu minor oraz\nliczba ich wierszy. k jest maksymalnym indeksem id do którego będziemy wypełniać\ntabelę main. k0 jest indeksem od którego zaczynamy. Jeśli wynosi on 1 lub nie\njest podany, zawartość tabeli main zostanie skasowana przed dalszym zapisem.\n\nTo co się dzieje wewnątrz pętli jest dość przewidywalne. Tworzymy wartość id \nzgodnie z zapowiedzianym schematem (auto_increment), losujemy klucze obce,\nzapisujemy wiersz i przechodzimy dalej. Tej akcji można użyć na kilka sposobów.\nNa przykład żeby wypełnić tabelę main_1 dziesięcioma wierszami wpiszemy:\n\ntime http -b GET localhost:8000/main/10/10/10\n\n\nJeśli chcemy ją wyczyścić:\n\ntime http -b GET localhost:8000/main/10/10/0\n\n\nTeraz możemy zapisać z powrotem 10 wierszy, ale rozbijając to na dwa kroki:\n\ntime http -b GET localhost:8000/main/10/10/1/5\ntime http -b GET localhost:8000/main/10/10/6/10\n\n\nZanim wypełnimy tabelę main_1 milionami wierszy należy zauważyć, że pierwszą\nprzyczyną dla której szybkość wykonywania insertów jest niezadowalająca jest\nsprawdzanie poprawności więzów przy każdym zapisie. Celowo nie dodałem\ntransakcji, żebyśmy mogli porównać szybkość wykonywania tego kodu z analogicznym\notoczonym transakcją. Wyniki dla 100k wierszy:\n\nBez transakcjiZ transakcją6m 41.672s0m 57.804sTransakcje uzyskamy dzięki\nnastępującej modyfikacji ciała akcji mainAction:\n\n        $conn = $this->getDoctrine()->getConnection();\n        if($k0==1) { $conn->delete('main_1',[1=>1]); }\n        $conn->beginTransaction();\n        try{\n            // loop over rows - exactly the same as before\n            $conn->commit();\n        } catch(\\Exception $e) {\n            $conn->rollBack();\n            throw $e;\n        }\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\n\n\nPomiary\nPonieważ nadszedł czas na wykonywanie pomiarów, warto było by stworzyć dla\nwyników kolejną tabelę nie połączoną z poprzednimi. Powinna ona zawierać czas,\nparametry i opis mierzonej funkcjonalności. Jednak dla czystości kodu oddzielimy\nczęść generującą tabele od wykonującej akcje. Zależy mi też na pogrupowaniu\nakcji ze względu na to czy stawiają bazę, czy dokonują na niej pomiarów. Oto\nnowa struktura katalogów jaką zastosujemy.\n\n\n\nNasz model odpowiedzialny za tworzeniu schematu bazy będzie miał kod wycięty z\nprywatnych funkcji i własności DefaultController oraz jego konstruktora.\n\n> src/AppBundle/Model/SchemaGenerator.php\n\n\n<?php\n\nnamespace AppBundle\\Model;\n\nuse AppBundle\\Controller\\BaseController;\nuse Doctrine\\DBAL\\Schema\\Schema;\nuse Doctrine\\DBAL\\Schema\\Table;\n\nclass SchemaGenerator\n\n\nNie zmieni się tam nic poza konstruktorem:\n\n    public function __construct($n)\n    {\n        $this->main = [];\n        $this->minor = [];\n        $this->N = $n ? $n : BaseController::N;\n    }\n\n\nUstawia on domyślnie N na wartość stałej z BaseController, albo na wartość\npodaną przy powoływaniu instancji obiektu. Jak wspomniałem, funkcje \nappendMinorToSchema i appendMainToSchema się nie zmieniają. Dochodzi za to\nfunkcja appendLogToSchema:\n\n    /**\n     * @param $schema Schema\n     */\n    private function appendLogToSchema($schema)\n    {\n        $log = $schema->createTable(\"log\");\n        $log->addColumn(\"id\", \"integer\",array(\"autoincrement\"=>true,\"unsigned\" => true));\n        $log->addColumn(\"n\", \"smallint\",array(\"unsigned\" => true));\n        $log->addColumn(\"l\", \"smallint\",array(\"unsigned\" => true));\n        $log->addColumn(\"k0\", \"integer\",array(\"unsigned\" => true));\n        $log->addColumn(\"k\", \"integer\",array(\"unsigned\" => true));\n        $log->addColumn(\"execution_time\", \"float\");\n        $log->addColumn(\"operation\", \"string\",array());\n        $log->setPrimaryKey(array(\"id\"));\n    }\n\n\nBędzie to tabela przechowująca wyniki pomiarów z parametrami. Wyposażymy nasz\ngenerator w jedną funkcję, która zbinduje poprzednie funkcje ze schematem i\nzwróci nam gotowy schemat.\n\n    /**\n     * @return Schema Schema\n     */\n    public function generate()\n    {\n        $schema=new Schema();\n\n        $this->appendMinorToSchema($schema);\n        $this->appendMainToSchema($schema);\n        $this->appendLogToSchema($schema);\n\n        return $schema;\n    }\n\n\nTo wszystko, jeśli chodzi o model. Spójrzmy na kontroler bazowy.\n\n<?php\n\nnamespace AppBundle\\Controller;\n\nuse Symfony\\Bundle\\FrameworkBundle\\Controller\\Controller;\n\nclass BaseController extends Controller\n{\n    const N = 10;\n    const L = 10;\n    const K = 1000;\n}\n\n\nJest to nasz kontener na stałe. Sam nie wiem, czy w takim przypadku, nie lepiej\nbyło by tego nawet zrobić w parametrach Symfony. I pewnie tak zrobię, jeśli dla\ntego kontrolera nie pojawią się jakieś dodatkowe zastosowania. Tym czasem\nzostało nam jeszcze dostosowanie DefaultController. Przede wszystkim zmieniliśmy\njego nazwę (nazwę pliku i klasy) na PreparationController aby lepiej odpowiadała\njego funkcjonalności. W Metodzie doAction usunęliśmy ustawianie zmiennej\nprywatnej N w pierwszej instrukcji warunkowej. Wiąże się to z tym, że wycięliśmy\nteż wszystkie zmienne i funkcje prywatne oraz konstruktor. Trzy linijkową\ngenerację schematu zastąpiliśmy linią:\n\n        $schema = (new SchemaGenerator($n))->generate();\n\n\nNa koniec zwiększyliśmy jeszcze bardziej elastyczność metody mainAction, ze\nwzględu na to, że zainteresowało mnie jakie dokładnie różnice robi ustawianie\ntransakcji przy jakich ilościach wierszy. Dodałem też numer tabeli main do\nroutingu, jeśli chcaił bym nie ruszając dużej już wypełnionej tabeli, wykonywać\ntesty na tej drugiej.\n\n    /**\n     * @Route(\"/main\")\n     * @Route(\"/main/{n}/{l}/{k}\")\n     * @Route(\"/main/{n}/{l}/{k0}/{k}\")\n     * @Route(\"/main/{n}/{l}/{k0}/{k}/{main}/{transaction}\")\n     */\n    public function mainAction($n=self::N,$l=self::L,$k=self::K,$k0=1,$main=1,$transaction=true)\n    {\n        $conn = $this->getDoctrine()->getConnection();\n        if($k0==1) { $conn->delete('main_'.$main,[1=>1]); }\n        if($k>1e4) { \n            set_time_limit(0);\n            ini_set(\"max_execution_time\", 0); \n        }\n        if($transaction) {$conn->beginTransaction();}\n        try{\n            for($i=$k0;$i<=$k;$i++){                // row in table main\n                $content = ['id'=>$i];\n                for($j=1;$j<=$n;$j++){            // foreign key of row\n                    $content['minor_'.$j.'_id'] = rand(1,$l);\n                }\n                $conn->insert('main_'.$main, $content);\n            }\n            if($transaction) {$conn->commit();}\n        } catch(\\Exception $e) {\n            if($transaction) {$conn->rollBack();}\n            throw $e;\n        }\n        return new  JsonResponse(['n'=>$n,'l'=>$l,'k0'=>$k0,'k'=>$k]);\n    }\n\n\nTe zmiany pozwalają zapisać wiersze do drugiej tabeli bez transakcji:\n\ntime http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/0\n\n\nLub z nimi\n\ntime http -b --timeout=3600 GET localhost:8000/main/10/10/1/10000/2/1\n\n\nDodaliśmy też ustawianie dłuższego czasu wykonywania jeśli ilość zapisywanych\nwierszy jest odpowiednio duża.\n\nHipotezy\nMamy już całkiem insteresujący zbiór zmiennych w naszym modelu. Możemy\nmanipulować liczbą tabel typu minor - N, liczbą ich kluczy - L, ilością wierszy\nktóre wstawiamy k-k0+1 i numerem wiersza od którego zaczynamy k0. Możemy też\nwstawiać wiersze z wykorzystaniem lub bez użycia transakcji. Wadą naszego\nsystemu pomiarowego jest narzut czasu związany z wykonywaniem doctrine i reszty \nphp, zaletą elastyczność api, które wystawiliśmy. Jednak wadę o której\nwspomniałem jesteśmy w stanie łatwo wyeliminować wykonując odpowiednio długie\npomiary. Przez długie mam na myśli długie w stosunku do czasu jaki zajmuje\nwykonanie kodu nie będącego bezpośrednio operacjami na bazie - łączenie,\nwczytywanie bibliotek itd. To zadanie od testowania selektów różni się tym, że\nmamy tu stosunkowo trudne, ale\n\nTestując będziemy zmieniać liczbę małych tabel n, 1-63, liczbę ich kluczy l od\n1-50, liczbę wstawianych wierszy k od 1 do 100.\n\nInterfejs: nazwa_testu, n,l,k",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T20:51:12.000Z",
            "updated_at": "2021-04-20T20:51:58.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "607f4f042fb35425592d0c54",
            "uuid": "75e2c9f9-ecf8-4f75-a90a-12ba627823eb",
            "title": "Analiza wpływu technologii na rozwój mediów.",
            "slug": "analiza-wplywu-technologii-na-rozwoj-mediow",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/gartner.png\",\"width\":702,\"height\":478,\"caption\":\"Rysunek 1: „Hype Cycle” pokazuje na jakim etapie rozwoju jest dana techno-logia (fot. Gartner)\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/obama.jpg\",\"width\":1919,\"height\":971,\"caption\":\"Wycinek video na któym Jordan Peele prezentuje Deep Fake z prezydentem Obamą\"}]],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Artykuł stanowi lekkie wprowadzenie do tematyki fałszywych wiadomości, post prawdy i manipulacji medialnej. Zagadnienia te omawiane są w kontekście dynamicznego rozwoju technologii, która z jednej strony pozwala je skuteczniej wykrywać, a z drugiej strony wytwarzać. Tekstu nie należy traktować jak opracowania naukowego, jest to raczej wyrażenie opinii autora i spekulacja na temat kierunku w jakim ewoluować będzie zjawisko publikowania “fake news”.\"]]],[1,\"h2\",[[0,[],0,\"Dlaczego warto kształcić się w zakresie “fakenews”\"]]],[1,\"p\",[[0,[],0,\"5 stycznia 2018 roku. Pogodny dzień, temperatura w okolicach 3 stopni celsjusza. W hotelu Grand America w Salt Lake City w stanie Utah odbywa się ogłoszenie słowa wybranego słowem roku 2017. Wybór sygnuje American Dialect Society[4] - organizacja o 129 letniej historii, której celem jest studiowanie języka angielskiego.\"]]],[1,\"p\",[[0,[],0,\"Wybór pada na “fake news”[16]. To mógłby być przypadek, ale...2 listopada 2017. Na Twitterze Collins Dictionary[15] również publikuje wy-bór “fake news” na słowo roku 2017[18]. Komitet Macquarie Dictionary wybrał je słowem roku już w 2016[27]. Tym czasem Dictionay.com ogłosił “misinformation” słowem 2018[7]. Oxford Dictionary uznał “post prawdę” za słowo 2016[34],1American Dialect  Society  nominował  “deepfake”[19]  do  głosowania  na  słowo 2018\"]]],[1,\"p\",[[0,[],0,\"W artykułach poświęconych zagadnieniu częściej mówi się, że jest to znak czasów,[1,  29]  a  nie  zbieg  okoliczności.  Przedstawia  się  poważne  skutki  polityczne[23]  i  gospodarcze[13].  Prowadzone  są  zakrojone  na  ogromną  skalę  ba-dania różnic w tempie rozprzestrzeniania się prawdziwych i fałszywych wiadomości[31,  28],  oraz  organizuje  konkursy  na  budowę  sieci  neuronowych  do  ich wykrywania[8]\"]]],[1,\"p\",[[0,[],0,\"Czym zatem jest “fake news” i jakie znaczenie ma dla nas w życiu codzien-nym?\"]]],[1,\"p\",[[0,[],0,\"Zgodnie z definicją proponowaną przez Mały Leksykon Post Prawdy[21]\"]]],[1,\"p\",[[0,[],0,\"”Pojęcie fake news najczęściej definiowane jest jako fałszywa wiado-mość, często o charakterze sensacyjnym, publikowana w mediach z intencją wprowadzenia odbiorcy w błąd w celu osiągnięcia korzyści finansowych, politycznych lub prestiżowych.”.\"]]],[1,\"p\",[[0,[],0,\"Wynika z niej wprost, że główym celem istnienia tego zjawiska jest transfer szeroko rozumianych zasobów od odbiorcy do twórcy fałszywej wiadomości. Na przykład jeśli fake newsami niszczy się zgodę w społeczeństwie[11], to łatwiej można je kontrolować i odwracać jego uwagę od miejsc gdzie twórca fake newsa narusza jego interesy. Znane z historii są przypadki, gdzie rozsiewanie fake new-sów prowadziło do znacznego transferu majątków w wywołanych nimi reakcji rynków. Stanowią one też skuteczne narzędzie w kampaniach politycznych i spo-łecznych w systemie demokratycznym.\"]]],[1,\"p\",[[0,[],0,\"Mam nadzieję, że to wystarczająca argumentacja, aby uznać, że w naszyminteresie jest zrozumienie tego zjawiska. W dalszej części artykułu zastanowimysię jaki wpływ na nie ma technologia.\"]]],[1,\"h2\",[[0,[],0,\"Jak technologie pomagają wykrywać i tworzyć propagandę.\"]]],[1,\"p\",[[0,[],0,\"Istnieje bardzo szerokie spektrum manipulacji medialnych od ewidentnych kłamstw, poprzez przemilczenia, wyrywanie fragmentów wypowiedzi z kontekstu, przetwarzanie zdjęć, zmianę skali na wykresach, produkowanie komentarzy pod artykułami, trolling, operacje fałszywej flagi, aż do subtelnego doboru słów,które pozwala nie zmieniając faktów oddziaływać na emocje odbiorcy.\"]]],[1,\"p\",[[0,[],0,\"Historia wojny o umysły jest równie ciekawa co obszerna. W tym opracowaniu  skupimy  się  jedynie  na  najnowszych  nabytkach  arsenału  defensywnego i ofensywnego tej walki. Dzięki opracowaniu Gartnera[9] możemy przyjrzeć się całemu wachlarzowi technologii, które w tym momencie wchodzą lub będą wchodzić do codziennego użycia.\"]]],[10,0],[1,\"p\",[[0,[],0,\"Wśród nich te które najbardziej wpływają na rynek mediów to:\"]]],[3,\"ul\",[[[0,[],0,\"wirtualna rzeczywistość\"]],[[0,[],0,\"rzeczywistość rozszerzona\"]],[[0,[],0,\"blockchain\"]],[[0,[],0,\"uczenie maszynowe\"]],[[0,[],0,\"głębokie uczenie\"]],[[0,[],0,\"kognitywne obliczenia\"]]]],[1,\"p\",[[0,[],0,\"Przyjrzyjmy się im po kolei.\"]]],[1,\"h3\",[[0,[],0,\"Wirtualna rzeczywistość (VR) a rzeczywistość rozszerzona (AR)\"]]],[1,\"p\",[[0,[],0,\"Wirtualna rzeczywistość jest kolejnym krokiem w przenoszeniu realnego świata do postaci cyfrowej. Rzeczywistość rozszerzona przeciwnie, pozwala na umieszczanie przedmiotów wirtualnych w świecie rzeczywistym. Skumulowany roczny wzrost wartości rynków VR i AR w latach 2015-2020 szacowany jest przez International Data Corporation na 180%. Dochody tych branż mają wzrosnąć z 5 mld dol. do 162 mld dol. w 2020 r[24]\"]]],[1,\"h4\",[[0,[],0,\"Wirtualna rzeczywistość (VR)\"]]],[1,\"p\",[[0,[],0,\"Wirtualną rzeczywistość znamy już z gier komputerowych\\\\cite{vr_gry}, gdzie przynajmniej w grach wojennych dominuje propaganda Amerykańska\\\\cite{tvgrypl_amerykanska_nodate}. Na potrzeby reklamy można zamówić usługi agencji VR\\\\cite{vr_rynek}, lub stworzyć stronę oferującą interakcje z obrazami i filmami w 360 stopniach\\\\cite{vr_360}. Treści dziennikarskie też już są tworzone z wykorzystaniem rozszerzonej rzeczywistości\\\\cite{wyborcza}. Świetnym przykładem jest film dokumentalny stworzony w technologii 360 stopni - “Hong Kong Unrest” z 2014. Film pokazuje demonstrację pro-demokratyczną i pozwala odbiorcy obserwować wydarzenia z punktu widzenia jej uczestnika. Według badań Google News Lab \\\"gdy widzowie są emocjonalnie zaangażowani w informacje, a tak jest w wirtualnej rzeczywistości, (...) pojawia się u nich potrzeba (...) dowiedzenia się na dany temat więcej\\\"\\\\cite{wyborcza}. Z drugiej strony zaangażowanie emocjonalne zwiększa szansę na skuteczność wywierania wpływu, a co za tym idzie angażujący materiał pozwala skuteczniej zmienić zachowania odbiorców\\\\cite{wawrzynski_emocje_2015}.\"]]],[1,\"p\",[[0,[],0,\"Świetnym tego przykładem jest produkcja VR Nonprofit Smile Train. Pozwala ona  użytkownikom Oculus Rift śledzić losy 12-letniej dziewczynki, Niszy, mieszkającej w syryjskim obozie dla uchodźców, która wyjeżdża z odległej wioski na operację do gabinetu chirurgicznego i radości, jaką doświadcza po powrocie do kraju. Film VR, pokazywany na dorocznej konferencji fundraisingowej UNICEF-u, pomógł zebrać 3,8 miliarda dolarów, z czego co szósta osoba, po doświadczeniu dokumentu wirtualnej rzeczywistości, przekazała na cele charytatywne dwukrotnie więcej niż pierwotnie zamierzała.\"]]],[1,\"p\",[[0,[],0,\"Nagrywać filmy w 360 stopniach może zacząć każdy z nas, ponieważ ceny takich kamer są już bardzo niskie\\\\cite{one_x}. Myślę, że wirtualna rzeczywistość nie szykuje nam trzęsienia ziemi w zakresie narzędzi propagandowych, jest po prostu etapem ewolucji, następstwem tego, że kiedyś pojawił się cyfrowy dźwięk, obraz, film. Po prostu wciąż rosnące możliwości oddziaływania na odbiorców sprawiają, że przekaz może być jeszcze skuteczniejszy.\"]]],[1,\"h4\",[[0,[],0,\"Rzeczywistość rozszerzona (AR)\"]]],[1,\"p\",[[0,[],0,\"Rozszerzoną rzeczywistość mieliśmy okazję widzieć jakiś czas temu nawet kilkanaście razy podczas jednego przejazdu autobusem, kiedy wszyscy polowali na pokemony. Przyjęła się ona w zastosowaniach takich jak przewodniki turystyczne\\\\cite{rzeczywistosc_rozszerzona_a_ksiazka_i_prasa}, reklamy butów\\\\cite{Ludzis-Todorov}, szkolenia chirurgów\\\\cite{noauthor_nowoczesne_nodate}, sortowanie części samolotów\\\\cite{ejo_rzeczywistosc_nodate}. Podobnie jak w\"],[0,[],0,\"irtualna rzeczywisto\"],[0,[],0,\"ść, tak rozszerzona rzeczywistość znalazła zastosowanie w dziennikarstwie\\\\cite{wawrzynski_emocje_2015}. W tą technologię inwestuje Axel Springer Digital Ventures\\\\cite{wyborcza_axel_nodate} - firma blisko powiązana z jednym z największych wydawców na Polskim rynku\\\\cite{szpak_wsrod_nodate}. Tutaj sytuacja fake news i propagandy jest podobna jak w wirtualnej rzeczywistości.\"]]],[1,\"h4\",[[0,[],0,\"Rzeczywistość mieszana (MR)\"]]],[1,\"p\",[[0,[],0,\"Ze względu na konwergencję rzeczywistości rozszerzonej i wirtualnej można się spotkać z pojęciem rzeczywistości mieszanej “mixed reality” (MR) na określenie tych dwóch. Jeśli miałbym je jakoś podsumować, to istnieje duże prawdopodobieństwo, że fake newsy i treści propagandowe produkowane z wykorzystaniem tak emocjonalnie silnych form przekazu jak mieszana rzeczywistość będę znacznie silniej zapadały w pamięć i wpływały na zachowania odbiorców. Oddziaływanie to może służyć zarówno celom charytatywnym, inspirować do podróży, zaciekawiać historią swojego kraju jak też stanowić narzędzie dezinformacji i dezintegracji społeczeństw.\"]]],[1,\"h3\",[[0,[],0,\"Block Chain\"]]],[1,\"p\",[[0,[],0,\"Kiedy w 2008 roku Satoshi Nakamoto wprowadził technologię blockchain w walucie Bitcoin\\\\cite{nakamoto_bitcoin}, został stworzony grunt pod budowę zdecentralizowanych, zaufanych, publicznych, zbiorów danych. Dzięki bańce spekulacyjnej na kryptowaluty z roku 2017 w badanie i ulepszanie tej technologii zainwestowano bardzo dużo pieniędzy. Wzrosła też świadomość jej istnienia i potencjalnych możliwości. Dzisiaj coraz więcej branż widzi zastosowanie w technologii blockchain, która może w znaczny sposób zmienić modele biznesowe działających w nich przedsiębiorstw. Wyjątkiem nie jest tu dziennikarstwo.\"]]],[1,\"p\",[[0,[],0,\"W znakomitej pracy “Journalism Model Based on Blockchain with Sharing Space”\\\\cite{sym11010019} (“Model dziennikarstwa bazujący na blockchainie z przestrzenią wspólną”) opublikowanej 27 grudnia 2018 Byeowool Kim oraz Yongik Yoon przedstawiają model dziennikarstwa bazujący na hybrydowym blockchainie. Pokazują jak rozwiązać problemy ograniczania fake news, automatycznego, spersonalizowanego i wolnego od manipulacji ustawiania proponowanych artykułów, dzielenia się opiniami oraz zapewnienia dopływu kapitału na rozwijanie opisanej platformy z reklam. Jest to co prawda propozycja, pionierski opis koncepcji, jak mogłaby działać branża dziennikarska w przyszłości, ale bez trudu znaleźć możemy istniejące już platformy oparte o blockchain, które działają w branży mediów.\"]]],[1,\"h4\",[[0,[],0,\"Steem - blockchainowa sieć społecznościowa\"]]],[1,\"p\",[[0,[],0,\"Steem (nie mylić ze Steam) - sieć społecznościowa, która wychodząc z założenia, że największe serwisy pozwalające użytkownikom dodawać treści nabierają wartości dzięki tym treściom zaproponowała system wypłat dla twórców, których artykuły / wpisy / materiały video są uważane przez społeczność za wartościowe.\"]]],[1,\"h4\",[[0,[],0,\"Po.et - rozproszona baza praw własności\"]]],[1,\"p\",[[0,[],0,\"Po.et -  system pozwalający wiązać prawa własności i metadane z zasobami cyfrowymi. Jawna, kryptograficznie zabezpieczona, niezależna od żadnej instytucji informacja o twórcy danej treści stanowi solidny fundament do budowy narzędzi pozwalających automatycznie oceniać jakim zaufaniem możemy darzyć newsy, które czytamy. Jeśli twórca ma nieposzlakowaną opinię i bez wykradzenia jego kluczy prywatnych nie można się pod niego podszyć, należy założyć, że nie będzie chciał zniszczyć sobie reputacji udostępniając nieprawdziwą wiadomość. Z drugiej strony jeśli społeczność udowodni fałszywe wiadomości jakiemuś twórcy treści, warto byłoby mieć możliwość prześledzenia argumentów obu stron bez konieczności samodzielnego długiego ich wyszukiwania. Po.et nie udostępnia jeszcze tych dodatkowych możliwości, które pomogły by zautomatyzować obronę przez fake news i manipulacją, ale stanowi dobry fundament na którym tego typu aplikacje będą mogły w przyszłości wyrastać.\"]]],[1,\"h4\",[[0,[],0,\"Civil - platforma dziennikarska z systemem reputacji\"]]],[1,\"p\",[[0,[],0,\"Civil - należąca do społeczności sieć dziennikarska oparta o przejrzystość i zaufanie. Dzięki tej platformie można już teraz prowadzić dziennikarstwo oparte o blockchain, które uwzględnia finansową zachętę dla osób sprawdzających poprawność faktów. Społeczny charakter sieci pozwala na uniezależnienia sprawdzania od jednej instytucji, a system reputacji dla osób sprawdzających fakty pozwala bronić się przed nadużyciami. Jest to model bardzo bliski temu opisanemu we wspomnianej wyżej pracy, z zastrzeżeniem, finansowego aspektu przedsięwzięcia. Konsumenci treści produkowanych na Civil są obciążeni kosztem dostępu do nich. Stanowi to poważne ograniczenie, ponieważ jedynie nieznaczna część społeczeństwa jest chętna płacić za dostęp do cyfrowych newsów.\"]]],[1,\"p\",[[0,[],0,\"Ogólny wniosek jaki należałoby sformułować w kontekście wpływu blockchain na rynek mediów jest pozytywny. Wiele wskazuje na to, że zdecentralizowane, zalgorytmizowane sieci wykluczające możliwość cenzury, a z drugiej strony pozwalające na prowadzenie przez społeczność śledztw i weryfikowania źródeł informacji stanowią ważny brakujący element branży medialnej. Niepokoi jednak aspekt prawny, ponieważ władza w każdej części świata boi się tego nad czym nie ma kontroli i legalne istnienie takiej platformy może zostać zablokowane przez ustawodawców pod pretekstem ochrony danych osobowych i sprzeczności z prawem do bycia zapomnianym, które obowiązuje na terenie Unii Europejskiej.\"]]],[1,\"h3\",[[0,[],0,\"Uczenie maszynowe, Głębokie uczenie, Kognitywne obliczenia\"]]],[1,\"p\",[[0,[],0,\"Trzy ostatnie technologię omówimy razem, ponieważ w potocznym języku i tak opisuje się wszystko jako sztuczną inteligencję, a w ścisłym znaczeniu dwie kolejne są po prostu wyspecjalizowanymi gałęziami bardzo szerokiego pojęcia jakim jest uczenie maszynowe.\"]]],[1,\"p\",[[0,[],0,\"Uczenie maszynowe i sztuczna inteligencja mają bardzo szerokie zastosowania w ogromnej ilości branż i to już od naprawdę długiego czasu. Co więc sprawia, że są na tej liście? Postęp w możliwościach, które przed nimi stoją. Skupimy się na detekcji fake-news oraz tworzeniu treści typu deepfake. Na koniec zarysujemy możliwości, które mimo, że są wciąż poza zasięgiem będą naturalną konsekwencją rozwoju tej gałęzi technologii.\"]]],[1,\"h4\",[[0,[],0,\"Detekcja Fake News\"]]],[1,\"p\",[[0,[],0,\"Cały problem z fake news polega na tym, że jako wiadomość nieprawdziwa zwykle kłóci się z naszą racjonalną wizją świata. Ewolucja tak nas zaprojektowała, aby reagować silniej na te bodźce, które dotyczą zmiany, na przykład zmieniają nasze postrzeganie świata. Szok związany z czytaniem nie prawdy, zdziwienie, niedowierzanie powiązane są z reakcją taką jak napisanie komentarza, kliknięcie. Z drugiej strony wszelka aktywność związana z wiadomością jest automatycznie premiowana, ponieważ twórcy platform wychodzą z bądź co bądź racjonalnego założenia, że to co przyciąga użytkowników do ich platformy i wymusza na nich oglądanie reklam powinno być wzmacniane. Nie dziwi zatem implementacja mechanizmów, które odpowiadają za priorytetyzację wyświetlania wiadomości treści kontrowersyjnych. Skoro zaś fake newsy są kontrowersyjne i powodują bardziej aktywną interakcję użytkowników z tymi treściami, to wynikiem jest ich wirusowe rozprzestrzenianie.\"]]],[1,\"p\",[[0,[],0,\"Mimo to firmy takie jak Google i Facebook dostrzegając skalę problemu i długofalowe skutki takiej sytuacji takie jak utrata zaufania użytkowników. Zdają sobie sprawę, że odchodzenie użytkowników w poszukiwania bardziej wiarygodnych źródeł informacji, da efekcie odpływ kapitału reklamodawców. Podjęły zatem walkę z fake news. Z jednej strony jest to współpraca z organizacjami wyspecjalizowanymi w sprawdzaniu wiarygodności informacji, z drugiej ułatwienie użytkownikom raportowania treści, które budzą podejrzenie prawdziwości, z trzeciej automatyzacja i prace nad algorytmami które ułatwiłyby weryfikację i obniżyły jej koszty. W ten proces zaangażowały się również środowiska naukowe. Sytuacja jest rozwojowa i należy spodziewać się, że platformy zaczną prowadzić cenzurę treści uznanych za fałszywe.\"]]],[1,\"h4\",[[0,[],0,\"Tworzenie Deep Fake\"]]],[1,\"p\",[[0,[],0,\"Z drugiej strony ta sama technologia uczenia maszynowego może być rozwijana nie w celu wykrywania, lecz w celu tworzenia zmanipulowanych wiadomości. Naśladując ludzi sztuczna inteligencja może wytwarzać treści, a boty mające dostęp do serwisów społecznościowych mogą je tam rozpowszechniać. Przykład: niemal 20 proc. tweetów związanych z wyborami w USA stworzyły boty\\\\cite{crazynauka_prawda}. Jednak to nic w porównaniu z technologią tworzenia bardzo realistycznie wyglądających video w których zarówno prezentowana osoba, jak i jej głos mogą być dowolnie modelowane przez twórców. Jest ona wykorzystywana do prezentowania wiadomości w Chińskiej Republice Ludowej, a jej szeroko komentowana demonstracja dostępna jest pod linkiem.\"]]],[10,1],[1,\"p\",[[0,[],0,\"Kontakt z deep fake może być bardzo trudny do odkręcenia, tym bardziej, że będą one ewoluowały w stronę podniesienia siły oddziaływania poprzez korzystanie z technologii mieszanej rzeczywistości oraz z uwagi na sposób działania naszej pamięci. Badania dowodzą, że nawet jeśli w danym momencie zdajemy sobie sprawę, że dany przekaz jest fałszywy, to w wyniku zapominania i zamazywania się wspomnień stopniowo tracimy tą informację, natomiast sam przekaz pamiętamy lepiej. Oznacza to, że po odpowiednim czasie możemy traktować go na równi z innymi prawdziwymi informacjami przez co sama świadomość, że coś jest nie prawdą nie musi oznaczać, że fałszywa informacja nie wpłynie w przyszłości na nasze zachowanie.\"]]],[1,\"h4\",[[0,[],0,\"Sztuczna inteligencja jako członek społeczeństwa, Interfejsy Mózg - Komputer, Mózg - Mózg\"]]],[1,\"p\",[[0,[],0,\"Wybiegniemy teraz trochę w przyszłość. Ciężko powiedzieć jak odległą ponieważ zdania badaczy są podzielone, jednak zwykle mówi się o kilkudziesięciu latach. Chodzi o moment, kiedy zatrze się granica między \\\"możliwościami obliczeniowymi\\\" mózgów biologicznych oraz cyfrowych. Będzie to oznaczać, że sztuczna inteligencja dorówna nam, a później przewyższy nas w możliwościach poznawania i analizy rzeczywistości. Teraz traktujemy ją jako narzędzie do rozwiązywania problemów, lecz może się okazać, że instancje sztucznej inteligencji staną się członkami naszego społeczeństwa, zaczną tworzyć własne treści tak jak to się robi w dziennikarstwie obliczeniowym z tą różnicą, że bez kontroli człowieka. Zaczną też czytać treści i interesować się własną edukacją i rozwojem.\"]]],[1,\"p\",[[0,[],0,\"Prawdopodobnie nieco wcześniej rozwinie się technologia nazywana interfejsem mózg - komputer. Już teraz możemy komunikować się z komputerem za pomocą głosu, myszki, klawiatury, ekranu, głośników i coraz bardziej wymyślnych akcesoriów. Jednak nazwa “interfejs mózg - komputer” zarezerwowana jest dla bezpośredniej komunikacji układów cyfrowych z ludzką myślą. Znane są przypadki takiej komunikacji jak przekazywanie sygnałów między ludźmi z wszczepionymi chipami, adaptacja ludzkiego organizmu do korzystania z układu elektronicznego do echolokacji. Z interfejsu mózg - komputer korzystają też osoby sparaliżowane, które mogą dzięki niemu pisać na klawiaturze odpowiednio koncentrując swoje myśli. Ponieważ technologia ta się wciąż rozwija należy oczekiwać momentu, w którym szybkość wprowadzania tekstu do komputera w ten sposób przekroczy tempo z jakim ludzie potrafią pisać na klawiaturach. Jeśli jednak komputery mogą komunikować się ze sobą za pomocą bardzo wydajnych protokołów, a prędkość wymiany myśli między maszyną a człowiekiem wzrośnie, to nic nie będzie stało na przeszkodzie, aby takim elektronicznym mostkiem spiąć ze sobą dwa mózgi. Jeśli dwa, to dlaczego nie więcej. Jest więc duża szansa na to, że nasze mózgi dostaną możliwość stania się cegiełkami budującymi większą sieć. Oczywistym jest, że tak ogromna zmiana topologii przestrzeni, w której przepływają myśli i wiadomości otworzy zupełnie inną perspektywę patrzenia na problem manipulacji medialnej.\"]]],[1,\"h2\",[[0,[],0,\"Ocena wpływu technologii na kształt mediów w przyszłości.\"]]],[1,\"p\",[[0,[],0,\"Czas zamknąć naszą niesamowitą podróż po świecie nowych technologii, ich wpływu na dziennikarstwo i futurystycznych wizji tego jak może on wyglądać w przyszłości. Wszystkie podane powyżej technologie będą się rozwijać i to jak będzie wyglądał świat za jakiś czas będzie nałożeniem się ich wszystkich.\"]]],[1,\"p\",[[0,[],0,\"Nie znam odpowiedzi na pytania o to, jaki dokładnie kształt przybierze rynek wydawniczy oraz czy i jak cywilizacja poradzi sobie z problemem fake news. Mogę jednak zasugerować pewien sposób patrzenia, który uważam za cenny przy ocenie takich rzeczy:\"]]],[3,\"ul\",[[[0,[],0,\"Po pierwsze należy się zastanowić kto i jaki interes ma w jakim stanie rzeczy. Ile jest gotów w to zainwestować? Jakie zyski może z tego czerpać?\"]],[[0,[],0,\"Po drugie należy rozważyć problem sprzecznych interesów w kategoriach teorii gier i zapytać nie o strategię najlepszą dla uczestników gry, ale o strategię ewolucyjnie stabilną, to znaczy taką, w której żadnemu z uczestników nie będzie opłacało się zmieniać swojego zachowania.\"]]]],[1,\"p\",[[0,[],0,\"Tym czasem dla nas na codzień najlepszym sposobem na korzystanie z mediów jest robienie tego świadomie i poszerzanie swojej wiedzy dotyczącej kierujących nimi zasad.\"]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Artykuł stanowi lekkie wprowadzenie do tematyki fałszywych wiadomości, post prawdy i manipulacji medialnej. Zagadnienia te omawiane są w kontekście dynamicznego rozwoju technologii, która z jednej strony pozwala je skuteczniej wykrywać, a z drugiej strony wytwarzać. Tekstu nie należy traktować jak opracowania naukowego, jest to raczej wyrażenie opinii autora i spekulacja na temat kierunku w jakim ewoluować będzie zjawisko publikowania “fake news”.</p><h2 id=\"dlaczego-warto-kszta%C5%82ci%C4%87-si%C4%99-w-zakresie-%E2%80%9Cfakenews%E2%80%9D\">Dlaczego warto kształcić się w zakresie “fakenews”</h2><p>5 stycznia 2018 roku. Pogodny dzień, temperatura w okolicach 3 stopni celsjusza. W hotelu Grand America w Salt Lake City w stanie Utah odbywa się ogłoszenie słowa wybranego słowem roku 2017. Wybór sygnuje American Dialect Society[4] - organizacja o 129 letniej historii, której celem jest studiowanie języka angielskiego.</p><p>Wybór pada na “fake news”[16]. To mógłby być przypadek, ale...2 listopada 2017. Na Twitterze Collins Dictionary[15] również publikuje wy-bór “fake news” na słowo roku 2017[18]. Komitet Macquarie Dictionary wybrał je słowem roku już w 2016[27]. Tym czasem Dictionay.com ogłosił “misinformation” słowem 2018[7]. Oxford Dictionary uznał “post prawdę” za słowo 2016[34],1American Dialect  Society  nominował  “deepfake”[19]  do  głosowania  na  słowo 2018</p><p>W artykułach poświęconych zagadnieniu częściej mówi się, że jest to znak czasów,[1,  29]  a  nie  zbieg  okoliczności.  Przedstawia  się  poważne  skutki  polityczne[23]  i  gospodarcze[13].  Prowadzone  są  zakrojone  na  ogromną  skalę  ba-dania różnic w tempie rozprzestrzeniania się prawdziwych i fałszywych wiadomości[31,  28],  oraz  organizuje  konkursy  na  budowę  sieci  neuronowych  do  ich wykrywania[8]</p><p>Czym zatem jest “fake news” i jakie znaczenie ma dla nas w życiu codzien-nym?</p><p>Zgodnie z definicją proponowaną przez Mały Leksykon Post Prawdy[21]</p><p>”Pojęcie fake news najczęściej definiowane jest jako fałszywa wiado-mość, często o charakterze sensacyjnym, publikowana w mediach z intencją wprowadzenia odbiorcy w błąd w celu osiągnięcia korzyści finansowych, politycznych lub prestiżowych.”.</p><p>Wynika z niej wprost, że główym celem istnienia tego zjawiska jest transfer szeroko rozumianych zasobów od odbiorcy do twórcy fałszywej wiadomości. Na przykład jeśli fake newsami niszczy się zgodę w społeczeństwie[11], to łatwiej można je kontrolować i odwracać jego uwagę od miejsc gdzie twórca fake newsa narusza jego interesy. Znane z historii są przypadki, gdzie rozsiewanie fake new-sów prowadziło do znacznego transferu majątków w wywołanych nimi reakcji rynków. Stanowią one też skuteczne narzędzie w kampaniach politycznych i spo-łecznych w systemie demokratycznym.</p><p>Mam nadzieję, że to wystarczająca argumentacja, aby uznać, że w naszyminteresie jest zrozumienie tego zjawiska. W dalszej części artykułu zastanowimysię jaki wpływ na nie ma technologia.</p><h2 id=\"jak-technologie-pomagaj%C4%85-wykrywa%C4%87-i-tworzy%C4%87-propagand%C4%99\">Jak technologie pomagają wykrywać i tworzyć propagandę.</h2><p>Istnieje bardzo szerokie spektrum manipulacji medialnych od ewidentnych kłamstw, poprzez przemilczenia, wyrywanie fragmentów wypowiedzi z kontekstu, przetwarzanie zdjęć, zmianę skali na wykresach, produkowanie komentarzy pod artykułami, trolling, operacje fałszywej flagi, aż do subtelnego doboru słów,które pozwala nie zmieniając faktów oddziaływać na emocje odbiorcy.</p><p>Historia wojny o umysły jest równie ciekawa co obszerna. W tym opracowaniu  skupimy  się  jedynie  na  najnowszych  nabytkach  arsenału  defensywnego i ofensywnego tej walki. Dzięki opracowaniu Gartnera[9] możemy przyjrzeć się całemu wachlarzowi technologii, które w tym momencie wchodzą lub będą wchodzić do codziennego użycia.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/04/gartner.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"702\" height=\"478\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/gartner.png 600w, __GHOST_URL__/content/images/2021/04/gartner.png 702w\"><figcaption>Rysunek 1: „Hype Cycle” pokazuje na jakim etapie rozwoju jest dana techno-logia (fot. Gartner)</figcaption></figure><p>Wśród nich te które najbardziej wpływają na rynek mediów to:</p><ul><li>wirtualna rzeczywistość</li><li>rzeczywistość rozszerzona</li><li>blockchain</li><li>uczenie maszynowe</li><li>głębokie uczenie</li><li>kognitywne obliczenia</li></ul><p>Przyjrzyjmy się im po kolei.</p><h3 id=\"wirtualna-rzeczywisto%C5%9B%C4%87-vr-a-rzeczywisto%C5%9B%C4%87-rozszerzona-ar\">Wirtualna rzeczywistość (VR) a rzeczywistość rozszerzona (AR)</h3><p>Wirtualna rzeczywistość jest kolejnym krokiem w przenoszeniu realnego świata do postaci cyfrowej. Rzeczywistość rozszerzona przeciwnie, pozwala na umieszczanie przedmiotów wirtualnych w świecie rzeczywistym. Skumulowany roczny wzrost wartości rynków VR i AR w latach 2015-2020 szacowany jest przez International Data Corporation na 180%. Dochody tych branż mają wzrosnąć z 5 mld dol. do 162 mld dol. w 2020 r[24]</p><h4 id=\"wirtualna-rzeczywisto%C5%9B%C4%87-vr\">Wirtualna rzeczywistość (VR)</h4><p>Wirtualną rzeczywistość znamy już z gier komputerowych\\cite{vr_gry}, gdzie przynajmniej w grach wojennych dominuje propaganda Amerykańska\\cite{tvgrypl_amerykanska_nodate}. Na potrzeby reklamy można zamówić usługi agencji VR\\cite{vr_rynek}, lub stworzyć stronę oferującą interakcje z obrazami i filmami w 360 stopniach\\cite{vr_360}. Treści dziennikarskie też już są tworzone z wykorzystaniem rozszerzonej rzeczywistości\\cite{wyborcza}. Świetnym przykładem jest film dokumentalny stworzony w technologii 360 stopni - “Hong Kong Unrest” z 2014. Film pokazuje demonstrację pro-demokratyczną i pozwala odbiorcy obserwować wydarzenia z punktu widzenia jej uczestnika. Według badań Google News Lab \"gdy widzowie są emocjonalnie zaangażowani w informacje, a tak jest w wirtualnej rzeczywistości, (...) pojawia się u nich potrzeba (...) dowiedzenia się na dany temat więcej\"\\cite{wyborcza}. Z drugiej strony zaangażowanie emocjonalne zwiększa szansę na skuteczność wywierania wpływu, a co za tym idzie angażujący materiał pozwala skuteczniej zmienić zachowania odbiorców\\cite{wawrzynski_emocje_2015}.</p><p>Świetnym tego przykładem jest produkcja VR Nonprofit Smile Train. Pozwala ona  użytkownikom Oculus Rift śledzić losy 12-letniej dziewczynki, Niszy, mieszkającej w syryjskim obozie dla uchodźców, która wyjeżdża z odległej wioski na operację do gabinetu chirurgicznego i radości, jaką doświadcza po powrocie do kraju. Film VR, pokazywany na dorocznej konferencji fundraisingowej UNICEF-u, pomógł zebrać 3,8 miliarda dolarów, z czego co szósta osoba, po doświadczeniu dokumentu wirtualnej rzeczywistości, przekazała na cele charytatywne dwukrotnie więcej niż pierwotnie zamierzała.</p><p>Nagrywać filmy w 360 stopniach może zacząć każdy z nas, ponieważ ceny takich kamer są już bardzo niskie\\cite{one_x}. Myślę, że wirtualna rzeczywistość nie szykuje nam trzęsienia ziemi w zakresie narzędzi propagandowych, jest po prostu etapem ewolucji, następstwem tego, że kiedyś pojawił się cyfrowy dźwięk, obraz, film. Po prostu wciąż rosnące możliwości oddziaływania na odbiorców sprawiają, że przekaz może być jeszcze skuteczniejszy.</p><h4 id=\"rzeczywisto%C5%9B%C4%87-rozszerzona-ar\">Rzeczywistość rozszerzona (AR)</h4><p>Rozszerzoną rzeczywistość mieliśmy okazję widzieć jakiś czas temu nawet kilkanaście razy podczas jednego przejazdu autobusem, kiedy wszyscy polowali na pokemony. Przyjęła się ona w zastosowaniach takich jak przewodniki turystyczne\\cite{rzeczywistosc_rozszerzona_a_ksiazka_i_prasa}, reklamy butów\\cite{Ludzis-Todorov}, szkolenia chirurgów\\cite{noauthor_nowoczesne_nodate}, sortowanie części samolotów\\cite{ejo_rzeczywistosc_nodate}. Podobnie jak wirtualna rzeczywistość, tak rozszerzona rzeczywistość znalazła zastosowanie w dziennikarstwie\\cite{wawrzynski_emocje_2015}. W tą technologię inwestuje Axel Springer Digital Ventures\\cite{wyborcza_axel_nodate} - firma blisko powiązana z jednym z największych wydawców na Polskim rynku\\cite{szpak_wsrod_nodate}. Tutaj sytuacja fake news i propagandy jest podobna jak w wirtualnej rzeczywistości.</p><h4 id=\"rzeczywisto%C5%9B%C4%87-mieszana-mr\">Rzeczywistość mieszana (MR)</h4><p>Ze względu na konwergencję rzeczywistości rozszerzonej i wirtualnej można się spotkać z pojęciem rzeczywistości mieszanej “mixed reality” (MR) na określenie tych dwóch. Jeśli miałbym je jakoś podsumować, to istnieje duże prawdopodobieństwo, że fake newsy i treści propagandowe produkowane z wykorzystaniem tak emocjonalnie silnych form przekazu jak mieszana rzeczywistość będę znacznie silniej zapadały w pamięć i wpływały na zachowania odbiorców. Oddziaływanie to może służyć zarówno celom charytatywnym, inspirować do podróży, zaciekawiać historią swojego kraju jak też stanowić narzędzie dezinformacji i dezintegracji społeczeństw.</p><h3 id=\"block-chain\">Block Chain</h3><p>Kiedy w 2008 roku Satoshi Nakamoto wprowadził technologię blockchain w walucie Bitcoin\\cite{nakamoto_bitcoin}, został stworzony grunt pod budowę zdecentralizowanych, zaufanych, publicznych, zbiorów danych. Dzięki bańce spekulacyjnej na kryptowaluty z roku 2017 w badanie i ulepszanie tej technologii zainwestowano bardzo dużo pieniędzy. Wzrosła też świadomość jej istnienia i potencjalnych możliwości. Dzisiaj coraz więcej branż widzi zastosowanie w technologii blockchain, która może w znaczny sposób zmienić modele biznesowe działających w nich przedsiębiorstw. Wyjątkiem nie jest tu dziennikarstwo.</p><p>W znakomitej pracy “Journalism Model Based on Blockchain with Sharing Space”\\cite{sym11010019} (“Model dziennikarstwa bazujący na blockchainie z przestrzenią wspólną”) opublikowanej 27 grudnia 2018 Byeowool Kim oraz Yongik Yoon przedstawiają model dziennikarstwa bazujący na hybrydowym blockchainie. Pokazują jak rozwiązać problemy ograniczania fake news, automatycznego, spersonalizowanego i wolnego od manipulacji ustawiania proponowanych artykułów, dzielenia się opiniami oraz zapewnienia dopływu kapitału na rozwijanie opisanej platformy z reklam. Jest to co prawda propozycja, pionierski opis koncepcji, jak mogłaby działać branża dziennikarska w przyszłości, ale bez trudu znaleźć możemy istniejące już platformy oparte o blockchain, które działają w branży mediów.</p><h4 id=\"steemblockchainowa-sie%C4%87-spo%C5%82eczno%C5%9Bciowa\">Steem - blockchainowa sieć społecznościowa</h4><p>Steem (nie mylić ze Steam) - sieć społecznościowa, która wychodząc z założenia, że największe serwisy pozwalające użytkownikom dodawać treści nabierają wartości dzięki tym treściom zaproponowała system wypłat dla twórców, których artykuły / wpisy / materiały video są uważane przez społeczność za wartościowe.</p><h4 id=\"poetrozproszona-baza-praw-w%C5%82asno%C5%9Bci\">Po.et - rozproszona baza praw własności</h4><p>Po.et -  system pozwalający wiązać prawa własności i metadane z zasobami cyfrowymi. Jawna, kryptograficznie zabezpieczona, niezależna od żadnej instytucji informacja o twórcy danej treści stanowi solidny fundament do budowy narzędzi pozwalających automatycznie oceniać jakim zaufaniem możemy darzyć newsy, które czytamy. Jeśli twórca ma nieposzlakowaną opinię i bez wykradzenia jego kluczy prywatnych nie można się pod niego podszyć, należy założyć, że nie będzie chciał zniszczyć sobie reputacji udostępniając nieprawdziwą wiadomość. Z drugiej strony jeśli społeczność udowodni fałszywe wiadomości jakiemuś twórcy treści, warto byłoby mieć możliwość prześledzenia argumentów obu stron bez konieczności samodzielnego długiego ich wyszukiwania. Po.et nie udostępnia jeszcze tych dodatkowych możliwości, które pomogły by zautomatyzować obronę przez fake news i manipulacją, ale stanowi dobry fundament na którym tego typu aplikacje będą mogły w przyszłości wyrastać.</p><h4 id=\"civilplatforma-dziennikarska-z-systemem-reputacji\">Civil - platforma dziennikarska z systemem reputacji</h4><p>Civil - należąca do społeczności sieć dziennikarska oparta o przejrzystość i zaufanie. Dzięki tej platformie można już teraz prowadzić dziennikarstwo oparte o blockchain, które uwzględnia finansową zachętę dla osób sprawdzających poprawność faktów. Społeczny charakter sieci pozwala na uniezależnienia sprawdzania od jednej instytucji, a system reputacji dla osób sprawdzających fakty pozwala bronić się przed nadużyciami. Jest to model bardzo bliski temu opisanemu we wspomnianej wyżej pracy, z zastrzeżeniem, finansowego aspektu przedsięwzięcia. Konsumenci treści produkowanych na Civil są obciążeni kosztem dostępu do nich. Stanowi to poważne ograniczenie, ponieważ jedynie nieznaczna część społeczeństwa jest chętna płacić za dostęp do cyfrowych newsów.</p><p>Ogólny wniosek jaki należałoby sformułować w kontekście wpływu blockchain na rynek mediów jest pozytywny. Wiele wskazuje na to, że zdecentralizowane, zalgorytmizowane sieci wykluczające możliwość cenzury, a z drugiej strony pozwalające na prowadzenie przez społeczność śledztw i weryfikowania źródeł informacji stanowią ważny brakujący element branży medialnej. Niepokoi jednak aspekt prawny, ponieważ władza w każdej części świata boi się tego nad czym nie ma kontroli i legalne istnienie takiej platformy może zostać zablokowane przez ustawodawców pod pretekstem ochrony danych osobowych i sprzeczności z prawem do bycia zapomnianym, które obowiązuje na terenie Unii Europejskiej.</p><h3 id=\"uczenie-maszynowe-g%C5%82%C4%99bokie-uczenie-kognitywne-obliczenia\">Uczenie maszynowe, Głębokie uczenie, Kognitywne obliczenia</h3><p>Trzy ostatnie technologię omówimy razem, ponieważ w potocznym języku i tak opisuje się wszystko jako sztuczną inteligencję, a w ścisłym znaczeniu dwie kolejne są po prostu wyspecjalizowanymi gałęziami bardzo szerokiego pojęcia jakim jest uczenie maszynowe.</p><p>Uczenie maszynowe i sztuczna inteligencja mają bardzo szerokie zastosowania w ogromnej ilości branż i to już od naprawdę długiego czasu. Co więc sprawia, że są na tej liście? Postęp w możliwościach, które przed nimi stoją. Skupimy się na detekcji fake-news oraz tworzeniu treści typu deepfake. Na koniec zarysujemy możliwości, które mimo, że są wciąż poza zasięgiem będą naturalną konsekwencją rozwoju tej gałęzi technologii.</p><h4 id=\"detekcja-fake-news\">Detekcja Fake News</h4><p>Cały problem z fake news polega na tym, że jako wiadomość nieprawdziwa zwykle kłóci się z naszą racjonalną wizją świata. Ewolucja tak nas zaprojektowała, aby reagować silniej na te bodźce, które dotyczą zmiany, na przykład zmieniają nasze postrzeganie świata. Szok związany z czytaniem nie prawdy, zdziwienie, niedowierzanie powiązane są z reakcją taką jak napisanie komentarza, kliknięcie. Z drugiej strony wszelka aktywność związana z wiadomością jest automatycznie premiowana, ponieważ twórcy platform wychodzą z bądź co bądź racjonalnego założenia, że to co przyciąga użytkowników do ich platformy i wymusza na nich oglądanie reklam powinno być wzmacniane. Nie dziwi zatem implementacja mechanizmów, które odpowiadają za priorytetyzację wyświetlania wiadomości treści kontrowersyjnych. Skoro zaś fake newsy są kontrowersyjne i powodują bardziej aktywną interakcję użytkowników z tymi treściami, to wynikiem jest ich wirusowe rozprzestrzenianie.</p><p>Mimo to firmy takie jak Google i Facebook dostrzegając skalę problemu i długofalowe skutki takiej sytuacji takie jak utrata zaufania użytkowników. Zdają sobie sprawę, że odchodzenie użytkowników w poszukiwania bardziej wiarygodnych źródeł informacji, da efekcie odpływ kapitału reklamodawców. Podjęły zatem walkę z fake news. Z jednej strony jest to współpraca z organizacjami wyspecjalizowanymi w sprawdzaniu wiarygodności informacji, z drugiej ułatwienie użytkownikom raportowania treści, które budzą podejrzenie prawdziwości, z trzeciej automatyzacja i prace nad algorytmami które ułatwiłyby weryfikację i obniżyły jej koszty. W ten proces zaangażowały się również środowiska naukowe. Sytuacja jest rozwojowa i należy spodziewać się, że platformy zaczną prowadzić cenzurę treści uznanych za fałszywe.</p><h4 id=\"tworzenie-deep-fake\">Tworzenie Deep Fake</h4><p>Z drugiej strony ta sama technologia uczenia maszynowego może być rozwijana nie w celu wykrywania, lecz w celu tworzenia zmanipulowanych wiadomości. Naśladując ludzi sztuczna inteligencja może wytwarzać treści, a boty mające dostęp do serwisów społecznościowych mogą je tam rozpowszechniać. Przykład: niemal 20 proc. tweetów związanych z wyborami w USA stworzyły boty\\cite{crazynauka_prawda}. Jednak to nic w porównaniu z technologią tworzenia bardzo realistycznie wyglądających video w których zarówno prezentowana osoba, jak i jej głos mogą być dowolnie modelowane przez twórców. Jest ona wykorzystywana do prezentowania wiadomości w Chińskiej Republice Ludowej, a jej szeroko komentowana demonstracja dostępna jest pod linkiem.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/04/obama.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"1919\" height=\"971\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/obama.jpg 600w, __GHOST_URL__/content/images/size/w1000/2021/04/obama.jpg 1000w, __GHOST_URL__/content/images/size/w1600/2021/04/obama.jpg 1600w, __GHOST_URL__/content/images/2021/04/obama.jpg 1919w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Wycinek video na któym Jordan Peele prezentuje Deep Fake z prezydentem Obamą</figcaption></figure><p>Kontakt z deep fake może być bardzo trudny do odkręcenia, tym bardziej, że będą one ewoluowały w stronę podniesienia siły oddziaływania poprzez korzystanie z technologii mieszanej rzeczywistości oraz z uwagi na sposób działania naszej pamięci. Badania dowodzą, że nawet jeśli w danym momencie zdajemy sobie sprawę, że dany przekaz jest fałszywy, to w wyniku zapominania i zamazywania się wspomnień stopniowo tracimy tą informację, natomiast sam przekaz pamiętamy lepiej. Oznacza to, że po odpowiednim czasie możemy traktować go na równi z innymi prawdziwymi informacjami przez co sama świadomość, że coś jest nie prawdą nie musi oznaczać, że fałszywa informacja nie wpłynie w przyszłości na nasze zachowanie.</p><h4 id=\"sztuczna-inteligencja-jako-cz%C5%82onek-spo%C5%82ecze%C5%84stwa-interfejsy-m%C3%B3zgkomputer-m%C3%B3zgm%C3%B3zg\">Sztuczna inteligencja jako członek społeczeństwa, Interfejsy Mózg - Komputer, Mózg - Mózg</h4><p>Wybiegniemy teraz trochę w przyszłość. Ciężko powiedzieć jak odległą ponieważ zdania badaczy są podzielone, jednak zwykle mówi się o kilkudziesięciu latach. Chodzi o moment, kiedy zatrze się granica między \"możliwościami obliczeniowymi\" mózgów biologicznych oraz cyfrowych. Będzie to oznaczać, że sztuczna inteligencja dorówna nam, a później przewyższy nas w możliwościach poznawania i analizy rzeczywistości. Teraz traktujemy ją jako narzędzie do rozwiązywania problemów, lecz może się okazać, że instancje sztucznej inteligencji staną się członkami naszego społeczeństwa, zaczną tworzyć własne treści tak jak to się robi w dziennikarstwie obliczeniowym z tą różnicą, że bez kontroli człowieka. Zaczną też czytać treści i interesować się własną edukacją i rozwojem.</p><p>Prawdopodobnie nieco wcześniej rozwinie się technologia nazywana interfejsem mózg - komputer. Już teraz możemy komunikować się z komputerem za pomocą głosu, myszki, klawiatury, ekranu, głośników i coraz bardziej wymyślnych akcesoriów. Jednak nazwa “interfejs mózg - komputer” zarezerwowana jest dla bezpośredniej komunikacji układów cyfrowych z ludzką myślą. Znane są przypadki takiej komunikacji jak przekazywanie sygnałów między ludźmi z wszczepionymi chipami, adaptacja ludzkiego organizmu do korzystania z układu elektronicznego do echolokacji. Z interfejsu mózg - komputer korzystają też osoby sparaliżowane, które mogą dzięki niemu pisać na klawiaturze odpowiednio koncentrując swoje myśli. Ponieważ technologia ta się wciąż rozwija należy oczekiwać momentu, w którym szybkość wprowadzania tekstu do komputera w ten sposób przekroczy tempo z jakim ludzie potrafią pisać na klawiaturach. Jeśli jednak komputery mogą komunikować się ze sobą za pomocą bardzo wydajnych protokołów, a prędkość wymiany myśli między maszyną a człowiekiem wzrośnie, to nic nie będzie stało na przeszkodzie, aby takim elektronicznym mostkiem spiąć ze sobą dwa mózgi. Jeśli dwa, to dlaczego nie więcej. Jest więc duża szansa na to, że nasze mózgi dostaną możliwość stania się cegiełkami budującymi większą sieć. Oczywistym jest, że tak ogromna zmiana topologii przestrzeni, w której przepływają myśli i wiadomości otworzy zupełnie inną perspektywę patrzenia na problem manipulacji medialnej.</p><h2 id=\"ocena-wp%C5%82ywu-technologii-na-kszta%C5%82t-medi%C3%B3w-w-przysz%C5%82o%C5%9Bci\">Ocena wpływu technologii na kształt mediów w przyszłości.</h2><p>Czas zamknąć naszą niesamowitą podróż po świecie nowych technologii, ich wpływu na dziennikarstwo i futurystycznych wizji tego jak może on wyglądać w przyszłości. Wszystkie podane powyżej technologie będą się rozwijać i to jak będzie wyglądał świat za jakiś czas będzie nałożeniem się ich wszystkich.</p><p>Nie znam odpowiedzi na pytania o to, jaki dokładnie kształt przybierze rynek wydawniczy oraz czy i jak cywilizacja poradzi sobie z problemem fake news. Mogę jednak zasugerować pewien sposób patrzenia, który uważam za cenny przy ocenie takich rzeczy:</p><ul><li>Po pierwsze należy się zastanowić kto i jaki interes ma w jakim stanie rzeczy. Ile jest gotów w to zainwestować? Jakie zyski może z tego czerpać?</li><li>Po drugie należy rozważyć problem sprzecznych interesów w kategoriach teorii gier i zapytać nie o strategię najlepszą dla uczestników gry, ale o strategię ewolucyjnie stabilną, to znaczy taką, w której żadnemu z uczestników nie będzie opłacało się zmieniać swojego zachowania.</li></ul><p>Tym czasem dla nas na codzień najlepszym sposobem na korzystanie z mediów jest robienie tego świadomie i poszerzanie swojej wiedzy dotyczącej kierujących nimi zasad.</p>",
            "comment_id": "607f4f042fb35425592d0c54",
            "plaintext": "Artykuł stanowi lekkie wprowadzenie do tematyki fałszywych wiadomości, post\nprawdy i manipulacji medialnej. Zagadnienia te omawiane są w kontekście\ndynamicznego rozwoju technologii, która z jednej strony pozwala je skuteczniej\nwykrywać, a z drugiej strony wytwarzać. Tekstu nie należy traktować jak\nopracowania naukowego, jest to raczej wyrażenie opinii autora i spekulacja na\ntemat kierunku w jakim ewoluować będzie zjawisko publikowania “fake news”.\n\nDlaczego warto kształcić się w zakresie “fakenews”\n5 stycznia 2018 roku. Pogodny dzień, temperatura w okolicach 3 stopni celsjusza.\nW hotelu Grand America w Salt Lake City w stanie Utah odbywa się ogłoszenie\nsłowa wybranego słowem roku 2017. Wybór sygnuje American Dialect Society[4] -\norganizacja o 129 letniej historii, której celem jest studiowanie języka\nangielskiego.\n\nWybór pada na “fake news”[16]. To mógłby być przypadek, ale...2 listopada 2017.\nNa Twitterze Collins Dictionary[15] również publikuje wy-bór “fake news” na\nsłowo roku 2017[18]. Komitet Macquarie Dictionary wybrał je słowem roku już w\n2016[27]. Tym czasem Dictionay.com ogłosił “misinformation” słowem 2018[7].\nOxford Dictionary uznał “post prawdę” za słowo 2016[34],1American Dialect\n Society  nominował  “deepfake”[19]  do  głosowania  na  słowo 2018\n\nW artykułach poświęconych zagadnieniu częściej mówi się, że jest to znak\nczasów,[1,  29]  a  nie  zbieg  okoliczności.  Przedstawia  się  poważne  skutki\n polityczne[23]  i  gospodarcze[13].  Prowadzone  są  zakrojone  na  ogromną\n skalę  ba-dania różnic w tempie rozprzestrzeniania się prawdziwych i fałszywych\nwiadomości[31,  28],  oraz  organizuje  konkursy  na  budowę  sieci  neuronowych\n do  ich wykrywania[8]\n\nCzym zatem jest “fake news” i jakie znaczenie ma dla nas w życiu codzien-nym?\n\nZgodnie z definicją proponowaną przez Mały Leksykon Post Prawdy[21]\n\n”Pojęcie fake news najczęściej definiowane jest jako fałszywa wiado-mość, często\no charakterze sensacyjnym, publikowana w mediach z intencją wprowadzenia\nodbiorcy w błąd w celu osiągnięcia korzyści finansowych, politycznych lub\nprestiżowych.”.\n\nWynika z niej wprost, że główym celem istnienia tego zjawiska jest transfer\nszeroko rozumianych zasobów od odbiorcy do twórcy fałszywej wiadomości. Na\nprzykład jeśli fake newsami niszczy się zgodę w społeczeństwie[11], to łatwiej\nmożna je kontrolować i odwracać jego uwagę od miejsc gdzie twórca fake newsa\nnarusza jego interesy. Znane z historii są przypadki, gdzie rozsiewanie fake\nnew-sów prowadziło do znacznego transferu majątków w wywołanych nimi reakcji\nrynków. Stanowią one też skuteczne narzędzie w kampaniach politycznych i\nspo-łecznych w systemie demokratycznym.\n\nMam nadzieję, że to wystarczająca argumentacja, aby uznać, że w naszyminteresie\njest zrozumienie tego zjawiska. W dalszej części artykułu zastanowimysię jaki\nwpływ na nie ma technologia.\n\nJak technologie pomagają wykrywać i tworzyć propagandę.\nIstnieje bardzo szerokie spektrum manipulacji medialnych od ewidentnych kłamstw,\npoprzez przemilczenia, wyrywanie fragmentów wypowiedzi z kontekstu,\nprzetwarzanie zdjęć, zmianę skali na wykresach, produkowanie komentarzy pod\nartykułami, trolling, operacje fałszywej flagi, aż do subtelnego doboru\nsłów,które pozwala nie zmieniając faktów oddziaływać na emocje odbiorcy.\n\nHistoria wojny o umysły jest równie ciekawa co obszerna. W tym opracowaniu\n skupimy  się  jedynie  na  najnowszych  nabytkach  arsenału  defensywnego i\nofensywnego tej walki. Dzięki opracowaniu Gartnera[9] możemy przyjrzeć się\ncałemu wachlarzowi technologii, które w tym momencie wchodzą lub będą wchodzić\ndo codziennego użycia.\n\nRysunek 1: „Hype Cycle” pokazuje na jakim etapie rozwoju jest dana techno-logia\n(fot. Gartner)Wśród nich te które najbardziej wpływają na rynek mediów to:\n\n * wirtualna rzeczywistość\n * rzeczywistość rozszerzona\n * blockchain\n * uczenie maszynowe\n * głębokie uczenie\n * kognitywne obliczenia\n\nPrzyjrzyjmy się im po kolei.\n\nWirtualna rzeczywistość (VR) a rzeczywistość rozszerzona (AR)\nWirtualna rzeczywistość jest kolejnym krokiem w przenoszeniu realnego świata do\npostaci cyfrowej. Rzeczywistość rozszerzona przeciwnie, pozwala na umieszczanie\nprzedmiotów wirtualnych w świecie rzeczywistym. Skumulowany roczny wzrost\nwartości rynków VR i AR w latach 2015-2020 szacowany jest przez International\nData Corporation na 180%. Dochody tych branż mają wzrosnąć z 5 mld dol. do 162\nmld dol. w 2020 r[24]\n\nWirtualna rzeczywistość (VR)\nWirtualną rzeczywistość znamy już z gier komputerowych\\cite{vr_gry}, gdzie\nprzynajmniej w grach wojennych dominuje propaganda\nAmerykańska\\cite{tvgrypl_amerykanska_nodate}. Na potrzeby reklamy można zamówić\nusługi agencji VR\\cite{vr_rynek}, lub stworzyć stronę oferującą interakcje z\nobrazami i filmami w 360 stopniach\\cite{vr_360}. Treści dziennikarskie też już\nsą tworzone z wykorzystaniem rozszerzonej rzeczywistości\\cite{wyborcza}.\nŚwietnym przykładem jest film dokumentalny stworzony w technologii 360 stopni -\n“Hong Kong Unrest” z 2014. Film pokazuje demonstrację pro-demokratyczną i\npozwala odbiorcy obserwować wydarzenia z punktu widzenia jej uczestnika. Według\nbadań Google News Lab \"gdy widzowie są emocjonalnie zaangażowani w informacje, a\ntak jest w wirtualnej rzeczywistości, (...) pojawia się u nich potrzeba (...)\ndowiedzenia się na dany temat więcej\"\\cite{wyborcza}. Z drugiej strony\nzaangażowanie emocjonalne zwiększa szansę na skuteczność wywierania wpływu, a co\nza tym idzie angażujący materiał pozwala skuteczniej zmienić zachowania\nodbiorców\\cite{wawrzynski_emocje_2015}.\n\nŚwietnym tego przykładem jest produkcja VR Nonprofit Smile Train. Pozwala ona\n użytkownikom Oculus Rift śledzić losy 12-letniej dziewczynki, Niszy,\nmieszkającej w syryjskim obozie dla uchodźców, która wyjeżdża z odległej wioski\nna operację do gabinetu chirurgicznego i radości, jaką doświadcza po powrocie do\nkraju. Film VR, pokazywany na dorocznej konferencji fundraisingowej UNICEF-u,\npomógł zebrać 3,8 miliarda dolarów, z czego co szósta osoba, po doświadczeniu\ndokumentu wirtualnej rzeczywistości, przekazała na cele charytatywne dwukrotnie\nwięcej niż pierwotnie zamierzała.\n\nNagrywać filmy w 360 stopniach może zacząć każdy z nas, ponieważ ceny takich\nkamer są już bardzo niskie\\cite{one_x}. Myślę, że wirtualna rzeczywistość nie\nszykuje nam trzęsienia ziemi w zakresie narzędzi propagandowych, jest po prostu\netapem ewolucji, następstwem tego, że kiedyś pojawił się cyfrowy dźwięk, obraz,\nfilm. Po prostu wciąż rosnące możliwości oddziaływania na odbiorców sprawiają,\nże przekaz może być jeszcze skuteczniejszy.\n\nRzeczywistość rozszerzona (AR)\nRozszerzoną rzeczywistość mieliśmy okazję widzieć jakiś czas temu nawet\nkilkanaście razy podczas jednego przejazdu autobusem, kiedy wszyscy polowali na\npokemony. Przyjęła się ona w zastosowaniach takich jak przewodniki\nturystyczne\\cite{rzeczywistosc_rozszerzona_a_ksiazka_i_prasa}, reklamy\nbutów\\cite{Ludzis-Todorov}, szkolenia\nchirurgów\\cite{noauthor_nowoczesne_nodate}, sortowanie części\nsamolotów\\cite{ejo_rzeczywistosc_nodate}. Podobnie jak wirtualna rzeczywistość,\ntak rozszerzona rzeczywistość znalazła zastosowanie w\ndziennikarstwie\\cite{wawrzynski_emocje_2015}. W tą technologię inwestuje Axel\nSpringer Digital Ventures\\cite{wyborcza_axel_nodate} - firma blisko powiązana z\njednym z największych wydawców na Polskim rynku\\cite{szpak_wsrod_nodate}. Tutaj\nsytuacja fake news i propagandy jest podobna jak w wirtualnej rzeczywistości.\n\nRzeczywistość mieszana (MR)\nZe względu na konwergencję rzeczywistości rozszerzonej i wirtualnej można się\nspotkać z pojęciem rzeczywistości mieszanej “mixed reality” (MR) na określenie\ntych dwóch. Jeśli miałbym je jakoś podsumować, to istnieje duże\nprawdopodobieństwo, że fake newsy i treści propagandowe produkowane z\nwykorzystaniem tak emocjonalnie silnych form przekazu jak mieszana rzeczywistość\nbędę znacznie silniej zapadały w pamięć i wpływały na zachowania odbiorców.\nOddziaływanie to może służyć zarówno celom charytatywnym, inspirować do podróży,\nzaciekawiać historią swojego kraju jak też stanowić narzędzie dezinformacji i\ndezintegracji społeczeństw.\n\nBlock Chain\nKiedy w 2008 roku Satoshi Nakamoto wprowadził technologię blockchain w walucie\nBitcoin\\cite{nakamoto_bitcoin}, został stworzony grunt pod budowę\nzdecentralizowanych, zaufanych, publicznych, zbiorów danych. Dzięki bańce\nspekulacyjnej na kryptowaluty z roku 2017 w badanie i ulepszanie tej technologii\nzainwestowano bardzo dużo pieniędzy. Wzrosła też świadomość jej istnienia i\npotencjalnych możliwości. Dzisiaj coraz więcej branż widzi zastosowanie w\ntechnologii blockchain, która może w znaczny sposób zmienić modele biznesowe\ndziałających w nich przedsiębiorstw. Wyjątkiem nie jest tu dziennikarstwo.\n\nW znakomitej pracy “Journalism Model Based on Blockchain with Sharing\nSpace”\\cite{sym11010019} (“Model dziennikarstwa bazujący na blockchainie z\nprzestrzenią wspólną”) opublikowanej 27 grudnia 2018 Byeowool Kim oraz Yongik\nYoon przedstawiają model dziennikarstwa bazujący na hybrydowym blockchainie.\nPokazują jak rozwiązać problemy ograniczania fake news, automatycznego,\nspersonalizowanego i wolnego od manipulacji ustawiania proponowanych artykułów,\ndzielenia się opiniami oraz zapewnienia dopływu kapitału na rozwijanie opisanej\nplatformy z reklam. Jest to co prawda propozycja, pionierski opis koncepcji, jak\nmogłaby działać branża dziennikarska w przyszłości, ale bez trudu znaleźć możemy\nistniejące już platformy oparte o blockchain, które działają w branży mediów.\n\nSteem - blockchainowa sieć społecznościowa\nSteem (nie mylić ze Steam) - sieć społecznościowa, która wychodząc z założenia,\nże największe serwisy pozwalające użytkownikom dodawać treści nabierają wartości\ndzięki tym treściom zaproponowała system wypłat dla twórców, których artykuły /\nwpisy / materiały video są uważane przez społeczność za wartościowe.\n\nPo.et - rozproszona baza praw własności\nPo.et -  system pozwalający wiązać prawa własności i metadane z zasobami\ncyfrowymi. Jawna, kryptograficznie zabezpieczona, niezależna od żadnej\ninstytucji informacja o twórcy danej treści stanowi solidny fundament do budowy\nnarzędzi pozwalających automatycznie oceniać jakim zaufaniem możemy darzyć\nnewsy, które czytamy. Jeśli twórca ma nieposzlakowaną opinię i bez wykradzenia\njego kluczy prywatnych nie można się pod niego podszyć, należy założyć, że nie\nbędzie chciał zniszczyć sobie reputacji udostępniając nieprawdziwą wiadomość. Z\ndrugiej strony jeśli społeczność udowodni fałszywe wiadomości jakiemuś twórcy\ntreści, warto byłoby mieć możliwość prześledzenia argumentów obu stron bez\nkonieczności samodzielnego długiego ich wyszukiwania. Po.et nie udostępnia\njeszcze tych dodatkowych możliwości, które pomogły by zautomatyzować obronę\nprzez fake news i manipulacją, ale stanowi dobry fundament na którym tego typu\naplikacje będą mogły w przyszłości wyrastać.\n\nCivil - platforma dziennikarska z systemem reputacji\nCivil - należąca do społeczności sieć dziennikarska oparta o przejrzystość i\nzaufanie. Dzięki tej platformie można już teraz prowadzić dziennikarstwo oparte\no blockchain, które uwzględnia finansową zachętę dla osób sprawdzających\npoprawność faktów. Społeczny charakter sieci pozwala na uniezależnienia\nsprawdzania od jednej instytucji, a system reputacji dla osób sprawdzających\nfakty pozwala bronić się przed nadużyciami. Jest to model bardzo bliski temu\nopisanemu we wspomnianej wyżej pracy, z zastrzeżeniem, finansowego aspektu\nprzedsięwzięcia. Konsumenci treści produkowanych na Civil są obciążeni kosztem\ndostępu do nich. Stanowi to poważne ograniczenie, ponieważ jedynie nieznaczna\nczęść społeczeństwa jest chętna płacić za dostęp do cyfrowych newsów.\n\nOgólny wniosek jaki należałoby sformułować w kontekście wpływu blockchain na\nrynek mediów jest pozytywny. Wiele wskazuje na to, że zdecentralizowane,\nzalgorytmizowane sieci wykluczające możliwość cenzury, a z drugiej strony\npozwalające na prowadzenie przez społeczność śledztw i weryfikowania źródeł\ninformacji stanowią ważny brakujący element branży medialnej. Niepokoi jednak\naspekt prawny, ponieważ władza w każdej części świata boi się tego nad czym nie\nma kontroli i legalne istnienie takiej platformy może zostać zablokowane przez\nustawodawców pod pretekstem ochrony danych osobowych i sprzeczności z prawem do\nbycia zapomnianym, które obowiązuje na terenie Unii Europejskiej.\n\nUczenie maszynowe, Głębokie uczenie, Kognitywne obliczenia\nTrzy ostatnie technologię omówimy razem, ponieważ w potocznym języku i tak\nopisuje się wszystko jako sztuczną inteligencję, a w ścisłym znaczeniu dwie\nkolejne są po prostu wyspecjalizowanymi gałęziami bardzo szerokiego pojęcia\njakim jest uczenie maszynowe.\n\nUczenie maszynowe i sztuczna inteligencja mają bardzo szerokie zastosowania w\nogromnej ilości branż i to już od naprawdę długiego czasu. Co więc sprawia, że\nsą na tej liście? Postęp w możliwościach, które przed nimi stoją. Skupimy się na\ndetekcji fake-news oraz tworzeniu treści typu deepfake. Na koniec zarysujemy\nmożliwości, które mimo, że są wciąż poza zasięgiem będą naturalną konsekwencją\nrozwoju tej gałęzi technologii.\n\nDetekcja Fake News\nCały problem z fake news polega na tym, że jako wiadomość nieprawdziwa zwykle\nkłóci się z naszą racjonalną wizją świata. Ewolucja tak nas zaprojektowała, aby\nreagować silniej na te bodźce, które dotyczą zmiany, na przykład zmieniają nasze\npostrzeganie świata. Szok związany z czytaniem nie prawdy, zdziwienie,\nniedowierzanie powiązane są z reakcją taką jak napisanie komentarza, kliknięcie.\nZ drugiej strony wszelka aktywność związana z wiadomością jest automatycznie\npremiowana, ponieważ twórcy platform wychodzą z bądź co bądź racjonalnego\nzałożenia, że to co przyciąga użytkowników do ich platformy i wymusza na nich\noglądanie reklam powinno być wzmacniane. Nie dziwi zatem implementacja\nmechanizmów, które odpowiadają za priorytetyzację wyświetlania wiadomości treści\nkontrowersyjnych. Skoro zaś fake newsy są kontrowersyjne i powodują bardziej\naktywną interakcję użytkowników z tymi treściami, to wynikiem jest ich wirusowe\nrozprzestrzenianie.\n\nMimo to firmy takie jak Google i Facebook dostrzegając skalę problemu i\ndługofalowe skutki takiej sytuacji takie jak utrata zaufania użytkowników. Zdają\nsobie sprawę, że odchodzenie użytkowników w poszukiwania bardziej wiarygodnych\nźródeł informacji, da efekcie odpływ kapitału reklamodawców. Podjęły zatem walkę\nz fake news. Z jednej strony jest to współpraca z organizacjami\nwyspecjalizowanymi w sprawdzaniu wiarygodności informacji, z drugiej ułatwienie\nużytkownikom raportowania treści, które budzą podejrzenie prawdziwości, z\ntrzeciej automatyzacja i prace nad algorytmami które ułatwiłyby weryfikację i\nobniżyły jej koszty. W ten proces zaangażowały się również środowiska naukowe.\nSytuacja jest rozwojowa i należy spodziewać się, że platformy zaczną prowadzić\ncenzurę treści uznanych za fałszywe.\n\nTworzenie Deep Fake\nZ drugiej strony ta sama technologia uczenia maszynowego może być rozwijana nie\nw celu wykrywania, lecz w celu tworzenia zmanipulowanych wiadomości. Naśladując\nludzi sztuczna inteligencja może wytwarzać treści, a boty mające dostęp do\nserwisów społecznościowych mogą je tam rozpowszechniać. Przykład: niemal 20\nproc. tweetów związanych z wyborami w USA stworzyły\nboty\\cite{crazynauka_prawda}. Jednak to nic w porównaniu z technologią tworzenia\nbardzo realistycznie wyglądających video w których zarówno prezentowana osoba,\njak i jej głos mogą być dowolnie modelowane przez twórców. Jest ona\nwykorzystywana do prezentowania wiadomości w Chińskiej Republice Ludowej, a jej\nszeroko komentowana demonstracja dostępna jest pod linkiem.\n\nWycinek video na któym Jordan Peele prezentuje Deep Fake z prezydentem Obamą\nKontakt z deep fake może być bardzo trudny do odkręcenia, tym bardziej, że będą\none ewoluowały w stronę podniesienia siły oddziaływania poprzez korzystanie z\ntechnologii mieszanej rzeczywistości oraz z uwagi na sposób działania naszej\npamięci. Badania dowodzą, że nawet jeśli w danym momencie zdajemy sobie sprawę,\nże dany przekaz jest fałszywy, to w wyniku zapominania i zamazywania się\nwspomnień stopniowo tracimy tą informację, natomiast sam przekaz pamiętamy\nlepiej. Oznacza to, że po odpowiednim czasie możemy traktować go na równi z\ninnymi prawdziwymi informacjami przez co sama świadomość, że coś jest nie prawdą\nnie musi oznaczać, że fałszywa informacja nie wpłynie w przyszłości na nasze\nzachowanie.\n\nSztuczna inteligencja jako członek społeczeństwa, Interfejsy Mózg - Komputer,\nMózg - Mózg\nWybiegniemy teraz trochę w przyszłość. Ciężko powiedzieć jak odległą ponieważ\nzdania badaczy są podzielone, jednak zwykle mówi się o kilkudziesięciu latach.\nChodzi o moment, kiedy zatrze się granica między \"możliwościami obliczeniowymi\"\nmózgów biologicznych oraz cyfrowych. Będzie to oznaczać, że sztuczna\ninteligencja dorówna nam, a później przewyższy nas w możliwościach poznawania i\nanalizy rzeczywistości. Teraz traktujemy ją jako narzędzie do rozwiązywania\nproblemów, lecz może się okazać, że instancje sztucznej inteligencji staną się\nczłonkami naszego społeczeństwa, zaczną tworzyć własne treści tak jak to się\nrobi w dziennikarstwie obliczeniowym z tą różnicą, że bez kontroli człowieka.\nZaczną też czytać treści i interesować się własną edukacją i rozwojem.\n\nPrawdopodobnie nieco wcześniej rozwinie się technologia nazywana interfejsem\nmózg - komputer. Już teraz możemy komunikować się z komputerem za pomocą głosu,\nmyszki, klawiatury, ekranu, głośników i coraz bardziej wymyślnych akcesoriów.\nJednak nazwa “interfejs mózg - komputer” zarezerwowana jest dla bezpośredniej\nkomunikacji układów cyfrowych z ludzką myślą. Znane są przypadki takiej\nkomunikacji jak przekazywanie sygnałów między ludźmi z wszczepionymi chipami,\nadaptacja ludzkiego organizmu do korzystania z układu elektronicznego do\necholokacji. Z interfejsu mózg - komputer korzystają też osoby sparaliżowane,\nktóre mogą dzięki niemu pisać na klawiaturze odpowiednio koncentrując swoje\nmyśli. Ponieważ technologia ta się wciąż rozwija należy oczekiwać momentu, w\nktórym szybkość wprowadzania tekstu do komputera w ten sposób przekroczy tempo z\njakim ludzie potrafią pisać na klawiaturach. Jeśli jednak komputery mogą\nkomunikować się ze sobą za pomocą bardzo wydajnych protokołów, a prędkość\nwymiany myśli między maszyną a człowiekiem wzrośnie, to nic nie będzie stało na\nprzeszkodzie, aby takim elektronicznym mostkiem spiąć ze sobą dwa mózgi. Jeśli\ndwa, to dlaczego nie więcej. Jest więc duża szansa na to, że nasze mózgi dostaną\nmożliwość stania się cegiełkami budującymi większą sieć. Oczywistym jest, że tak\nogromna zmiana topologii przestrzeni, w której przepływają myśli i wiadomości\notworzy zupełnie inną perspektywę patrzenia na problem manipulacji medialnej.\n\nOcena wpływu technologii na kształt mediów w przyszłości.\nCzas zamknąć naszą niesamowitą podróż po świecie nowych technologii, ich wpływu\nna dziennikarstwo i futurystycznych wizji tego jak może on wyglądać w\nprzyszłości. Wszystkie podane powyżej technologie będą się rozwijać i to jak\nbędzie wyglądał świat za jakiś czas będzie nałożeniem się ich wszystkich.\n\nNie znam odpowiedzi na pytania o to, jaki dokładnie kształt przybierze rynek\nwydawniczy oraz czy i jak cywilizacja poradzi sobie z problemem fake news. Mogę\njednak zasugerować pewien sposób patrzenia, który uważam za cenny przy ocenie\ntakich rzeczy:\n\n * Po pierwsze należy się zastanowić kto i jaki interes ma w jakim stanie\n   rzeczy. Ile jest gotów w to zainwestować? Jakie zyski może z tego czerpać?\n * Po drugie należy rozważyć problem sprzecznych interesów w kategoriach teorii\n   gier i zapytać nie o strategię najlepszą dla uczestników gry, ale o strategię\n   ewolucyjnie stabilną, to znaczy taką, w której żadnemu z uczestników nie\n   będzie opłacało się zmieniać swojego zachowania.\n\nTym czasem dla nas na codzień najlepszym sposobem na korzystanie z mediów jest\nrobienie tego świadomie i poszerzanie swojej wiedzy dotyczącej kierujących nimi\nzasad.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-20T22:00:36.000Z",
            "updated_at": "2022-06-11T10:05:35.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60801d0b2fb35425592d0ce6",
            "uuid": "d2da7b3c-d041-41eb-9113-7ebf770019c0",
            "title": "Bot Telegramowy w Typescript",
            "slug": "bot-telegramowy-w-typescript",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"tsc --init\\nnpm init -y\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/mullwar/telebot\",\"metadata\":{\"url\":\"https://github.com/mullwar/telebot\",\"title\":\"mullwar/telebot\",\"description\":\"The easy way to write Telegram bots in Node.js. Contribute to mullwar/telebot development by creating an account on GitHub.\",\"author\":\"mullwar\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/28e2e0d632e6c5b5866fa981f2f368713cd217aeac325b6e15a0a50d59af327a/mullwar/telebot\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"code\",{\"code\":\"npm i telebot @types/telebot @types/node typescript ts-node\"}],[\"code\",{\"code\":\"\\\"target\\\": \\\"ESNEXT\\\",\\n\\\"moduleResolution\\\": \\\"node\\\",\\n\\\"allowSyntheticDefaultImports\\\": true,\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-21-22-23-23.png\",\"width\":586,\"height\":815}],[\"code\",{\"code\":\"TELEGRAM_TOKEN=xxx\"}],[\"code\",{\"code\":\"    \\\"start\\\": \\\"ts-node index.ts\\\",\\n\"}],[\"code\",{\"code\":\"include .env\\nexport\\n\\nnode_modules: package.json\\n\\tnpm i\\n\\nup: node_modules\\n\\tnpm run start\"}],[\"code\",{\"code\":\"import TeleBot from \\\"telebot\\\"\\n\\nconst bot = new TeleBot({\\n    token: process.env.TELEGRAM_TOKEN || '',\\n});\\n\\nbot.on([\\\"/configure_bot\\\"], (msg) => {\\n    console.log(msg);\\n    bot.sendMessage(msg.chat.id, `CHAT_ID: ${msg.chat.id}`);\\n});\\n\\nbot.start();\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-21-22-39-45.png\",\"width\":590,\"height\":129}],[\"code\",{\"code\":\"GROUP_LOG_ID=-506870285\"}],[\"code\",{\"code\":\"setInterval(() => {\\n    const rand = Math.random();\\n    if (rand > .5) {\\n        bot.sendMessage(parseInt(process.env.GROUP_LOG_ID || ''), `${rand}`)\\n    }\\n}, 1000)\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-21-22-48-26.png\",\"width\":299,\"height\":477}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Jeden z projektów, które wypuściliśmy w tamtym miesiącu używał Telegrama do wysyłania powiadomień. Wpis pokaże Ci jak skonfigurować wysyłkę powiadomień od zera używając \"],[0,[0],1,\"typescript\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Przygotowanie środowiska\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od przygotowania plików konfiguracyjnych:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Instalujemy \"],[0,[0],1,\"telebot\"],[0,[],0,\" - paczkę zapewniającą SDK telegrama. Jej dokumentacja znajduje się tutaj:\"]]],[10,1],[1,\"p\",[[0,[],0,\"razem z nią instalujemy niezbędny zestaw bibliotek do \"],[0,[0],1,\"typescript\"],[0,[],0,\":\"]]],[10,2],[1,\"p\",[[0,[],0,\"W pliku \"],[0,[0],1,\"tsconfig.json\"],[0,[],0,\" nadpisujemy następujące opcje:\"]]],[10,3],[1,\"h2\",[[0,[],0,\"Uzyskanie TOKENU API\"]]],[1,\"p\",[[0,[],0,\"Aby móc korzystać z API będziemy potrzebowali tokenu. Najprostszym sposobem jego uzyskania jest napisanie na telegramie do bota tworzącego boty. Jest to \"],[0,[0],1,\"BotFather\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Cała konwersacja polega na tym, że podajemy komendę tworzącą bota, jego \"],[0,[0],1,\"name\"],[0,[],0,\", \"],[0,[0],1,\"username\"],[0,[],0,\" i dostajemy token. \"]]],[10,4],[1,\"h2\",[[0,[],0,\"Dołączenie tokenu do projektu\"]]],[1,\"p\",[[0,[],0,\"Zalecam dodanie \"],[0,[0],1,\"TELEGRAM_TOKEN\"],[0,[],0,\" z tą wartością do pliku \"],[0,[0],1,\".env\"],[0,[],0,\" np\"]]],[10,5],[1,\"p\",[[0,[],0,\"W \"],[0,[0],1,\"package.json\"],[0,[],0,\" dołączamy linię \"]]],[10,6],[1,\"p\",[[0,[],0,\"wewnątrz \"],[0,[0],1,\"scripts\"],[0,[],0,\". Tworzymy plik \"],[0,[0],1,\"Makefile\"]]],[10,7],[1,\"p\",[[0,[],0,\"dzięki niemu automatycznie importujemy \"],[0,[0],1,\".env\"],[0,[],0,\" i nie musimy używać flag z linii komend ani paczek takich jak \"],[0,[0],1,\"dotenv\"],[0,[],0,\". Nie zapomnijmy dodać \"],[0,[0],1,\".env\"],[0,[],0,\" do \"],[0,[0],1,\".gitignore\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Kod do uzyskania ID chatu\"]]],[1,\"p\",[[0,[],0,\"Jeśli chcemy, żeby nasz bot odpowiadał wystarczy w pliku \"],[0,[0],1,\"index.ts\"],[0,[],0,\" napisać kod:\"]]],[10,8],[1,\"p\",[[0,[],0,\"Następnie dołączyć bota do chatu i napisać do niego. Wynik będzie następujący:\"]]],[10,9],[1,\"p\",[[0,[],0,\"Identyfikator chatu jest kluczową informacją, jeśli chcemy wysyłać do niego powiadomienia. ID chatu i Token to kluczowe informacje mówiące jaki bot i gdzie pisze. W naszym przypadku bot był ustawiony tak, żeby różne dane wysyłać na różne grupy więc musieliśmy powtórzyć to polecenie dla kliku grup i zanotować je w pliku \"],[0,[0],1,\".env\"],[0,[],0,\". Do \"],[0,[0],1,\".env\"],[0,[],0,\" dopisujemy linię\"]]],[10,10],[1,\"h2\",[[0,[],0,\"Wysyłka sygnałów\"]]],[1,\"p\",[[0,[],0,\"Będziemy co sekundę wysyłać do kanału losową liczbę jeśli będzie większa niż 0.5. Wystarcz do tego kod\"]]],[10,11],[10,12],[1,\"p\",[[0,[],0,\"To był bardzo prosty kod i bardzo prosty bot. Z takimi botami można robić praktyczne rzeczy. Np:\"]]],[3,\"ul\",[[[0,[],0,\"Budować tekstowy interfejs do zdalnej konfiguracji systemu. Takie CLI jest tańsze niż podłączanie frontendu, formularzy i przycisków. \"]],[[0,[],0,\"Budować systemy powiadamiające o zdarzeniach. Jest to łatwiejsze niż wysyłka SMS, czy Emaili do których wymagani (albo zalecani) są zewnętrzni dostawcy. W telegramie ominęliśmy problem płatności za wiadomości, a grupy mogą mieścić setki tysięcy członków.\"]]]],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Jeden z projektów, które wypuściliśmy w tamtym miesiącu używał Telegrama do wysyłania powiadomień. Wpis pokaże Ci jak skonfigurować wysyłkę powiadomień od zera używając <code>typescript</code>.</p><h2 id=\"przygotowanie-%C5%9Brodowiska\">Przygotowanie środowiska</h2><p>Zaczniemy od przygotowania plików konfiguracyjnych:</p><pre><code>tsc --init\nnpm init -y</code></pre><p>Instalujemy <code>telebot</code> - paczkę zapewniającą SDK telegrama. Jej dokumentacja znajduje się tutaj:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/mullwar/telebot\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">mullwar/telebot</div><div class=\"kg-bookmark-description\">The easy way to write Telegram bots in Node.js. Contribute to mullwar/telebot development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">mullwar</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/28e2e0d632e6c5b5866fa981f2f368713cd217aeac325b6e15a0a50d59af327a/mullwar/telebot\"></div></a></figure><p>razem z nią instalujemy niezbędny zestaw bibliotek do <code>typescript</code>:</p><pre><code>npm i telebot @types/telebot @types/node typescript ts-node</code></pre><p>W pliku <code>tsconfig.json</code> nadpisujemy następujące opcje:</p><pre><code>\"target\": \"ESNEXT\",\n\"moduleResolution\": \"node\",\n\"allowSyntheticDefaultImports\": true,</code></pre><h2 id=\"uzyskanie-tokenu-api\">Uzyskanie TOKENU API</h2><p>Aby móc korzystać z API będziemy potrzebowali tokenu. Najprostszym sposobem jego uzyskania jest napisanie na telegramie do bota tworzącego boty. Jest to <code>BotFather</code>.</p><p>Cała konwersacja polega na tym, że podajemy komendę tworzącą bota, jego <code>name</code>, <code>username</code> i dostajemy token. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-21-22-23-23.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"586\" height=\"815\"></figure><h2 id=\"do%C5%82%C4%85czenie-tokenu-do-projektu\">Dołączenie tokenu do projektu</h2><p>Zalecam dodanie <code>TELEGRAM_TOKEN</code> z tą wartością do pliku <code>.env</code> np</p><pre><code>TELEGRAM_TOKEN=xxx</code></pre><p>W <code>package.json</code> dołączamy linię </p><pre><code>    \"start\": \"ts-node index.ts\",\n</code></pre><p>wewnątrz <code>scripts</code>. Tworzymy plik <code>Makefile</code></p><pre><code>include .env\nexport\n\nnode_modules: package.json\n\tnpm i\n\nup: node_modules\n\tnpm run start</code></pre><p>dzięki niemu automatycznie importujemy <code>.env</code> i nie musimy używać flag z linii komend ani paczek takich jak <code>dotenv</code>. Nie zapomnijmy dodać <code>.env</code> do <code>.gitignore</code>.</p><h2 id=\"kod-do-uzyskania-id-chatu\">Kod do uzyskania ID chatu</h2><p>Jeśli chcemy, żeby nasz bot odpowiadał wystarczy w pliku <code>index.ts</code> napisać kod:</p><pre><code>import TeleBot from \"telebot\"\n\nconst bot = new TeleBot({\n    token: process.env.TELEGRAM_TOKEN || '',\n});\n\nbot.on([\"/configure_bot\"], (msg) =&gt; {\n    console.log(msg);\n    bot.sendMessage(msg.chat.id, `CHAT_ID: ${msg.chat.id}`);\n});\n\nbot.start();</code></pre><p>Następnie dołączyć bota do chatu i napisać do niego. Wynik będzie następujący:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-21-22-39-45.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"590\" height=\"129\"></figure><p>Identyfikator chatu jest kluczową informacją, jeśli chcemy wysyłać do niego powiadomienia. ID chatu i Token to kluczowe informacje mówiące jaki bot i gdzie pisze. W naszym przypadku bot był ustawiony tak, żeby różne dane wysyłać na różne grupy więc musieliśmy powtórzyć to polecenie dla kliku grup i zanotować je w pliku <code>.env</code>. Do <code>.env</code> dopisujemy linię</p><pre><code>GROUP_LOG_ID=-506870285</code></pre><h2 id=\"wysy%C5%82ka-sygna%C5%82%C3%B3w\">Wysyłka sygnałów</h2><p>Będziemy co sekundę wysyłać do kanału losową liczbę jeśli będzie większa niż 0.5. Wystarcz do tego kod</p><pre><code>setInterval(() =&gt; {\n    const rand = Math.random();\n    if (rand &gt; .5) {\n        bot.sendMessage(parseInt(process.env.GROUP_LOG_ID || ''), `${rand}`)\n    }\n}, 1000)</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-21-22-48-26.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"299\" height=\"477\"></figure><p>To był bardzo prosty kod i bardzo prosty bot. Z takimi botami można robić praktyczne rzeczy. Np:</p><ul><li>Budować tekstowy interfejs do zdalnej konfiguracji systemu. Takie CLI jest tańsze niż podłączanie frontendu, formularzy i przycisków. </li><li>Budować systemy powiadamiające o zdarzeniach. Jest to łatwiejsze niż wysyłka SMS, czy Emaili do których wymagani (albo zalecani) są zewnętrzni dostawcy. W telegramie ominęliśmy problem płatności za wiadomości, a grupy mogą mieścić setki tysięcy członków.</li></ul><p></p>",
            "comment_id": "60801d0b2fb35425592d0ce6",
            "plaintext": "Jeden z projektów, które wypuściliśmy w tamtym miesiącu używał Telegrama do\nwysyłania powiadomień. Wpis pokaże Ci jak skonfigurować wysyłkę powiadomień od\nzera używając typescript.\n\nPrzygotowanie środowiska\nZaczniemy od przygotowania plików konfiguracyjnych:\n\ntsc --init\nnpm init -y\n\nInstalujemy telebot - paczkę zapewniającą SDK telegrama. Jej dokumentacja\nznajduje się tutaj:\n\nmullwar/telebotThe easy way to write Telegram bots in Node.js. Contribute to\nmullwar/telebot development by creating an account on GitHub.GitHubmullwar\n[https://github.com/mullwar/telebot]razem z nią instalujemy niezbędny zestaw\nbibliotek do typescript:\n\nnpm i telebot @types/telebot @types/node typescript ts-node\n\nW pliku tsconfig.json nadpisujemy następujące opcje:\n\n\"target\": \"ESNEXT\",\n\"moduleResolution\": \"node\",\n\"allowSyntheticDefaultImports\": true,\n\nUzyskanie TOKENU API\nAby móc korzystać z API będziemy potrzebowali tokenu. Najprostszym sposobem jego\nuzyskania jest napisanie na telegramie do bota tworzącego boty. Jest to \nBotFather.\n\nCała konwersacja polega na tym, że podajemy komendę tworzącą bota, jego name, \nusername i dostajemy token. \n\nDołączenie tokenu do projektu\nZalecam dodanie TELEGRAM_TOKEN z tą wartością do pliku .env np\n\nTELEGRAM_TOKEN=xxx\n\nW package.json dołączamy linię \n\n    \"start\": \"ts-node index.ts\",\n\n\nwewnątrz scripts. Tworzymy plik Makefile\n\ninclude .env\nexport\n\nnode_modules: package.json\n\tnpm i\n\nup: node_modules\n\tnpm run start\n\ndzięki niemu automatycznie importujemy .env i nie musimy używać flag z linii\nkomend ani paczek takich jak dotenv. Nie zapomnijmy dodać .env do .gitignore.\n\nKod do uzyskania ID chatu\nJeśli chcemy, żeby nasz bot odpowiadał wystarczy w pliku index.ts napisać kod:\n\nimport TeleBot from \"telebot\"\n\nconst bot = new TeleBot({\n    token: process.env.TELEGRAM_TOKEN || '',\n});\n\nbot.on([\"/configure_bot\"], (msg) => {\n    console.log(msg);\n    bot.sendMessage(msg.chat.id, `CHAT_ID: ${msg.chat.id}`);\n});\n\nbot.start();\n\nNastępnie dołączyć bota do chatu i napisać do niego. Wynik będzie następujący:\n\nIdentyfikator chatu jest kluczową informacją, jeśli chcemy wysyłać do niego\npowiadomienia. ID chatu i Token to kluczowe informacje mówiące jaki bot i gdzie\npisze. W naszym przypadku bot był ustawiony tak, żeby różne dane wysyłać na\nróżne grupy więc musieliśmy powtórzyć to polecenie dla kliku grup i zanotować je\nw pliku .env. Do .env dopisujemy linię\n\nGROUP_LOG_ID=-506870285\n\nWysyłka sygnałów\nBędziemy co sekundę wysyłać do kanału losową liczbę jeśli będzie większa niż\n0.5. Wystarcz do tego kod\n\nsetInterval(() => {\n    const rand = Math.random();\n    if (rand > .5) {\n        bot.sendMessage(parseInt(process.env.GROUP_LOG_ID || ''), `${rand}`)\n    }\n}, 1000)\n\nTo był bardzo prosty kod i bardzo prosty bot. Z takimi botami można robić\npraktyczne rzeczy. Np:\n\n * Budować tekstowy interfejs do zdalnej konfiguracji systemu. Takie CLI jest\n   tańsze niż podłączanie frontendu, formularzy i przycisków. \n * Budować systemy powiadamiające o zdarzeniach. Jest to łatwiejsze niż wysyłka\n   SMS, czy Emaili do których wymagani (albo zalecani) są zewnętrzni dostawcy. W\n   telegramie ominęliśmy problem płatności za wiadomości, a grupy mogą mieścić\n   setki tysięcy członków.",
            "feature_image": "__GHOST_URL__/content/images/2021/04/telegram.svg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-21T12:39:39.000Z",
            "updated_at": "2021-05-24T11:06:00.000Z",
            "published_at": "2021-05-24T11:06:00.000Z",
            "custom_excerpt": "Dowiedz się jak stworzyć bota na telegramie, dodać w nim nasłuch na komendy oraz skonfigurować wysyłanie powiadomień.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "608173b82fb35425592d0d66",
            "uuid": "2fb927a2-f216-425e-98fd-323ac3c57476",
            "title": "Konsolowy CRM z Prisma i MongoDB",
            "slug": "mongo-prisma",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"npm install -D prisma typescript ts-node @types/node jest ts-jest @types/jest\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.notion.so/Getting-Started-with-MongoDB-and-Prisma-58b41c67eb554787944c600d2239801f\",\"metadata\":{\"url\":\"https://www.notion.so\",\"title\":\"Notion – The all-in-one workspace for your notes, tasks, wikis, and databases.\",\"description\":\"A new tool that blends your everyday work apps into one. It’s the all-in-one workspace for you and your team\",\"author\":null,\"publisher\":\"Notion\",\"thumbnail\":\"https://www.notion.so/images/meta/default.png\",\"icon\":\"https://www.notion.so/images/logo-ios.png\"}}]],\"markups\":[[\"a\",[\"href\",\"https://www.notion.so/Getting-Started-with-MongoDB-and-Prisma-58b41c67eb554787944c600d2239801f\"]],[\"a\",[\"href\",\"https://gautamsi.medium.com/mongodb-provider-for-prisma-2-and-keystone-next-1618418c8937\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"18 kwietnia 2021 została \"]]],[10,0],[1,\"p\",[]],[1,\"p\",[]],[10,1],[1,\"p\",[[0,[0],1,\"https://www.notion.so/Getting-Started-with-MongoDB-and-Prisma-58b41c67eb554787944c600d2239801f\"]]],[1,\"p\",[]],[1,\"p\",[[0,[1],1,\"https://gautamsi.medium.com/mongodb-provider-for-prisma-2-and-keystone-next-1618418c8937\"]]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>18 kwietnia 2021 została </p><pre><code>npm install -D prisma typescript ts-node @types/node jest ts-jest @types/jest</code></pre><p></p><p></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.notion.so/Getting-Started-with-MongoDB-and-Prisma-58b41c67eb554787944c600d2239801f\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Notion – The all-in-one workspace for your notes, tasks, wikis, and databases.</div><div class=\"kg-bookmark-description\">A new tool that blends your everyday work apps into one. It’s the all-in-one workspace for you and your team</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.notion.so/images/logo-ios.png\"><span class=\"kg-bookmark-author\">Notion</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.notion.so/images/meta/default.png\"></div></a></figure><p><a href=\"https://www.notion.so/Getting-Started-with-MongoDB-and-Prisma-58b41c67eb554787944c600d2239801f\">https://www.notion.so/Getting-Started-with-MongoDB-and-Prisma-58b41c67eb554787944c600d2239801f</a></p><p></p><p><a href=\"https://gautamsi.medium.com/mongodb-provider-for-prisma-2-and-keystone-next-1618418c8937\">https://gautamsi.medium.com/mongodb-provider-for-prisma-2-and-keystone-next-1618418c8937</a></p>",
            "comment_id": "608173b82fb35425592d0d66",
            "plaintext": "18 kwietnia 2021 została \n\nnpm install -D prisma typescript ts-node @types/node jest ts-jest @types/jest\n\n\n\n\n\nNotion – The all-in-one workspace for your notes, tasks, wikis, and databases.A\nnew tool that blends your everyday work apps into one. It’s the all-in-one\nworkspace for you and your teamNotion\n[https://www.notion.so/Getting-Started-with-MongoDB-and-Prisma-58b41c67eb554787944c600d2239801f]\nhttps://www.notion.so/Getting-Started-with-MongoDB-and-Prisma-58b41c67eb554787944c600d2239801f\n\n\n\nhttps://gautamsi.medium.com/mongodb-provider-for-prisma-2-and-keystone-next-1618418c8937",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-22T13:01:44.000Z",
            "updated_at": "2021-06-25T18:28:28.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "608718422fb35425592d0da6",
            "uuid": "1d6da099-93cb-4a66-afdd-5656937cdf95",
            "title": "Continuous Delivery w Gitlab Ci (Docker in Docker)",
            "slug": "continous-delivery-w-gitlab-ci-docker-in-docker",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/EUO5sFpWoAMaecY.jpg\",\"width\":1200,\"height\":902}],[\"code\",{\"code\":\"make up - podnoszenie wszystkich serwisów do developowania\\nmake deploy - umieszczenie projektu na serwerze\\nmake t - wykonanie testów automatycznych\\nmake ssh - zalogowanie na serwer powiązany z tym projektem\"}],[\"code\",{\"code\":\"ssh-keygen -t ed25519 -f ~/.ssh/ci -q -N \\\"\\\"\"}],[\"code\",{\"code\":\"~/.ssh/ci\"}],[\"code\",{\"code\":\"~/.ssh/ci.pub\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-14-14-01.png\",\"width\":716,\"height\":544}],[\"code\",{\"code\":\"cat ~/.ssh/ci | base64 -w0 \"}],[\"code\",{\"code\":\" cat ~/.ssh/ci | base64 -w0 | base64 -d\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-30-21.png\",\"width\":1161,\"height\":226}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-38-08.png\",\"width\":1118,\"height\":821}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-42-36.png\",\"width\":742,\"height\":537}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-45-02.png\",\"width\":822,\"height\":146}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/protected_branches_page_v12_3.png\",\"width\":855,\"height\":458}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://docs.gitlab.com/ee/user/project/protected_branches.html\",\"metadata\":{\"url\":\"https://docs.gitlab.com/ee/user/project/protected_branches.html\",\"title\":\"Protected branches | GitLab\",\"description\":\"Documentation for GitLab Community Edition, GitLab Enterprise Edition, Omnibus GitLab, and GitLab Runner.\",\"author\":null,\"publisher\":\"GitLab Docs\",\"thumbnail\":\"https://docs.gitlab.com/assets/images/gitlab-logo.svg\",\"icon\":\"https://docs.gitlab.com/assets/images/apple-touch-icon.png\"}}],[\"code\",{\"code\":\"variables:\\n  DOCKER_REGISTRY_DOMAIN: \\\"registry.digitalocean.com\\\"\\n  DOCKER_HOST: tcp://docker:2375\\n  DOCKER_TLS_CERTDIR: \\\"\\\"\\n  DOCKER_DRIVER: overlay2\\n\\nimage: docker:latest\\n\\nservices:\\n  - docker:dind\\n\\n.deploy:\\n  image: archlinux:latest\\n  stage: deploy\\n  before_script:\\n    - pacman -Sy make ansible python python-pip openssh docker --noconfirm\\n    - docker login -u ${DOCKER_TOKEN} -p ${DOCKER_TOKEN} ${DOCKER_REGISTRY_DOMAIN}\\n    - pip3 install docker docker-compose\\n    - eval $(ssh-agent -s)\\n    - ssh-add <(echo \\\"$SSH_PRIVATE_KEY_BASE64 | base64 -d\\\")\\n    - mkdir -p ~/.ssh\\n    - '[[ -f /.dockerenv ]] && echo -e \\\"Host *\\\\n\\\\tStrictHostKeyChecking no\\\\n\\\\n\\\" > ~/.ssh/config'\\n  script:\\n    - ENV=${ENV} make deploy\\n\\nprod:\\n  extends: .deploy\\n  variables:\\n    ENV: prod\\n  only:\\n    refs:\\n      - prod\\n\\nstag:\\n  extends: .deploy\\n  variables:\\n    ENV: stag\\n  only:\\n    refs:\\n      - stag\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://docs.gitlab.com/runner/executors/\",\"metadata\":{\"url\":\"https://docs.gitlab.com/runner/executors/\",\"title\":\"Executors | GitLab\",\"description\":\"Documentation for GitLab Community Edition, GitLab Enterprise Edition, Omnibus GitLab, and GitLab Runner.\",\"author\":null,\"publisher\":\"GitLab Docs\",\"thumbnail\":\"https://docs.gitlab.com/assets/images/gitlab-logo.svg\",\"icon\":\"https://docs.gitlab.com/assets/images/apple-touch-icon.png\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.testcontainers.org/supported_docker_environment/continuous_integration/gitlab_ci/\",\"metadata\":{\"url\":\"https://www.testcontainers.org/supported_docker_environment/continuous_integration/gitlab_ci/\",\"title\":\"GitLab CI - Testcontainers\",\"description\":null,\"author\":null,\"publisher\":\"Testcontainers\",\"thumbnail\":\"https://d33wubrfki0l68.cloudfront.net/13c9a4b570398ec611da4ec48085caaa48c5f2d2/39fb0/logo.svg\",\"icon\":\"https://www.testcontainers.org/favicon.ico\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#use-docker-in-docker-workflow-with-docker-executor\",\"metadata\":{\"url\":\"https://docs.gitlab.com/ee/ci/docker/using_docker_build.html\",\"title\":\"Use Docker to build Docker images | GitLab\",\"description\":\"Documentation for GitLab Community Edition, GitLab Enterprise Edition, Omnibus GitLab, and GitLab Runner.\",\"author\":null,\"publisher\":\"GitLab Docs\",\"thumbnail\":\"https://docs.gitlab.com/assets/images/gitlab-logo.svg\",\"icon\":\"https://docs.gitlab.com/assets/images/apple-touch-icon.png\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://docs.docker.com/storage/storagedriver/overlayfs-driver/\",\"metadata\":{\"url\":\"https://docs.docker.com/storage/storagedriver/overlayfs-driver/\",\"title\":\"Use the OverlayFS storage driver\",\"description\":\"Learn how to optimize your use of OverlayFS driver.\",\"author\":null,\"publisher\":\"Docker Documentation\",\"thumbnail\":\"https://docs.docker.com/favicons/docs@2x.ico\",\"icon\":\"https://docs.docker.com/favicons/docs@2x.ico\"}}],[\"code\",{\"code\":\"image: docker:latest\"}],[\"code\",{\"code\":\"services:\\n  - docker:dind\\n\"}],[\"code\",{\"code\":\"prod:\\n  extends: .deploy\\n  variables:\\n    ENV: prod\\n  only:\\n    refs:\\n      - prod\\n\\nstag:\\n  extends: .deploy\\n  variables:\\n    ENV: stag\\n  only:\\n    refs:\\n      - stag\"}],[\"code\",{\"code\":\".deploy:\\n  image: archlinux:latest\\n  stage: deploy\\n  before_script:\\n    - pacman -Sy make ansible python python-pip openssh docker --noconfirm\\n#    - docker login\\n    - docker login -u ${DOCKER_TOKEN} -p ${DOCKER_TOKEN} ${DOCKER_REGISTRY_DOMAIN}\\n    - pip3 install docker docker-compose\\n    - eval $(ssh-agent -s)\\n    - ssh-add <(echo ${SSH_PRIVATE_KEY_BASE64} | base64 -d)\\n    - mkdir -p ~/.ssh\\n    - '[[ -f /.dockerenv ]] && echo -e \\\"Host *\\\\n\\\\tStrictHostKeyChecking no\\\\n\\\\n\\\" > ~/.ssh/config'\\n  script:\\n    - ENV=${ENV} make deploy\"}],[\"code\",{\"code\":\"  stage: deploy\"}],[\"code\",{\"code\":\"- pacman -Sy make ansible python python-pip openssh docker --noconfirm\\n\"}],[\"code\",{\"code\":\"- docker login -u ${DOCKER_TOKEN} -p ${DOCKER_TOKEN} ${DOCKER_REGISTRY_DOMAIN}\"}],[\"code\",{\"code\":\"- pip3 install docker docker-compose\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://stackoverflow.com/questions/59384708/ansible-returns-with-failed-to-import-the-required-python-library-docker-sdk-f/65495769#65495769\",\"metadata\":{\"url\":\"https://stackoverflow.com/questions/59384708/ansible-returns-with-failed-to-import-the-required-python-library-docker-sdk-f\",\"title\":\"ansible returns with “Failed to import the required Python library (Docker SDK for Python: docker (Python >= 2.7) or docker-py (Python 2.6))\",\"description\":\"I am running myserver in ubuntu: + sudo cat /etc/os-release\\nNAME=“Ubuntu”\\nVERSION=“16.04.6 LTS (Xenial Xerus)”\\nID=ubuntu\\nID_LIKE=debian\\nPRETTY_NAME=“Ubuntu 16.04.6 LTS”\\nVERSION_ID=“16.04″\\nHOME_URL...\",\"author\":\"Learner\",\"publisher\":\"Stack Overflow\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded\",\"icon\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://docs.ansible.com/ansible/latest/collections/community/docker/docker_compose_module.html#ansible-collections-community-docker-docker-compose-module\",\"metadata\":{\"url\":\"https://docs.ansible.com/ansible/latest/collections/community/docker/docker_compose_module.html\",\"title\":\"community.docker.docker_compose – Manage multi-container Docker applications with Docker Compose. — Ansible Documentation\",\"description\":null,\"author\":null,\"publisher\":null,\"thumbnail\":\"https://docs.ansible.com/ansible/latest/_static/images/logo_invert.png\",\"icon\":null}}],[\"code\",{\"code\":\"eval $(ssh-agent -s)\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://superuser.com/questions/284374/ssh-keys-ssh-agent-bash-and-ssh-add\",\"metadata\":{\"url\":\"https://superuser.com/questions/284374/ssh-keys-ssh-agent-bash-and-ssh-add\",\"title\":\"ssh keys ssh-agent bash and ssh-add\",\"description\":\"I am new to ssh keys. Can anyone explain how the ssh-agent bash and ssh-add works? I need to understand its internals in future.\",\"author\":\"maneeshshetty\",\"publisher\":\"Super User\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon@2.png?v=e869e4459439\",\"icon\":\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon.png?v=0ad5b7a83e49\"}}],[\"code\",{\"code\":\"- ssh-add <(echo ${SSH_PRIVATE_KEY_BASE64} | base64 -d)\"}],[\"code\",{\"code\":\"- mkdir -p ~/.ssh\\n- '[[ -f /.dockerenv ]] && echo -e \\\"Host *\\\\n\\\\tStrictHostKeyChecking no\\\\n\\\\n\\\" > ~/.ssh/config'\"}],[\"code\",{\"code\":\"  script:\\n    - ENV=${ENV} make deploy\"}],[\"code\",{\"code\":\"include .env\\nexport\\n\\nnode_modules: package.json\\n\\tnpm i\\n\\nup: node_modules\\n\\tnpm run start\\n\\nt:\\n\\tnpm test\\n\\ngenerate:\\n\\tnpx prisma generate\\n\\n.ONESHELL:\\ndeploy:\\n\\tif [ ! -e \\\"hosts.$(ENV)\\\" ]; then printf \\\"Use ENV=stag or ENV=prod before make deploy\\\\n\\\" && exit ; fi;\\n\\tansible-playbook -i hosts.$(ENV) deploy.yml\\n\\nclean:\\n\\trm index.js helpers/*.js interfaces/*.js test/*.js signals/*.js\"}],[\"code\",{\"code\":\"[local]\\n127.0.0.1 env=prod\\n\\n[api]\\n134.xxx.xxx.149 ansible_user=root env=prod\"}],[\"code\",{\"code\":\"[local]\\n127.0.0.1 env=stag\\n\\n[api]\\n134.yyy.yyy.149  ansible_user=root env=stag\"}],[\"code\",{\"code\":\"---\\n- name: Merge Env\\n  hosts: local\\n  connection: local\\n  tags:\\n    - deploy\\n  tasks:\\n    - name: Prepare env\\n      shell: \\\"sort -u -t '=' -k 1,1 .env.{{env}} .env > .env.{{env}}.build\\\"\\n- name: Build Backend\\n  hosts: local\\n  connection: local\\n  tags:\\n    - build\\n  tasks:\\n    - name: Build Image\\n      community.general.docker_image:\\n        build:\\n          path: .\\n          pull: no\\n        name: registry.digitalocean.com/main/telegram.ts\\n        push: true\\n        source: build\\n        force_source: yes\\n      environment:\\n        DOCKER_BUILDKIT: 1\\n- name: Deploy Backend\\n  hosts: api\\n  tags:\\n    - deploy\\n  vars:\\n    path: /root/telegram.ts\\n  tasks:\\n    - name: Creates directory\\n      file:\\n        path: \\\"{{ path }}\\\"\\n        state: directory\\n    - name: Copy Docker Compose\\n      copy:\\n        src: docker-compose.yml\\n        dest: \\\"{{ path }}/docker-compose.yml\\\"\\n    - name: Copy .env\\n      copy:\\n        src: \\\"./.env.{{ env }}.build\\\"\\n        dest: \\\"{{ path }}/.env\\\"\\n    - name: Reload Compose\\n      community.general.docker_compose:\\n        pull: yes\\n        project_src: \\\"{{ path }}\\\"\"}],[\"code\",{\"code\":\"- name: Merge Env\\n  hosts: local\\n  connection: local\\n  tags:\\n    - deploy\\n  tasks:\\n    - name: Prepare env\\n      shell: \\\"sort -u -t '=' -k 1,1 .env.{{env}} .env > .env.{{env}}.build\\\"\\n\"}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Skrót CI/CD - ciągła integracja i ciągłe dostarczanie oznaczają, że zamiast manualnego wdrażania systemu na serwer zmiana kodu źródłowego powoduje wykonanie się testów automatycznych i aktualizację systemu na serwerze.\"]]],[1,\"p\",[[0,[],0,\"W artykule opiszę korzyści z implementacji tego podejścia oraz konfigurację, której używam w swojej organizacji. Mam nadzieję, że będzie mogła ona posłużyć komuś jako wzór. Być może dzięki waszym komentarzom będę w stanie ją ulepszyć.\"]]],[10,0],[1,\"h2\",[[0,[],0,\"Wartość biznesowa CI/CD\"]]],[1,\"p\",[[0,[],0,\"Ten proces ma wiele korzyści. Są to:\"]]],[3,\"ul\",[[[0,[],0,\"obniżenie kosztu deploymentu [ automatyzacja ]\"]],[[0,[],0,\"podniesienie bezpieczeństwa wdrożeń [ uprawnienia ]\"]],[[0,[],0,\"formalizacja procesu [ testy automatyczne, kopie zapasowe ]\"]],[[0,[],0,\"wgląd do logów z wdrożeń [ kto, kiedy, co i gdzie wdrożył ]\"]]]],[1,\"h3\",[[0,[],0,\"Koszty\"]]],[1,\"p\",[[0,[],0,\"Wdrożenie aktualizacji systemu na serwer może zajmować od kilku sekund do kilkudziesięciu minut. Zwykle główną część czasu zajmuje kompilacja lub budowanie kodu wynikowego ze źródeł projektu. Często obok samego kodu projektu, należy zaktualizować zmienne środowiskowe, przeinstalować nowe wersje zależnych paczek, wykonać migrację bazy danych, postawić nowe serwisy, a czasem nawet nowe serwery.\"]]],[1,\"p\",[[0,[],0,\"Najszybsze w realizacji, ale najdroższe w utrzymaniu jest manualne wykonywanie tych czynności. Rodzi to też ryzyko błędu ludzkiego.\"]]],[1,\"p\",[[0,[],0,\"Tańszym w utrzymaniu jest napisanie do tego skryptów, albo konfiguracji i wykonywanie jednego polecenia, aby przeprowadzić pełny deployment.\"]]],[1,\"p\",[[0,[],0,\"Najlepszym rozwiązaniem jest CI/CD czyli takie skonfigurowanie systemu, żeby od początku każda zmiana w kodzie załączona w odpowiedniej gałęzi repozytorium powodowała zbudowanie systemu i jego instalację na serwerze.\"]]],[1,\"p\",[[0,[],0,\"Wówczas koszty na DevOps ograniczają się do konfigurowania systemu i nie narastają wraz z intensyfikacją częstotliwości wypuszczania poprawek i nowych wersji.\"]]],[1,\"h3\",[[0,[],0,\"Bezpieczeństwo\"]]],[1,\"p\",[[0,[],0,\"Kiedy pracowałem jako freelancer, jednocześnie pisałem kod i miałem dostęp do danych produkcyjnych. Samodzielne robienie wdrożenia było naturalne. Nie było w tym nic dziwnego, że miałem klucze do wszystkich serwerów.\"]]],[1,\"p\",[[0,[],0,\"Jeśli w projekcie pracuje kilka osób i każda z nich, żeby wdrożyć poprawki potrzebuje dostępu do serwera, rodzi to pewne problemy. Trudniejszy staje się zarówno proces nadawania uprawnień jak i ich kontroli.\"]]],[1,\"p\",[[0,[],0,\"Bez dawania dostępu wszystkim do wszystkiego mamy z kolei opóźnienia wynikające z oczekiwania aż osoby mające dostęp pobiorą kod i puszczą go na serwer samodzielnie.\"]]],[1,\"p\",[[0,[],0,\"Dobrze konfigurując ustawienia repozytorium z kodem możemy wdrożenia uprościć i uszczelnić jednocześnie.\"]]],[1,\"h3\",[[0,[],0,\"Formalizacja\"]]],[1,\"p\",[[0,[],0,\"Z natury biurokracja i zbędne formalizmy są czymś z czym lepiej walczyć, niż to rozwijać. Natomiast pewne formalne nakładane na procesy pozwalają opanować chaos i uniknąć błędów. Przy wdrażaniu systemów IT na serwer jest to kluczowe.\"]]],[1,\"p\",[[0,[],0,\"Wykonanie kopii zapasowej przed migracją bazy. Ograniczenie osób mogących wykonać wdrożenie. Przetestowanie automatyczne oprogramowania przed jego instalacją. Te wszystkie rzeczy można na sztywno określić w konfiguracji aplikacji utrzymującej repozytorium z kodem i plikach na podstawie których przeprowadzane jest wdrożenie.\"]]],[1,\"h3\",[[0,[],0,\"Zapis historii\"]]],[1,\"p\",[[0,[],0,\"Każda aktualizacja ma dokładną datę, można przejrzeć jej logi. Informacje, kto i kiedy wprowadził system do użytku, jaką miał wersję, jakie wersje miały zależne paczki.\"]]],[1,\"p\",[[0,[],0,\"Przy pracy zespołowej pozwala to zorientować się, jaka wersja systemu jest obecnie dostępna na którym środowisku. Często mamy środowiska produkcyjne, testowe i developerskie z różnymi wersjami tego samego oprogramowania.\"]]],[1,\"p\",[[0,[],0,\"Dostęp do tych informacji jest bardzo ważny zarówno z powodów formalnych jak i przez ich znaczenie dla wykrywania błędów.\"]]],[1,\"h2\",[[0,[],0,\"Jak to skonfigurować\"]]],[1,\"p\",[[0,[],0,\"Dostępnych konfiguracji CI/CD jest bardzo dużo. Tutaj zaprezentuję taką, która uniwersalnie może być dzielona przez wszystkie projekty, które robię.\"]]],[1,\"p\",[[0,[],0,\"Ceną za tą uniwersalność jest rozbudowany stack technologiczny i więcej warstw abstrakcji, niż jest to niezbędne. Wartością jest przenośność, więc jest duża szansa, że część tej konfiguracji zadziała u Ciebie.\"]]],[1,\"p\",[[0,[],0,\"Stack technologiczny:\"]]],[3,\"ul\",[[[0,[],0,\"gitlab ci\"]],[[0,[],0,\"make\"]],[[0,[],0,\"ansible\"]],[[0,[],0,\"docker\"]]]],[1,\"h3\",[[0,[],0,\"Schemat działania\"]]],[1,\"p\",[[0,[],0,\"Po dołączeniu commita do gałęzi \"],[0,[0],1,\"prod\"],[0,[],0,\" lub \"],[0,[0],1,\"stag\"],[0,[],0,\" wykonywana jest komenda \"],[0,[0],1,\"make deploy\"],[0,[],0,\" ze zmienną środowiskową \"],[0,[0],1,\"ENV\"],[0,[],0,\" taką jak nazwa gałęzi.\"]]],[1,\"p\",[[0,[],0,\"W \"],[0,[0],1,\"makefile\"],[0,[],0,\" do komendy \"],[0,[0],1,\"deploy\"],[0,[],0,\" podłączony jest \"],[0,[0],1,\"ansible\"],[0,[],0,\" z plikiem \"],[0,[0],1,\"hosts\"],[0,[],0,\" wybieranym na podstawie flagi \"],[0,[0],1,\"ENV\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Ansible dostaje \"],[0,[0],1,\"ENV\"],[0,[],0,\" i plik \"],[0,[0],1,\"hosts\"],[0,[],0,\" dzięki któremu buduje obraz dockerowy, wysyła go do repozytorium obrazów, następnie przygotowuje zmienne środowiskowe, przesyła je na serwer wraz z plikiem \"],[0,[0],1,\"docker-compose.yml\"],[0,[],0,\", loguje się na serwer przez \"],[0,[0],1,\"ssh\"],[0,[],0,\" i przeładowuje obraz.\"]]],[1,\"p\",[[0,[],0,\"Wymagane klucze:\"]]],[3,\"ul\",[[[0,[],0,\"do działania wymagany jest token do repozytorium docker\"]],[[0,[],0,\"musimy mieć klucz prywatny, dla którego klucz publiczny jest umieszczony w \"],[0,[0],1,\"authorized_keys\"],[0,[],0,\" na serwerze\"]]]],[1,\"p\",[[0,[],0,\"Dlaczego używamy \"],[0,[0],1,\"make\"],[0,[],0,\"?\"]]],[1,\"p\",[[0,[],0,\"Właściwie to można zagnieździć polecenie \"],[0,[0],1,\"ansible\"],[0,[],0,\" wewnątrz \"],[0,[0],1,\".gitlab-ci.yml\"],[0,[],0,\", ale dołożenie \"],[0,[0],1,\"make\"],[0,[],0,\" pozwala na uproszczenie konwencji, która rozciąga się na wszystkie projekty w organizacji.\"]]],[1,\"p\",[[0,[],0,\"Konwencja którą przyjąłem pozwala na jej ujednolicenie dla projektów pisanych w \"],[0,[0],1,\"php\"],[0,[],0,\", \"],[0,[0],1,\"node\"],[0,[],0,\", \"],[0,[0],1,\"python\"],[0,[],0,\".\"]]],[10,1],[1,\"h3\",[[0,[],0,\"Klucze\"]]],[1,\"p\",[[0,[],0,\"Aby wygenerować klucz wykonujemy komendę:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Utworzy ona dwa pliki - klucz prywatny nie zabezpieczony hasłem:\"]]],[10,3],[1,\"p\",[[0,[],0,\"oraz klucz publiczny \"]]],[10,4],[1,\"p\",[[0,[],0,\"Klucz publiczny wgrywamy na serwer dołączając jego zawartość do \"],[0,[0],1,\"~/.ssh/authorized_keys\"],[0,[],0,\" na serwerze.\"]]],[1,\"p\",[[0,[],0,\"Klucz prywatny musimy umieścić w zmiennych środowiskowych gitlaba. Nie możemy tego zrobić bezpośrednio, ponieważ wielo-liniowe zmienne nie mogą być maskowane.\"]]],[10,5],[1,\"p\",[[0,[],0,\"Dzięki poleceniu\"]]],[10,6],[1,\"p\",[[0,[],0,\"możemy dostać klucz zakodowany jako \"],[0,[0],1,\"base64\"],[0,[],0,\". Flaga \"],[0,[0],1,\"-w0\"],[0,[],0,\" pozwala nie zawijać linii\"]]],[1,\"blockquote\",[[0,[],0,\"-w, --wrap=COLS       wrap encoded lines after COLS character \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t(default 76). Use 0 to disable line wrapping\"]]],[1,\"p\",[[0,[],0,\"W celu ponownego odkodowania klucz a można użyć flagi \"],[0,[0],1,\"-d\"]]],[10,7],[1,\"p\",[[0,[],0,\"Drugim kluczem jest \"],[0,[0],1,\"DOCKER_TOKEN\"],[0,[],0,\". Metoda jego uzyskania zależy od repozytorium dockerowego. Najpopularniejsze to:\"]]],[3,\"ul\",[[[0,[],0,\"Dockerhub\"]],[[0,[],0,\"Gitlab\"]],[[0,[],0,\"Digital Ocean\"]],[[0,[],0,\"Google Container Registry\"]],[[0,[],0,\"Codefresh Docker Registry\"]]]],[1,\"p\",[[0,[],0,\"Dla Digital Ocean po wybraniu \\\"Container Registry\\\" wybieramy \\\"Actions\\\" i pobieramy token o uprawnieniach \\\"Read and Write\\\". \"]]],[10,8],[1,\"h3\",[[0,[],0,\"Dodanie zmiennych do Gitlaba\"]]],[1,\"p\",[[0,[],0,\"W gitlabie wybieramy grupę lub projekt dla których chcemy ustawić zmienne, przechodzimy do \\\"Settings\\\", \\\"CI/CD\\\", rozwijamy \\\"Variables\\\"\"]]],[10,9],[1,\"p\",[[0,[],0,\"Zakodowany klucz widoczny dzięki poleceniu \"],[0,[0],1,\"cat ~/.ssh/ci | base64 -w0\"],[0,[],0,\" nazwiemy \"],[0,[0],1,\"SSH_PRIVATE_KEY_BASE64\"],[0,[],0,\". Ważne, żebyśmy dodając tą zmienną ustawili protected i mask.\"]]],[10,10],[1,\"p\",[[0,[],0,\"Poprawnie ustawiając te zmienne zobaczymy tabelę:\"]]],[10,11],[1,\"p\",[[0,[],0,\"Niektóre repozytoria dockera mogą rozróżniać \"],[0,[0],1,\"DOCKER_USER\"],[0,[],0,\" i \"],[0,[0],1,\"DOCKER_PASSWORD\"],[0,[],0,\". Wykorzystanie \"],[0,[0],1,\"DOCKER_TOKEN\"],[0,[],0,\" jest typowe dla konwencji z Digital Ocean.\"]]],[1,\"h3\",[[0,[],0,\"Protected i Masked\"]]],[1,\"p\",[[0,[],0,\"W gitlabie mamy możliwość oznaczenia zmiennych jako \\\"protected\\\" lub \\\"masked\\\". Opcja \\\"protected\\\" pozwala na udostępnienie zmiennych jedynie w gałęziach lub tagach, które też oznaczone są jako protected. Pozwala to na przypisanie im uprawnień, określenie, kto może dołączać kod do tych gałęzi, czy wymaga on akceptacji przez właściciela kodu.\"]]],[10,12],[1,\"p\",[[0,[],0,\"Więcej na temat chronionych gałęzi możecie przeczytaj tutaj:\"]]],[10,13],[1,\"p\",[[0,[],0,\"Druga opcja: \\\"masked\\\" oznacza, że zmienne nie będą widoczne w logach. Muszą spełniać kilka wymagań, między innymi ich wartości powinny mieścić się w jednej linii. Właśnie z tego powodu przetworzyliśmy klucz prywatny na postać zakodowaną przez \"],[0,[0],1,\"base64\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Pamiętaj, że ta konfiguracja nie zadziała, jeśli nie oznaczysz swoich gałęzi w repozytorium, dla których wykonujesz deployment jako \"],[0,[0],1,\"protected\"],[0,[],0,\". Jeśli nie chcesz tego robić, to nie używaj opcji \\\"protected\\\" dla zmiennych środowiskowych.\"]]],[1,\"h3\",[[0,[],0,\"Uniwersalny workflow .gitlab-ci.yml\"]]],[1,\"p\",[[0,[],0,\"Niezależnie od serwisu, który wdrażam (poza wyjątkiem wtyczek do przeglądarki, czy tych frontów, które trafiają na netlify) zadania są takie same:\"]]],[3,\"ol\",[[[0,[],0,\"Potrzebujemy systemu na którym zalogujemy się do rejestru dockera\"]],[[0,[],0,\"Określimy środowisko na podstawie nazwy gałęzi\"]],[[0,[],0,\"Przygotujemy się do podłączenia docelowego serwera przez ssh\"]],[[0,[],0,\"Włączymy \"],[0,[0],1,\"ansible\"],[0,[],0,\", żeby wykonał zadania deploymentu:\"]]]],[1,\"p\",[[0,[],0,\"Te zadania to:\"]]],[3,\"ul\",[[[0,[],0,\"zbudowanie obrazu dockera\"]],[[0,[],0,\"wypchnięcie obrazu do rejestru\"]],[[0,[],0,\"zalogowanie się na serwer\"]],[[0,[],0,\"przeładowanie obrazu\"]]]],[1,\"p\",[[0,[],0,\"Poniżej prezentuję plik \"],[0,[0],1,\".gitlab-ci.yml\"],[0,[],0,\", który pozwala to zrobić:\"]]],[10,14],[1,\"h4\",[[0,[],0,\"Zmienne\"]]],[1,\"p\",[[0,[],0,\"Zmienne na początku to ustawienia dockera.\"]]],[3,\"ul\",[[[0,[0],1,\"DOCKER_REGISTRY_DOMAIN\"],[0,[],0,\" pozwala wskazać gdzie ma być przechowywany obraz z aplikacją.\"]],[[0,[0],1,\"DOCKER_HOST\"],[0,[],0,\" jest wymagane przy konfiguracji \"],[0,[0],1,\"Docker in docker\"],[0,[],0,\". Tak zwany \"],[0,[0],1,\"dind\"],[0,[],0,\". Pozwala to używać dockera wewnątrz dockerowego egzekutora. Mówi ona kontenerowi aby używał daemona \"],[0,[0],1,\"DinD\"],[0,[],0,\".\"]]]],[1,\"p\",[[0,[],0,\"Jest to bardzo wygodna konfiguracja ponieważ egzekutor dockerowy jest jednym z najbardziej elastycznych i wszechstronnych.\"]]],[1,\"p\",[[0,[],0,\"Pełne zestawienie egzekutorów:\"]]],[10,15],[1,\"p\",[[0,[],0,\"Przykładowa minimalna konfiguracja \"],[0,[0],1,\"dind\"],[0,[],0,\" (bardzo podobna do mojej)\"]]],[10,16],[1,\"p\",[[0,[],0,\"Pełna dokumentacja \"],[0,[0],1,\"dind\"]]],[10,17],[1,\"p\",[[0,[],0,\"Brak ustawienia \"],[0,[0],1,\"DOCKER_HOST\"],[0,[],0,\" będzie powodował błąd:\"]]],[1,\"blockquote\",[[0,[],0,\"Error connecting: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))\"]]],[3,\"ul\",[[[0,[0],1,\"DOCKER_TLS_CERTDIR\"],[0,[],0,\" - Wyłącza Dockerowi próbę łączenia się po TLS.\"]],[[0,[0],1,\"DOCKER_DRIVER\"],[0,[],0,\" - poprawia wydajność i stabliność sterowników dockera do systemu plików\"]]]],[1,\"p\",[[0,[],0,\"Więcej o tych sterownikach mówi dokumentacja:\"]]],[10,18],[1,\"h4\",[[0,[],0,\"Obrazy\"]]],[1,\"p\",[[0,[],0,\"W naszym pliku mamy jeden obraz:\"]]],[10,19],[1,\"p\",[[0,[],0,\"Często można spotkać się z tym, że w \"],[0,[0],1,\".gitlab-ci.yml\"],[0,[],0,\" podłącza się ich więcej. Ma to sens jeśli chcemy tu rozstawić środowisko testowe, albo mamy nie dockerowy deployment w którym budowane są artefakty poza dockerem. W naszym przypadku wszystko jest ukryte na innej warstwie. Gitlab Ci jest traktowany jako inicjator procesu, który przekazuje nazwę środowiska z gałęzi gita, łączy się z repozytorim dockera i zapewnia wstrzyknięcie klucza do łączenia z serwerem.\"]]],[1,\"p\",[[0,[],0,\"Odpowiedzialność pliku \"],[0,[0],1,\".gitlab-ci.yml\"],[0,[],0,\" jest dzięki temu uniwersalna i nie trzeba w nim większej ilości obrazów.\"]]],[1,\"h4\",[[0,[],0,\"Serwisy\"]]],[1,\"p\",[[0,[],0,\"Tak samo jak z obrazami, sytuacja wygląda z serwisami. Jest to tylko jeden \"],[0,[0],1,\"dind\"],[0,[],0,\", który pozwala nam przygotować egzekutor dockerowy do budowania obrazu dockerowego.\"]]],[1,\"p\",[[0,[],0,\"Dlatego linie z serwisami to jedynie\"]]],[10,20],[1,\"h4\",[[0,[],0,\"Środowiska\"]]],[1,\"p\",[[0,[],0,\"Zmienimy trochę kolejność i przejdziemy do końcówki pliku. Mamy tu wpisy:\"]]],[10,21],[1,\"p\",[[0,[],0,\"Mówią one tylko, żeby włączyć task \"],[0,[0],1,\".deploy\"],[0,[],0,\" jeśli gałąź to \"],[0,[0],1,\"stag\"],[0,[],0,\" lub \"],[0,[0],1,\"prod\"],[0,[],0,\". W każdym z przypadków, w tasku \"],[0,[0],1,\".deploy\"],[0,[],0,\" dostępna będzie zmienna \"],[0,[0],1,\"ENV\"],[0,[],0,\" o wartości równej nazwie gałęzi.\"]]],[1,\"h4\",[[0,[],0,\"Deployment\"]]],[1,\"p\",[[0,[],0,\"Sam deployment opisany kodem:\"]]],[10,22],[1,\"p\",[[0,[],0,\"składa się z następujących kroków:\"]]],[1,\"h5\",[[0,[],0,\"Wskazanie obrazu źródłowego\"]]],[1,\"p\",[[0,[],0,\"Wybraliśmy \"],[0,[0],1,\"archlinux:latest\"],[0,[],0,\". Ten uchodzący za jeden z trudniejszych do zainstalowania systemów odwdzięcza się jednym z najprostszych w obsłudze managerów pakietów. Jest w nim praktycznie wszystko. Główne alternatywy to:\"]]],[3,\"ul\",[[[0,[],0,\"Ubuntu - ze starymi paczkami\"]],[[0,[],0,\"Alpine - bez potrzebnych paczek\"]]]],[1,\"p\",[[0,[],0,\"Na tym tle arch jest nie do pobicia, tym bardziej, że stosowany jest jako bazowy system na komputerach większości programistów w naszej organizacji.\"]]],[1,\"h5\",[[0,[],0,\"Wskazanie stage\"]]],[10,23],[1,\"p\",[[0,[],0,\"Zarządzanie stages ma sens jeśli proces budowania, deploymentu i testowania są zarządzane na poziomie \"],[0,[0],1,\".gitlab-ci.yml\"],[0,[],0,\". W tym wpisie wyciąłem część z testami automatycznymi i skupiłem się na wdrożeniu.\"]]],[1,\"h5\",[[0,[],0,\"Instalacja zależności\"]]],[10,24],[1,\"p\",[[0,[],0,\"Pacman jest managerem pakietów archa, analogicznie jak \"],[0,[0],1,\"apt\"],[0,[],0,\" dla \"],[0,[0],1,\"Ubuntu\"],[0,[],0,\" oraz \"],[0,[0],1,\"apk\"],[0,[],0,\" dla \"],[0,[0],1,\"Alpine\"],[0,[],0,\". Instalujemy następujące pakiety:\"]]],[3,\"ul\",[[[0,[],0,\"make - potrzebny do wykonania komendy \"],[0,[0],1,\"make deploy\"],[0,[],0,\", która pod spodem włączy \"],[0,[0],1,\"ansible\"],[0,[],0,\". Gdyby nie ta konwencja, można by to wyrzucić.\"]],[[0,[],0,\"ansible - dużo wygodniejsza alternatywa do automatyzacji deploymentu niż pisanie skryptów w bashu, pozwala na optymalizację wykonywanych akcji dzięki oparciu się o idempotentność operacji.\"]],[[0,[],0,\"python, python-pip - w pythonie napisane jest api dockera, przez które ansible nim zarządza, można je traktować jako paczki wymagane do instalacji wtyczki \"],[0,[0],1,\"community.general.docker_image\"],[0,[],0,\" ansible\"]],[[0,[],0,\"openssh - to jest pakiet pozwalający na komunikację ssh, wymagany do połączenia się z serwerem\"]],[[0,[],0,\"docker - kluczowy jest docker. Mimo, że stosujemy serwis \"],[0,[0],1,\"docker:dind\"],[0,[],0,\" daje on tylko możliwość podłączenia się do dockera. Samą aplikcję dockera musimy zainstalować, choć nie będziemy startować deamona dockera, tylko skorzystamy z tego wystawionego z serwisu \"],[0,[0],1,\"docker:dind\"],[0,[],0,\".\"]]]],[1,\"h5\",[[0,[],0,\"Logowanie do repozytorium obrazów\"]]],[10,25],[1,\"p\",[[0,[],0,\"Ta komenda może różnić się w zależności od repozytorium. Niektóre z nich rozróżniają \"],[0,[0],1,\"DOCKER_USER\"],[0,[],0,\" i \"],[0,[0],1,\"DOCKER_PASSWORD\"],[0,[],0,\". W digital ocean oba nazwane są tak samo - \"],[0,[0],1,\"DOCKER_TOKEN\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Wynikiem włączenia tego polecenia jest możliwość wysyłania zbudowanego obrazu do repozytorium dockerowego.\"]]],[1,\"h5\",[[0,[],0,\"Instalacja pythonowych sterowników dockera\"]]],[10,26],[1,\"p\",[[0,[],0,\"O tym problemie pisałem kiedyś na stackoverflow: \"]]],[10,27],[1,\"p\",[[0,[],0,\"Dokumentacja omawiająca te wymagania dostępna jest pod linkiem:\"]]],[10,28],[1,\"h5\",[[0,[],0,\"Włączenie agenta ssh\"]]],[10,29],[1,\"p\",[[0,[],0,\"Powoduje to uruchomienie agenta ssh w tle i ustawienie odpowiednich zmiennych środowiskowych dla bieżącej powłoki\"]]],[10,30],[1,\"h5\",[[0,[],0,\"Dodanie klucza prywatnego\"]]],[10,31],[1,\"p\",[[0,[],0,\"Wykonujemy tu dwie operacje:\"]]],[3,\"ul\",[[[0,[],0,\"odwracamy kodowanie klucza jako base64\"]],[[0,[],0,\"dodajemy ten klucz do agenta ssh\"]]]],[1,\"h5\",[[0,[],0,\"Wyłączenie sprawdzania kluczy hosta dla rejestru dockera\"]]],[10,32],[1,\"p\",[[0,[],0,\"Instancja serwera z egzekutorem powstaje na czas budowania i znika zaraz potem. W normalnych sytuacjach łącząc się z nowym serwerem jesli nie mamy go w \"],[0,[0],1,\"known_hosts\"],[0,[],0,\" dostajemy ostrzeżenie i musimy potwierdzić tą operację. \"]]],[1,\"p\",[[0,[],0,\"Jeśli chcemy, żeby proces odbywał się automatycznie, to musimy wyłączyć ten mechanizm.\"]]],[1,\"h5\",[[0,[],0,\"Wykonanie deploymentu\"]]],[10,33],[1,\"p\",[[0,[],0,\"Doszliśmy do końca pliku \"],[0,[0],1,\".gitlab-ci.yml\"],[0,[],0,\". Ostateczna komenda \"],[0,[0],1,\"make deploy\"],[0,[],0,\" wykonuje budowanie obrazu i deployment. Jej włączenie nie powiodło by się, gdyby nie te wszystkie przygotowawcze kroki, które opisaliśmy powyżej.\"]]],[1,\"h2\",[[0,[],0,\"Makefile\"]]],[1,\"p\",[[0,[],0,\"Pliki Makefile różnią się w zależności od projektu, ale można przyjąć, że ich struktura jest raczej podobna. Jako przykład podam plik z jednego z projektów:\"]]],[10,34],[1,\"p\",[[0,[],0,\"Jego kluczowa część - \"],[0,[0],1,\"make deploy\"],[0,[],0,\" składa się z dwóch poleceń:\"]]],[3,\"ul\",[[[0,[],0,\"sprawdzenia czy \"],[0,[0],1,\"ENV\"],[0,[],0,\" jest poprawny - wymagany aby istniały pliki \"],[0,[0],1,\"hosts.prod\"],[0,[],0,\" i \"],[0,[0],1,\"hosts.stag\"],[0,[],0,\".\"]],[[0,[],0,\"wykonania playbooku \"],[0,[0],1,\"deploy.yml\"],[0,[],0,\" za pomocą \"],[0,[0],1,\"ansible\"],[0,[],0,\" z odpowiednim plikiem \"],[0,[0],1,\"hosts\"],[0,[],0,\".\"]]]],[1,\"p\",[[0,[],0,\"Zobaczymy teraz jaką strukturę mają pliki, których używa \"],[0,[0],1,\"ansible\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Pliki Hosts\"]]],[1,\"p\",[[0,[],0,\"Plik \"],[0,[0],1,\"hosts.prod\"],[0,[],0,\" jest bardzo prosty\"]]],[10,35],[1,\"p\",[[0,[],0,\"analogicznie plik \"],[0,[0],1,\"hosts.stag\"]]],[10,36],[1,\"p\",[[0,[],0,\"Definiują one parę hostów, ale oczywiście może być ich czasami więcej. Host lokalny służy do budowania obrazu, a host o nazwie \"],[0,[0],1,\"api\"],[0,[],0,\", czasem nazywany przeze mnie \"],[0,[0],1,\"front\"],[0,[],0,\" to zdalny serwer na który ma trafić obraz aplikacji.\"]]],[1,\"h2\",[[0,[],0,\"Playbook Ansible\"]]],[1,\"p\",[[0,[],0,\"Do tej pory omówiliśmy \"],[0,[0],1,\".gitlab-ci.yml\"],[0,[],0,\" odpowiedzialny za przygotowanie egzekutora. Pokazaliśmy też pliki \"],[0,[0],1,\"hosts\"],[0,[],0,\" z adresami serwerów docelowych. Teraz zaprezentuję plik \"],[0,[0],1,\"deploy.yml\"],[0,[],0,\" czyli playbook ansible odpowiedzialny za budowanie i deployment obrazu dockerowego.\"]]],[10,37],[1,\"p\",[[0,[],0,\"Zawiera on parę kontrowersyjnych fragmentów i wciąż nie jest idealny. Dlatego omówię go szczegółowo wskazując gdzie i na jakie kompromisy poszedłem przygotowując go.\"]]],[1,\"p\",[[0,[],0,\"Najbardziej problematyczna częścią jest tu zarządzanie zmiennymi środowiskowymi i sekretami. W obecnej formie w repozytorium znajdują się pliki \"],[0,[0],1,\".env\"],[0,[],0,\", \"],[0,[0],1,\".env.prod\"],[0,[],0,\" oraz \"],[0,[0],1,\".env.stag\"],[0,[],0,\". Dwa ostatnie nadpisują ustawienia z pierwszego. Pierwszy task \\\"Prepare env\\\" odpowiada za zbudowanie pliku \"],[0,[0],1,\".env.stag.build\"],[0,[],0,\" lub \"],[0,[0],1,\".env.prod.build\"],[0,[],0,\".\"]]],[10,38],[1,\"p\",[[0,[],0,\"Dlaczego uważam, że to problematyczna część? Przede wszystkim dlatego, że w tych plikach znajdują się hasła i klucze. Jestem przekonany, że nie powinny się one znajdować w repozytorium, ale  problemy związane z ich bezpiecznym współdzieleniem w ramach organizacji nie zostały jeszcze rozwiązane.\"]]],[1,\"p\",[[0,[],0,\" \"]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Skrót CI/CD - ciągła integracja i ciągłe dostarczanie oznaczają, że zamiast manualnego wdrażania systemu na serwer zmiana kodu źródłowego powoduje wykonanie się testów automatycznych i aktualizację systemu na serwerze.</p><p>W artykule opiszę korzyści z implementacji tego podejścia oraz konfigurację, której używam w swojej organizacji. Mam nadzieję, że będzie mogła ona posłużyć komuś jako wzór. Być może dzięki waszym komentarzom będę w stanie ją ulepszyć.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/EUO5sFpWoAMaecY.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"1200\" height=\"902\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/EUO5sFpWoAMaecY.jpg 600w, __GHOST_URL__/content/images/size/w1000/2021/04/EUO5sFpWoAMaecY.jpg 1000w, __GHOST_URL__/content/images/2021/04/EUO5sFpWoAMaecY.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"warto%C5%9B%C4%87-biznesowa-cicd\">Wartość biznesowa CI/CD</h2><p>Ten proces ma wiele korzyści. Są to:</p><ul><li>obniżenie kosztu deploymentu [ automatyzacja ]</li><li>podniesienie bezpieczeństwa wdrożeń [ uprawnienia ]</li><li>formalizacja procesu [ testy automatyczne, kopie zapasowe ]</li><li>wgląd do logów z wdrożeń [ kto, kiedy, co i gdzie wdrożył ]</li></ul><h3 id=\"koszty\">Koszty</h3><p>Wdrożenie aktualizacji systemu na serwer może zajmować od kilku sekund do kilkudziesięciu minut. Zwykle główną część czasu zajmuje kompilacja lub budowanie kodu wynikowego ze źródeł projektu. Często obok samego kodu projektu, należy zaktualizować zmienne środowiskowe, przeinstalować nowe wersje zależnych paczek, wykonać migrację bazy danych, postawić nowe serwisy, a czasem nawet nowe serwery.</p><p>Najszybsze w realizacji, ale najdroższe w utrzymaniu jest manualne wykonywanie tych czynności. Rodzi to też ryzyko błędu ludzkiego.</p><p>Tańszym w utrzymaniu jest napisanie do tego skryptów, albo konfiguracji i wykonywanie jednego polecenia, aby przeprowadzić pełny deployment.</p><p>Najlepszym rozwiązaniem jest CI/CD czyli takie skonfigurowanie systemu, żeby od początku każda zmiana w kodzie załączona w odpowiedniej gałęzi repozytorium powodowała zbudowanie systemu i jego instalację na serwerze.</p><p>Wówczas koszty na DevOps ograniczają się do konfigurowania systemu i nie narastają wraz z intensyfikacją częstotliwości wypuszczania poprawek i nowych wersji.</p><h3 id=\"bezpiecze%C5%84stwo\">Bezpieczeństwo</h3><p>Kiedy pracowałem jako freelancer, jednocześnie pisałem kod i miałem dostęp do danych produkcyjnych. Samodzielne robienie wdrożenia było naturalne. Nie było w tym nic dziwnego, że miałem klucze do wszystkich serwerów.</p><p>Jeśli w projekcie pracuje kilka osób i każda z nich, żeby wdrożyć poprawki potrzebuje dostępu do serwera, rodzi to pewne problemy. Trudniejszy staje się zarówno proces nadawania uprawnień jak i ich kontroli.</p><p>Bez dawania dostępu wszystkim do wszystkiego mamy z kolei opóźnienia wynikające z oczekiwania aż osoby mające dostęp pobiorą kod i puszczą go na serwer samodzielnie.</p><p>Dobrze konfigurując ustawienia repozytorium z kodem możemy wdrożenia uprościć i uszczelnić jednocześnie.</p><h3 id=\"formalizacja\">Formalizacja</h3><p>Z natury biurokracja i zbędne formalizmy są czymś z czym lepiej walczyć, niż to rozwijać. Natomiast pewne formalne nakładane na procesy pozwalają opanować chaos i uniknąć błędów. Przy wdrażaniu systemów IT na serwer jest to kluczowe.</p><p>Wykonanie kopii zapasowej przed migracją bazy. Ograniczenie osób mogących wykonać wdrożenie. Przetestowanie automatyczne oprogramowania przed jego instalacją. Te wszystkie rzeczy można na sztywno określić w konfiguracji aplikacji utrzymującej repozytorium z kodem i plikach na podstawie których przeprowadzane jest wdrożenie.</p><h3 id=\"zapis-historii\">Zapis historii</h3><p>Każda aktualizacja ma dokładną datę, można przejrzeć jej logi. Informacje, kto i kiedy wprowadził system do użytku, jaką miał wersję, jakie wersje miały zależne paczki.</p><p>Przy pracy zespołowej pozwala to zorientować się, jaka wersja systemu jest obecnie dostępna na którym środowisku. Często mamy środowiska produkcyjne, testowe i developerskie z różnymi wersjami tego samego oprogramowania.</p><p>Dostęp do tych informacji jest bardzo ważny zarówno z powodów formalnych jak i przez ich znaczenie dla wykrywania błędów.</p><h2 id=\"jak-to-skonfigurowa%C4%87\">Jak to skonfigurować</h2><p>Dostępnych konfiguracji CI/CD jest bardzo dużo. Tutaj zaprezentuję taką, która uniwersalnie może być dzielona przez wszystkie projekty, które robię.</p><p>Ceną za tą uniwersalność jest rozbudowany stack technologiczny i więcej warstw abstrakcji, niż jest to niezbędne. Wartością jest przenośność, więc jest duża szansa, że część tej konfiguracji zadziała u Ciebie.</p><p>Stack technologiczny:</p><ul><li>gitlab ci</li><li>make</li><li>ansible</li><li>docker</li></ul><h3 id=\"schemat-dzia%C5%82ania\">Schemat działania</h3><p>Po dołączeniu commita do gałęzi <code>prod</code> lub <code>stag</code> wykonywana jest komenda <code>make deploy</code> ze zmienną środowiskową <code>ENV</code> taką jak nazwa gałęzi.</p><p>W <code>makefile</code> do komendy <code>deploy</code> podłączony jest <code>ansible</code> z plikiem <code>hosts</code> wybieranym na podstawie flagi <code>ENV</code>. </p><p>Ansible dostaje <code>ENV</code> i plik <code>hosts</code> dzięki któremu buduje obraz dockerowy, wysyła go do repozytorium obrazów, następnie przygotowuje zmienne środowiskowe, przesyła je na serwer wraz z plikiem <code>docker-compose.yml</code>, loguje się na serwer przez <code>ssh</code> i przeładowuje obraz.</p><p>Wymagane klucze:</p><ul><li>do działania wymagany jest token do repozytorium docker</li><li>musimy mieć klucz prywatny, dla którego klucz publiczny jest umieszczony w <code>authorized_keys</code> na serwerze</li></ul><p>Dlaczego używamy <code>make</code>?</p><p>Właściwie to można zagnieździć polecenie <code>ansible</code> wewnątrz <code>.gitlab-ci.yml</code>, ale dołożenie <code>make</code> pozwala na uproszczenie konwencji, która rozciąga się na wszystkie projekty w organizacji.</p><p>Konwencja którą przyjąłem pozwala na jej ujednolicenie dla projektów pisanych w <code>php</code>, <code>node</code>, <code>python</code>.</p><pre><code>make up - podnoszenie wszystkich serwisów do developowania\nmake deploy - umieszczenie projektu na serwerze\nmake t - wykonanie testów automatycznych\nmake ssh - zalogowanie na serwer powiązany z tym projektem</code></pre><h3 id=\"klucze\">Klucze</h3><p>Aby wygenerować klucz wykonujemy komendę:</p><pre><code>ssh-keygen -t ed25519 -f ~/.ssh/ci -q -N \"\"</code></pre><p>Utworzy ona dwa pliki - klucz prywatny nie zabezpieczony hasłem:</p><pre><code>~/.ssh/ci</code></pre><p>oraz klucz publiczny </p><pre><code>~/.ssh/ci.pub</code></pre><p>Klucz publiczny wgrywamy na serwer dołączając jego zawartość do <code>~/.ssh/authorized_keys</code> na serwerze.</p><p>Klucz prywatny musimy umieścić w zmiennych środowiskowych gitlaba. Nie możemy tego zrobić bezpośrednio, ponieważ wielo-liniowe zmienne nie mogą być maskowane.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-14-14-01.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"716\" height=\"544\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-27-14-14-01.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-14-14-01.png 716w\"></figure><p>Dzięki poleceniu</p><pre><code>cat ~/.ssh/ci | base64 -w0 </code></pre><p>możemy dostać klucz zakodowany jako <code>base64</code>. Flaga <code>-w0</code> pozwala nie zawijać linii</p><blockquote>-w, --wrap=COLS       wrap encoded lines after COLS character \t\t\t\t\t\t\t\t\t\t\t(default 76). Use 0 to disable line wrapping</blockquote><p>W celu ponownego odkodowania klucz a można użyć flagi <code>-d</code></p><pre><code> cat ~/.ssh/ci | base64 -w0 | base64 -d</code></pre><p>Drugim kluczem jest <code>DOCKER_TOKEN</code>. Metoda jego uzyskania zależy od repozytorium dockerowego. Najpopularniejsze to:</p><ul><li>Dockerhub</li><li>Gitlab</li><li>Digital Ocean</li><li>Google Container Registry</li><li>Codefresh Docker Registry</li></ul><p>Dla Digital Ocean po wybraniu \"Container Registry\" wybieramy \"Actions\" i pobieramy token o uprawnieniach \"Read and Write\". </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-30-21.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1161\" height=\"226\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-27-18-30-21.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/Screenshot-from-2021-04-27-18-30-21.png 1000w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-30-21.png 1161w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"dodanie-zmiennych-do-gitlaba\">Dodanie zmiennych do Gitlaba</h3><p>W gitlabie wybieramy grupę lub projekt dla których chcemy ustawić zmienne, przechodzimy do \"Settings\", \"CI/CD\", rozwijamy \"Variables\"</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-38-08.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1118\" height=\"821\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-27-18-38-08.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/Screenshot-from-2021-04-27-18-38-08.png 1000w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-38-08.png 1118w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Zakodowany klucz widoczny dzięki poleceniu <code>cat ~/.ssh/ci | base64 -w0</code> nazwiemy <code>SSH_PRIVATE_KEY_BASE64</code>. Ważne, żebyśmy dodając tą zmienną ustawili protected i mask.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-42-36.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"742\" height=\"537\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-27-18-42-36.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-42-36.png 742w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Poprawnie ustawiając te zmienne zobaczymy tabelę:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-45-02.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"822\" height=\"146\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-27-18-45-02.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-27-18-45-02.png 822w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Niektóre repozytoria dockera mogą rozróżniać <code>DOCKER_USER</code> i <code>DOCKER_PASSWORD</code>. Wykorzystanie <code>DOCKER_TOKEN</code> jest typowe dla konwencji z Digital Ocean.</p><h3 id=\"protected-i-masked\">Protected i Masked</h3><p>W gitlabie mamy możliwość oznaczenia zmiennych jako \"protected\" lub \"masked\". Opcja \"protected\" pozwala na udostępnienie zmiennych jedynie w gałęziach lub tagach, które też oznaczone są jako protected. Pozwala to na przypisanie im uprawnień, określenie, kto może dołączać kod do tych gałęzi, czy wymaga on akceptacji przez właściciela kodu.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/protected_branches_page_v12_3.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"855\" height=\"458\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/protected_branches_page_v12_3.png 600w, __GHOST_URL__/content/images/2021/04/protected_branches_page_v12_3.png 855w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Więcej na temat chronionych gałęzi możecie przeczytaj tutaj:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.gitlab.com/ee/user/project/protected_branches.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Protected branches | GitLab</div><div class=\"kg-bookmark-description\">Documentation for GitLab Community Edition, GitLab Enterprise Edition, Omnibus GitLab, and GitLab Runner.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.gitlab.com/assets/images/apple-touch-icon.png\"><span class=\"kg-bookmark-author\">GitLab Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.gitlab.com/assets/images/gitlab-logo.svg\"></div></a></figure><p>Druga opcja: \"masked\" oznacza, że zmienne nie będą widoczne w logach. Muszą spełniać kilka wymagań, między innymi ich wartości powinny mieścić się w jednej linii. Właśnie z tego powodu przetworzyliśmy klucz prywatny na postać zakodowaną przez <code>base64</code>.</p><p>Pamiętaj, że ta konfiguracja nie zadziała, jeśli nie oznaczysz swoich gałęzi w repozytorium, dla których wykonujesz deployment jako <code>protected</code>. Jeśli nie chcesz tego robić, to nie używaj opcji \"protected\" dla zmiennych środowiskowych.</p><h3 id=\"uniwersalny-workflow-gitlab-ciyml\">Uniwersalny workflow .gitlab-ci.yml</h3><p>Niezależnie od serwisu, który wdrażam (poza wyjątkiem wtyczek do przeglądarki, czy tych frontów, które trafiają na netlify) zadania są takie same:</p><ol><li>Potrzebujemy systemu na którym zalogujemy się do rejestru dockera</li><li>Określimy środowisko na podstawie nazwy gałęzi</li><li>Przygotujemy się do podłączenia docelowego serwera przez ssh</li><li>Włączymy <code>ansible</code>, żeby wykonał zadania deploymentu:</li></ol><p>Te zadania to:</p><ul><li>zbudowanie obrazu dockera</li><li>wypchnięcie obrazu do rejestru</li><li>zalogowanie się na serwer</li><li>przeładowanie obrazu</li></ul><p>Poniżej prezentuję plik <code>.gitlab-ci.yml</code>, który pozwala to zrobić:</p><pre><code>variables:\n  DOCKER_REGISTRY_DOMAIN: \"registry.digitalocean.com\"\n  DOCKER_HOST: tcp://docker:2375\n  DOCKER_TLS_CERTDIR: \"\"\n  DOCKER_DRIVER: overlay2\n\nimage: docker:latest\n\nservices:\n  - docker:dind\n\n.deploy:\n  image: archlinux:latest\n  stage: deploy\n  before_script:\n    - pacman -Sy make ansible python python-pip openssh docker --noconfirm\n    - docker login -u ${DOCKER_TOKEN} -p ${DOCKER_TOKEN} ${DOCKER_REGISTRY_DOMAIN}\n    - pip3 install docker docker-compose\n    - eval $(ssh-agent -s)\n    - ssh-add &lt;(echo \"$SSH_PRIVATE_KEY_BASE64 | base64 -d\")\n    - mkdir -p ~/.ssh\n    - '[[ -f /.dockerenv ]] &amp;&amp; echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" &gt; ~/.ssh/config'\n  script:\n    - ENV=${ENV} make deploy\n\nprod:\n  extends: .deploy\n  variables:\n    ENV: prod\n  only:\n    refs:\n      - prod\n\nstag:\n  extends: .deploy\n  variables:\n    ENV: stag\n  only:\n    refs:\n      - stag</code></pre><h4 id=\"zmienne\">Zmienne</h4><p>Zmienne na początku to ustawienia dockera.</p><ul><li><code>DOCKER_REGISTRY_DOMAIN</code> pozwala wskazać gdzie ma być przechowywany obraz z aplikacją.</li><li><code>DOCKER_HOST</code> jest wymagane przy konfiguracji <code>Docker in docker</code>. Tak zwany <code>dind</code>. Pozwala to używać dockera wewnątrz dockerowego egzekutora. Mówi ona kontenerowi aby używał daemona <code>DinD</code>.</li></ul><p>Jest to bardzo wygodna konfiguracja ponieważ egzekutor dockerowy jest jednym z najbardziej elastycznych i wszechstronnych.</p><p>Pełne zestawienie egzekutorów:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.gitlab.com/runner/executors/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Executors | GitLab</div><div class=\"kg-bookmark-description\">Documentation for GitLab Community Edition, GitLab Enterprise Edition, Omnibus GitLab, and GitLab Runner.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.gitlab.com/assets/images/apple-touch-icon.png\"><span class=\"kg-bookmark-author\">GitLab Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.gitlab.com/assets/images/gitlab-logo.svg\"></div></a></figure><p>Przykładowa minimalna konfiguracja <code>dind</code> (bardzo podobna do mojej)</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.testcontainers.org/supported_docker_environment/continuous_integration/gitlab_ci/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitLab CI - Testcontainers</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.testcontainers.org/favicon.ico\"><span class=\"kg-bookmark-author\">Testcontainers</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://d33wubrfki0l68.cloudfront.net/13c9a4b570398ec611da4ec48085caaa48c5f2d2/39fb0/logo.svg\"></div></a></figure><p>Pełna dokumentacja <code>dind</code></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#use-docker-in-docker-workflow-with-docker-executor\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Use Docker to build Docker images | GitLab</div><div class=\"kg-bookmark-description\">Documentation for GitLab Community Edition, GitLab Enterprise Edition, Omnibus GitLab, and GitLab Runner.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.gitlab.com/assets/images/apple-touch-icon.png\"><span class=\"kg-bookmark-author\">GitLab Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.gitlab.com/assets/images/gitlab-logo.svg\"></div></a></figure><p>Brak ustawienia <code>DOCKER_HOST</code> będzie powodował błąd:</p><blockquote>Error connecting: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))</blockquote><ul><li><code>DOCKER_TLS_CERTDIR</code> - Wyłącza Dockerowi próbę łączenia się po TLS.</li><li><code>DOCKER_DRIVER</code> - poprawia wydajność i stabliność sterowników dockera do systemu plików</li></ul><p>Więcej o tych sterownikach mówi dokumentacja:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.docker.com/storage/storagedriver/overlayfs-driver/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Use the OverlayFS storage driver</div><div class=\"kg-bookmark-description\">Learn how to optimize your use of OverlayFS driver.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.docker.com/favicons/docs@2x.ico\"><span class=\"kg-bookmark-author\">Docker Documentation</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.docker.com/favicons/docs@2x.ico\"></div></a></figure><h4 id=\"obrazy\">Obrazy</h4><p>W naszym pliku mamy jeden obraz:</p><pre><code>image: docker:latest</code></pre><p>Często można spotkać się z tym, że w <code>.gitlab-ci.yml</code> podłącza się ich więcej. Ma to sens jeśli chcemy tu rozstawić środowisko testowe, albo mamy nie dockerowy deployment w którym budowane są artefakty poza dockerem. W naszym przypadku wszystko jest ukryte na innej warstwie. Gitlab Ci jest traktowany jako inicjator procesu, który przekazuje nazwę środowiska z gałęzi gita, łączy się z repozytorim dockera i zapewnia wstrzyknięcie klucza do łączenia z serwerem.</p><p>Odpowiedzialność pliku <code>.gitlab-ci.yml</code> jest dzięki temu uniwersalna i nie trzeba w nim większej ilości obrazów.</p><h4 id=\"serwisy\">Serwisy</h4><p>Tak samo jak z obrazami, sytuacja wygląda z serwisami. Jest to tylko jeden <code>dind</code>, który pozwala nam przygotować egzekutor dockerowy do budowania obrazu dockerowego.</p><p>Dlatego linie z serwisami to jedynie</p><pre><code>services:\n  - docker:dind\n</code></pre><h4 id=\"%C5%9Brodowiska\">Środowiska</h4><p>Zmienimy trochę kolejność i przejdziemy do końcówki pliku. Mamy tu wpisy:</p><pre><code>prod:\n  extends: .deploy\n  variables:\n    ENV: prod\n  only:\n    refs:\n      - prod\n\nstag:\n  extends: .deploy\n  variables:\n    ENV: stag\n  only:\n    refs:\n      - stag</code></pre><p>Mówią one tylko, żeby włączyć task <code>.deploy</code> jeśli gałąź to <code>stag</code> lub <code>prod</code>. W każdym z przypadków, w tasku <code>.deploy</code> dostępna będzie zmienna <code>ENV</code> o wartości równej nazwie gałęzi.</p><h4 id=\"deployment\">Deployment</h4><p>Sam deployment opisany kodem:</p><pre><code>.deploy:\n  image: archlinux:latest\n  stage: deploy\n  before_script:\n    - pacman -Sy make ansible python python-pip openssh docker --noconfirm\n#    - docker login\n    - docker login -u ${DOCKER_TOKEN} -p ${DOCKER_TOKEN} ${DOCKER_REGISTRY_DOMAIN}\n    - pip3 install docker docker-compose\n    - eval $(ssh-agent -s)\n    - ssh-add &lt;(echo ${SSH_PRIVATE_KEY_BASE64} | base64 -d)\n    - mkdir -p ~/.ssh\n    - '[[ -f /.dockerenv ]] &amp;&amp; echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" &gt; ~/.ssh/config'\n  script:\n    - ENV=${ENV} make deploy</code></pre><p>składa się z następujących kroków:</p><h5 id=\"wskazanie-obrazu-%C5%BAr%C3%B3d%C5%82owego\">Wskazanie obrazu źródłowego</h5><p>Wybraliśmy <code>archlinux:latest</code>. Ten uchodzący za jeden z trudniejszych do zainstalowania systemów odwdzięcza się jednym z najprostszych w obsłudze managerów pakietów. Jest w nim praktycznie wszystko. Główne alternatywy to:</p><ul><li>Ubuntu - ze starymi paczkami</li><li>Alpine - bez potrzebnych paczek</li></ul><p>Na tym tle arch jest nie do pobicia, tym bardziej, że stosowany jest jako bazowy system na komputerach większości programistów w naszej organizacji.</p><h5 id=\"wskazanie-stage\">Wskazanie stage</h5><pre><code>  stage: deploy</code></pre><p>Zarządzanie stages ma sens jeśli proces budowania, deploymentu i testowania są zarządzane na poziomie <code>.gitlab-ci.yml</code>. W tym wpisie wyciąłem część z testami automatycznymi i skupiłem się na wdrożeniu.</p><h5 id=\"instalacja-zale%C5%BCno%C5%9Bci\">Instalacja zależności</h5><pre><code>- pacman -Sy make ansible python python-pip openssh docker --noconfirm\n</code></pre><p>Pacman jest managerem pakietów archa, analogicznie jak <code>apt</code> dla <code>Ubuntu</code> oraz <code>apk</code> dla <code>Alpine</code>. Instalujemy następujące pakiety:</p><ul><li>make - potrzebny do wykonania komendy <code>make deploy</code>, która pod spodem włączy <code>ansible</code>. Gdyby nie ta konwencja, można by to wyrzucić.</li><li>ansible - dużo wygodniejsza alternatywa do automatyzacji deploymentu niż pisanie skryptów w bashu, pozwala na optymalizację wykonywanych akcji dzięki oparciu się o idempotentność operacji.</li><li>python, python-pip - w pythonie napisane jest api dockera, przez które ansible nim zarządza, można je traktować jako paczki wymagane do instalacji wtyczki <code>community.general.docker_image</code> ansible</li><li>openssh - to jest pakiet pozwalający na komunikację ssh, wymagany do połączenia się z serwerem</li><li>docker - kluczowy jest docker. Mimo, że stosujemy serwis <code>docker:dind</code> daje on tylko możliwość podłączenia się do dockera. Samą aplikcję dockera musimy zainstalować, choć nie będziemy startować deamona dockera, tylko skorzystamy z tego wystawionego z serwisu <code>docker:dind</code>.</li></ul><h5 id=\"logowanie-do-repozytorium-obraz%C3%B3w\">Logowanie do repozytorium obrazów</h5><pre><code>- docker login -u ${DOCKER_TOKEN} -p ${DOCKER_TOKEN} ${DOCKER_REGISTRY_DOMAIN}</code></pre><p>Ta komenda może różnić się w zależności od repozytorium. Niektóre z nich rozróżniają <code>DOCKER_USER</code> i <code>DOCKER_PASSWORD</code>. W digital ocean oba nazwane są tak samo - <code>DOCKER_TOKEN</code>.</p><p>Wynikiem włączenia tego polecenia jest możliwość wysyłania zbudowanego obrazu do repozytorium dockerowego.</p><h5 id=\"instalacja-pythonowych-sterownik%C3%B3w-dockera\">Instalacja pythonowych sterowników dockera</h5><pre><code>- pip3 install docker docker-compose</code></pre><p>O tym problemie pisałem kiedyś na stackoverflow: </p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://stackoverflow.com/questions/59384708/ansible-returns-with-failed-to-import-the-required-python-library-docker-sdk-f/65495769#65495769\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">ansible returns with “Failed to import the required Python library (Docker SDK for Python: docker (Python &gt;&#x3D; 2.7) or docker-py (Python 2.6))</div><div class=\"kg-bookmark-description\">I am running myserver in ubuntu: + sudo cat /etc/os-releaseNAME&#x3D;“Ubuntu”VERSION&#x3D;“16.04.6 LTS (Xenial Xerus)”ID&#x3D;ubuntuID_LIKE&#x3D;debianPRETTY_NAME&#x3D;“Ubuntu 16.04.6 LTS”VERSION_ID&#x3D;“16.04″HOME_URL...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v&#x3D;c78bd457575a\"><span class=\"kg-bookmark-author\">Stack Overflow</span><span class=\"kg-bookmark-publisher\">Learner</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v&#x3D;73d79a89bded\"></div></a></figure><p>Dokumentacja omawiająca te wymagania dostępna jest pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.ansible.com/ansible/latest/collections/community/docker/docker_compose_module.html#ansible-collections-community-docker-docker-compose-module\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">community.docker.docker_compose – Manage multi-container Docker applications with Docker Compose. — Ansible Documentation</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.ansible.com/ansible/latest/_static/images/logo_invert.png\"></div></a></figure><h5 id=\"w%C5%82%C4%85czenie-agenta-ssh\">Włączenie agenta ssh</h5><pre><code>eval $(ssh-agent -s)</code></pre><p>Powoduje to uruchomienie agenta ssh w tle i ustawienie odpowiednich zmiennych środowiskowych dla bieżącej powłoki</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://superuser.com/questions/284374/ssh-keys-ssh-agent-bash-and-ssh-add\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">ssh keys ssh-agent bash and ssh-add</div><div class=\"kg-bookmark-description\">I am new to ssh keys. Can anyone explain how the ssh-agent bash and ssh-add works? I need to understand its internals in future.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon.png?v&#x3D;0ad5b7a83e49\"><span class=\"kg-bookmark-author\">Super User</span><span class=\"kg-bookmark-publisher\">maneeshshetty</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon@2.png?v&#x3D;e869e4459439\"></div></a></figure><h5 id=\"dodanie-klucza-prywatnego\">Dodanie klucza prywatnego</h5><pre><code>- ssh-add &lt;(echo ${SSH_PRIVATE_KEY_BASE64} | base64 -d)</code></pre><p>Wykonujemy tu dwie operacje:</p><ul><li>odwracamy kodowanie klucza jako base64</li><li>dodajemy ten klucz do agenta ssh</li></ul><h5 id=\"wy%C5%82%C4%85czenie-sprawdzania-kluczy-hosta-dla-rejestru-dockera\">Wyłączenie sprawdzania kluczy hosta dla rejestru dockera</h5><pre><code>- mkdir -p ~/.ssh\n- '[[ -f /.dockerenv ]] &amp;&amp; echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" &gt; ~/.ssh/config'</code></pre><p>Instancja serwera z egzekutorem powstaje na czas budowania i znika zaraz potem. W normalnych sytuacjach łącząc się z nowym serwerem jesli nie mamy go w <code>known_hosts</code> dostajemy ostrzeżenie i musimy potwierdzić tą operację. </p><p>Jeśli chcemy, żeby proces odbywał się automatycznie, to musimy wyłączyć ten mechanizm.</p><h5 id=\"wykonanie-deploymentu\">Wykonanie deploymentu</h5><pre><code>  script:\n    - ENV=${ENV} make deploy</code></pre><p>Doszliśmy do końca pliku <code>.gitlab-ci.yml</code>. Ostateczna komenda <code>make deploy</code> wykonuje budowanie obrazu i deployment. Jej włączenie nie powiodło by się, gdyby nie te wszystkie przygotowawcze kroki, które opisaliśmy powyżej.</p><h2 id=\"makefile\">Makefile</h2><p>Pliki Makefile różnią się w zależności od projektu, ale można przyjąć, że ich struktura jest raczej podobna. Jako przykład podam plik z jednego z projektów:</p><pre><code>include .env\nexport\n\nnode_modules: package.json\n\tnpm i\n\nup: node_modules\n\tnpm run start\n\nt:\n\tnpm test\n\ngenerate:\n\tnpx prisma generate\n\n.ONESHELL:\ndeploy:\n\tif [ ! -e \"hosts.$(ENV)\" ]; then printf \"Use ENV=stag or ENV=prod before make deploy\\n\" &amp;&amp; exit ; fi;\n\tansible-playbook -i hosts.$(ENV) deploy.yml\n\nclean:\n\trm index.js helpers/*.js interfaces/*.js test/*.js signals/*.js</code></pre><p>Jego kluczowa część - <code>make deploy</code> składa się z dwóch poleceń:</p><ul><li>sprawdzenia czy <code>ENV</code> jest poprawny - wymagany aby istniały pliki <code>hosts.prod</code> i <code>hosts.stag</code>.</li><li>wykonania playbooku <code>deploy.yml</code> za pomocą <code>ansible</code> z odpowiednim plikiem <code>hosts</code>.</li></ul><p>Zobaczymy teraz jaką strukturę mają pliki, których używa <code>ansible</code>.</p><h2 id=\"pliki-hosts\">Pliki Hosts</h2><p>Plik <code>hosts.prod</code> jest bardzo prosty</p><pre><code>[local]\n127.0.0.1 env=prod\n\n[api]\n134.xxx.xxx.149 ansible_user=root env=prod</code></pre><p>analogicznie plik <code>hosts.stag</code></p><pre><code>[local]\n127.0.0.1 env=stag\n\n[api]\n134.yyy.yyy.149  ansible_user=root env=stag</code></pre><p>Definiują one parę hostów, ale oczywiście może być ich czasami więcej. Host lokalny służy do budowania obrazu, a host o nazwie <code>api</code>, czasem nazywany przeze mnie <code>front</code> to zdalny serwer na który ma trafić obraz aplikacji.</p><h2 id=\"playbook-ansible\">Playbook Ansible</h2><p>Do tej pory omówiliśmy <code>.gitlab-ci.yml</code> odpowiedzialny za przygotowanie egzekutora. Pokazaliśmy też pliki <code>hosts</code> z adresami serwerów docelowych. Teraz zaprezentuję plik <code>deploy.yml</code> czyli playbook ansible odpowiedzialny za budowanie i deployment obrazu dockerowego.</p><pre><code>---\n- name: Merge Env\n  hosts: local\n  connection: local\n  tags:\n    - deploy\n  tasks:\n    - name: Prepare env\n      shell: \"sort -u -t '=' -k 1,1 .env.{{env}} .env &gt; .env.{{env}}.build\"\n- name: Build Backend\n  hosts: local\n  connection: local\n  tags:\n    - build\n  tasks:\n    - name: Build Image\n      community.general.docker_image:\n        build:\n          path: .\n          pull: no\n        name: registry.digitalocean.com/main/telegram.ts\n        push: true\n        source: build\n        force_source: yes\n      environment:\n        DOCKER_BUILDKIT: 1\n- name: Deploy Backend\n  hosts: api\n  tags:\n    - deploy\n  vars:\n    path: /root/telegram.ts\n  tasks:\n    - name: Creates directory\n      file:\n        path: \"{{ path }}\"\n        state: directory\n    - name: Copy Docker Compose\n      copy:\n        src: docker-compose.yml\n        dest: \"{{ path }}/docker-compose.yml\"\n    - name: Copy .env\n      copy:\n        src: \"./.env.{{ env }}.build\"\n        dest: \"{{ path }}/.env\"\n    - name: Reload Compose\n      community.general.docker_compose:\n        pull: yes\n        project_src: \"{{ path }}\"</code></pre><p>Zawiera on parę kontrowersyjnych fragmentów i wciąż nie jest idealny. Dlatego omówię go szczegółowo wskazując gdzie i na jakie kompromisy poszedłem przygotowując go.</p><p>Najbardziej problematyczna częścią jest tu zarządzanie zmiennymi środowiskowymi i sekretami. W obecnej formie w repozytorium znajdują się pliki <code>.env</code>, <code>.env.prod</code> oraz <code>.env.stag</code>. Dwa ostatnie nadpisują ustawienia z pierwszego. Pierwszy task \"Prepare env\" odpowiada za zbudowanie pliku <code>.env.stag.build</code> lub <code>.env.prod.build</code>.</p><pre><code>- name: Merge Env\n  hosts: local\n  connection: local\n  tags:\n    - deploy\n  tasks:\n    - name: Prepare env\n      shell: \"sort -u -t '=' -k 1,1 .env.{{env}} .env &gt; .env.{{env}}.build\"\n</code></pre><p>Dlaczego uważam, że to problematyczna część? Przede wszystkim dlatego, że w tych plikach znajdują się hasła i klucze. Jestem przekonany, że nie powinny się one znajdować w repozytorium, ale  problemy związane z ich bezpiecznym współdzieleniem w ramach organizacji nie zostały jeszcze rozwiązane.</p><p> </p>",
            "comment_id": "608718422fb35425592d0da6",
            "plaintext": "Skrót CI/CD - ciągła integracja i ciągłe dostarczanie oznaczają, że zamiast\nmanualnego wdrażania systemu na serwer zmiana kodu źródłowego powoduje wykonanie\nsię testów automatycznych i aktualizację systemu na serwerze.\n\nW artykule opiszę korzyści z implementacji tego podejścia oraz konfigurację,\nktórej używam w swojej organizacji. Mam nadzieję, że będzie mogła ona posłużyć\nkomuś jako wzór. Być może dzięki waszym komentarzom będę w stanie ją ulepszyć.\n\nWartość biznesowa CI/CD\nTen proces ma wiele korzyści. Są to:\n\n * obniżenie kosztu deploymentu [ automatyzacja ]\n * podniesienie bezpieczeństwa wdrożeń [ uprawnienia ]\n * formalizacja procesu [ testy automatyczne, kopie zapasowe ]\n * wgląd do logów z wdrożeń [ kto, kiedy, co i gdzie wdrożył ]\n\nKoszty\nWdrożenie aktualizacji systemu na serwer może zajmować od kilku sekund do\nkilkudziesięciu minut. Zwykle główną część czasu zajmuje kompilacja lub\nbudowanie kodu wynikowego ze źródeł projektu. Często obok samego kodu projektu,\nnależy zaktualizować zmienne środowiskowe, przeinstalować nowe wersje zależnych\npaczek, wykonać migrację bazy danych, postawić nowe serwisy, a czasem nawet nowe\nserwery.\n\nNajszybsze w realizacji, ale najdroższe w utrzymaniu jest manualne wykonywanie\ntych czynności. Rodzi to też ryzyko błędu ludzkiego.\n\nTańszym w utrzymaniu jest napisanie do tego skryptów, albo konfiguracji i\nwykonywanie jednego polecenia, aby przeprowadzić pełny deployment.\n\nNajlepszym rozwiązaniem jest CI/CD czyli takie skonfigurowanie systemu, żeby od\npoczątku każda zmiana w kodzie załączona w odpowiedniej gałęzi repozytorium\npowodowała zbudowanie systemu i jego instalację na serwerze.\n\nWówczas koszty na DevOps ograniczają się do konfigurowania systemu i nie\nnarastają wraz z intensyfikacją częstotliwości wypuszczania poprawek i nowych\nwersji.\n\nBezpieczeństwo\nKiedy pracowałem jako freelancer, jednocześnie pisałem kod i miałem dostęp do\ndanych produkcyjnych. Samodzielne robienie wdrożenia było naturalne. Nie było w\ntym nic dziwnego, że miałem klucze do wszystkich serwerów.\n\nJeśli w projekcie pracuje kilka osób i każda z nich, żeby wdrożyć poprawki\npotrzebuje dostępu do serwera, rodzi to pewne problemy. Trudniejszy staje się\nzarówno proces nadawania uprawnień jak i ich kontroli.\n\nBez dawania dostępu wszystkim do wszystkiego mamy z kolei opóźnienia wynikające\nz oczekiwania aż osoby mające dostęp pobiorą kod i puszczą go na serwer\nsamodzielnie.\n\nDobrze konfigurując ustawienia repozytorium z kodem możemy wdrożenia uprościć i\nuszczelnić jednocześnie.\n\nFormalizacja\nZ natury biurokracja i zbędne formalizmy są czymś z czym lepiej walczyć, niż to\nrozwijać. Natomiast pewne formalne nakładane na procesy pozwalają opanować chaos\ni uniknąć błędów. Przy wdrażaniu systemów IT na serwer jest to kluczowe.\n\nWykonanie kopii zapasowej przed migracją bazy. Ograniczenie osób mogących\nwykonać wdrożenie. Przetestowanie automatyczne oprogramowania przed jego\ninstalacją. Te wszystkie rzeczy można na sztywno określić w konfiguracji\naplikacji utrzymującej repozytorium z kodem i plikach na podstawie których\nprzeprowadzane jest wdrożenie.\n\nZapis historii\nKażda aktualizacja ma dokładną datę, można przejrzeć jej logi. Informacje, kto i\nkiedy wprowadził system do użytku, jaką miał wersję, jakie wersje miały zależne\npaczki.\n\nPrzy pracy zespołowej pozwala to zorientować się, jaka wersja systemu jest\nobecnie dostępna na którym środowisku. Często mamy środowiska produkcyjne,\ntestowe i developerskie z różnymi wersjami tego samego oprogramowania.\n\nDostęp do tych informacji jest bardzo ważny zarówno z powodów formalnych jak i\nprzez ich znaczenie dla wykrywania błędów.\n\nJak to skonfigurować\nDostępnych konfiguracji CI/CD jest bardzo dużo. Tutaj zaprezentuję taką, która\nuniwersalnie może być dzielona przez wszystkie projekty, które robię.\n\nCeną za tą uniwersalność jest rozbudowany stack technologiczny i więcej warstw\nabstrakcji, niż jest to niezbędne. Wartością jest przenośność, więc jest duża\nszansa, że część tej konfiguracji zadziała u Ciebie.\n\nStack technologiczny:\n\n * gitlab ci\n * make\n * ansible\n * docker\n\nSchemat działania\nPo dołączeniu commita do gałęzi prod lub stag wykonywana jest komenda make\ndeploy ze zmienną środowiskową ENV taką jak nazwa gałęzi.\n\nW makefile do komendy deploy podłączony jest ansible z plikiem hosts wybieranym\nna podstawie flagi ENV. \n\nAnsible dostaje ENV i plik hosts dzięki któremu buduje obraz dockerowy, wysyła\ngo do repozytorium obrazów, następnie przygotowuje zmienne środowiskowe,\nprzesyła je na serwer wraz z plikiem docker-compose.yml, loguje się na serwer\nprzez ssh i przeładowuje obraz.\n\nWymagane klucze:\n\n * do działania wymagany jest token do repozytorium docker\n * musimy mieć klucz prywatny, dla którego klucz publiczny jest umieszczony w \n   authorized_keys na serwerze\n\nDlaczego używamy make?\n\nWłaściwie to można zagnieździć polecenie ansible wewnątrz .gitlab-ci.yml, ale\ndołożenie make pozwala na uproszczenie konwencji, która rozciąga się na\nwszystkie projekty w organizacji.\n\nKonwencja którą przyjąłem pozwala na jej ujednolicenie dla projektów pisanych w \nphp, node, python.\n\nmake up - podnoszenie wszystkich serwisów do developowania\nmake deploy - umieszczenie projektu na serwerze\nmake t - wykonanie testów automatycznych\nmake ssh - zalogowanie na serwer powiązany z tym projektem\n\nKlucze\nAby wygenerować klucz wykonujemy komendę:\n\nssh-keygen -t ed25519 -f ~/.ssh/ci -q -N \"\"\n\nUtworzy ona dwa pliki - klucz prywatny nie zabezpieczony hasłem:\n\n~/.ssh/ci\n\noraz klucz publiczny \n\n~/.ssh/ci.pub\n\nKlucz publiczny wgrywamy na serwer dołączając jego zawartość do \n~/.ssh/authorized_keys na serwerze.\n\nKlucz prywatny musimy umieścić w zmiennych środowiskowych gitlaba. Nie możemy\ntego zrobić bezpośrednio, ponieważ wielo-liniowe zmienne nie mogą być maskowane.\n\nDzięki poleceniu\n\ncat ~/.ssh/ci | base64 -w0 \n\nmożemy dostać klucz zakodowany jako base64. Flaga -w0 pozwala nie zawijać linii\n\n> -w, --wrap=COLS       wrap encoded lines after COLS character\n\t\t\t\t\t\t\t\t\t\t\t(default 76). Use 0 to disable line wrapping\nW celu ponownego odkodowania klucz a można użyć flagi -d\n\n cat ~/.ssh/ci | base64 -w0 | base64 -d\n\nDrugim kluczem jest DOCKER_TOKEN. Metoda jego uzyskania zależy od repozytorium\ndockerowego. Najpopularniejsze to:\n\n * Dockerhub\n * Gitlab\n * Digital Ocean\n * Google Container Registry\n * Codefresh Docker Registry\n\nDla Digital Ocean po wybraniu \"Container Registry\" wybieramy \"Actions\" i\npobieramy token o uprawnieniach \"Read and Write\". \n\nDodanie zmiennych do Gitlaba\nW gitlabie wybieramy grupę lub projekt dla których chcemy ustawić zmienne,\nprzechodzimy do \"Settings\", \"CI/CD\", rozwijamy \"Variables\"\n\nZakodowany klucz widoczny dzięki poleceniu cat ~/.ssh/ci | base64 -w0 nazwiemy \nSSH_PRIVATE_KEY_BASE64. Ważne, żebyśmy dodając tą zmienną ustawili protected i\nmask.\n\nPoprawnie ustawiając te zmienne zobaczymy tabelę:\n\nNiektóre repozytoria dockera mogą rozróżniać DOCKER_USER i DOCKER_PASSWORD.\nWykorzystanie DOCKER_TOKEN jest typowe dla konwencji z Digital Ocean.\n\nProtected i Masked\nW gitlabie mamy możliwość oznaczenia zmiennych jako \"protected\" lub \"masked\".\nOpcja \"protected\" pozwala na udostępnienie zmiennych jedynie w gałęziach lub\ntagach, które też oznaczone są jako protected. Pozwala to na przypisanie im\nuprawnień, określenie, kto może dołączać kod do tych gałęzi, czy wymaga on\nakceptacji przez właściciela kodu.\n\nWięcej na temat chronionych gałęzi możecie przeczytaj tutaj:\n\nProtected branches | GitLabDocumentation for GitLab Community Edition, GitLab\nEnterprise Edition, Omnibus GitLab, and GitLab Runner.GitLab Docs\n[https://docs.gitlab.com/ee/user/project/protected_branches.html]Druga opcja:\n\"masked\" oznacza, że zmienne nie będą widoczne w logach. Muszą spełniać kilka\nwymagań, między innymi ich wartości powinny mieścić się w jednej linii. Właśnie\nz tego powodu przetworzyliśmy klucz prywatny na postać zakodowaną przez base64.\n\nPamiętaj, że ta konfiguracja nie zadziała, jeśli nie oznaczysz swoich gałęzi w\nrepozytorium, dla których wykonujesz deployment jako protected. Jeśli nie chcesz\ntego robić, to nie używaj opcji \"protected\" dla zmiennych środowiskowych.\n\nUniwersalny workflow .gitlab-ci.yml\nNiezależnie od serwisu, który wdrażam (poza wyjątkiem wtyczek do przeglądarki,\nczy tych frontów, które trafiają na netlify) zadania są takie same:\n\n 1. Potrzebujemy systemu na którym zalogujemy się do rejestru dockera\n 2. Określimy środowisko na podstawie nazwy gałęzi\n 3. Przygotujemy się do podłączenia docelowego serwera przez ssh\n 4. Włączymy ansible, żeby wykonał zadania deploymentu:\n\nTe zadania to:\n\n * zbudowanie obrazu dockera\n * wypchnięcie obrazu do rejestru\n * zalogowanie się na serwer\n * przeładowanie obrazu\n\nPoniżej prezentuję plik .gitlab-ci.yml, który pozwala to zrobić:\n\nvariables:\n  DOCKER_REGISTRY_DOMAIN: \"registry.digitalocean.com\"\n  DOCKER_HOST: tcp://docker:2375\n  DOCKER_TLS_CERTDIR: \"\"\n  DOCKER_DRIVER: overlay2\n\nimage: docker:latest\n\nservices:\n  - docker:dind\n\n.deploy:\n  image: archlinux:latest\n  stage: deploy\n  before_script:\n    - pacman -Sy make ansible python python-pip openssh docker --noconfirm\n    - docker login -u ${DOCKER_TOKEN} -p ${DOCKER_TOKEN} ${DOCKER_REGISTRY_DOMAIN}\n    - pip3 install docker docker-compose\n    - eval $(ssh-agent -s)\n    - ssh-add <(echo \"$SSH_PRIVATE_KEY_BASE64 | base64 -d\")\n    - mkdir -p ~/.ssh\n    - '[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\n  script:\n    - ENV=${ENV} make deploy\n\nprod:\n  extends: .deploy\n  variables:\n    ENV: prod\n  only:\n    refs:\n      - prod\n\nstag:\n  extends: .deploy\n  variables:\n    ENV: stag\n  only:\n    refs:\n      - stag\n\nZmienne\nZmienne na początku to ustawienia dockera.\n\n * DOCKER_REGISTRY_DOMAIN pozwala wskazać gdzie ma być przechowywany obraz z\n   aplikacją.\n * DOCKER_HOST jest wymagane przy konfiguracji Docker in docker. Tak zwany dind.\n   Pozwala to używać dockera wewnątrz dockerowego egzekutora. Mówi ona\n   kontenerowi aby używał daemona DinD.\n\nJest to bardzo wygodna konfiguracja ponieważ egzekutor dockerowy jest jednym z\nnajbardziej elastycznych i wszechstronnych.\n\nPełne zestawienie egzekutorów:\n\nExecutors | GitLabDocumentation for GitLab Community Edition, GitLab Enterprise\nEdition, Omnibus GitLab, and GitLab Runner.GitLab Docs\n[https://docs.gitlab.com/runner/executors/]Przykładowa minimalna konfiguracja dind (bardzo podobna do mojej)\n\nGitLab CI - TestcontainersTestcontainers\n[https://www.testcontainers.org/supported_docker_environment/continuous_integration/gitlab_ci/]\nPełna dokumentacja dind\n\nUse Docker to build Docker images | GitLabDocumentation for GitLab Community\nEdition, GitLab Enterprise Edition, Omnibus GitLab, and GitLab Runner.GitLab\nDocs\n[https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#use-docker-in-docker-workflow-with-docker-executor]\nBrak ustawienia DOCKER_HOST będzie powodował błąd:\n\n> Error connecting: Error while fetching server API version: ('Connection\naborted.', FileNotFoundError(2, 'No such file or directory'))\n * DOCKER_TLS_CERTDIR - Wyłącza Dockerowi próbę łączenia się po TLS.\n * DOCKER_DRIVER - poprawia wydajność i stabliność sterowników dockera do\n   systemu plików\n\nWięcej o tych sterownikach mówi dokumentacja:\n\nUse the OverlayFS storage driverLearn how to optimize your use of OverlayFS\ndriver.Docker Documentation\n[https://docs.docker.com/storage/storagedriver/overlayfs-driver/]Obrazy\nW naszym pliku mamy jeden obraz:\n\nimage: docker:latest\n\nCzęsto można spotkać się z tym, że w .gitlab-ci.yml podłącza się ich więcej. Ma\nto sens jeśli chcemy tu rozstawić środowisko testowe, albo mamy nie dockerowy\ndeployment w którym budowane są artefakty poza dockerem. W naszym przypadku\nwszystko jest ukryte na innej warstwie. Gitlab Ci jest traktowany jako inicjator\nprocesu, który przekazuje nazwę środowiska z gałęzi gita, łączy się z\nrepozytorim dockera i zapewnia wstrzyknięcie klucza do łączenia z serwerem.\n\nOdpowiedzialność pliku .gitlab-ci.yml jest dzięki temu uniwersalna i nie trzeba\nw nim większej ilości obrazów.\n\nSerwisy\nTak samo jak z obrazami, sytuacja wygląda z serwisami. Jest to tylko jeden dind,\nktóry pozwala nam przygotować egzekutor dockerowy do budowania obrazu\ndockerowego.\n\nDlatego linie z serwisami to jedynie\n\nservices:\n  - docker:dind\n\n\nŚrodowiska\nZmienimy trochę kolejność i przejdziemy do końcówki pliku. Mamy tu wpisy:\n\nprod:\n  extends: .deploy\n  variables:\n    ENV: prod\n  only:\n    refs:\n      - prod\n\nstag:\n  extends: .deploy\n  variables:\n    ENV: stag\n  only:\n    refs:\n      - stag\n\nMówią one tylko, żeby włączyć task .deploy jeśli gałąź to stag lub prod. W\nkażdym z przypadków, w tasku .deploy dostępna będzie zmienna ENV o wartości\nrównej nazwie gałęzi.\n\nDeployment\nSam deployment opisany kodem:\n\n.deploy:\n  image: archlinux:latest\n  stage: deploy\n  before_script:\n    - pacman -Sy make ansible python python-pip openssh docker --noconfirm\n#    - docker login\n    - docker login -u ${DOCKER_TOKEN} -p ${DOCKER_TOKEN} ${DOCKER_REGISTRY_DOMAIN}\n    - pip3 install docker docker-compose\n    - eval $(ssh-agent -s)\n    - ssh-add <(echo ${SSH_PRIVATE_KEY_BASE64} | base64 -d)\n    - mkdir -p ~/.ssh\n    - '[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\n  script:\n    - ENV=${ENV} make deploy\n\nskłada się z następujących kroków:\n\nWskazanie obrazu źródłowego\nWybraliśmy archlinux:latest. Ten uchodzący za jeden z trudniejszych do\nzainstalowania systemów odwdzięcza się jednym z najprostszych w obsłudze\nmanagerów pakietów. Jest w nim praktycznie wszystko. Główne alternatywy to:\n\n * Ubuntu - ze starymi paczkami\n * Alpine - bez potrzebnych paczek\n\nNa tym tle arch jest nie do pobicia, tym bardziej, że stosowany jest jako bazowy\nsystem na komputerach większości programistów w naszej organizacji.\n\nWskazanie stage\n  stage: deploy\n\nZarządzanie stages ma sens jeśli proces budowania, deploymentu i testowania są\nzarządzane na poziomie .gitlab-ci.yml. W tym wpisie wyciąłem część z testami\nautomatycznymi i skupiłem się na wdrożeniu.\n\nInstalacja zależności\n- pacman -Sy make ansible python python-pip openssh docker --noconfirm\n\n\nPacman jest managerem pakietów archa, analogicznie jak apt dla Ubuntu oraz apk \ndla Alpine. Instalujemy następujące pakiety:\n\n * make - potrzebny do wykonania komendy make deploy, która pod spodem włączy \n   ansible. Gdyby nie ta konwencja, można by to wyrzucić.\n * ansible - dużo wygodniejsza alternatywa do automatyzacji deploymentu niż\n   pisanie skryptów w bashu, pozwala na optymalizację wykonywanych akcji dzięki\n   oparciu się o idempotentność operacji.\n * python, python-pip - w pythonie napisane jest api dockera, przez które\n   ansible nim zarządza, można je traktować jako paczki wymagane do instalacji\n   wtyczki community.general.docker_image ansible\n * openssh - to jest pakiet pozwalający na komunikację ssh, wymagany do\n   połączenia się z serwerem\n * docker - kluczowy jest docker. Mimo, że stosujemy serwis docker:dind daje on\n   tylko możliwość podłączenia się do dockera. Samą aplikcję dockera musimy\n   zainstalować, choć nie będziemy startować deamona dockera, tylko skorzystamy\n   z tego wystawionego z serwisu docker:dind.\n\nLogowanie do repozytorium obrazów\n- docker login -u ${DOCKER_TOKEN} -p ${DOCKER_TOKEN} ${DOCKER_REGISTRY_DOMAIN}\n\nTa komenda może różnić się w zależności od repozytorium. Niektóre z nich\nrozróżniają DOCKER_USER i DOCKER_PASSWORD. W digital ocean oba nazwane są tak\nsamo - DOCKER_TOKEN.\n\nWynikiem włączenia tego polecenia jest możliwość wysyłania zbudowanego obrazu do\nrepozytorium dockerowego.\n\nInstalacja pythonowych sterowników dockera\n- pip3 install docker docker-compose\n\nO tym problemie pisałem kiedyś na stackoverflow: \n\nansible returns with “Failed to import the required Python library (Docker SDK\nfor Python: docker (Python >= 2.7) or docker-py (Python 2.6))I am running\nmyserver in ubuntu: + sudo cat /etc/os-releaseNAME=“Ubuntu”VERSION=“16.04.6 LTS\n(Xenial Xerus)”ID=ubuntuID_LIKE=debianPRETTY_NAME=“Ubuntu 16.04.6\nLTS”VERSION_ID=“16.04″HOME_URL...Stack OverflowLearner\n[https://stackoverflow.com/questions/59384708/ansible-returns-with-failed-to-import-the-required-python-library-docker-sdk-f/65495769#65495769]\nDokumentacja omawiająca te wymagania dostępna jest pod linkiem:\n\ncommunity.docker.docker_compose – Manage multi-container Docker applications\nwith Docker Compose. — Ansible Documentation\n[https://docs.ansible.com/ansible/latest/collections/community/docker/docker_compose_module.html#ansible-collections-community-docker-docker-compose-module]\nWłączenie agenta ssh\neval $(ssh-agent -s)\n\nPowoduje to uruchomienie agenta ssh w tle i ustawienie odpowiednich zmiennych\nśrodowiskowych dla bieżącej powłoki\n\nssh keys ssh-agent bash and ssh-addI am new to ssh keys. Can anyone explain how\nthe ssh-agent bash and ssh-add works? I need to understand its internals in\nfuture.Super Usermaneeshshetty\n[https://superuser.com/questions/284374/ssh-keys-ssh-agent-bash-and-ssh-add]\nDodanie klucza prywatnego\n- ssh-add <(echo ${SSH_PRIVATE_KEY_BASE64} | base64 -d)\n\nWykonujemy tu dwie operacje:\n\n * odwracamy kodowanie klucza jako base64\n * dodajemy ten klucz do agenta ssh\n\nWyłączenie sprawdzania kluczy hosta dla rejestru dockera\n- mkdir -p ~/.ssh\n- '[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\n\nInstancja serwera z egzekutorem powstaje na czas budowania i znika zaraz potem.\nW normalnych sytuacjach łącząc się z nowym serwerem jesli nie mamy go w \nknown_hosts dostajemy ostrzeżenie i musimy potwierdzić tą operację. \n\nJeśli chcemy, żeby proces odbywał się automatycznie, to musimy wyłączyć ten\nmechanizm.\n\nWykonanie deploymentu\n  script:\n    - ENV=${ENV} make deploy\n\nDoszliśmy do końca pliku .gitlab-ci.yml. Ostateczna komenda make deploy wykonuje\nbudowanie obrazu i deployment. Jej włączenie nie powiodło by się, gdyby nie te\nwszystkie przygotowawcze kroki, które opisaliśmy powyżej.\n\nMakefile\nPliki Makefile różnią się w zależności od projektu, ale można przyjąć, że ich\nstruktura jest raczej podobna. Jako przykład podam plik z jednego z projektów:\n\ninclude .env\nexport\n\nnode_modules: package.json\n\tnpm i\n\nup: node_modules\n\tnpm run start\n\nt:\n\tnpm test\n\ngenerate:\n\tnpx prisma generate\n\n.ONESHELL:\ndeploy:\n\tif [ ! -e \"hosts.$(ENV)\" ]; then printf \"Use ENV=stag or ENV=prod before make deploy\\n\" && exit ; fi;\n\tansible-playbook -i hosts.$(ENV) deploy.yml\n\nclean:\n\trm index.js helpers/*.js interfaces/*.js test/*.js signals/*.js\n\nJego kluczowa część - make deploy składa się z dwóch poleceń:\n\n * sprawdzenia czy ENV jest poprawny - wymagany aby istniały pliki hosts.prod i \n   hosts.stag.\n * wykonania playbooku deploy.yml za pomocą ansible z odpowiednim plikiem hosts.\n\nZobaczymy teraz jaką strukturę mają pliki, których używa ansible.\n\nPliki Hosts\nPlik hosts.prod jest bardzo prosty\n\n[local]\n127.0.0.1 env=prod\n\n[api]\n134.xxx.xxx.149 ansible_user=root env=prod\n\nanalogicznie plik hosts.stag\n\n[local]\n127.0.0.1 env=stag\n\n[api]\n134.yyy.yyy.149  ansible_user=root env=stag\n\nDefiniują one parę hostów, ale oczywiście może być ich czasami więcej. Host\nlokalny służy do budowania obrazu, a host o nazwie api, czasem nazywany przeze\nmnie front to zdalny serwer na który ma trafić obraz aplikacji.\n\nPlaybook Ansible\nDo tej pory omówiliśmy .gitlab-ci.yml odpowiedzialny za przygotowanie\negzekutora. Pokazaliśmy też pliki hosts z adresami serwerów docelowych. Teraz\nzaprezentuję plik deploy.yml czyli playbook ansible odpowiedzialny za budowanie\ni deployment obrazu dockerowego.\n\n---\n- name: Merge Env\n  hosts: local\n  connection: local\n  tags:\n    - deploy\n  tasks:\n    - name: Prepare env\n      shell: \"sort -u -t '=' -k 1,1 .env.{{env}} .env > .env.{{env}}.build\"\n- name: Build Backend\n  hosts: local\n  connection: local\n  tags:\n    - build\n  tasks:\n    - name: Build Image\n      community.general.docker_image:\n        build:\n          path: .\n          pull: no\n        name: registry.digitalocean.com/main/telegram.ts\n        push: true\n        source: build\n        force_source: yes\n      environment:\n        DOCKER_BUILDKIT: 1\n- name: Deploy Backend\n  hosts: api\n  tags:\n    - deploy\n  vars:\n    path: /root/telegram.ts\n  tasks:\n    - name: Creates directory\n      file:\n        path: \"{{ path }}\"\n        state: directory\n    - name: Copy Docker Compose\n      copy:\n        src: docker-compose.yml\n        dest: \"{{ path }}/docker-compose.yml\"\n    - name: Copy .env\n      copy:\n        src: \"./.env.{{ env }}.build\"\n        dest: \"{{ path }}/.env\"\n    - name: Reload Compose\n      community.general.docker_compose:\n        pull: yes\n        project_src: \"{{ path }}\"\n\nZawiera on parę kontrowersyjnych fragmentów i wciąż nie jest idealny. Dlatego\nomówię go szczegółowo wskazując gdzie i na jakie kompromisy poszedłem\nprzygotowując go.\n\nNajbardziej problematyczna częścią jest tu zarządzanie zmiennymi środowiskowymi\ni sekretami. W obecnej formie w repozytorium znajdują się pliki .env, .env.prod \noraz .env.stag. Dwa ostatnie nadpisują ustawienia z pierwszego. Pierwszy task\n\"Prepare env\" odpowiada za zbudowanie pliku .env.stag.build lub .env.prod.build.\n\n- name: Merge Env\n  hosts: local\n  connection: local\n  tags:\n    - deploy\n  tasks:\n    - name: Prepare env\n      shell: \"sort -u -t '=' -k 1,1 .env.{{env}} .env > .env.{{env}}.build\"\n\n\nDlaczego uważam, że to problematyczna część? Przede wszystkim dlatego, że w tych\nplikach znajdują się hasła i klucze. Jestem przekonany, że nie powinny się one\nznajdować w repozytorium, ale  problemy związane z ich bezpiecznym\nwspółdzieleniem w ramach organizacji nie zostały jeszcze rozwiązane.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-26T19:45:06.000Z",
            "updated_at": "2021-04-28T14:31:15.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "608879632fb35425592d0f97",
            "uuid": "1004940f-a730-45f0-8c68-3aee212066c5",
            "title": "Jak pobrałem dane o 4k firm w pół godziny",
            "slug": "jak-pobralem-dane-o-4k-firm-w-pol-minuty",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://rejestr.io/api-krs\",\"metadata\":{\"url\":\"https://rejestr.io/api-krs\",\"title\":\"Dokumentacja API | Rejestr.io\",\"description\":null,\"author\":null,\"publisher\":\"Rejestr.io\",\"thumbnail\":\"https://rejestr.io/img/logo.svg\",\"icon\":\"https://rejestr.io/apple-touch-icon.png\"}}],[\"code\",{\"code\":\"npx tsc --init\\nnpm init -y\\nnpm i --save-dev @types/node typescript ts-node chai @types/chai\\ntouch app.ts\"}],[\"code\",{\"code\":\"libreoffice --headless --convert-to csv raw/base.xlsx --outdir raw --infilter=csv:44,34,76\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://unix.stackexchange.com/questions/259361/specify-encoding-with-libreoffice-convert-to-csv\",\"metadata\":{\"url\":\"https://unix.stackexchange.com/questions/259361/specify-encoding-with-libreoffice-convert-to-csv\",\"title\":\"Specify encoding with libreoffice --convert-to csv\",\"description\":\"Excel files can be converted to CSV using: $ libreoffice --convert-to csv --headless --outdir dir file.xlsx Everything appears to work just fine. The encoding, though, is set to something wonky.\",\"author\":\"Scott Deerwester\",\"publisher\":\"Unix & Linux Stack Exchange\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon@2.png?v=32fb07f7ce26\",\"icon\":\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon.png?v=5cf7fe716a89\"}}],[\"code\",{\"code\":\"import fs from 'fs'\\nimport chai from 'chai'\\n\\nconst getCompanies = (): string[] => {\\n    const rawDir = process.cwd() + `/raw`\\n\\n    const companies = fs\\n        .readFileSync(rawDir + `/base.csv`)\\n        .toString()\\n        .split(`\\\\n`) // split to lines\\n        .map((line: string) => line.split(',')[1]) // get second column\\n        .filter(line => line) // only valid names\\n        .filter((line, index) => index); // excluded header with columns names\\n\\n    companies.forEach(company => {\\n        chai.expect(company).to.be.a('string')\\n    })\\n\\n    return companies;\\n}\\n\\nconsole.dir(getCompanies(), {depth: Infinity, maxArrayLength: Infinity})\"}],[\"code\",{\"code\":\"npx ts-node app.ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-27-23-20-39.png\",\"width\":948,\"height\":774}],[\"code\",{\"code\":\"API_KEY=95772018-xxx\"}],[\"code\",{\"code\":\"include .env\\nexport\\n\\nnode_modules: package.json \\n\\tnpm i\\n\\nup: node_modules\\n\\tnpx ts-node app.ts\"}],[\"code\",{\"code\":\"npm i axios\"}],[\"code\",{\"code\":\"curl https://rejestr.io/api/v1/krs?name=energia --header \\\"Authorization: aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee\\\"\"}],[\"code\",{\"code\":\"import fs from 'fs'\\nimport chai from 'chai'\\nimport axios from \\\"axios\\\";\\n\\nconst getCompanies = (): string[] => {\\n    const rawDir = process.cwd() + `/raw`\\n\\n    const companies = fs\\n        .readFileSync(rawDir + `/base.csv`)\\n        .toString()\\n        .split(`\\\\n`)\\n        .map((line: string) => line.split(',')[1])\\n        .filter(line => line)\\n        .filter((line, index) => index);\\n\\n    companies.forEach(company => {\\n        chai.expect(company).to.be.a('string')\\n    })\\n\\n    return companies;\\n}\\n\\nconst main = async () => {\\n    const companies = getCompanies();\\n\\n    const {data} = await axios.get(`https://rejestr.io/api/v1/krs`, {\\n            params: {\\n                name: companies[0]\\n            },\\n            headers: {\\n                Authorization: process.env.API_KEY\\n            }\\n        }\\n    )\\n\\n    return {name: companies[0], data}\\n}\\n\\nmain()\\n    .then(res => console.dir(res, {depth: Infinity, maxArrayLength: Infinity}))\\n    .catch(console.error)\"}],[\"code\",{\"code\":\"make up\"}],[\"code\",{\"code\":\"{\\n  name: 'Grupa Kapitałowa POLSKIE GÓRNICTWO NAFTOWE I GAZOWNICTWO SPÓŁKA AKCYJNA',\\n  data: { total: 0, items: [] }\\n}\\n\",\"language\":\"json\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-27-23-39-42.png\",\"width\":799,\"height\":258}],[\"image\",{\"caption\":\"\",\"src\":\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-27-23-41-57.png\",\"width\":738,\"height\":736}],[\"code\",{\"code\":\"const getCompanies = (): string[] => {\\n    const rawDir = process.cwd() + `/raw`\\n\\n    const companies = fs\\n        .readFileSync(rawDir + `/base.csv`)\\n        .toString()\\n        .split(`\\\\n`)\\n        .map((line: string) => line.split(',')[1])\\n        .filter(line => line)\\n        .filter((line, index) => index)\\n        .map(name => name.replace(/(SPÓŁKA AKCYJNA)|(SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ)|(KOMANDYTOWA)/g,'').trim())\\n\\n    companies.forEach(company => {\\n        chai.expect(company).to.be.a('string')\\n    })\\n\\n    return companies;\\n}\"}],[\"code\",{\"code\":\"npm i mongodb chalk @types/mongodb\"}],[\"code\",{\"code\":\"import fs from 'fs'\\nimport chai from 'chai'\\nimport axios from \\\"axios\\\";\\nimport chalk from 'chalk';\\n\\nimport {MongoClient} from 'mongodb';\\n\\n// const url = \\\"mongodb://localhost:27017/krs\\\";\\nconst url = \\\"\\\";\\n\\nconst getDb = async ():Promise<any> => {\\n    return new Promise((resolve, reject) => {\\n        MongoClient.connect(url, {useUnifiedTopology: true}, (err, db) => {\\n            if (err) reject(err);\\n            resolve(db)\\n        });\\n    })\\n\\n}\\n\\n\\n\\nconst getCompanies = (): string[] => {\\n    const rawDir = process.cwd() + `/raw`\\n\\n    const companies = fs\\n        .readFileSync(rawDir + `/base.csv`)\\n        .toString()\\n        .split(`\\\\n`)\\n        .map((line: string) => line.split(',')[1])\\n        .filter(line => line)\\n        .filter((line, index) => index)\\n        .map(name => name.replace(/(SPÓŁKA AKCYJNA)|(SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ)|(KOMANDYTOWA)/g, '').trim())\\n\\n    companies.forEach(company => {\\n        chai.expect(company).to.be.a('string')\\n    })\\n\\n    return companies;\\n}\\n\\nconst main = async () => {\\n    const companies = getCompanies();\\n\\n    const time0 = new Date().getTime();\\n\\n\\n    const db = await getDb()\\n    db.db(\\\"krs\\\").collection('companies').createIndex({ name: 1 })\\n\\n    for(let i = 0; i< companies.length; i++) {\\n        const company = companies[i];\\n\\n        try {\\n            const {data} = await axios.get(`https://rejestr.io/api/v1/krs`, {\\n                    params: {\\n                        name: company\\n                    },\\n                    headers: {\\n                        Authorization: process.env.API_KEY\\n                    }\\n                }\\n            )\\n\\n            await db.db(\\\"krs\\\").collection('companies').insertOne({name: company, data})\\n\\n            const time = (new Date().getTime()) - time0;\\n\\n            if (data.total) {\\n                console.log(chalk.green(`${time}\\\\t${i}\\\\t${company}\\\\t\\\\t\\\\t${data.total}`));\\n            } else {\\n                console.log(chalk.red(`${time}\\\\t${i}\\\\t${company}\\\\t\\\\t\\\\t${data.total}`));\\n            }\\n        } catch (e) {\\n            console.log(chalk.red(e))\\n        }\\n    }\\n}\\n\\nmain().catch(console.error)\\n\\n\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-28-00-12-48.png\",\"width\":944,\"height\":508}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-28-00-28-51.png\",\"width\":945,\"height\":1033}],[\"code\",{\"code\":\"import fs from 'fs'\\nimport chai from 'chai'\\nimport axios from \\\"axios\\\";\\nimport chalk from 'chalk';\\n\\nimport {MongoClient} from 'mongodb';\\n\\nconst url = process.env.MONGO_URI || '';\\n\\nconst getDb = async ():Promise<any> => {\\n    return new Promise((resolve, reject) => {\\n        MongoClient.connect(url, {useUnifiedTopology: true}, (err, db) => {\\n            if (err) reject(err);\\n            resolve(db)\\n        });\\n    })\\n\\n}\\n\\n\\n\\nconst getCompanies = (): string[] => {\\n    const rawDir = process.cwd() + `/raw`\\n\\n    const companies = fs\\n        .readFileSync(rawDir + `/base.csv`)\\n        .toString()\\n        .split(`\\\\n`)\\n        .map((line: string) => line.split(',')[1])\\n        .filter(line => line)\\n        .filter((line, index) => index)\\n        .map(name => name.replace(/(SPÓŁKA AKCYJNA)|(SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ)|(KOMANDYTOWA)|(^Grupa Kapitałowa)|(OPERATOR)|(-GRUPA GDF SUEZ ENERGIA POLSKA)|(S\\\\.?A\\\\.?)|(WARSZAWA)|(STOEN)|(Sp\\\\. z o\\\\.o\\\\.)|(S\\\\.K\\\\.)|(G\\\\.K\\\\.)/ig, '').trim())\\n\\n    companies.forEach(company => {\\n        chai.expect(company).to.be.a('string')\\n    })\\n\\n    return [...new Set(companies)];\\n}\\n\\nconst main = async () => {\\n    const companies = getCompanies();\\n\\n    const time0 = new Date().getTime();\\n\\n\\n    const db = await getDb()\\n    db.db(\\\"krs\\\").collection('companies').createIndex({ name: 1 })\\n\\n    for(let i = 0; i< companies.length; i++) {\\n        const company = companies[i];\\n\\n        try {\\n            const existing = await db.db(\\\"krs\\\").collection('companies').findOne({name: company})\\n\\n            if(existing) {\\n                const time = (new Date().getTime()) - time0\\n                if (existing.data.total) {\\n                    console.log(chalk.yellow(`${time}\\\\t${i}\\\\t${existing.data.total}\\\\t${company}\\\\tSKIPPED`));\\n                } else {\\n                    console.log(chalk.red(`${time}\\\\t${i}\\\\t${existing.data.total}\\\\t${company}`));\\n                }\\n                continue;\\n            }\\n\\n            const {data} = await axios.get(`https://rejestr.io/api/v1/krs`, {\\n                    params: {\\n                        name: company\\n                    },\\n                    headers: {\\n                        Authorization: process.env.API_KEY\\n                    }\\n                }\\n            )\\n\\n            await db.db(\\\"krs\\\").collection('companies').insertOne({name: company, data})\\n\\n            const time = (new Date().getTime()) - time0;\\n\\n            if (data.total) {\\n                console.log(chalk.green(`${time}\\\\t${i}\\\\t${data.total}\\\\t${company}`));\\n            } else {\\n                console.log(chalk.red(`${time}\\\\t${i}\\\\t${data.total}\\\\t${company}`));\\n            }\\n        } catch (e) {\\n            console.log(chalk.red(e))\\n        }\\n    }\\n}\\n\\nmain().catch(console.error)\\n\\n\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-28-00-40-49.png\",\"width\":738,\"height\":483}]],\"markups\":[[\"code\"],[\"a\",[\"href\",\"http://www.imsig.pl/szukaj/krs,45812,PRZEDSI%C4%98BIORSTWO_GOSPODARKI_KOMUNALNEJ_SP%C3%93%C5%81KA_Z_OGRANICZON%C4%84_ODPOWIEDZIALNO%C5%9ACI%C4%84\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"O firmach wiedziałem tylko jak się nazywają. Potrzebowałem ich adresów, ...\"]]],[1,\"p\",[[0,[],0,\"Żeby to osiągnąć wydałem 20 zł w rejestr.io na dostęp do 10k żądań api. Dostałem klucz. Dokumentacja Rejestr.io dostępna jest pod linkiem:\"]]],[10,0],[1,\"h2\",[[0,[],0,\"Przygotowanie danych wejściowych\"]]],[1,\"p\",[[0,[],0,\"Zaczynamy od standardowego przygotowania projektu w typescript:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Plik źródłowy to xlsx z nazwami firm w katalogu \"],[0,[0],1,\"raw/base.xlsx\"]]],[1,\"p\",[[0,[],0,\"Konwertujemy go do \"],[0,[0],1,\"csv\"],[0,[],0,\" poleceniem:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Zagadkowa flaga \"],[0,[0],1,\"infilter\"],[0,[],0,\" pozwala konwertować do formatu UTF-8 z poprawną obsługą polskich znaków. Więcej na jej temat możecie poczytać pod linkiem:\"]]],[10,3],[1,\"p\",[[0,[],0,\"Ten plik odczytujemy w skrypcie linia po linii i dzielimy ze względu na przecinki, tak aby dostać tablicę z samymi nazwami firm.\"]]],[1,\"p\",[[0,[],0,\"Ten bardzo prosty kod:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Pozwala po wykonaniu go komendą\"]]],[10,5],[1,\"p\",[[0,[],0,\"zobaczyć listę firm\"]]],[10,6],[1,\"h2\",[[0,[],0,\"Pobranie danych o firmach z KRS\"]]],[1,\"p\",[[0,[],0,\"Zgodnie z dokumentacją Rejestr.io zbudujemy zapytania, które pozwolą pobrać dane firm. Zaczniemy od zapisania klucza API w pliku \"],[0,[0],1,\".env\"]]],[10,7],[1,\"p\",[[0,[],0,\"Aby pobierać zmienne środowiskowe możemy używać basha, albo bibliotek takich jak \"],[0,[0],1,\"dotenv\"],[0,[],0,\", ale preferuję dwie linie w konfiguracji \"],[0,[0],1,\"makefile\"],[0,[],0,\". Na przykład taki \"],[0,[0],1,\"Makefile\"],[0,[],0,\":\"]]],[10,8],[1,\"p\",[[0,[],0,\"Jego zalety to:\"]]],[3,\"ul\",[[[0,[],0,\"wpisujemy \"],[0,[0],1,\"make up\"],[0,[],0,\" i nie martwimy się o zmienne środowiskowe\"]],[[0,[],0,\"nie martwimy się o instalację paczek\"]],[[0,[],0,\"za nas przeinstalowuje paczki po aktualizacji \"],[0,[0],1,\"package.json\"]]]],[1,\"p\",[[0,[],0,\"Aby wysyłać żądania http użyjemy biblioteki \"],[0,[0],1,\"axios\"],[0,[],0,\". Instalujemy ją komendą:\"]]],[10,9],[1,\"p\",[[0,[],0,\"Polecenie pobierające dane organizacji opisane w dokumentacji wygląda tak:\"]]],[10,10],[1,\"p\",[[0,[],0,\" Szuka ono organizacji w KRS po nazwie zawierającej słowo \\\"energia\\\".\"]]],[1,\"p\",[[0,[],0,\"Po przepisaniu do \"],[0,[0],1,\"node-js\"],[0,[],0,\" dostaniemy kod:\"]]],[10,11],[1,\"p\",[[0,[],0,\"Rozczarowujące może być to, że uruchamiając kod komendą \"]]],[10,12],[1,\"p\",[[0,[],0,\"zobaczymy\"]]],[10,13],[1,\"p\",[[0,[],0,\"Wynika to z własności wyszukiwarki \"],[0,[0],1,\"rejestr.io\"],[0,[],0,\" która nie zwraca poprawnych wyników jeśli nazwy zawierają typ podmiotu, np rodzaj spółki\"]]],[10,14],[1,\"p\",[[0,[],0,\"Po wycięciu \"],[0,[0],1,\"SPÓŁKA AKCYJNA\"],[0,[],0,\" zobaczymy poprawne wyniki\"]]],[10,15],[1,\"p\",[[0,[],0,\"Do naszej funkcji \"],[0,[0],1,\"getCompanies\"],[0,[],0,\" aplikujemy poprawkę wycinającą typy podmiotów. Teraz funkcja ta przyjmie postać:\"]]],[10,16],[1,\"p\",[[0,[],0,\"W tej chwili cały skrypt celowo analizuje jedynie pierwszą firmę. Od pobrania danych dla wszystkich dzieli nas jedynie dopisanie jednej pętli. Jednak z doświadczenia wiemy, że dla niektórych firm będzie trzeba powtórzyć zapytanie, ponieważ prawdopodobnie w nazwach są błędy, albo wyszukiwarka nie zwróci poprawnego wyniku.\"]]],[1,\"h2\",[[0,[],0,\"Podłączenie do bazy i zapis wyników\"]]],[1,\"p\",[[0,[],0,\"Aby jednocześnie móc zapisać pobrane dane warto podłączyć system do bazy. Jest wiele dostępnych baz danych, ale do tego zadania preferuję \"],[0,[0],1,\"MongoDB\"],[0,[],0,\" z uwagi na łatwość wykonywania w niej agregacji, prostotę eksportu do formatów \"],[0,[0],1,\"json\"],[0,[],0,\" i \"],[0,[0],1,\"xlsx\"],[0,[],0,\" oraz brak konieczności definiowania schematu.\"]]],[1,\"p\",[[0,[],0,\"Zainstalujemy sterowniki \"],[0,[0],1,\"node-js\"],[0,[],0,\" dla mongo i bibliotekę do kolorowania wyników w konsoli:\"]]],[10,17],[1,\"p\",[[0,[],0,\"Podłączenie do bazy wykonamy za pomocą kodu:\"]]],[10,18],[1,\"p\",[[0,[],0,\"Okazuje się, że nie wszystkie firmy pobieramy prawidłowo:\"]]],[10,19],[1,\"p\",[[0,[],0,\"Powtarza się ten sam motyw co ze spółką akcyjną. \"],[0,[0],1,\"Grupa Kapitałowa\"],[0,[],0,\" powoduje, że firma jest źle wyszukiwana. Podobnie \"],[0,[0],1,\"OPERATOR\"],[0,[],0,\" występujące na końcu nazwy.\"]]],[1,\"p\",[[0,[],0,\"Po kilku poprawkach i wykluczeniu paru losowo wybranych nazw mamy około 15% odrzuceń. Baza firm przygotowywana była ręcznie i przez to konwencje nazw różnią się od tych oficjalnych w Rejestr.io.\"]]],[1,\"p\",[[0,[],0,\"Kolejne kolumny to:\"]]],[3,\"ul\",[[[0,[],0,\"czas od włączenia programu\"]],[[0,[],0,\"numer porządkowy (liczony od 0)\"]],[[0,[],0,\"ilość firm dopasowanych w Rejestr.io\"]]]],[10,20],[1,\"p\",[[0,[],0,\"O słabej jakości bazy świadczą takie kwiatki jak:\"]]],[1,\"blockquote\",[[0,[1],1,\"PRZEDSIĘBIORSTWO GOSPODARKI KOMUNALNEJ SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ\"]]],[1,\"p\",[[0,[],0,\"Prawdopodobnie w prawie każdym szanującym się miasteczku mieści się firma o takiej nazwie.\"]]],[1,\"p\",[[0,[],0,\"Kod w tej chwili prezentuje się tak:\"]]],[10,21],[1,\"p\",[[0,[],0,\"Jego mocne strony to:\"]]],[3,\"ul\",[[[0,[],0,\"oszczędzamy requesty do API, jeśli mamy nazwę, która ma już dopasowania, to nie jest dalej przetwarzana.\"]],[[0,[],0,\"dane zapisywane są tak, aby nie było duplikatów\"]]]],[1,\"p\",[[0,[],0,\"Niestety w pobranych danych nie ma kapitału zakładowego. Przykładowy obiekt ma dane: \"]]],[10,22],[1,\"h2\",[[0,[],0,\"Szczegółowe zapytania\"]]],[1,\"p\",[[0,[],0,\"Kolejnym krokiem będzie zapomnienie o firmach, których nie udało się zeskanować. Niektórych wyników jak \"],[0,[0],1,\"INSTYTUT CHEMII BIOORGANICZNEJ POLSKIEJ AKADEMII NAUK\"],[0,[],0,\" nie da się uratować. Dopiero manualny research pozwala stwierdzić, że rejestr io zapisuje to jako \"],[0,[0],1,\"FUNDACJA ICHB PAN\"],[0,[],0,\", ale nie możemy nauczyć algorytmu poprawnego nazywania wszystkich firm z bazy.\"]]],[1,\"p\",[[0,[],0,\"Dlatego godząc się z tym, że pobraliśmy tylko część wyciągniemy konkretne numery KRS i identyfikatory firm i na tej podstawie zapytamy o dane szczegółowe.\"]]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>O firmach wiedziałem tylko jak się nazywają. Potrzebowałem ich adresów, ...</p><p>Żeby to osiągnąć wydałem 20 zł w rejestr.io na dostęp do 10k żądań api. Dostałem klucz. Dokumentacja Rejestr.io dostępna jest pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://rejestr.io/api-krs\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Dokumentacja API | Rejestr.io</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://rejestr.io/apple-touch-icon.png\"><span class=\"kg-bookmark-author\">Rejestr.io</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://rejestr.io/img/logo.svg\"></div></a></figure><h2 id=\"przygotowanie-danych-wej%C5%9Bciowych\">Przygotowanie danych wejściowych</h2><p>Zaczynamy od standardowego przygotowania projektu w typescript:</p><pre><code>npx tsc --init\nnpm init -y\nnpm i --save-dev @types/node typescript ts-node chai @types/chai\ntouch app.ts</code></pre><p>Plik źródłowy to xlsx z nazwami firm w katalogu <code>raw/base.xlsx</code></p><p>Konwertujemy go do <code>csv</code> poleceniem:</p><pre><code>libreoffice --headless --convert-to csv raw/base.xlsx --outdir raw --infilter=csv:44,34,76</code></pre><p>Zagadkowa flaga <code>infilter</code> pozwala konwertować do formatu UTF-8 z poprawną obsługą polskich znaków. Więcej na jej temat możecie poczytać pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://unix.stackexchange.com/questions/259361/specify-encoding-with-libreoffice-convert-to-csv\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Specify encoding with libreoffice --convert-to csv</div><div class=\"kg-bookmark-description\">Excel files can be converted to CSV using: $ libreoffice --convert-to csv --headless --outdir dir file.xlsx Everything appears to work just fine. The encoding, though, is set to something wonky.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon.png?v&#x3D;5cf7fe716a89\"><span class=\"kg-bookmark-author\">Unix &amp; Linux Stack Exchange</span><span class=\"kg-bookmark-publisher\">Scott Deerwester</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon@2.png?v&#x3D;32fb07f7ce26\"></div></a></figure><p>Ten plik odczytujemy w skrypcie linia po linii i dzielimy ze względu na przecinki, tak aby dostać tablicę z samymi nazwami firm.</p><p>Ten bardzo prosty kod:</p><pre><code>import fs from 'fs'\nimport chai from 'chai'\n\nconst getCompanies = (): string[] =&gt; {\n    const rawDir = process.cwd() + `/raw`\n\n    const companies = fs\n        .readFileSync(rawDir + `/base.csv`)\n        .toString()\n        .split(`\\n`) // split to lines\n        .map((line: string) =&gt; line.split(',')[1]) // get second column\n        .filter(line =&gt; line) // only valid names\n        .filter((line, index) =&gt; index); // excluded header with columns names\n\n    companies.forEach(company =&gt; {\n        chai.expect(company).to.be.a('string')\n    })\n\n    return companies;\n}\n\nconsole.dir(getCompanies(), {depth: Infinity, maxArrayLength: Infinity})</code></pre><p>Pozwala po wykonaniu go komendą</p><pre><code>npx ts-node app.ts</code></pre><p>zobaczyć listę firm</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-27-23-20-39.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"948\" height=\"774\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Zrzut-ekranu-z-2021-04-27-23-20-39.png 600w, __GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-27-23-20-39.png 948w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"pobranie-danych-o-firmach-z-krs\">Pobranie danych o firmach z KRS</h2><p>Zgodnie z dokumentacją Rejestr.io zbudujemy zapytania, które pozwolą pobrać dane firm. Zaczniemy od zapisania klucza API w pliku <code>.env</code></p><pre><code>API_KEY=95772018-xxx</code></pre><p>Aby pobierać zmienne środowiskowe możemy używać basha, albo bibliotek takich jak <code>dotenv</code>, ale preferuję dwie linie w konfiguracji <code>makefile</code>. Na przykład taki <code>Makefile</code>:</p><pre><code>include .env\nexport\n\nnode_modules: package.json \n\tnpm i\n\nup: node_modules\n\tnpx ts-node app.ts</code></pre><p>Jego zalety to:</p><ul><li>wpisujemy <code>make up</code> i nie martwimy się o zmienne środowiskowe</li><li>nie martwimy się o instalację paczek</li><li>za nas przeinstalowuje paczki po aktualizacji <code>package.json</code></li></ul><p>Aby wysyłać żądania http użyjemy biblioteki <code>axios</code>. Instalujemy ją komendą:</p><pre><code>npm i axios</code></pre><p>Polecenie pobierające dane organizacji opisane w dokumentacji wygląda tak:</p><pre><code>curl https://rejestr.io/api/v1/krs?name=energia --header \"Authorization: aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee\"</code></pre><p> Szuka ono organizacji w KRS po nazwie zawierającej słowo \"energia\".</p><p>Po przepisaniu do <code>node-js</code> dostaniemy kod:</p><pre><code>import fs from 'fs'\nimport chai from 'chai'\nimport axios from \"axios\";\n\nconst getCompanies = (): string[] =&gt; {\n    const rawDir = process.cwd() + `/raw`\n\n    const companies = fs\n        .readFileSync(rawDir + `/base.csv`)\n        .toString()\n        .split(`\\n`)\n        .map((line: string) =&gt; line.split(',')[1])\n        .filter(line =&gt; line)\n        .filter((line, index) =&gt; index);\n\n    companies.forEach(company =&gt; {\n        chai.expect(company).to.be.a('string')\n    })\n\n    return companies;\n}\n\nconst main = async () =&gt; {\n    const companies = getCompanies();\n\n    const {data} = await axios.get(`https://rejestr.io/api/v1/krs`, {\n            params: {\n                name: companies[0]\n            },\n            headers: {\n                Authorization: process.env.API_KEY\n            }\n        }\n    )\n\n    return {name: companies[0], data}\n}\n\nmain()\n    .then(res =&gt; console.dir(res, {depth: Infinity, maxArrayLength: Infinity}))\n    .catch(console.error)</code></pre><p>Rozczarowujące może być to, że uruchamiając kod komendą </p><pre><code>make up</code></pre><p>zobaczymy</p><pre><code class=\"language-json\">{\n  name: 'Grupa Kapitałowa POLSKIE GÓRNICTWO NAFTOWE I GAZOWNICTWO SPÓŁKA AKCYJNA',\n  data: { total: 0, items: [] }\n}\n</code></pre><p>Wynika to z własności wyszukiwarki <code>rejestr.io</code> która nie zwraca poprawnych wyników jeśli nazwy zawierają typ podmiotu, np rodzaj spółki</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-27-23-39-42.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"799\" height=\"258\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Zrzut-ekranu-z-2021-04-27-23-39-42.png 600w, __GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-27-23-39-42.png 799w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Po wycięciu <code>SPÓŁKA AKCYJNA</code> zobaczymy poprawne wyniki</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-27-23-41-57.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"738\" height=\"736\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Zrzut-ekranu-z-2021-04-27-23-41-57.png 600w, __GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-27-23-41-57.png 738w\" sizes=\"(min-width: 720px) 720px\"><figcaption></figcaption></figure><p>Do naszej funkcji <code>getCompanies</code> aplikujemy poprawkę wycinającą typy podmiotów. Teraz funkcja ta przyjmie postać:</p><pre><code>const getCompanies = (): string[] =&gt; {\n    const rawDir = process.cwd() + `/raw`\n\n    const companies = fs\n        .readFileSync(rawDir + `/base.csv`)\n        .toString()\n        .split(`\\n`)\n        .map((line: string) =&gt; line.split(',')[1])\n        .filter(line =&gt; line)\n        .filter((line, index) =&gt; index)\n        .map(name =&gt; name.replace(/(SPÓŁKA AKCYJNA)|(SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ)|(KOMANDYTOWA)/g,'').trim())\n\n    companies.forEach(company =&gt; {\n        chai.expect(company).to.be.a('string')\n    })\n\n    return companies;\n}</code></pre><p>W tej chwili cały skrypt celowo analizuje jedynie pierwszą firmę. Od pobrania danych dla wszystkich dzieli nas jedynie dopisanie jednej pętli. Jednak z doświadczenia wiemy, że dla niektórych firm będzie trzeba powtórzyć zapytanie, ponieważ prawdopodobnie w nazwach są błędy, albo wyszukiwarka nie zwróci poprawnego wyniku.</p><h2 id=\"pod%C5%82%C4%85czenie-do-bazy-i-zapis-wynik%C3%B3w\">Podłączenie do bazy i zapis wyników</h2><p>Aby jednocześnie móc zapisać pobrane dane warto podłączyć system do bazy. Jest wiele dostępnych baz danych, ale do tego zadania preferuję <code>MongoDB</code> z uwagi na łatwość wykonywania w niej agregacji, prostotę eksportu do formatów <code>json</code> i <code>xlsx</code> oraz brak konieczności definiowania schematu.</p><p>Zainstalujemy sterowniki <code>node-js</code> dla mongo i bibliotekę do kolorowania wyników w konsoli:</p><pre><code>npm i mongodb chalk @types/mongodb</code></pre><p>Podłączenie do bazy wykonamy za pomocą kodu:</p><pre><code>import fs from 'fs'\nimport chai from 'chai'\nimport axios from \"axios\";\nimport chalk from 'chalk';\n\nimport {MongoClient} from 'mongodb';\n\n// const url = \"mongodb://localhost:27017/krs\";\nconst url = \"\";\n\nconst getDb = async ():Promise&lt;any&gt; =&gt; {\n    return new Promise((resolve, reject) =&gt; {\n        MongoClient.connect(url, {useUnifiedTopology: true}, (err, db) =&gt; {\n            if (err) reject(err);\n            resolve(db)\n        });\n    })\n\n}\n\n\n\nconst getCompanies = (): string[] =&gt; {\n    const rawDir = process.cwd() + `/raw`\n\n    const companies = fs\n        .readFileSync(rawDir + `/base.csv`)\n        .toString()\n        .split(`\\n`)\n        .map((line: string) =&gt; line.split(',')[1])\n        .filter(line =&gt; line)\n        .filter((line, index) =&gt; index)\n        .map(name =&gt; name.replace(/(SPÓŁKA AKCYJNA)|(SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ)|(KOMANDYTOWA)/g, '').trim())\n\n    companies.forEach(company =&gt; {\n        chai.expect(company).to.be.a('string')\n    })\n\n    return companies;\n}\n\nconst main = async () =&gt; {\n    const companies = getCompanies();\n\n    const time0 = new Date().getTime();\n\n\n    const db = await getDb()\n    db.db(\"krs\").collection('companies').createIndex({ name: 1 })\n\n    for(let i = 0; i&lt; companies.length; i++) {\n        const company = companies[i];\n\n        try {\n            const {data} = await axios.get(`https://rejestr.io/api/v1/krs`, {\n                    params: {\n                        name: company\n                    },\n                    headers: {\n                        Authorization: process.env.API_KEY\n                    }\n                }\n            )\n\n            await db.db(\"krs\").collection('companies').insertOne({name: company, data})\n\n            const time = (new Date().getTime()) - time0;\n\n            if (data.total) {\n                console.log(chalk.green(`${time}\\t${i}\\t${company}\\t\\t\\t${data.total}`));\n            } else {\n                console.log(chalk.red(`${time}\\t${i}\\t${company}\\t\\t\\t${data.total}`));\n            }\n        } catch (e) {\n            console.log(chalk.red(e))\n        }\n    }\n}\n\nmain().catch(console.error)\n\n</code></pre><p>Okazuje się, że nie wszystkie firmy pobieramy prawidłowo:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-28-00-12-48.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"944\" height=\"508\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Zrzut-ekranu-z-2021-04-28-00-12-48.png 600w, __GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-28-00-12-48.png 944w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Powtarza się ten sam motyw co ze spółką akcyjną. <code>Grupa Kapitałowa</code> powoduje, że firma jest źle wyszukiwana. Podobnie <code>OPERATOR</code> występujące na końcu nazwy.</p><p>Po kilku poprawkach i wykluczeniu paru losowo wybranych nazw mamy około 15% odrzuceń. Baza firm przygotowywana była ręcznie i przez to konwencje nazw różnią się od tych oficjalnych w Rejestr.io.</p><p>Kolejne kolumny to:</p><ul><li>czas od włączenia programu</li><li>numer porządkowy (liczony od 0)</li><li>ilość firm dopasowanych w Rejestr.io</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-28-00-28-51.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"945\" height=\"1033\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Zrzut-ekranu-z-2021-04-28-00-28-51.png 600w, __GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-28-00-28-51.png 945w\" sizes=\"(min-width: 720px) 720px\"></figure><p>O słabej jakości bazy świadczą takie kwiatki jak:</p><blockquote><a href=\"http://www.imsig.pl/szukaj/krs,45812,PRZEDSI%C4%98BIORSTWO_GOSPODARKI_KOMUNALNEJ_SP%C3%93%C5%81KA_Z_OGRANICZON%C4%84_ODPOWIEDZIALNO%C5%9ACI%C4%84\">PRZEDSIĘBIORSTWO GOSPODARKI KOMUNALNEJ SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ</a></blockquote><p>Prawdopodobnie w prawie każdym szanującym się miasteczku mieści się firma o takiej nazwie.</p><p>Kod w tej chwili prezentuje się tak:</p><pre><code>import fs from 'fs'\nimport chai from 'chai'\nimport axios from \"axios\";\nimport chalk from 'chalk';\n\nimport {MongoClient} from 'mongodb';\n\nconst url = process.env.MONGO_URI || '';\n\nconst getDb = async ():Promise&lt;any&gt; =&gt; {\n    return new Promise((resolve, reject) =&gt; {\n        MongoClient.connect(url, {useUnifiedTopology: true}, (err, db) =&gt; {\n            if (err) reject(err);\n            resolve(db)\n        });\n    })\n\n}\n\n\n\nconst getCompanies = (): string[] =&gt; {\n    const rawDir = process.cwd() + `/raw`\n\n    const companies = fs\n        .readFileSync(rawDir + `/base.csv`)\n        .toString()\n        .split(`\\n`)\n        .map((line: string) =&gt; line.split(',')[1])\n        .filter(line =&gt; line)\n        .filter((line, index) =&gt; index)\n        .map(name =&gt; name.replace(/(SPÓŁKA AKCYJNA)|(SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ)|(KOMANDYTOWA)|(^Grupa Kapitałowa)|(OPERATOR)|(-GRUPA GDF SUEZ ENERGIA POLSKA)|(S\\.?A\\.?)|(WARSZAWA)|(STOEN)|(Sp\\. z o\\.o\\.)|(S\\.K\\.)|(G\\.K\\.)/ig, '').trim())\n\n    companies.forEach(company =&gt; {\n        chai.expect(company).to.be.a('string')\n    })\n\n    return [...new Set(companies)];\n}\n\nconst main = async () =&gt; {\n    const companies = getCompanies();\n\n    const time0 = new Date().getTime();\n\n\n    const db = await getDb()\n    db.db(\"krs\").collection('companies').createIndex({ name: 1 })\n\n    for(let i = 0; i&lt; companies.length; i++) {\n        const company = companies[i];\n\n        try {\n            const existing = await db.db(\"krs\").collection('companies').findOne({name: company})\n\n            if(existing) {\n                const time = (new Date().getTime()) - time0\n                if (existing.data.total) {\n                    console.log(chalk.yellow(`${time}\\t${i}\\t${existing.data.total}\\t${company}\\tSKIPPED`));\n                } else {\n                    console.log(chalk.red(`${time}\\t${i}\\t${existing.data.total}\\t${company}`));\n                }\n                continue;\n            }\n\n            const {data} = await axios.get(`https://rejestr.io/api/v1/krs`, {\n                    params: {\n                        name: company\n                    },\n                    headers: {\n                        Authorization: process.env.API_KEY\n                    }\n                }\n            )\n\n            await db.db(\"krs\").collection('companies').insertOne({name: company, data})\n\n            const time = (new Date().getTime()) - time0;\n\n            if (data.total) {\n                console.log(chalk.green(`${time}\\t${i}\\t${data.total}\\t${company}`));\n            } else {\n                console.log(chalk.red(`${time}\\t${i}\\t${data.total}\\t${company}`));\n            }\n        } catch (e) {\n            console.log(chalk.red(e))\n        }\n    }\n}\n\nmain().catch(console.error)\n\n</code></pre><p>Jego mocne strony to:</p><ul><li>oszczędzamy requesty do API, jeśli mamy nazwę, która ma już dopasowania, to nie jest dalej przetwarzana.</li><li>dane zapisywane są tak, aby nie było duplikatów</li></ul><p>Niestety w pobranych danych nie ma kapitału zakładowego. Przykładowy obiekt ma dane: </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-28-00-40-49.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"738\" height=\"483\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Zrzut-ekranu-z-2021-04-28-00-40-49.png 600w, __GHOST_URL__/content/images/2021/04/Zrzut-ekranu-z-2021-04-28-00-40-49.png 738w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"szczeg%C3%B3%C5%82owe-zapytania\">Szczegółowe zapytania</h2><p>Kolejnym krokiem będzie zapomnienie o firmach, których nie udało się zeskanować. Niektórych wyników jak <code>INSTYTUT CHEMII BIOORGANICZNEJ POLSKIEJ AKADEMII NAUK</code> nie da się uratować. Dopiero manualny research pozwala stwierdzić, że rejestr io zapisuje to jako <code>FUNDACJA ICHB PAN</code>, ale nie możemy nauczyć algorytmu poprawnego nazywania wszystkich firm z bazy.</p><p>Dlatego godząc się z tym, że pobraliśmy tylko część wyciągniemy konkretne numery KRS i identyfikatory firm i na tej podstawie zapytamy o dane szczegółowe.</p>",
            "comment_id": "608879632fb35425592d0f97",
            "plaintext": "O firmach wiedziałem tylko jak się nazywają. Potrzebowałem ich adresów, ...\n\nŻeby to osiągnąć wydałem 20 zł w rejestr.io na dostęp do 10k żądań api. Dostałem\nklucz. Dokumentacja Rejestr.io dostępna jest pod linkiem:\n\nDokumentacja API | Rejestr.ioRejestr.io [https://rejestr.io/api-krs]\nPrzygotowanie danych wejściowych\nZaczynamy od standardowego przygotowania projektu w typescript:\n\nnpx tsc --init\nnpm init -y\nnpm i --save-dev @types/node typescript ts-node chai @types/chai\ntouch app.ts\n\nPlik źródłowy to xlsx z nazwami firm w katalogu raw/base.xlsx\n\nKonwertujemy go do csv poleceniem:\n\nlibreoffice --headless --convert-to csv raw/base.xlsx --outdir raw --infilter=csv:44,34,76\n\nZagadkowa flaga infilter pozwala konwertować do formatu UTF-8 z poprawną obsługą\npolskich znaków. Więcej na jej temat możecie poczytać pod linkiem:\n\nSpecify encoding with libreoffice --convert-to csvExcel files can be converted\nto CSV using: $ libreoffice --convert-to csv --headless --outdir dir file.xlsx\nEverything appears to work just fine. The encoding, though, is set to something\nwonky.Unix & Linux Stack ExchangeScott Deerwester\n[https://unix.stackexchange.com/questions/259361/specify-encoding-with-libreoffice-convert-to-csv]\nTen plik odczytujemy w skrypcie linia po linii i dzielimy ze względu na\nprzecinki, tak aby dostać tablicę z samymi nazwami firm.\n\nTen bardzo prosty kod:\n\nimport fs from 'fs'\nimport chai from 'chai'\n\nconst getCompanies = (): string[] => {\n    const rawDir = process.cwd() + `/raw`\n\n    const companies = fs\n        .readFileSync(rawDir + `/base.csv`)\n        .toString()\n        .split(`\\n`) // split to lines\n        .map((line: string) => line.split(',')[1]) // get second column\n        .filter(line => line) // only valid names\n        .filter((line, index) => index); // excluded header with columns names\n\n    companies.forEach(company => {\n        chai.expect(company).to.be.a('string')\n    })\n\n    return companies;\n}\n\nconsole.dir(getCompanies(), {depth: Infinity, maxArrayLength: Infinity})\n\nPozwala po wykonaniu go komendą\n\nnpx ts-node app.ts\n\nzobaczyć listę firm\n\nPobranie danych o firmach z KRS\nZgodnie z dokumentacją Rejestr.io zbudujemy zapytania, które pozwolą pobrać dane\nfirm. Zaczniemy od zapisania klucza API w pliku .env\n\nAPI_KEY=95772018-xxx\n\nAby pobierać zmienne środowiskowe możemy używać basha, albo bibliotek takich jak \ndotenv, ale preferuję dwie linie w konfiguracji makefile. Na przykład taki \nMakefile:\n\ninclude .env\nexport\n\nnode_modules: package.json \n\tnpm i\n\nup: node_modules\n\tnpx ts-node app.ts\n\nJego zalety to:\n\n * wpisujemy make up i nie martwimy się o zmienne środowiskowe\n * nie martwimy się o instalację paczek\n * za nas przeinstalowuje paczki po aktualizacji package.json\n\nAby wysyłać żądania http użyjemy biblioteki axios. Instalujemy ją komendą:\n\nnpm i axios\n\nPolecenie pobierające dane organizacji opisane w dokumentacji wygląda tak:\n\ncurl https://rejestr.io/api/v1/krs?name=energia --header \"Authorization: aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee\"\n\n Szuka ono organizacji w KRS po nazwie zawierającej słowo \"energia\".\n\nPo przepisaniu do node-js dostaniemy kod:\n\nimport fs from 'fs'\nimport chai from 'chai'\nimport axios from \"axios\";\n\nconst getCompanies = (): string[] => {\n    const rawDir = process.cwd() + `/raw`\n\n    const companies = fs\n        .readFileSync(rawDir + `/base.csv`)\n        .toString()\n        .split(`\\n`)\n        .map((line: string) => line.split(',')[1])\n        .filter(line => line)\n        .filter((line, index) => index);\n\n    companies.forEach(company => {\n        chai.expect(company).to.be.a('string')\n    })\n\n    return companies;\n}\n\nconst main = async () => {\n    const companies = getCompanies();\n\n    const {data} = await axios.get(`https://rejestr.io/api/v1/krs`, {\n            params: {\n                name: companies[0]\n            },\n            headers: {\n                Authorization: process.env.API_KEY\n            }\n        }\n    )\n\n    return {name: companies[0], data}\n}\n\nmain()\n    .then(res => console.dir(res, {depth: Infinity, maxArrayLength: Infinity}))\n    .catch(console.error)\n\nRozczarowujące może być to, że uruchamiając kod komendą \n\nmake up\n\nzobaczymy\n\n{\n  name: 'Grupa Kapitałowa POLSKIE GÓRNICTWO NAFTOWE I GAZOWNICTWO SPÓŁKA AKCYJNA',\n  data: { total: 0, items: [] }\n}\n\n\nWynika to z własności wyszukiwarki rejestr.io która nie zwraca poprawnych\nwyników jeśli nazwy zawierają typ podmiotu, np rodzaj spółki\n\nPo wycięciu SPÓŁKA AKCYJNA zobaczymy poprawne wyniki\n\nDo naszej funkcji getCompanies aplikujemy poprawkę wycinającą typy podmiotów.\nTeraz funkcja ta przyjmie postać:\n\nconst getCompanies = (): string[] => {\n    const rawDir = process.cwd() + `/raw`\n\n    const companies = fs\n        .readFileSync(rawDir + `/base.csv`)\n        .toString()\n        .split(`\\n`)\n        .map((line: string) => line.split(',')[1])\n        .filter(line => line)\n        .filter((line, index) => index)\n        .map(name => name.replace(/(SPÓŁKA AKCYJNA)|(SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ)|(KOMANDYTOWA)/g,'').trim())\n\n    companies.forEach(company => {\n        chai.expect(company).to.be.a('string')\n    })\n\n    return companies;\n}\n\nW tej chwili cały skrypt celowo analizuje jedynie pierwszą firmę. Od pobrania\ndanych dla wszystkich dzieli nas jedynie dopisanie jednej pętli. Jednak z\ndoświadczenia wiemy, że dla niektórych firm będzie trzeba powtórzyć zapytanie,\nponieważ prawdopodobnie w nazwach są błędy, albo wyszukiwarka nie zwróci\npoprawnego wyniku.\n\nPodłączenie do bazy i zapis wyników\nAby jednocześnie móc zapisać pobrane dane warto podłączyć system do bazy. Jest\nwiele dostępnych baz danych, ale do tego zadania preferuję MongoDB z uwagi na\nłatwość wykonywania w niej agregacji, prostotę eksportu do formatów json i xlsx \noraz brak konieczności definiowania schematu.\n\nZainstalujemy sterowniki node-js dla mongo i bibliotekę do kolorowania wyników w\nkonsoli:\n\nnpm i mongodb chalk @types/mongodb\n\nPodłączenie do bazy wykonamy za pomocą kodu:\n\nimport fs from 'fs'\nimport chai from 'chai'\nimport axios from \"axios\";\nimport chalk from 'chalk';\n\nimport {MongoClient} from 'mongodb';\n\n// const url = \"mongodb://localhost:27017/krs\";\nconst url = \"\";\n\nconst getDb = async ():Promise<any> => {\n    return new Promise((resolve, reject) => {\n        MongoClient.connect(url, {useUnifiedTopology: true}, (err, db) => {\n            if (err) reject(err);\n            resolve(db)\n        });\n    })\n\n}\n\n\n\nconst getCompanies = (): string[] => {\n    const rawDir = process.cwd() + `/raw`\n\n    const companies = fs\n        .readFileSync(rawDir + `/base.csv`)\n        .toString()\n        .split(`\\n`)\n        .map((line: string) => line.split(',')[1])\n        .filter(line => line)\n        .filter((line, index) => index)\n        .map(name => name.replace(/(SPÓŁKA AKCYJNA)|(SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ)|(KOMANDYTOWA)/g, '').trim())\n\n    companies.forEach(company => {\n        chai.expect(company).to.be.a('string')\n    })\n\n    return companies;\n}\n\nconst main = async () => {\n    const companies = getCompanies();\n\n    const time0 = new Date().getTime();\n\n\n    const db = await getDb()\n    db.db(\"krs\").collection('companies').createIndex({ name: 1 })\n\n    for(let i = 0; i< companies.length; i++) {\n        const company = companies[i];\n\n        try {\n            const {data} = await axios.get(`https://rejestr.io/api/v1/krs`, {\n                    params: {\n                        name: company\n                    },\n                    headers: {\n                        Authorization: process.env.API_KEY\n                    }\n                }\n            )\n\n            await db.db(\"krs\").collection('companies').insertOne({name: company, data})\n\n            const time = (new Date().getTime()) - time0;\n\n            if (data.total) {\n                console.log(chalk.green(`${time}\\t${i}\\t${company}\\t\\t\\t${data.total}`));\n            } else {\n                console.log(chalk.red(`${time}\\t${i}\\t${company}\\t\\t\\t${data.total}`));\n            }\n        } catch (e) {\n            console.log(chalk.red(e))\n        }\n    }\n}\n\nmain().catch(console.error)\n\n\n\nOkazuje się, że nie wszystkie firmy pobieramy prawidłowo:\n\nPowtarza się ten sam motyw co ze spółką akcyjną. Grupa Kapitałowa powoduje, że\nfirma jest źle wyszukiwana. Podobnie OPERATOR występujące na końcu nazwy.\n\nPo kilku poprawkach i wykluczeniu paru losowo wybranych nazw mamy około 15%\nodrzuceń. Baza firm przygotowywana była ręcznie i przez to konwencje nazw różnią\nsię od tych oficjalnych w Rejestr.io.\n\nKolejne kolumny to:\n\n * czas od włączenia programu\n * numer porządkowy (liczony od 0)\n * ilość firm dopasowanych w Rejestr.io\n\nO słabej jakości bazy świadczą takie kwiatki jak:\n\n> PRZEDSIĘBIORSTWO GOSPODARKI KOMUNALNEJ SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ\n[http://www.imsig.pl/szukaj/krs,45812,PRZEDSI%C4%98BIORSTWO_GOSPODARKI_KOMUNALNEJ_SP%C3%93%C5%81KA_Z_OGRANICZON%C4%84_ODPOWIEDZIALNO%C5%9ACI%C4%84]\nPrawdopodobnie w prawie każdym szanującym się miasteczku mieści się firma o\ntakiej nazwie.\n\nKod w tej chwili prezentuje się tak:\n\nimport fs from 'fs'\nimport chai from 'chai'\nimport axios from \"axios\";\nimport chalk from 'chalk';\n\nimport {MongoClient} from 'mongodb';\n\nconst url = process.env.MONGO_URI || '';\n\nconst getDb = async ():Promise<any> => {\n    return new Promise((resolve, reject) => {\n        MongoClient.connect(url, {useUnifiedTopology: true}, (err, db) => {\n            if (err) reject(err);\n            resolve(db)\n        });\n    })\n\n}\n\n\n\nconst getCompanies = (): string[] => {\n    const rawDir = process.cwd() + `/raw`\n\n    const companies = fs\n        .readFileSync(rawDir + `/base.csv`)\n        .toString()\n        .split(`\\n`)\n        .map((line: string) => line.split(',')[1])\n        .filter(line => line)\n        .filter((line, index) => index)\n        .map(name => name.replace(/(SPÓŁKA AKCYJNA)|(SPÓŁKA Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ)|(KOMANDYTOWA)|(^Grupa Kapitałowa)|(OPERATOR)|(-GRUPA GDF SUEZ ENERGIA POLSKA)|(S\\.?A\\.?)|(WARSZAWA)|(STOEN)|(Sp\\. z o\\.o\\.)|(S\\.K\\.)|(G\\.K\\.)/ig, '').trim())\n\n    companies.forEach(company => {\n        chai.expect(company).to.be.a('string')\n    })\n\n    return [...new Set(companies)];\n}\n\nconst main = async () => {\n    const companies = getCompanies();\n\n    const time0 = new Date().getTime();\n\n\n    const db = await getDb()\n    db.db(\"krs\").collection('companies').createIndex({ name: 1 })\n\n    for(let i = 0; i< companies.length; i++) {\n        const company = companies[i];\n\n        try {\n            const existing = await db.db(\"krs\").collection('companies').findOne({name: company})\n\n            if(existing) {\n                const time = (new Date().getTime()) - time0\n                if (existing.data.total) {\n                    console.log(chalk.yellow(`${time}\\t${i}\\t${existing.data.total}\\t${company}\\tSKIPPED`));\n                } else {\n                    console.log(chalk.red(`${time}\\t${i}\\t${existing.data.total}\\t${company}`));\n                }\n                continue;\n            }\n\n            const {data} = await axios.get(`https://rejestr.io/api/v1/krs`, {\n                    params: {\n                        name: company\n                    },\n                    headers: {\n                        Authorization: process.env.API_KEY\n                    }\n                }\n            )\n\n            await db.db(\"krs\").collection('companies').insertOne({name: company, data})\n\n            const time = (new Date().getTime()) - time0;\n\n            if (data.total) {\n                console.log(chalk.green(`${time}\\t${i}\\t${data.total}\\t${company}`));\n            } else {\n                console.log(chalk.red(`${time}\\t${i}\\t${data.total}\\t${company}`));\n            }\n        } catch (e) {\n            console.log(chalk.red(e))\n        }\n    }\n}\n\nmain().catch(console.error)\n\n\n\nJego mocne strony to:\n\n * oszczędzamy requesty do API, jeśli mamy nazwę, która ma już dopasowania, to\n   nie jest dalej przetwarzana.\n * dane zapisywane są tak, aby nie było duplikatów\n\nNiestety w pobranych danych nie ma kapitału zakładowego. Przykładowy obiekt ma\ndane: \n\nSzczegółowe zapytania\nKolejnym krokiem będzie zapomnienie o firmach, których nie udało się zeskanować.\nNiektórych wyników jak INSTYTUT CHEMII BIOORGANICZNEJ POLSKIEJ AKADEMII NAUK nie\nda się uratować. Dopiero manualny research pozwala stwierdzić, że rejestr io\nzapisuje to jako FUNDACJA ICHB PAN, ale nie możemy nauczyć algorytmu poprawnego\nnazywania wszystkich firm z bazy.\n\nDlatego godząc się z tym, że pobraliśmy tylko część wyciągniemy konkretne numery\nKRS i identyfikatory firm i na tej podstawie zapytamy o dane szczegółowe.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-27T20:51:47.000Z",
            "updated_at": "2021-04-27T22:50:23.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "608980982fb35425592d11c6",
            "uuid": "13d43d89-1a73-4e6f-b218-915e4fc5fdc4",
            "title": "Jak przechowywać sekrety w gicie z blackbox",
            "slug": "blackbox",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"embed\",{\"url\":\"https://www.youtube.com/watch?v=17UVejOw3zA\",\"html\":\"<iframe width=\\\"200\\\" height=\\\"113\\\" src=\\\"https://www.youtube.com/embed/17UVejOw3zA?feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\",\"metadata\":{\"title\":\"3.4 Hiding API Keys with Environment Variables (dotenv) and Pushing Code to GitHub\",\"author_name\":\"The Coding Train\",\"author_url\":\"https://www.youtube.com/user/shiffman\",\"height\":113,\"width\":200,\"version\":\"1.0\",\"provider_name\":\"YouTube\",\"provider_url\":\"https://www.youtube.com/\",\"thumbnail_height\":360,\"thumbnail_width\":480,\"thumbnail_url\":\"https://i.ytimg.com/vi/17UVejOw3zA/hqdefault.jpg\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://secrethub.io/blog/decouple-application-secrets-from-ci-cd-pipeline/\",\"metadata\":{\"url\":\"https://secrethub.io/blog/decouple-application-secrets-from-ci-cd-pipeline/\",\"title\":\"Decouple Application Secrets from Your CI/CD Pipeline - SecretHub\",\"description\":\"Keep your passwords, API keys, and other secrets out of CI/CD pipelines. Instead, load them on the moment they’re actually needed: at runtime. Check out our blog here.\",\"author\":\"Floris van der Grinten on 26 June 2019\",\"publisher\":\"SecretHub\",\"thumbnail\":\"https://secrethub.io/img/blog/pipeline-og.png\",\"icon\":\"https://secrethub.io/img/favicon/android-icon-192x192.png\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://blog.1password.com/introducing-secrets-automation/\",\"metadata\":{\"url\":\"https://blog.1password.com/introducing-secrets-automation/\",\"title\":\"Introducing 1Password Secrets Automation | 1Password\",\"description\":\"1Password remembers your passwords all for you. Save your passwords and log in to sites with a single click. It’s that simple.\",\"author\":\"Jeff Shiner\",\"publisher\":\"1Password Blog\",\"thumbnail\":\"https://blog.1password.com/posts/2021/secrets-automation-launch/header.png\",\"icon\":\"https://1password.com/icons/apple-touch-icon-180x180-precomposed-v1.png\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://docs.ansible.com/ansible/latest/user_guide/vault.html\",\"metadata\":{\"url\":\"https://docs.ansible.com/ansible/latest/user_guide/vault.html\",\"title\":\"Encrypting content with Ansible Vault — Ansible Documentation\",\"description\":null,\"author\":null,\"publisher\":null,\"thumbnail\":\"https://docs.ansible.com/ansible/latest/_static/images/logo_invert.png\",\"icon\":null}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/StackExchange/blackbox\",\"metadata\":{\"url\":\"https://github.com/StackExchange/blackbox\",\"title\":\"StackExchange/blackbox\",\"description\":\"Safely store secrets in Git/Mercurial/Subversion. Contribute to StackExchange/blackbox development by creating an account on GitHub.\",\"author\":\"StackExchange\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/3d613ff8894411312445f2b256914be36e939f66bb22d78dcebac6fb84eea94a/StackExchange/blackbox\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"code\",{\"code\":\"yay -S blackbox-vcs\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/StackExchange/blackbox#installation-instructions\",\"metadata\":{\"url\":\"https://github.com/StackExchange/blackbox\",\"title\":\"StackExchange/blackbox\",\"description\":\"Safely store secrets in Git/Mercurial/Subversion. Contribute to StackExchange/blackbox development by creating an account on GitHub.\",\"author\":\"StackExchange\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/3d613ff8894411312445f2b256914be36e939f66bb22d78dcebac6fb84eea94a/StackExchange/blackbox\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.man42.net/blog/2016/12/git-blackbox/#step-2-install-blackbox\",\"metadata\":{\"url\":\"https://www.man42.net/blog/2016/12/git-blackbox/\",\"title\":\"How to store secrets in git with blackbox - man42 blog\",\"description\":\"How to store secrets in git with blackbox\",\"author\":\"kunnix\",\"publisher\":\"man42 blog\",\"thumbnail\":\"https://www.man42.net/blog/favicon.png\",\"icon\":\"https://www.man42.net/blog/favicon.png\"}}],[\"code\",{\"code\":\"sudo apt-get install ruby-dev build-essential -y && \\\\\\nsudo gem install fpm -f && \\\\\\ncd /tmp && \\\\\\nrm -rf /tmp/blackbox && \\\\\\ngit clone --depth 1 https://github.com/StackExchange/blackbox.git -q && \\\\\\ncd /tmp/blackbox && \\\\\\nmake packages-deb && \\\\\\ndpkg -i `ls /root/debbuild-stack_blackbox/*.deb`\"}],[\"code\",{\"code\":\"git init\"}],[\"code\",{\"code\":\"blackbox_initialize -y\\n\"}],[\"code\",{\"code\":\"Enable blackbox for this git repo? (yes/no) yes\\nVCS_TYPE: git\\n\\n\\nNEXT STEP: You need to manually check these in:\\n      git commit -m'INITIALIZE BLACKBOX' .blackbox /media/nvme/pro/exp/b2/.gitignore\"}],[\"code\",{\"code\":\"tree .blackbox \\n.blackbox\\n├── blackbox-admins.txt\\n└── blackbox-files.txt\\n\"}],[\"code\",{\"code\":\"echo 'SECRET=prod' > .env.prod\"}],[\"code\",{\"code\":\"blackbox_register_new_file .env.prod\"}],[\"code\",{\"code\":\"$ blackbox_register_new_file .env.prod \\n========== PLAINFILE .env.prod\\n========== ENCRYPTED .env.prod.gpg\\n========== Importing keychain: START\\ngpg: keybox '/tmp/blackbox/.blackbox/pubring.kbx' created\\ngpg: WARNING: nothing exported\\ngpg: directory '/root/.gnupg' created\\ngpg: keybox '/root/.gnupg/pubring.kbx' created\\ngpg: no valid OpenPGP data found.\\ngpg: Total number processed: 0\\n========== Importing keychain: DONE\\n========== Encrypting: .env.prod\\nYou did not specify a user ID. (you may use \\\"-r\\\")\\n\\nCurrent recipients:\\n\\nEnter the user ID.  End with an empty line: \\ngpg: no valid addressees\\ngpg: .env.prod: encryption failed: No user ID\\n\"}],[\"code\",{\"code\":\"cat >keydetails <<EOF\\n%no-protection\\nKey-Type: default\\nSubkey-Type: default\\nName-Real: server_name\\nName-Comment: 165.xxx.xxx.80\\nName-Email: gustaw.daniel@gmail.com\\nExpire-Date: 0\\n%no-ask-passphrase\\n%commit\\n%echo done\\nEOF\"}],[\"code\",{\"code\":\"gpg --verbose --batch --gen-key keydetails\"}],[\"code\",{\"code\":\"gpg --quiet -K | awk '{print $1}' | sed '4q;d'\"}],[\"code\",{\"code\":\"BEC513926DA11A7F1676CB4B15B21A69BBB0B659\"}],[\"code\",{\"code\":\"gpg --keyserver hkps://keyserver.ubuntu.com --send-keys `gpg --quiet -K | awk '{print $1}' | sed '4q;d'`\"}],[\"code\",{\"code\":\"gpg: sending key 15B21A69BBB0B659 to hkps://keyserver.ubuntu.com\"}],[\"code\",{\"code\":\"gpg --full-generate-key\"}],[\"code\",{\"code\":\"gpg --keyserver hkps://keyserver.ubuntu.com --recv-keys 15B21A69BBB0B659\"}],[\"code\",{\"code\":\" blackbox_addadmin 15B21A69BBB0B659\"}],[\"code\",{\"code\":\"gpg -K\"}],[\"code\",{\"code\":\"blackbox_register_new_file .env.prod \"}],[\"code\",{\"code\":\"scp .env.prod.gpg root@165.xxx.xxx.80:/tmp/b2\"}],[\"code\",{\"code\":\"scp -r .blackbox root@165.xxx.xxx.80:/tmp/b2\"}],[\"code\",{\"code\":\"blackbox_postdeploy\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gist.github.com/vrillusions/5484422\",\"metadata\":{\"url\":\"https://gist.github.com/vrillusions/5484422\",\"title\":\"Generate gpg key via batch file\",\"description\":\"Generate gpg key via batch file. GitHub Gist: instantly share code, notes, and snippets.\",\"author\":\"262588213843476\",\"publisher\":\"Gist\",\"thumbnail\":\"https://github.githubassets.com/images/modules/gists/gist-og-image.png\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Sekret jest to ciąg znaków, który ze wględu na uprawnienia, które są w nim zakodowane powinien być traktowany inaczej niż kod źródłowy. Może to być klucz do API, URI bazy danych zawierający hasło, tajny klucz do generowania tokenów JWT. \"]]],[1,\"p\",[[0,[],0,\"Nie powinno się trzymać tych wartości w kodzie źródłowym ponieważ prowadzi to do problemów z zarządzaniem uprawnieniami do kodu źródłowego. Na youtube można znaleźć bardzo podstawowy tutorial, pokazujący jak uniknąć podstawowego błędu - trzymania sekretów w systemie kontroli wersji.\"]]],[10,0],[1,\"p\",[[0,[],0,\"Niestety nie podaje on alternatywnego sposobu zarządzania sekretami, tak aby zachować równowagę między automatyzacją deploymentu, wygodnym współdzieleniem kluczy w zespole oraz bezpieczeństwem.\"]]],[1,\"p\",[[0,[],0,\"Naturalne problemy jakie pojawiają się po wyjęciu sekretów z repozytorium to:\"]]],[3,\"ul\",[[[0,[],0,\"kopiowanie ich między developerami\"]],[[0,[],0,\"synchronizacja ich stanów na serwerach w różnych środowiskach\"]]]],[1,\"p\",[[0,[],0,\"Problem ten nasila się jeszcze bardziej, kiedy nad projektem pracuje więcej osób, zespół zmienia się, różne osoby w zespole dołączają różne zmienne środowiskowe, deploymenty wymagają pobrania zmiennych środowiskowych z komputerów programistów.\"]]],[1,\"p\",[[0,[],0,\"Jednym z ciekawych rozwiązań, jakie rozważałem kilka miesięcy temu jest Secret Hub. Ich świetny artykuł dobrze tłumaczy na czym polegają problemy dobrymi praktykami zarządzania sekretami:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Sama koncepcja tego narzędzia idealnie trafiła w moje potrzeby, mam 4 programistów, konieczność zachowania 150 sekretów i miesięczne wydatki na infrastrukturę IT około 150 USD. Cena Secret Hub przy mojej skali działania to 100 USD/msc - stanowczo za dużo.\"]]],[1,\"p\",[[0,[],0,\"Serwis 1Password, który wchłonął Secret Hub, odstraszył mnie nie zrozumiałymi zasadami cennika.\"]]],[10,2],[1,\"p\",[[0,[],0,\"Wobec słabej oferty serwisów komercyjnych przyjrzałem się darmowym rozwiązaniom open source.\"]]],[1,\"p\",[[0,[],0,\"Jednym z nich jest Ansible Vault. Rozwiązanie bardzo dobrze integrujące się z Ansible.\"]]],[10,3],[1,\"p\",[[0,[],0,\"Kolejnym narzędziem, które sprawdziłem był Blackbox. Oparte o klucze GPG narzędzie do szyfrowania niektórych plików z systemu kontroli wersji.\"]]],[10,4],[1,\"p\",[[0,[],0,\"W tym artykule opiszemy jak przygotować klucze GPG, zainstalować i używać blackbox oraz przeprowadzimy bardzo uproszczony deployment z wykorzystaniem tego narzędzia. \"]]],[1,\"h2\",[[0,[],0,\"Instalacja blackbox. \"]]],[1,\"p\",[[0,[],0,\"Na archu jest to proste:\"]]],[10,5],[1,\"p\",[[0,[],0,\"Jeśli masz inny system, to wymaga kilku komend:\"]]],[10,6],[1,\"p\",[[0,[],0,\"Stosunkowo uniwersalną instrukcję instalacji możemy znaleźć tutaj\"]]],[10,7],[1,\"p\",[[0,[],0,\"Na Ubuntu można zainstalować używając tego polecenia:\"]]],[10,8],[1,\"h2\",[[0,[],0,\"Inicjalizacja blackbox\"]]],[1,\"p\",[[0,[],0,\"Tworzymy repozytorium\"]]],[10,9],[1,\"p\",[[0,[],0,\"Inicjalizujemy \"],[0,[0],1,\"blackbox\"]]],[10,10],[1,\"p\",[[0,[],0,\"Po potwierdzeniu wpisaniem \"],[0,[0],1,\"yes\"],[0,[],0,\" możemy zobaczyć komunikat potwierdzający, poprawną inicjalizację.\"]]],[10,11],[1,\"p\",[[0,[],0,\"Tworzy ona ukryty katalog \"],[0,[0],1,\".blackbox\"],[0,[],0,\" \"]]],[10,12],[1,\"h2\",[[0,[],0,\"Szyfrowanie sekretów\"]]],[1,\"p\",[[0,[],0,\"Przygotujmy plik z tajnymi kluczami:\"]]],[10,13],[1,\"p\",[[0,[],0,\"Jeśli będziemy chcieli go zaszyfrować poleceniem\"]]],[10,14],[1,\"p\",[[0,[],0,\"okaże się, że nie możemy tego zrobić bez utworzenia klucza GPG\"]]],[10,15],[1,\"p\",[[0,[],0,\"Jak wspomnieliśmy Blackbox jest oparty o klucze GPG i korzystając z niego należy proces wymiany kluczy wpleść w proces zarządzania sekretami.\"]]],[1,\"p\",[[0,[],0,\"Aby móc szyfrować utworzymy klucze GPG. Jeden na komputerze lokalnym a drugi na serwerze. Pokażę jak wygląda ten proces na serwerze: \"]]],[1,\"p\",[[0,[],0,\"Jego konfigurację możemy utworzyć przez\"]]],[10,16],[1,\"p\",[[0,[],0,\"Samo wgranie wygenerowanie klucza na podstawie tego pliku wymaga wpisania komendy:\"]]],[10,17],[1,\"p\",[[0,[],0,\"Teraz, aby wysłać klucz na serwer dodamy musimy poznać jego \"],[0,[0],1,\"id\"],[0,[],0,\". Za pomocą poleceń \"],[0,[0],1,\"sed\"],[0,[],0,\" oraz \"],[0,[0],1,\"awk\"],[0,[],0,\" możemy wyłuskać je poleceniem:\"]]],[10,18],[1,\"p\",[[0,[],0,\"Jest to długa wersja ID\"]]],[10,19],[1,\"p\",[[0,[],0,\"Wysyłkę tego klucza na serwer wykonamy poleceniem:\"]]],[10,20],[1,\"p\",[[0,[],0,\"Powinno ono zwrócić:\"]]],[10,21],[1,\"p\",[[0,[],0,\"Na komputerze lokalnym możemy wpisać po prostu \"]]],[10,22],[1,\"p\",[[0,[],0,\"ponieważ nie jest wymagany taki poziom automatyzacji.\"]]],[1,\"p\",[[0,[],0,\"Aby pobrać klucz z serwera na komputer lokalny piszemy:\"]]],[10,23],[1,\"p\",[[0,[],0,\"Teraz możemy dołączyć administratorów danych do blackboxa. Służą do tego polecenia:\"]]],[10,24],[1,\"p\",[[0,[],0,\"które pozwala na dostęp do danych serwerowi oraz analogiczne z id klucza z komputera lokalnego. Klucze prywatne możemy pokazać poleceniem\"]]],[10,25],[1,\"p\",[[0,[],0,\"Teraz możemy poprawnie zaszyfrować plik \"],[0,[0],1,\".env.prod\"],[0,[],0,\".\"]]],[10,26],[1,\"p\",[[0,[],0,\"To polecenie spowoduje, że plik \"],[0,[0],1,\".env.prod\"],[0,[],0,\" zniknie i na jego miejsce pojawi się zaszyfrowany \"],[0,[0],1,\".env.prod.gpg\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Teraz poleceniem \"],[0,[0],1,\"scp\"],[0,[],0,\" możemy przesłać ten plik na serwer i tam odczytać go. \"]]],[10,27],[1,\"p\",[[0,[],0,\"Razem z plikiem powinniśmy wysłać też ukryty katalog \"],[0,[0],1,\".blackbox\"],[0,[],0,\", ponieważ jest on częścią repozytorium.\"]]],[10,28],[1,\"p\",[[0,[],0,\"Następnie na serwerze wykonujemy:\"]]],[10,29],[1,\"p\",[[0,[],0,\"i możemy zobaczyć odszyfrowany plik \"],[0,[0],1,\".env.prod\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Rozrysowanie całego procesu\"]]],[1,\"p\",[]],[1,\"p\",[]],[1,\"p\",[[0,[],0,\"Jak utworzyć klucz \"],[0,[0],1,\"gpg\"],[0,[],0,\" bez interakcji ze strony użytkownika:\"]]],[10,30],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Sekret jest to ciąg znaków, który ze wględu na uprawnienia, które są w nim zakodowane powinien być traktowany inaczej niż kod źródłowy. Może to być klucz do API, URI bazy danych zawierający hasło, tajny klucz do generowania tokenów JWT. </p><p>Nie powinno się trzymać tych wartości w kodzie źródłowym ponieważ prowadzi to do problemów z zarządzaniem uprawnieniami do kodu źródłowego. Na youtube można znaleźć bardzo podstawowy tutorial, pokazujący jak uniknąć podstawowego błędu - trzymania sekretów w systemie kontroli wersji.</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/17UVejOw3zA?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p>Niestety nie podaje on alternatywnego sposobu zarządzania sekretami, tak aby zachować równowagę między automatyzacją deploymentu, wygodnym współdzieleniem kluczy w zespole oraz bezpieczeństwem.</p><p>Naturalne problemy jakie pojawiają się po wyjęciu sekretów z repozytorium to:</p><ul><li>kopiowanie ich między developerami</li><li>synchronizacja ich stanów na serwerach w różnych środowiskach</li></ul><p>Problem ten nasila się jeszcze bardziej, kiedy nad projektem pracuje więcej osób, zespół zmienia się, różne osoby w zespole dołączają różne zmienne środowiskowe, deploymenty wymagają pobrania zmiennych środowiskowych z komputerów programistów.</p><p>Jednym z ciekawych rozwiązań, jakie rozważałem kilka miesięcy temu jest Secret Hub. Ich świetny artykuł dobrze tłumaczy na czym polegają problemy dobrymi praktykami zarządzania sekretami:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://secrethub.io/blog/decouple-application-secrets-from-ci-cd-pipeline/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Decouple Application Secrets from Your CI/CD Pipeline - SecretHub</div><div class=\"kg-bookmark-description\">Keep your passwords, API keys, and other secrets out of CI/CD pipelines. Instead, load them on the moment they’re actually needed: at runtime. Check out our blog here.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://secrethub.io/img/favicon/android-icon-192x192.png\"><span class=\"kg-bookmark-author\">SecretHub</span><span class=\"kg-bookmark-publisher\">Floris van der Grinten on 26 June 2019</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://secrethub.io/img/blog/pipeline-og.png\"></div></a></figure><p>Sama koncepcja tego narzędzia idealnie trafiła w moje potrzeby, mam 4 programistów, konieczność zachowania 150 sekretów i miesięczne wydatki na infrastrukturę IT około 150 USD. Cena Secret Hub przy mojej skali działania to 100 USD/msc - stanowczo za dużo.</p><p>Serwis 1Password, który wchłonął Secret Hub, odstraszył mnie nie zrozumiałymi zasadami cennika.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://blog.1password.com/introducing-secrets-automation/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Introducing 1Password Secrets Automation | 1Password</div><div class=\"kg-bookmark-description\">1Password remembers your passwords all for you. Save your passwords and log in to sites with a single click. It’s that simple.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://1password.com/icons/apple-touch-icon-180x180-precomposed-v1.png\"><span class=\"kg-bookmark-author\">1Password Blog</span><span class=\"kg-bookmark-publisher\">Jeff Shiner</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://blog.1password.com/posts/2021/secrets-automation-launch/header.png\"></div></a></figure><p>Wobec słabej oferty serwisów komercyjnych przyjrzałem się darmowym rozwiązaniom open source.</p><p>Jednym z nich jest Ansible Vault. Rozwiązanie bardzo dobrze integrujące się z Ansible.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.ansible.com/ansible/latest/user_guide/vault.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Encrypting content with Ansible Vault — Ansible Documentation</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.ansible.com/ansible/latest/_static/images/logo_invert.png\"></div></a></figure><p>Kolejnym narzędziem, które sprawdziłem był Blackbox. Oparte o klucze GPG narzędzie do szyfrowania niektórych plików z systemu kontroli wersji.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/StackExchange/blackbox\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">StackExchange/blackbox</div><div class=\"kg-bookmark-description\">Safely store secrets in Git/Mercurial/Subversion. Contribute to StackExchange/blackbox development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">StackExchange</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/3d613ff8894411312445f2b256914be36e939f66bb22d78dcebac6fb84eea94a/StackExchange/blackbox\"></div></a></figure><p>W tym artykule opiszemy jak przygotować klucze GPG, zainstalować i używać blackbox oraz przeprowadzimy bardzo uproszczony deployment z wykorzystaniem tego narzędzia. </p><h2 id=\"instalacja-blackbox\">Instalacja blackbox. </h2><p>Na archu jest to proste:</p><pre><code>yay -S blackbox-vcs</code></pre><p>Jeśli masz inny system, to wymaga kilku komend:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/StackExchange/blackbox#installation-instructions\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">StackExchange/blackbox</div><div class=\"kg-bookmark-description\">Safely store secrets in Git/Mercurial/Subversion. Contribute to StackExchange/blackbox development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">StackExchange</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/3d613ff8894411312445f2b256914be36e939f66bb22d78dcebac6fb84eea94a/StackExchange/blackbox\"></div></a></figure><p>Stosunkowo uniwersalną instrukcję instalacji możemy znaleźć tutaj</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.man42.net/blog/2016/12/git-blackbox/#step-2-install-blackbox\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">How to store secrets in git with blackbox - man42 blog</div><div class=\"kg-bookmark-description\">How to store secrets in git with blackbox</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.man42.net/blog/favicon.png\"><span class=\"kg-bookmark-author\">man42 blog</span><span class=\"kg-bookmark-publisher\">kunnix</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.man42.net/blog/favicon.png\"></div></a></figure><p>Na Ubuntu można zainstalować używając tego polecenia:</p><pre><code>sudo apt-get install ruby-dev build-essential -y &amp;&amp; \\\nsudo gem install fpm -f &amp;&amp; \\\ncd /tmp &amp;&amp; \\\nrm -rf /tmp/blackbox &amp;&amp; \\\ngit clone --depth 1 https://github.com/StackExchange/blackbox.git -q &amp;&amp; \\\ncd /tmp/blackbox &amp;&amp; \\\nmake packages-deb &amp;&amp; \\\ndpkg -i `ls /root/debbuild-stack_blackbox/*.deb`</code></pre><h2 id=\"inicjalizacja-blackbox\">Inicjalizacja blackbox</h2><p>Tworzymy repozytorium</p><pre><code>git init</code></pre><p>Inicjalizujemy <code>blackbox</code></p><pre><code>blackbox_initialize -y\n</code></pre><p>Po potwierdzeniu wpisaniem <code>yes</code> możemy zobaczyć komunikat potwierdzający, poprawną inicjalizację.</p><pre><code>Enable blackbox for this git repo? (yes/no) yes\nVCS_TYPE: git\n\n\nNEXT STEP: You need to manually check these in:\n      git commit -m'INITIALIZE BLACKBOX' .blackbox /media/nvme/pro/exp/b2/.gitignore</code></pre><p>Tworzy ona ukryty katalog <code>.blackbox</code> </p><pre><code>tree .blackbox \n.blackbox\n├── blackbox-admins.txt\n└── blackbox-files.txt\n</code></pre><h2 id=\"szyfrowanie-sekret%C3%B3w\">Szyfrowanie sekretów</h2><p>Przygotujmy plik z tajnymi kluczami:</p><pre><code>echo 'SECRET=prod' &gt; .env.prod</code></pre><p>Jeśli będziemy chcieli go zaszyfrować poleceniem</p><pre><code>blackbox_register_new_file .env.prod</code></pre><p>okaże się, że nie możemy tego zrobić bez utworzenia klucza GPG</p><pre><code>$ blackbox_register_new_file .env.prod \n========== PLAINFILE .env.prod\n========== ENCRYPTED .env.prod.gpg\n========== Importing keychain: START\ngpg: keybox '/tmp/blackbox/.blackbox/pubring.kbx' created\ngpg: WARNING: nothing exported\ngpg: directory '/root/.gnupg' created\ngpg: keybox '/root/.gnupg/pubring.kbx' created\ngpg: no valid OpenPGP data found.\ngpg: Total number processed: 0\n========== Importing keychain: DONE\n========== Encrypting: .env.prod\nYou did not specify a user ID. (you may use \"-r\")\n\nCurrent recipients:\n\nEnter the user ID.  End with an empty line: \ngpg: no valid addressees\ngpg: .env.prod: encryption failed: No user ID\n</code></pre><p>Jak wspomnieliśmy Blackbox jest oparty o klucze GPG i korzystając z niego należy proces wymiany kluczy wpleść w proces zarządzania sekretami.</p><p>Aby móc szyfrować utworzymy klucze GPG. Jeden na komputerze lokalnym a drugi na serwerze. Pokażę jak wygląda ten proces na serwerze: </p><p>Jego konfigurację możemy utworzyć przez</p><pre><code>cat &gt;keydetails &lt;&lt;EOF\n%no-protection\nKey-Type: default\nSubkey-Type: default\nName-Real: server_name\nName-Comment: 165.xxx.xxx.80\nName-Email: gustaw.daniel@gmail.com\nExpire-Date: 0\n%no-ask-passphrase\n%commit\n%echo done\nEOF</code></pre><p>Samo wgranie wygenerowanie klucza na podstawie tego pliku wymaga wpisania komendy:</p><pre><code>gpg --verbose --batch --gen-key keydetails</code></pre><p>Teraz, aby wysłać klucz na serwer dodamy musimy poznać jego <code>id</code>. Za pomocą poleceń <code>sed</code> oraz <code>awk</code> możemy wyłuskać je poleceniem:</p><pre><code>gpg --quiet -K | awk '{print $1}' | sed '4q;d'</code></pre><p>Jest to długa wersja ID</p><pre><code>BEC513926DA11A7F1676CB4B15B21A69BBB0B659</code></pre><p>Wysyłkę tego klucza na serwer wykonamy poleceniem:</p><pre><code>gpg --keyserver hkps://keyserver.ubuntu.com --send-keys `gpg --quiet -K | awk '{print $1}' | sed '4q;d'`</code></pre><p>Powinno ono zwrócić:</p><pre><code>gpg: sending key 15B21A69BBB0B659 to hkps://keyserver.ubuntu.com</code></pre><p>Na komputerze lokalnym możemy wpisać po prostu </p><pre><code>gpg --full-generate-key</code></pre><p>ponieważ nie jest wymagany taki poziom automatyzacji.</p><p>Aby pobrać klucz z serwera na komputer lokalny piszemy:</p><pre><code>gpg --keyserver hkps://keyserver.ubuntu.com --recv-keys 15B21A69BBB0B659</code></pre><p>Teraz możemy dołączyć administratorów danych do blackboxa. Służą do tego polecenia:</p><pre><code> blackbox_addadmin 15B21A69BBB0B659</code></pre><p>które pozwala na dostęp do danych serwerowi oraz analogiczne z id klucza z komputera lokalnego. Klucze prywatne możemy pokazać poleceniem</p><pre><code>gpg -K</code></pre><p>Teraz możemy poprawnie zaszyfrować plik <code>.env.prod</code>.</p><pre><code>blackbox_register_new_file .env.prod </code></pre><p>To polecenie spowoduje, że plik <code>.env.prod</code> zniknie i na jego miejsce pojawi się zaszyfrowany <code>.env.prod.gpg</code>.</p><p>Teraz poleceniem <code>scp</code> możemy przesłać ten plik na serwer i tam odczytać go. </p><pre><code>scp .env.prod.gpg root@165.xxx.xxx.80:/tmp/b2</code></pre><p>Razem z plikiem powinniśmy wysłać też ukryty katalog <code>.blackbox</code>, ponieważ jest on częścią repozytorium.</p><pre><code>scp -r .blackbox root@165.xxx.xxx.80:/tmp/b2</code></pre><p>Następnie na serwerze wykonujemy:</p><pre><code>blackbox_postdeploy</code></pre><p>i możemy zobaczyć odszyfrowany plik <code>.env.prod</code>.</p><h2 id=\"rozrysowanie-ca%C5%82ego-procesu\">Rozrysowanie całego procesu</h2><p></p><p></p><p>Jak utworzyć klucz <code>gpg</code> bez interakcji ze strony użytkownika:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gist.github.com/vrillusions/5484422\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Generate gpg key via batch file</div><div class=\"kg-bookmark-description\">Generate gpg key via batch file. GitHub Gist: instantly share code, notes, and snippets.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">Gist</span><span class=\"kg-bookmark-publisher\">262588213843476</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://github.githubassets.com/images/modules/gists/gist-og-image.png\"></div></a></figure>",
            "comment_id": "608980982fb35425592d11c6",
            "plaintext": "Sekret jest to ciąg znaków, który ze wględu na uprawnienia, które są w nim\nzakodowane powinien być traktowany inaczej niż kod źródłowy. Może to być klucz\ndo API, URI bazy danych zawierający hasło, tajny klucz do generowania tokenów\nJWT. \n\nNie powinno się trzymać tych wartości w kodzie źródłowym ponieważ prowadzi to do\nproblemów z zarządzaniem uprawnieniami do kodu źródłowego. Na youtube można\nznaleźć bardzo podstawowy tutorial, pokazujący jak uniknąć podstawowego błędu -\ntrzymania sekretów w systemie kontroli wersji.\n\nNiestety nie podaje on alternatywnego sposobu zarządzania sekretami, tak aby\nzachować równowagę między automatyzacją deploymentu, wygodnym współdzieleniem\nkluczy w zespole oraz bezpieczeństwem.\n\nNaturalne problemy jakie pojawiają się po wyjęciu sekretów z repozytorium to:\n\n * kopiowanie ich między developerami\n * synchronizacja ich stanów na serwerach w różnych środowiskach\n\nProblem ten nasila się jeszcze bardziej, kiedy nad projektem pracuje więcej\nosób, zespół zmienia się, różne osoby w zespole dołączają różne zmienne\nśrodowiskowe, deploymenty wymagają pobrania zmiennych środowiskowych z\nkomputerów programistów.\n\nJednym z ciekawych rozwiązań, jakie rozważałem kilka miesięcy temu jest Secret\nHub. Ich świetny artykuł dobrze tłumaczy na czym polegają problemy dobrymi\npraktykami zarządzania sekretami:\n\nDecouple Application Secrets from Your CI/CD Pipeline - SecretHubKeep your\npasswords, API keys, and other secrets out of CI/CD pipelines. Instead, load\nthem on the moment they’re actually needed: at runtime. Check out our blog\nhere.\nSecretHubFloris van der Grinten on 26 June 2019\n[https://secrethub.io/blog/decouple-application-secrets-from-ci-cd-pipeline/]\nSama koncepcja tego narzędzia idealnie trafiła w moje potrzeby, mam 4\nprogramistów, konieczność zachowania 150 sekretów i miesięczne wydatki na\ninfrastrukturę IT około 150 USD. Cena Secret Hub przy mojej skali działania to\n100 USD/msc - stanowczo za dużo.\n\nSerwis 1Password, który wchłonął Secret Hub, odstraszył mnie nie zrozumiałymi\nzasadami cennika.\n\nIntroducing 1Password Secrets Automation | 1Password1Password remembers your\npasswords all for you. Save your passwords and log in to sites with a single\nclick. It’s that simple.1Password BlogJeff Shiner\n[https://blog.1password.com/introducing-secrets-automation/]Wobec słabej oferty\nserwisów komercyjnych przyjrzałem się darmowym rozwiązaniom open source.\n\nJednym z nich jest Ansible Vault. Rozwiązanie bardzo dobrze integrujące się z\nAnsible.\n\nEncrypting content with Ansible Vault — Ansible Documentation\n[https://docs.ansible.com/ansible/latest/user_guide/vault.html]Kolejnym\nnarzędziem, które sprawdziłem był Blackbox. Oparte o klucze GPG narzędzie do\nszyfrowania niektórych plików z systemu kontroli wersji.\n\nStackExchange/blackboxSafely store secrets in Git/Mercurial/Subversion.\nContribute to StackExchange/blackbox development by creating an account on\nGitHub.GitHubStackExchange [https://github.com/StackExchange/blackbox]W tym\nartykule opiszemy jak przygotować klucze GPG, zainstalować i używać blackbox\noraz przeprowadzimy bardzo uproszczony deployment z wykorzystaniem tego\nnarzędzia. \n\nInstalacja blackbox. \nNa archu jest to proste:\n\nyay -S blackbox-vcs\n\nJeśli masz inny system, to wymaga kilku komend:\n\nStackExchange/blackboxSafely store secrets in Git/Mercurial/Subversion.\nContribute to StackExchange/blackbox development by creating an account on\nGitHub.GitHubStackExchange\n[https://github.com/StackExchange/blackbox#installation-instructions]Stosunkowo\nuniwersalną instrukcję instalacji możemy znaleźć tutaj\n\nHow to store secrets in git with blackbox - man42 blogHow to store secrets in\ngit with blackboxman42 blogkunnix\n[https://www.man42.net/blog/2016/12/git-blackbox/#step-2-install-blackbox]Na\nUbuntu można zainstalować używając tego polecenia:\n\nsudo apt-get install ruby-dev build-essential -y && \\\nsudo gem install fpm -f && \\\ncd /tmp && \\\nrm -rf /tmp/blackbox && \\\ngit clone --depth 1 https://github.com/StackExchange/blackbox.git -q && \\\ncd /tmp/blackbox && \\\nmake packages-deb && \\\ndpkg -i `ls /root/debbuild-stack_blackbox/*.deb`\n\nInicjalizacja blackbox\nTworzymy repozytorium\n\ngit init\n\nInicjalizujemy blackbox\n\nblackbox_initialize -y\n\n\nPo potwierdzeniu wpisaniem yes możemy zobaczyć komunikat potwierdzający,\npoprawną inicjalizację.\n\nEnable blackbox for this git repo? (yes/no) yes\nVCS_TYPE: git\n\n\nNEXT STEP: You need to manually check these in:\n      git commit -m'INITIALIZE BLACKBOX' .blackbox /media/nvme/pro/exp/b2/.gitignore\n\nTworzy ona ukryty katalog .blackbox \n\ntree .blackbox \n.blackbox\n├── blackbox-admins.txt\n└── blackbox-files.txt\n\n\nSzyfrowanie sekretów\nPrzygotujmy plik z tajnymi kluczami:\n\necho 'SECRET=prod' > .env.prod\n\nJeśli będziemy chcieli go zaszyfrować poleceniem\n\nblackbox_register_new_file .env.prod\n\nokaże się, że nie możemy tego zrobić bez utworzenia klucza GPG\n\n$ blackbox_register_new_file .env.prod \n========== PLAINFILE .env.prod\n========== ENCRYPTED .env.prod.gpg\n========== Importing keychain: START\ngpg: keybox '/tmp/blackbox/.blackbox/pubring.kbx' created\ngpg: WARNING: nothing exported\ngpg: directory '/root/.gnupg' created\ngpg: keybox '/root/.gnupg/pubring.kbx' created\ngpg: no valid OpenPGP data found.\ngpg: Total number processed: 0\n========== Importing keychain: DONE\n========== Encrypting: .env.prod\nYou did not specify a user ID. (you may use \"-r\")\n\nCurrent recipients:\n\nEnter the user ID.  End with an empty line: \ngpg: no valid addressees\ngpg: .env.prod: encryption failed: No user ID\n\n\nJak wspomnieliśmy Blackbox jest oparty o klucze GPG i korzystając z niego należy\nproces wymiany kluczy wpleść w proces zarządzania sekretami.\n\nAby móc szyfrować utworzymy klucze GPG. Jeden na komputerze lokalnym a drugi na\nserwerze. Pokażę jak wygląda ten proces na serwerze: \n\nJego konfigurację możemy utworzyć przez\n\ncat >keydetails <<EOF\n%no-protection\nKey-Type: default\nSubkey-Type: default\nName-Real: server_name\nName-Comment: 165.xxx.xxx.80\nName-Email: gustaw.daniel@gmail.com\nExpire-Date: 0\n%no-ask-passphrase\n%commit\n%echo done\nEOF\n\nSamo wgranie wygenerowanie klucza na podstawie tego pliku wymaga wpisania\nkomendy:\n\ngpg --verbose --batch --gen-key keydetails\n\nTeraz, aby wysłać klucz na serwer dodamy musimy poznać jego id. Za pomocą\npoleceń sed oraz awk możemy wyłuskać je poleceniem:\n\ngpg --quiet -K | awk '{print $1}' | sed '4q;d'\n\nJest to długa wersja ID\n\nBEC513926DA11A7F1676CB4B15B21A69BBB0B659\n\nWysyłkę tego klucza na serwer wykonamy poleceniem:\n\ngpg --keyserver hkps://keyserver.ubuntu.com --send-keys `gpg --quiet -K | awk '{print $1}' | sed '4q;d'`\n\nPowinno ono zwrócić:\n\ngpg: sending key 15B21A69BBB0B659 to hkps://keyserver.ubuntu.com\n\nNa komputerze lokalnym możemy wpisać po prostu \n\ngpg --full-generate-key\n\nponieważ nie jest wymagany taki poziom automatyzacji.\n\nAby pobrać klucz z serwera na komputer lokalny piszemy:\n\ngpg --keyserver hkps://keyserver.ubuntu.com --recv-keys 15B21A69BBB0B659\n\nTeraz możemy dołączyć administratorów danych do blackboxa. Służą do tego\npolecenia:\n\n blackbox_addadmin 15B21A69BBB0B659\n\nktóre pozwala na dostęp do danych serwerowi oraz analogiczne z id klucza z\nkomputera lokalnego. Klucze prywatne możemy pokazać poleceniem\n\ngpg -K\n\nTeraz możemy poprawnie zaszyfrować plik .env.prod.\n\nblackbox_register_new_file .env.prod \n\nTo polecenie spowoduje, że plik .env.prod zniknie i na jego miejsce pojawi się\nzaszyfrowany .env.prod.gpg.\n\nTeraz poleceniem scp możemy przesłać ten plik na serwer i tam odczytać go. \n\nscp .env.prod.gpg root@165.xxx.xxx.80:/tmp/b2\n\nRazem z plikiem powinniśmy wysłać też ukryty katalog .blackbox, ponieważ jest on\nczęścią repozytorium.\n\nscp -r .blackbox root@165.xxx.xxx.80:/tmp/b2\n\nNastępnie na serwerze wykonujemy:\n\nblackbox_postdeploy\n\ni możemy zobaczyć odszyfrowany plik .env.prod.\n\nRozrysowanie całego procesu\n\n\n\n\nJak utworzyć klucz gpg bez interakcji ze strony użytkownika:\n\nGenerate gpg key via batch fileGenerate gpg key via batch file. GitHub Gist:\ninstantly share code, notes, and snippets.Gist262588213843476\n[https://gist.github.com/vrillusions/5484422]",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-28T15:34:48.000Z",
            "updated_at": "2021-04-29T23:10:50.000Z",
            "published_at": "2021-04-29T16:51:55.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "608a9c962fb35425592d1323",
            "uuid": "40752b32-e5ba-481d-b48c-843054b937cb",
            "title": "Rozesłanie kluczy na serwery",
            "slug": "rozeslanie-kluczy-na-serwery",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"ssh-keygen -t ed25519 -C \\\"<comment>\\\" -f ~/.ssh/new_key\"}],[\"code\",{\"code\":\"167.xxx.xxx.221\\n157.yyy.yyy.194\\n134.zzz.zzz.149\"}],[\"code\",{\"code\":\"xargs -a /tmp/ips -n 1 -I {} ssh-copy-id -i ~/.ssh/new_key root@{}\"}],[\"code\",{\"code\":\"ssh root@134.zzz.zzz.149 'tail -n 1 ~/.ssh/authorized_keys'\"}],[\"code\",{\"code\":\"cat ~/.ssh/new_key.pub\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://docs.gitlab.com/ee/ssh/\",\"metadata\":{\"url\":\"https://docs.gitlab.com/ee/ssh/\",\"title\":\"GitLab and SSH keys | GitLab\",\"description\":\"Documentation for GitLab Community Edition, GitLab Enterprise Edition, Omnibus GitLab, and GitLab Runner.\",\"author\":null,\"publisher\":\"GitLab Docs\",\"thumbnail\":\"https://docs.gitlab.com/assets/images/gitlab-logo.svg\",\"icon\":\"https://docs.gitlab.com/assets/images/apple-touch-icon.png\"}}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Aby wygenerować parę kluczy \"],[0,[0],1,\"ssh\"],[0,[],0,\" w określonej lokalizacji, używamy flagi \"],[0,[0],1,\"-f\"],[0,[],0,\". Na przykład:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Załóżmy, że w pliku \"],[0,[0],1,\"/tmp/ips\"],[0,[],0,\" mamy numery \"],[0,[0],1,\"ip\"],[0,[],0,\" serwerów. Zakładam, że już mamy wymieniony z nimi nasz podstawowy klucz.\"]]],[10,1],[1,\"p\",[[0,[],0,\"Chcemy logować się na te serwery nowym kluczem \"],[0,[0],1,\"~/.ssh/new_key\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Aby rozesłać odpowiadający mu klucz publiczny do pliku \"],[0,[0],1,\"~/.ssh/authorized_keys\"],[0,[],0,\" na tych serwerach wykonujemy polecenie \"]]],[10,2],[1,\"p\",[[0,[],0,\"Możemy zweryfikować czy się powiodło sprawdzając, czy polecenie:\"]]],[10,3],[1,\"p\",[[0,[],0,\"pokaże tą samą zawartość co lokalny plik z kluczem publicznym:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Świetny artykuł o kluczach znajdziemy tutaj:\"]]],[10,5],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Aby wygenerować parę kluczy <code>ssh</code> w określonej lokalizacji, używamy flagi <code>-f</code>. Na przykład:</p><pre><code>ssh-keygen -t ed25519 -C \"&lt;comment&gt;\" -f ~/.ssh/new_key</code></pre><p>Załóżmy, że w pliku <code>/tmp/ips</code> mamy numery <code>ip</code> serwerów. Zakładam, że już mamy wymieniony z nimi nasz podstawowy klucz.</p><pre><code>167.xxx.xxx.221\n157.yyy.yyy.194\n134.zzz.zzz.149</code></pre><p>Chcemy logować się na te serwery nowym kluczem <code>~/.ssh/new_key</code>. </p><p>Aby rozesłać odpowiadający mu klucz publiczny do pliku <code>~/.ssh/authorized_keys</code> na tych serwerach wykonujemy polecenie </p><pre><code>xargs -a /tmp/ips -n 1 -I {} ssh-copy-id -i ~/.ssh/new_key root@{}</code></pre><p>Możemy zweryfikować czy się powiodło sprawdzając, czy polecenie:</p><pre><code>ssh root@134.zzz.zzz.149 'tail -n 1 ~/.ssh/authorized_keys'</code></pre><p>pokaże tą samą zawartość co lokalny plik z kluczem publicznym:</p><pre><code>cat ~/.ssh/new_key.pub</code></pre><p>Świetny artykuł o kluczach znajdziemy tutaj:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.gitlab.com/ee/ssh/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitLab and SSH keys | GitLab</div><div class=\"kg-bookmark-description\">Documentation for GitLab Community Edition, GitLab Enterprise Edition, Omnibus GitLab, and GitLab Runner.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://docs.gitlab.com/assets/images/apple-touch-icon.png\"><span class=\"kg-bookmark-author\">GitLab Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://docs.gitlab.com/assets/images/gitlab-logo.svg\"></div></a></figure>",
            "comment_id": "608a9c962fb35425592d1323",
            "plaintext": "Aby wygenerować parę kluczy ssh w określonej lokalizacji, używamy flagi -f. Na\nprzykład:\n\nssh-keygen -t ed25519 -C \"<comment>\" -f ~/.ssh/new_key\n\nZałóżmy, że w pliku /tmp/ips mamy numery ip serwerów. Zakładam, że już mamy\nwymieniony z nimi nasz podstawowy klucz.\n\n167.xxx.xxx.221\n157.yyy.yyy.194\n134.zzz.zzz.149\n\nChcemy logować się na te serwery nowym kluczem ~/.ssh/new_key. \n\nAby rozesłać odpowiadający mu klucz publiczny do pliku ~/.ssh/authorized_keys na\ntych serwerach wykonujemy polecenie \n\nxargs -a /tmp/ips -n 1 -I {} ssh-copy-id -i ~/.ssh/new_key root@{}\n\nMożemy zweryfikować czy się powiodło sprawdzając, czy polecenie:\n\nssh root@134.zzz.zzz.149 'tail -n 1 ~/.ssh/authorized_keys'\n\npokaże tą samą zawartość co lokalny plik z kluczem publicznym:\n\ncat ~/.ssh/new_key.pub\n\nŚwietny artykuł o kluczach znajdziemy tutaj:\n\nGitLab and SSH keys | GitLabDocumentation for GitLab Community Edition, GitLab\nEnterprise Edition, Omnibus GitLab, and GitLab Runner.GitLab Docs\n[https://docs.gitlab.com/ee/ssh/]",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-29T11:46:30.000Z",
            "updated_at": "2021-04-29T12:06:59.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "608aa9202fb35425592d138d",
            "uuid": "6243db18-db47-4a73-8a84-50ce57a961ea",
            "title": "Jak skonfigurować SSL w lokalnym developmencie",
            "slug": "jak-skonfigurowac-ssl-w-lokalnym-developmencie",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"cat /etc/resolv.conf\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://wiki.archlinux.org/index.php/Domain_name_resolution\",\"metadata\":{\"url\":\"https://wiki.archlinux.org/index.php/Domain_name_resolution\",\"title\":\"Domain name resolution - ArchWiki\",\"description\":null,\"author\":null,\"publisher\":\"ArchWiki\",\"thumbnail\":\"https://wiki.archlinux.org/images/3/38/Tango-view-fullscreen.png\",\"icon\":\"https://wiki.archlinux.org/favicon.ico\"}}],[\"code\",{\"code\":\"# Static table lookup for hostnames.\\n# See hosts(5) for details.\\n127.0.0.1\\tlocalhost\\n::1\\t\\tlocalhost\\n127.0.1.1\\thp-1589\\n\"}],[\"code\",{\"code\":\"sudo nvim /etc/hosts\"}],[\"code\",{\"code\":\"127.0.0.1\\tlocal.dev\"}],[\"code\",{\"code\":\"<?php\\nheader('Content-Type: application/json');\\necho '{\\\"status\\\":\\\"ok\\\"}';\\n\"}],[\"code\",{\"code\":\"php -S localhost:8000 index.php\"}],[\"code\",{\"code\":\"http http://localhost:8000/\"}],[\"code\",{\"code\":\"http http://local.dev:8000/\"}],[\"code\",{\"code\":\"http: error: ConnectionError: HTTPConnectionPool(host='local.dev', port=8000): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fbaa2dfcc40>: Failed to establish a new connection: [Errno 111] Connection refused')) while doing a GET request to URL: http://local.dev:8000/\"}],[\"code\",{\"code\":\"getent hosts local.dev\\n127.0.0.1       local.dev\"}],[\"code\",{\"code\":\"php -S 0.0.0.0:8000 index.php\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-29-15-26-10.png\",\"width\":318,\"height\":216}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.pixelstech.net/article/1538275121-Difference-between-localhost-and-127-0-0-1\",\"metadata\":{\"url\":\"https://www.pixelstech.net/article/1538275121-Difference-between-localhost-and-127-0-0-1\",\"title\":\"Difference between localhost and 127.0.0.1\",\"description\":\"Lots of people would think what the address 127.0.0.1 is when first seeing this address. In fact, 127.0.0.1 is a loopback address which refers to the local machine. It is generally used for local test\",\"author\":null,\"publisher\":\"Pixelstech.net\",\"thumbnail\":\"https://www.pixelstech.net/images/logo.png\",\"icon\":null}}],[\"code\",{\"code\":\"yay -S nginx\"}],[\"code\",{\"code\":\"sudo systemctl start nginx.service\"}],[\"code\",{\"code\":\"sudo systemctl enable nginx.service\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-29-16-05-22.png\",\"width\":353,\"height\":416,\"caption\":\"\"}],[\"code\",{\"code\":\"launchctl load /usr/local/Cellar/nginx/1.21.4/homebrew.mxcl.nginx.plist\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://apple.stackexchange.com/a/308421\",\"metadata\":{\"url\":\"https://apple.stackexchange.com/questions/29056/launchctl-difference-between-load-and-start-unload-and-stop\",\"title\":\"Launchctl difference between load and start, unload and stop\",\"description\":\"I was reading through the launchctl man page and have a few questions about its functioning: What is the difference between load and start, unload and stop?\\nWhere do I find the job label for a dae...\",\"author\":\"Jason Rubenstein\",\"publisher\":\"Ask Different\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/apple/Img/apple-touch-icon@2.png?v=b514451ec60c\",\"icon\":\"https://cdn.sstatic.net/Sites/apple/Img/apple-touch-icon.png?v=daa7ff1d953e\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://wiki.archlinux.org/index.php/nginx\",\"metadata\":{\"url\":\"https://wiki.archlinux.org/index.php/nginx\",\"title\":\"nginx - ArchWiki\",\"description\":null,\"author\":null,\"publisher\":\"ArchWiki\",\"thumbnail\":\"https://wiki.archlinux.org/images/8/87/Tango-edit-clear.png\",\"icon\":\"https://wiki.archlinux.org/favicon.ico\"}}],[\"code\",{\"code\":\"sudo mkdir /etc/nginx/ssl\\ncd /etc/nginx/ssl\\nsudo openssl req -new -x509 -nodes -newkey rsa:4096 -keyout server.key -out server.crt -days 1095\\nsudo chmod 400 server.key\\nsudo chmod 444 server.crt\"}],[\"code\",{\"code\":\"http --verify no https://localhost\\n\\nhttp: error: ConnectionError: HTTPSConnectionPool(host='localhost', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f089f77fee0>: Failed to establish a new connection: [Errno 111] Connection refused')) while doing a GET request to URL: https://localhost/\"}],[\"code\",{\"code\":\"sudo nvim /etc/nginx/nginx.conf\"}],[\"code\",{\"code\":\"sudo nano /usr/local/etc/nginx/nginx.conf\"}],[\"code\",{\"code\":\"    server { \\n        listen       443 ssl; \\n        server_name  localhost; \\n\\n        ssl_certificate      ssl/server.crt; \\n        ssl_certificate_key  ssl/server.key; \\n\\n        location / { \\n            root   /usr/share/nginx/html; \\n            index  index.html index.htm; \\n        } \\n    } \\n\"}],[\"code\",{\"code\":\"sudo systemctl reload nginx.service\"}],[\"code\",{\"code\":\"sudo brew services restart nginx\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://newbedev.com/how-to-restart-nginx-on-mac-os-x\",\"metadata\":{\"url\":\"https://newbedev.com\",\"title\":\"How to restart Nginx on Mac OS X? | Newbedev\",\"description\":\"Solution 1: sudo nginx -s stop && sudo nginx Solution 2: For a one-liner, you could just do: sudo nginx -s reload The -s options stands for signal, and is the o\",\"author\":null,\"publisher\":\"NewbeDEV\",\"thumbnail\":\"https://newbedev.sfo3.digitaloceanspaces.com/wp-content/uploads/2021/11/12032228/BANNER-NEWBEDEV-15.png\",\"icon\":\"https://newbedev.com/android-icon-192x192.png\"}}],[\"code\",{\"code\":\"http --verify no -h https://localhost \\nHTTP/1.1 200 OK\\n\"}],[\"code\",{\"code\":\"openssl genrsa -out myCA.key 2048\"}],[\"code\",{\"code\":\"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpQIBAAKCAQEA+aKMj19W37DjX3nrQ7XTjP3trXXK5hLvByRDKL/QsMGOrxac\\n...\\nXt0itnAcq1vPqqRcsV+YPAE8oyAOXHM1aaTQIH5mp5jHySOqZtSFca8=\\n-----END RSA PRIVATE KEY-----\\n\"}],[\"code\",{\"code\":\"openssl req -x509 -new -nodes -key myCA.key -sha256 -days 825 -out myCA.pem\"}],[\"code\",{\"code\":\"You are about to be asked to enter information that will be incorporated\\ninto your certificate request.\\nWhat you are about to enter is what is called a Distinguished Name or a DN.\\nThere are quite a few fields but you can leave some blank\\nFor some fields there will be a default value,\\nIf you enter '.', the field will be left blank.\\n-----\\nCountry Name (2 letter code) [AU]:PL\\nState or Province Name (full name) [Some-State]:Mazovian\\nLocality Name (eg, city) []:Warsaw\\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Precise Lab CA\\nOrganizational Unit Name (eg, section) []:\\nCommon Name (e.g. server FQDN or YOUR name) []:PL_CA\\nEmail Address []:gustaw.daniel@gmail.com\"}],[\"code\",{\"code\":\"-----BEGIN CERTIFICATE-----\\nMIID5zCCAs+gAwIBAgIUUfo+Snobo0e/HXHJm5Hf4B0TvGEwDQYJKoZIhvcNAQEL\\n...\\n7ntEpRg3YZUdDtM0ptDvETM8+H35V9aZtUo1/e2136x459pGZd1aJz+Hhg==\\n-----END CERTIFICATE-----\\n\"}],[\"code\",{\"code\":\"NAME=local.dev\"}],[\"code\",{\"code\":\"openssl genrsa -out $NAME.key 2048\"}],[\"code\",{\"code\":\"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEApvXY4EiWGELQuVTEH9YZ8Qoi0Owq39cQ+g93e7EaKlMzx1fU\\n...\\nVburjZcC/InypDy0ZChc6tC0z5A6qkWlLA+3eGs8ADtvQ4qtCS9+Aw==\\n-----END RSA PRIVATE KEY-----\"}],[\"code\",{\"code\":\"openssl req -new -key local.dev.key -out local.dev.csr\"}],[\"code\",{\"code\":\"You are about to be asked to enter information that will be incorporated\\ninto your certificate request.\\nWhat you are about to enter is what is called a Distinguished Name or a DN.\\nThere are quite a few fields but you can leave some blank\\nFor some fields there will be a default value,\\nIf you enter '.', the field will be left blank.\\n-----\\nCountry Name (2 letter code) [AU]:PL\\nState or Province Name (full name) [Some-State]:Mazovian\\nLocality Name (eg, city) []:Warsaw\\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Precise Lab Org\\nOrganizational Unit Name (eg, section) []:\\nCommon Name (e.g. server FQDN or YOUR name) []:PL   \\nEmail Address []:gustaw.daniel@gmail.com\\n\\nPlease enter the following 'extra' attributes\\nto be sent with your certificate request\\nA challenge password []:\\nAn optional company name []:\\n\"}],[\"code\",{\"code\":\"-----BEGIN CERTIFICATE REQUEST-----\\nMIICxjCCAa4CAQAwgYAxCzAJBgNVBAYTAlBMMREwDwYDVQQIDAhNYXpvdmlhbjEP\\n...\\n9f1qkg6LHapOjzevheKWEjWG1hnJjBOj42mmIDBVZBHVszP7rrfiRMma\\n-----END CERTIFICATE REQUEST-----\\n\"}],[\"code\",{\"code\":\"authorityKeyIdentifier=keyid,issuer\\nbasicConstraints=CA:FALSE\\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\\nsubjectAltName = @alt_names\\n[alt_names]\\nDNS.1 = local.dev\"}],[\"code\",{\"code\":\"openssl x509 -req -in $NAME.csr -CA myCA.pem -CAkey myCA.key -CAcreateserial -out $NAME.crt -days 825 -sha256 -extfile $NAME.ext\"}],[\"code\",{\"code\":\"Signature ok\\nsubject=C = PL, ST = Mazovian, L = Warsaw, O = Precise Lab, emailAddress = gustaw.daniel@gmail.com\\nGetting CA Private Key\"}],[\"code\",{\"code\":\"openssl verify -CAfile myCA.pem -verify_hostname local.dev local.dev.crt\\n                                                                                                         \\nlocal.dev.crt: OK\\n\"}],[\"code\",{\"code\":\"openssl verify -CAfile myCA.pem local.dev.crt\"}],[\"code\",{\"code\":\"chrome://settings/certificates\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-01-52-21.png\",\"width\":1296,\"height\":776}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-01-52-11.png\",\"width\":629,\"height\":375}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/2021-11-15_16-37.png\",\"width\":1794,\"height\":1088}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/2021-11-15_16-39.png\",\"width\":558,\"height\":303}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/2021-11-15_15-49.png\",\"width\":1726,\"height\":866}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/2021-11-15_15-54.png\",\"width\":2636,\"height\":1666}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/2021-11-15_16-34.png\",\"width\":2506,\"height\":1670}],[\"code\",{\"code\":\"    server {\\n        listen       443 ssl;\\n        server_name  local.dev;\\n\\n        ssl_certificate      ssl/local.dev.crt;\\n        ssl_certificate_key  ssl/local.dev.key;\\n\\n        location / {\\n                proxy_pass          http://127.0.0.1:8000;\\n                proxy_set_header    Host             $host;\\n                proxy_set_header    X-Real-IP        $remote_addr;\\n                proxy_set_header    X-Forwarded-For  $proxy_add_x_forwarded_for;\\n                proxy_set_header    X-Client-Verify  SUCCESS;\\n                proxy_set_header    X-Client-DN      $ssl_client_s_dn;\\n                proxy_set_header    X-SSL-Subject    $ssl_client_s_dn;\\n                proxy_set_header    X-SSL-Issuer     $ssl_client_i_dn;\\n                proxy_read_timeout 1800;\\n                proxy_connect_timeout 1800;\\n        }\\n    }\\n\"}],[\"code\",{\"code\":\"sudo systemctl reload nginx.service\"}],[\"code\",{\"code\":\"sudo brew services restart nginx\\nsudo pkill nginx\\nsudo nginx\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-01-52-38.png\",\"width\":468,\"height\":363}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/2021-11-15_16-43.png\",\"width\":778,\"height\":436}],[\"code\",{\"code\":\"http https://local.dev \\n\\nhttp: error: SSLError: HTTPSConnectionPool(host='local.dev', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)'))) while doing a GET request to URL: https://local.dev/\\n\"}],[\"code\",{\"code\":\"http --verify /etc/nginx/ssl/myCA.pem https://local.dev\"}],[\"code\",{\"code\":\"http --verify /usr/local/etc/nginx/ssl/myCA.pem https://local.dev\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-02-15-33.png\",\"width\":529,\"height\":256}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/5u96xh.jpeg\",\"width\":674,\"height\":370}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://auth0.com/docs/libraries/secure-local-development#how-to-set-up-a-secure-local-server\",\"metadata\":{\"url\":\"https://auth0.com/docs/\",\"title\":\"HTTPS in Development\",\"description\":\"Securing local development servers to work with samesite cookies\",\"author\":\"Auth0\",\"publisher\":\"Auth0 Docs\",\"thumbnail\":\"https://cdn2.auth0.com/docs/media/social-media/fb-card.png\",\"icon\":\"https://cdn.auth0.com/website/new-homepage/dark-favicon.png\"}}],[\"code\",{\"code\":\"yay -S caddy\"}],[\"code\",{\"code\":\"brew install caddy\"}],[\"code\",{\"code\":\"sudo pkill nginx\"}],[\"code\",{\"code\":\"caddy reverse-proxy --from localhost:443 --to localhost:8000\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/2021-11-15_17-05.png\",\"width\":709,\"height\":723}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/2021-11-15_17-06.png\",\"width\":1032,\"height\":477}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/2021-11-15_17-06_1.png\",\"width\":1730,\"height\":202}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://caddyserver.com/docs/getting-started\",\"metadata\":{\"url\":\"https://caddyserver.com\",\"title\":\"Getting Started - Caddy Documentation\",\"description\":\"Caddy is a powerful, enterprise-ready, open source web server with automatic HTTPS written in Go\",\"author\":\"Caddy Web Server\",\"publisher\":null,\"thumbnail\":\"https://caddyserver.com/resources/images/caddy-open-graph.jpg\",\"icon\":\"https://caddyserver.com/resources/images/favicon.png\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://stackoverflow.com/questions/44443269/how-to-use-a-ca-like-curls-cacert-with-httpie/67326625#67326625\",\"metadata\":{\"url\":\"https://stackoverflow.com/questions/44443269/how-to-use-a-ca-like-curls-cacert-with-httpie\",\"title\":\"How to use a CA (like curl’s --cacert) with HTTPie\",\"description\":\"In curl I can connect with a private key, client cert, and a ca cert like this curl --cert cert.pem --key key.pem --cacert ca.pem https://example.org I can see the --cert and --cert-key options in\",\"author\":\"Ahmadster\",\"publisher\":\"Stack Overflow\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded\",\"icon\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://stackoverflow.com/a/35867609/6398044\",\"metadata\":{\"url\":\"https://stackoverflow.com/questions/27963749/setup-https-ssl-on-localhost-for-meteor-development\",\"title\":\"Setup (https) SSL on localhost for meteor development\",\"description\":\"How do you create a self signed SSL certificate to use on local server on mac 10.9? I require my localhost serving as https://localhost I am using the linkedin API. The feature which requires the...\",\"author\":\"meteorBuzz\",\"publisher\":\"Stack Overflow\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded\",\"icon\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"http://markstutpnt.blogspot.com/2019/01/error-18-at-0-depth-lookup-self-signed.html\",\"metadata\":{\"url\":\"http://markstutpnt.blogspot.com/2019/01/error-18-at-0-depth-lookup-self-signed.html\",\"title\":\"error 18 at 0 depth lookup: self signed certificate\",\"description\":\"I was trying to test SSL connection between MySQL client and server. For that I created SSL certificate and keys by following the MySQL doc...\",\"author\":\"Abhishek G\",\"publisher\":\"Blogger\",\"thumbnail\":\"https://lh3.googleusercontent.com/ULB6iBuCeTVvSjjjU1A-O8e9ZpVba6uvyhtiWRti_rBAs9yMYOFBujxriJRZ-A=w1200\",\"icon\":\"http://markstutpnt.blogspot.com/favicon.ico\"}}]],\"markups\":[[\"code\"],[\"a\",[\"href\",\"https://www.javatpoint.com/installing-nginx-on-mac\"]],[\"a\",[\"href\",\"https://local.dev/\"]],[\"a\",[\"href\",\"https://localhost\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Ustawianie certyfikatu ssl podczas developmentu może być poważnym wyzwaniem. Nie wynika to ze złożoności tego zadania, ale z pułapek, w jakie można wpaść jeśli posiada się luki w wiedzy na temat sieci, certyfikatów i protokołu https.\"]]],[1,\"p\",[[0,[],0,\"W tym wpisie pokażę jak krok po kroku przejść przez proces ustawiania lokalnego developmentu z https. Zrobimy przy tym kilka dygresji dotyczących problemów jakie mogą się pojawić.\"]]],[1,\"p\",[[0,[],0,\"W tym wpisie opisuję jak nadpisać zewnętrzne DNS, utworzyć organizację certyfikującą, przygotować żądanie utworzenia certyfikatu dla domeny, spełnić je, zaufać tej organizacji, skonfigurować serwer nginx do proxowania ruchu i używania certyfikatu domeny i finalnie cieszyć się połączeniem https.\"]]],[1,\"h2\",[[0,[],0,\"Lokalna domena\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od podstaw. Czyli lokalnego przekierowania domeny na nasz lokalny komputer. Zwykle kiedy pytamy przeglądarki o domenę serwery DNS ustawione w naszym komputerze dostarczają na numer IP na który należy wysłać żądanie.\"]]],[1,\"p\",[[0,[],0,\"Ustawienia \"],[0,[0],1,\"DNS\"],[0,[],0,\" dla naszego komputera możemy sprawdzić w pliku \"],[0,[0],1,\"resolv.conf\"]]],[10,0],[10,1],[1,\"p\",[[0,[],0,\"Nie zawsze jednak musimy pytać o IP serwerów \"],[0,[0],1,\"DNS\"],[0,[],0,\". Zapytania do zewnętrznych serwerów DNS możemy przesłonić naszymi wpisami w pliku \"],[0,[0],1,\"/etc/hosts\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Zawartość tego pliku może u Ciebie wyglądać tak:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Aby dodać do niego naszą domenę musimy edytować plik \"],[0,[0],1,\"hosts\"]]],[10,3],[1,\"p\",[[0,[],0,\"Dodajemy na końcu linię:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Aby przetestować tą konfigurację napiszemy prostą stronę w \"],[0,[0],1,\"php\"],[0,[],0,\". Do pliku \"],[0,[0],1,\"index.php\"],[0,[],0,\" zapisujemy:\"]]],[10,5],[1,\"p\",[[0,[],0,\"Możemy ją hostować poleceniem\"]]],[10,6],[1,\"p\",[[0,[],0,\"Naturalnie polecenie:\"]]],[10,7],[1,\"p\",[[0,[],0,\"zwróci nam \"],[0,[0],1,\"{\\\"status\\\": \\\"ok\\\"}\"],[0,[],0,\". Niestety zapytanie o domenę:\"]]],[10,8],[1,\"p\",[[0,[],0,\"pokarze błąd:\"]]],[10,9],[1,\"p\",[[0,[],0,\"Domena kieruje nas w odpowiednie miejsce co może potwierdzić \"],[0,[0],1,\"getent\"]]],[10,10],[1,\"p\",[[0,[],0,\"Problem leży w ograniczeniu hostów na których jest ustawiony serwer.\"]]],[1,\"blockquote\",[[0,[],0,\"Pułapka 1: sprawdź jakiego hosta ma twój lokalny server.\"]]],[1,\"p\",[[0,[],0,\"W komendzie \"],[0,[0],1,\"php -S localhost:8000 index.php\"],[0,[],0,\" nie powinniśmy używać \"],[0,[0],1,\"localhost\"],[0,[],0,\". Jest to częsty przypadek również w innych językach, gdzie frameworki serwują domyślnie na hoście localhost a powinny na \"],[0,[0],1,\"0.0.0.0\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Aby naprawić problem wyłączamy serwer i stawiamy go komendą\"]]],[10,11],[1,\"p\",[[0,[],0,\"Tym razem działa on poprawnie.\"]]],[10,12],[1,\"p\",[[0,[],0,\"Dlaczego tak jest? Sam localhost stanowi tylko alias względem adresu \"],[0,[0],1,\"127.0.0.1\"],[0,[],0,\". Nasza domena \"],[0,[0],1,\"local.dev\"],[0,[],0,\" też jest aliasem do \"],[0,[0],1,\"127.0.0.1\"],[0,[],0,\" ale już nie do \"],[0,[0],1,\"localhost\"],[0,[],0,\". Ustawiając serwer komendą: \"],[0,[0],1,\"php -S 127.0.0.1:8000 index.php\"],[0,[],0,\", też uzyskaliśmy pożądany wynik. Chyba, że pracowali byśmy z adresacją ipv6, wtedy zamiast lub obok \"],[0,[0],1,\"127.0.0.1\"],[0,[],0,\" w \"],[0,[0],1,\"/etc/hosts\"],[0,[],0,\" ustawili byśmy \"],[0,[0],1,\"::1\"],[0,[],0,\". Jeśli temat różnic między \"],[0,[0],1,\"localhost\"],[0,[],0,\" a \"],[0,[0],1,\"127.0.0.1\"],[0,[],0,\" jest dla Ciebie nowy polecam Ci artykuł: \"]]],[10,13],[1,\"h2\",[[0,[],0,\"Instalacja Nginx\"]]],[1,\"p\",[[0,[],0,\"Pokazane tu rozwiązanie, to nie jedyna droga, bo wiele serwerów i frameworków ma swoje własne rozwiązania do ssl w lokalnym developmencie. Zaletą mojego podejścia jest uniwersalność. \"]]],[1,\"p\",[[0,[],0,\"Instalacja serwera \"],[0,[0],1,\"nginx\"]]],[10,14],[1,\"p\",[[0,[],0,\"Włączamy go:\"]]],[10,15],[1,\"p\",[[0,[],0,\"Jeśli chcemy, żeby startował przy każdym włączeniu systemy dodajemy:\"]]],[10,16],[1,\"p\",[[0,[],0,\"Sam nie używał bym tego drugiego polecenia na komputerze lokalnym, ponieważ niepotrzebnie blokuje port \"],[0,[0],1,\"80\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Po instalacji \"],[0,[0],1,\"nginx\"],[0,[],0,\" przywitał nas swoją stroną startową na porcie \"],[0,[0],1,\"80\"],[0,[],0,\". \"]]],[10,17],[1,\"h3\",[[0,[],0,\"Nginx w Mac OS\"]]],[1,\"p\",[[0,[],0,\"Na systemie \"],[0,[0],1,\"Mac OS\"],[0,[],0,\" ngnix domyślnie startuje na porcie \"],[0,[0],1,\"8080\"]]],[1,\"p\",[[0,[1],1,\"https://www.javatpoint.com/installing-nginx-on-mac\"]]],[1,\"p\",[[0,[],0,\"Możemy to zmienić edytując plik \"],[0,[0],1,\"/usr/local/etc/nginx/nginx.conf\"],[0,[],0,\" a sam serwer włączyć poleceniem\"]]],[10,18],[1,\"p\",[[0,[],0,\"przy czym wersja w Twoim systemie może różnić się od tej podanej przeze mnie. Odpowiednikiem archowego \"],[0,[0],1,\"enable\"],[0,[],0,\" jest opcjonalna flaga \"],[0,[0],1,\"-w\"]]],[10,19],[1,\"h2\",[[0,[],0,\"Przygotowanie certyfikatu self-signed\"]]],[1,\"p\",[[0,[],0,\"Aby móc posługiwać się certyfikatem SSL podczas lokalnego developmentu aplikacji należy posłużyć się certyfikatem \"],[0,[0],1,\"self-signed\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Jego utworzenie opisano w dokumentacji archa:\"]]],[10,20],[1,\"p\",[[0,[],0,\"Interesujące nas polecenia to:\"]]],[10,21],[1,\"p\",[[0,[],0,\"Na \"],[0,[0],1,\"Mac OS\"],[0,[],0,\" lepszą lokalizacją będzie katalog \"],[0,[0],1,\"/usr/local/etc/nginx/ssl\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Dołączenie certyfikatu do Nginx\"]]],[1,\"p\",[[0,[],0,\"W tej chwili nasz certyfikat nie jest jeszcze podłączony do serwera. Nginx nie nasłuchuje na porcie \"],[0,[0],1,\"443\"],[0,[],0,\" i przez to zapytanie o \"],[0,[0],1,\"https://localhost\"],[0,[],0,\" kończy się niepowodzeniem:\"]]],[10,22],[1,\"p\",[[0,[],0,\"Zmienimy teraz ustawienia \"],[0,[0],1,\"nginx\"],[0,[],0,\" \"]]],[10,23],[1,\"p\",[[0,[],0,\"lub na \"],[0,[0],1,\"Mac OS\"],[0,[],0,\" \"]]],[10,24],[1,\"p\",[[0,[],0,\"dodając pod kluczem \"],[0,[0],1,\"http\"],[0,[],0,\" wpis:\"]]],[10,25],[1,\"p\",[[0,[],0,\"Po przeładowaniu serwisu komendą:\"]]],[10,26],[1,\"p\",[[0,[],0,\"lub na \"],[0,[0],1,\"Mac OS\"]]],[10,27],[10,28],[1,\"p\",[[0,[],0,\"zobaczymy, że domyślna strona nginx jest dostępna pod \"],[0,[0],1,\"https\"],[0,[],0,\":\"]]],[10,29],[1,\"p\",[[0,[],0,\"Zaletą takiej konfiguracji jest to, że https działa, ale certyfikaty samopodpisane nie są obsługiwane przez \"],[0,[0],1,\"httpie\"],[0,[],0,\" a przeglądarka też może mieć z nimi problemy.\"]]],[1,\"p\",[[0,[],0,\"Aby przejść do kolejnego kroku skasujemy te certyfikaty. Nie będziemy ich więcej używać. Zamiast certyfikatów samo-podpisanych stworzymy organizację, która podpisze nam certyfikat domeny.\"]]],[1,\"h2\",[[0,[],0,\"Przekierowanie ssl do aplikacji\"]]],[1,\"p\",[[0,[],0,\"Stajemy się weryfikatorem certyfikatów (CA)\"]]],[1,\"h4\",[[0,[],0,\"Weryfikator Certyfikatów (CA)\"]]],[1,\"p\",[[0,[],0,\"Generowanie klucza prywatnego bez hasła\"]]],[10,30],[1,\"p\",[[0,[],0,\"To polecenie tworzy plik \"],[0,[0],1,\"myCA.key\"],[0,[],0,\" \"]]],[10,31],[1,\"p\",[[0,[],0,\"Generowanie certyfikatu \"],[0,[0],1,\"root\"],[0,[],0,\".\"]]],[10,32],[1,\"p\",[[0,[],0,\"Dostajemy pytania o dane instytucji certyfikującej. Na pytania odpowiedziałem w następujący sposób:\"]]],[10,33],[1,\"p\",[[0,[],0,\"dostaliśmy plik \"],[0,[0],1,\"myCA.pem\"],[0,[],0,\" o zawartości\"]]],[10,34],[1,\"h4\",[[0,[],0,\"Certyfikat podpisany\"]]],[1,\"p\",[[0,[],0,\"Tworzymy \"],[0,[0],1,\"CA-signed\"],[0,[],0,\" certyfikat (już nie samo-podpisany)\"]]],[1,\"p\",[[0,[],0,\"Definiujemy zmienną z zapisaną domeną:\"]]],[10,35],[1,\"p\",[[0,[],0,\"Generujemy klucz prywatny\"]]],[10,36],[1,\"p\",[[0,[],0,\"dostajemy plik \"],[0,[0],1,\"local.dev.key\"],[0,[],0,\" o treści\"]]],[10,37],[1,\"p\",[[0,[],0,\"Następnie tworzymy żądanie jego podpisania.\"]]],[10,38],[1,\"p\",[[0,[],0,\"Ponownie jesteśmy pytani o dane. Tym razem są to dane organizacji chcącej podpisać certyfikat. Nie możemy podać tej samej \"],[0,[0],1,\"Common Name\"],[0,[],0,\". Moje odpowiedzi:\"]]],[10,39],[1,\"p\",[[0,[],0,\"Po wykonaniu tego polecenia dostajemy plik \"],[0,[0],1,\"local.dev.csr\"],[0,[],0,\" o treści:\"]]],[10,40],[1,\"p\",[[0,[],0,\"Teraz utworzymy plik konfiguracyjny rozszerzenia. Zapisujemy do pliku \"],[0,[0],1,\"$NAME.ext\"],[0,[],0,\" zawartość\"]]],[10,41],[1,\"p\",[[0,[],0,\"Tworzymy podpisany certyfikat\"]]],[10,42],[1,\"p\",[[0,[],0,\" Jeśli wszystko się powiodło powinniśmy zobaczyć:\"]]],[10,43],[1,\"p\",[[0,[],0,\"Sprawdzenie czy poprawnie zbudowaliśmy certyfikat możemy wykonać komendą:\"]]],[10,44],[1,\"p\",[[0,[],0,\"lub na \"],[0,[0],1,\"Mac OS\"]]],[10,45],[1,\"p\",[[0,[],0,\"Podsumujmy kroki, które wykonaliśmy:\"]]],[3,\"ul\",[[[0,[],0,\"zostaliśmy organizacją certyfikującą \\\"Precise Lab CA\\\", która ma klucz \"],[0,[0],1,\"myCA.key\"],[0,[],0,\" i certyfikat \"],[0,[0],1,\"myCA.pem\"]],[[0,[],0,\"podpisaliśmy certyfikat domeny używając certyfikatu i klucza organizacji certyfikującej dla domeny. Był do tego potrzebny jej klucz \"],[0,[0],1,\"local.dev.key\"],[0,[],0,\", żądanie jego podpisania \"],[0,[0],1,\"local.dev.csr\"],[0,[],0,\" wystawione przez \\\"Precise Lab Org\\\" i plik konfiguracyjny rozszerzenia \"],[0,[0],1,\"local.dev.ext\"]],[[0,[],0,\"podpisany certyfikat znajduje się w pliku \"],[0,[0],1,\"local.dev.crt\"],[0,[],0,\".\"]]]],[1,\"h4\",[[0,[],0,\"Zaufanie organizacji certyfikującej w Chrome\"]]],[1,\"p\",[[0,[],0,\"Teraz powinniśmy zaufać organizacji certyfikującej. Dodajmy jej plik \"],[0,[0],1,\"pem\"],[0,[],0,\" jako \"],[0,[0],1,\"Authority\"],[0,[],0,\" w ustawieniach przeglądarki. W pasku adresu wpisujemy:\"]]],[10,46],[1,\"p\",[[0,[],0,\"Zobaczymy:\"]]],[10,47],[1,\"p\",[[0,[],0,\"Po kliknięciu import i wybraniu pliku \"],[0,[0],1,\"myCA.pem\"],[0,[],0,\" zaznaczamy jakim operacjom tej organizacji chcemy ufać:\"]]],[10,48],[1,\"h4\",[[0,[],0,\"Zaufanie organizacji certyfikującej w Firefox\"]]],[1,\"p\",[[0,[],0,\"W Firefox wchodzimy na adres \"],[0,[0],1,\"about:preferences#privacy\"],[0,[],0,\" i w zakładce \\\"Certificates\\\" do \\\"View Certificates\\\". Następnie wybieramy import i plik \"],[0,[0],1,\"myCA.pem\"]]],[10,49],[1,\"p\",[[0,[],0,\" od razu zaznaczamy organizację certyfikującą jako zaufaną\"]]],[10,50],[1,\"p\",[[0,[],0,\"W przeciwieństwie do Chrome, te ustawienia są niezależne od systemu operacyjnego.\"]]],[1,\"h4\",[[0,[],0,\"Zaufanie organizacji certyfikującej na Mac OS w Chrome\"]]],[1,\"p\",[[0,[],0,\"Na komputerach z \"],[0,[0],1,\"Mac OS\"],[0,[],0,\" nie możemy zmienić ustawień bezpośrednio w chome. Zamiast tego otwieramy finder. Znajdujemy w nim plik \"],[0,[0],1,\"myCA.pem\"],[0,[],0,\" i klikamy go dwa razy. \"]]],[10,51],[1,\"p\",[[0,[],0,\"po potwierdzeniu hasłem powinniśmy zobaczyć w programie \\\"Pęk Kluczy\\\" (Keychain) naszą organizację w zakładce \\\"Certificates\\\"\"]]],[10,52],[1,\"p\",[[0,[],0,\"Teraz musimy oznaczyć ten certyfikat jako zaufany wybierając opcję \\\"Always Trust\\\".\"]]],[10,53],[1,\"h4\",[[0,[],0,\"Konfiguracja Nginx jako proxy\"]]],[1,\"p\",[[0,[],0,\"Kolejny raz zmieniamy ustawienia \"],[0,[0],1,\"nginx\"],[0,[],0,\". Tym razem przełączamy się na wygenerowany certyfikat i jego klucz.\"]]],[10,54],[1,\"p\",[[0,[],0,\"Nie możemy zapomnieć o przeładowaniu serwera:\"]]],[10,55],[1,\"p\",[[0,[],0,\"Na \"],[0,[0],1,\"Mac OS\"],[0,[],0,\" nie ma \"],[0,[0],1,\"systemctl\"],[0,[],0,\" i używamy \"],[0,[0],1,\"brew\"]]],[10,56],[1,\"p\",[[0,[],0,\"Po wejściu na stronę:\"]]],[1,\"blockquote\",[[0,[2],1,\"https://local.dev/\"]]],[1,\"p\",[[0,[],0,\"możemy cieszyć się widokiem kłódki przy adresie lokalnej strony:\"]]],[3,\"ul\",[[[0,[],0,\"na Chrome\"]]]],[10,57],[3,\"ul\",[[[0,[],0,\"oraz na Firefox\"]]]],[10,58],[1,\"p\",[[0,[],0,\"W konsoli nie zobaczymy jednak poprawnego wyniku:\"]]],[10,59],[1,\"p\",[[0,[],0,\"Błąd mówi nam, że nie udało się zweryfikować lokalnego wystawcy certyfikatu. Aby request z konsoli zadziałał musimy wskazać certyfikat organizacji weryfikującej jako argument flagi \"],[0,[0],1,\"--verify\"],[0,[],0,\".\"]]],[10,60],[1,\"p\",[[0,[],0,\"lub na \"],[0,[0],1,\"Mac OS\"]]],[10,61],[10,62],[1,\"h3\",[[0,[],0,\"Zastosowania lokalnego certyfikatu SSL\"]]],[1,\"p\",[[0,[],0,\"Pokazaliśmy jak skonfigurować połączenie po https na lokalnym komputerze, co jest szczególnie przydatne w developmencie aplikacji webowych. Zwykle można rozwijać swoje projekty lokalnie z użyciem \"],[0,[0],1,\"http\"],[0,[],0,\". \"]]],[10,63],[1,\"p\",[[0,[],0,\"Czasami \"],[0,[0],1,\"https\"],[0,[],0,\" jest wymagany przez takie mechanizmy jak:\"]]],[3,\"ul\",[[[0,[],0,\"ustawienia Secure lub SameSite dla Cookie\"]],[[0,[],0,\"ustawienia dostępu dla kamery lub mikrofonu w przeglądarce\"]],[[0,[],0,\"niektóre adresy webhooks zewnętrznych API\"]]]],[1,\"h3\",[[0,[],0,\"Zalety i wady Caddy\"]]],[1,\"p\",[[0,[],0,\"Auth0 w swojej dokumentacji rekomenduje wykorzystanie programu \"],[0,[0],1,\"caddy\"],[0,[],0,\".\"]]],[10,64],[1,\"p\",[[0,[],0,\"Jego instalacja to\"]]],[10,65],[1,\"p\",[[0,[],0,\"lub\"]]],[10,66],[1,\"p\",[[0,[],0,\"Wyłączymy teraz nasz serwer \"],[0,[0],1,\"nginx\"],[0,[],0,\". \"]]],[10,67],[1,\"p\",[[0,[],0,\"uruchamiany \"],[0,[0],1,\"caddy\"],[0,[],0,\" poleceniem\"]]],[10,68],[1,\"p\",[[0,[],0,\"I mamy następujący efekt:\"]]],[3,\"ol\",[[[0,[],0,\"Na chrome działa nam kłódka na stronie \"],[0,[0],1,\"https://localhost\"]]]],[10,69],[1,\"p\",[[0,[],0,\"2. Na Firefox \"],[0,[0],1,\"https://localhost\"],[0,[],0,\" nie działa\"]]],[10,70],[1,\"p\",[[0,[],0,\"3. Z poziomu linii komend (httpie) też nie działa\"]]],[10,71],[1,\"p\",[[0,[],0,\"4. Z drugiej strony curl działa \"],[0,[0],0,\"curl \"],[0,[3],2,\"https://localhost\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Czyli \\\"caddy\\\" to metoda na bardzo szybkie konfigurowanie lokalnego ssl ale z ograniczeniami. Ich dokumentacja wygląda obiecująco, ale można się spodziewać, że napotykając na błędy będziemy mieli znacznie mniejsze szanse na support od community, niż w przypadku samodzielnej konfiguracji zgodnie z krokami przedstawionymi w tym wpisie. Jeśli zaczniemy od Caddy bez rozumienia jak skonfigurować ssl samodzielnie, to szansa, że spotkane błędy zatrzymają nas na długi czas znacznie wzrośnie.\"]]],[10,72],[1,\"h4\",[[0,[],0,\"Wartościowe linki pogłębiające temat SSL\"]]],[1,\"p\",[[0,[],0,\"Przygotowując ten wpis korzystałem z wielu zewnętrznych źródeł. Najbardziej wartościowe jakie znalazłem są podlinkowane poniżej.\"]]],[10,73],[10,74],[10,75],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Ustawianie certyfikatu ssl podczas developmentu może być poważnym wyzwaniem. Nie wynika to ze złożoności tego zadania, ale z pułapek, w jakie można wpaść jeśli posiada się luki w wiedzy na temat sieci, certyfikatów i protokołu https.</p><p>W tym wpisie pokażę jak krok po kroku przejść przez proces ustawiania lokalnego developmentu z https. Zrobimy przy tym kilka dygresji dotyczących problemów jakie mogą się pojawić.</p><p>W tym wpisie opisuję jak nadpisać zewnętrzne DNS, utworzyć organizację certyfikującą, przygotować żądanie utworzenia certyfikatu dla domeny, spełnić je, zaufać tej organizacji, skonfigurować serwer nginx do proxowania ruchu i używania certyfikatu domeny i finalnie cieszyć się połączeniem https.</p><h2 id=\"lokalna-domena\">Lokalna domena</h2><p>Zaczniemy od podstaw. Czyli lokalnego przekierowania domeny na nasz lokalny komputer. Zwykle kiedy pytamy przeglądarki o domenę serwery DNS ustawione w naszym komputerze dostarczają na numer IP na który należy wysłać żądanie.</p><p>Ustawienia <code>DNS</code> dla naszego komputera możemy sprawdzić w pliku <code>resolv.conf</code></p><pre><code>cat /etc/resolv.conf</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://wiki.archlinux.org/index.php/Domain_name_resolution\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Domain name resolution - ArchWiki</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://wiki.archlinux.org/favicon.ico\"><span class=\"kg-bookmark-author\">ArchWiki</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://wiki.archlinux.org/images/3/38/Tango-view-fullscreen.png\"></div></a></figure><p>Nie zawsze jednak musimy pytać o IP serwerów <code>DNS</code>. Zapytania do zewnętrznych serwerów DNS możemy przesłonić naszymi wpisami w pliku <code>/etc/hosts</code>.</p><p>Zawartość tego pliku może u Ciebie wyglądać tak:</p><pre><code># Static table lookup for hostnames.\n# See hosts(5) for details.\n127.0.0.1\tlocalhost\n::1\t\tlocalhost\n127.0.1.1\thp-1589\n</code></pre><p>Aby dodać do niego naszą domenę musimy edytować plik <code>hosts</code></p><pre><code>sudo nvim /etc/hosts</code></pre><p>Dodajemy na końcu linię:</p><pre><code>127.0.0.1\tlocal.dev</code></pre><p>Aby przetestować tą konfigurację napiszemy prostą stronę w <code>php</code>. Do pliku <code>index.php</code> zapisujemy:</p><pre><code>&lt;?php\nheader('Content-Type: application/json');\necho '{\"status\":\"ok\"}';\n</code></pre><p>Możemy ją hostować poleceniem</p><pre><code>php -S localhost:8000 index.php</code></pre><p>Naturalnie polecenie:</p><pre><code>http http://localhost:8000/</code></pre><p>zwróci nam <code>{\"status\": \"ok\"}</code>. Niestety zapytanie o domenę:</p><pre><code>http http://local.dev:8000/</code></pre><p>pokarze błąd:</p><pre><code>http: error: ConnectionError: HTTPConnectionPool(host='local.dev', port=8000): Max retries exceeded with url: / (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7fbaa2dfcc40&gt;: Failed to establish a new connection: [Errno 111] Connection refused')) while doing a GET request to URL: http://local.dev:8000/</code></pre><p>Domena kieruje nas w odpowiednie miejsce co może potwierdzić <code>getent</code></p><pre><code>getent hosts local.dev\n127.0.0.1       local.dev</code></pre><p>Problem leży w ograniczeniu hostów na których jest ustawiony serwer.</p><blockquote>Pułapka 1: sprawdź jakiego hosta ma twój lokalny server.</blockquote><p>W komendzie <code>php -S localhost:8000 index.php</code> nie powinniśmy używać <code>localhost</code>. Jest to częsty przypadek również w innych językach, gdzie frameworki serwują domyślnie na hoście localhost a powinny na <code>0.0.0.0</code>.</p><p>Aby naprawić problem wyłączamy serwer i stawiamy go komendą</p><pre><code>php -S 0.0.0.0:8000 index.php</code></pre><p>Tym razem działa on poprawnie.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-29-15-26-10.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"318\" height=\"216\"></figure><p>Dlaczego tak jest? Sam localhost stanowi tylko alias względem adresu <code>127.0.0.1</code>. Nasza domena <code>local.dev</code> też jest aliasem do <code>127.0.0.1</code> ale już nie do <code>localhost</code>. Ustawiając serwer komendą: <code>php -S 127.0.0.1:8000 index.php</code>, też uzyskaliśmy pożądany wynik. Chyba, że pracowali byśmy z adresacją ipv6, wtedy zamiast lub obok <code>127.0.0.1</code> w <code>/etc/hosts</code> ustawili byśmy <code>::1</code>. Jeśli temat różnic między <code>localhost</code> a <code>127.0.0.1</code> jest dla Ciebie nowy polecam Ci artykuł: </p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.pixelstech.net/article/1538275121-Difference-between-localhost-and-127-0-0-1\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Difference between localhost and 127.0.0.1</div><div class=\"kg-bookmark-description\">Lots of people would think what the address 127.0.0.1 is when first seeing this address. In fact, 127.0.0.1 is a loopback address which refers to the local machine. It is generally used for local test</div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">Pixelstech.net</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.pixelstech.net/images/logo.png\"></div></a></figure><h2 id=\"instalacja-nginx\">Instalacja Nginx</h2><p>Pokazane tu rozwiązanie, to nie jedyna droga, bo wiele serwerów i frameworków ma swoje własne rozwiązania do ssl w lokalnym developmencie. Zaletą mojego podejścia jest uniwersalność. </p><p>Instalacja serwera <code>nginx</code></p><pre><code>yay -S nginx</code></pre><p>Włączamy go:</p><pre><code>sudo systemctl start nginx.service</code></pre><p>Jeśli chcemy, żeby startował przy każdym włączeniu systemy dodajemy:</p><pre><code>sudo systemctl enable nginx.service</code></pre><p>Sam nie używał bym tego drugiego polecenia na komputerze lokalnym, ponieważ niepotrzebnie blokuje port <code>80</code>.</p><p>Po instalacji <code>nginx</code> przywitał nas swoją stroną startową na porcie <code>80</code>. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-29-16-05-22.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"353\" height=\"416\"></figure><h3 id=\"nginx-w-mac-os\">Nginx w Mac OS</h3><p>Na systemie <code>Mac OS</code> ngnix domyślnie startuje na porcie <code>8080</code></p><p><a href=\"https://www.javatpoint.com/installing-nginx-on-mac\">https://www.javatpoint.com/installing-nginx-on-mac</a></p><p>Możemy to zmienić edytując plik <code>/usr/local/etc/nginx/nginx.conf</code> a sam serwer włączyć poleceniem</p><pre><code>launchctl load /usr/local/Cellar/nginx/1.21.4/homebrew.mxcl.nginx.plist</code></pre><p>przy czym wersja w Twoim systemie może różnić się od tej podanej przeze mnie. Odpowiednikiem archowego <code>enable</code> jest opcjonalna flaga <code>-w</code></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://apple.stackexchange.com/a/308421\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Launchctl difference between load and start, unload and stop</div><div class=\"kg-bookmark-description\">I was reading through the launchctl man page and have a few questions about its functioning: What is the difference between load and start, unload and stop?Where do I find the job label for a dae...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/apple/Img/apple-touch-icon.png?v&#x3D;daa7ff1d953e\"><span class=\"kg-bookmark-author\">Ask Different</span><span class=\"kg-bookmark-publisher\">Jason Rubenstein</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/apple/Img/apple-touch-icon@2.png?v&#x3D;b514451ec60c\"></div></a></figure><h2 id=\"przygotowanie-certyfikatu-self-signed\">Przygotowanie certyfikatu self-signed</h2><p>Aby móc posługiwać się certyfikatem SSL podczas lokalnego developmentu aplikacji należy posłużyć się certyfikatem <code>self-signed</code>.</p><p>Jego utworzenie opisano w dokumentacji archa:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://wiki.archlinux.org/index.php/nginx\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">nginx - ArchWiki</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://wiki.archlinux.org/favicon.ico\"><span class=\"kg-bookmark-author\">ArchWiki</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://wiki.archlinux.org/images/8/87/Tango-edit-clear.png\"></div></a></figure><p>Interesujące nas polecenia to:</p><pre><code>sudo mkdir /etc/nginx/ssl\ncd /etc/nginx/ssl\nsudo openssl req -new -x509 -nodes -newkey rsa:4096 -keyout server.key -out server.crt -days 1095\nsudo chmod 400 server.key\nsudo chmod 444 server.crt</code></pre><p>Na <code>Mac OS</code> lepszą lokalizacją będzie katalog <code>/usr/local/etc/nginx/ssl</code>.</p><h2 id=\"do%C5%82%C4%85czenie-certyfikatu-do-nginx\">Dołączenie certyfikatu do Nginx</h2><p>W tej chwili nasz certyfikat nie jest jeszcze podłączony do serwera. Nginx nie nasłuchuje na porcie <code>443</code> i przez to zapytanie o <code>https://localhost</code> kończy się niepowodzeniem:</p><pre><code>http --verify no https://localhost\n\nhttp: error: ConnectionError: HTTPSConnectionPool(host='localhost', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x7f089f77fee0&gt;: Failed to establish a new connection: [Errno 111] Connection refused')) while doing a GET request to URL: https://localhost/</code></pre><p>Zmienimy teraz ustawienia <code>nginx</code> </p><pre><code>sudo nvim /etc/nginx/nginx.conf</code></pre><p>lub na <code>Mac OS</code> </p><pre><code>sudo nano /usr/local/etc/nginx/nginx.conf</code></pre><p>dodając pod kluczem <code>http</code> wpis:</p><pre><code>    server { \n        listen       443 ssl; \n        server_name  localhost; \n\n        ssl_certificate      ssl/server.crt; \n        ssl_certificate_key  ssl/server.key; \n\n        location / { \n            root   /usr/share/nginx/html; \n            index  index.html index.htm; \n        } \n    } \n</code></pre><p>Po przeładowaniu serwisu komendą:</p><pre><code>sudo systemctl reload nginx.service</code></pre><p>lub na <code>Mac OS</code></p><pre><code>sudo brew services restart nginx</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://newbedev.com/how-to-restart-nginx-on-mac-os-x\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">How to restart Nginx on Mac OS X? | Newbedev</div><div class=\"kg-bookmark-description\">Solution 1: sudo nginx -s stop &amp;&amp; sudo nginx Solution 2: For a one-liner, you could just do: sudo nginx -s reload The -s options stands for signal, and is the o</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://newbedev.com/android-icon-192x192.png\"><span class=\"kg-bookmark-author\">NewbeDEV</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://newbedev.sfo3.digitaloceanspaces.com/wp-content/uploads/2021/11/12032228/BANNER-NEWBEDEV-15.png\"></div></a></figure><p>zobaczymy, że domyślna strona nginx jest dostępna pod <code>https</code>:</p><pre><code>http --verify no -h https://localhost \nHTTP/1.1 200 OK\n</code></pre><p>Zaletą takiej konfiguracji jest to, że https działa, ale certyfikaty samopodpisane nie są obsługiwane przez <code>httpie</code> a przeglądarka też może mieć z nimi problemy.</p><p>Aby przejść do kolejnego kroku skasujemy te certyfikaty. Nie będziemy ich więcej używać. Zamiast certyfikatów samo-podpisanych stworzymy organizację, która podpisze nam certyfikat domeny.</p><h2 id=\"przekierowanie-ssl-do-aplikacji\">Przekierowanie ssl do aplikacji</h2><p>Stajemy się weryfikatorem certyfikatów (CA)</p><h4 id=\"weryfikator-certyfikat%C3%B3w-ca\">Weryfikator Certyfikatów (CA)</h4><p>Generowanie klucza prywatnego bez hasła</p><pre><code>openssl genrsa -out myCA.key 2048</code></pre><p>To polecenie tworzy plik <code>myCA.key</code> </p><pre><code>-----BEGIN RSA PRIVATE KEY-----\nMIIEpQIBAAKCAQEA+aKMj19W37DjX3nrQ7XTjP3trXXK5hLvByRDKL/QsMGOrxac\n...\nXt0itnAcq1vPqqRcsV+YPAE8oyAOXHM1aaTQIH5mp5jHySOqZtSFca8=\n-----END RSA PRIVATE KEY-----\n</code></pre><p>Generowanie certyfikatu <code>root</code>.</p><pre><code>openssl req -x509 -new -nodes -key myCA.key -sha256 -days 825 -out myCA.pem</code></pre><p>Dostajemy pytania o dane instytucji certyfikującej. Na pytania odpowiedziałem w następujący sposób:</p><pre><code>You are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter '.', the field will be left blank.\n-----\nCountry Name (2 letter code) [AU]:PL\nState or Province Name (full name) [Some-State]:Mazovian\nLocality Name (eg, city) []:Warsaw\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Precise Lab CA\nOrganizational Unit Name (eg, section) []:\nCommon Name (e.g. server FQDN or YOUR name) []:PL_CA\nEmail Address []:gustaw.daniel@gmail.com</code></pre><p>dostaliśmy plik <code>myCA.pem</code> o zawartości</p><pre><code>-----BEGIN CERTIFICATE-----\nMIID5zCCAs+gAwIBAgIUUfo+Snobo0e/HXHJm5Hf4B0TvGEwDQYJKoZIhvcNAQEL\n...\n7ntEpRg3YZUdDtM0ptDvETM8+H35V9aZtUo1/e2136x459pGZd1aJz+Hhg==\n-----END CERTIFICATE-----\n</code></pre><h4 id=\"certyfikat-podpisany\">Certyfikat podpisany</h4><p>Tworzymy <code>CA-signed</code> certyfikat (już nie samo-podpisany)</p><p>Definiujemy zmienną z zapisaną domeną:</p><pre><code>NAME=local.dev</code></pre><p>Generujemy klucz prywatny</p><pre><code>openssl genrsa -out $NAME.key 2048</code></pre><p>dostajemy plik <code>local.dev.key</code> o treści</p><pre><code>-----BEGIN RSA PRIVATE KEY-----\nMIIEpAIBAAKCAQEApvXY4EiWGELQuVTEH9YZ8Qoi0Owq39cQ+g93e7EaKlMzx1fU\n...\nVburjZcC/InypDy0ZChc6tC0z5A6qkWlLA+3eGs8ADtvQ4qtCS9+Aw==\n-----END RSA PRIVATE KEY-----</code></pre><p>Następnie tworzymy żądanie jego podpisania.</p><pre><code>openssl req -new -key local.dev.key -out local.dev.csr</code></pre><p>Ponownie jesteśmy pytani o dane. Tym razem są to dane organizacji chcącej podpisać certyfikat. Nie możemy podać tej samej <code>Common Name</code>. Moje odpowiedzi:</p><pre><code>You are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter '.', the field will be left blank.\n-----\nCountry Name (2 letter code) [AU]:PL\nState or Province Name (full name) [Some-State]:Mazovian\nLocality Name (eg, city) []:Warsaw\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Precise Lab Org\nOrganizational Unit Name (eg, section) []:\nCommon Name (e.g. server FQDN or YOUR name) []:PL   \nEmail Address []:gustaw.daniel@gmail.com\n\nPlease enter the following 'extra' attributes\nto be sent with your certificate request\nA challenge password []:\nAn optional company name []:\n</code></pre><p>Po wykonaniu tego polecenia dostajemy plik <code>local.dev.csr</code> o treści:</p><pre><code>-----BEGIN CERTIFICATE REQUEST-----\nMIICxjCCAa4CAQAwgYAxCzAJBgNVBAYTAlBMMREwDwYDVQQIDAhNYXpvdmlhbjEP\n...\n9f1qkg6LHapOjzevheKWEjWG1hnJjBOj42mmIDBVZBHVszP7rrfiRMma\n-----END CERTIFICATE REQUEST-----\n</code></pre><p>Teraz utworzymy plik konfiguracyjny rozszerzenia. Zapisujemy do pliku <code>$NAME.ext</code> zawartość</p><pre><code>authorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\nsubjectAltName = @alt_names\n[alt_names]\nDNS.1 = local.dev</code></pre><p>Tworzymy podpisany certyfikat</p><pre><code>openssl x509 -req -in $NAME.csr -CA myCA.pem -CAkey myCA.key -CAcreateserial -out $NAME.crt -days 825 -sha256 -extfile $NAME.ext</code></pre><p> Jeśli wszystko się powiodło powinniśmy zobaczyć:</p><pre><code>Signature ok\nsubject=C = PL, ST = Mazovian, L = Warsaw, O = Precise Lab, emailAddress = gustaw.daniel@gmail.com\nGetting CA Private Key</code></pre><p>Sprawdzenie czy poprawnie zbudowaliśmy certyfikat możemy wykonać komendą:</p><pre><code>openssl verify -CAfile myCA.pem -verify_hostname local.dev local.dev.crt\n                                                                                                         \nlocal.dev.crt: OK\n</code></pre><p>lub na <code>Mac OS</code></p><pre><code>openssl verify -CAfile myCA.pem local.dev.crt</code></pre><p>Podsumujmy kroki, które wykonaliśmy:</p><ul><li>zostaliśmy organizacją certyfikującą \"Precise Lab CA\", która ma klucz <code>myCA.key</code> i certyfikat <code>myCA.pem</code></li><li>podpisaliśmy certyfikat domeny używając certyfikatu i klucza organizacji certyfikującej dla domeny. Był do tego potrzebny jej klucz <code>local.dev.key</code>, żądanie jego podpisania <code>local.dev.csr</code> wystawione przez \"Precise Lab Org\" i plik konfiguracyjny rozszerzenia <code>local.dev.ext</code></li><li>podpisany certyfikat znajduje się w pliku <code>local.dev.crt</code>.</li></ul><h4 id=\"zaufanie-organizacji-certyfikuj%C4%85cej-w-chrome\">Zaufanie organizacji certyfikującej w Chrome</h4><p>Teraz powinniśmy zaufać organizacji certyfikującej. Dodajmy jej plik <code>pem</code> jako <code>Authority</code> w ustawieniach przeglądarki. W pasku adresu wpisujemy:</p><pre><code>chrome://settings/certificates</code></pre><p>Zobaczymy:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-01-52-21.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1296\" height=\"776\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-30-01-52-21.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/Screenshot-from-2021-04-30-01-52-21.png 1000w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-01-52-21.png 1296w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Po kliknięciu import i wybraniu pliku <code>myCA.pem</code> zaznaczamy jakim operacjom tej organizacji chcemy ufać:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-01-52-11.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"629\" height=\"375\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/Screenshot-from-2021-04-30-01-52-11.png 600w, __GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-01-52-11.png 629w\"></figure><h4 id=\"zaufanie-organizacji-certyfikuj%C4%85cej-w-firefox\">Zaufanie organizacji certyfikującej w Firefox</h4><p>W Firefox wchodzimy na adres <code>about:preferences#privacy</code> i w zakładce \"Certificates\" do \"View Certificates\". Następnie wybieramy import i plik <code>myCA.pem</code></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/2021-11-15_16-37.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1794\" height=\"1088\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/2021-11-15_16-37.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/2021-11-15_16-37.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/11/2021-11-15_16-37.png 1600w, __GHOST_URL__/content/images/2021/11/2021-11-15_16-37.png 1794w\" sizes=\"(min-width: 720px) 720px\"></figure><p> od razu zaznaczamy organizację certyfikującą jako zaufaną</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/2021-11-15_16-39.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"558\" height=\"303\"></figure><p>W przeciwieństwie do Chrome, te ustawienia są niezależne od systemu operacyjnego.</p><h4 id=\"zaufanie-organizacji-certyfikuj%C4%85cej-na-mac-os-w-chrome\">Zaufanie organizacji certyfikującej na Mac OS w Chrome</h4><p>Na komputerach z <code>Mac OS</code> nie możemy zmienić ustawień bezpośrednio w chome. Zamiast tego otwieramy finder. Znajdujemy w nim plik <code>myCA.pem</code> i klikamy go dwa razy. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/2021-11-15_15-49.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1726\" height=\"866\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/2021-11-15_15-49.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/2021-11-15_15-49.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/11/2021-11-15_15-49.png 1600w, __GHOST_URL__/content/images/2021/11/2021-11-15_15-49.png 1726w\" sizes=\"(min-width: 720px) 720px\"></figure><p>po potwierdzeniu hasłem powinniśmy zobaczyć w programie \"Pęk Kluczy\" (Keychain) naszą organizację w zakładce \"Certificates\"</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/2021-11-15_15-54.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1264\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/2021-11-15_15-54.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/2021-11-15_15-54.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/11/2021-11-15_15-54.png 1600w, __GHOST_URL__/content/images/size/w2400/2021/11/2021-11-15_15-54.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Teraz musimy oznaczyć ten certyfikat jako zaufany wybierając opcję \"Always Trust\".</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/2021-11-15_16-34.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1333\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/2021-11-15_16-34.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/2021-11-15_16-34.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/11/2021-11-15_16-34.png 1600w, __GHOST_URL__/content/images/size/w2400/2021/11/2021-11-15_16-34.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><h4 id=\"konfiguracja-nginx-jako-proxy\">Konfiguracja Nginx jako proxy</h4><p>Kolejny raz zmieniamy ustawienia <code>nginx</code>. Tym razem przełączamy się na wygenerowany certyfikat i jego klucz.</p><pre><code>    server {\n        listen       443 ssl;\n        server_name  local.dev;\n\n        ssl_certificate      ssl/local.dev.crt;\n        ssl_certificate_key  ssl/local.dev.key;\n\n        location / {\n                proxy_pass          http://127.0.0.1:8000;\n                proxy_set_header    Host             $host;\n                proxy_set_header    X-Real-IP        $remote_addr;\n                proxy_set_header    X-Forwarded-For  $proxy_add_x_forwarded_for;\n                proxy_set_header    X-Client-Verify  SUCCESS;\n                proxy_set_header    X-Client-DN      $ssl_client_s_dn;\n                proxy_set_header    X-SSL-Subject    $ssl_client_s_dn;\n                proxy_set_header    X-SSL-Issuer     $ssl_client_i_dn;\n                proxy_read_timeout 1800;\n                proxy_connect_timeout 1800;\n        }\n    }\n</code></pre><p>Nie możemy zapomnieć o przeładowaniu serwera:</p><pre><code>sudo systemctl reload nginx.service</code></pre><p>Na <code>Mac OS</code> nie ma <code>systemctl</code> i używamy <code>brew</code></p><pre><code>sudo brew services restart nginx\nsudo pkill nginx\nsudo nginx</code></pre><p>Po wejściu na stronę:</p><blockquote><a href=\"https://local.dev/\">https://local.dev/</a></blockquote><p>możemy cieszyć się widokiem kłódki przy adresie lokalnej strony:</p><ul><li>na Chrome</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-01-52-38.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"468\" height=\"363\"></figure><ul><li>oraz na Firefox</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/2021-11-15_16-43.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"778\" height=\"436\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/2021-11-15_16-43.png 600w, __GHOST_URL__/content/images/2021/11/2021-11-15_16-43.png 778w\" sizes=\"(min-width: 720px) 720px\"></figure><p>W konsoli nie zobaczymy jednak poprawnego wyniku:</p><pre><code>http https://local.dev \n\nhttp: error: SSLError: HTTPSConnectionPool(host='local.dev', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)'))) while doing a GET request to URL: https://local.dev/\n</code></pre><p>Błąd mówi nam, że nie udało się zweryfikować lokalnego wystawcy certyfikatu. Aby request z konsoli zadziałał musimy wskazać certyfikat organizacji weryfikującej jako argument flagi <code>--verify</code>.</p><pre><code>http --verify /etc/nginx/ssl/myCA.pem https://local.dev</code></pre><p>lub na <code>Mac OS</code></p><pre><code>http --verify /usr/local/etc/nginx/ssl/myCA.pem https://local.dev</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/Screenshot-from-2021-04-30-02-15-33.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"529\" height=\"256\"></figure><h3 id=\"zastosowania-lokalnego-certyfikatu-ssl\">Zastosowania lokalnego certyfikatu SSL</h3><p>Pokazaliśmy jak skonfigurować połączenie po https na lokalnym komputerze, co jest szczególnie przydatne w developmencie aplikacji webowych. Zwykle można rozwijać swoje projekty lokalnie z użyciem <code>http</code>. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/5u96xh.jpeg\" class=\"kg-image\" alt loading=\"lazy\" width=\"674\" height=\"370\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/5u96xh.jpeg 600w, __GHOST_URL__/content/images/2021/11/5u96xh.jpeg 674w\"></figure><p>Czasami <code>https</code> jest wymagany przez takie mechanizmy jak:</p><ul><li>ustawienia Secure lub SameSite dla Cookie</li><li>ustawienia dostępu dla kamery lub mikrofonu w przeglądarce</li><li>niektóre adresy webhooks zewnętrznych API</li></ul><h3 id=\"zalety-i-wady-caddy\">Zalety i wady Caddy</h3><p>Auth0 w swojej dokumentacji rekomenduje wykorzystanie programu <code>caddy</code>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://auth0.com/docs/libraries/secure-local-development#how-to-set-up-a-secure-local-server\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">HTTPS in Development</div><div class=\"kg-bookmark-description\">Securing local development servers to work with samesite cookies</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.auth0.com/website/new-homepage/dark-favicon.png\"><span class=\"kg-bookmark-author\">Auth0 Docs</span><span class=\"kg-bookmark-publisher\">Auth0</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn2.auth0.com/docs/media/social-media/fb-card.png\"></div></a></figure><p>Jego instalacja to</p><pre><code>yay -S caddy</code></pre><p>lub</p><pre><code>brew install caddy</code></pre><p>Wyłączymy teraz nasz serwer <code>nginx</code>. </p><pre><code>sudo pkill nginx</code></pre><p>uruchamiany <code>caddy</code> poleceniem</p><pre><code>caddy reverse-proxy --from localhost:443 --to localhost:8000</code></pre><p>I mamy następujący efekt:</p><ol><li>Na chrome działa nam kłódka na stronie <code>https://localhost</code></li></ol><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/2021-11-15_17-05.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"709\" height=\"723\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/2021-11-15_17-05.png 600w, __GHOST_URL__/content/images/2021/11/2021-11-15_17-05.png 709w\"></figure><p>2. Na Firefox <code>https://localhost</code> nie działa</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/2021-11-15_17-06.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1032\" height=\"477\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/2021-11-15_17-06.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/2021-11-15_17-06.png 1000w, __GHOST_URL__/content/images/2021/11/2021-11-15_17-06.png 1032w\" sizes=\"(min-width: 720px) 720px\"></figure><p>3. Z poziomu linii komend (httpie) też nie działa</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/2021-11-15_17-06_1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1730\" height=\"202\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/2021-11-15_17-06_1.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/2021-11-15_17-06_1.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/11/2021-11-15_17-06_1.png 1600w, __GHOST_URL__/content/images/2021/11/2021-11-15_17-06_1.png 1730w\" sizes=\"(min-width: 720px) 720px\"></figure><p>4. Z drugiej strony curl działa <code>curl <a href=\"https://localhost\">https://localhost</a></code>.</p><p>Czyli \"caddy\" to metoda na bardzo szybkie konfigurowanie lokalnego ssl ale z ograniczeniami. Ich dokumentacja wygląda obiecująco, ale można się spodziewać, że napotykając na błędy będziemy mieli znacznie mniejsze szanse na support od community, niż w przypadku samodzielnej konfiguracji zgodnie z krokami przedstawionymi w tym wpisie. Jeśli zaczniemy od Caddy bez rozumienia jak skonfigurować ssl samodzielnie, to szansa, że spotkane błędy zatrzymają nas na długi czas znacznie wzrośnie.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://caddyserver.com/docs/getting-started\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Getting Started - Caddy Documentation</div><div class=\"kg-bookmark-description\">Caddy is a powerful, enterprise-ready, open source web server with automatic HTTPS written in Go</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://caddyserver.com/resources/images/favicon.png\"><span class=\"kg-bookmark-publisher\">Caddy Web Server</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://caddyserver.com/resources/images/caddy-open-graph.jpg\"></div></a></figure><h4 id=\"warto%C5%9Bciowe-linki-pog%C5%82%C4%99biaj%C4%85ce-temat-ssl\">Wartościowe linki pogłębiające temat SSL</h4><p>Przygotowując ten wpis korzystałem z wielu zewnętrznych źródeł. Najbardziej wartościowe jakie znalazłem są podlinkowane poniżej.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://stackoverflow.com/questions/44443269/how-to-use-a-ca-like-curls-cacert-with-httpie/67326625#67326625\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">How to use a CA (like curl’s --cacert) with HTTPie</div><div class=\"kg-bookmark-description\">In curl I can connect with a private key, client cert, and a ca cert like this curl --cert cert.pem --key key.pem --cacert ca.pem https://example.org I can see the --cert and --cert-key options in</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v&#x3D;c78bd457575a\"><span class=\"kg-bookmark-author\">Stack Overflow</span><span class=\"kg-bookmark-publisher\">Ahmadster</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v&#x3D;73d79a89bded\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://stackoverflow.com/a/35867609/6398044\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Setup (https) SSL on localhost for meteor development</div><div class=\"kg-bookmark-description\">How do you create a self signed SSL certificate to use on local server on mac 10.9? I require my localhost serving as https://localhost I am using the linkedin API. The feature which requires the...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v&#x3D;c78bd457575a\"><span class=\"kg-bookmark-author\">Stack Overflow</span><span class=\"kg-bookmark-publisher\">meteorBuzz</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v&#x3D;73d79a89bded\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"http://markstutpnt.blogspot.com/2019/01/error-18-at-0-depth-lookup-self-signed.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">error 18 at 0 depth lookup: self signed certificate</div><div class=\"kg-bookmark-description\">I was trying to test SSL connection between MySQL client and server. For that I created SSL certificate and keys by following the MySQL doc...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"http://markstutpnt.blogspot.com/favicon.ico\"><span class=\"kg-bookmark-author\">Blogger</span><span class=\"kg-bookmark-publisher\">Abhishek G</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://lh3.googleusercontent.com/ULB6iBuCeTVvSjjjU1A-O8e9ZpVba6uvyhtiWRti_rBAs9yMYOFBujxriJRZ-A&#x3D;w1200\"></div></a></figure>",
            "comment_id": "608aa9202fb35425592d138d",
            "plaintext": "Ustawianie certyfikatu ssl podczas developmentu może być poważnym wyzwaniem. Nie\nwynika to ze złożoności tego zadania, ale z pułapek, w jakie można wpaść jeśli\nposiada się luki w wiedzy na temat sieci, certyfikatów i protokołu https.\n\nW tym wpisie pokażę jak krok po kroku przejść przez proces ustawiania lokalnego\ndevelopmentu z https. Zrobimy przy tym kilka dygresji dotyczących problemów\njakie mogą się pojawić.\n\nW tym wpisie opisuję jak nadpisać zewnętrzne DNS, utworzyć organizację\ncertyfikującą, przygotować żądanie utworzenia certyfikatu dla domeny, spełnić\nje, zaufać tej organizacji, skonfigurować serwer nginx do proxowania ruchu i\nużywania certyfikatu domeny i finalnie cieszyć się połączeniem https.\n\nLokalna domena\nZaczniemy od podstaw. Czyli lokalnego przekierowania domeny na nasz lokalny\nkomputer. Zwykle kiedy pytamy przeglądarki o domenę serwery DNS ustawione w\nnaszym komputerze dostarczają na numer IP na który należy wysłać żądanie.\n\nUstawienia DNS dla naszego komputera możemy sprawdzić w pliku resolv.conf\n\ncat /etc/resolv.conf\n\nDomain name resolution - ArchWikiArchWiki\n[https://wiki.archlinux.org/index.php/Domain_name_resolution]Nie zawsze jednak\nmusimy pytać o IP serwerów DNS. Zapytania do zewnętrznych serwerów DNS możemy\nprzesłonić naszymi wpisami w pliku /etc/hosts.\n\nZawartość tego pliku może u Ciebie wyglądać tak:\n\n# Static table lookup for hostnames.\n# See hosts(5) for details.\n127.0.0.1\tlocalhost\n::1\t\tlocalhost\n127.0.1.1\thp-1589\n\n\nAby dodać do niego naszą domenę musimy edytować plik hosts\n\nsudo nvim /etc/hosts\n\nDodajemy na końcu linię:\n\n127.0.0.1\tlocal.dev\n\nAby przetestować tą konfigurację napiszemy prostą stronę w php. Do pliku \nindex.php zapisujemy:\n\n<?php\nheader('Content-Type: application/json');\necho '{\"status\":\"ok\"}';\n\n\nMożemy ją hostować poleceniem\n\nphp -S localhost:8000 index.php\n\nNaturalnie polecenie:\n\nhttp http://localhost:8000/\n\nzwróci nam {\"status\": \"ok\"}. Niestety zapytanie o domenę:\n\nhttp http://local.dev:8000/\n\npokarze błąd:\n\nhttp: error: ConnectionError: HTTPConnectionPool(host='local.dev', port=8000): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fbaa2dfcc40>: Failed to establish a new connection: [Errno 111] Connection refused')) while doing a GET request to URL: http://local.dev:8000/\n\nDomena kieruje nas w odpowiednie miejsce co może potwierdzić getent\n\ngetent hosts local.dev\n127.0.0.1       local.dev\n\nProblem leży w ograniczeniu hostów na których jest ustawiony serwer.\n\n> Pułapka 1: sprawdź jakiego hosta ma twój lokalny server.\nW komendzie php -S localhost:8000 index.php nie powinniśmy używać localhost.\nJest to częsty przypadek również w innych językach, gdzie frameworki serwują\ndomyślnie na hoście localhost a powinny na 0.0.0.0.\n\nAby naprawić problem wyłączamy serwer i stawiamy go komendą\n\nphp -S 0.0.0.0:8000 index.php\n\nTym razem działa on poprawnie.\n\nDlaczego tak jest? Sam localhost stanowi tylko alias względem adresu 127.0.0.1.\nNasza domena local.dev też jest aliasem do 127.0.0.1 ale już nie do localhost.\nUstawiając serwer komendą: php -S 127.0.0.1:8000 index.php, też uzyskaliśmy\npożądany wynik. Chyba, że pracowali byśmy z adresacją ipv6, wtedy zamiast lub\nobok 127.0.0.1 w /etc/hosts ustawili byśmy ::1. Jeśli temat różnic między \nlocalhost a 127.0.0.1 jest dla Ciebie nowy polecam Ci artykuł: \n\nDifference between localhost and 127.0.0.1Lots of people would think what the\naddress 127.0.0.1 is when first seeing this address. In fact, 127.0.0.1 is a\nloopback address which refers to the local machine. It is generally used for\nlocal testPixelstech.net\n[https://www.pixelstech.net/article/1538275121-Difference-between-localhost-and-127-0-0-1]\nInstalacja Nginx\nPokazane tu rozwiązanie, to nie jedyna droga, bo wiele serwerów i frameworków ma\nswoje własne rozwiązania do ssl w lokalnym developmencie. Zaletą mojego\npodejścia jest uniwersalność. \n\nInstalacja serwera nginx\n\nyay -S nginx\n\nWłączamy go:\n\nsudo systemctl start nginx.service\n\nJeśli chcemy, żeby startował przy każdym włączeniu systemy dodajemy:\n\nsudo systemctl enable nginx.service\n\nSam nie używał bym tego drugiego polecenia na komputerze lokalnym, ponieważ\nniepotrzebnie blokuje port 80.\n\nPo instalacji nginx przywitał nas swoją stroną startową na porcie 80. \n\nNginx w Mac OS\nNa systemie Mac OS ngnix domyślnie startuje na porcie 8080\n\nhttps://www.javatpoint.com/installing-nginx-on-mac\n\nMożemy to zmienić edytując plik /usr/local/etc/nginx/nginx.conf a sam serwer\nwłączyć poleceniem\n\nlaunchctl load /usr/local/Cellar/nginx/1.21.4/homebrew.mxcl.nginx.plist\n\nprzy czym wersja w Twoim systemie może różnić się od tej podanej przeze mnie.\nOdpowiednikiem archowego enable jest opcjonalna flaga -w\n\nLaunchctl difference between load and start, unload and stopI was reading\nthrough the launchctl man page and have a few questions about its functioning:\nWhat is the difference between load and start, unload and stop?Where do I find\nthe job label for a dae...Ask DifferentJason Rubenstein\n[https://apple.stackexchange.com/a/308421]Przygotowanie certyfikatu self-signed\nAby móc posługiwać się certyfikatem SSL podczas lokalnego developmentu aplikacji\nnależy posłużyć się certyfikatem self-signed.\n\nJego utworzenie opisano w dokumentacji archa:\n\nnginx - ArchWikiArchWiki [https://wiki.archlinux.org/index.php/nginx]\nInteresujące nas polecenia to:\n\nsudo mkdir /etc/nginx/ssl\ncd /etc/nginx/ssl\nsudo openssl req -new -x509 -nodes -newkey rsa:4096 -keyout server.key -out server.crt -days 1095\nsudo chmod 400 server.key\nsudo chmod 444 server.crt\n\nNa Mac OS lepszą lokalizacją będzie katalog /usr/local/etc/nginx/ssl.\n\nDołączenie certyfikatu do Nginx\nW tej chwili nasz certyfikat nie jest jeszcze podłączony do serwera. Nginx nie\nnasłuchuje na porcie 443 i przez to zapytanie o https://localhost kończy się\nniepowodzeniem:\n\nhttp --verify no https://localhost\n\nhttp: error: ConnectionError: HTTPSConnectionPool(host='localhost', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f089f77fee0>: Failed to establish a new connection: [Errno 111] Connection refused')) while doing a GET request to URL: https://localhost/\n\nZmienimy teraz ustawienia nginx \n\nsudo nvim /etc/nginx/nginx.conf\n\nlub na Mac OS \n\nsudo nano /usr/local/etc/nginx/nginx.conf\n\ndodając pod kluczem http wpis:\n\n    server { \n        listen       443 ssl; \n        server_name  localhost; \n\n        ssl_certificate      ssl/server.crt; \n        ssl_certificate_key  ssl/server.key; \n\n        location / { \n            root   /usr/share/nginx/html; \n            index  index.html index.htm; \n        } \n    } \n\n\nPo przeładowaniu serwisu komendą:\n\nsudo systemctl reload nginx.service\n\nlub na Mac OS\n\nsudo brew services restart nginx\n\nHow to restart Nginx on Mac OS X? | NewbedevSolution 1: sudo nginx -s stop &&\nsudo nginx Solution 2: For a one-liner, you could just do: sudo nginx -s reload\nThe -s options stands for signal, and is the oNewbeDEV\n[https://newbedev.com/how-to-restart-nginx-on-mac-os-x]zobaczymy, że domyślna\nstrona nginx jest dostępna pod https:\n\nhttp --verify no -h https://localhost \nHTTP/1.1 200 OK\n\n\nZaletą takiej konfiguracji jest to, że https działa, ale certyfikaty\nsamopodpisane nie są obsługiwane przez httpie a przeglądarka też może mieć z\nnimi problemy.\n\nAby przejść do kolejnego kroku skasujemy te certyfikaty. Nie będziemy ich więcej\nużywać. Zamiast certyfikatów samo-podpisanych stworzymy organizację, która\npodpisze nam certyfikat domeny.\n\nPrzekierowanie ssl do aplikacji\nStajemy się weryfikatorem certyfikatów (CA)\n\nWeryfikator Certyfikatów (CA)\nGenerowanie klucza prywatnego bez hasła\n\nopenssl genrsa -out myCA.key 2048\n\nTo polecenie tworzy plik myCA.key \n\n-----BEGIN RSA PRIVATE KEY-----\nMIIEpQIBAAKCAQEA+aKMj19W37DjX3nrQ7XTjP3trXXK5hLvByRDKL/QsMGOrxac\n...\nXt0itnAcq1vPqqRcsV+YPAE8oyAOXHM1aaTQIH5mp5jHySOqZtSFca8=\n-----END RSA PRIVATE KEY-----\n\n\nGenerowanie certyfikatu root.\n\nopenssl req -x509 -new -nodes -key myCA.key -sha256 -days 825 -out myCA.pem\n\nDostajemy pytania o dane instytucji certyfikującej. Na pytania odpowiedziałem w\nnastępujący sposób:\n\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter '.', the field will be left blank.\n-----\nCountry Name (2 letter code) [AU]:PL\nState or Province Name (full name) [Some-State]:Mazovian\nLocality Name (eg, city) []:Warsaw\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Precise Lab CA\nOrganizational Unit Name (eg, section) []:\nCommon Name (e.g. server FQDN or YOUR name) []:PL_CA\nEmail Address []:gustaw.daniel@gmail.com\n\ndostaliśmy plik myCA.pem o zawartości\n\n-----BEGIN CERTIFICATE-----\nMIID5zCCAs+gAwIBAgIUUfo+Snobo0e/HXHJm5Hf4B0TvGEwDQYJKoZIhvcNAQEL\n...\n7ntEpRg3YZUdDtM0ptDvETM8+H35V9aZtUo1/e2136x459pGZd1aJz+Hhg==\n-----END CERTIFICATE-----\n\n\nCertyfikat podpisany\nTworzymy CA-signed certyfikat (już nie samo-podpisany)\n\nDefiniujemy zmienną z zapisaną domeną:\n\nNAME=local.dev\n\nGenerujemy klucz prywatny\n\nopenssl genrsa -out $NAME.key 2048\n\ndostajemy plik local.dev.key o treści\n\n-----BEGIN RSA PRIVATE KEY-----\nMIIEpAIBAAKCAQEApvXY4EiWGELQuVTEH9YZ8Qoi0Owq39cQ+g93e7EaKlMzx1fU\n...\nVburjZcC/InypDy0ZChc6tC0z5A6qkWlLA+3eGs8ADtvQ4qtCS9+Aw==\n-----END RSA PRIVATE KEY-----\n\nNastępnie tworzymy żądanie jego podpisania.\n\nopenssl req -new -key local.dev.key -out local.dev.csr\n\nPonownie jesteśmy pytani o dane. Tym razem są to dane organizacji chcącej\npodpisać certyfikat. Nie możemy podać tej samej Common Name. Moje odpowiedzi:\n\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter '.', the field will be left blank.\n-----\nCountry Name (2 letter code) [AU]:PL\nState or Province Name (full name) [Some-State]:Mazovian\nLocality Name (eg, city) []:Warsaw\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Precise Lab Org\nOrganizational Unit Name (eg, section) []:\nCommon Name (e.g. server FQDN or YOUR name) []:PL   \nEmail Address []:gustaw.daniel@gmail.com\n\nPlease enter the following 'extra' attributes\nto be sent with your certificate request\nA challenge password []:\nAn optional company name []:\n\n\nPo wykonaniu tego polecenia dostajemy plik local.dev.csr o treści:\n\n-----BEGIN CERTIFICATE REQUEST-----\nMIICxjCCAa4CAQAwgYAxCzAJBgNVBAYTAlBMMREwDwYDVQQIDAhNYXpvdmlhbjEP\n...\n9f1qkg6LHapOjzevheKWEjWG1hnJjBOj42mmIDBVZBHVszP7rrfiRMma\n-----END CERTIFICATE REQUEST-----\n\n\nTeraz utworzymy plik konfiguracyjny rozszerzenia. Zapisujemy do pliku $NAME.ext \nzawartość\n\nauthorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\nsubjectAltName = @alt_names\n[alt_names]\nDNS.1 = local.dev\n\nTworzymy podpisany certyfikat\n\nopenssl x509 -req -in $NAME.csr -CA myCA.pem -CAkey myCA.key -CAcreateserial -out $NAME.crt -days 825 -sha256 -extfile $NAME.ext\n\n Jeśli wszystko się powiodło powinniśmy zobaczyć:\n\nSignature ok\nsubject=C = PL, ST = Mazovian, L = Warsaw, O = Precise Lab, emailAddress = gustaw.daniel@gmail.com\nGetting CA Private Key\n\nSprawdzenie czy poprawnie zbudowaliśmy certyfikat możemy wykonać komendą:\n\nopenssl verify -CAfile myCA.pem -verify_hostname local.dev local.dev.crt\n                                                                                                         \nlocal.dev.crt: OK\n\n\nlub na Mac OS\n\nopenssl verify -CAfile myCA.pem local.dev.crt\n\nPodsumujmy kroki, które wykonaliśmy:\n\n * zostaliśmy organizacją certyfikującą \"Precise Lab CA\", która ma klucz \n   myCA.key i certyfikat myCA.pem\n * podpisaliśmy certyfikat domeny używając certyfikatu i klucza organizacji\n   certyfikującej dla domeny. Był do tego potrzebny jej klucz local.dev.key,\n   żądanie jego podpisania local.dev.csr wystawione przez \"Precise Lab Org\" i\n   plik konfiguracyjny rozszerzenia local.dev.ext\n * podpisany certyfikat znajduje się w pliku local.dev.crt.\n\nZaufanie organizacji certyfikującej w Chrome\nTeraz powinniśmy zaufać organizacji certyfikującej. Dodajmy jej plik pem jako \nAuthority w ustawieniach przeglądarki. W pasku adresu wpisujemy:\n\nchrome://settings/certificates\n\nZobaczymy:\n\nPo kliknięciu import i wybraniu pliku myCA.pem zaznaczamy jakim operacjom tej\norganizacji chcemy ufać:\n\nZaufanie organizacji certyfikującej w Firefox\nW Firefox wchodzimy na adres about:preferences#privacy i w zakładce\n\"Certificates\" do \"View Certificates\". Następnie wybieramy import i plik \nmyCA.pem\n\n od razu zaznaczamy organizację certyfikującą jako zaufaną\n\nW przeciwieństwie do Chrome, te ustawienia są niezależne od systemu\noperacyjnego.\n\nZaufanie organizacji certyfikującej na Mac OS w Chrome\nNa komputerach z Mac OS nie możemy zmienić ustawień bezpośrednio w chome.\nZamiast tego otwieramy finder. Znajdujemy w nim plik myCA.pem i klikamy go dwa\nrazy. \n\npo potwierdzeniu hasłem powinniśmy zobaczyć w programie \"Pęk Kluczy\" (Keychain)\nnaszą organizację w zakładce \"Certificates\"\n\nTeraz musimy oznaczyć ten certyfikat jako zaufany wybierając opcję \"Always\nTrust\".\n\nKonfiguracja Nginx jako proxy\nKolejny raz zmieniamy ustawienia nginx. Tym razem przełączamy się na\nwygenerowany certyfikat i jego klucz.\n\n    server {\n        listen       443 ssl;\n        server_name  local.dev;\n\n        ssl_certificate      ssl/local.dev.crt;\n        ssl_certificate_key  ssl/local.dev.key;\n\n        location / {\n                proxy_pass          http://127.0.0.1:8000;\n                proxy_set_header    Host             $host;\n                proxy_set_header    X-Real-IP        $remote_addr;\n                proxy_set_header    X-Forwarded-For  $proxy_add_x_forwarded_for;\n                proxy_set_header    X-Client-Verify  SUCCESS;\n                proxy_set_header    X-Client-DN      $ssl_client_s_dn;\n                proxy_set_header    X-SSL-Subject    $ssl_client_s_dn;\n                proxy_set_header    X-SSL-Issuer     $ssl_client_i_dn;\n                proxy_read_timeout 1800;\n                proxy_connect_timeout 1800;\n        }\n    }\n\n\nNie możemy zapomnieć o przeładowaniu serwera:\n\nsudo systemctl reload nginx.service\n\nNa Mac OS nie ma systemctl i używamy brew\n\nsudo brew services restart nginx\nsudo pkill nginx\nsudo nginx\n\nPo wejściu na stronę:\n\n> https://local.dev/\nmożemy cieszyć się widokiem kłódki przy adresie lokalnej strony:\n\n * na Chrome\n\n * oraz na Firefox\n\nW konsoli nie zobaczymy jednak poprawnego wyniku:\n\nhttp https://local.dev \n\nhttp: error: SSLError: HTTPSConnectionPool(host='local.dev', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)'))) while doing a GET request to URL: https://local.dev/\n\n\nBłąd mówi nam, że nie udało się zweryfikować lokalnego wystawcy certyfikatu. Aby\nrequest z konsoli zadziałał musimy wskazać certyfikat organizacji weryfikującej\njako argument flagi --verify.\n\nhttp --verify /etc/nginx/ssl/myCA.pem https://local.dev\n\nlub na Mac OS\n\nhttp --verify /usr/local/etc/nginx/ssl/myCA.pem https://local.dev\n\nZastosowania lokalnego certyfikatu SSL\nPokazaliśmy jak skonfigurować połączenie po https na lokalnym komputerze, co\njest szczególnie przydatne w developmencie aplikacji webowych. Zwykle można\nrozwijać swoje projekty lokalnie z użyciem http. \n\nCzasami https jest wymagany przez takie mechanizmy jak:\n\n * ustawienia Secure lub SameSite dla Cookie\n * ustawienia dostępu dla kamery lub mikrofonu w przeglądarce\n * niektóre adresy webhooks zewnętrznych API\n\nZalety i wady Caddy\nAuth0 w swojej dokumentacji rekomenduje wykorzystanie programu caddy.\n\nHTTPS in DevelopmentSecuring local development servers to work with samesite\ncookiesAuth0 DocsAuth0\n[https://auth0.com/docs/libraries/secure-local-development#how-to-set-up-a-secure-local-server]\nJego instalacja to\n\nyay -S caddy\n\nlub\n\nbrew install caddy\n\nWyłączymy teraz nasz serwer nginx. \n\nsudo pkill nginx\n\nuruchamiany caddy poleceniem\n\ncaddy reverse-proxy --from localhost:443 --to localhost:8000\n\nI mamy następujący efekt:\n\n 1. Na chrome działa nam kłódka na stronie https://localhost\n\n2. Na Firefox https://localhost nie działa\n\n3. Z poziomu linii komend (httpie) też nie działa\n\n4. Z drugiej strony curl działa curl https://localhost.\n\nCzyli \"caddy\" to metoda na bardzo szybkie konfigurowanie lokalnego ssl ale z\nograniczeniami. Ich dokumentacja wygląda obiecująco, ale można się spodziewać,\nże napotykając na błędy będziemy mieli znacznie mniejsze szanse na support od\ncommunity, niż w przypadku samodzielnej konfiguracji zgodnie z krokami\nprzedstawionymi w tym wpisie. Jeśli zaczniemy od Caddy bez rozumienia jak\nskonfigurować ssl samodzielnie, to szansa, że spotkane błędy zatrzymają nas na\ndługi czas znacznie wzrośnie.\n\nGetting Started - Caddy DocumentationCaddy is a powerful, enterprise-ready,\nopen\nsource web server with automatic HTTPS written in GoCaddy Web Server\n[https://caddyserver.com/docs/getting-started]Wartościowe linki pogłębiające\ntemat SSL\nPrzygotowując ten wpis korzystałem z wielu zewnętrznych źródeł. Najbardziej\nwartościowe jakie znalazłem są podlinkowane poniżej.\n\nHow to use a CA (like curl’s --cacert) with HTTPieIn curl I can connect with a\nprivate key, client cert, and a ca cert like this curl --cert cert.pem --key\nkey.pem --cacert ca.pem https://example.org I can see the --cert and --cert-key\noptions inStack OverflowAhmadster\n[https://stackoverflow.com/questions/44443269/how-to-use-a-ca-like-curls-cacert-with-httpie/67326625#67326625]\nSetup (https) SSL on localhost for meteor developmentHow do you create a self\nsigned SSL certificate to use on local server on mac 10.9? I require my\nlocalhost serving as https://localhost I am using the linkedin API. The feature\nwhich requires the...Stack OverflowmeteorBuzz\n[https://stackoverflow.com/a/35867609/6398044]error 18 at 0 depth lookup: self\nsigned certificateI was trying to test SSL connection between MySQL client and\nserver. For that I created SSL certificate and keys by following the MySQL\ndoc...BloggerAbhishek G\n[http://markstutpnt.blogspot.com/2019/01/error-18-at-0-depth-lookup-self-signed.html]",
            "feature_image": "__GHOST_URL__/content/images/2021/11/certyfikaty-ssl-kei-pl-mediatekst-1.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-04-29T12:40:00.000Z",
            "updated_at": "2021-11-15T16:47:42.000Z",
            "published_at": "2021-11-15T16:47:42.000Z",
            "custom_excerpt": "Ustawienie połączenia https na domenie localhost może być wyzwaniem jeśli robimy to pierwszy raz. Ten wpis jest bardzo szczegółowym tutorialem ze wszystkimi komendami i screenshotami.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "609d1c74c52f4a12ffdfc578",
            "uuid": "4d94ca8b-22e5-46dc-806d-1fc4daa31b4e",
            "title": "mkcert",
            "slug": "mkcert",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"yay -S nss mkcert\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/FiloSottile/mkcert\",\"metadata\":{\"url\":\"https://github.com/FiloSottile/mkcert\",\"title\":\"FiloSottile/mkcert\",\"description\":\"A simple zero-config tool to make locally trusted development certificates with any names you’d like. - FiloSottile/mkcert\",\"author\":\"FiloSottile\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://repository-images.githubusercontent.com/138547797/1779e880-6164-11e9-971a-09791e669578\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"code\",{\"code\":\"mkcert localhost\"}]],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Instalujemy narzędzie\"]]],[10,0],[10,1],[1,\"p\",[[0,[],0,\"Tworzymy certyfikat\"]]],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Instalujemy narzędzie</p><pre><code>yay -S nss mkcert</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/FiloSottile/mkcert\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">FiloSottile/mkcert</div><div class=\"kg-bookmark-description\">A simple zero-config tool to make locally trusted development certificates with any names you’d like. - FiloSottile/mkcert</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">FiloSottile</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://repository-images.githubusercontent.com/138547797/1779e880-6164-11e9-971a-09791e669578\"></div></a></figure><p>Tworzymy certyfikat</p><pre><code>mkcert localhost</code></pre>",
            "comment_id": "609d1c74c52f4a12ffdfc578",
            "plaintext": "Instalujemy narzędzie\n\nyay -S nss mkcert\n\nFiloSottile/mkcertA simple zero-config tool to make locally trusted development\ncertificates with any names you’d like. - FiloSottile/mkcertGitHubFiloSottile\n[https://github.com/FiloSottile/mkcert]Tworzymy certyfikat\n\nmkcert localhost",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-05-13T12:32:52.000Z",
            "updated_at": "2021-05-13T12:35:11.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60ae3d5bc52f4a12ffdfc587",
            "uuid": "5c22d529-566e-464c-ab26-7986c548b2f4",
            "title": "Konfiguracja wysyłki emaili w Strapi przez Emaillabs",
            "slug": "strapi-emaillabs",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/2022-06-11_14-13.png\",\"width\":1164,\"height\":513}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/Send-us-all.jpg\",\"width\":600,\"height\":437}],[\"code\",{\"code\":\"npx create-strapi-app@latest strapi-email --quickstart\",\"language\":\"bash\"}],[\"code\",{\"code\":\"http POST localhost:1337/admin/login email=gustaw.daniel@gmail.com password=Pass1234\",\"language\":\"httpie\"}],[\"code\",{\"code\":\"http 'http://localhost:1337/email/settings' Authorization:'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwiaWF0IjoxNjU0OTQ2MDk5LCJleHAiOjE2NTc1MzgwOTl9.sy5AoNWE1fjcrNxjSFgteZHzxn097FyPlj-3D9e7ykw'\",\"language\":\"httpie\"}],[\"code\",{\"code\":\"npx strapi routes:list \",\"language\":\"bash\"}],[\"code\",{\"code\":\"{\\n  \\\"dependencies\\\": {\\n    \\\"strapi-provider-email-emaillabs\\\": \\\"file:providers/strapi-provider-email-emaillabs\\\",\\n  }\\n}\",\"language\":\"json\"}],[\"code\",{\"code\":\"module.exports = ({ env }) => ({\\n  email: {\\n    provider: 'emaillabs',\\n    providerOptions: {\\n      smtp: env('EMAILLABS_SMTP'),\\n      apiKey: env('EMAILLABS_API_KEY'),\\n      secretKey: env('EMAILLABS_SECRET_KEY')\\n    },\\n    settings: {\\n      defaultFrom: 'office@preciselab.io',\\n      testAddress: 'gustaw.daniel@gmail.com',\\n      defaultName: 'Precise Lab'\\n    },\\n  },\\n});\\n\",\"language\":\"javascript\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/email1.jpg\",\"width\":1440,\"height\":1440}],[\"code\",{\"code\":\"const axios = require(\\\"axios\\\");\\nconst qs = require('qs');\\n\\nconst sendByEmaillabs = async (providerOptions, settings, options) => {\\n  const url = \\\"https://api.emaillabs.net.pl/api/sendmail_templates\\\";\\n\\n  const receiversObject = [options].reduce((p, n) => {\\n    return {\\n      ...p,\\n      [n.to]: {\\n        vars: {\\n          email: n.to\\n        }\\n      }\\n    }\\n  }, {})\\n\\n  console.log(receiversObject);\\n\\n  try {\\n    const response = await axios.post(url, qs.stringify({\\n      smtp_account: providerOptions.smtp,\\n      to: receiversObject,\\n      subject: options.subject,\\n      text: options.text,\\n      from: settings.defaultFrom,\\n      from_name: settings.defaultName,\\n    }), {\\n      headers: {\\n        'Authorization': 'Basic ' + Buffer.from(providerOptions.apiKey + \\\":\\\" + providerOptions.secretKey).toString(\\\"base64\\\")\\n      }\\n    })\\n\\n    return response.data;\\n\\n  } catch (e) {\\n    console.log(e);\\n    throw e;\\n  }\\n}\\n\\nmodule.exports = {\\n  init: (providerOptions = {}, settings = {}) => {\\n    return {\\n      send: async options => {\\n        return sendByEmaillabs(providerOptions, settings, options)\\n      },\\n    };\\n  },\\n};\\n\",\"language\":\"javascript\"}],[\"code\",{\"code\":\"await strapi.plugins[\\\"email\\\"].services.email.send({\\n      to: process.env.ADMIN_EMAIL,\\n      from: \\\"office@preciselab.io\\\",\\n      replyTo: `${entity.email}`,\\n      subject: `Zgłoszenie ze strony internetowej ${entity.studentName}`,\\n      text: `Wypełniono formularz zgłoszeniowy\\n\\n| Imię i nazwisko ucznia  | ${entity.studentName}\\n| Data urodzenia          | ${entity.birthDate}\\n| Imię i nazwisko rodzica | ${entity.parentName}\\n| Telefon                 | ${entity.phone}\\n| E-mail                  | ${entity.email}\\n\\nAdres:\\n${entity.address}\\n\\n${\\n  entity.notes ??\\n  `Uwagi:\\n${entity.notes}`\\n}\\n\\n       Data: ${entity.createdAt.toISOString()}`,\\n    });\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://docs.strapi.io/developer-docs/latest/plugins/email.html#configure-the-plugin\",\"metadata\":{\"url\":\"https://docs.strapi.io/developer-docs/latest/plugins/email.html\",\"title\":\"Email - Strapi Developer Docs\",\"description\":\"Send email from your server or externals providers.\",\"author\":null,\"publisher\":\"Strapi Developer Docs\",\"thumbnail\":\"https://strapi.io/documentation/assets/meta.png\",\"icon\":\"https://strapi.io/assets/favicon-32x32.png\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/10/2022-10-06_23-01.png\",\"width\":927,\"height\":527}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/10/2022-10-06_23-02.png\",\"width\":923,\"height\":588}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/10/2022-10-06_23-04.png\",\"width\":942,\"height\":545}],[\"code\",{\"code\":\"http 'http://localhost:1337/email/settings' Authorization:'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjYwNDE1Mjk0OTE0OWU3NWE1Mjg0MmY4YyIsImlhdCI6MTY2NTA4MTc2MywiZXhwIjoxNjY3NjczNzYzfQ.7nCMQjGI9y5XNRtVaEpoc-oiiBm37Y27cHFpLNnudQo'\"}],[\"code\",{\"code\":\"{\\n    \\\"config\\\": {\\n        \\\"provider\\\": \\\"emaillabs\\\",\\n        \\\"settings\\\": {\\n            \\\"defaultFrom\\\": \\\"office@preciselab.io\\\",\\n            \\\"testAddress\\\": \\\"gustaw.daniel@gmail.com\\\"\\n        }\\n    }\\n}\",\"language\":\"json\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/uns09pyvenq71.jpg\",\"width\":827,\"height\":976}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/sending-email-like-a-boss.jpg\",\"width\":599,\"height\":397}]],\"markups\":[[\"a\",[\"href\",\" https://strapi.io/\"]],[\"a\",[\"href\",\"https://emaillabs.io/\"]],[\"code\"],[\"strong\"]],\"sections\":[[1,\"p\",[[0,[0],1,\"Strapi\"],[0,[],0,\" to wgodny CMS pozwalający wyklikać model danych i wygenerować na jego podstawie rest api oraz graphql. \"]]],[10,0],[1,\"p\",[[0,[1],1,\"Emaillabs\"],[0,[],0,\" to polski serwis obsługujący wysyłkę e-maili. \"]]],[10,1],[1,\"h2\",[[0,[],0,\"Wprowadzenie do strapi\"]]],[1,\"p\",[[0,[],0,\"Projekt tworzymy poleceniem\"]]],[10,2],[1,\"p\",[[0,[],0,\"Pod adresem \"],[0,[2],1,\"localhost:1337\"],[0,[],0,\" tworzymy konto administratora. Następnie możemy pobrać jego token:\"]]],[10,3],[1,\"p\",[[0,[],0,\"możemy sprawdzić ustawienie e-maila zapytaniem\"]]],[10,4],[1,\"p\",[[0,[],0,\"Jeśli interesuje Cię pełna lista dostępnych końcówek api możesz użyć CLI\"]]],[10,5],[1,\"h2\",[[0,[],0,\"Provider Emaillabs\"]]],[1,\"p\",[[0,[],0,\"Nie ma on paczki w npm, ani tym bardziej wtyczki w Strapi, lecz mimo to, możemy skonfigurować strapi tak, żeby do wysyłek e-mail używać Emaillabs.\"]]],[1,\"p\",[[0,[],0,\"W pliku \"],[0,[3],1,\"package.json\"],[0,[],0,\" dodajemy lokalną paczkę o nazwie zaczynającej się od \"],[0,[2],1,\"strapi-provider-email\"],[0,[],0,\". To ważne, bo dzięki temu strapi rozpoznaje, że chcemy nadpisywać wysyłkę emaili.\"]]],[10,6],[1,\"p\",[[0,[],0,\"Konfugurację providera umieszczamy w \"],[0,[2],1,\"config/plugins.js\"],[0,[],0,\" nazwa w polu \"],[0,[2],1,\"provider\"],[0,[],0,\" musi pasować do ostatniego członu nazwy w \"],[0,[2],1,\"dependencies\"],[0,[],0,\". W opcjach instruujemy program, żeby podstawowych danych do integracji szukał w zmiennych środowiskowych, a w settings ustawiamy domyślne wartości dotyczące wysyłki.\"]]],[10,7],[1,\"p\",[[0,[],0,\"Częstym błędem jest podanie tej samej domeny adresu nadawcy i odbiorcy. Nie można tak robić, bo wysyłka między tymi samymi domenami przez zewnętrznego dostawcę jakim jest Emaillabs może zostać zablokowana. Za adres testowy należy wybrać adres z innej domeny.\"]]],[10,8],[1,\"p\",[[0,[],0,\"Sam kod naszego providera umieszczamy w pliku \"],[0,[2],1,\"providers/strapi-provider-email-emaillabs/index.js\"],[0,[],0,\" \"]]],[1,\"p\",[[0,[],0,\"jest to implementacja \"],[0,[2],1,\"send\"],[0,[],0,\", która otrzymuje przekazywane przez strapi parametry i wykonuje wysyłkę. Wobec braku sdk od emailabs używamy axiosa do wysyłki żądania i qs do przetwarzania body.\"]]],[10,9],[1,\"p\",[[0,[],0,\"Teraz możemy wysłać e-mail wstawiając do kontrolera\"]]],[10,10],[1,\"p\",[[0,[],0,\"Pełen interfejs pokazanej tu metody znajdziemy w dokumentacji strapi:\"]]],[10,11],[1,\"p\",[[0,[],0,\"Do \"],[0,[2],1,\".env\"],[0,[],0,\" dodajemy smtp i klucze api, \"],[0,[2],1,\"EMAILLABS_SMTP\"],[0,[],0,\" znajdziemy na głównej stronie\"]]],[10,12],[1,\"p\",[[0,[],0,\"klucze api w zakładce \\\"Administrator -> Api\\\"\"]]],[10,13],[1,\"p\",[[0,[],0,\"Należy też pamiętać o autoryzacji nadawcy, żeby nasze e-maile dochodziły. Będzie to wymagało dodania odpowiednich rekordów w DNS, ale wykracza to poza zakres tego wpisu.\"]]],[10,14],[1,\"p\",[[0,[],0,\"Ponownie wysyłając zapytanie o konfigurację e-maila, które wysłaliśmy na początku\"]]],[10,15],[1,\"p\",[[0,[],0,\"powinniśmy zobaczyć\"]]],[10,16],[1,\"p\",[[0,[],0,\"Przetestujmy to i przejdziemy do tematu załączników.\"]]],[10,17],[10,18],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p><a href=\" https://strapi.io/\">Strapi</a> to wgodny CMS pozwalający wyklikać model danych i wygenerować na jego podstawie rest api oraz graphql. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/2022-06-11_14-13.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1164\" height=\"513\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/2022-06-11_14-13.png 600w, __GHOST_URL__/content/images/size/w1000/2022/06/2022-06-11_14-13.png 1000w, __GHOST_URL__/content/images/2022/06/2022-06-11_14-13.png 1164w\" sizes=\"(min-width: 720px) 720px\"></figure><p><a href=\"https://emaillabs.io/\">Emaillabs</a> to polski serwis obsługujący wysyłkę e-maili. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/Send-us-all.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"600\" height=\"437\" srcset=\"__GHOST_URL__/content/images/2022/06/Send-us-all.jpg 600w\"></figure><h2 id=\"wprowadzenie-do-strapi\">Wprowadzenie do strapi</h2><p>Projekt tworzymy poleceniem</p><pre><code class=\"language-bash\">npx create-strapi-app@latest strapi-email --quickstart</code></pre><p>Pod adresem <code>localhost:1337</code> tworzymy konto administratora. Następnie możemy pobrać jego token:</p><pre><code class=\"language-httpie\">http POST localhost:1337/admin/login email=gustaw.daniel@gmail.com password=Pass1234</code></pre><p>możemy sprawdzić ustawienie e-maila zapytaniem</p><pre><code class=\"language-httpie\">http 'http://localhost:1337/email/settings' Authorization:'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwiaWF0IjoxNjU0OTQ2MDk5LCJleHAiOjE2NTc1MzgwOTl9.sy5AoNWE1fjcrNxjSFgteZHzxn097FyPlj-3D9e7ykw'</code></pre><p>Jeśli interesuje Cię pełna lista dostępnych końcówek api możesz użyć CLI</p><pre><code class=\"language-bash\">npx strapi routes:list </code></pre><h2 id=\"provider-emaillabs\">Provider Emaillabs</h2><p>Nie ma on paczki w npm, ani tym bardziej wtyczki w Strapi, lecz mimo to, możemy skonfigurować strapi tak, żeby do wysyłek e-mail używać Emaillabs.</p><p>W pliku <strong>package.json</strong> dodajemy lokalną paczkę o nazwie zaczynającej się od <code>strapi-provider-email</code>. To ważne, bo dzięki temu strapi rozpoznaje, że chcemy nadpisywać wysyłkę emaili.</p><pre><code class=\"language-json\">{\n  \"dependencies\": {\n    \"strapi-provider-email-emaillabs\": \"file:providers/strapi-provider-email-emaillabs\",\n  }\n}</code></pre><p>Konfugurację providera umieszczamy w <code>config/plugins.js</code> nazwa w polu <code>provider</code> musi pasować do ostatniego członu nazwy w <code>dependencies</code>. W opcjach instruujemy program, żeby podstawowych danych do integracji szukał w zmiennych środowiskowych, a w settings ustawiamy domyślne wartości dotyczące wysyłki.</p><pre><code class=\"language-javascript\">module.exports = ({ env }) =&gt; ({\n  email: {\n    provider: 'emaillabs',\n    providerOptions: {\n      smtp: env('EMAILLABS_SMTP'),\n      apiKey: env('EMAILLABS_API_KEY'),\n      secretKey: env('EMAILLABS_SECRET_KEY')\n    },\n    settings: {\n      defaultFrom: 'office@preciselab.io',\n      testAddress: 'gustaw.daniel@gmail.com',\n      defaultName: 'Precise Lab'\n    },\n  },\n});\n</code></pre><p>Częstym błędem jest podanie tej samej domeny adresu nadawcy i odbiorcy. Nie można tak robić, bo wysyłka między tymi samymi domenami przez zewnętrznego dostawcę jakim jest Emaillabs może zostać zablokowana. Za adres testowy należy wybrać adres z innej domeny.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/email1.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"1440\" height=\"1440\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/email1.jpg 600w, __GHOST_URL__/content/images/size/w1000/2022/06/email1.jpg 1000w, __GHOST_URL__/content/images/2022/06/email1.jpg 1440w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Sam kod naszego providera umieszczamy w pliku <code>providers/strapi-provider-email-emaillabs/index.js</code> </p><p>jest to implementacja <code>send</code>, która otrzymuje przekazywane przez strapi parametry i wykonuje wysyłkę. Wobec braku sdk od emailabs używamy axiosa do wysyłki żądania i qs do przetwarzania body.</p><pre><code class=\"language-javascript\">const axios = require(\"axios\");\nconst qs = require('qs');\n\nconst sendByEmaillabs = async (providerOptions, settings, options) =&gt; {\n  const url = \"https://api.emaillabs.net.pl/api/sendmail_templates\";\n\n  const receiversObject = [options].reduce((p, n) =&gt; {\n    return {\n      ...p,\n      [n.to]: {\n        vars: {\n          email: n.to\n        }\n      }\n    }\n  }, {})\n\n  console.log(receiversObject);\n\n  try {\n    const response = await axios.post(url, qs.stringify({\n      smtp_account: providerOptions.smtp,\n      to: receiversObject,\n      subject: options.subject,\n      text: options.text,\n      from: settings.defaultFrom,\n      from_name: settings.defaultName,\n    }), {\n      headers: {\n        'Authorization': 'Basic ' + Buffer.from(providerOptions.apiKey + \":\" + providerOptions.secretKey).toString(\"base64\")\n      }\n    })\n\n    return response.data;\n\n  } catch (e) {\n    console.log(e);\n    throw e;\n  }\n}\n\nmodule.exports = {\n  init: (providerOptions = {}, settings = {}) =&gt; {\n    return {\n      send: async options =&gt; {\n        return sendByEmaillabs(providerOptions, settings, options)\n      },\n    };\n  },\n};\n</code></pre><p>Teraz możemy wysłać e-mail wstawiając do kontrolera</p><pre><code>await strapi.plugins[\"email\"].services.email.send({\n      to: process.env.ADMIN_EMAIL,\n      from: \"office@preciselab.io\",\n      replyTo: `${entity.email}`,\n      subject: `Zgłoszenie ze strony internetowej ${entity.studentName}`,\n      text: `Wypełniono formularz zgłoszeniowy\n\n| Imię i nazwisko ucznia  | ${entity.studentName}\n| Data urodzenia          | ${entity.birthDate}\n| Imię i nazwisko rodzica | ${entity.parentName}\n| Telefon                 | ${entity.phone}\n| E-mail                  | ${entity.email}\n\nAdres:\n${entity.address}\n\n${\n  entity.notes ??\n  `Uwagi:\n${entity.notes}`\n}\n\n       Data: ${entity.createdAt.toISOString()}`,\n    });</code></pre><p>Pełen interfejs pokazanej tu metody znajdziemy w dokumentacji strapi:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://docs.strapi.io/developer-docs/latest/plugins/email.html#configure-the-plugin\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Email - Strapi Developer Docs</div><div class=\"kg-bookmark-description\">Send email from your server or externals providers.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://strapi.io/assets/favicon-32x32.png\"><span class=\"kg-bookmark-author\">Strapi Developer Docs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://strapi.io/documentation/assets/meta.png\"></div></a></figure><p>Do <code>.env</code> dodajemy smtp i klucze api, <code>EMAILLABS_SMTP</code> znajdziemy na głównej stronie</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/10/2022-10-06_23-01.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"927\" height=\"527\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/10/2022-10-06_23-01.png 600w, __GHOST_URL__/content/images/2022/10/2022-10-06_23-01.png 927w\" sizes=\"(min-width: 720px) 720px\"></figure><p>klucze api w zakładce \"Administrator -&gt; Api\"</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/10/2022-10-06_23-02.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"923\" height=\"588\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/10/2022-10-06_23-02.png 600w, __GHOST_URL__/content/images/2022/10/2022-10-06_23-02.png 923w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Należy też pamiętać o autoryzacji nadawcy, żeby nasze e-maile dochodziły. Będzie to wymagało dodania odpowiednich rekordów w DNS, ale wykracza to poza zakres tego wpisu.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/10/2022-10-06_23-04.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"942\" height=\"545\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/10/2022-10-06_23-04.png 600w, __GHOST_URL__/content/images/2022/10/2022-10-06_23-04.png 942w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Ponownie wysyłając zapytanie o konfigurację e-maila, które wysłaliśmy na początku</p><pre><code>http 'http://localhost:1337/email/settings' Authorization:'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjYwNDE1Mjk0OTE0OWU3NWE1Mjg0MmY4YyIsImlhdCI6MTY2NTA4MTc2MywiZXhwIjoxNjY3NjczNzYzfQ.7nCMQjGI9y5XNRtVaEpoc-oiiBm37Y27cHFpLNnudQo'</code></pre><p>powinniśmy zobaczyć</p><pre><code class=\"language-json\">{\n    \"config\": {\n        \"provider\": \"emaillabs\",\n        \"settings\": {\n            \"defaultFrom\": \"office@preciselab.io\",\n            \"testAddress\": \"gustaw.daniel@gmail.com\"\n        }\n    }\n}</code></pre><p>Przetestujmy to i przejdziemy do tematu załączników.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/uns09pyvenq71.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"827\" height=\"976\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/uns09pyvenq71.jpg 600w, __GHOST_URL__/content/images/2022/06/uns09pyvenq71.jpg 827w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/sending-email-like-a-boss.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"599\" height=\"397\"></figure>",
            "comment_id": "60ae3d5bc52f4a12ffdfc587",
            "plaintext": "Strapi [ https://strapi.io/] to wgodny CMS pozwalający wyklikać model danych i\nwygenerować na jego podstawie rest api oraz graphql. \n\nEmaillabs [https://emaillabs.io/] to polski serwis obsługujący wysyłkę e-maili. \n\nWprowadzenie do strapi\nProjekt tworzymy poleceniem\n\nnpx create-strapi-app@latest strapi-email --quickstart\n\nPod adresem localhost:1337 tworzymy konto administratora. Następnie możemy\npobrać jego token:\n\nhttp POST localhost:1337/admin/login email=gustaw.daniel@gmail.com password=Pass1234\n\nmożemy sprawdzić ustawienie e-maila zapytaniem\n\nhttp 'http://localhost:1337/email/settings' Authorization:'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwiaWF0IjoxNjU0OTQ2MDk5LCJleHAiOjE2NTc1MzgwOTl9.sy5AoNWE1fjcrNxjSFgteZHzxn097FyPlj-3D9e7ykw'\n\nJeśli interesuje Cię pełna lista dostępnych końcówek api możesz użyć CLI\n\nnpx strapi routes:list \n\nProvider Emaillabs\nNie ma on paczki w npm, ani tym bardziej wtyczki w Strapi, lecz mimo to, możemy\nskonfigurować strapi tak, żeby do wysyłek e-mail używać Emaillabs.\n\nW pliku package.json dodajemy lokalną paczkę o nazwie zaczynającej się od \nstrapi-provider-email. To ważne, bo dzięki temu strapi rozpoznaje, że chcemy\nnadpisywać wysyłkę emaili.\n\n{\n  \"dependencies\": {\n    \"strapi-provider-email-emaillabs\": \"file:providers/strapi-provider-email-emaillabs\",\n  }\n}\n\nKonfugurację providera umieszczamy w config/plugins.js nazwa w polu provider \nmusi pasować do ostatniego członu nazwy w dependencies. W opcjach instruujemy\nprogram, żeby podstawowych danych do integracji szukał w zmiennych\nśrodowiskowych, a w settings ustawiamy domyślne wartości dotyczące wysyłki.\n\nmodule.exports = ({ env }) => ({\n  email: {\n    provider: 'emaillabs',\n    providerOptions: {\n      smtp: env('EMAILLABS_SMTP'),\n      apiKey: env('EMAILLABS_API_KEY'),\n      secretKey: env('EMAILLABS_SECRET_KEY')\n    },\n    settings: {\n      defaultFrom: 'office@preciselab.io',\n      testAddress: 'gustaw.daniel@gmail.com',\n      defaultName: 'Precise Lab'\n    },\n  },\n});\n\n\nCzęstym błędem jest podanie tej samej domeny adresu nadawcy i odbiorcy. Nie\nmożna tak robić, bo wysyłka między tymi samymi domenami przez zewnętrznego\ndostawcę jakim jest Emaillabs może zostać zablokowana. Za adres testowy należy\nwybrać adres z innej domeny.\n\nSam kod naszego providera umieszczamy w pliku \nproviders/strapi-provider-email-emaillabs/index.js \n\njest to implementacja send, która otrzymuje przekazywane przez strapi parametry\ni wykonuje wysyłkę. Wobec braku sdk od emailabs używamy axiosa do wysyłki\nżądania i qs do przetwarzania body.\n\nconst axios = require(\"axios\");\nconst qs = require('qs');\n\nconst sendByEmaillabs = async (providerOptions, settings, options) => {\n  const url = \"https://api.emaillabs.net.pl/api/sendmail_templates\";\n\n  const receiversObject = [options].reduce((p, n) => {\n    return {\n      ...p,\n      [n.to]: {\n        vars: {\n          email: n.to\n        }\n      }\n    }\n  }, {})\n\n  console.log(receiversObject);\n\n  try {\n    const response = await axios.post(url, qs.stringify({\n      smtp_account: providerOptions.smtp,\n      to: receiversObject,\n      subject: options.subject,\n      text: options.text,\n      from: settings.defaultFrom,\n      from_name: settings.defaultName,\n    }), {\n      headers: {\n        'Authorization': 'Basic ' + Buffer.from(providerOptions.apiKey + \":\" + providerOptions.secretKey).toString(\"base64\")\n      }\n    })\n\n    return response.data;\n\n  } catch (e) {\n    console.log(e);\n    throw e;\n  }\n}\n\nmodule.exports = {\n  init: (providerOptions = {}, settings = {}) => {\n    return {\n      send: async options => {\n        return sendByEmaillabs(providerOptions, settings, options)\n      },\n    };\n  },\n};\n\n\nTeraz możemy wysłać e-mail wstawiając do kontrolera\n\nawait strapi.plugins[\"email\"].services.email.send({\n      to: process.env.ADMIN_EMAIL,\n      from: \"office@preciselab.io\",\n      replyTo: `${entity.email}`,\n      subject: `Zgłoszenie ze strony internetowej ${entity.studentName}`,\n      text: `Wypełniono formularz zgłoszeniowy\n\n| Imię i nazwisko ucznia  | ${entity.studentName}\n| Data urodzenia          | ${entity.birthDate}\n| Imię i nazwisko rodzica | ${entity.parentName}\n| Telefon                 | ${entity.phone}\n| E-mail                  | ${entity.email}\n\nAdres:\n${entity.address}\n\n${\n  entity.notes ??\n  `Uwagi:\n${entity.notes}`\n}\n\n       Data: ${entity.createdAt.toISOString()}`,\n    });\n\nPełen interfejs pokazanej tu metody znajdziemy w dokumentacji strapi:\n\nEmail - Strapi Developer DocsSend email from your server or externals\nproviders.\nStrapi Developer Docs\n[https://docs.strapi.io/developer-docs/latest/plugins/email.html#configure-the-plugin]\nDo .env dodajemy smtp i klucze api, EMAILLABS_SMTP znajdziemy na głównej stronie\n\nklucze api w zakładce \"Administrator -> Api\"\n\nNależy też pamiętać o autoryzacji nadawcy, żeby nasze e-maile dochodziły. Będzie\nto wymagało dodania odpowiednich rekordów w DNS, ale wykracza to poza zakres\ntego wpisu.\n\nPonownie wysyłając zapytanie o konfigurację e-maila, które wysłaliśmy na\npoczątku\n\nhttp 'http://localhost:1337/email/settings' Authorization:'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjYwNDE1Mjk0OTE0OWU3NWE1Mjg0MmY4YyIsImlhdCI6MTY2NTA4MTc2MywiZXhwIjoxNjY3NjczNzYzfQ.7nCMQjGI9y5XNRtVaEpoc-oiiBm37Y27cHFpLNnudQo'\n\npowinniśmy zobaczyć\n\n{\n    \"config\": {\n        \"provider\": \"emaillabs\",\n        \"settings\": {\n            \"defaultFrom\": \"office@preciselab.io\",\n            \"testAddress\": \"gustaw.daniel@gmail.com\"\n        }\n    }\n}\n\nPrzetestujmy to i przejdziemy do tematu załączników.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-05-26T12:21:47.000Z",
            "updated_at": "2022-10-06T19:10:57.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60c7453bc52f4a12ffdfc595",
            "uuid": "2ee6bff5-6551-4c15-b218-6b8eb71b48d4",
            "title": "Scraping najbardziej popularnych kont na twitterze",
            "slug": "scraping-najbardziej-popularnych-kont-na-twitterze",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/\",\"metadata\":{\"url\":\"https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/\",\"title\":\"The Most Followed Twitter Profiles | Trackalytics\",\"description\":\"The Most Followed Twitter Profiles | Trackalytics\",\"author\":null,\"publisher\":\"Trackalytics\",\"thumbnail\":\"https://www.trackalytics.com/assets/images/trackalytics-icon.png\",\"icon\":null}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-14-16-00-32.png\",\"width\":1003,\"height\":893}],[\"code\",{\"code\":\"view-source:https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-14-16-02-24.png\",\"width\":1864,\"height\":955}],[\"code\",{\"code\":\"npm init -y && tsc --init\",\"language\":\"bash\"}],[\"code\",{\"code\":\"mkdir -p raw\",\"language\":\"bash\"}],[\"code\",{\"code\":\"npm i -D @types/node\",\"language\":\"bash\"}],[\"code\",{\"code\":\"interface TwitterAccount {\\n    // todo implement\\n}\\n\\nclass Page {\\n    i: number;\\n\\n    constructor(i: number) {\\n        this.i = i;\\n    }\\n\\n    url() {\\n        return `https://www.trackalytics.com/the-most-followed-twitter-profiles/page/${this.i}/`\\n    }\\n\\n    file() {\\n        return `${process.cwd()}/raw/${this.i}.html`\\n    }\\n\\n    sync() {\\n        // TODO implement\\n        return false;\\n    }\\n\\n    parse(): TwitterAccount[] {\\n        // todo implement\\n        return []\\n    }\\n}\\n\\nconst main = async () => {\\n    let i = 1;\\n    const accounts = [];\\n    while (new Page(i).sync()) {\\n        const newAccounts = new Page(i).parse()\\n        if (newAccounts.length === 0) break;\\n        accounts.push(...newAccounts);\\n        i++;\\n    }\\n    return accounts;\\n}\\n\\nmain().then(console.log).catch(console.error)\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-14-16-20-30.png\",\"width\":449,\"height\":176}],[\"code\",{\"code\":\"interface TwitterAccount {\\n    rank: number\\n    avatar: string\\n    name: string\\n    url: string\\n    followers_total: number\\n    followers_today: number\\n    following_total: number\\n    following_today: number\\n    tweets_total: number\\n    tweets_today: number\\n}\",\"language\":\"ts\"}],[\"code\",{\"code\":\"npm i axios debug\\nnpm i -D @types/debug\",\"language\":\"bash\"}],[\"code\",{\"code\":\"import axios from \\\"axios\\\";\\nimport * as fs from \\\"fs\\\";\\nimport Debug from 'debug';\\n\\nconst debug = Debug('app');\"}],[\"code\",{\"code\":\"    async sync() {\\n        try {\\n            const fileExists = fs.existsSync(this.file())\\n\\n            if (fileExists) return true;\\n\\n            const {data, status} = await axios.get(this.url());\\n\\n            if (status !== 200) return false;\\n\\n            fs.writeFileSync(this.file(), data);\\n            debug(`Saved ${this.file()}`)\\n\\n            return true;\\n        } catch (e) {\\n            console.error(e)\\n            return false;\\n        }\\n    }\",\"language\":\"ts\"}],[\"code\",{\"code\":\"[...document.querySelectorAll('.post-content>table>tbody tr')].map(tr => { \\n\\nconst cols = [3,4,5].map(i => tr.querySelector(`td:nth-child(${i})`).textContent.split(/\\\\s+/).filter(x => x && x !== \\\"(\\\").map(x => parseInt(x.replace(/\\\\)|\\\\(|,/g,''))))\\n\\nreturn {\\n       rank: parseInt(tr.querySelector('.badge-info').textContent),\\n    avatar: tr.querySelector('img').src,\\n    name:  tr.querySelector('td:nth-child(2) a').title,\\n    url: tr.querySelector('td:nth-child(2) a').href,\\n    followers_total: cols[0][0],\\n    followers_today: cols[0][1],\\n    following_total: cols[1][0],\\n    following_today: cols[1][1],\\n    tweets_total: cols[2][0],\\n    tweets_today: cols[2][1]\\n}})\",\"language\":\"ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-21-13-28-38.png\",\"width\":623,\"height\":567}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/cheeriojs/cheerio/issues/700\",\"metadata\":{\"url\":\"https://github.com/cheeriojs/cheerio/issues/700\",\"title\":\"Is cheerio still 8x faster than jsdom? · Issue #700 · cheeriojs/cheerio\",\"description\":\"This part of the readme has been written 3,5 years ago. ba80a89 Is it still the case (especially regarding the 4.x serie of jsdom)?\",\"author\":\"cheeriojs\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/1cad19803f841f3c43f5ded49564813f7387da844013345c0f13caeea312cc46/cheeriojs/cheerio/issues/700\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"code\",{\"code\":\"    parse(): TwitterAccount[] {\\n        const content = fs.readFileSync(this.file()).toString();\\n        const $ = cheerio.load(content);\\n\\n        return $('.post-content>table>tbody tr').toArray().map(tr => {\\n            const cols = [3, 4, 5].map(i => cheerio(tr)\\n                .find(`td:nth-child(${i})`).text().split(/\\\\s+/)\\n                .filter(x => x && x !== \\\"(\\\").map(\\n                    x => parseInt(x.replace(/\\\\)|\\\\(|,/g, ''))))\\n\\n            return {\\n                rank: parseInt(cheerio(tr).find('.badge-info').text()),\\n                avatar: cheerio(tr).find('img').attr('src') || '',\\n                name: cheerio(tr).find('td:nth-child(2) a').attr('title') || '',\\n                url: cheerio(tr).find('td:nth-child(2) a').attr('href') || '',\\n                followers_total: cols[0][0],\\n                followers_today: cols[0][1],\\n                following_total: cols[1][0],\\n                following_today: cols[1][1],\\n                tweets_total: cols[2][0],\\n                tweets_today: cols[2][1]\\n            }\\n        })\\n    }\",\"language\":\"ts\"}],[\"code\",{\"code\":\"const main = async () => {\\n    let i = 1;\\n    const accounts = [];\\n    while (await new Page(i).sync()) {\\n        const newAccounts = new Page(i).parse()\\n        if (newAccounts.length === 0) break;\\n        accounts.push(...newAccounts);\\n        i++;\\n        debug(`Page ${i}`);\\n    }\\n    return accounts;\\n}\\n\\nmain().then(a => {\\n    fs.writeFileSync(process.cwd() + '/accounts.json', JSON.stringify(a.map(a => ({\\n        ...a,\\n        username: a.url.split('/').filter(a => a).reverse()[0]\\n    }))));\\n    console.log(a);\\n}).catch(console.error)\",\"language\":\"ts\"}],[\"code\",{\"code\":\"npm i cheerio\"}],[\"code\",{\"code\":\"time DEBUG=app ts-node index.ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-21-13-57-17.png\",\"width\":1105,\"height\":767}],[\"code\",{\"code\":\"mongoimport --collection twitter_accounts <connection_string>  --jsonArray --drop --file ./accounts.json\"}],[\"code\",{\"code\":\"[{\\n    $group: {\\n        _id: null,\\n        tweets_today: {\\n            $sum: '$tweets_today'\\n        },\\n        tweets_total: {\\n            $sum: '$tweets_total'\\n        },\\n        followers_today: {\\n            $sum: '$followers_today'\\n        },\\n        followers_total: {\\n            $sum: '$followers_total'\\n        },\\n        count: {\\n            $sum: 1\\n        }\\n    }\\n}]\",\"language\":\"json\"}],[\"code\",{\"code\":\"tweets_today:177779\\ntweets_total:613509174\\nfollowers_today:9577284\\nfollowers_total:20159062136\\ncount:16349\"}],[\"code\",{\"code\":\"[{$match: {\\n  tweets_total: {$gt: 0}\\n}}, {$addFields: {\\n  influence_by_tweet: {$divide: ['$followers_total','$tweets_total']}\\n}}, {$sort: {\\n  influence_by_tweet: -1\\n}}, {$match: {\\n  influence_by_tweet: {$gt: 100}\\n}}, {$group: {\\n        _id: null,\\n        tweets_today: {\\n            $sum: '$tweets_today'\\n        },\\n        tweets_total: {\\n            $sum: '$tweets_total'\\n        },\\n        followers_today: {\\n            $sum: '$followers_today'\\n        },\\n        followers_total: {\\n            $sum: '$followers_total'\\n        },\\n        count: {\\n            $sum: 1\\n        }\\n    }}]\",\"language\":\"json\"}],[\"code\",{\"code\":\"tweets_today:17161\\ntweets_total:32346484\\nfollowers_today:8197454\\nfollowers_total:14860523601\\ncount:3798\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/\"]],[\"code\"],[\"a\",[\"href\",\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/accounts.json\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Listę najbardziej popularnych kont w serwisie Twitter możemy znaleźć na stronie Trackalytics:\"]]],[10,0],[1,\"p\",[[0,[],0,\"W tym wpisie pokażę, jak pobrać te dane i posortujemy je względem ilości tweetów na ilość obserwujących. Następnie przeanalizujemy, jaką liczbę twórców mogli byśmy obserwować jednocześnie aby nie przekroczyć limitu darmowego api Twittera: 500 tys tweetów / msc.\"]]],[1,\"h3\",[[0,[],0,\"Analiza scrapowanej strony\"]]],[1,\"p\",[[0,[],0,\"Przed rozpoczęciem scrapingu należy zawsze wybrać odpowiedni wektor pozyskiwania danych. Pierwszą rzeczą, którą warto sprawdzać, jest zakładka network w przeglądarce. W naszym przypadku na stronie:\"]]],[1,\"blockquote\",[[0,[0],1,\"https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/\"]]],[1,\"p\",[[0,[],0,\"Mamy request o wyrenderowaną już stronę:\"]]],[10,1],[1,\"p\",[[0,[],0,\"więc rendering musi odbywać się na backendzie. Potwierdzimy to sprawdzając źródło strony.\"]]],[10,2],[1,\"p\",[[0,[],0,\"Faktycznie widzimy tu dane gotowe do scrapingu:\"]]],[10,3],[1,\"p\",[[0,[],0,\"Napiszemy więc skrypt, który pobierze ja i przetworzy za pomocą biblioteki \"],[0,[1],1,\"cheerio\"],[0,[],0,\".\"]]],[1,\"h3\",[[0,[],0,\"Przygotowanie projektu\"]]],[1,\"p\",[[0,[],0,\"Projekt inicjalizujemy komendami:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Tworzymy katalog \"],[0,[1],1,\"raw\"],[0,[],0,\" na pobierane pliki\"]]],[10,5],[1,\"p\",[[0,[],0,\"Instalujemy typescript\"]]],[10,6],[1,\"p\",[[0,[],0,\"Rdzeń naszego programu może wyglądać tak:\"]]],[10,7],[1,\"p\",[[0,[],0,\"Mamy tu za zaimplementowania interfejs kont wynikający ze struktury pobieranych danych, funkcję do sprawdzania czy strona istnieje i zapisu danych oraz funkcję do parsowania.\"]]],[1,\"h3\",[[0,[],0,\"Model danych\"]]],[1,\"p\",[[0,[],0,\"Patrząc na wyświetlane dane:\"]]],[10,8],[1,\"p\",[[0,[],0,\"Można stworzyć następujący interfejs opisujący konto Twittera\"]]],[10,9],[1,\"h3\",[[0,[],0,\"Pobieranie stron\"]]],[1,\"p\",[[0,[],0,\"Do pobierania stron użyjemy biblioteki \"],[0,[1],1,\"axios\"],[0,[],0,\". Do logowania danych nada się \"],[0,[1],1,\"debug\"],[0,[],0,\".\"]]],[10,10],[1,\"p\",[[0,[],0,\"Po wykonaniu kilku importów:\"]]],[10,11],[1,\"p\",[[0,[],0,\"Funkcja do synchronizacji mogła by wyglądać tak:\"]]],[10,12],[1,\"p\",[[0,[],0,\"Widzimy, że jeśli plik jest zapisany, to nie sprawdzamy dalej. Zatem nie ma ryzyka bombardowania strony docelowej nie potrzebnymi zapytaniami. To ważny aspekt scrapingu. Następnie jeśli strona zostanie poprawnie pobrana to jest zapisywana i również oznaczana jako istniejąca. Wynik negatywny dostaniemy jedynie w przypadku wystąpienia wyjątku oraz dla statusu innego niż 200.\"]]],[1,\"h3\",[[0,[],0,\"Przetwarzanie stron\"]]],[1,\"p\",[[0,[],0,\"Metoda \"],[0,[1],1,\"parse\"],[0,[],0,\" obiektu \"],[0,[1],1,\"Page\"],[0,[],0,\" powinna zwracać listę profili Twittera. Najprościej jest prototypować ją bezpośrednio w konsoli przeglądarki, a następnie przepisać taki selektor do cheerio. Tak właśnie zrobimy. Oto funkcja \"],[0,[1],1,\"parse\"],[0,[],0,\" napisana w konsoli przeglądarki:\"]]],[10,13],[10,14],[1,\"p\",[[0,[],0,\"W \"],[0,[1],1,\"node js\"],[0,[],0,\" nie mamy obiektu \"],[0,[1],1,\"document\"],[0,[],0,\" i aby wykonywać selektory na drzewie dom musimy je zbudować z tekstu tak jak robi to przeglądarka. Z tym, że zamiast natywnie wbudowanego mechanizmu wykorzystamy do tego jedną z popularnych bibliotek. Najbardziej znane są:\"]]],[3,\"ul\",[[[0,[],0,\"cheerio\"]],[[0,[],0,\"js dom\"]]]],[1,\"p\",[[0,[],0,\"Zrobiłem kiedyś ich porównanie pod względem wydajności:\"]]],[10,15],[1,\"p\",[[0,[],0,\"Wszystko wskazuje na to, że \"],[0,[1],1,\"cheerio\"],[0,[],0,\" jest znacznie lepszym wyborem.\"]]],[1,\"p\",[[0,[],0,\"Aby przetworzyć ją do postaci akceptowalnej przez cherio musimy \"],[0,[1],1,\"document\"],[0,[],0,\" zastąpić przez \"],[0,[1],1,\"cheerio.load(content)\"],[0,[],0,\", a elementy należy otaczać \"],[0,[1],1,\"cheerio(element).find\"],[0,[],0,\" aby szukać ich potomków. Do tego do atrybutów potrzebujemy funkcji \"],[0,[1],1,\"attr\"],[0,[],0,\" i na tablicach funkcji \"],[0,[1],1,\"toArray\"],[0,[],0,\". To właściwie wszystkie zmiany, ich wprowadzenie zajmuje chwilę i w wyniku ich zastosowania do selektora działającego w przeglądarce dostaniemy implementację funkcji \"],[0,[1],1,\"parse\"]]],[10,16],[1,\"p\",[[0,[],0,\"Dokładając do tego drobną modyfikację końcówki programu, żeby zapisywał uzyskane dane w pliku \"],[0,[1],1,\"json\"],[0,[],0,\" \"]]],[10,17],[1,\"p\",[[0,[],0,\"po zainstalowaniu paczki \"],[0,[1],1,\"cheerio\"],[0,[],0,\" \"]]],[10,18],[1,\"p\",[[0,[],0,\"możemy włączyć nasz program poleceniem\"]]],[10,19],[1,\"p\",[[0,[],0,\"Poniżej widzimy jak wygląda ono w otoczeniu programów \"],[0,[1],1,\"bmon\"],[0,[],0,\" do monitorowania interfejsów sieciowych oraz \"],[0,[1],1,\"htop\"],[0,[],0,\" do sprawdzania pamięci \"],[0,[1],1,\"ram\"],[0,[],0,\" oraz zużycia procesora.\"]]],[10,20],[1,\"p\",[[0,[],0,\"Do zapisania tego pliku w bazie danych mongo możemy użyć polecenia:\"]]],[10,21],[1,\"p\",[[0,[],0,\"Następnie wykonując agregację:\"]]],[10,22],[1,\"p\",[[0,[],0,\"możemy dowiedzieć się, że 16k najpopularniejszych kont na twitterze wytworzyło 0.6 miliarda tweetów, z czego 177 tysięcy dzisiaj.\"]]],[10,23],[1,\"p\",[[0,[],0,\"Łączna liczba followersów to 20 mld (oczywiście są w tym liczne duplikaty), a dzisiaj pozyskani followersi tych kont to 10 mln.  \"]]],[1,\"p\",[[0,[],0,\"Darmowe api twittera pozwala na nasłuch w czasie rzeczywistym do 500 tys tweetów. Oznacza to, że dziennie można zbierać średnio 16 tysięcy.\"]]],[1,\"p\",[[0,[],0,\"Załóżmy, że naszym zadaniem jest obserwacja tych kont, które najmniejszą liczbą wpisów robią największe zasięgi. W ich odnalezieniu pomoże nam kolejna agregacja:\"]]],[10,24],[1,\"p\",[[0,[],0,\"Dzięki niej możemy wybrać 3798 kont które dzienne postują jedynie 17161 tweetów ale mają zasięg do 14 mld użytkowników łącznie a dzisiaj pozyskali 8 mln.\"]]],[10,25],[1,\"p\",[[0,[],0,\"Oznacza to, że ilość obserwowanych kont spadła do 23%, ilość tweetów dziennie do 9%, ale ilość wszystkich followerów utrzymała się na poziomie 73% wcześniejszej wartości (oczywiście te obliczenia nie uwzględniają duplikacji), a ilość pozyskiwanych dzisiaj followerów przez te wybrane konta to 85% z pierwotnej wartości.\"]]],[1,\"p\",[[0,[],0,\"Podsumowując. Wybraliśmy tylko część kont, które pisząc 9% tweetów względem całej grupy najpopularniejszych kont każdego dnia pozwalają uzyskać 85% z interesującego nas zasięgu.\"]]],[1,\"p\",[[0,[],0,\"Naszym kryterium odcięcia jest uzyskiwanie przynajmniej 100 followersów na jednym tweecie. Powinniśmy się spodziewać około 17000/24/60 = 11 tweetów na minutę.\"]]],[1,\"p\",[[0,[],0,\"Zgodnie z tradycją tego bloga na końcu podaję link do zescrapowanych danych:\"]]],[1,\"p\",[[0,[2],1,\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/accounts.json\"]]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Listę najbardziej popularnych kont w serwisie Twitter możemy znaleźć na stronie Trackalytics:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">The Most Followed Twitter Profiles | Trackalytics</div><div class=\"kg-bookmark-description\">The Most Followed Twitter Profiles | Trackalytics</div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">Trackalytics</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.trackalytics.com/assets/images/trackalytics-icon.png\"></div></a></figure><p>W tym wpisie pokażę, jak pobrać te dane i posortujemy je względem ilości tweetów na ilość obserwujących. Następnie przeanalizujemy, jaką liczbę twórców mogli byśmy obserwować jednocześnie aby nie przekroczyć limitu darmowego api Twittera: 500 tys tweetów / msc.</p><h3 id=\"analiza-scrapowanej-strony\">Analiza scrapowanej strony</h3><p>Przed rozpoczęciem scrapingu należy zawsze wybrać odpowiedni wektor pozyskiwania danych. Pierwszą rzeczą, którą warto sprawdzać, jest zakładka network w przeglądarce. W naszym przypadku na stronie:</p><blockquote><a href=\"https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/\">https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/</a></blockquote><p>Mamy request o wyrenderowaną już stronę:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-14-16-00-32.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1003\" height=\"893\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/Screenshot-from-2021-06-14-16-00-32.png 600w, __GHOST_URL__/content/images/size/w1000/2021/06/Screenshot-from-2021-06-14-16-00-32.png 1000w, __GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-14-16-00-32.png 1003w\" sizes=\"(min-width: 720px) 720px\"></figure><p>więc rendering musi odbywać się na backendzie. Potwierdzimy to sprawdzając źródło strony.</p><pre><code>view-source:https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/</code></pre><p>Faktycznie widzimy tu dane gotowe do scrapingu:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-14-16-02-24.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1864\" height=\"955\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/Screenshot-from-2021-06-14-16-02-24.png 600w, __GHOST_URL__/content/images/size/w1000/2021/06/Screenshot-from-2021-06-14-16-02-24.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/06/Screenshot-from-2021-06-14-16-02-24.png 1600w, __GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-14-16-02-24.png 1864w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Napiszemy więc skrypt, który pobierze ja i przetworzy za pomocą biblioteki <code>cheerio</code>.</p><h3 id=\"przygotowanie-projektu\">Przygotowanie projektu</h3><p>Projekt inicjalizujemy komendami:</p><pre><code class=\"language-bash\">npm init -y &amp;&amp; tsc --init</code></pre><p>Tworzymy katalog <code>raw</code> na pobierane pliki</p><pre><code class=\"language-bash\">mkdir -p raw</code></pre><p>Instalujemy typescript</p><pre><code class=\"language-bash\">npm i -D @types/node</code></pre><p>Rdzeń naszego programu może wyglądać tak:</p><pre><code class=\"language-ts\">interface TwitterAccount {\n    // todo implement\n}\n\nclass Page {\n    i: number;\n\n    constructor(i: number) {\n        this.i = i;\n    }\n\n    url() {\n        return `https://www.trackalytics.com/the-most-followed-twitter-profiles/page/${this.i}/`\n    }\n\n    file() {\n        return `${process.cwd()}/raw/${this.i}.html`\n    }\n\n    sync() {\n        // TODO implement\n        return false;\n    }\n\n    parse(): TwitterAccount[] {\n        // todo implement\n        return []\n    }\n}\n\nconst main = async () =&gt; {\n    let i = 1;\n    const accounts = [];\n    while (new Page(i).sync()) {\n        const newAccounts = new Page(i).parse()\n        if (newAccounts.length === 0) break;\n        accounts.push(...newAccounts);\n        i++;\n    }\n    return accounts;\n}\n\nmain().then(console.log).catch(console.error)</code></pre><p>Mamy tu za zaimplementowania interfejs kont wynikający ze struktury pobieranych danych, funkcję do sprawdzania czy strona istnieje i zapisu danych oraz funkcję do parsowania.</p><h3 id=\"model-danych\">Model danych</h3><p>Patrząc na wyświetlane dane:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-14-16-20-30.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"449\" height=\"176\"></figure><p>Można stworzyć następujący interfejs opisujący konto Twittera</p><pre><code class=\"language-ts\">interface TwitterAccount {\n    rank: number\n    avatar: string\n    name: string\n    url: string\n    followers_total: number\n    followers_today: number\n    following_total: number\n    following_today: number\n    tweets_total: number\n    tweets_today: number\n}</code></pre><h3 id=\"pobieranie-stron\">Pobieranie stron</h3><p>Do pobierania stron użyjemy biblioteki <code>axios</code>. Do logowania danych nada się <code>debug</code>.</p><pre><code class=\"language-bash\">npm i axios debug\nnpm i -D @types/debug</code></pre><p>Po wykonaniu kilku importów:</p><pre><code>import axios from \"axios\";\nimport * as fs from \"fs\";\nimport Debug from 'debug';\n\nconst debug = Debug('app');</code></pre><p>Funkcja do synchronizacji mogła by wyglądać tak:</p><pre><code class=\"language-ts\">    async sync() {\n        try {\n            const fileExists = fs.existsSync(this.file())\n\n            if (fileExists) return true;\n\n            const {data, status} = await axios.get(this.url());\n\n            if (status !== 200) return false;\n\n            fs.writeFileSync(this.file(), data);\n            debug(`Saved ${this.file()}`)\n\n            return true;\n        } catch (e) {\n            console.error(e)\n            return false;\n        }\n    }</code></pre><p>Widzimy, że jeśli plik jest zapisany, to nie sprawdzamy dalej. Zatem nie ma ryzyka bombardowania strony docelowej nie potrzebnymi zapytaniami. To ważny aspekt scrapingu. Następnie jeśli strona zostanie poprawnie pobrana to jest zapisywana i również oznaczana jako istniejąca. Wynik negatywny dostaniemy jedynie w przypadku wystąpienia wyjątku oraz dla statusu innego niż 200.</p><h3 id=\"przetwarzanie-stron\">Przetwarzanie stron</h3><p>Metoda <code>parse</code> obiektu <code>Page</code> powinna zwracać listę profili Twittera. Najprościej jest prototypować ją bezpośrednio w konsoli przeglądarki, a następnie przepisać taki selektor do cheerio. Tak właśnie zrobimy. Oto funkcja <code>parse</code> napisana w konsoli przeglądarki:</p><pre><code class=\"language-ts\">[...document.querySelectorAll('.post-content&gt;table&gt;tbody tr')].map(tr =&gt; { \n\nconst cols = [3,4,5].map(i =&gt; tr.querySelector(`td:nth-child(${i})`).textContent.split(/\\s+/).filter(x =&gt; x &amp;&amp; x !== \"(\").map(x =&gt; parseInt(x.replace(/\\)|\\(|,/g,''))))\n\nreturn {\n       rank: parseInt(tr.querySelector('.badge-info').textContent),\n    avatar: tr.querySelector('img').src,\n    name:  tr.querySelector('td:nth-child(2) a').title,\n    url: tr.querySelector('td:nth-child(2) a').href,\n    followers_total: cols[0][0],\n    followers_today: cols[0][1],\n    following_total: cols[1][0],\n    following_today: cols[1][1],\n    tweets_total: cols[2][0],\n    tweets_today: cols[2][1]\n}})</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-21-13-28-38.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"623\" height=\"567\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/Screenshot-from-2021-06-21-13-28-38.png 600w, __GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-21-13-28-38.png 623w\"></figure><p>W <code>node js</code> nie mamy obiektu <code>document</code> i aby wykonywać selektory na drzewie dom musimy je zbudować z tekstu tak jak robi to przeglądarka. Z tym, że zamiast natywnie wbudowanego mechanizmu wykorzystamy do tego jedną z popularnych bibliotek. Najbardziej znane są:</p><ul><li>cheerio</li><li>js dom</li></ul><p>Zrobiłem kiedyś ich porównanie pod względem wydajności:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/cheeriojs/cheerio/issues/700\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Is cheerio still 8x faster than jsdom? · Issue #700 · cheeriojs/cheerio</div><div class=\"kg-bookmark-description\">This part of the readme has been written 3,5 years ago. ba80a89 Is it still the case (especially regarding the 4.x serie of jsdom)?</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">cheeriojs</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/1cad19803f841f3c43f5ded49564813f7387da844013345c0f13caeea312cc46/cheeriojs/cheerio/issues/700\"></div></a></figure><p>Wszystko wskazuje na to, że <code>cheerio</code> jest znacznie lepszym wyborem.</p><p>Aby przetworzyć ją do postaci akceptowalnej przez cherio musimy <code>document</code> zastąpić przez <code>cheerio.load(content)</code>, a elementy należy otaczać <code>cheerio(element).find</code> aby szukać ich potomków. Do tego do atrybutów potrzebujemy funkcji <code>attr</code> i na tablicach funkcji <code>toArray</code>. To właściwie wszystkie zmiany, ich wprowadzenie zajmuje chwilę i w wyniku ich zastosowania do selektora działającego w przeglądarce dostaniemy implementację funkcji <code>parse</code></p><pre><code class=\"language-ts\">    parse(): TwitterAccount[] {\n        const content = fs.readFileSync(this.file()).toString();\n        const $ = cheerio.load(content);\n\n        return $('.post-content&gt;table&gt;tbody tr').toArray().map(tr =&gt; {\n            const cols = [3, 4, 5].map(i =&gt; cheerio(tr)\n                .find(`td:nth-child(${i})`).text().split(/\\s+/)\n                .filter(x =&gt; x &amp;&amp; x !== \"(\").map(\n                    x =&gt; parseInt(x.replace(/\\)|\\(|,/g, ''))))\n\n            return {\n                rank: parseInt(cheerio(tr).find('.badge-info').text()),\n                avatar: cheerio(tr).find('img').attr('src') || '',\n                name: cheerio(tr).find('td:nth-child(2) a').attr('title') || '',\n                url: cheerio(tr).find('td:nth-child(2) a').attr('href') || '',\n                followers_total: cols[0][0],\n                followers_today: cols[0][1],\n                following_total: cols[1][0],\n                following_today: cols[1][1],\n                tweets_total: cols[2][0],\n                tweets_today: cols[2][1]\n            }\n        })\n    }</code></pre><p>Dokładając do tego drobną modyfikację końcówki programu, żeby zapisywał uzyskane dane w pliku <code>json</code> </p><pre><code class=\"language-ts\">const main = async () =&gt; {\n    let i = 1;\n    const accounts = [];\n    while (await new Page(i).sync()) {\n        const newAccounts = new Page(i).parse()\n        if (newAccounts.length === 0) break;\n        accounts.push(...newAccounts);\n        i++;\n        debug(`Page ${i}`);\n    }\n    return accounts;\n}\n\nmain().then(a =&gt; {\n    fs.writeFileSync(process.cwd() + '/accounts.json', JSON.stringify(a.map(a =&gt; ({\n        ...a,\n        username: a.url.split('/').filter(a =&gt; a).reverse()[0]\n    }))));\n    console.log(a);\n}).catch(console.error)</code></pre><p>po zainstalowaniu paczki <code>cheerio</code> </p><pre><code>npm i cheerio</code></pre><p>możemy włączyć nasz program poleceniem</p><pre><code>time DEBUG=app ts-node index.ts</code></pre><p>Poniżej widzimy jak wygląda ono w otoczeniu programów <code>bmon</code> do monitorowania interfejsów sieciowych oraz <code>htop</code> do sprawdzania pamięci <code>ram</code> oraz zużycia procesora.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-21-13-57-17.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1105\" height=\"767\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/Screenshot-from-2021-06-21-13-57-17.png 600w, __GHOST_URL__/content/images/size/w1000/2021/06/Screenshot-from-2021-06-21-13-57-17.png 1000w, __GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-21-13-57-17.png 1105w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Do zapisania tego pliku w bazie danych mongo możemy użyć polecenia:</p><pre><code>mongoimport --collection twitter_accounts &lt;connection_string&gt;  --jsonArray --drop --file ./accounts.json</code></pre><p>Następnie wykonując agregację:</p><pre><code class=\"language-json\">[{\n    $group: {\n        _id: null,\n        tweets_today: {\n            $sum: '$tweets_today'\n        },\n        tweets_total: {\n            $sum: '$tweets_total'\n        },\n        followers_today: {\n            $sum: '$followers_today'\n        },\n        followers_total: {\n            $sum: '$followers_total'\n        },\n        count: {\n            $sum: 1\n        }\n    }\n}]</code></pre><p>możemy dowiedzieć się, że 16k najpopularniejszych kont na twitterze wytworzyło 0.6 miliarda tweetów, z czego 177 tysięcy dzisiaj.</p><pre><code>tweets_today:177779\ntweets_total:613509174\nfollowers_today:9577284\nfollowers_total:20159062136\ncount:16349</code></pre><p>Łączna liczba followersów to 20 mld (oczywiście są w tym liczne duplikaty), a dzisiaj pozyskani followersi tych kont to 10 mln.  </p><p>Darmowe api twittera pozwala na nasłuch w czasie rzeczywistym do 500 tys tweetów. Oznacza to, że dziennie można zbierać średnio 16 tysięcy.</p><p>Załóżmy, że naszym zadaniem jest obserwacja tych kont, które najmniejszą liczbą wpisów robią największe zasięgi. W ich odnalezieniu pomoże nam kolejna agregacja:</p><pre><code class=\"language-json\">[{$match: {\n  tweets_total: {$gt: 0}\n}}, {$addFields: {\n  influence_by_tweet: {$divide: ['$followers_total','$tweets_total']}\n}}, {$sort: {\n  influence_by_tweet: -1\n}}, {$match: {\n  influence_by_tweet: {$gt: 100}\n}}, {$group: {\n        _id: null,\n        tweets_today: {\n            $sum: '$tweets_today'\n        },\n        tweets_total: {\n            $sum: '$tweets_total'\n        },\n        followers_today: {\n            $sum: '$followers_today'\n        },\n        followers_total: {\n            $sum: '$followers_total'\n        },\n        count: {\n            $sum: 1\n        }\n    }}]</code></pre><p>Dzięki niej możemy wybrać 3798 kont które dzienne postują jedynie 17161 tweetów ale mają zasięg do 14 mld użytkowników łącznie a dzisiaj pozyskali 8 mln.</p><pre><code>tweets_today:17161\ntweets_total:32346484\nfollowers_today:8197454\nfollowers_total:14860523601\ncount:3798</code></pre><p>Oznacza to, że ilość obserwowanych kont spadła do 23%, ilość tweetów dziennie do 9%, ale ilość wszystkich followerów utrzymała się na poziomie 73% wcześniejszej wartości (oczywiście te obliczenia nie uwzględniają duplikacji), a ilość pozyskiwanych dzisiaj followerów przez te wybrane konta to 85% z pierwotnej wartości.</p><p>Podsumowując. Wybraliśmy tylko część kont, które pisząc 9% tweetów względem całej grupy najpopularniejszych kont każdego dnia pozwalają uzyskać 85% z interesującego nas zasięgu.</p><p>Naszym kryterium odcięcia jest uzyskiwanie przynajmniej 100 followersów na jednym tweecie. Powinniśmy się spodziewać około 17000/24/60 = 11 tweetów na minutę.</p><p>Zgodnie z tradycją tego bloga na końcu podaję link do zescrapowanych danych:</p><p><a href=\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/accounts.json\">https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/accounts.json</a></p>",
            "comment_id": "60c7453bc52f4a12ffdfc595",
            "plaintext": "Listę najbardziej popularnych kont w serwisie Twitter możemy znaleźć na stronie\nTrackalytics:\n\nThe Most Followed Twitter Profiles | TrackalyticsThe Most Followed Twitter\nProfiles | TrackalyticsTrackalytics\n[https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/]W tym\nwpisie pokażę, jak pobrać te dane i posortujemy je względem ilości tweetów na\nilość obserwujących. Następnie przeanalizujemy, jaką liczbę twórców mogli byśmy\nobserwować jednocześnie aby nie przekroczyć limitu darmowego api Twittera: 500\ntys tweetów / msc.\n\nAnaliza scrapowanej strony\nPrzed rozpoczęciem scrapingu należy zawsze wybrać odpowiedni wektor pozyskiwania\ndanych. Pierwszą rzeczą, którą warto sprawdzać, jest zakładka network w\nprzeglądarce. W naszym przypadku na stronie:\n\n> https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/\nMamy request o wyrenderowaną już stronę:\n\nwięc rendering musi odbywać się na backendzie. Potwierdzimy to sprawdzając\nźródło strony.\n\nview-source:https://www.trackalytics.com/the-most-followed-twitter-profiles/page/1/\n\nFaktycznie widzimy tu dane gotowe do scrapingu:\n\nNapiszemy więc skrypt, który pobierze ja i przetworzy za pomocą biblioteki \ncheerio.\n\nPrzygotowanie projektu\nProjekt inicjalizujemy komendami:\n\nnpm init -y && tsc --init\n\nTworzymy katalog raw na pobierane pliki\n\nmkdir -p raw\n\nInstalujemy typescript\n\nnpm i -D @types/node\n\nRdzeń naszego programu może wyglądać tak:\n\ninterface TwitterAccount {\n    // todo implement\n}\n\nclass Page {\n    i: number;\n\n    constructor(i: number) {\n        this.i = i;\n    }\n\n    url() {\n        return `https://www.trackalytics.com/the-most-followed-twitter-profiles/page/${this.i}/`\n    }\n\n    file() {\n        return `${process.cwd()}/raw/${this.i}.html`\n    }\n\n    sync() {\n        // TODO implement\n        return false;\n    }\n\n    parse(): TwitterAccount[] {\n        // todo implement\n        return []\n    }\n}\n\nconst main = async () => {\n    let i = 1;\n    const accounts = [];\n    while (new Page(i).sync()) {\n        const newAccounts = new Page(i).parse()\n        if (newAccounts.length === 0) break;\n        accounts.push(...newAccounts);\n        i++;\n    }\n    return accounts;\n}\n\nmain().then(console.log).catch(console.error)\n\nMamy tu za zaimplementowania interfejs kont wynikający ze struktury pobieranych\ndanych, funkcję do sprawdzania czy strona istnieje i zapisu danych oraz funkcję\ndo parsowania.\n\nModel danych\nPatrząc na wyświetlane dane:\n\nMożna stworzyć następujący interfejs opisujący konto Twittera\n\ninterface TwitterAccount {\n    rank: number\n    avatar: string\n    name: string\n    url: string\n    followers_total: number\n    followers_today: number\n    following_total: number\n    following_today: number\n    tweets_total: number\n    tweets_today: number\n}\n\nPobieranie stron\nDo pobierania stron użyjemy biblioteki axios. Do logowania danych nada się debug\n.\n\nnpm i axios debug\nnpm i -D @types/debug\n\nPo wykonaniu kilku importów:\n\nimport axios from \"axios\";\nimport * as fs from \"fs\";\nimport Debug from 'debug';\n\nconst debug = Debug('app');\n\nFunkcja do synchronizacji mogła by wyglądać tak:\n\n    async sync() {\n        try {\n            const fileExists = fs.existsSync(this.file())\n\n            if (fileExists) return true;\n\n            const {data, status} = await axios.get(this.url());\n\n            if (status !== 200) return false;\n\n            fs.writeFileSync(this.file(), data);\n            debug(`Saved ${this.file()}`)\n\n            return true;\n        } catch (e) {\n            console.error(e)\n            return false;\n        }\n    }\n\nWidzimy, że jeśli plik jest zapisany, to nie sprawdzamy dalej. Zatem nie ma\nryzyka bombardowania strony docelowej nie potrzebnymi zapytaniami. To ważny\naspekt scrapingu. Następnie jeśli strona zostanie poprawnie pobrana to jest\nzapisywana i również oznaczana jako istniejąca. Wynik negatywny dostaniemy\njedynie w przypadku wystąpienia wyjątku oraz dla statusu innego niż 200.\n\nPrzetwarzanie stron\nMetoda parse obiektu Page powinna zwracać listę profili Twittera. Najprościej\njest prototypować ją bezpośrednio w konsoli przeglądarki, a następnie przepisać\ntaki selektor do cheerio. Tak właśnie zrobimy. Oto funkcja parse napisana w\nkonsoli przeglądarki:\n\n[...document.querySelectorAll('.post-content>table>tbody tr')].map(tr => { \n\nconst cols = [3,4,5].map(i => tr.querySelector(`td:nth-child(${i})`).textContent.split(/\\s+/).filter(x => x && x !== \"(\").map(x => parseInt(x.replace(/\\)|\\(|,/g,''))))\n\nreturn {\n       rank: parseInt(tr.querySelector('.badge-info').textContent),\n    avatar: tr.querySelector('img').src,\n    name:  tr.querySelector('td:nth-child(2) a').title,\n    url: tr.querySelector('td:nth-child(2) a').href,\n    followers_total: cols[0][0],\n    followers_today: cols[0][1],\n    following_total: cols[1][0],\n    following_today: cols[1][1],\n    tweets_total: cols[2][0],\n    tweets_today: cols[2][1]\n}})\n\nW node js nie mamy obiektu document i aby wykonywać selektory na drzewie dom\nmusimy je zbudować z tekstu tak jak robi to przeglądarka. Z tym, że zamiast\nnatywnie wbudowanego mechanizmu wykorzystamy do tego jedną z popularnych\nbibliotek. Najbardziej znane są:\n\n * cheerio\n * js dom\n\nZrobiłem kiedyś ich porównanie pod względem wydajności:\n\nIs cheerio still 8x faster than jsdom? · Issue #700 · cheeriojs/cheerioThis\npart\nof the readme has been written 3,5 years ago. ba80a89 Is it still the case\n(especially regarding the 4.x serie of jsdom)?GitHubcheeriojs\n[https://github.com/cheeriojs/cheerio/issues/700]Wszystko wskazuje na to, że cheerio jest znacznie lepszym wyborem.\n\nAby przetworzyć ją do postaci akceptowalnej przez cherio musimy document \nzastąpić przez cheerio.load(content), a elementy należy otaczać \ncheerio(element).find aby szukać ich potomków. Do tego do atrybutów potrzebujemy\nfunkcji attr i na tablicach funkcji toArray. To właściwie wszystkie zmiany, ich\nwprowadzenie zajmuje chwilę i w wyniku ich zastosowania do selektora\ndziałającego w przeglądarce dostaniemy implementację funkcji parse\n\n    parse(): TwitterAccount[] {\n        const content = fs.readFileSync(this.file()).toString();\n        const $ = cheerio.load(content);\n\n        return $('.post-content>table>tbody tr').toArray().map(tr => {\n            const cols = [3, 4, 5].map(i => cheerio(tr)\n                .find(`td:nth-child(${i})`).text().split(/\\s+/)\n                .filter(x => x && x !== \"(\").map(\n                    x => parseInt(x.replace(/\\)|\\(|,/g, ''))))\n\n            return {\n                rank: parseInt(cheerio(tr).find('.badge-info').text()),\n                avatar: cheerio(tr).find('img').attr('src') || '',\n                name: cheerio(tr).find('td:nth-child(2) a').attr('title') || '',\n                url: cheerio(tr).find('td:nth-child(2) a').attr('href') || '',\n                followers_total: cols[0][0],\n                followers_today: cols[0][1],\n                following_total: cols[1][0],\n                following_today: cols[1][1],\n                tweets_total: cols[2][0],\n                tweets_today: cols[2][1]\n            }\n        })\n    }\n\nDokładając do tego drobną modyfikację końcówki programu, żeby zapisywał uzyskane\ndane w pliku json \n\nconst main = async () => {\n    let i = 1;\n    const accounts = [];\n    while (await new Page(i).sync()) {\n        const newAccounts = new Page(i).parse()\n        if (newAccounts.length === 0) break;\n        accounts.push(...newAccounts);\n        i++;\n        debug(`Page ${i}`);\n    }\n    return accounts;\n}\n\nmain().then(a => {\n    fs.writeFileSync(process.cwd() + '/accounts.json', JSON.stringify(a.map(a => ({\n        ...a,\n        username: a.url.split('/').filter(a => a).reverse()[0]\n    }))));\n    console.log(a);\n}).catch(console.error)\n\npo zainstalowaniu paczki cheerio \n\nnpm i cheerio\n\nmożemy włączyć nasz program poleceniem\n\ntime DEBUG=app ts-node index.ts\n\nPoniżej widzimy jak wygląda ono w otoczeniu programów bmon do monitorowania\ninterfejsów sieciowych oraz htop do sprawdzania pamięci ram oraz zużycia\nprocesora.\n\nDo zapisania tego pliku w bazie danych mongo możemy użyć polecenia:\n\nmongoimport --collection twitter_accounts <connection_string>  --jsonArray --drop --file ./accounts.json\n\nNastępnie wykonując agregację:\n\n[{\n    $group: {\n        _id: null,\n        tweets_today: {\n            $sum: '$tweets_today'\n        },\n        tweets_total: {\n            $sum: '$tweets_total'\n        },\n        followers_today: {\n            $sum: '$followers_today'\n        },\n        followers_total: {\n            $sum: '$followers_total'\n        },\n        count: {\n            $sum: 1\n        }\n    }\n}]\n\nmożemy dowiedzieć się, że 16k najpopularniejszych kont na twitterze wytworzyło\n0.6 miliarda tweetów, z czego 177 tysięcy dzisiaj.\n\ntweets_today:177779\ntweets_total:613509174\nfollowers_today:9577284\nfollowers_total:20159062136\ncount:16349\n\nŁączna liczba followersów to 20 mld (oczywiście są w tym liczne duplikaty), a\ndzisiaj pozyskani followersi tych kont to 10 mln.\n\nDarmowe api twittera pozwala na nasłuch w czasie rzeczywistym do 500 tys\ntweetów. Oznacza to, że dziennie można zbierać średnio 16 tysięcy.\n\nZałóżmy, że naszym zadaniem jest obserwacja tych kont, które najmniejszą liczbą\nwpisów robią największe zasięgi. W ich odnalezieniu pomoże nam kolejna\nagregacja:\n\n[{$match: {\n  tweets_total: {$gt: 0}\n}}, {$addFields: {\n  influence_by_tweet: {$divide: ['$followers_total','$tweets_total']}\n}}, {$sort: {\n  influence_by_tweet: -1\n}}, {$match: {\n  influence_by_tweet: {$gt: 100}\n}}, {$group: {\n        _id: null,\n        tweets_today: {\n            $sum: '$tweets_today'\n        },\n        tweets_total: {\n            $sum: '$tweets_total'\n        },\n        followers_today: {\n            $sum: '$followers_today'\n        },\n        followers_total: {\n            $sum: '$followers_total'\n        },\n        count: {\n            $sum: 1\n        }\n    }}]\n\nDzięki niej możemy wybrać 3798 kont które dzienne postują jedynie 17161 tweetów\nale mają zasięg do 14 mld użytkowników łącznie a dzisiaj pozyskali 8 mln.\n\ntweets_today:17161\ntweets_total:32346484\nfollowers_today:8197454\nfollowers_total:14860523601\ncount:3798\n\nOznacza to, że ilość obserwowanych kont spadła do 23%, ilość tweetów dziennie do\n9%, ale ilość wszystkich followerów utrzymała się na poziomie 73% wcześniejszej\nwartości (oczywiście te obliczenia nie uwzględniają duplikacji), a ilość\npozyskiwanych dzisiaj followerów przez te wybrane konta to 85% z pierwotnej\nwartości.\n\nPodsumowując. Wybraliśmy tylko część kont, które pisząc 9% tweetów względem\ncałej grupy najpopularniejszych kont każdego dnia pozwalają uzyskać 85% z\ninteresującego nas zasięgu.\n\nNaszym kryterium odcięcia jest uzyskiwanie przynajmniej 100 followersów na\njednym tweecie. Powinniśmy się spodziewać około 17000/24/60 = 11 tweetów na\nminutę.\n\nZgodnie z tradycją tego bloga na końcu podaję link do zescrapowanych danych:\n\nhttps://preciselab.fra1.digitaloceanspaces.com/blog/scraping/accounts.json",
            "feature_image": "__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-21-13-57-17-1.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-06-14T12:02:03.000Z",
            "updated_at": "2021-06-26T09:35:10.000Z",
            "published_at": "2021-06-21T16:24:01.000Z",
            "custom_excerpt": "Dzięki obserwacji wpisów z twittera możemy śledzić różne trendy. W tym wpisie pokażę jak pobrać dane o kontach w tym serwisie i wybrać te, które mają największy współczynnik wpływu.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60d6e8ff72a5cb20e224a224",
            "uuid": "fdb8fe0a-c2db-4ebe-9f75-ee2a8c756e74",
            "title": "Analiza częstości nazw altcoinów w korpusie języka angielskiego",
            "slug": "analiza-czestosci-nazw-kryptowalut-w-korpusie-jezyka-angielskiego",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"https://api.coinmarketcap.com/data-api/v3/cryptocurrency/listing\"}],[\"code\",{\"code\":\"{\\n    \\\"data\\\": {\\n        \\\"cryptoCurrencyList\\\": [\\n            {\\n                \\\"id\\\": 8138,\\n                \\\"name\\\": \\\"LinkBased\\\",\\n                \\\"symbol\\\": \\\"LBD\\\",\\n                \\\"slug\\\": \\\"linkbased\\\",\\n                \\\"tags\\\": [],\\n                \\\"cmcRank\\\": 4601,\\n                \\\"marketPairCount\\\": 1,\\n                \\\"circulatingSupply\\\": 0E-8,\\n                \\\"totalSupply\\\": 813923.00000000,\\n                \\\"isActive\\\": 1,\\n                \\\"lastUpdated\\\": \\\"2021-06-26T09:08:12.000Z\\\",\\n                \\\"dateAdded\\\": \\\"2020-12-30T00:00:00.000Z\\\",\\n                \\\"quotes\\\": [\\n                    {\\n                        \\\"name\\\": \\\"USD\\\",\\n                        \\\"price\\\": 1.59351133162663,\\n                        \\\"volume24h\\\": 514.07425485,\\n                        \\\"marketCap\\\": 0E-22,\\n                        \\\"percentChange1h\\\": -0.13208528,\\n                        \\\"percentChange24h\\\": -26.50872672,\\n                        \\\"percentChange7d\\\": -34.07116202,\\n                        \\\"lastUpdated\\\": \\\"2021-06-26T09:08:12.000Z\\\",\\n                        \\\"percentChange30d\\\": -56.37728930,\\n                        \\\"percentChange60d\\\": -57.50444478,\\n                        \\\"percentChange90d\\\": -46.98725744,\\n                        \\\"fullyDilluttedMarketCap\\\": 1296995.52,\\n                        \\\"dominance\\\": 0.0,\\n                        \\\"ytdPriceChangePercentage\\\": 41.3223\\n                    }\\n                ],\\n                \\\"isAudited\\\": false\\n            },\\n            ...\\n        ],\\n        \\\"totalCount\\\": \\\"5465\\\"\\n    },\\n    \\\"status\\\": {\\n        \\\"timestamp\\\": \\\"2021-06-26T09:10:02.180Z\\\",\\n        \\\"error_code\\\": \\\"0\\\",\\n        \\\"error_message\\\": \\\"SUCCESS\\\",\\n        \\\"elapsed\\\": \\\"134\\\",\\n        \\\"credit_count\\\": 0\\n    }\\n}\"}],[\"code\",{\"code\":\"{\\n    \\\"status\\\": {\\n        \\\"credit_count\\\": 0,\\n        \\\"elapsed\\\": \\\"4\\\",\\n        \\\"error_code\\\": \\\"500\\\",\\n        \\\"error_message\\\": \\\"The system is busy, please try again later!\\\",\\n        \\\"timestamp\\\": \\\"2021-06-26T09:07:58.780Z\\\"\\n    }\\n}\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://coinmarketcap.com/alexandria/glossary/dominance\",\"metadata\":{\"url\":\"https://coinmarketcap.com/alexandria/glossary/dominance\",\"title\":\"Dominance | CoinMarketCap\",\"description\":\"A measure of Bitcoin’s value in the context of the larger cryptocurrency market.\",\"author\":null,\"publisher\":\"CoinMarketCap\",\"thumbnail\":\"https://assets-global.website-files.com/5f3306add5c511a054f17da5/5f3306add5c5114bcef17ddf_icon-arrow-up.svg\",\"icon\":\"https://assets-global.website-files.com/5f3306add5c511a054f17da5/5f3306add5c51111caf17f0c_Icon-App-256x256%403x.png\"}}],[\"code\",{\"code\":\"npm init -y && tsc --init && npm i axios && npm i -D @types/node && mkdir -p src raw out && touch src/getAltcoins.ts\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"__GHOST_URL__/scraping-najbardziej-popularnych-kont-na-twitterze/\",\"metadata\":{\"url\":\"__GHOST_URL__/scraping-najbardziej-popularnych-kont-na-twitterze/\",\"title\":\"Scraping najbardziej popularnych kont na twitterze\",\"description\":\"Dzięki obserwacji wpisów z twittera możemy śledzić różne trendy. W tym wpisie pokażę jak pobrać dane o kontach w tym serwisie i wybrać te, które mają największy współczynnik wpływu.\",\"author\":\"Daniel Gustaw\",\"publisher\":\"Daniel Gustaw\",\"thumbnail\":\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-21-13-57-17-1.png\",\"icon\":\"__GHOST_URL__/favicon.ico\"}}],[\"code\",{\"code\":\"import * as fs from \\\"fs\\\";\\n\\ninterface CmcCoin {\\n    // todo implement\\n}\\n\\nclass Page {\\n    i: number;\\n\\n    constructor(i: number) {\\n        this.i = i;\\n    }\\n\\n    url() {\\n        return `https://api.coinmarketcap.com/data-api/v3/cryptocurrency/listing?start=${1 + 100 * this.i}`\\n    }\\n\\n    file() {\\n        return `${process.cwd()}/raw/${this.i}.json`\\n    }\\n\\n    sync() {\\n        // TODO implement\\n        return false;\\n    }\\n\\n    parse(): CmcCoin[] {\\n        // todo implement\\n        return []\\n    }\\n}\\n\\nconst main = async ():Promise<CmcCoin[]> => {\\n    let i = 0;\\n    const allItems:CmcCoin[] = [];\\n    while (await new Page(i).sync()) {\\n        const items = new Page(i).parse()\\n        if (items.length === 0) break;\\n        allItems.push(...items);\\n        i++;\\n    }\\n    return allItems;\\n}\\n\\nmain().then((coins) => {\\n    fs.writeFileSync(process.cwd() + '/out/coins.json', JSON.stringify(coins));\\n    console.log(coins);\\n}).catch(console.error)\"}],[\"code\",{\"code\":\"{\\n  \\\"id\\\": 1,\\n  \\\"name\\\": \\\"Bitcoin\\\",\\n  \\\"symbol\\\": \\\"BTC\\\",\\n  \\\"slug\\\": \\\"bitcoin\\\",\\n  \\\"tags\\\": [\\n    \\\"mineable\\\",\\n    \\\"pow\\\",\\n    \\\"sha-256\\\",\\n    \\\"store-of-value\\\",\\n    \\\"state-channels\\\",\\n    \\\"coinbase-ventures-portfolio\\\",\\n    \\\"three-arrows-capital-portfolio\\\",\\n    \\\"polychain-capital-portfolio\\\",\\n    \\\"binance-labs-portfolio\\\",\\n    \\\"arrington-xrp-capital\\\",\\n    \\\"blockchain-capital-portfolio\\\",\\n    \\\"boostvc-portfolio\\\",\\n    \\\"cms-holdings-portfolio\\\",\\n    \\\"dcg-portfolio\\\",\\n    \\\"dragonfly-capital-portfolio\\\",\\n    \\\"electric-capital-portfolio\\\",\\n    \\\"fabric-ventures-portfolio\\\",\\n    \\\"framework-ventures\\\",\\n    \\\"galaxy-digital-portfolio\\\",\\n    \\\"huobi-capital\\\",\\n    \\\"alameda-research-portfolio\\\",\\n    \\\"a16z-portfolio\\\",\\n    \\\"1confirmation-portfolio\\\",\\n    \\\"winklevoss-capital\\\",\\n    \\\"usv-portfolio\\\",\\n    \\\"placeholder-ventures-portfolio\\\",\\n    \\\"pantera-capital-portfolio\\\",\\n    \\\"multicoin-capital-portfolio\\\",\\n    \\\"paradigm-xzy-screener\\\"\\n  ],\\n  \\\"cmcRank\\\": 1,\\n  \\\"marketPairCount\\\": 9193,\\n  \\\"circulatingSupply\\\": 18742968,\\n  \\\"totalSupply\\\": 18742968,\\n  \\\"maxSupply\\\": 21000000,\\n  \\\"isActive\\\": 1,\\n  \\\"lastUpdated\\\": \\\"2021-06-26T09:20:02.000Z\\\",\\n  \\\"dateAdded\\\": \\\"2013-04-28T00:00:00.000Z\\\",\\n  \\\"quotes\\\": [\\n    {\\n      \\\"name\\\": \\\"USD\\\",\\n      \\\"price\\\": 30407.151465830357,\\n      \\\"volume24h\\\": 41711690274.967766,\\n      \\\"marketCap\\\": 569920266895.2114,\\n      \\\"percentChange1h\\\": 0.67834797,\\n      \\\"percentChange24h\\\": -11.72063275,\\n      \\\"percentChange7d\\\": -15.05133094,\\n      \\\"lastUpdated\\\": \\\"2021-06-26T09:20:02.000Z\\\",\\n      \\\"percentChange30d\\\": -22.4475165,\\n      \\\"percentChange60d\\\": -44.25026974,\\n      \\\"percentChange90d\\\": -46.26175604,\\n      \\\"fullyDilluttedMarketCap\\\": 638550180782.44,\\n      \\\"dominance\\\": 48.2033,\\n      \\\"turnover\\\": 0.07318864,\\n      \\\"ytdPriceChangePercentage\\\": 3.5167\\n    }\\n  ],\\n  \\\"isAudited\\\": false\\n}\"}],[\"code\",{\"code\":\"interface CmcCoin {\\n    \\\"id\\\": number,\\n    \\\"name\\\": string,\\n    \\\"symbol\\\": string,\\n    \\\"slug\\\": string,\\n    \\\"tags\\\": string[],\\n    \\\"cmcRank\\\": number,\\n    \\\"marketPairCount\\\": number,\\n    \\\"circulatingSupply\\\": number,\\n    \\\"totalSupply\\\": number,\\n    \\\"maxSupply\\\": number,\\n    \\\"isActive\\\": number,\\n    \\\"lastUpdated\\\": string,\\n    \\\"dateAdded\\\": string,\\n    \\\"quotes\\\": {\\n        \\\"name\\\": string,\\n        \\\"price\\\": number,\\n        \\\"volume24h\\\": number,\\n        \\\"marketCap\\\": number,\\n        \\\"percentChange1h\\\": number,\\n        \\\"percentChange24h\\\": number,\\n        \\\"percentChange7d\\\": number,\\n        \\\"lastUpdated\\\": string,\\n        \\\"percentChange30d\\\": number,\\n        \\\"percentChange60d\\\": number,\\n        \\\"percentChange90d\\\": number,\\n        \\\"fullyDilluttedMarketCap\\\": number,\\n        \\\"dominance\\\": number,\\n        \\\"turnover\\\": number,\\n        \\\"ytdPriceChangePercentage\\\": number\\n    }[],\\n    \\\"isAudited\\\": boolean\\n}\"}],[\"code\",{\"code\":\"npm i debug && npm i -D @types/debug\"}],[\"code\",{\"code\":\"import axios from \\\"axios\\\";\\nimport * as fs from \\\"fs\\\";\\nimport Debug from 'debug';\\n\\nconst debug = Debug('app');\"}],[\"code\",{\"code\":\"    async sync() {\\n        try {\\n            const fileExists = fs.existsSync(this.file())\\n\\n            if (fileExists) return true;\\n\\n            const {data, status} = await axios.get(this.url());\\n\\n            if (status !== 200) return false;\\n\\n            fs.writeFileSync(this.file(), JSON.stringify(data));\\n            debug(`Saved ${this.file()}`)\\n\\n            return true;\\n        } catch (e) {\\n            console.error(e)\\n            return false;\\n        }\\n    }\"}],[\"code\",{\"code\":\"typeof data === 'string' ? data : JSON.stringify(data)\"}],[\"code\",{\"code\":\"    parse(): CmcCoin[] {\\n        try {\\n            const content = JSON.parse(fs.readFileSync(this.file()).toString());\\n            return content.data.cryptoCurrencyList\\n        } catch (e) {\\n            return []\\n        }\\n    }\"}],[\"code\",{\"code\":\"DEBUG=app ts-node src/getAltcoins.ts\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.english-corpora.org/\",\"metadata\":{\"url\":\"https://www.english-corpora.org/\",\"title\":\"English Corpora: most widely used online corpora. Billions of words of data: free online access\",\"description\":\"Compare genres, dialects, time periods. Search by PoS, collocates, synonyms, and much more.\",\"author\":null,\"publisher\":null,\"thumbnail\":\"https://www.english-corpora.org/images/words.jpg\",\"icon\":\"https://www.english-corpora.org/favicon.ico\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-27-20-30-56.png\",\"width\":384,\"height\":96}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.kaggle.com/rtatman/english-word-frequency\",\"metadata\":{\"url\":\"https://kaggle.com/rtatman/english-word-frequency\",\"title\":\"English Word Frequency\",\"description\":\"### Context: How frequently a word occurs in a language is an important piece of information for natural language processing and linguists. In natural language processing, very frequent words tend to be less informative than less frequent one and are often removed during preprocessing. Human langu…\",\"author\":null,\"publisher\":\"Kaggle\",\"thumbnail\":\"https://storage.googleapis.com/kaggle-datasets-images/2367/3976/89827c5d6650a01f5bed5d768983f781/dataset-card.jpg\",\"icon\":\"https://www.kaggle.com/static/images/favicon.ico\"}}],[\"code\",{\"code\":\"grep -E '^credit,' dict/unigram_freq.csv\"}],[\"code\",{\"code\":\"credit,175916536\"}],[\"code\",{\"code\":\"grep -E '^theta,' dict/unigram_freq.csv\"}],[\"code\",{\"code\":\"theta,5070673\"}],[\"code\",{\"code\":\"import child_process from 'child_process';\\n\\nconst grepWithFork = (filename: string, word: string): Buffer => {\\n    const cmd = `egrep '^${word},' ${filename}`;\\n    return child_process.execSync(cmd, {maxBuffer: 200000000})\\n}\\n\\nexport const checkFrequency = async (word: string): Promise<number> => {\\n    return parseInt(grepWithFork(\\n        process.cwd() + '/dict/unigram_freq.csv',\\n        word\\n    ).toString().replace(`${word},`, '')) || 0;\\n}\\n\\ncheckFrequency('credit').then(console.log).catch(console.error)\\ncheckFrequency('theta').then(console.log).catch(console.error)\"}],[\"code\",{\"code\":\"175916536\\n5070673\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://stackoverflow.com/questions/28400727/from-node-js-which-is-faster-shell-grep-or-fs-readfile\",\"metadata\":{\"url\":\"https://stackoverflow.com/questions/28400727/from-node-js-which-is-faster-shell-grep-or-fs-readfile\",\"title\":\"From node.js, which is faster, shell grep or fs.readFile?\",\"description\":\"I have a long running node.js process and I need to scan a log file for a pattern. I have at least two obvious choices: spawn a grep process or read the file using fs.read* and parse the buffer/str...\",\"author\":\"Matt Simerson\",\"publisher\":\"Stack Overflow\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v=73d79a89bded\",\"icon\":\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a\"}}],[\"code\",{\"code\":\"import {CmcCoin} from \\\"./CmcCoin\\\";\\n\\nexport interface CoinWithFrequency extends CmcCoin {\\n    frequency: {\\n        name: number,\\n        symbol: number,\\n        slug: number\\n    }\\n}\"}],[\"code\",{\"code\":\"import {grepWithFork} from \\\"./grepWithFork\\\";\\n\\nexport const checkFrequency = (word: string): number => {\\n    try {\\n        return parseInt(grepWithFork(\\n            process.cwd() + '/dict/unigram_freq.csv',\\n            word\\n        ).toString().replace(`${word},`, '')) || 0;\\n    } catch (e) {\\n        return 0\\n    }\\n}\"}],[\"code\",{\"code\":\"import {CmcCoin} from \\\"../interface/CmcCoin\\\";\\nimport {Page} from \\\"./Page\\\";\\n\\nexport const getCoins = async ():Promise<CmcCoin[]> => {\\n    let i = 0;\\n    const allItems:CmcCoin[] = [];\\n    while (await new Page(i).sync()) {\\n        const items = new Page(i).parse()\\n        if (items.length === 0) break;\\n        allItems.push(...items);\\n        i++;\\n    }\\n    return allItems;\\n}\"}],[\"code\",{\"code\":\"import {CmcCoin} from \\\"../interface/CmcCoin\\\";\\nimport {CoinWithFrequency} from \\\"../interface/CoinWithFrequency\\\";\\nimport {checkFrequency} from \\\"./checkFrequency\\\";\\n\\nexport const enhanceSingleCoin = (coin: CmcCoin): CoinWithFrequency => {\\n    return {\\n        ...coin,\\n        frequency: {\\n            name: checkFrequency(coin.name.toLowerCase()),\\n            slug: checkFrequency(coin.slug.toLowerCase()),\\n            symbol: checkFrequency(coin.symbol.toLowerCase())\\n        }\\n    }\\n}\"}],[\"code\",{\"code\":\"import {CoinWithFrequency} from \\\"../interface/CoinWithFrequency\\\";\\nimport {getCoins} from \\\"./getCoins\\\";\\nimport {enhanceSingleCoin} from \\\"./enhanceSingleCoin\\\";\\n\\nexport const enhanceCoins = async (): Promise<CoinWithFrequency[]> => {\\n    const coins = await getCoins();\\n    const res: CoinWithFrequency[] = []\\n    let i = 0, s = new Date().getTime(), n = () => new Date().getTime() - s;\\n    for (const coin of coins) {\\n        res.push(enhanceSingleCoin(coin));\\n        console.log(`${i++}\\\\t${i/coins.length}\\\\t${n()}`);\\n    }\\n    return res;\\n}\"}],[\"code\",{\"code\":\"import fs from \\\"fs\\\";\\nimport {enhanceCoins} from \\\"./helpers/enhanceCoins\\\";\\n\\nenhanceCoins().then((coins) => {\\n    fs.writeFileSync(process.cwd() + '/out/coins-with-freq.json', JSON.stringify(coins));\\n    console.log(coins)\\n}).catch(console.error)\"}],[\"code\",{\"code\":\"DEBUG=app ts-node src/enhanceCoinsByFrequenceis.ts\"}],[\"code\",{\"code\":\"import {CoinWithFrequency} from \\\"./CoinWithFrequency\\\";\\n\\nexport enum PhraseType {\\n    slug = 'slug',\\n    name = 'name',\\n    symbol = 'symbol',\\n}\\n\\nexport interface Phrase {\\n    coinId: number,\\n    value: string,\\n    capToFrequency: number,\\n    type: PhraseType\\n    coin?: CoinWithFrequency\\n}\"}],[\"code\",{\"code\":\"import {CoinWithFrequency} from \\\"../interface/CoinWithFrequency\\\";\\nimport {Phrase, PhraseType} from \\\"../interface/Phrase\\\";\\nimport {SortOptions} from \\\"../interface/SortOptions\\\";\\n\\nexport const convertCoinsToPhrases = (\\n    coins: CoinWithFrequency[],\\n    options: SortOptions = {withCoin: true}\\n): Phrase[] => {\\n    const phrases: Phrase[] = [];\\n    for (const coin of coins) {\\n        const newPhrases = [PhraseType.name, PhraseType.slug, PhraseType.symbol]\\n            .map((type: PhraseType): Phrase => {\\n                return {\\n                    coinId: coin.id,\\n                    value: coin[type as keyof CoinWithFrequency] as string,\\n                    capToFrequency: coin.quotes[0].marketCap / coin.frequency[type],\\n                    type,\\n                    ... options.withCoin ? {coin} : {}\\n                }\\n            })\\n        phrases.push(...newPhrases)\\n    }\\n    return phrases\\n}\"}],[\"code\",{\"code\":\"export interface SortOptions {\\n    withCoin: boolean\\n}\"}],[\"code\",{\"code\":\"import {SortOptions} from \\\"../interface/SortOptions\\\";\\nimport fs from \\\"fs\\\";\\nimport {convertCoinsToPhrases} from \\\"./convertCoinsToPhrases\\\";\\n\\nexport const sortCurrencies = async (options: SortOptions) => {\\n    const coins = JSON.parse(fs.readFileSync(process.cwd() + '/out/coins-with-freq.json').toString());\\n    const phrases = convertCoinsToPhrases(coins, options)\\n    phrases.sort((a, b) => a.capToFrequency - b.capToFrequency)\\n    return phrases;\\n}\"}],[\"code\",{\"code\":\"import fs from 'fs';\\nimport {sortCurrencies} from \\\"./helpers/sortCurrencies\\\";\\n\\nsortCurrencies({withCoin: false}).then((coins) => {\\n    fs.writeFileSync(process.cwd() + '/out/phrases.json', JSON.stringify(coins));\\n    console.log(coins);\\n}).catch(console.error)\"}],[\"code\",{\"code\":\"ts-node src/preparePhrases.ts\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-28-09-09-53.png\",\"width\":1071,\"height\":1232}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-28-09-07-09.png\",\"width\":1115,\"height\":882}]],\"markups\":[[\"code\"],[\"a\",[\"href\",\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/coins.json\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Celem artykułu jest pokazanie jak odfiltrować spośród wszystkich nazw altcoinów, te nie występujące w języku naturalnym. Zastosowanie tej techniki pozwoliło nam na skuteczny monitoring wzmianek na temat tysięcy kryptowalut na Twitterze w projekcie \"],[0,[0],1,\"MaxData\"],[0,[],0,\" .\"]]],[1,\"p\",[[0,[],0,\"Plan działania:\"]]],[3,\"ol\",[[[0,[],0,\"Musimy mieć nazwy kryptowalut. Pokażę jak je pobrać i uporządkować.\"]],[[0,[],0,\"Musimy mieć korpus języka. Pokażę jak się do niego dostać.\"]],[[0,[],0,\"Musimy połączyć oba zbiory danych i wyznaczyć kryterium odcięcia kryptowaluty z monitoringu.\"]]]],[1,\"p\",[[0,[],0,\"Jeśli bardzo zależało by nam na obserwacji frazy występującej w języku naturalnym wymagało by to analizy kontekstu. Jest to oczywiście możliwe, ale w naszym przypadku prościej jest nam odciąć kilka altcoinów o nazwach występujących w korpusie niż analizować kontekst. Głównie dlatego, że te odcięte altcoiny stanowią niewielki ułamek całości rynku, a ich uwzględnienie podniosło by poziom skomplikowania wielokrotnie.\"]]],[1,\"h2\",[[0,[],0,\"Nazwy altcoinów\"]]],[1,\"p\",[[0,[],0,\"Nazwy kryptowalut pobraliśmy z \"],[0,[0],1,\"Coin Market Cap\"],[0,[],0,\" za pomocą końcówki\"]]],[10,0],[1,\"p\",[[0,[],0,\"z parametrem \"],[0,[0],1,\"start\"],[0,[],0,\" iterowanym po \"],[0,[0],1,\"1+100*n\"],[0,[],0,\" dla \"],[0,[0],1,\"n\"],[0,[],0,\" od \"],[0,[0],1,\"0\"],[0,[],0,\" do momentu gdzie odpowiedź nie będzie zawierała klucza \"],[0,[0],1,\"data\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\" Przykładowa dobra odpowiedź to:\"]]],[10,1],[1,\"p\",[[0,[],0,\"A kiedy wyjdziemy poza zakres dostaniemy:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Najbardziej interesują nas parametry:\"]]],[3,\"ul\",[[[0,[],0,\"name\"]],[[0,[],0,\"symbol\"]],[[0,[],0,\"quotes[0].marketCap albo jego znormalizowana wersja quotes[0].dominance\"]]]],[10,3],[1,\"p\",[[0,[],0,\"Pobierzemy wszystkie dane o kryptowalutach i zapiszemy je w pliku. Przygotowujemy projekt:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Rdzeń programu \"],[0,[0],1,\"getAltcoins.ts\"],[0,[],0,\" możemy przenieść z naszego niedawnego wpisu:\"]]],[10,5],[1,\"p\",[[0,[],0,\"Czyli mniej więcej tak:\"]]],[10,6],[1,\"h3\",[[0,[],0,\"Implementacja interfejsu CmcCoin\"]]],[1,\"p\",[[0,[],0,\"Najprostszą metodą jest przyjrzenie się temu co zwraca API dla Bitcoina:\"]]],[10,7],[1,\"p\",[[0,[],0,\" i przerobienie tego na interfejs:\"]]],[10,8],[1,\"h3\",[[0,[],0,\"Synchronizacja\"]]],[1,\"p\",[[0,[],0,\"Po dodaniu paczki \"],[0,[0],1,\"debug\"],[0,[],0,\" poleceniem\"]]],[10,9],[1,\"p\",[[0,[],0,\"i kilku importów\"]]],[10,10],[1,\"p\",[[0,[],0,\"analogicznie jak w poprzednio wspomnianym artykule implementujemy \"],[0,[0],1,\"sync\"]]],[10,11],[1,\"p\",[[0,[],0,\"Jedyną różnicą jest tu \"],[0,[0],1,\"JSON.stringify\"],[0,[],0,\" ponieważ chcemy zapisać do pliku ciąg znaków a nie obiekt. Tym razem korzystamy z \"],[0,[0],1,\"api\"],[0,[],0,\" a nie pobieramy \"],[0,[0],1,\"html\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Możemy napisać to nawet uniwersalniej\"]]],[10,12],[1,\"p\",[[0,[],0,\"co pozwoli nam na używanie wielokrotnie tego raz napisanego kodu.\"]]],[1,\"h3\",[[0,[],0,\"Parsowanie\"]]],[1,\"p\",[[0,[],0,\"Metoda do parsowania jest wyjątkowo prosta:\"]]],[10,13],[1,\"p\",[[0,[],0,\"polega na próbie wydobycia listy pod określonym kluczem, a jeśli to niemożliwe zwraca pustą tablicę powodując zakończenie głównej pętli programu.\"]]],[1,\"p\",[[0,[],0,\"Finalnie po włączeniu programu:\"]]],[10,14],[1,\"p\",[[0,[],0,\"w katalogu \"],[0,[0],1,\"out/coins.json\"],[0,[],0,\" dostajemy plik, który zamieściłem pod linkiem:\"]]],[1,\"p\",[[0,[1],1,\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/coins.json\"]]],[1,\"h2\",[[0,[],0,\"Pobranie i obsługa korpusu językowego\"]]],[1,\"p\",[[0,[],0,\"Po wpisaniu frazy \\\"english corpus\\\" bardzo szybko trafiamy na stronę \"]]],[10,15],[1,\"p\",[[0,[],0,\"Jest to scam. Zawiera informację, że jest darmowa i wystarczy zarejestrować konto\"]]],[10,16],[1,\"p\",[[0,[],0,\"ale posiada ograniczenia przez które możemy skanować dziennie jedynie 50 słów. Straciłem czas próbując automatyzować pobieranie danych z tego serwisu.\"]]],[1,\"p\",[[0,[],0,\"Pobranie z niego próbek prowadzi do tego, że mamy poszatkowane dane nie zdatne do żadnego zastosowania i dopiero wejście w cennik wyjaśnia, że można u nich kupić korpus za kilkaset dolarów.\"]]],[1,\"p\",[[0,[],0,\"Na szczęście udało mi się pobrać wymagane dane ze strony o znacznie gorszym pozycjonowaniu, ale za to dużo bardziej wartościowej:\"]]],[10,17],[1,\"p\",[[0,[],0,\"Tam też rejestracja jest wymagana, ale w zamian dostajemy dostęp do ciekawych danych, interesujących treści i fantastycznego kursu. Nawet jak tego nie potrzebujemy to po prostu dane mamy za darmo. Jest to 5MB plik csv z kolumnami zawierającymi słowo oraz ilość zliczeń.\"]]],[1,\"p\",[[0,[],0,\"Umieściłem ten plik pod ścieżką \"],[0,[0],1,\"dict/unigram_freq.csv\"],[0,[],0,\". Aby zapytać o ilość zliczeń słowa \"],[0,[0],1,\"credit\"],[0,[],0,\" wystarczy wpisać:\"]]],[10,18],[1,\"p\",[[0,[],0,\"dostajemy:\"]]],[10,19],[1,\"p\",[[0,[],0,\"Analogicznie dla frazy:\"]]],[10,20],[1,\"p\",[[0,[],0,\"mamy:\"]]],[10,21],[1,\"p\",[[0,[],0,\"Za pomocą typescriptu mogli byśmy zapisać to tak:\"]]],[10,22],[1,\"p\",[[0,[],0,\"wykonanie tego pliku zwróci nam częstości:\"]]],[10,23],[1,\"p\",[[0,[],0,\"z tego co wiem, to wykorzystanie systemowego grepa jest jedną z najbardziej wydajnych metod w tym konkretnym przypadku, ponieważ nie wymaga ładowania całego pliku do pamięci, pisania logiki wyszukiwania a jednocześnie pozwala zrzucić odpowiedzialność za optymalizację wyszukiwania na twórców \"],[0,[0],1,\"grep\"],[0,[],0,\". Sam nie robiłem takich eksperymentów, ale czytałem, że do 2-3 tysięcy linii można w node js wyszukać szybciej, bo nie tracimy czasu na włączanie osobnego procesu, ale przy większych plikach okazuje się, że optymalizacja grepa nadrabia opóźnienia związane z wykonywaniem komend przez \"],[0,[0],1,\"child_process\"],[0,[],0,\".\"]]],[10,24],[1,\"h2\",[[0,[],0,\"Połączenie częstości z nazwami coinów\"]]],[1,\"p\",[[0,[],0,\"Wykonałem drobny refactoring. W \"],[0,[0],1,\"src\"],[0,[],0,\" utworzyłem katalogi \"],[0,[0],1,\"interface\"],[0,[],0,\" oraz \"],[0,[0],1,\"helpers\"],[0,[],0,\". Do \"],[0,[0],1,\"interface\"],[0,[],0,\" przeniosłem \"],[0,[0],1,\"CmcCoin\"],[0,[],0,\", oraz utworzyłem \"],[0,[0],1,\"CoinWithFrequency.ts\"],[0,[],0,\" zawierający\"]]],[10,25],[1,\"p\",[[0,[],0,\"jest to struktura danych pozwalająca nam ująć możliwie dokładne dane dotyczące częstotliwości występowania nie tylko nazw ale też symboli i potencjalnie \"],[0,[0],1,\"slug\"],[0,[],0,\" coinów.\"]]],[1,\"p\",[[0,[],0,\"Do \"],[0,[0],1,\"helpers\"],[0,[],0,\" przeniosłem klasę \"],[0,[0],1,\"Page\"],[0,[],0,\", oraz funkcje \"],[0,[0],1,\"grepWithFork\"],[0,[],0,\" i \"],[0,[0],1,\"checkFrequency\"],[0,[],0,\" z tym, że ta druga dostała obsługę wyjątków:\"]]],[10,26],[1,\"p\",[[0,[],0,\"Ostatnią zmianą jest wyrzucenie z \"],[0,[0],1,\"getAltcoins\"],[0,[],0,\" funkcji \"],[0,[0],1,\"main\"],[0,[],0,\" i nazwanie jej \"],[0,[0],1,\"getCoins\"],[0,[],0,\". W pliku o tej samej nazwie w \"],[0,[0],1,\"helpers\"],[0,[],0,\" znalazł się teraz kod\"]]],[10,27],[1,\"p\",[[0,[],0,\"Nową funkcją jest bardzo prosta funkcja \"],[0,[0],1,\"enhanceSingleCoin\"],[0,[],0,\" umieszczona też w \"],[0,[0],1,\"helpers\"],[0,[],0,\" w pliku z tą nazwą o treści:\"]]],[10,28],[1,\"p\",[[0,[],0,\"Iterując za jej pomocą po tablicy walut przetwarzamy je kolejno\"]]],[10,29],[1,\"p\",[[0,[],0,\"Ponieważ trwa to chwilę do funkcji dodałem proste wyświetlanie postępu oraz czasu wykonywania.\"]]],[1,\"p\",[[0,[],0,\"Nasz ostatni skrypt: \"],[0,[0],1,\"enhanceCoinsByFrequenceis.ts\"],[0,[],0,\" zawiera jedynie zapisanie wyników tej funkcji do pliku:\"]]],[10,30],[1,\"p\",[[0,[],0,\"Po jego wykonaniu poleceniem\"]]],[10,31],[1,\"p\",[[0,[],0,\"dostajemy plik z walutami wzbogaconymi o częstości \"],[0,[0],1,\"/out/coins-with-freq.json\"],[0,[],0,\".\"]]],[1,\"h3\",[[0,[],0,\"Sortowanie fraz\"]]],[1,\"p\",[[0,[],0,\"Przyjrzyjmy się teraz posortowanej względem stosunku \"],[0,[0],1,\"quotes[0].marketCap\"],[0,[],0,\" do parametrów określonych pod kluczem \"],[0,[0],1,\"frequency\"],[0,[],0,\". Zaczniemy od ustalenia struktury danych wyjściowych:\"]]],[10,32],[1,\"p\",[[0,[],0,\"Parametr \"],[0,[0],1,\"coin\"],[0,[],0,\" nie jest wymagany, bo zakładam, że dla celów analizy może się przydać, ale ilość danych w tym parametrze jest na tyle duża, że może się okazać, że warto oczyścić z niego ostateczny wynik.\"]]],[1,\"p\",[[0,[],0,\"Podstawową cegiełkę ostatniej fazy stanowi zamiana coinów na frazy\"]]],[10,33],[1,\"p\",[[0,[],0,\"importowane tu opcje sortowania:\"]]],[10,34],[1,\"p\",[[0,[],0,\"sprowadzają się jedynie do określenia, czy chcemy widzieć wyniki z innymi danymi o coinie.\"]]],[1,\"p\",[[0,[],0,\"Do sortowania użyjemy funkcji:\"]]],[10,35],[1,\"p\",[[0,[],0,\"stąd już prosta droga do zapisania wyników do pliku skryptem \"],[0,[0],1,\"src/preparePhrases.ts\"]]],[10,36],[1,\"p\",[[0,[],0,\"Po jego włączeniu poleceniem:\"]]],[10,37],[1,\"p\",[[0,[],0,\"Możemy zobaczyć, że dla bardzo mało znanych coinów, ale za to popularnych słów nasz współczynnik jest bardzo niski.\"]]],[10,38],[1,\"p\",[[0,[],0,\"możemy się spodziewać wielu tweetów ze słowami takimi jak \"],[0,[0],1,\"you\"],[0,[],0,\", \"],[0,[0],1,\"giant\"],[0,[],0,\", \"],[0,[0],1,\"spectrum\"],[0,[],0,\", \"],[0,[0],1,\"pop\"],[0,[],0,\", \"],[0,[0],1,\"cyl\"],[0,[],0,\", \"],[0,[0],1,\"vote\"],[0,[],0,\", \"],[0,[0],1,\"get\"],[0,[],0,\", \"],[0,[0],1,\"real\"],[0,[],0,\" czy \"],[0,[0],1,\"kind\"],[0,[],0,\" w których autor nie miał na myśli kryptowalut. Z drugiej strony nie istnieje obiektywne kryterium odcięcia. \"]]],[10,39],[1,\"p\",[[0,[],0,\"Gdybym ustawił je na 100, wycięte zostało by 2328/16395 = 14% fraz. Przy wartości \"],[0,[0],1,\"5\"],[0,[],0,\" mamy odcięcie 1560/16395 = 9.5%. \"]]],[1,\"h2\",[[0,[],0,\"Podsumowanie\"]]],[1,\"p\",[[0,[],0,\"Obiektywne wyznaczenie kryterium odcięcia altcoinów z monitoringu okazało się niemożliwe, ale konieczność podjęcia kilku tysięcy decyzji typu \\\"włączyć/wyłączyć\\\" z obserwacji została zastąpiony jedną decyzją o granicznym stosunku wartości coina względem częstości użycia jego nazwy w języku angielskim.\"]]],[1,\"p\",[[0,[],0,\"Widzimy, że ogromna większość szumu jest wycinana jeśli zrezygnujemy z obserwacji około 10% altcoinów o nazwach lub skrótach będących popularnymi zwrotami.\"]]],[1,\"p\",[[0,[],0,\"Całość zamknęła się w około 211 liniach typescriptu, z czego 57 to interfejsy.\"]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Celem artykułu jest pokazanie jak odfiltrować spośród wszystkich nazw altcoinów, te nie występujące w języku naturalnym. Zastosowanie tej techniki pozwoliło nam na skuteczny monitoring wzmianek na temat tysięcy kryptowalut na Twitterze w projekcie <code>MaxData</code> .</p><p>Plan działania:</p><ol><li>Musimy mieć nazwy kryptowalut. Pokażę jak je pobrać i uporządkować.</li><li>Musimy mieć korpus języka. Pokażę jak się do niego dostać.</li><li>Musimy połączyć oba zbiory danych i wyznaczyć kryterium odcięcia kryptowaluty z monitoringu.</li></ol><p>Jeśli bardzo zależało by nam na obserwacji frazy występującej w języku naturalnym wymagało by to analizy kontekstu. Jest to oczywiście możliwe, ale w naszym przypadku prościej jest nam odciąć kilka altcoinów o nazwach występujących w korpusie niż analizować kontekst. Głównie dlatego, że te odcięte altcoiny stanowią niewielki ułamek całości rynku, a ich uwzględnienie podniosło by poziom skomplikowania wielokrotnie.</p><h2 id=\"nazwy-altcoin%C3%B3w\">Nazwy altcoinów</h2><p>Nazwy kryptowalut pobraliśmy z <code>Coin Market Cap</code> za pomocą końcówki</p><pre><code>https://api.coinmarketcap.com/data-api/v3/cryptocurrency/listing</code></pre><p>z parametrem <code>start</code> iterowanym po <code>1+100*n</code> dla <code>n</code> od <code>0</code> do momentu gdzie odpowiedź nie będzie zawierała klucza <code>data</code>.</p><p> Przykładowa dobra odpowiedź to:</p><pre><code>{\n    \"data\": {\n        \"cryptoCurrencyList\": [\n            {\n                \"id\": 8138,\n                \"name\": \"LinkBased\",\n                \"symbol\": \"LBD\",\n                \"slug\": \"linkbased\",\n                \"tags\": [],\n                \"cmcRank\": 4601,\n                \"marketPairCount\": 1,\n                \"circulatingSupply\": 0E-8,\n                \"totalSupply\": 813923.00000000,\n                \"isActive\": 1,\n                \"lastUpdated\": \"2021-06-26T09:08:12.000Z\",\n                \"dateAdded\": \"2020-12-30T00:00:00.000Z\",\n                \"quotes\": [\n                    {\n                        \"name\": \"USD\",\n                        \"price\": 1.59351133162663,\n                        \"volume24h\": 514.07425485,\n                        \"marketCap\": 0E-22,\n                        \"percentChange1h\": -0.13208528,\n                        \"percentChange24h\": -26.50872672,\n                        \"percentChange7d\": -34.07116202,\n                        \"lastUpdated\": \"2021-06-26T09:08:12.000Z\",\n                        \"percentChange30d\": -56.37728930,\n                        \"percentChange60d\": -57.50444478,\n                        \"percentChange90d\": -46.98725744,\n                        \"fullyDilluttedMarketCap\": 1296995.52,\n                        \"dominance\": 0.0,\n                        \"ytdPriceChangePercentage\": 41.3223\n                    }\n                ],\n                \"isAudited\": false\n            },\n            ...\n        ],\n        \"totalCount\": \"5465\"\n    },\n    \"status\": {\n        \"timestamp\": \"2021-06-26T09:10:02.180Z\",\n        \"error_code\": \"0\",\n        \"error_message\": \"SUCCESS\",\n        \"elapsed\": \"134\",\n        \"credit_count\": 0\n    }\n}</code></pre><p>A kiedy wyjdziemy poza zakres dostaniemy:</p><pre><code>{\n    \"status\": {\n        \"credit_count\": 0,\n        \"elapsed\": \"4\",\n        \"error_code\": \"500\",\n        \"error_message\": \"The system is busy, please try again later!\",\n        \"timestamp\": \"2021-06-26T09:07:58.780Z\"\n    }\n}</code></pre><p>Najbardziej interesują nas parametry:</p><ul><li>name</li><li>symbol</li><li>quotes[0].marketCap albo jego znormalizowana wersja quotes[0].dominance</li></ul><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://coinmarketcap.com/alexandria/glossary/dominance\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Dominance | CoinMarketCap</div><div class=\"kg-bookmark-description\">A measure of Bitcoin’s value in the context of the larger cryptocurrency market.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://assets-global.website-files.com/5f3306add5c511a054f17da5/5f3306add5c51111caf17f0c_Icon-App-256x256%403x.png\"><span class=\"kg-bookmark-author\">CoinMarketCap</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://assets-global.website-files.com/5f3306add5c511a054f17da5/5f3306add5c5114bcef17ddf_icon-arrow-up.svg\"></div></a></figure><p>Pobierzemy wszystkie dane o kryptowalutach i zapiszemy je w pliku. Przygotowujemy projekt:</p><pre><code>npm init -y &amp;&amp; tsc --init &amp;&amp; npm i axios &amp;&amp; npm i -D @types/node &amp;&amp; mkdir -p src raw out &amp;&amp; touch src/getAltcoins.ts</code></pre><p>Rdzeń programu <code>getAltcoins.ts</code> możemy przenieść z naszego niedawnego wpisu:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"__GHOST_URL__/scraping-najbardziej-popularnych-kont-na-twitterze/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Scraping najbardziej popularnych kont na twitterze</div><div class=\"kg-bookmark-description\">Dzięki obserwacji wpisów z twittera możemy śledzić różne trendy. W tym wpisie pokażę jak pobrać dane o kontach w tym serwisie i wybrać te, które mają największy współczynnik wpływu.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"__GHOST_URL__/favicon.ico\"><span class=\"kg-bookmark-author\">Daniel Gustaw</span><span class=\"kg-bookmark-publisher\">Daniel Gustaw</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-21-13-57-17-1.png\"></div></a></figure><p>Czyli mniej więcej tak:</p><pre><code>import * as fs from \"fs\";\n\ninterface CmcCoin {\n    // todo implement\n}\n\nclass Page {\n    i: number;\n\n    constructor(i: number) {\n        this.i = i;\n    }\n\n    url() {\n        return `https://api.coinmarketcap.com/data-api/v3/cryptocurrency/listing?start=${1 + 100 * this.i}`\n    }\n\n    file() {\n        return `${process.cwd()}/raw/${this.i}.json`\n    }\n\n    sync() {\n        // TODO implement\n        return false;\n    }\n\n    parse(): CmcCoin[] {\n        // todo implement\n        return []\n    }\n}\n\nconst main = async ():Promise&lt;CmcCoin[]&gt; =&gt; {\n    let i = 0;\n    const allItems:CmcCoin[] = [];\n    while (await new Page(i).sync()) {\n        const items = new Page(i).parse()\n        if (items.length === 0) break;\n        allItems.push(...items);\n        i++;\n    }\n    return allItems;\n}\n\nmain().then((coins) =&gt; {\n    fs.writeFileSync(process.cwd() + '/out/coins.json', JSON.stringify(coins));\n    console.log(coins);\n}).catch(console.error)</code></pre><h3 id=\"implementacja-interfejsu-cmccoin\">Implementacja interfejsu CmcCoin</h3><p>Najprostszą metodą jest przyjrzenie się temu co zwraca API dla Bitcoina:</p><pre><code>{\n  \"id\": 1,\n  \"name\": \"Bitcoin\",\n  \"symbol\": \"BTC\",\n  \"slug\": \"bitcoin\",\n  \"tags\": [\n    \"mineable\",\n    \"pow\",\n    \"sha-256\",\n    \"store-of-value\",\n    \"state-channels\",\n    \"coinbase-ventures-portfolio\",\n    \"three-arrows-capital-portfolio\",\n    \"polychain-capital-portfolio\",\n    \"binance-labs-portfolio\",\n    \"arrington-xrp-capital\",\n    \"blockchain-capital-portfolio\",\n    \"boostvc-portfolio\",\n    \"cms-holdings-portfolio\",\n    \"dcg-portfolio\",\n    \"dragonfly-capital-portfolio\",\n    \"electric-capital-portfolio\",\n    \"fabric-ventures-portfolio\",\n    \"framework-ventures\",\n    \"galaxy-digital-portfolio\",\n    \"huobi-capital\",\n    \"alameda-research-portfolio\",\n    \"a16z-portfolio\",\n    \"1confirmation-portfolio\",\n    \"winklevoss-capital\",\n    \"usv-portfolio\",\n    \"placeholder-ventures-portfolio\",\n    \"pantera-capital-portfolio\",\n    \"multicoin-capital-portfolio\",\n    \"paradigm-xzy-screener\"\n  ],\n  \"cmcRank\": 1,\n  \"marketPairCount\": 9193,\n  \"circulatingSupply\": 18742968,\n  \"totalSupply\": 18742968,\n  \"maxSupply\": 21000000,\n  \"isActive\": 1,\n  \"lastUpdated\": \"2021-06-26T09:20:02.000Z\",\n  \"dateAdded\": \"2013-04-28T00:00:00.000Z\",\n  \"quotes\": [\n    {\n      \"name\": \"USD\",\n      \"price\": 30407.151465830357,\n      \"volume24h\": 41711690274.967766,\n      \"marketCap\": 569920266895.2114,\n      \"percentChange1h\": 0.67834797,\n      \"percentChange24h\": -11.72063275,\n      \"percentChange7d\": -15.05133094,\n      \"lastUpdated\": \"2021-06-26T09:20:02.000Z\",\n      \"percentChange30d\": -22.4475165,\n      \"percentChange60d\": -44.25026974,\n      \"percentChange90d\": -46.26175604,\n      \"fullyDilluttedMarketCap\": 638550180782.44,\n      \"dominance\": 48.2033,\n      \"turnover\": 0.07318864,\n      \"ytdPriceChangePercentage\": 3.5167\n    }\n  ],\n  \"isAudited\": false\n}</code></pre><p> i przerobienie tego na interfejs:</p><pre><code>interface CmcCoin {\n    \"id\": number,\n    \"name\": string,\n    \"symbol\": string,\n    \"slug\": string,\n    \"tags\": string[],\n    \"cmcRank\": number,\n    \"marketPairCount\": number,\n    \"circulatingSupply\": number,\n    \"totalSupply\": number,\n    \"maxSupply\": number,\n    \"isActive\": number,\n    \"lastUpdated\": string,\n    \"dateAdded\": string,\n    \"quotes\": {\n        \"name\": string,\n        \"price\": number,\n        \"volume24h\": number,\n        \"marketCap\": number,\n        \"percentChange1h\": number,\n        \"percentChange24h\": number,\n        \"percentChange7d\": number,\n        \"lastUpdated\": string,\n        \"percentChange30d\": number,\n        \"percentChange60d\": number,\n        \"percentChange90d\": number,\n        \"fullyDilluttedMarketCap\": number,\n        \"dominance\": number,\n        \"turnover\": number,\n        \"ytdPriceChangePercentage\": number\n    }[],\n    \"isAudited\": boolean\n}</code></pre><h3 id=\"synchronizacja\">Synchronizacja</h3><p>Po dodaniu paczki <code>debug</code> poleceniem</p><pre><code>npm i debug &amp;&amp; npm i -D @types/debug</code></pre><p>i kilku importów</p><pre><code>import axios from \"axios\";\nimport * as fs from \"fs\";\nimport Debug from 'debug';\n\nconst debug = Debug('app');</code></pre><p>analogicznie jak w poprzednio wspomnianym artykule implementujemy <code>sync</code></p><pre><code>    async sync() {\n        try {\n            const fileExists = fs.existsSync(this.file())\n\n            if (fileExists) return true;\n\n            const {data, status} = await axios.get(this.url());\n\n            if (status !== 200) return false;\n\n            fs.writeFileSync(this.file(), JSON.stringify(data));\n            debug(`Saved ${this.file()}`)\n\n            return true;\n        } catch (e) {\n            console.error(e)\n            return false;\n        }\n    }</code></pre><p>Jedyną różnicą jest tu <code>JSON.stringify</code> ponieważ chcemy zapisać do pliku ciąg znaków a nie obiekt. Tym razem korzystamy z <code>api</code> a nie pobieramy <code>html</code>.</p><p>Możemy napisać to nawet uniwersalniej</p><pre><code>typeof data === 'string' ? data : JSON.stringify(data)</code></pre><p>co pozwoli nam na używanie wielokrotnie tego raz napisanego kodu.</p><h3 id=\"parsowanie\">Parsowanie</h3><p>Metoda do parsowania jest wyjątkowo prosta:</p><pre><code>    parse(): CmcCoin[] {\n        try {\n            const content = JSON.parse(fs.readFileSync(this.file()).toString());\n            return content.data.cryptoCurrencyList\n        } catch (e) {\n            return []\n        }\n    }</code></pre><p>polega na próbie wydobycia listy pod określonym kluczem, a jeśli to niemożliwe zwraca pustą tablicę powodując zakończenie głównej pętli programu.</p><p>Finalnie po włączeniu programu:</p><pre><code>DEBUG=app ts-node src/getAltcoins.ts</code></pre><p>w katalogu <code>out/coins.json</code> dostajemy plik, który zamieściłem pod linkiem:</p><p><a href=\"https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/coins.json\">https://preciselab.fra1.digitaloceanspaces.com/blog/scraping/coins.json</a></p><h2 id=\"pobranie-i-obs%C5%82uga-korpusu-j%C4%99zykowego\">Pobranie i obsługa korpusu językowego</h2><p>Po wpisaniu frazy \"english corpus\" bardzo szybko trafiamy na stronę </p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.english-corpora.org/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">English Corpora: most widely used online corpora. Billions of words of data: free online access</div><div class=\"kg-bookmark-description\">Compare genres, dialects, time periods. Search by PoS, collocates, synonyms, and much more.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.english-corpora.org/favicon.ico\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.english-corpora.org/images/words.jpg\"></div></a></figure><p>Jest to scam. Zawiera informację, że jest darmowa i wystarczy zarejestrować konto</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-27-20-30-56.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"384\" height=\"96\"></figure><p>ale posiada ograniczenia przez które możemy skanować dziennie jedynie 50 słów. Straciłem czas próbując automatyzować pobieranie danych z tego serwisu.</p><p>Pobranie z niego próbek prowadzi do tego, że mamy poszatkowane dane nie zdatne do żadnego zastosowania i dopiero wejście w cennik wyjaśnia, że można u nich kupić korpus za kilkaset dolarów.</p><p>Na szczęście udało mi się pobrać wymagane dane ze strony o znacznie gorszym pozycjonowaniu, ale za to dużo bardziej wartościowej:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.kaggle.com/rtatman/english-word-frequency\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">English Word Frequency</div><div class=\"kg-bookmark-description\">### Context: How frequently a word occurs in a language is an important piece of information for natural language processing and linguists. In natural language processing, very frequent words tend to be less informative than less frequent one and are often removed during preprocessing. Human langu…</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.kaggle.com/static/images/favicon.ico\"><span class=\"kg-bookmark-author\">Kaggle</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://storage.googleapis.com/kaggle-datasets-images/2367/3976/89827c5d6650a01f5bed5d768983f781/dataset-card.jpg\"></div></a></figure><p>Tam też rejestracja jest wymagana, ale w zamian dostajemy dostęp do ciekawych danych, interesujących treści i fantastycznego kursu. Nawet jak tego nie potrzebujemy to po prostu dane mamy za darmo. Jest to 5MB plik csv z kolumnami zawierającymi słowo oraz ilość zliczeń.</p><p>Umieściłem ten plik pod ścieżką <code>dict/unigram_freq.csv</code>. Aby zapytać o ilość zliczeń słowa <code>credit</code> wystarczy wpisać:</p><pre><code>grep -E '^credit,' dict/unigram_freq.csv</code></pre><p>dostajemy:</p><pre><code>credit,175916536</code></pre><p>Analogicznie dla frazy:</p><pre><code>grep -E '^theta,' dict/unigram_freq.csv</code></pre><p>mamy:</p><pre><code>theta,5070673</code></pre><p>Za pomocą typescriptu mogli byśmy zapisać to tak:</p><pre><code>import child_process from 'child_process';\n\nconst grepWithFork = (filename: string, word: string): Buffer =&gt; {\n    const cmd = `egrep '^${word},' ${filename}`;\n    return child_process.execSync(cmd, {maxBuffer: 200000000})\n}\n\nexport const checkFrequency = async (word: string): Promise&lt;number&gt; =&gt; {\n    return parseInt(grepWithFork(\n        process.cwd() + '/dict/unigram_freq.csv',\n        word\n    ).toString().replace(`${word},`, '')) || 0;\n}\n\ncheckFrequency('credit').then(console.log).catch(console.error)\ncheckFrequency('theta').then(console.log).catch(console.error)</code></pre><p>wykonanie tego pliku zwróci nam częstości:</p><pre><code>175916536\n5070673</code></pre><p>z tego co wiem, to wykorzystanie systemowego grepa jest jedną z najbardziej wydajnych metod w tym konkretnym przypadku, ponieważ nie wymaga ładowania całego pliku do pamięci, pisania logiki wyszukiwania a jednocześnie pozwala zrzucić odpowiedzialność za optymalizację wyszukiwania na twórców <code>grep</code>. Sam nie robiłem takich eksperymentów, ale czytałem, że do 2-3 tysięcy linii można w node js wyszukać szybciej, bo nie tracimy czasu na włączanie osobnego procesu, ale przy większych plikach okazuje się, że optymalizacja grepa nadrabia opóźnienia związane z wykonywaniem komend przez <code>child_process</code>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://stackoverflow.com/questions/28400727/from-node-js-which-is-faster-shell-grep-or-fs-readfile\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">From node.js, which is faster, shell grep or fs.readFile?</div><div class=\"kg-bookmark-description\">I have a long running node.js process and I need to scan a log file for a pattern. I have at least two obvious choices: spawn a grep process or read the file using fs.read* and parse the buffer/str...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v&#x3D;c78bd457575a\"><span class=\"kg-bookmark-author\">Stack Overflow</span><span class=\"kg-bookmark-publisher\">Matt Simerson</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon@2.png?v&#x3D;73d79a89bded\"></div></a></figure><h2 id=\"po%C5%82%C4%85czenie-cz%C4%99sto%C5%9Bci-z-nazwami-coin%C3%B3w\">Połączenie częstości z nazwami coinów</h2><p>Wykonałem drobny refactoring. W <code>src</code> utworzyłem katalogi <code>interface</code> oraz <code>helpers</code>. Do <code>interface</code> przeniosłem <code>CmcCoin</code>, oraz utworzyłem <code>CoinWithFrequency.ts</code> zawierający</p><pre><code>import {CmcCoin} from \"./CmcCoin\";\n\nexport interface CoinWithFrequency extends CmcCoin {\n    frequency: {\n        name: number,\n        symbol: number,\n        slug: number\n    }\n}</code></pre><p>jest to struktura danych pozwalająca nam ująć możliwie dokładne dane dotyczące częstotliwości występowania nie tylko nazw ale też symboli i potencjalnie <code>slug</code> coinów.</p><p>Do <code>helpers</code> przeniosłem klasę <code>Page</code>, oraz funkcje <code>grepWithFork</code> i <code>checkFrequency</code> z tym, że ta druga dostała obsługę wyjątków:</p><pre><code>import {grepWithFork} from \"./grepWithFork\";\n\nexport const checkFrequency = (word: string): number =&gt; {\n    try {\n        return parseInt(grepWithFork(\n            process.cwd() + '/dict/unigram_freq.csv',\n            word\n        ).toString().replace(`${word},`, '')) || 0;\n    } catch (e) {\n        return 0\n    }\n}</code></pre><p>Ostatnią zmianą jest wyrzucenie z <code>getAltcoins</code> funkcji <code>main</code> i nazwanie jej <code>getCoins</code>. W pliku o tej samej nazwie w <code>helpers</code> znalazł się teraz kod</p><pre><code>import {CmcCoin} from \"../interface/CmcCoin\";\nimport {Page} from \"./Page\";\n\nexport const getCoins = async ():Promise&lt;CmcCoin[]&gt; =&gt; {\n    let i = 0;\n    const allItems:CmcCoin[] = [];\n    while (await new Page(i).sync()) {\n        const items = new Page(i).parse()\n        if (items.length === 0) break;\n        allItems.push(...items);\n        i++;\n    }\n    return allItems;\n}</code></pre><p>Nową funkcją jest bardzo prosta funkcja <code>enhanceSingleCoin</code> umieszczona też w <code>helpers</code> w pliku z tą nazwą o treści:</p><pre><code>import {CmcCoin} from \"../interface/CmcCoin\";\nimport {CoinWithFrequency} from \"../interface/CoinWithFrequency\";\nimport {checkFrequency} from \"./checkFrequency\";\n\nexport const enhanceSingleCoin = (coin: CmcCoin): CoinWithFrequency =&gt; {\n    return {\n        ...coin,\n        frequency: {\n            name: checkFrequency(coin.name.toLowerCase()),\n            slug: checkFrequency(coin.slug.toLowerCase()),\n            symbol: checkFrequency(coin.symbol.toLowerCase())\n        }\n    }\n}</code></pre><p>Iterując za jej pomocą po tablicy walut przetwarzamy je kolejno</p><pre><code>import {CoinWithFrequency} from \"../interface/CoinWithFrequency\";\nimport {getCoins} from \"./getCoins\";\nimport {enhanceSingleCoin} from \"./enhanceSingleCoin\";\n\nexport const enhanceCoins = async (): Promise&lt;CoinWithFrequency[]&gt; =&gt; {\n    const coins = await getCoins();\n    const res: CoinWithFrequency[] = []\n    let i = 0, s = new Date().getTime(), n = () =&gt; new Date().getTime() - s;\n    for (const coin of coins) {\n        res.push(enhanceSingleCoin(coin));\n        console.log(`${i++}\\t${i/coins.length}\\t${n()}`);\n    }\n    return res;\n}</code></pre><p>Ponieważ trwa to chwilę do funkcji dodałem proste wyświetlanie postępu oraz czasu wykonywania.</p><p>Nasz ostatni skrypt: <code>enhanceCoinsByFrequenceis.ts</code> zawiera jedynie zapisanie wyników tej funkcji do pliku:</p><pre><code>import fs from \"fs\";\nimport {enhanceCoins} from \"./helpers/enhanceCoins\";\n\nenhanceCoins().then((coins) =&gt; {\n    fs.writeFileSync(process.cwd() + '/out/coins-with-freq.json', JSON.stringify(coins));\n    console.log(coins)\n}).catch(console.error)</code></pre><p>Po jego wykonaniu poleceniem</p><pre><code>DEBUG=app ts-node src/enhanceCoinsByFrequenceis.ts</code></pre><p>dostajemy plik z walutami wzbogaconymi o częstości <code>/out/coins-with-freq.json</code>.</p><h3 id=\"sortowanie-fraz\">Sortowanie fraz</h3><p>Przyjrzyjmy się teraz posortowanej względem stosunku <code>quotes[0].marketCap</code> do parametrów określonych pod kluczem <code>frequency</code>. Zaczniemy od ustalenia struktury danych wyjściowych:</p><pre><code>import {CoinWithFrequency} from \"./CoinWithFrequency\";\n\nexport enum PhraseType {\n    slug = 'slug',\n    name = 'name',\n    symbol = 'symbol',\n}\n\nexport interface Phrase {\n    coinId: number,\n    value: string,\n    capToFrequency: number,\n    type: PhraseType\n    coin?: CoinWithFrequency\n}</code></pre><p>Parametr <code>coin</code> nie jest wymagany, bo zakładam, że dla celów analizy może się przydać, ale ilość danych w tym parametrze jest na tyle duża, że może się okazać, że warto oczyścić z niego ostateczny wynik.</p><p>Podstawową cegiełkę ostatniej fazy stanowi zamiana coinów na frazy</p><pre><code>import {CoinWithFrequency} from \"../interface/CoinWithFrequency\";\nimport {Phrase, PhraseType} from \"../interface/Phrase\";\nimport {SortOptions} from \"../interface/SortOptions\";\n\nexport const convertCoinsToPhrases = (\n    coins: CoinWithFrequency[],\n    options: SortOptions = {withCoin: true}\n): Phrase[] =&gt; {\n    const phrases: Phrase[] = [];\n    for (const coin of coins) {\n        const newPhrases = [PhraseType.name, PhraseType.slug, PhraseType.symbol]\n            .map((type: PhraseType): Phrase =&gt; {\n                return {\n                    coinId: coin.id,\n                    value: coin[type as keyof CoinWithFrequency] as string,\n                    capToFrequency: coin.quotes[0].marketCap / coin.frequency[type],\n                    type,\n                    ... options.withCoin ? {coin} : {}\n                }\n            })\n        phrases.push(...newPhrases)\n    }\n    return phrases\n}</code></pre><p>importowane tu opcje sortowania:</p><pre><code>export interface SortOptions {\n    withCoin: boolean\n}</code></pre><p>sprowadzają się jedynie do określenia, czy chcemy widzieć wyniki z innymi danymi o coinie.</p><p>Do sortowania użyjemy funkcji:</p><pre><code>import {SortOptions} from \"../interface/SortOptions\";\nimport fs from \"fs\";\nimport {convertCoinsToPhrases} from \"./convertCoinsToPhrases\";\n\nexport const sortCurrencies = async (options: SortOptions) =&gt; {\n    const coins = JSON.parse(fs.readFileSync(process.cwd() + '/out/coins-with-freq.json').toString());\n    const phrases = convertCoinsToPhrases(coins, options)\n    phrases.sort((a, b) =&gt; a.capToFrequency - b.capToFrequency)\n    return phrases;\n}</code></pre><p>stąd już prosta droga do zapisania wyników do pliku skryptem <code>src/preparePhrases.ts</code></p><pre><code>import fs from 'fs';\nimport {sortCurrencies} from \"./helpers/sortCurrencies\";\n\nsortCurrencies({withCoin: false}).then((coins) =&gt; {\n    fs.writeFileSync(process.cwd() + '/out/phrases.json', JSON.stringify(coins));\n    console.log(coins);\n}).catch(console.error)</code></pre><p>Po jego włączeniu poleceniem:</p><pre><code>ts-node src/preparePhrases.ts</code></pre><p>Możemy zobaczyć, że dla bardzo mało znanych coinów, ale za to popularnych słów nasz współczynnik jest bardzo niski.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-28-09-09-53.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1071\" height=\"1232\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/Screenshot-from-2021-06-28-09-09-53.png 600w, __GHOST_URL__/content/images/size/w1000/2021/06/Screenshot-from-2021-06-28-09-09-53.png 1000w, __GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-28-09-09-53.png 1071w\" sizes=\"(min-width: 720px) 720px\"></figure><p>możemy się spodziewać wielu tweetów ze słowami takimi jak <code>you</code>, <code>giant</code>, <code>spectrum</code>, <code>pop</code>, <code>cyl</code>, <code>vote</code>, <code>get</code>, <code>real</code> czy <code>kind</code> w których autor nie miał na myśli kryptowalut. Z drugiej strony nie istnieje obiektywne kryterium odcięcia. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-28-09-07-09.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1115\" height=\"882\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/06/Screenshot-from-2021-06-28-09-07-09.png 600w, __GHOST_URL__/content/images/size/w1000/2021/06/Screenshot-from-2021-06-28-09-07-09.png 1000w, __GHOST_URL__/content/images/2021/06/Screenshot-from-2021-06-28-09-07-09.png 1115w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Gdybym ustawił je na 100, wycięte zostało by 2328/16395 = 14% fraz. Przy wartości <code>5</code> mamy odcięcie 1560/16395 = 9.5%. </p><h2 id=\"podsumowanie\">Podsumowanie</h2><p>Obiektywne wyznaczenie kryterium odcięcia altcoinów z monitoringu okazało się niemożliwe, ale konieczność podjęcia kilku tysięcy decyzji typu \"włączyć/wyłączyć\" z obserwacji została zastąpiony jedną decyzją o granicznym stosunku wartości coina względem częstości użycia jego nazwy w języku angielskim.</p><p>Widzimy, że ogromna większość szumu jest wycinana jeśli zrezygnujemy z obserwacji około 10% altcoinów o nazwach lub skrótach będących popularnymi zwrotami.</p><p>Całość zamknęła się w około 211 liniach typescriptu, z czego 57 to interfejsy.</p>",
            "comment_id": "60d6e8ff72a5cb20e224a224",
            "plaintext": "Celem artykułu jest pokazanie jak odfiltrować spośród wszystkich nazw altcoinów,\nte nie występujące w języku naturalnym. Zastosowanie tej techniki pozwoliło nam\nna skuteczny monitoring wzmianek na temat tysięcy kryptowalut na Twitterze w\nprojekcie MaxData .\n\nPlan działania:\n\n 1. Musimy mieć nazwy kryptowalut. Pokażę jak je pobrać i uporządkować.\n 2. Musimy mieć korpus języka. Pokażę jak się do niego dostać.\n 3. Musimy połączyć oba zbiory danych i wyznaczyć kryterium odcięcia\n    kryptowaluty z monitoringu.\n\nJeśli bardzo zależało by nam na obserwacji frazy występującej w języku\nnaturalnym wymagało by to analizy kontekstu. Jest to oczywiście możliwe, ale w\nnaszym przypadku prościej jest nam odciąć kilka altcoinów o nazwach\nwystępujących w korpusie niż analizować kontekst. Głównie dlatego, że te odcięte\naltcoiny stanowią niewielki ułamek całości rynku, a ich uwzględnienie podniosło\nby poziom skomplikowania wielokrotnie.\n\nNazwy altcoinów\nNazwy kryptowalut pobraliśmy z Coin Market Cap za pomocą końcówki\n\nhttps://api.coinmarketcap.com/data-api/v3/cryptocurrency/listing\n\nz parametrem start iterowanym po 1+100*n dla n od 0 do momentu gdzie odpowiedź\nnie będzie zawierała klucza data.\n\n Przykładowa dobra odpowiedź to:\n\n{\n    \"data\": {\n        \"cryptoCurrencyList\": [\n            {\n                \"id\": 8138,\n                \"name\": \"LinkBased\",\n                \"symbol\": \"LBD\",\n                \"slug\": \"linkbased\",\n                \"tags\": [],\n                \"cmcRank\": 4601,\n                \"marketPairCount\": 1,\n                \"circulatingSupply\": 0E-8,\n                \"totalSupply\": 813923.00000000,\n                \"isActive\": 1,\n                \"lastUpdated\": \"2021-06-26T09:08:12.000Z\",\n                \"dateAdded\": \"2020-12-30T00:00:00.000Z\",\n                \"quotes\": [\n                    {\n                        \"name\": \"USD\",\n                        \"price\": 1.59351133162663,\n                        \"volume24h\": 514.07425485,\n                        \"marketCap\": 0E-22,\n                        \"percentChange1h\": -0.13208528,\n                        \"percentChange24h\": -26.50872672,\n                        \"percentChange7d\": -34.07116202,\n                        \"lastUpdated\": \"2021-06-26T09:08:12.000Z\",\n                        \"percentChange30d\": -56.37728930,\n                        \"percentChange60d\": -57.50444478,\n                        \"percentChange90d\": -46.98725744,\n                        \"fullyDilluttedMarketCap\": 1296995.52,\n                        \"dominance\": 0.0,\n                        \"ytdPriceChangePercentage\": 41.3223\n                    }\n                ],\n                \"isAudited\": false\n            },\n            ...\n        ],\n        \"totalCount\": \"5465\"\n    },\n    \"status\": {\n        \"timestamp\": \"2021-06-26T09:10:02.180Z\",\n        \"error_code\": \"0\",\n        \"error_message\": \"SUCCESS\",\n        \"elapsed\": \"134\",\n        \"credit_count\": 0\n    }\n}\n\nA kiedy wyjdziemy poza zakres dostaniemy:\n\n{\n    \"status\": {\n        \"credit_count\": 0,\n        \"elapsed\": \"4\",\n        \"error_code\": \"500\",\n        \"error_message\": \"The system is busy, please try again later!\",\n        \"timestamp\": \"2021-06-26T09:07:58.780Z\"\n    }\n}\n\nNajbardziej interesują nas parametry:\n\n * name\n * symbol\n * quotes[0].marketCap albo jego znormalizowana wersja quotes[0].dominance\n\nDominance | CoinMarketCapA measure of Bitcoin’s value in the context of the\nlarger cryptocurrency market.CoinMarketCap\n[https://coinmarketcap.com/alexandria/glossary/dominance]Pobierzemy wszystkie\ndane o kryptowalutach i zapiszemy je w pliku. Przygotowujemy projekt:\n\nnpm init -y && tsc --init && npm i axios && npm i -D @types/node && mkdir -p src raw out && touch src/getAltcoins.ts\n\nRdzeń programu getAltcoins.ts możemy przenieść z naszego niedawnego wpisu:\n\nScraping najbardziej popularnych kont na twitterzeDzięki obserwacji wpisów z\ntwittera możemy śledzić różne trendy. W tym wpisie pokażę jak pobrać dane o\nkontach w tym serwisie i wybrać te, które mają największy współczynnik wpływu.\nDaniel GustawDaniel Gustaw\n[https://gustawdaniel.com/scraping-najbardziej-popularnych-kont-na-twitterze/]\nCzyli mniej więcej tak:\n\nimport * as fs from \"fs\";\n\ninterface CmcCoin {\n    // todo implement\n}\n\nclass Page {\n    i: number;\n\n    constructor(i: number) {\n        this.i = i;\n    }\n\n    url() {\n        return `https://api.coinmarketcap.com/data-api/v3/cryptocurrency/listing?start=${1 + 100 * this.i}`\n    }\n\n    file() {\n        return `${process.cwd()}/raw/${this.i}.json`\n    }\n\n    sync() {\n        // TODO implement\n        return false;\n    }\n\n    parse(): CmcCoin[] {\n        // todo implement\n        return []\n    }\n}\n\nconst main = async ():Promise<CmcCoin[]> => {\n    let i = 0;\n    const allItems:CmcCoin[] = [];\n    while (await new Page(i).sync()) {\n        const items = new Page(i).parse()\n        if (items.length === 0) break;\n        allItems.push(...items);\n        i++;\n    }\n    return allItems;\n}\n\nmain().then((coins) => {\n    fs.writeFileSync(process.cwd() + '/out/coins.json', JSON.stringify(coins));\n    console.log(coins);\n}).catch(console.error)\n\nImplementacja interfejsu CmcCoin\nNajprostszą metodą jest przyjrzenie się temu co zwraca API dla Bitcoina:\n\n{\n  \"id\": 1,\n  \"name\": \"Bitcoin\",\n  \"symbol\": \"BTC\",\n  \"slug\": \"bitcoin\",\n  \"tags\": [\n    \"mineable\",\n    \"pow\",\n    \"sha-256\",\n    \"store-of-value\",\n    \"state-channels\",\n    \"coinbase-ventures-portfolio\",\n    \"three-arrows-capital-portfolio\",\n    \"polychain-capital-portfolio\",\n    \"binance-labs-portfolio\",\n    \"arrington-xrp-capital\",\n    \"blockchain-capital-portfolio\",\n    \"boostvc-portfolio\",\n    \"cms-holdings-portfolio\",\n    \"dcg-portfolio\",\n    \"dragonfly-capital-portfolio\",\n    \"electric-capital-portfolio\",\n    \"fabric-ventures-portfolio\",\n    \"framework-ventures\",\n    \"galaxy-digital-portfolio\",\n    \"huobi-capital\",\n    \"alameda-research-portfolio\",\n    \"a16z-portfolio\",\n    \"1confirmation-portfolio\",\n    \"winklevoss-capital\",\n    \"usv-portfolio\",\n    \"placeholder-ventures-portfolio\",\n    \"pantera-capital-portfolio\",\n    \"multicoin-capital-portfolio\",\n    \"paradigm-xzy-screener\"\n  ],\n  \"cmcRank\": 1,\n  \"marketPairCount\": 9193,\n  \"circulatingSupply\": 18742968,\n  \"totalSupply\": 18742968,\n  \"maxSupply\": 21000000,\n  \"isActive\": 1,\n  \"lastUpdated\": \"2021-06-26T09:20:02.000Z\",\n  \"dateAdded\": \"2013-04-28T00:00:00.000Z\",\n  \"quotes\": [\n    {\n      \"name\": \"USD\",\n      \"price\": 30407.151465830357,\n      \"volume24h\": 41711690274.967766,\n      \"marketCap\": 569920266895.2114,\n      \"percentChange1h\": 0.67834797,\n      \"percentChange24h\": -11.72063275,\n      \"percentChange7d\": -15.05133094,\n      \"lastUpdated\": \"2021-06-26T09:20:02.000Z\",\n      \"percentChange30d\": -22.4475165,\n      \"percentChange60d\": -44.25026974,\n      \"percentChange90d\": -46.26175604,\n      \"fullyDilluttedMarketCap\": 638550180782.44,\n      \"dominance\": 48.2033,\n      \"turnover\": 0.07318864,\n      \"ytdPriceChangePercentage\": 3.5167\n    }\n  ],\n  \"isAudited\": false\n}\n\n i przerobienie tego na interfejs:\n\ninterface CmcCoin {\n    \"id\": number,\n    \"name\": string,\n    \"symbol\": string,\n    \"slug\": string,\n    \"tags\": string[],\n    \"cmcRank\": number,\n    \"marketPairCount\": number,\n    \"circulatingSupply\": number,\n    \"totalSupply\": number,\n    \"maxSupply\": number,\n    \"isActive\": number,\n    \"lastUpdated\": string,\n    \"dateAdded\": string,\n    \"quotes\": {\n        \"name\": string,\n        \"price\": number,\n        \"volume24h\": number,\n        \"marketCap\": number,\n        \"percentChange1h\": number,\n        \"percentChange24h\": number,\n        \"percentChange7d\": number,\n        \"lastUpdated\": string,\n        \"percentChange30d\": number,\n        \"percentChange60d\": number,\n        \"percentChange90d\": number,\n        \"fullyDilluttedMarketCap\": number,\n        \"dominance\": number,\n        \"turnover\": number,\n        \"ytdPriceChangePercentage\": number\n    }[],\n    \"isAudited\": boolean\n}\n\nSynchronizacja\nPo dodaniu paczki debug poleceniem\n\nnpm i debug && npm i -D @types/debug\n\ni kilku importów\n\nimport axios from \"axios\";\nimport * as fs from \"fs\";\nimport Debug from 'debug';\n\nconst debug = Debug('app');\n\nanalogicznie jak w poprzednio wspomnianym artykule implementujemy sync\n\n    async sync() {\n        try {\n            const fileExists = fs.existsSync(this.file())\n\n            if (fileExists) return true;\n\n            const {data, status} = await axios.get(this.url());\n\n            if (status !== 200) return false;\n\n            fs.writeFileSync(this.file(), JSON.stringify(data));\n            debug(`Saved ${this.file()}`)\n\n            return true;\n        } catch (e) {\n            console.error(e)\n            return false;\n        }\n    }\n\nJedyną różnicą jest tu JSON.stringify ponieważ chcemy zapisać do pliku ciąg\nznaków a nie obiekt. Tym razem korzystamy z api a nie pobieramy html.\n\nMożemy napisać to nawet uniwersalniej\n\ntypeof data === 'string' ? data : JSON.stringify(data)\n\nco pozwoli nam na używanie wielokrotnie tego raz napisanego kodu.\n\nParsowanie\nMetoda do parsowania jest wyjątkowo prosta:\n\n    parse(): CmcCoin[] {\n        try {\n            const content = JSON.parse(fs.readFileSync(this.file()).toString());\n            return content.data.cryptoCurrencyList\n        } catch (e) {\n            return []\n        }\n    }\n\npolega na próbie wydobycia listy pod określonym kluczem, a jeśli to niemożliwe\nzwraca pustą tablicę powodując zakończenie głównej pętli programu.\n\nFinalnie po włączeniu programu:\n\nDEBUG=app ts-node src/getAltcoins.ts\n\nw katalogu out/coins.json dostajemy plik, który zamieściłem pod linkiem:\n\nhttps://preciselab.fra1.digitaloceanspaces.com/blog/scraping/coins.json\n\nPobranie i obsługa korpusu językowego\nPo wpisaniu frazy \"english corpus\" bardzo szybko trafiamy na stronę \n\nEnglish Corpora: most widely used online corpora. Billions of words of data:\nfree online accessCompare genres, dialects, time periods. Search by PoS,\ncollocates, synonyms, and much more. [https://www.english-corpora.org/]Jest to\nscam. Zawiera informację, że jest darmowa i wystarczy zarejestrować konto\n\nale posiada ograniczenia przez które możemy skanować dziennie jedynie 50 słów.\nStraciłem czas próbując automatyzować pobieranie danych z tego serwisu.\n\nPobranie z niego próbek prowadzi do tego, że mamy poszatkowane dane nie zdatne\ndo żadnego zastosowania i dopiero wejście w cennik wyjaśnia, że można u nich\nkupić korpus za kilkaset dolarów.\n\nNa szczęście udało mi się pobrać wymagane dane ze strony o znacznie gorszym\npozycjonowaniu, ale za to dużo bardziej wartościowej:\n\nEnglish Word Frequency### Context: How frequently a word occurs in a language\nis\nan important piece of information for natural language processing and\nlinguists.\nIn natural language processing, very frequent words tend to be less informative\nthan less frequent one and are often removed during preprocessing. Human langu…\nKaggle [https://www.kaggle.com/rtatman/english-word-frequency]Tam też\nrejestracja jest wymagana, ale w zamian dostajemy dostęp do ciekawych danych,\ninteresujących treści i fantastycznego kursu. Nawet jak tego nie potrzebujemy to\npo prostu dane mamy za darmo. Jest to 5MB plik csv z kolumnami zawierającymi\nsłowo oraz ilość zliczeń.\n\nUmieściłem ten plik pod ścieżką dict/unigram_freq.csv. Aby zapytać o ilość\nzliczeń słowa credit wystarczy wpisać:\n\ngrep -E '^credit,' dict/unigram_freq.csv\n\ndostajemy:\n\ncredit,175916536\n\nAnalogicznie dla frazy:\n\ngrep -E '^theta,' dict/unigram_freq.csv\n\nmamy:\n\ntheta,5070673\n\nZa pomocą typescriptu mogli byśmy zapisać to tak:\n\nimport child_process from 'child_process';\n\nconst grepWithFork = (filename: string, word: string): Buffer => {\n    const cmd = `egrep '^${word},' ${filename}`;\n    return child_process.execSync(cmd, {maxBuffer: 200000000})\n}\n\nexport const checkFrequency = async (word: string): Promise<number> => {\n    return parseInt(grepWithFork(\n        process.cwd() + '/dict/unigram_freq.csv',\n        word\n    ).toString().replace(`${word},`, '')) || 0;\n}\n\ncheckFrequency('credit').then(console.log).catch(console.error)\ncheckFrequency('theta').then(console.log).catch(console.error)\n\nwykonanie tego pliku zwróci nam częstości:\n\n175916536\n5070673\n\nz tego co wiem, to wykorzystanie systemowego grepa jest jedną z najbardziej\nwydajnych metod w tym konkretnym przypadku, ponieważ nie wymaga ładowania całego\npliku do pamięci, pisania logiki wyszukiwania a jednocześnie pozwala zrzucić\nodpowiedzialność za optymalizację wyszukiwania na twórców grep. Sam nie robiłem\ntakich eksperymentów, ale czytałem, że do 2-3 tysięcy linii można w node js\nwyszukać szybciej, bo nie tracimy czasu na włączanie osobnego procesu, ale przy\nwiększych plikach okazuje się, że optymalizacja grepa nadrabia opóźnienia\nzwiązane z wykonywaniem komend przez child_process.\n\nFrom node.js, which is faster, shell grep or fs.readFile?I have a long running\nnode.js process and I need to scan a log file for a pattern. I have at least\ntwo\nobvious choices: spawn a grep process or read the file using fs.read* and parse\nthe buffer/str...Stack OverflowMatt Simerson\n[https://stackoverflow.com/questions/28400727/from-node-js-which-is-faster-shell-grep-or-fs-readfile]\nPołączenie częstości z nazwami coinów\nWykonałem drobny refactoring. W src utworzyłem katalogi interface oraz helpers.\nDo interface przeniosłem CmcCoin, oraz utworzyłem CoinWithFrequency.ts \nzawierający\n\nimport {CmcCoin} from \"./CmcCoin\";\n\nexport interface CoinWithFrequency extends CmcCoin {\n    frequency: {\n        name: number,\n        symbol: number,\n        slug: number\n    }\n}\n\njest to struktura danych pozwalająca nam ująć możliwie dokładne dane dotyczące\nczęstotliwości występowania nie tylko nazw ale też symboli i potencjalnie slug \ncoinów.\n\nDo helpers przeniosłem klasę Page, oraz funkcje grepWithFork i checkFrequency z\ntym, że ta druga dostała obsługę wyjątków:\n\nimport {grepWithFork} from \"./grepWithFork\";\n\nexport const checkFrequency = (word: string): number => {\n    try {\n        return parseInt(grepWithFork(\n            process.cwd() + '/dict/unigram_freq.csv',\n            word\n        ).toString().replace(`${word},`, '')) || 0;\n    } catch (e) {\n        return 0\n    }\n}\n\nOstatnią zmianą jest wyrzucenie z getAltcoins funkcji main i nazwanie jej \ngetCoins. W pliku o tej samej nazwie w helpers znalazł się teraz kod\n\nimport {CmcCoin} from \"../interface/CmcCoin\";\nimport {Page} from \"./Page\";\n\nexport const getCoins = async ():Promise<CmcCoin[]> => {\n    let i = 0;\n    const allItems:CmcCoin[] = [];\n    while (await new Page(i).sync()) {\n        const items = new Page(i).parse()\n        if (items.length === 0) break;\n        allItems.push(...items);\n        i++;\n    }\n    return allItems;\n}\n\nNową funkcją jest bardzo prosta funkcja enhanceSingleCoin umieszczona też w \nhelpers w pliku z tą nazwą o treści:\n\nimport {CmcCoin} from \"../interface/CmcCoin\";\nimport {CoinWithFrequency} from \"../interface/CoinWithFrequency\";\nimport {checkFrequency} from \"./checkFrequency\";\n\nexport const enhanceSingleCoin = (coin: CmcCoin): CoinWithFrequency => {\n    return {\n        ...coin,\n        frequency: {\n            name: checkFrequency(coin.name.toLowerCase()),\n            slug: checkFrequency(coin.slug.toLowerCase()),\n            symbol: checkFrequency(coin.symbol.toLowerCase())\n        }\n    }\n}\n\nIterując za jej pomocą po tablicy walut przetwarzamy je kolejno\n\nimport {CoinWithFrequency} from \"../interface/CoinWithFrequency\";\nimport {getCoins} from \"./getCoins\";\nimport {enhanceSingleCoin} from \"./enhanceSingleCoin\";\n\nexport const enhanceCoins = async (): Promise<CoinWithFrequency[]> => {\n    const coins = await getCoins();\n    const res: CoinWithFrequency[] = []\n    let i = 0, s = new Date().getTime(), n = () => new Date().getTime() - s;\n    for (const coin of coins) {\n        res.push(enhanceSingleCoin(coin));\n        console.log(`${i++}\\t${i/coins.length}\\t${n()}`);\n    }\n    return res;\n}\n\nPonieważ trwa to chwilę do funkcji dodałem proste wyświetlanie postępu oraz\nczasu wykonywania.\n\nNasz ostatni skrypt: enhanceCoinsByFrequenceis.ts zawiera jedynie zapisanie\nwyników tej funkcji do pliku:\n\nimport fs from \"fs\";\nimport {enhanceCoins} from \"./helpers/enhanceCoins\";\n\nenhanceCoins().then((coins) => {\n    fs.writeFileSync(process.cwd() + '/out/coins-with-freq.json', JSON.stringify(coins));\n    console.log(coins)\n}).catch(console.error)\n\nPo jego wykonaniu poleceniem\n\nDEBUG=app ts-node src/enhanceCoinsByFrequenceis.ts\n\ndostajemy plik z walutami wzbogaconymi o częstości /out/coins-with-freq.json.\n\nSortowanie fraz\nPrzyjrzyjmy się teraz posortowanej względem stosunku quotes[0].marketCap do\nparametrów określonych pod kluczem frequency. Zaczniemy od ustalenia struktury\ndanych wyjściowych:\n\nimport {CoinWithFrequency} from \"./CoinWithFrequency\";\n\nexport enum PhraseType {\n    slug = 'slug',\n    name = 'name',\n    symbol = 'symbol',\n}\n\nexport interface Phrase {\n    coinId: number,\n    value: string,\n    capToFrequency: number,\n    type: PhraseType\n    coin?: CoinWithFrequency\n}\n\nParametr coin nie jest wymagany, bo zakładam, że dla celów analizy może się\nprzydać, ale ilość danych w tym parametrze jest na tyle duża, że może się\nokazać, że warto oczyścić z niego ostateczny wynik.\n\nPodstawową cegiełkę ostatniej fazy stanowi zamiana coinów na frazy\n\nimport {CoinWithFrequency} from \"../interface/CoinWithFrequency\";\nimport {Phrase, PhraseType} from \"../interface/Phrase\";\nimport {SortOptions} from \"../interface/SortOptions\";\n\nexport const convertCoinsToPhrases = (\n    coins: CoinWithFrequency[],\n    options: SortOptions = {withCoin: true}\n): Phrase[] => {\n    const phrases: Phrase[] = [];\n    for (const coin of coins) {\n        const newPhrases = [PhraseType.name, PhraseType.slug, PhraseType.symbol]\n            .map((type: PhraseType): Phrase => {\n                return {\n                    coinId: coin.id,\n                    value: coin[type as keyof CoinWithFrequency] as string,\n                    capToFrequency: coin.quotes[0].marketCap / coin.frequency[type],\n                    type,\n                    ... options.withCoin ? {coin} : {}\n                }\n            })\n        phrases.push(...newPhrases)\n    }\n    return phrases\n}\n\nimportowane tu opcje sortowania:\n\nexport interface SortOptions {\n    withCoin: boolean\n}\n\nsprowadzają się jedynie do określenia, czy chcemy widzieć wyniki z innymi danymi\no coinie.\n\nDo sortowania użyjemy funkcji:\n\nimport {SortOptions} from \"../interface/SortOptions\";\nimport fs from \"fs\";\nimport {convertCoinsToPhrases} from \"./convertCoinsToPhrases\";\n\nexport const sortCurrencies = async (options: SortOptions) => {\n    const coins = JSON.parse(fs.readFileSync(process.cwd() + '/out/coins-with-freq.json').toString());\n    const phrases = convertCoinsToPhrases(coins, options)\n    phrases.sort((a, b) => a.capToFrequency - b.capToFrequency)\n    return phrases;\n}\n\nstąd już prosta droga do zapisania wyników do pliku skryptem \nsrc/preparePhrases.ts\n\nimport fs from 'fs';\nimport {sortCurrencies} from \"./helpers/sortCurrencies\";\n\nsortCurrencies({withCoin: false}).then((coins) => {\n    fs.writeFileSync(process.cwd() + '/out/phrases.json', JSON.stringify(coins));\n    console.log(coins);\n}).catch(console.error)\n\nPo jego włączeniu poleceniem:\n\nts-node src/preparePhrases.ts\n\nMożemy zobaczyć, że dla bardzo mało znanych coinów, ale za to popularnych słów\nnasz współczynnik jest bardzo niski.\n\nmożemy się spodziewać wielu tweetów ze słowami takimi jak you, giant, spectrum, \npop, cyl, vote, get, real czy kind w których autor nie miał na myśli\nkryptowalut. Z drugiej strony nie istnieje obiektywne kryterium odcięcia. \n\nGdybym ustawił je na 100, wycięte zostało by 2328/16395 = 14% fraz. Przy\nwartości 5 mamy odcięcie 1560/16395 = 9.5%. \n\nPodsumowanie\nObiektywne wyznaczenie kryterium odcięcia altcoinów z monitoringu okazało się\nniemożliwe, ale konieczność podjęcia kilku tysięcy decyzji typu\n\"włączyć/wyłączyć\" z obserwacji została zastąpiony jedną decyzją o granicznym\nstosunku wartości coina względem częstości użycia jego nazwy w języku\nangielskim.\n\nWidzimy, że ogromna większość szumu jest wycinana jeśli zrezygnujemy z\nobserwacji około 10% altcoinów o nazwach lub skrótach będących popularnymi\nzwrotami.\n\nCałość zamknęła się w około 211 liniach typescriptu, z czego 57 to interfejsy.",
            "feature_image": "__GHOST_URL__/content/images/2021/06/istockphoto-946862244-612x612.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-06-26T08:44:47.000Z",
            "updated_at": "2021-06-30T10:22:00.000Z",
            "published_at": "2021-06-30T10:22:00.000Z",
            "custom_excerpt": "Celem artykułu jest pokazanie jak odfiltrować spośród wszystkich nazw kryptowalut, te nie występujące w języku naturalnym.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60e08131ae5f887e4011812f",
            "uuid": "67e3ce7c-0a8e-42c2-8b07-d97330eb9af7",
            "title": "Apollo Server w Node JS + Mongo DB + Prisma",
            "slug": "jak-napisac-backend-w-apollo",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"npm init -y && tsc --init && npm i -D typescript @types/node @types/jest jest jest-extended ts-jest prisma nodemon ts-node && npm i @prisma/client apollo-server graphql\\n\"}],[\"code\",{\"code\":\"echo '{ \\\"watch\\\": [\\\"src\\\"],  \\\"ext\\\": \\\"ts,json\\\",  \\\"ignore\\\": [\\\"src/**/*.spec.ts\\\"] }' > nodemon.json\"}],[\"code\",{\"code\":\"    \\\"start\\\": \\\"nodemon --exec 'ts-node' src/gql.ts\\\",\\n    \\\"test\\\": \\\"jest\\\",\\n    \\\"codegen\\\": \\\"graphql-codegen --config codegen.yml\\\"\"}],[\"code\",{\"code\":\"overwrite: true\\n#schema: \\\"http://localhost:4000\\\"\\nschema: \\\"./src/type-defs.graphql\\\"\\ndocuments: null\\ngenerates:\\n  src/generated/graphql.ts:\\n    plugins:\\n      - \\\"typescript\\\"\\n      - \\\"typescript-resolvers\\\"\\n      - \\\"typescript-mongodb\\\"\\n      - \\\"typescript-document-nodes\\\"\\n  ./graphql.schema.json:\\n    plugins:\\n      - \\\"introspection\\\"\\n\"}],[\"code\",{\"code\":\"npm i -D @graphql-codegen/cli @graphql-codegen/introspection @graphql-codegen/typescript @graphql-codegen/typescript-document-nodes @graphql-codegen/typescript-mongodb @graphql-codegen/typescript-resolvers && npm i -g graphql-codegen\"}],[\"code\",{\"code\":\"type Query {\\n    \\\"A simple type for getting started!\\\"\\n    hello: String\\n}\"}],[\"code\",{\"code\":\"npm i -D graphql-import-node\"}],[\"code\",{\"code\":\"\\\"resolveJsonModule\\\": true\"}],[\"code\",{\"code\":\"\\\"target\\\": \\\"ESNext\\\", \"}],[\"code\",{\"code\":\"import \\\"graphql-import-node\\\";\\n\\nimport { ApolloServer }from 'apollo-server';\\nimport typeDefs from './type-defs.graphql'\\n\\nconst resolvers = {\\n    Query: {\\n        hello: () => 'world',\\n    },\\n};\\n\\nconst server = new ApolloServer({\\n    typeDefs,\\n    resolvers,\\n});\\n\\nserver.listen().then(({ url }) => {\\n    console.log(`? Server ready at ${url}`);\\n});\"}],[\"code\",{\"code\":\"npm run start\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-03-19-37-56.png\",\"width\":1872,\"height\":487,\"cardWidth\":\"full\"}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Pokażę jak napisać aplikację, która wylicza wpływ nagłych zmiany rezerwy BTC na giełdach na ich cenę. Kod piszemy od zera w technologiach\"]]],[3,\"ul\",[[[0,[],0,\"node js (typescript)\"]],[[0,[],0,\"mongo db (prisma)\"]],[[0,[],0,\"apollo server\"]]]],[1,\"h2\",[[0,[],0,\"Przygotowanie serwera Apollo\"]]],[1,\"p\",[[0,[],0,\"Inicjalizujemy projekt:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Przygotowujemy nodemon\"]]],[10,1],[1,\"p\",[[0,[],0,\"W \"],[0,[0],1,\"package.json\"],[0,[],0,\" ustawiamy skrypty\"]]],[10,2],[1,\"p\",[[0,[],0,\"Dołączamy plik \"],[0,[0],1,\"codegen.yml\"],[0,[],0,\" o treści\"]]],[10,3],[1,\"p\",[[0,[],0,\"Instalujemy paczki:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Aby wygenerować typy typescript na podstawie schematu graphql będziemy wykonywać komendę \"],[0,[0],1,\"npm run codegen\"],[0,[],0,\", ale żeby ona zadziałała w pliku \"],[0,[0],1,\"./src/type-defs.graphql\"],[0,[],0,\" musimy umieścić typy graphql. Zacznijmy od prostego\"]]],[10,5],[1,\"p\",[[0,[],0,\"Żeby zaimportować ten plik i użyć go do konfiguracji serwera potrzebujemy jeszcze jednej paczki:\"]]],[10,6],[1,\"p\",[[0,[],0,\"Jednocześnie w pliku \"],[0,[0],1,\"tsconfig.json\"],[0,[],0,\" dodajemy:\"]]],[10,7],[1,\"p\",[[0,[],0,\"oraz ustawiamy\"]]],[10,8],[1,\"p\",[[0,[],0,\"Teraz w pliku \"],[0,[0],1,\"src/gql.ts\"],[0,[],0,\" stawiamy najprostszy możliwy serwer graphql\"]]],[10,9],[1,\"p\",[[0,[],0,\"Po wystartowaniu serwera poleceniem\"]]],[10,10],[1,\"p\",[[0,[],0,\"pod adresem \"],[0,[0],1,\"localhost:4000\"],[0,[],0,\" zobaczymy\"]]],[10,11],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Pokażę jak napisać aplikację, która wylicza wpływ nagłych zmiany rezerwy BTC na giełdach na ich cenę. Kod piszemy od zera w technologiach</p><ul><li>node js (typescript)</li><li>mongo db (prisma)</li><li>apollo server</li></ul><h2 id=\"przygotowanie-serwera-apollo\">Przygotowanie serwera Apollo</h2><p>Inicjalizujemy projekt:</p><pre><code>npm init -y &amp;&amp; tsc --init &amp;&amp; npm i -D typescript @types/node @types/jest jest jest-extended ts-jest prisma nodemon ts-node &amp;&amp; npm i @prisma/client apollo-server graphql\n</code></pre><p>Przygotowujemy nodemon</p><pre><code>echo '{ \"watch\": [\"src\"],  \"ext\": \"ts,json\",  \"ignore\": [\"src/**/*.spec.ts\"] }' &gt; nodemon.json</code></pre><p>W <code>package.json</code> ustawiamy skrypty</p><pre><code>    \"start\": \"nodemon --exec 'ts-node' src/gql.ts\",\n    \"test\": \"jest\",\n    \"codegen\": \"graphql-codegen --config codegen.yml\"</code></pre><p>Dołączamy plik <code>codegen.yml</code> o treści</p><pre><code>overwrite: true\n#schema: \"http://localhost:4000\"\nschema: \"./src/type-defs.graphql\"\ndocuments: null\ngenerates:\n  src/generated/graphql.ts:\n    plugins:\n      - \"typescript\"\n      - \"typescript-resolvers\"\n      - \"typescript-mongodb\"\n      - \"typescript-document-nodes\"\n  ./graphql.schema.json:\n    plugins:\n      - \"introspection\"\n</code></pre><p>Instalujemy paczki:</p><pre><code>npm i -D @graphql-codegen/cli @graphql-codegen/introspection @graphql-codegen/typescript @graphql-codegen/typescript-document-nodes @graphql-codegen/typescript-mongodb @graphql-codegen/typescript-resolvers &amp;&amp; npm i -g graphql-codegen</code></pre><p>Aby wygenerować typy typescript na podstawie schematu graphql będziemy wykonywać komendę <code>npm run codegen</code>, ale żeby ona zadziałała w pliku <code>./src/type-defs.graphql</code> musimy umieścić typy graphql. Zacznijmy od prostego</p><pre><code>type Query {\n    \"A simple type for getting started!\"\n    hello: String\n}</code></pre><p>Żeby zaimportować ten plik i użyć go do konfiguracji serwera potrzebujemy jeszcze jednej paczki:</p><pre><code>npm i -D graphql-import-node</code></pre><p>Jednocześnie w pliku <code>tsconfig.json</code> dodajemy:</p><pre><code>\"resolveJsonModule\": true</code></pre><p>oraz ustawiamy</p><pre><code>\"target\": \"ESNext\", </code></pre><p>Teraz w pliku <code>src/gql.ts</code> stawiamy najprostszy możliwy serwer graphql</p><pre><code>import \"graphql-import-node\";\n\nimport { ApolloServer }from 'apollo-server';\nimport typeDefs from './type-defs.graphql'\n\nconst resolvers = {\n    Query: {\n        hello: () =&gt; 'world',\n    },\n};\n\nconst server = new ApolloServer({\n    typeDefs,\n    resolvers,\n});\n\nserver.listen().then(({ url }) =&gt; {\n    console.log(`? Server ready at ${url}`);\n});</code></pre><p>Po wystartowaniu serwera poleceniem</p><pre><code>npm run start</code></pre><p>pod adresem <code>localhost:4000</code> zobaczymy</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-03-19-37-56.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1872\" height=\"487\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-03-19-37-56.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-03-19-37-56.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/07/Screenshot-from-2021-07-03-19-37-56.png 1600w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-03-19-37-56.png 1872w\"></figure>",
            "comment_id": "60e08131ae5f887e4011812f",
            "plaintext": "Pokażę jak napisać aplikację, która wylicza wpływ nagłych zmiany rezerwy BTC na\ngiełdach na ich cenę. Kod piszemy od zera w technologiach\n\n * node js (typescript)\n * mongo db (prisma)\n * apollo server\n\nPrzygotowanie serwera Apollo\nInicjalizujemy projekt:\n\nnpm init -y && tsc --init && npm i -D typescript @types/node @types/jest jest jest-extended ts-jest prisma nodemon ts-node && npm i @prisma/client apollo-server graphql\n\n\nPrzygotowujemy nodemon\n\necho '{ \"watch\": [\"src\"],  \"ext\": \"ts,json\",  \"ignore\": [\"src/**/*.spec.ts\"] }' > nodemon.json\n\nW package.json ustawiamy skrypty\n\n    \"start\": \"nodemon --exec 'ts-node' src/gql.ts\",\n    \"test\": \"jest\",\n    \"codegen\": \"graphql-codegen --config codegen.yml\"\n\nDołączamy plik codegen.yml o treści\n\noverwrite: true\n#schema: \"http://localhost:4000\"\nschema: \"./src/type-defs.graphql\"\ndocuments: null\ngenerates:\n  src/generated/graphql.ts:\n    plugins:\n      - \"typescript\"\n      - \"typescript-resolvers\"\n      - \"typescript-mongodb\"\n      - \"typescript-document-nodes\"\n  ./graphql.schema.json:\n    plugins:\n      - \"introspection\"\n\n\nInstalujemy paczki:\n\nnpm i -D @graphql-codegen/cli @graphql-codegen/introspection @graphql-codegen/typescript @graphql-codegen/typescript-document-nodes @graphql-codegen/typescript-mongodb @graphql-codegen/typescript-resolvers && npm i -g graphql-codegen\n\nAby wygenerować typy typescript na podstawie schematu graphql będziemy wykonywać\nkomendę npm run codegen, ale żeby ona zadziałała w pliku ./src/type-defs.graphql \nmusimy umieścić typy graphql. Zacznijmy od prostego\n\ntype Query {\n    \"A simple type for getting started!\"\n    hello: String\n}\n\nŻeby zaimportować ten plik i użyć go do konfiguracji serwera potrzebujemy\njeszcze jednej paczki:\n\nnpm i -D graphql-import-node\n\nJednocześnie w pliku tsconfig.json dodajemy:\n\n\"resolveJsonModule\": true\n\noraz ustawiamy\n\n\"target\": \"ESNext\", \n\nTeraz w pliku src/gql.ts stawiamy najprostszy możliwy serwer graphql\n\nimport \"graphql-import-node\";\n\nimport { ApolloServer }from 'apollo-server';\nimport typeDefs from './type-defs.graphql'\n\nconst resolvers = {\n    Query: {\n        hello: () => 'world',\n    },\n};\n\nconst server = new ApolloServer({\n    typeDefs,\n    resolvers,\n});\n\nserver.listen().then(({ url }) => {\n    console.log(`? Server ready at ${url}`);\n});\n\nPo wystartowaniu serwera poleceniem\n\nnpm run start\n\npod adresem localhost:4000 zobaczymy",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-07-03T15:24:33.000Z",
            "updated_at": "2021-07-03T17:36:42.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60e4e4c1ae5f887e4011818a",
            "uuid": "0b0eb74b-8c26-4714-bbed-61b6d70fd928",
            "title": "Broadcast Channel API",
            "slug": "broadcast-channel-api",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"npm install -g parcel-bundler\"}],[\"code\",{\"code\":\"echo '<html><body><script src=\\\"./index.ts\\\"></script></body></html>' > index.html\\ntouch index.ts\"}],[\"code\",{\"code\":\"parcel index.html\"}],[\"code\",{\"code\":\"const bc = new BroadcastChannel('channel');\"}],[\"code\",{\"code\":\"const id = Math.random();\"}],[\"code\",{\"code\":\"let send = 0, received = 0;\"}],[\"code\",{\"code\":\"console.log(\\\"START\\\", id);\"}],[\"code\",{\"code\":\"bc.onmessage = (e) => {\\n    console.log(e.data, send, received);\\n    received++;\\n}\"}],[\"code\",{\"code\":\"setTimeout(() => {\\n    bc.postMessage({title: `Connection from ${id}`})\\n}, 250)\"}],[\"code\",{\"code\":\"const i = setInterval(() => {\\n    const uptime = performance.now();\\n    bc.postMessage({id, uptime, send, received})\\n    send++;\\n    if (uptime > 1e3) clearInterval(i)\\n}, 500)\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://developer.mozilla.org/en-US/docs/Web/API/Performance\",\"metadata\":{\"url\":\"https://developer.mozilla.org/en-US/docs/Web/API/Performance\",\"title\":\"Performance - Web APIs | MDN\",\"description\":\"The Performance interface provides access to performance-related information for the current page. It’s part of the High Resolution Time API, but is enhanced by the Performance Timeline API, the Navigation Timing API, the User Timing API, and the Resource Timing API.\",\"author\":null,\"publisher\":\"MDN\",\"thumbnail\":\"https://developer.mozilla.org/mdn-social-share.0ca9dbda.png\",\"icon\":\"https://developer.mozilla.org/apple-touch-icon.0ea0fa02.png\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-01-56-23.png\",\"width\":1873,\"height\":201,\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-01-57-17.png\",\"width\":1866,\"height\":916,\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-02-12-15.png\",\"width\":1861,\"height\":417,\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-09-38-48.png\",\"width\":1896,\"height\":581,\"cardWidth\":\"full\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://developer.mozilla.org/en-US/docs/Glossary/Origin\",\"metadata\":{\"url\":\"https://developer.mozilla.org/en-US/docs/Glossary/Origin\",\"title\":\"Origin - MDN Web Docs Glossary: Definitions of Web-related terms | MDN\",\"description\":\"Web content’s origin is defined by the scheme (protocol), hostname (domain), and port of the URL used to access it. Two objects have the same origin only when the scheme, hostname, and port all match.\",\"author\":null,\"publisher\":\"MDN\",\"thumbnail\":\"https://developer.mozilla.org/mdn-social-share.0ca9dbda.png\",\"icon\":\"https://developer.mozilla.org/apple-touch-icon.0ea0fa02.png\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-02-16-02.png\",\"width\":361,\"height\":62}],[\"code\",{\"code\":\"ip route\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-08-20-47.png\",\"width\":477,\"height\":100}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://parceljs.org/cli.html\",\"metadata\":{\"url\":\"https://parceljs.org/cli.html\",\"title\":\"? CLI\",\"description\":null,\"author\":null,\"publisher\":\"Parcel\",\"thumbnail\":\"https://parceljs.org/assets/parcel.png\",\"icon\":\"https://parceljs.org/assets/favicon.ico\"}}],[\"code\",{\"code\":\"parce index.html --host 192.168.2.162\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-08-21-16.png\",\"width\":479,\"height\":57,\"alt\":\"\",\"caption\":\"\"}],[\"code\",{\"code\":\"const popup = window.open('https://another-origin.com', ...);\\npopup.postMessage('Sup popup!', 'https://another-origin.com');\"}],[\"code\",{\"code\":\"const iframe = document.querySelector('iframe');\\niframe.contentWindow.onmessage = function(e) {\\n  if (e.origin !== 'https://expected-origin.com') {\\n    return;\\n  }\\n  e.source.postMessage('Ack!', e.origin);\\n};\"}],[\"code\",{\"code\":\"<html lang=\\\"en\\\">\\n<body style=\\\"margin:0;\\\">\\n<canvas id=\\\"canvas\\\" style=\\\"width: 100vw; height: 100vh;\\\"></canvas>\\n<script src=\\\"./index.ts\\\"></script>\\n</body>\\n</html>\"}],[\"code\",{\"code\":\"interface Window {\\n    canvas?: HTMLCanvasElement;\\n}\"}],[\"code\",{\"code\":\"const getCanvasAndCtx = (): { canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D } => {\\n    const canvas = window.canvas || document.querySelector('#canvas');\\n    if (canvas instanceof HTMLCanvasElement) {\\n        window.canvas = canvas;\\n        const ctx = canvas.getContext('2d');\\n        if(ctx) {\\n            return {canvas, ctx}\\n        } else {\\n            throw new Error('Canvas do not have context');\\n        }\\n    }\\n    throw new Error('Canvas Not found');\\n}\"}],[\"code\",{\"code\":\"const syncCanvasSize = () => {\\n    const { canvas } = getCanvasAndCtx()\\n    canvas.height = window.innerHeight;\\n    canvas.width = window.innerWidth;\\n}\"}],[\"code\",{\"code\":\"window.addEventListener('resize', syncCanvasSize)\\n\\nwindow.addEventListener('DOMContentLoaded', () => {\\n    syncCanvasSize();\\n    const {canvas, ctx} = getCanvasAndCtx()\"}],[\"code\",{\"code\":\"    let flag = false,\\n        prevX = 0,\\n        currX = 0,\\n        prevY = 0,\\n        currY = 0;\"}],[\"code\",{\"code\":\"    function drawLine() {\\n        ctx.beginPath();\\n        ctx.moveTo(prevX, prevY);\\n        ctx.lineTo(currX, currY);\\n        ctx.strokeStyle = \\\"black\\\";\\n        ctx.lineWidth = 2;\\n        ctx.stroke();\\n        ctx.closePath();\\n    }\\n\\n    function drawDot() {\\n        ctx.beginPath();\\n        ctx.fillStyle = 'black';\\n        ctx.fillRect(currX, currY, 2, 2);\\n        ctx.closePath();\\n    }\"}],[\"code\",{\"code\":\"    function findPosition(res: EventType, e: { clientX: number, clientY: number }) {\\n        if (res == EventType.down) {\\n            prevX = currX;\\n            prevY = currY;\\n            currX = e.clientX;\\n            currY = e.clientY;\\n            flag = true;\\n            drawDot()\\n        }\\n        if ([EventType.up, EventType.out].includes(res)) {\\n            flag = false;\\n        }\\n        if (res == EventType.move) {\\n            if (flag) {\\n                prevX = currX;\\n                prevY = currY;\\n                currX = e.clientX;\\n                currY = e.clientY;\\n                drawLine();\\n            }\\n        }\\n    }\"}],[\"code\",{\"code\":\"    canvas.addEventListener(\\\"mousemove\\\", (e) => {\\n        findPosition(EventType.move, e)\\n    });\\n    canvas.addEventListener(\\\"mousedown\\\", (e) => {\\n        findPosition(EventType.down, e)\\n    });\\n    canvas.addEventListener(\\\"mouseup\\\", (e) => {\\n        findPosition(EventType.up, e)\\n    });\\n    canvas.addEventListener(\\\"mouseout\\\", (e) => {\\n        findPosition(EventType.out, e)\\n    });\\n\\n})\"}],[\"code\",{\"code\":\"const bc = new BroadcastChannel('channel');\"}],[\"code\",{\"code\":\"bc.onmessage = (e) => {\\n\\tif(e.data.cmd === 'findPosition') {\\n\\t\\tfindPosition(e.data.args[0], e.data.args[1], false)\\n\\t}\\n}\"}],[\"code\",{\"code\":\"function findPosition(res: EventType, e: {clientX: number, clientY: number}, propagate: boolean) {\\n\\n    if(propagate) {\\n        bc.postMessage({cmd: 'findPosition', args: [res, {clientX: e.clientX, clientY: e.clientY}]})\\n        }\"}],[\"code\",{\"code\":\"interface Window {\\n    canvas?: HTMLCanvasElement;\\n}\\n\\nconst getCanvasAndCtx = (): { canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D } => {\\n    const canvas = window.canvas || document.querySelector('#canvas');\\n    if (canvas instanceof HTMLCanvasElement) {\\n        window.canvas = canvas;\\n        const ctx = canvas.getContext('2d');\\n        if(ctx) {\\n            return {canvas, ctx}\\n        } else {\\n            throw new Error('Canvas do not have context');\\n        }\\n    }\\n    throw new Error('Canvas Not found');\\n}\\n\\nconst syncCanvasSize = () => {\\n    const {canvas} = getCanvasAndCtx()\\n    canvas.height = window.innerHeight;\\n    canvas.width = window.innerWidth;\\n}\\n\\nwindow.addEventListener('resize', syncCanvasSize)\\n\\nenum EventType {\\n    down,\\n    up,\\n    move,\\n    out\\n}\\n\\nwindow.addEventListener('DOMContentLoaded', () => {\\n    syncCanvasSize();\\n    const {canvas, ctx} = getCanvasAndCtx()\\n\\n    let flag = false,\\n        prevX = 0,\\n        currX = 0,\\n        prevY = 0,\\n        currY = 0;\\n\\n    const bc = new BroadcastChannel('channel');\\n\\n    function drawLine() {\\n        ctx.beginPath();\\n        ctx.moveTo(prevX, prevY);\\n        ctx.lineTo(currX, currY);\\n        ctx.strokeStyle = \\\"black\\\";\\n        ctx.lineWidth = 2;\\n        ctx.stroke();\\n        ctx.closePath();\\n    }\\n\\n    function drawDot() {\\n        ctx.beginPath();\\n        ctx.fillStyle = 'black';\\n        ctx.fillRect(currX, currY, 2, 2);\\n        ctx.closePath();\\n    }\\n\\n    function findPosition(res: EventType, e: { clientX: number, clientY: number }, propagate: boolean) {\\n\\n        if (propagate) {\\n            bc.postMessage({cmd: 'findPosition', args: [res, {clientX: e.clientX, clientY: e.clientY}]})\\n        }\\n\\n        if (res == EventType.down) {\\n            prevX = currX;\\n            prevY = currY;\\n            currX = e.clientX;\\n            currY = e.clientY;\\n            flag = true;\\n            drawDot()\\n        }\\n        if ([EventType.up, EventType.out].includes(res)) {\\n            flag = false;\\n        }\\n        if (res == EventType.move) {\\n            if (flag) {\\n                prevX = currX;\\n                prevY = currY;\\n                currX = e.clientX;\\n                currY = e.clientY;\\n                drawLine();\\n            }\\n        }\\n    }\\n\\n    canvas.addEventListener(\\\"mousemove\\\", (e) => {\\n        findPosition(EventType.move, e, true)\\n    });\\n    canvas.addEventListener(\\\"mousedown\\\", (e) => {\\n        findPosition(EventType.down, e, true)\\n    });\\n    canvas.addEventListener(\\\"mouseup\\\", (e) => {\\n        findPosition(EventType.up, e, true)\\n    });\\n    canvas.addEventListener(\\\"mouseout\\\", (e) => {\\n        findPosition(EventType.out, e, true)\\n    });\\n\\n    bc.onmessage = (e) => {\\n        if (e.data.cmd === 'findPosition') {\\n            findPosition(e.data.args[0], e.data.args[1], false)\\n        }\\n    }\\n\\n})\"}],[\"embed\",{\"url\":\"https://youtu.be/BPnzdw8Nryk\",\"html\":\"<iframe width=\\\"200\\\" height=\\\"150\\\" src=\\\"https://www.youtube.com/embed/BPnzdw8Nryk?feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\",\"metadata\":{\"title\":\"Broadcast Channel API\",\"author_name\":\"gustawdaniel\",\"author_url\":\"https://www.youtube.com/user/gustawdaniel\",\"height\":150,\"width\":200,\"version\":\"1.0\",\"provider_name\":\"YouTube\",\"provider_url\":\"https://www.youtube.com/\",\"thumbnail_height\":360,\"thumbnail_width\":480,\"thumbnail_url\":\"https://i.ytimg.com/vi/BPnzdw8Nryk/hqdefault.jpg\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://developer.mozilla.org/en-US/docs/Web/API/Broadcast_Channel_API\",\"metadata\":{\"url\":\"https://developer.mozilla.org/en-US/docs/Web/API/Broadcast_Channel_API\",\"title\":\"Broadcast Channel API - Web APIs | MDN\",\"description\":\"The Broadcast Channel API allows basic communication between browsing contexts (that is, windows, tabs, frames, or iframes) and workers on the same origin.\",\"author\":null,\"publisher\":\"MDN\",\"thumbnail\":\"https://developer.mozilla.org/mdn-social-share.0ca9dbda.png\",\"icon\":\"https://developer.mozilla.org/apple-touch-icon.0ea0fa02.png\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://developers.google.com/web/updates/2016/09/broadcastchannel\",\"metadata\":{\"url\":\"https://developers.google.com/web/updates/2016/09/broadcastchannel\",\"title\":\"BroadcastChannel API: A Message Bus for the Web | Google Developers\",\"description\":\"BroadcastChannel API can be used for simple pub/sub between windows, tabs, iframes, or workers.\",\"author\":\"Eric Bidelman\",\"publisher\":\"Google Developers\",\"thumbnail\":\"https://developers.google.com/web/images/social-webfu-16x9.png\",\"icon\":\"https://www.gstatic.com/devrel-devsite/prod/v5f61782021051fb502364887a46a1c5ce2cd6f3d29a3549e907afe67612e9bba/developers/images/touchicon-180.png\"}}],[\"embed\",{\"url\":\"https://www.youtube.com/watch?v=wYcvzLFHFN0\",\"html\":\"<iframe width=\\\"200\\\" height=\\\"113\\\" src=\\\"https://www.youtube.com/embed/wYcvzLFHFN0?feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\",\"metadata\":{\"title\":\"Send Data Between Tabs and Windows! - Broadcast Channel API in JavaScript\",\"author_name\":\"dcode\",\"author_url\":\"https://www.youtube.com/c/dcode-software\",\"height\":113,\"width\":200,\"version\":\"1.0\",\"provider_name\":\"YouTube\",\"provider_url\":\"https://www.youtube.com/\",\"thumbnail_height\":360,\"thumbnail_width\":480,\"thumbnail_url\":\"https://i.ytimg.com/vi/wYcvzLFHFN0/hqdefault.jpg\"}}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Nauczymy się jak używać \"],[0,[0],1,\"Broadcast Channel API\"],[0,[],0,\" do przesyłania danych między kartami lub oknami przeglądarki bez wykorzystania serwera i socketów.\"]]],[1,\"h2\",[[0,[],0,\"Parcel Bundler - intuicyjny i prosty builder \"]]],[1,\"p\",[[0,[],0,\"Jak zwykle prezentujemy kod od początku do końca. Zaczniemy od instalacji parcela - najprostszego bundler w świecie JS działającego out of the box w przeciwieństwie do webpacka, którego konfiguracja jest po prostu nudna. Parcela instalujemy komendą:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Tworzymy pliki \"],[0,[0],1,\"html\"],[0,[],0,\" i \"],[0,[0],1,\"ts\"],[0,[],0,\" poleceniami:\"]]],[10,1],[1,\"p\",[[0,[],0,\"I włączamy nasz serwer\"]]],[10,2],[1,\"h2\",[[0,[],0,\"Podstawy działania Broadcast Channel API\"]]],[1,\"p\",[[0,[],0,\"Pokażemy teraz jak w konsoli przeglądarki zobaczyć najprostsze działanie Broadcast Channel Api. W pliku \"],[0,[0],1,\"index.ts\"],[0,[],0,\" inicjalizujemy kanał.\"]]],[10,3],[1,\"p\",[[0,[],0,\"Następnie przypiszemy naszej karcie w przeglądarce losowe ID\"]]],[10,4],[1,\"p\",[[0,[],0,\"Oraz zapiszemy w pamięci liczniki wiadomości wysłanych i odebranych\"]]],[10,5],[1,\"p\",[[0,[],0,\"Jako wiadomość powitalną wyświetlimy id wybrane dla naszej karty\"]]],[10,6],[1,\"p\",[[0,[],0,\"Następnie ustawiamy nasłuch na wiadomości\"]]],[10,7],[1,\"p\",[[0,[],0,\"Podnosimy w nim licznik wiadomości odebranych oraz pokazujemy przysłane dane oraz wartości liczników w danej karcie.\"]]],[1,\"p\",[[0,[],0,\"Teraz czas na wysyłanie wiadomości do kanału. Służą do tego funkcje \"],[0,[0],1,\"postMessage\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Chwilę po włączeniu karty chcemy wysłać wiadomość powitalną do innych kart\"]]],[10,8],[1,\"p\",[[0,[],0,\"Timeout pozwala poczekać na to, żeby inne karty się przeładowały. Gdyby nie on, to na kartach które nie są gotowe kiedy ta wiadomość jest wysyłana nie zobaczyli byśmy console loga.\"]]],[1,\"p\",[[0,[],0,\"Następnie chcemy wysłać jeszcze dwie wiadomości, które przestawią nam liczniki wysłań \"]]],[10,9],[1,\"p\",[[0,[],0,\"Przy okazji użyliśmy tu innego API - performance:\"]]],[10,10],[1,\"p\",[[0,[],0,\"Dla dwóch kart w możemy zobaczyć, że w każdej karcie widać jej odrębny identyfikator i wiadomości wysłane z przeciwnej karty.\"]]],[10,11],[1,\"p\",[[0,[],0,\"Nic nie stoi na przeszkodzie, żebyśmy włączyli cztery karty na raz. Wtedy wiadomości od trzech pozostałych w każdej z nich będą się wzajemnie przeplatać.\"]]],[10,12],[1,\"p\",[[0,[],0,\"Możemy wrócić do dwóch kart i odświeżyć kilka razy tą z prawej strony. W wyniku takiego działania ta po lewej dostanie kilkukrotnie nowe powiadomienia, a na tej prawej nie będzie widać nic poza jej własnym przedstawieniem się ponieważ lewa karta zakończyła już nadawanie wiadomości. Konkretny wynik odświeżania prawej karty przedstawia screenshot:\"]]],[10,13],[1,\"p\",[[0,[],0,\"Widzimy tu, że wiadomości pochodzą od różnych ID, bo karta po prawej zmienia ID przy każdym odświeżeniu.\"]]],[1,\"p\",[[0,[],0,\"Kolejny eksperyment to sprawdzenie czy Broad Cast Channel działa między różnymi przeglądarkami:\"]]],[10,14],[1,\"p\",[[0,[],0,\"Okazało się, że nie. Ma to sens, bo jeśli miało by działać między przeglądarkami, to musiała by istnieć komunikacja między procesami utrzymującymi przeglądarki.\"]]],[1,\"h2\",[[0,[],0,\"Zasada Same Origin\"]]],[1,\"p\",[[0,[],0,\"Broadcast Channel ma zasięg działania w dla wszystkich kart, przeglądarek, iframes w ramach tego samego Origin czyli schematu (protokołu), hosta i portu. \"]]],[1,\"p\",[[0,[],0,\"Więcej o samym Origin możemy przeczytać w słowniku Mozilla Developers\"]]],[10,15],[1,\"p\",[[0,[],0,\"Sprawdzimy czy dla różnych komputerów też będzie działał poprawnie. W tym celu musimy zmienić ustawienia parcela, bo obecnie wystawia on nasz serwis na localhost\"]]],[10,16],[1,\"p\",[[0,[],0,\"Nasz obecny adres IP możemy sprawdzić poleceniem\"]]],[10,17],[10,18],[1,\"p\",[]],[1,\"p\",[[0,[],0,\"Z dokumentacji możemy wyczytać, że wystarczy dodanie flagi \"],[0,[0],1,\"--host\"]]],[10,19],[10,20],[10,21],[1,\"p\",[[0,[],0,\"Okazało się, że komunikacja nie jest przesyłana między różnymi komputerami.\"]]],[1,\"p\",[[0,[],0,\"Jest to zgodne z intuicją. O ile w przypadku Web Socketów istnieje jakiś serwer do utrzymywania (czy nawet WebRCT do samego nawiązywania) połączenia, to tutaj jedyną warstwą transportu danych jest pamięć operacyjna komputera na którym używany jest Broadcast Channel.\"]]],[1,\"h2\",[[0,[],0,\"Broadcast Channel API a Shared Workers, Message Channel i post Message\"]]],[1,\"p\",[[0,[],0,\"Być może zastanawiasz się jaka jest różnica między omawianym API a innymi metodami komunikacji między kontekstami jak:\"]]],[3,\"ul\",[[[0,[],0,\"Shared Workers\"]],[[0,[],0,\"Message Channel\"]],[[0,[],0,\"window.postMessage()\"]]]],[1,\"p\",[[0,[],0,\"W przypadku SharedWorkers możesz zrobić to samo co za pomocą BroadcastChannel ale wymaga to większej ilości kodu. Zalecam używanie SharedWorkers do bardziej zaawansowanych zdań jak zarządzanie blokadami, współdzielenie stanu, synchronizacja zasobów czy dzielenie połączenia WebSocket między kartami.\"]]],[1,\"p\",[[0,[],0,\"Natomiast Broadcast Channel Api jest wygodniejsze w prostych przypadkach, kiedy chcemy wysłać wiadomość do wszystkich okien, zakładek lub workerów.  \"]]],[1,\"p\",[[0,[],0,\"Co do MessageChannel API to główna różnica polega na tym, że w MessageChannel API wysyła się wiadomość do jednego odbiorcy, podczas gdy w Broadcast Channel wysyłający jest jeden, a odbiorcami są zawsze wszystkie pozostałe konteksty.\"]]],[1,\"p\",[[0,[],0,\"W window.postMessage wymagane jest z kolei utrzymywanie referencji do obiektu iframe lub workera, żeby nadawać komunikację, na przykład:\"]]],[10,22],[1,\"p\",[[0,[],0,\"Z drugiej strony trzeba też pilnować, żeby przy odbieraniu sprawdzić źródło wiadomości ze względów bezpieczeństwa:\"]]],[10,23],[1,\"p\",[[0,[],0,\"Pod tym względem Broadcast Channel jest bardziej ograniczony, bo nie pozwala na komunikację między różnymi Origin, ale zapewnia to domyślnie wyższe bezpieczeństwo. Z drugiej strony window.postMessage nie pozwalał na wysyłkę do innych okien bo nie można do nich było złapać referencji.\"]]],[1,\"h2\",[[0,[],0,\"Rysowanie na Canvas w niezależnych kartach\"]]],[1,\"p\",[[0,[],0,\"Czas na praktyczny przykład. No może nie super użyteczny, ale za to dobrze prezentujący możliwości Broadcast Channel API.\"]]],[1,\"p\",[[0,[],0,\"Zaprogramujemy aplikację pozwalającą na przenoszenie rysowanych kształtów na płótnie między kartami przeglądarki.\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od zwykłego rysowania myszką na canvas. W tym celu zmienimy nasz kod \"],[0,[0],1,\"index.html\"],[0,[],0,\" dodając do niego płótno i niezbędne style\"]]],[10,24],[1,\"p\",[[0,[],0,\"W skrypcie \"],[0,[0],1,\"index.ts\"],[0,[],0,\" wpisujemy\"]]],[10,25],[1,\"p\",[[0,[],0,\"Pozwoli nam to na trzymanie canvasu w oknie. Aby nie wyszukiwać go wiele razy możemy użyć \"],[0,[0],1,\"window\"],[0,[],0,\" jako cache w którym będziemy go trzymać po pierwszym znalezieniu.\"]]],[10,26],[1,\"p\",[[0,[],0,\"W celu dostrojenia wielkości canvasu deklarujemy funkcję \"],[0,[0],1,\"syncCanvasSize\"]]],[10,27],[1,\"p\",[[0,[],0,\"Wykonamy ją przy każdym evencie \"],[0,[0],1,\"resize\"],[0,[],0,\" na \"],[0,[0],1,\"window\"],[0,[],0,\" oraz po załadowaniu strony\"]]],[10,28],[1,\"p\",[[0,[],0,\"Definiujemy kilka parametrów do określania stanu i historii kursora.\"]]],[10,29],[1,\"p\",[[0,[],0,\"Następnie definiujemy funkcje \"],[0,[0],1,\"drawLine\"],[0,[],0,\" rysującą linię oraz \"],[0,[0],1,\"drawDot\"],[0,[],0,\" rysującą kropkę\"]]],[10,30],[1,\"p\",[[0,[],0,\"Oraz najważniejszą funkcję \"],[0,[0],1,\"findPosition\"],[0,[],0,\" - sterującą logiką rysowania\"]]],[10,31],[1,\"p\",[[0,[],0,\"Na końcu dodajemy nasłuch na wydarzenia powiązane z myszą aby używać funkcji \"],[0,[0],1,\"findPosition\"]]],[10,32],[1,\"p\",[[0,[],0,\"Powyższy kod pozwala nam to na rysowanie na canvasie w ramach pojedynczej karty. Żeby było możliwe przenoszenie obrazu między kartami wykorzystamy Broadcast Channel. \"]]],[1,\"p\",[[0,[],0,\"Wymagana będzie jego inicjalizacja:\"]]],[10,33],[1,\"p\",[[0,[],0,\"Dodanie nasłuchu na polecenie \"],[0,[0],1,\"findPosition\"],[0,[],0,\".\"]]],[10,34],[1,\"p\",[[0,[],0,\"Do samej funkcji \"],[0,[0],1,\"findPosition\"],[0,[],0,\" dodaliśmy trzeci argument - \"],[0,[0],1,\"propagate\"],[0,[],0,\" mówiący czy wywołanie tej funkcji ma powodować wysłanie wiadomości do kanału. Wartość \"],[0,[0],1,\"false\"],[0,[],0,\" pozwala unikną nieskończonego zagnieżdżenia.\"]]],[1,\"p\",[[0,[],0,\"Na końcu zmieniamy sygnaturę samej funkcji \"],[0,[0],1,\"findPosition\"],[0,[],0,\" tak jak to opisaliśmy i dodajemy fragment kodu odpowiedzialny za wysyłkę wiadomości do innych kart\"]]],[10,35],[1,\"p\",[[0,[],0,\"Warto zauważyć, że nie przekazujemy tu pełnych obiektów \"],[0,[0],1,\"event\"],[0,[],0,\" a jedynie współrzędne. Jest to nie tylko optymalizacja. Klonowanie takich obiektów jak Event nie jest możliwe między kontekstami.\"]]],[1,\"p\",[[0,[],0,\"Cały kod zawarty w \"],[0,[0],1,\"index.ts\"],[0,[],0,\" prezentuję poniżej:\"]]],[10,36],[1,\"p\",[[0,[],0,\"Aplikacja działa tak, że obraz rysowany w jednej karcie pojawia się we wszystkich pozostałych:\"]]],[10,37],[1,\"h2\",[[0,[],0,\"Zastosowania Broadcast Channel API\"]]],[1,\"p\",[[0,[],0,\"Przykładowa aplikacja pokazuje, że broadcast channel może być stosowany w bardzo wygodny sposób. Zapewnienie synchronizacji między kartami zostało wprowadzone przez dodanie 9 linii kodu z czego 3 to domknięcia nawiasów klamrowych.\"]]],[1,\"p\",[[0,[],0,\"Jego przykładowe zastosowania to:\"]]],[3,\"ul\",[[[0,[],0,\"Wykrywanie akcji użytkownika w innych zakładkach\"]],[[0,[],0,\"Sprawdzanie kiedy użytkownik zalogował się na swoje konto w innej zakładce lub oknie\"]],[[0,[],0,\"Zlecenie Workerom wykonania jakichś zadań w tle\"]],[[0,[],0,\"Rozsyłanie zdjęć załadowanych przez użytkownika w innych kartach\"]]]],[1,\"p\",[[0,[],0,\"Jeśli potrzebujemy komunikacji między komputerami to Broadcast Channel API nam nie pomoże i wtedy do komunikacji w czasie rzeczywistym należy użyć WebSockets lub WebRTC.\"]]],[1,\"p\",[[0,[],0,\"Polecane materiały oraz dokumentacja:\"]]],[10,38],[10,39],[10,40],[1,\"p\",[[0,[],0,\" \"]]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Nauczymy się jak używać <code>Broadcast Channel API</code> do przesyłania danych między kartami lub oknami przeglądarki bez wykorzystania serwera i socketów.</p><h2 id=\"parcel-bundlerintuicyjny-i-prosty-builder\">Parcel Bundler - intuicyjny i prosty builder </h2><p>Jak zwykle prezentujemy kod od początku do końca. Zaczniemy od instalacji parcela - najprostszego bundler w świecie JS działającego out of the box w przeciwieństwie do webpacka, którego konfiguracja jest po prostu nudna. Parcela instalujemy komendą:</p><pre><code>npm install -g parcel-bundler</code></pre><p>Tworzymy pliki <code>html</code> i <code>ts</code> poleceniami:</p><pre><code>echo '&lt;html&gt;&lt;body&gt;&lt;script src=\"./index.ts\"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;' &gt; index.html\ntouch index.ts</code></pre><p>I włączamy nasz serwer</p><pre><code>parcel index.html</code></pre><h2 id=\"podstawy-dzia%C5%82ania-broadcast-channel-api\">Podstawy działania Broadcast Channel API</h2><p>Pokażemy teraz jak w konsoli przeglądarki zobaczyć najprostsze działanie Broadcast Channel Api. W pliku <code>index.ts</code> inicjalizujemy kanał.</p><pre><code>const bc = new BroadcastChannel('channel');</code></pre><p>Następnie przypiszemy naszej karcie w przeglądarce losowe ID</p><pre><code>const id = Math.random();</code></pre><p>Oraz zapiszemy w pamięci liczniki wiadomości wysłanych i odebranych</p><pre><code>let send = 0, received = 0;</code></pre><p>Jako wiadomość powitalną wyświetlimy id wybrane dla naszej karty</p><pre><code>console.log(\"START\", id);</code></pre><p>Następnie ustawiamy nasłuch na wiadomości</p><pre><code>bc.onmessage = (e) =&gt; {\n    console.log(e.data, send, received);\n    received++;\n}</code></pre><p>Podnosimy w nim licznik wiadomości odebranych oraz pokazujemy przysłane dane oraz wartości liczników w danej karcie.</p><p>Teraz czas na wysyłanie wiadomości do kanału. Służą do tego funkcje <code>postMessage</code>.</p><p>Chwilę po włączeniu karty chcemy wysłać wiadomość powitalną do innych kart</p><pre><code>setTimeout(() =&gt; {\n    bc.postMessage({title: `Connection from ${id}`})\n}, 250)</code></pre><p>Timeout pozwala poczekać na to, żeby inne karty się przeładowały. Gdyby nie on, to na kartach które nie są gotowe kiedy ta wiadomość jest wysyłana nie zobaczyli byśmy console loga.</p><p>Następnie chcemy wysłać jeszcze dwie wiadomości, które przestawią nam liczniki wysłań </p><pre><code>const i = setInterval(() =&gt; {\n    const uptime = performance.now();\n    bc.postMessage({id, uptime, send, received})\n    send++;\n    if (uptime &gt; 1e3) clearInterval(i)\n}, 500)</code></pre><p>Przy okazji użyliśmy tu innego API - performance:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://developer.mozilla.org/en-US/docs/Web/API/Performance\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Performance - Web APIs | MDN</div><div class=\"kg-bookmark-description\">The Performance interface provides access to performance-related information for the current page. It’s part of the High Resolution Time API, but is enhanced by the Performance Timeline API, the Navigation Timing API, the User Timing API, and the Resource Timing API.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://developer.mozilla.org/apple-touch-icon.0ea0fa02.png\"><span class=\"kg-bookmark-author\">MDN</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://developer.mozilla.org/mdn-social-share.0ca9dbda.png\"></div></a></figure><p>Dla dwóch kart w możemy zobaczyć, że w każdej karcie widać jej odrębny identyfikator i wiadomości wysłane z przeciwnej karty.</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-01-56-23.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1873\" height=\"201\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-07-01-56-23.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-07-01-56-23.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/07/Screenshot-from-2021-07-07-01-56-23.png 1600w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-01-56-23.png 1873w\"></figure><p>Nic nie stoi na przeszkodzie, żebyśmy włączyli cztery karty na raz. Wtedy wiadomości od trzech pozostałych w każdej z nich będą się wzajemnie przeplatać.</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-01-57-17.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1866\" height=\"916\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-07-01-57-17.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-07-01-57-17.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/07/Screenshot-from-2021-07-07-01-57-17.png 1600w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-01-57-17.png 1866w\"></figure><p>Możemy wrócić do dwóch kart i odświeżyć kilka razy tą z prawej strony. W wyniku takiego działania ta po lewej dostanie kilkukrotnie nowe powiadomienia, a na tej prawej nie będzie widać nic poza jej własnym przedstawieniem się ponieważ lewa karta zakończyła już nadawanie wiadomości. Konkretny wynik odświeżania prawej karty przedstawia screenshot:</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-02-12-15.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1861\" height=\"417\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-07-02-12-15.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-07-02-12-15.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/07/Screenshot-from-2021-07-07-02-12-15.png 1600w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-02-12-15.png 1861w\"></figure><p>Widzimy tu, że wiadomości pochodzą od różnych ID, bo karta po prawej zmienia ID przy każdym odświeżeniu.</p><p>Kolejny eksperyment to sprawdzenie czy Broad Cast Channel działa między różnymi przeglądarkami:</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-09-38-48.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1896\" height=\"581\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-07-09-38-48.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-07-09-38-48.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/07/Screenshot-from-2021-07-07-09-38-48.png 1600w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-09-38-48.png 1896w\"></figure><p>Okazało się, że nie. Ma to sens, bo jeśli miało by działać między przeglądarkami, to musiała by istnieć komunikacja między procesami utrzymującymi przeglądarki.</p><h2 id=\"zasada-same-origin\">Zasada Same Origin</h2><p>Broadcast Channel ma zasięg działania w dla wszystkich kart, przeglądarek, iframes w ramach tego samego Origin czyli schematu (protokołu), hosta i portu. </p><p>Więcej o samym Origin możemy przeczytać w słowniku Mozilla Developers</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://developer.mozilla.org/en-US/docs/Glossary/Origin\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Origin - MDN Web Docs Glossary: Definitions of Web-related terms | MDN</div><div class=\"kg-bookmark-description\">Web content’s origin is defined by the scheme (protocol), hostname (domain), and port of the URL used to access it. Two objects have the same origin only when the scheme, hostname, and port all match.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://developer.mozilla.org/apple-touch-icon.0ea0fa02.png\"><span class=\"kg-bookmark-author\">MDN</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://developer.mozilla.org/mdn-social-share.0ca9dbda.png\"></div></a></figure><p>Sprawdzimy czy dla różnych komputerów też będzie działał poprawnie. W tym celu musimy zmienić ustawienia parcela, bo obecnie wystawia on nasz serwis na localhost</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-02-16-02.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"361\" height=\"62\"></figure><p>Nasz obecny adres IP możemy sprawdzić poleceniem</p><pre><code>ip route</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-08-20-47.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"477\" height=\"100\"></figure><p></p><p>Z dokumentacji możemy wyczytać, że wystarczy dodanie flagi <code>--host</code></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://parceljs.org/cli.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">? CLI</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://parceljs.org/assets/favicon.ico\"><span class=\"kg-bookmark-author\">Parcel</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://parceljs.org/assets/parcel.png\"></div></a></figure><pre><code>parce index.html --host 192.168.2.162</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-07-08-21-16.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"479\" height=\"57\"></figure><p>Okazało się, że komunikacja nie jest przesyłana między różnymi komputerami.</p><p>Jest to zgodne z intuicją. O ile w przypadku Web Socketów istnieje jakiś serwer do utrzymywania (czy nawet WebRCT do samego nawiązywania) połączenia, to tutaj jedyną warstwą transportu danych jest pamięć operacyjna komputera na którym używany jest Broadcast Channel.</p><h2 id=\"broadcast-channel-api-a-shared-workers-message-channel-i-post-message\">Broadcast Channel API a Shared Workers, Message Channel i post Message</h2><p>Być może zastanawiasz się jaka jest różnica między omawianym API a innymi metodami komunikacji między kontekstami jak:</p><ul><li>Shared Workers</li><li>Message Channel</li><li>window.postMessage()</li></ul><p>W przypadku SharedWorkers możesz zrobić to samo co za pomocą BroadcastChannel ale wymaga to większej ilości kodu. Zalecam używanie SharedWorkers do bardziej zaawansowanych zdań jak zarządzanie blokadami, współdzielenie stanu, synchronizacja zasobów czy dzielenie połączenia WebSocket między kartami.</p><p>Natomiast Broadcast Channel Api jest wygodniejsze w prostych przypadkach, kiedy chcemy wysłać wiadomość do wszystkich okien, zakładek lub workerów.  </p><p>Co do MessageChannel API to główna różnica polega na tym, że w MessageChannel API wysyła się wiadomość do jednego odbiorcy, podczas gdy w Broadcast Channel wysyłający jest jeden, a odbiorcami są zawsze wszystkie pozostałe konteksty.</p><p>W window.postMessage wymagane jest z kolei utrzymywanie referencji do obiektu iframe lub workera, żeby nadawać komunikację, na przykład:</p><pre><code>const popup = window.open('https://another-origin.com', ...);\npopup.postMessage('Sup popup!', 'https://another-origin.com');</code></pre><p>Z drugiej strony trzeba też pilnować, żeby przy odbieraniu sprawdzić źródło wiadomości ze względów bezpieczeństwa:</p><pre><code>const iframe = document.querySelector('iframe');\niframe.contentWindow.onmessage = function(e) {\n  if (e.origin !== 'https://expected-origin.com') {\n    return;\n  }\n  e.source.postMessage('Ack!', e.origin);\n};</code></pre><p>Pod tym względem Broadcast Channel jest bardziej ograniczony, bo nie pozwala na komunikację między różnymi Origin, ale zapewnia to domyślnie wyższe bezpieczeństwo. Z drugiej strony window.postMessage nie pozwalał na wysyłkę do innych okien bo nie można do nich było złapać referencji.</p><h2 id=\"rysowanie-na-canvas-w-niezale%C5%BCnych-kartach\">Rysowanie na Canvas w niezależnych kartach</h2><p>Czas na praktyczny przykład. No może nie super użyteczny, ale za to dobrze prezentujący możliwości Broadcast Channel API.</p><p>Zaprogramujemy aplikację pozwalającą na przenoszenie rysowanych kształtów na płótnie między kartami przeglądarki.</p><p>Zaczniemy od zwykłego rysowania myszką na canvas. W tym celu zmienimy nasz kod <code>index.html</code> dodając do niego płótno i niezbędne style</p><pre><code>&lt;html lang=\"en\"&gt;\n&lt;body style=\"margin:0;\"&gt;\n&lt;canvas id=\"canvas\" style=\"width: 100vw; height: 100vh;\"&gt;&lt;/canvas&gt;\n&lt;script src=\"./index.ts\"&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;</code></pre><p>W skrypcie <code>index.ts</code> wpisujemy</p><pre><code>interface Window {\n    canvas?: HTMLCanvasElement;\n}</code></pre><p>Pozwoli nam to na trzymanie canvasu w oknie. Aby nie wyszukiwać go wiele razy możemy użyć <code>window</code> jako cache w którym będziemy go trzymać po pierwszym znalezieniu.</p><pre><code>const getCanvasAndCtx = (): { canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D } =&gt; {\n    const canvas = window.canvas || document.querySelector('#canvas');\n    if (canvas instanceof HTMLCanvasElement) {\n        window.canvas = canvas;\n        const ctx = canvas.getContext('2d');\n        if(ctx) {\n            return {canvas, ctx}\n        } else {\n            throw new Error('Canvas do not have context');\n        }\n    }\n    throw new Error('Canvas Not found');\n}</code></pre><p>W celu dostrojenia wielkości canvasu deklarujemy funkcję <code>syncCanvasSize</code></p><pre><code>const syncCanvasSize = () =&gt; {\n    const { canvas } = getCanvasAndCtx()\n    canvas.height = window.innerHeight;\n    canvas.width = window.innerWidth;\n}</code></pre><p>Wykonamy ją przy każdym evencie <code>resize</code> na <code>window</code> oraz po załadowaniu strony</p><pre><code>window.addEventListener('resize', syncCanvasSize)\n\nwindow.addEventListener('DOMContentLoaded', () =&gt; {\n    syncCanvasSize();\n    const {canvas, ctx} = getCanvasAndCtx()</code></pre><p>Definiujemy kilka parametrów do określania stanu i historii kursora.</p><pre><code>    let flag = false,\n        prevX = 0,\n        currX = 0,\n        prevY = 0,\n        currY = 0;</code></pre><p>Następnie definiujemy funkcje <code>drawLine</code> rysującą linię oraz <code>drawDot</code> rysującą kropkę</p><pre><code>    function drawLine() {\n        ctx.beginPath();\n        ctx.moveTo(prevX, prevY);\n        ctx.lineTo(currX, currY);\n        ctx.strokeStyle = \"black\";\n        ctx.lineWidth = 2;\n        ctx.stroke();\n        ctx.closePath();\n    }\n\n    function drawDot() {\n        ctx.beginPath();\n        ctx.fillStyle = 'black';\n        ctx.fillRect(currX, currY, 2, 2);\n        ctx.closePath();\n    }</code></pre><p>Oraz najważniejszą funkcję <code>findPosition</code> - sterującą logiką rysowania</p><pre><code>    function findPosition(res: EventType, e: { clientX: number, clientY: number }) {\n        if (res == EventType.down) {\n            prevX = currX;\n            prevY = currY;\n            currX = e.clientX;\n            currY = e.clientY;\n            flag = true;\n            drawDot()\n        }\n        if ([EventType.up, EventType.out].includes(res)) {\n            flag = false;\n        }\n        if (res == EventType.move) {\n            if (flag) {\n                prevX = currX;\n                prevY = currY;\n                currX = e.clientX;\n                currY = e.clientY;\n                drawLine();\n            }\n        }\n    }</code></pre><p>Na końcu dodajemy nasłuch na wydarzenia powiązane z myszą aby używać funkcji <code>findPosition</code></p><pre><code>    canvas.addEventListener(\"mousemove\", (e) =&gt; {\n        findPosition(EventType.move, e)\n    });\n    canvas.addEventListener(\"mousedown\", (e) =&gt; {\n        findPosition(EventType.down, e)\n    });\n    canvas.addEventListener(\"mouseup\", (e) =&gt; {\n        findPosition(EventType.up, e)\n    });\n    canvas.addEventListener(\"mouseout\", (e) =&gt; {\n        findPosition(EventType.out, e)\n    });\n\n})</code></pre><p>Powyższy kod pozwala nam to na rysowanie na canvasie w ramach pojedynczej karty. Żeby było możliwe przenoszenie obrazu między kartami wykorzystamy Broadcast Channel. </p><p>Wymagana będzie jego inicjalizacja:</p><pre><code>const bc = new BroadcastChannel('channel');</code></pre><p>Dodanie nasłuchu na polecenie <code>findPosition</code>.</p><pre><code>bc.onmessage = (e) =&gt; {\n\tif(e.data.cmd === 'findPosition') {\n\t\tfindPosition(e.data.args[0], e.data.args[1], false)\n\t}\n}</code></pre><p>Do samej funkcji <code>findPosition</code> dodaliśmy trzeci argument - <code>propagate</code> mówiący czy wywołanie tej funkcji ma powodować wysłanie wiadomości do kanału. Wartość <code>false</code> pozwala unikną nieskończonego zagnieżdżenia.</p><p>Na końcu zmieniamy sygnaturę samej funkcji <code>findPosition</code> tak jak to opisaliśmy i dodajemy fragment kodu odpowiedzialny za wysyłkę wiadomości do innych kart</p><pre><code>function findPosition(res: EventType, e: {clientX: number, clientY: number}, propagate: boolean) {\n\n    if(propagate) {\n        bc.postMessage({cmd: 'findPosition', args: [res, {clientX: e.clientX, clientY: e.clientY}]})\n        }</code></pre><p>Warto zauważyć, że nie przekazujemy tu pełnych obiektów <code>event</code> a jedynie współrzędne. Jest to nie tylko optymalizacja. Klonowanie takich obiektów jak Event nie jest możliwe między kontekstami.</p><p>Cały kod zawarty w <code>index.ts</code> prezentuję poniżej:</p><pre><code>interface Window {\n    canvas?: HTMLCanvasElement;\n}\n\nconst getCanvasAndCtx = (): { canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D } =&gt; {\n    const canvas = window.canvas || document.querySelector('#canvas');\n    if (canvas instanceof HTMLCanvasElement) {\n        window.canvas = canvas;\n        const ctx = canvas.getContext('2d');\n        if(ctx) {\n            return {canvas, ctx}\n        } else {\n            throw new Error('Canvas do not have context');\n        }\n    }\n    throw new Error('Canvas Not found');\n}\n\nconst syncCanvasSize = () =&gt; {\n    const {canvas} = getCanvasAndCtx()\n    canvas.height = window.innerHeight;\n    canvas.width = window.innerWidth;\n}\n\nwindow.addEventListener('resize', syncCanvasSize)\n\nenum EventType {\n    down,\n    up,\n    move,\n    out\n}\n\nwindow.addEventListener('DOMContentLoaded', () =&gt; {\n    syncCanvasSize();\n    const {canvas, ctx} = getCanvasAndCtx()\n\n    let flag = false,\n        prevX = 0,\n        currX = 0,\n        prevY = 0,\n        currY = 0;\n\n    const bc = new BroadcastChannel('channel');\n\n    function drawLine() {\n        ctx.beginPath();\n        ctx.moveTo(prevX, prevY);\n        ctx.lineTo(currX, currY);\n        ctx.strokeStyle = \"black\";\n        ctx.lineWidth = 2;\n        ctx.stroke();\n        ctx.closePath();\n    }\n\n    function drawDot() {\n        ctx.beginPath();\n        ctx.fillStyle = 'black';\n        ctx.fillRect(currX, currY, 2, 2);\n        ctx.closePath();\n    }\n\n    function findPosition(res: EventType, e: { clientX: number, clientY: number }, propagate: boolean) {\n\n        if (propagate) {\n            bc.postMessage({cmd: 'findPosition', args: [res, {clientX: e.clientX, clientY: e.clientY}]})\n        }\n\n        if (res == EventType.down) {\n            prevX = currX;\n            prevY = currY;\n            currX = e.clientX;\n            currY = e.clientY;\n            flag = true;\n            drawDot()\n        }\n        if ([EventType.up, EventType.out].includes(res)) {\n            flag = false;\n        }\n        if (res == EventType.move) {\n            if (flag) {\n                prevX = currX;\n                prevY = currY;\n                currX = e.clientX;\n                currY = e.clientY;\n                drawLine();\n            }\n        }\n    }\n\n    canvas.addEventListener(\"mousemove\", (e) =&gt; {\n        findPosition(EventType.move, e, true)\n    });\n    canvas.addEventListener(\"mousedown\", (e) =&gt; {\n        findPosition(EventType.down, e, true)\n    });\n    canvas.addEventListener(\"mouseup\", (e) =&gt; {\n        findPosition(EventType.up, e, true)\n    });\n    canvas.addEventListener(\"mouseout\", (e) =&gt; {\n        findPosition(EventType.out, e, true)\n    });\n\n    bc.onmessage = (e) =&gt; {\n        if (e.data.cmd === 'findPosition') {\n            findPosition(e.data.args[0], e.data.args[1], false)\n        }\n    }\n\n})</code></pre><p>Aplikacja działa tak, że obraz rysowany w jednej karcie pojawia się we wszystkich pozostałych:</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"150\" src=\"https://www.youtube.com/embed/BPnzdw8Nryk?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><h2 id=\"zastosowania-broadcast-channel-api\">Zastosowania Broadcast Channel API</h2><p>Przykładowa aplikacja pokazuje, że broadcast channel może być stosowany w bardzo wygodny sposób. Zapewnienie synchronizacji między kartami zostało wprowadzone przez dodanie 9 linii kodu z czego 3 to domknięcia nawiasów klamrowych.</p><p>Jego przykładowe zastosowania to:</p><ul><li>Wykrywanie akcji użytkownika w innych zakładkach</li><li>Sprawdzanie kiedy użytkownik zalogował się na swoje konto w innej zakładce lub oknie</li><li>Zlecenie Workerom wykonania jakichś zadań w tle</li><li>Rozsyłanie zdjęć załadowanych przez użytkownika w innych kartach</li></ul><p>Jeśli potrzebujemy komunikacji między komputerami to Broadcast Channel API nam nie pomoże i wtedy do komunikacji w czasie rzeczywistym należy użyć WebSockets lub WebRTC.</p><p>Polecane materiały oraz dokumentacja:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://developer.mozilla.org/en-US/docs/Web/API/Broadcast_Channel_API\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Broadcast Channel API - Web APIs | MDN</div><div class=\"kg-bookmark-description\">The Broadcast Channel API allows basic communication between browsing contexts (that is, windows, tabs, frames, or iframes) and workers on the same origin.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://developer.mozilla.org/apple-touch-icon.0ea0fa02.png\"><span class=\"kg-bookmark-author\">MDN</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://developer.mozilla.org/mdn-social-share.0ca9dbda.png\"></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://developers.google.com/web/updates/2016/09/broadcastchannel\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">BroadcastChannel API: A Message Bus for the Web | Google Developers</div><div class=\"kg-bookmark-description\">BroadcastChannel API can be used for simple pub/sub between windows, tabs, iframes, or workers.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.gstatic.com/devrel-devsite/prod/v5f61782021051fb502364887a46a1c5ce2cd6f3d29a3549e907afe67612e9bba/developers/images/touchicon-180.png\"><span class=\"kg-bookmark-author\">Google Developers</span><span class=\"kg-bookmark-publisher\">Eric Bidelman</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://developers.google.com/web/images/social-webfu-16x9.png\"></div></a></figure><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/wYcvzLFHFN0?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p> </p>",
            "comment_id": "60e4e4c1ae5f887e4011818a",
            "plaintext": "Nauczymy się jak używać Broadcast Channel API do przesyłania danych między\nkartami lub oknami przeglądarki bez wykorzystania serwera i socketów.\n\nParcel Bundler - intuicyjny i prosty builder \nJak zwykle prezentujemy kod od początku do końca. Zaczniemy od instalacji\nparcela - najprostszego bundler w świecie JS działającego out of the box w\nprzeciwieństwie do webpacka, którego konfiguracja jest po prostu nudna. Parcela\ninstalujemy komendą:\n\nnpm install -g parcel-bundler\n\nTworzymy pliki html i ts poleceniami:\n\necho '<html><body><script src=\"./index.ts\"></script></body></html>' > index.html\ntouch index.ts\n\nI włączamy nasz serwer\n\nparcel index.html\n\nPodstawy działania Broadcast Channel API\nPokażemy teraz jak w konsoli przeglądarki zobaczyć najprostsze działanie\nBroadcast Channel Api. W pliku index.ts inicjalizujemy kanał.\n\nconst bc = new BroadcastChannel('channel');\n\nNastępnie przypiszemy naszej karcie w przeglądarce losowe ID\n\nconst id = Math.random();\n\nOraz zapiszemy w pamięci liczniki wiadomości wysłanych i odebranych\n\nlet send = 0, received = 0;\n\nJako wiadomość powitalną wyświetlimy id wybrane dla naszej karty\n\nconsole.log(\"START\", id);\n\nNastępnie ustawiamy nasłuch na wiadomości\n\nbc.onmessage = (e) => {\n    console.log(e.data, send, received);\n    received++;\n}\n\nPodnosimy w nim licznik wiadomości odebranych oraz pokazujemy przysłane dane\noraz wartości liczników w danej karcie.\n\nTeraz czas na wysyłanie wiadomości do kanału. Służą do tego funkcje postMessage.\n\nChwilę po włączeniu karty chcemy wysłać wiadomość powitalną do innych kart\n\nsetTimeout(() => {\n    bc.postMessage({title: `Connection from ${id}`})\n}, 250)\n\nTimeout pozwala poczekać na to, żeby inne karty się przeładowały. Gdyby nie on,\nto na kartach które nie są gotowe kiedy ta wiadomość jest wysyłana nie zobaczyli\nbyśmy console loga.\n\nNastępnie chcemy wysłać jeszcze dwie wiadomości, które przestawią nam liczniki\nwysłań \n\nconst i = setInterval(() => {\n    const uptime = performance.now();\n    bc.postMessage({id, uptime, send, received})\n    send++;\n    if (uptime > 1e3) clearInterval(i)\n}, 500)\n\nPrzy okazji użyliśmy tu innego API - performance:\n\nPerformance - Web APIs | MDNThe Performance interface provides access to\nperformance-related information for the current page. It’s part of the High\nResolution Time API, but is enhanced by the Performance Timeline API, the\nNavigation Timing API, the User Timing API, and the Resource Timing API.MDN\n[https://developer.mozilla.org/en-US/docs/Web/API/Performance]Dla dwóch kart w\nmożemy zobaczyć, że w każdej karcie widać jej odrębny identyfikator i wiadomości\nwysłane z przeciwnej karty.\n\nNic nie stoi na przeszkodzie, żebyśmy włączyli cztery karty na raz. Wtedy\nwiadomości od trzech pozostałych w każdej z nich będą się wzajemnie przeplatać.\n\nMożemy wrócić do dwóch kart i odświeżyć kilka razy tą z prawej strony. W wyniku\ntakiego działania ta po lewej dostanie kilkukrotnie nowe powiadomienia, a na tej\nprawej nie będzie widać nic poza jej własnym przedstawieniem się ponieważ lewa\nkarta zakończyła już nadawanie wiadomości. Konkretny wynik odświeżania prawej\nkarty przedstawia screenshot:\n\nWidzimy tu, że wiadomości pochodzą od różnych ID, bo karta po prawej zmienia ID\nprzy każdym odświeżeniu.\n\nKolejny eksperyment to sprawdzenie czy Broad Cast Channel działa między różnymi\nprzeglądarkami:\n\nOkazało się, że nie. Ma to sens, bo jeśli miało by działać między\nprzeglądarkami, to musiała by istnieć komunikacja między procesami utrzymującymi\nprzeglądarki.\n\nZasada Same Origin\nBroadcast Channel ma zasięg działania w dla wszystkich kart, przeglądarek,\niframes w ramach tego samego Origin czyli schematu (protokołu), hosta i portu. \n\nWięcej o samym Origin możemy przeczytać w słowniku Mozilla Developers\n\nOrigin - MDN Web Docs Glossary: Definitions of Web-related terms | MDNWeb\ncontent’s origin is defined by the scheme (protocol), hostname (domain), and\nport of the URL used to access it. Two objects have the same origin only when\nthe scheme, hostname, and port all match.MDN\n[https://developer.mozilla.org/en-US/docs/Glossary/Origin]Sprawdzimy czy dla\nróżnych komputerów też będzie działał poprawnie. W tym celu musimy zmienić\nustawienia parcela, bo obecnie wystawia on nasz serwis na localhost\n\nNasz obecny adres IP możemy sprawdzić poleceniem\n\nip route\n\n\n\nZ dokumentacji możemy wyczytać, że wystarczy dodanie flagi --host\n\n? CLIParcel [https://parceljs.org/cli.html]parce index.html --host 192.168.2.162\n\nOkazało się, że komunikacja nie jest przesyłana między różnymi komputerami.\n\nJest to zgodne z intuicją. O ile w przypadku Web Socketów istnieje jakiś serwer\ndo utrzymywania (czy nawet WebRCT do samego nawiązywania) połączenia, to tutaj\njedyną warstwą transportu danych jest pamięć operacyjna komputera na którym\nużywany jest Broadcast Channel.\n\nBroadcast Channel API a Shared Workers, Message Channel i post Message\nByć może zastanawiasz się jaka jest różnica między omawianym API a innymi\nmetodami komunikacji między kontekstami jak:\n\n * Shared Workers\n * Message Channel\n * window.postMessage()\n\nW przypadku SharedWorkers możesz zrobić to samo co za pomocą BroadcastChannel\nale wymaga to większej ilości kodu. Zalecam używanie SharedWorkers do bardziej\nzaawansowanych zdań jak zarządzanie blokadami, współdzielenie stanu,\nsynchronizacja zasobów czy dzielenie połączenia WebSocket między kartami.\n\nNatomiast Broadcast Channel Api jest wygodniejsze w prostych przypadkach, kiedy\nchcemy wysłać wiadomość do wszystkich okien, zakładek lub workerów.\n\nCo do MessageChannel API to główna różnica polega na tym, że w MessageChannel\nAPI wysyła się wiadomość do jednego odbiorcy, podczas gdy w Broadcast Channel\nwysyłający jest jeden, a odbiorcami są zawsze wszystkie pozostałe konteksty.\n\nW window.postMessage wymagane jest z kolei utrzymywanie referencji do obiektu\niframe lub workera, żeby nadawać komunikację, na przykład:\n\nconst popup = window.open('https://another-origin.com', ...);\npopup.postMessage('Sup popup!', 'https://another-origin.com');\n\nZ drugiej strony trzeba też pilnować, żeby przy odbieraniu sprawdzić źródło\nwiadomości ze względów bezpieczeństwa:\n\nconst iframe = document.querySelector('iframe');\niframe.contentWindow.onmessage = function(e) {\n  if (e.origin !== 'https://expected-origin.com') {\n    return;\n  }\n  e.source.postMessage('Ack!', e.origin);\n};\n\nPod tym względem Broadcast Channel jest bardziej ograniczony, bo nie pozwala na\nkomunikację między różnymi Origin, ale zapewnia to domyślnie wyższe\nbezpieczeństwo. Z drugiej strony window.postMessage nie pozwalał na wysyłkę do\ninnych okien bo nie można do nich było złapać referencji.\n\nRysowanie na Canvas w niezależnych kartach\nCzas na praktyczny przykład. No może nie super użyteczny, ale za to dobrze\nprezentujący możliwości Broadcast Channel API.\n\nZaprogramujemy aplikację pozwalającą na przenoszenie rysowanych kształtów na\npłótnie między kartami przeglądarki.\n\nZaczniemy od zwykłego rysowania myszką na canvas. W tym celu zmienimy nasz kod \nindex.html dodając do niego płótno i niezbędne style\n\n<html lang=\"en\">\n<body style=\"margin:0;\">\n<canvas id=\"canvas\" style=\"width: 100vw; height: 100vh;\"></canvas>\n<script src=\"./index.ts\"></script>\n</body>\n</html>\n\nW skrypcie index.ts wpisujemy\n\ninterface Window {\n    canvas?: HTMLCanvasElement;\n}\n\nPozwoli nam to na trzymanie canvasu w oknie. Aby nie wyszukiwać go wiele razy\nmożemy użyć window jako cache w którym będziemy go trzymać po pierwszym\nznalezieniu.\n\nconst getCanvasAndCtx = (): { canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D } => {\n    const canvas = window.canvas || document.querySelector('#canvas');\n    if (canvas instanceof HTMLCanvasElement) {\n        window.canvas = canvas;\n        const ctx = canvas.getContext('2d');\n        if(ctx) {\n            return {canvas, ctx}\n        } else {\n            throw new Error('Canvas do not have context');\n        }\n    }\n    throw new Error('Canvas Not found');\n}\n\nW celu dostrojenia wielkości canvasu deklarujemy funkcję syncCanvasSize\n\nconst syncCanvasSize = () => {\n    const { canvas } = getCanvasAndCtx()\n    canvas.height = window.innerHeight;\n    canvas.width = window.innerWidth;\n}\n\nWykonamy ją przy każdym evencie resize na window oraz po załadowaniu strony\n\nwindow.addEventListener('resize', syncCanvasSize)\n\nwindow.addEventListener('DOMContentLoaded', () => {\n    syncCanvasSize();\n    const {canvas, ctx} = getCanvasAndCtx()\n\nDefiniujemy kilka parametrów do określania stanu i historii kursora.\n\n    let flag = false,\n        prevX = 0,\n        currX = 0,\n        prevY = 0,\n        currY = 0;\n\nNastępnie definiujemy funkcje drawLine rysującą linię oraz drawDot rysującą\nkropkę\n\n    function drawLine() {\n        ctx.beginPath();\n        ctx.moveTo(prevX, prevY);\n        ctx.lineTo(currX, currY);\n        ctx.strokeStyle = \"black\";\n        ctx.lineWidth = 2;\n        ctx.stroke();\n        ctx.closePath();\n    }\n\n    function drawDot() {\n        ctx.beginPath();\n        ctx.fillStyle = 'black';\n        ctx.fillRect(currX, currY, 2, 2);\n        ctx.closePath();\n    }\n\nOraz najważniejszą funkcję findPosition - sterującą logiką rysowania\n\n    function findPosition(res: EventType, e: { clientX: number, clientY: number }) {\n        if (res == EventType.down) {\n            prevX = currX;\n            prevY = currY;\n            currX = e.clientX;\n            currY = e.clientY;\n            flag = true;\n            drawDot()\n        }\n        if ([EventType.up, EventType.out].includes(res)) {\n            flag = false;\n        }\n        if (res == EventType.move) {\n            if (flag) {\n                prevX = currX;\n                prevY = currY;\n                currX = e.clientX;\n                currY = e.clientY;\n                drawLine();\n            }\n        }\n    }\n\nNa końcu dodajemy nasłuch na wydarzenia powiązane z myszą aby używać funkcji \nfindPosition\n\n    canvas.addEventListener(\"mousemove\", (e) => {\n        findPosition(EventType.move, e)\n    });\n    canvas.addEventListener(\"mousedown\", (e) => {\n        findPosition(EventType.down, e)\n    });\n    canvas.addEventListener(\"mouseup\", (e) => {\n        findPosition(EventType.up, e)\n    });\n    canvas.addEventListener(\"mouseout\", (e) => {\n        findPosition(EventType.out, e)\n    });\n\n})\n\nPowyższy kod pozwala nam to na rysowanie na canvasie w ramach pojedynczej karty.\nŻeby było możliwe przenoszenie obrazu między kartami wykorzystamy Broadcast\nChannel. \n\nWymagana będzie jego inicjalizacja:\n\nconst bc = new BroadcastChannel('channel');\n\nDodanie nasłuchu na polecenie findPosition.\n\nbc.onmessage = (e) => {\n\tif(e.data.cmd === 'findPosition') {\n\t\tfindPosition(e.data.args[0], e.data.args[1], false)\n\t}\n}\n\nDo samej funkcji findPosition dodaliśmy trzeci argument - propagate mówiący czy\nwywołanie tej funkcji ma powodować wysłanie wiadomości do kanału. Wartość false \npozwala unikną nieskończonego zagnieżdżenia.\n\nNa końcu zmieniamy sygnaturę samej funkcji findPosition tak jak to opisaliśmy i\ndodajemy fragment kodu odpowiedzialny za wysyłkę wiadomości do innych kart\n\nfunction findPosition(res: EventType, e: {clientX: number, clientY: number}, propagate: boolean) {\n\n    if(propagate) {\n        bc.postMessage({cmd: 'findPosition', args: [res, {clientX: e.clientX, clientY: e.clientY}]})\n        }\n\nWarto zauważyć, że nie przekazujemy tu pełnych obiektów event a jedynie\nwspółrzędne. Jest to nie tylko optymalizacja. Klonowanie takich obiektów jak\nEvent nie jest możliwe między kontekstami.\n\nCały kod zawarty w index.ts prezentuję poniżej:\n\ninterface Window {\n    canvas?: HTMLCanvasElement;\n}\n\nconst getCanvasAndCtx = (): { canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D } => {\n    const canvas = window.canvas || document.querySelector('#canvas');\n    if (canvas instanceof HTMLCanvasElement) {\n        window.canvas = canvas;\n        const ctx = canvas.getContext('2d');\n        if(ctx) {\n            return {canvas, ctx}\n        } else {\n            throw new Error('Canvas do not have context');\n        }\n    }\n    throw new Error('Canvas Not found');\n}\n\nconst syncCanvasSize = () => {\n    const {canvas} = getCanvasAndCtx()\n    canvas.height = window.innerHeight;\n    canvas.width = window.innerWidth;\n}\n\nwindow.addEventListener('resize', syncCanvasSize)\n\nenum EventType {\n    down,\n    up,\n    move,\n    out\n}\n\nwindow.addEventListener('DOMContentLoaded', () => {\n    syncCanvasSize();\n    const {canvas, ctx} = getCanvasAndCtx()\n\n    let flag = false,\n        prevX = 0,\n        currX = 0,\n        prevY = 0,\n        currY = 0;\n\n    const bc = new BroadcastChannel('channel');\n\n    function drawLine() {\n        ctx.beginPath();\n        ctx.moveTo(prevX, prevY);\n        ctx.lineTo(currX, currY);\n        ctx.strokeStyle = \"black\";\n        ctx.lineWidth = 2;\n        ctx.stroke();\n        ctx.closePath();\n    }\n\n    function drawDot() {\n        ctx.beginPath();\n        ctx.fillStyle = 'black';\n        ctx.fillRect(currX, currY, 2, 2);\n        ctx.closePath();\n    }\n\n    function findPosition(res: EventType, e: { clientX: number, clientY: number }, propagate: boolean) {\n\n        if (propagate) {\n            bc.postMessage({cmd: 'findPosition', args: [res, {clientX: e.clientX, clientY: e.clientY}]})\n        }\n\n        if (res == EventType.down) {\n            prevX = currX;\n            prevY = currY;\n            currX = e.clientX;\n            currY = e.clientY;\n            flag = true;\n            drawDot()\n        }\n        if ([EventType.up, EventType.out].includes(res)) {\n            flag = false;\n        }\n        if (res == EventType.move) {\n            if (flag) {\n                prevX = currX;\n                prevY = currY;\n                currX = e.clientX;\n                currY = e.clientY;\n                drawLine();\n            }\n        }\n    }\n\n    canvas.addEventListener(\"mousemove\", (e) => {\n        findPosition(EventType.move, e, true)\n    });\n    canvas.addEventListener(\"mousedown\", (e) => {\n        findPosition(EventType.down, e, true)\n    });\n    canvas.addEventListener(\"mouseup\", (e) => {\n        findPosition(EventType.up, e, true)\n    });\n    canvas.addEventListener(\"mouseout\", (e) => {\n        findPosition(EventType.out, e, true)\n    });\n\n    bc.onmessage = (e) => {\n        if (e.data.cmd === 'findPosition') {\n            findPosition(e.data.args[0], e.data.args[1], false)\n        }\n    }\n\n})\n\nAplikacja działa tak, że obraz rysowany w jednej karcie pojawia się we\nwszystkich pozostałych:\n\nZastosowania Broadcast Channel API\nPrzykładowa aplikacja pokazuje, że broadcast channel może być stosowany w bardzo\nwygodny sposób. Zapewnienie synchronizacji między kartami zostało wprowadzone\nprzez dodanie 9 linii kodu z czego 3 to domknięcia nawiasów klamrowych.\n\nJego przykładowe zastosowania to:\n\n * Wykrywanie akcji użytkownika w innych zakładkach\n * Sprawdzanie kiedy użytkownik zalogował się na swoje konto w innej zakładce\n   lub oknie\n * Zlecenie Workerom wykonania jakichś zadań w tle\n * Rozsyłanie zdjęć załadowanych przez użytkownika w innych kartach\n\nJeśli potrzebujemy komunikacji między komputerami to Broadcast Channel API nam\nnie pomoże i wtedy do komunikacji w czasie rzeczywistym należy użyć WebSockets\nlub WebRTC.\n\nPolecane materiały oraz dokumentacja:\n\nBroadcast Channel API - Web APIs | MDNThe Broadcast Channel API allows basic\ncommunication between browsing contexts (that is, windows, tabs, frames, or\niframes) and workers on the same origin.MDN\n[https://developer.mozilla.org/en-US/docs/Web/API/Broadcast_Channel_API]\nBroadcastChannel API: A Message Bus for the Web | Google Developers\nBroadcastChannel API can be used for simple pub/sub between windows, tabs,\niframes, or workers.Google DevelopersEric Bidelman\n[https://developers.google.com/web/updates/2016/09/broadcastchannel]",
            "feature_image": "__GHOST_URL__/content/images/2021/07/shutterstock_749707636__1__copy.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-07-06T23:18:25.000Z",
            "updated_at": "2021-07-23T09:22:25.000Z",
            "published_at": "2021-07-07T11:08:19.000Z",
            "custom_excerpt": "Wpis pokazuje jak używać Broadcast Channel API do przesyłania danych między kartami lub oknami przeglądarki bez wykorzystania serwera i socketów.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60eea07650caaa182e07e399",
            "uuid": "ee1d20a6-c794-425b-8b5e-8ea3fc64cd65",
            "title": "Wpływ zmian rezerwy na giełdach na cenę BTC",
            "slug": "analiza-on-chain",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"from requests import get\\nimport dateutil.parser\\nimport pymongo\\nimport logging\\nfrom print_elapsed_time import print_elapsed_time\\n\\ndb_user = ''\\ndb_pass = ''\\ndb_name = 'on_chain_data'\\ndb_host = '127.0.0.1'\\ndb_is_srv = False\\n\\napi_token = 'xxx'\\n\\nclient = pymongo.MongoClient(\\n    \\\"mongodb{db_is_srv}://{db_auth}{db_host}/{db_name}?retryWrites=true&w=majority\\\".format(\\n        db_auth='{db_user}:{db_pass}@'.format(db_user=db_user, db_pass=db_pass) if db_user and db_pass else '',\\n        db_host=db_host,\\n        db_name=db_name,\\n        db_is_srv='+srv' if db_is_srv else ''\\n    ))\\n\\ndb = client[db_name]\\ndb.quant_btc_market_data_price_usd.create_index([('blockheight', pymongo.ASCENDING)], unique=True)\\ndb.quant_btc_exchange_flow_reserve.create_index([('blockheight', pymongo.ASCENDING)], unique=True)\\n\\n\\ndef get_resource(year, uri, params, collection):\\n    url = \\\"https://api.cryptoquant.com/{}\\\".format(uri)\\n\\n    params = {\\n                 'window': 'block',\\n                 'from': '{}0101T000000'.format(year),\\n                 'limit': 100000,\\n                 'to': '{}0101T000000'.format(year + 1),\\n             } | params\\n\\n    headers = {\\n        'Authorization': 'Bearer {token}'.format(token=api_token),\\n    }\\n\\n    response = get(url, headers=headers, params=params)\\n\\n    try:\\n        logs = response.json()['result']['data']\\n    except KeyError:\\n        return []\\n\\n    for log in logs:\\n        log['datetime'] = dateutil.parser.parse(log['datetime'])\\n\\n    if len(logs):\\n        try:\\n            db[collection].insert_many(logs)\\n        except pymongo.errors.BulkWriteError as e:\\n            logging.warning(e.details['writeErrors'])\\n\\n    return logs\\n\\n\\ndef get_price(year):\\n    return get_resource(\\n        year,\\n        'v1/btc/market-data/price-usd',\\n        {},\\n        'quant_btc_market_data_price_usd'\\n    )\\n\\n\\ndef get_reserve(year):\\n    return get_resource(\\n        year,\\n        'v1/btc/exchange-flows/reserve',\\n        {'exchange': 'all_exchange'},\\n        'quant_btc_exchange_flow_reserve'\\n    )\\n\\n\\ndef get_all_resources():\\n    for year in range(2009, 2021):\\n        res1 = len(get_price(year))\\n        res2 = len(get_reserve(year))\\n        print_elapsed_time('from {} - to {}, {}/{} results'.format(year, year + 1, res1, res2))\",\"language\":\"python\"}],[\"code\",{\"code\":\"python -i quant.py\"}],[\"code\",{\"code\":\">>> get_all_resources()\"}],[\"code\",{\"code\":\"{\\n    \\\"_id\\\":{\\\"$oid\\\":\\\"60749560134562392b920278\\\"},\\n    \\\"blockheight\\\":201299,\\n    \\\"datetime\\\":{\\\"$date\\\":\\\"2012-09-30T22:31:19.000Z\\\"},\\n    \\\"reserve\\\":27.523675060000194,\\n    \\\"reserve_usd\\\":341.2935707440024\\n}\",\"language\":\"json\"}],[\"code\",{\"code\":\"{\\n    \\\"_id\\\":{\\\"$oid\\\":\\\"607490d472b29b2a5863bfab\\\"},\\n    \\\"blockheight\\\":82996,\\n    \\\"datetime\\\":{\\\"$date\\\":\\\"2010-09-30T23:56:42.000Z\\\"},\\n    \\\"price_usd_open\\\":0.0619,\\n    \\\"price_usd_high\\\":0.0619,\\n    \\\"price_usd_low\\\":0.0619,\\n    \\\"price_usd_close\\\":0.0619\\n}\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://reference.wolfram.com/language/MongoLink/tutorial/MongoLinkSimpleTutorial.html\",\"metadata\":{\"url\":\"https://reference.wolfram.com/language/MongoLink/tutorial/MongoLinkSimpleTutorial.html\",\"title\":\"MongoLink Introduction—Wolfram Language Documentation\",\"description\":\"MongoLink is a set of tools for working with MongoDB. This tutorial shows how to perform the most common MongoDB operations using MongoLink. This tutorial assumes that a MongoDB server is running on your local machine at the default host and port. For platform-dependent instructions for running a Mo…\",\"author\":null,\"publisher\":null,\"thumbnail\":\"https://reference.wolfram.com/common/framework/img/spikey.en.png\",\"icon\":null}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-14-15-47-48.png\",\"width\":1156,\"height\":632}],[\"code\",{\"code\":\"sed -n '1!p' quant_btc_exchange_flow_reserve.csv | sort -t$',' -k 1,1 -n > sorted_quant_btc_exchange_flow_reserve.csv\\nsed -n '1!p' quant_btc_market_data_price_usd.csv | sort -t$',' -k 1,1 -n > sorted_quant_btc_market_data_price_usd.csv\"}],[\"code\",{\"code\":\"100000,0.3,2010-12-29T11:57:43.000Z,0.3,0.3,0.3\\n10000,0,2009-04-06T03:23:33.000Z,0,0,0\\n100001,0.3,2010-12-29T12:06:44.000Z,0.3,0.3,0.3\\n1000,0,2009-01-19T06:34:42.000Z,0,0,0\",\"language\":\"csv\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-14-15-58-17-1.png\",\"width\":1174,\"height\":408}],[\"code\",{\"code\":\"(*blockheight,datetime,open,low,high,close*)\\n\\npriceCSV = Import[\\\"/home/daniel/pro/crypto/on-chain-data/sorted_quant_btc_market_data_price_usd.csv\\\", \\\"Data\\\"];\\n(*blockheight,datetime,reserve,reserve_usd*)\\n\\nreserveCSV = Import[\\\"/home/daniel/pro/crypto/on-chain-data/sorted_quant_btc_exchange_flow_reserve.csv\\\", \\\"Data\\\"];\"}],[\"code\",{\"code\":\"(* block, reserve - array *)\\nres = Transpose[{reserveCSV[[All, 1]], reserveCSV[[All, 3]]}]\"}],[\"code\",{\"code\":\"ratRes = Module[{parts = 5}, \\n   Table[Module[{step}, step = IntegerPart[Length[res]/parts]; \\n     Ratios[#[[2]] & /@ res[[1 + i*step ;; (1 + i)*step ;; 100]]]\\n     ], {i, 0, parts - 1}]];\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/res-2.svg\",\"width\":829,\"height\":513,\"cardWidth\":\"\"}],[\"code\",{\"code\":\"ratRes = Module[{parts = 100}, \\n   Table[Module[{step}, step = IntegerPart[Length[res]/parts]; \\n     Ratios[#[[2]] & /@ res[[1 + i*step ;; (1 + i)*step]]]\\n     ], {i, 0, parts - 1}]];\"}],[\"code\",{\"code\":\"v = Variance[#] & /@ ratRes;\"}],[\"code\",{\"code\":\"w = MapIndexed[If[First[#2] < 36, 0, 1] &, v];\"}],[\"code\",{\"code\":\"nlm = NonlinearModelFit[v, c Exp[d x], {{c, 0.01}, {d, -0.1}}, x, Weights -> w];\\nbands90[x_] = nlm[\\\"MeanPredictionBands\\\", ConfidenceLevel -> .7];\"}],[\"code\",{\"code\":\"nlm[\\\"BestFit\\\"]\"}],[\"code\",{\"code\":\"Show[\\n ListLogPlot[{v}, PlotRange -> All], \\n LogPlot[{nlm[x], bands90[x]}, {x, 1, 100}, PlotRange -> All, \\n  Filling -> {2 -> {1}}],\\n Frame -> True, \\n PlotLabel -> \\n  \\\"Wariancja względnej zmienności rezerwy BTC w kolejnych okresach czasu\\\\nz dopasowaniem 7.18*10^-6*e^-0.051 x) (przy poziomie ufności 0.7)\\\\nx to numer przedziału czasowego od 1 do 100 z okresu 2012-04-02 - 2021-07-14\\\", ImageSize -> Full]\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/res2.svg\",\"width\":1260,\"height\":845,\"cardWidth\":\"full\"}],[\"code\",{\"code\":\"6.82*10^-6 E^(-5.06 t)\"}],[\"code\",{\"code\":\"Simplify[7.18*^-6 E^(-0.051 (t + 1/99)*99)]\"}],[\"code\",{\"code\":\"t = ( block_number - 173949 ) / ( 690974 - 173949 )\"}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Każdy inwestor interesujący się kryptowalutami wie, że trzymanie środków na giełdzie eksponuje go na stałe ryzyko:\"]]],[3,\"ul\",[[[0,[],0,\"upadku tej giełdy\"]],[[0,[],0,\"zamknięcia jej za pranie pieniędzy i finansowanie terroryzmu\"]],[[0,[],0,\"zniknięcia prezesa, który okazuje się być jedyną osobą mającą dostęp do środków\"]]]],[1,\"p\",[[0,[],0,\"Historia przekrętów i strat związanych z giełdami kryptowalut jest długa i interesująca. Jeśli jej nie znacie, zachęcam do poczytania o takich giełdach ja Cryptopia, Mt. Gox, FCoin, czy nasz polski BitMarket. Jednak dla nas stanowi ona jedynie wyjście do sformułowania hipotezy, którą omówimy w tym artykule.\"]]],[1,\"p\",[[0,[],0,\"Rozumowanie, które przedstawię brzmi następująco:\"]]],[1,\"p\",[[0,[],0,\"Skoro trzymając środki na giełdzie mogę je stracić, to nie powinienem ich tam trzymać. Z drugiej strony aby wykonać transakcję muszę je tam przelać. Zatem rozsądne będzie przelewanie BTC na adres giełdy tuż przed sprzedażą, a wyjmowanie BTC z adresu giełdy, kiedy nie chcę ich sprzedawać dłuższy czas.\"]]],[1,\"p\",[[0,[],0,\"Zatem jeśli na adresie giełdy szybko wzrasta ilość BTC zdeponowanych przez użytkowników, to oznacza, że sprzedając swoje środki mogą spowodować spadek ceny Bitcoina.\"]]],[1,\"p\",[[0,[],0,\"Taki mechanizm predykcji cen nie może być stosowany w klasycznych rynkach z kilku powodów:\"]]],[3,\"ul\",[[[0,[],0,\"giełdy i maklerzy w tradycyjnych rynkach są objęci funduszami gwarancyjnymi\"]],[[0,[],0,\"częstotliwość upadków giełd w klasycznych rynkach nie jest wysoka\"]],[[0,[],0,\"nie ma sposobu na uzyskanie informacji o wpłatach środków na te giełdy\"]]]],[1,\"p\",[[0,[],0,\"Jednak w przypadku wielu kryptowalut - w tym Bitcoina można śledzić transakcje przeglądając blockchain. Można z nich odfiltrować transakcje dotyczące adresów należących do giełd. W szczególności można wyszukać takich momentów, kiedy na giełdy wpływają naprawdę duże ilość BTC i sprawdzić jak oddziałuje to na jego cenę.\"]]],[1,\"p\",[[0,[],0,\"Jeśli inwestorzy stosują się do zasady bezpieczeństwa i wpłacają środki na giełdę z zamiarem ich szybkiej sprzedaży to powinniśmy się spodziewać opóźnionej korelacji między gwałtownym wzrostem rezerwy a spadkiem ceny w stosunkowo krótkim horyzoncie czasowym.\"]]],[1,\"p\",[[0,[],0,\"Ten wpis pokaże jak zbadałem to powiązanie i czy można to wykorzystać do podniesienia zwrotu z inwestycji w kryptowaluty.\"]]],[1,\"h2\",[[0,[],0,\"Zebranie danych o cenie i rezerwie BTC\"]]],[1,\"p\",[[0,[],0,\"Aby móc postawić pytania danym należy je najpierw pobrać. Wspomniałem, że można śledzić dane z bezpośrednio z BlockChain. Jest to prawda, ale wymaga to znajomości adresów giełd, w szczególności tych historycznych. Ich zebranie i poprawna klasyfikacji transakcji oraz odsianie ich spośród milionów transakcji jest technicznie możliwe, ale stanowi wyzwanie. Znacznie łatwiej jest kupić takie dane w cenie kilkuset USD.\"]]],[1,\"p\",[[0,[],0,\"Do ich pobrania posłuży nam skrypt napisany w pythonie:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Korzysta on z API serwisu \"],[0,[0],1,\"cryptoquant\"],[0,[],0,\", którego klucz jest wymagany do pobrania tych danych. Następnie są one zapisywane dwóch kolekcjach\"]]],[3,\"ul\",[[[0,[],0,\"quant_btc_market_data_price_usd\"]],[[0,[],0,\"quant_btc_exchange_flow_reserve\"]]]],[1,\"p\",[[0,[],0,\"Skrypt możemy uruchomić w trybie interaktywnym poleceniem\"]]],[10,1],[1,\"p\",[[0,[],0,\"a następnie wywołać funkcję, która pobierze dane i zapisze je do bazy:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Dla rezerwy mamy dane:\"]]],[10,3],[1,\"p\",[[0,[],0,\"Dla ceny\"]]],[10,4],[1,\"h2\",[[0,[],0,\"Czym jest \\\"nagły\\\" wzrost rezerwy\"]]],[1,\"p\",[[0,[],0,\"Aby nadać słowom \\\"nagły\\\", \\\"szybki\\\", \\\"gwałtywny\\\", \\\"znaczny\\\", \\\"istotny\\\" wzrost rezerwy sens matematyczny należy rozłożyć je na dwa wymiary:\"]]],[3,\"ul\",[[[0,[],0,\"tempo wzrostu ( pochodna logarytmiczna rezerwy względem numeracji bloków )\"]],[[0,[],0,\"czas trwania wzrostu ( liczony w ilości bloków )\"]]]],[1,\"p\",[[0,[],0,\"Para tych parametrów pozwala na wskazanie zakresów w których wzrost rezerwy wart był obserwacji.\"]]],[1,\"p\",[[0,[],0,\"Żeby pobrać dane z Mongo do programu Mathematica możemy używać pakietu \"],[0,[0],1,\"MongoLinks\"],[0,[],0,\", ale okazuje się on bardzo źle zoptymalizowany.\"]]],[10,5],[1,\"p\",[[0,[],0,\"Dlatego w tym przypadku lepiej wyeksportować dane z mongo do csv na przykład przez mongo compass.\"]]],[10,6],[1,\"p\",[[0,[],0,\"Te pliki nie są posortowane, ponieważ \"],[0,[0],1,\"cryptoquant\"],[0,[],0,\" zwraca je w kolejności odwrotnej niż upływ czasu. Sortujemy je poleceniami:\"]]],[10,7],[1,\"p\",[[0,[],0,\"które przy okazji kasują nagłówki. Opcja \"],[0,[0],1,\"-n\"],[0,[],0,\" to sortowanie numeryczne. Gdyby nie ona stosowane było by sortowanie alfabetyczne:\"]]],[10,8],[1,\"p\",[[0,[],0,\"Opcja \"],[0,[0],1,\"-t\"],[0,[],0,\" pozwala wybrać separator a \"],[0,[0],1,\"-k\"],[0,[],0,\" określić kolumny po których sortujemy.\"]]],[1,\"p\",[[0,[],0,\"Dzięki wykonaniu \"],[0,[0],1,\"head\"],[0,[],0,\" oraz \"],[0,[0],1,\"tail\"],[0,[],0,\" na posortowanym pliku widzimy zakres naszej analizy:\"]]],[3,\"ul\",[[[0,[],0,\"Start - blok 173949 - 2012-04-02\"]],[[0,[],0,\"Koniec - blok 690974 - 2021-07-14\"]]]],[10,9],[1,\"p\",[[0,[],0,\"Aby pobrać zawartość plików do nootebooka w \"],[0,[0],1,\"Mathematica\"],[0,[],0,\" wpisujemy:\"]]],[10,10],[1,\"p\",[[0,[],0,\"Wygenerowanie tablicy z rezerwą to:\"]]],[10,11],[1,\"p\",[[0,[],0,\"Następnie budujemy moduł do tworzenia tablicy tablic ze stosunkami rezerwy w okresach co ileś bloków. W tym przypadku mamy 5 okresów i krok ustawiony na 100 bloków.\"]]],[10,12],[1,\"p\",[[0,[],0,\"Ten moduł pozwoli nam zobaczyć jak ewoluowała zmienność rezerwy na przestrzeni czasu. Spodziewamy się, że kiedy bitcoin był młodszy, zmienność rezerwy była wyższa, bo rynek miał niższą kapitalizację. Zatem niewielkie transakcje mogły mocniej zaburzać wartość rezerwy.\"]]],[1,\"p\",[[0,[],0,\"Na histogramie nie jest to wyraźnie widoczne. Można nawet odnieść mylne wrażenie, że w początkowym okresie istnienia Bitcoina koncentracja względnej zmienności rezerwy woków jedynki (czyli jej stała wartość) była dominująca. Jest to mylne wrażenie, bo jednocześnie z wysoką koncentracją współwystępowały znacznie częstsze niż obecnie wartości skrajne. \"]]],[10,13],[1,\"p\",[[0,[],0,\"Jeśli podzielimy cały rozważany okres na 100 części i policzymy wariancję względnej zmiany rezerwy co jeden blok z tego okresu to okaże się, że początkowo ta wariancja miała nie tylko wyższe wartości ale i wyższy rozrzut. To znaczy, zdarzały się takie okresy, kiedy z rezerwą działo się bardzo niewiele.\"]]],[1,\"p\",[[0,[],0,\"Przedefiniujemy teraz \"],[0,[0],1,\"ratRes\"],[0,[],0,\" jako tablicę względnych rezerw podzieloną na 100 okresów. Tym razem sprawdzamy zmienność w ramach jednego bloku co jest bardziej arbitralnym wyborem.\"]]],[10,14],[1,\"p\",[[0,[],0,\"Wariancję rezerwy policzymy używając mapowania\"]]],[10,15],[1,\"p\",[[0,[],0,\"Ze względu na początkową zmienność dopasowanie krzywej wymaga specjalnego warzenia początkowych punktów wykresu. Najprostszą metodą jest ich wycięcie. Wybór granicy wycięcia niestety jest uznaniowy.\"]]],[10,16],[1,\"p\",[[0,[],0,\"W ten sposób mając wagi równe 1 dla punktów bliskich teraźniejszości i 0 dla odległej przeszłości możemy dopasować model wraz z granicami przedziału ufności.\"]]],[10,17],[1,\"p\",[[0,[],0,\"Parametry najlepszego dopasowania możemy dostać wpisując\"]]],[10,18],[1,\"p\",[[0,[],0,\"A wykres rysujemy poleceniem\"]]],[10,19],[10,20],[1,\"p\",[[0,[],0,\"Z wykresu widzimy, że zmienność rezerwy systematycznie spada i można założyć, że jest to spadek wykładniczy analogiczny do znanego nam z codzienności stygnięcia herbaty.\"]]],[1,\"p\",[[0,[],0,\"Kluczowym wnioskiem z przedstawionych obliczeń jest:\"]]],[1,\"blockquote\",[[0,[],0,\"Jeśli chcemy mówić o gwałtownej zmianie rezerwy musimy określić w jakim momencie historii Bitcoina jesteśmy. Obecnie rezerwa jest znacznie bardziej stabilna niż kiedyś i stosowanie stałego kryterium niezależnie od okresu zaburzyło by obraz sytuacji.\"]]],[1,\"p\",[[0,[],0,\"Początkowo opisałem \\\"tępo wzrostów\\\" jako pochodną logarytmiczną rezerwy. Słowo \\\"logarytmiczna\\\" pozwalało pozbyć się skali. Jednak teraz należało by zmienić nomenklaturę i zacząć myśleć o stosunku pochodnej logarytmicznej rezerwy do wariancji względnej zmienności rezerwy z danego okresu. \"]]],[1,\"p\",[[0,[],0,\"W ten sposób wyższa wariancja z przeszłości obniży \\\"znaczenie\\\" dużych zmian rezerwy z tamtego okresu, a niższa obecna wariancja zagwarantuje wyższą wrażliwość na obecne zmiany rezerwy.\"]]],[1,\"h2\",[[0,[],0,\"Nagły wzrost rezerwy BTC względem otoczenia\"]]],[1,\"p\",[[0,[],0,\"Przypomnijmy arbitralne wybory, które są istotną wadą prowadzonego tutaj rozumowania:\"]]],[3,\"ul\",[[[0,[],0,\"założyliśmy podział okresu na 100 podokresów (po około 5170 bloków - 29 dni)\"]],[[0,[],0,\"wycięliśmy 36 pierwszych okresów z dopasowania modelu krzywej wykładniczej\"]]]],[1,\"p\",[[0,[],0,\"Początkowo gwałtowny wzrost rozumieliśmy jako względną zmianę rezerwy powyżej jakiegoś poziomu trwającą przynajmniej jakiś czas.\"]]],[1,\"p\",[[0,[],0,\"Wystawiało nas to na ryzyko nadreprezentacji gwałtownych zmian z dalekiej historii i ominięcia obecnej zmienności jako niewystarczająco \\\"gwałtownej\\\".\"]]],[1,\"p\",[[0,[],0,\"Teraz przechodzimy do definiowania relatywnego tępa wzrostów względem wariancji względnej zmienności.\"]]],[1,\"p\",[[0,[],0,\"Przez wariancję względnej zmienności rezerwy rozumiemy krzywą\"]]],[10,21],[1,\"p\",[[0,[],0,\"gdzie \"],[0,[0],1,\"t = (x-1)/99\"],[0,[],0,\". Nie ma tu już podziału na 100 okresów. Jest tylko dopasowana do danych uśredniona wariancja względnej zmienności rezerwy. Współczynniki zmieniły się nieznacznie ze względu na to podstawienie. Ich zmiana została uwzględniona dzięki formule:\"]]],[10,22],[1,\"p\",[[0,[],0,\"Teraz \"],[0,[0],1,\"t\"],[0,[],0,\" zmienia się od \"],[0,[0],1,\"0\"],[0,[],0,\" do \"],[0,[0],1,\"1\"],[0,[],0,\". I zależy od numeru bloku zmieniającego się od 173949 do 690974 w prosty sposób:\"]]],[10,23],[1,\"p\",[[0,[],0,\"Wprowadzenie dzielnika w postaci tej wariancji jest istotną zmianą, bo \"],[0,[0],1,\"Exp[-0] = 1\"],[0,[],0,\" ale \"],[0,[0],1,\"Exp[-5] = 0.0067\"],[0,[],0,\" więc czułość na aktualne zmiany rezerwy jest kilkaset razy wyższa niż na te z początku istnienia Bitcoina.\"]]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Każdy inwestor interesujący się kryptowalutami wie, że trzymanie środków na giełdzie eksponuje go na stałe ryzyko:</p><ul><li>upadku tej giełdy</li><li>zamknięcia jej za pranie pieniędzy i finansowanie terroryzmu</li><li>zniknięcia prezesa, który okazuje się być jedyną osobą mającą dostęp do środków</li></ul><p>Historia przekrętów i strat związanych z giełdami kryptowalut jest długa i interesująca. Jeśli jej nie znacie, zachęcam do poczytania o takich giełdach ja Cryptopia, Mt. Gox, FCoin, czy nasz polski BitMarket. Jednak dla nas stanowi ona jedynie wyjście do sformułowania hipotezy, którą omówimy w tym artykule.</p><p>Rozumowanie, które przedstawię brzmi następująco:</p><p>Skoro trzymając środki na giełdzie mogę je stracić, to nie powinienem ich tam trzymać. Z drugiej strony aby wykonać transakcję muszę je tam przelać. Zatem rozsądne będzie przelewanie BTC na adres giełdy tuż przed sprzedażą, a wyjmowanie BTC z adresu giełdy, kiedy nie chcę ich sprzedawać dłuższy czas.</p><p>Zatem jeśli na adresie giełdy szybko wzrasta ilość BTC zdeponowanych przez użytkowników, to oznacza, że sprzedając swoje środki mogą spowodować spadek ceny Bitcoina.</p><p>Taki mechanizm predykcji cen nie może być stosowany w klasycznych rynkach z kilku powodów:</p><ul><li>giełdy i maklerzy w tradycyjnych rynkach są objęci funduszami gwarancyjnymi</li><li>częstotliwość upadków giełd w klasycznych rynkach nie jest wysoka</li><li>nie ma sposobu na uzyskanie informacji o wpłatach środków na te giełdy</li></ul><p>Jednak w przypadku wielu kryptowalut - w tym Bitcoina można śledzić transakcje przeglądając blockchain. Można z nich odfiltrować transakcje dotyczące adresów należących do giełd. W szczególności można wyszukać takich momentów, kiedy na giełdy wpływają naprawdę duże ilość BTC i sprawdzić jak oddziałuje to na jego cenę.</p><p>Jeśli inwestorzy stosują się do zasady bezpieczeństwa i wpłacają środki na giełdę z zamiarem ich szybkiej sprzedaży to powinniśmy się spodziewać opóźnionej korelacji między gwałtownym wzrostem rezerwy a spadkiem ceny w stosunkowo krótkim horyzoncie czasowym.</p><p>Ten wpis pokaże jak zbadałem to powiązanie i czy można to wykorzystać do podniesienia zwrotu z inwestycji w kryptowaluty.</p><h2 id=\"zebranie-danych-o-cenie-i-rezerwie-btc\">Zebranie danych o cenie i rezerwie BTC</h2><p>Aby móc postawić pytania danym należy je najpierw pobrać. Wspomniałem, że można śledzić dane z bezpośrednio z BlockChain. Jest to prawda, ale wymaga to znajomości adresów giełd, w szczególności tych historycznych. Ich zebranie i poprawna klasyfikacji transakcji oraz odsianie ich spośród milionów transakcji jest technicznie możliwe, ale stanowi wyzwanie. Znacznie łatwiej jest kupić takie dane w cenie kilkuset USD.</p><p>Do ich pobrania posłuży nam skrypt napisany w pythonie:</p><pre><code class=\"language-python\">from requests import get\nimport dateutil.parser\nimport pymongo\nimport logging\nfrom print_elapsed_time import print_elapsed_time\n\ndb_user = ''\ndb_pass = ''\ndb_name = 'on_chain_data'\ndb_host = '127.0.0.1'\ndb_is_srv = False\n\napi_token = 'xxx'\n\nclient = pymongo.MongoClient(\n    \"mongodb{db_is_srv}://{db_auth}{db_host}/{db_name}?retryWrites=true&amp;w=majority\".format(\n        db_auth='{db_user}:{db_pass}@'.format(db_user=db_user, db_pass=db_pass) if db_user and db_pass else '',\n        db_host=db_host,\n        db_name=db_name,\n        db_is_srv='+srv' if db_is_srv else ''\n    ))\n\ndb = client[db_name]\ndb.quant_btc_market_data_price_usd.create_index([('blockheight', pymongo.ASCENDING)], unique=True)\ndb.quant_btc_exchange_flow_reserve.create_index([('blockheight', pymongo.ASCENDING)], unique=True)\n\n\ndef get_resource(year, uri, params, collection):\n    url = \"https://api.cryptoquant.com/{}\".format(uri)\n\n    params = {\n                 'window': 'block',\n                 'from': '{}0101T000000'.format(year),\n                 'limit': 100000,\n                 'to': '{}0101T000000'.format(year + 1),\n             } | params\n\n    headers = {\n        'Authorization': 'Bearer {token}'.format(token=api_token),\n    }\n\n    response = get(url, headers=headers, params=params)\n\n    try:\n        logs = response.json()['result']['data']\n    except KeyError:\n        return []\n\n    for log in logs:\n        log['datetime'] = dateutil.parser.parse(log['datetime'])\n\n    if len(logs):\n        try:\n            db[collection].insert_many(logs)\n        except pymongo.errors.BulkWriteError as e:\n            logging.warning(e.details['writeErrors'])\n\n    return logs\n\n\ndef get_price(year):\n    return get_resource(\n        year,\n        'v1/btc/market-data/price-usd',\n        {},\n        'quant_btc_market_data_price_usd'\n    )\n\n\ndef get_reserve(year):\n    return get_resource(\n        year,\n        'v1/btc/exchange-flows/reserve',\n        {'exchange': 'all_exchange'},\n        'quant_btc_exchange_flow_reserve'\n    )\n\n\ndef get_all_resources():\n    for year in range(2009, 2021):\n        res1 = len(get_price(year))\n        res2 = len(get_reserve(year))\n        print_elapsed_time('from {} - to {}, {}/{} results'.format(year, year + 1, res1, res2))</code></pre><p>Korzysta on z API serwisu <code>cryptoquant</code>, którego klucz jest wymagany do pobrania tych danych. Następnie są one zapisywane dwóch kolekcjach</p><ul><li>quant_btc_market_data_price_usd</li><li>quant_btc_exchange_flow_reserve</li></ul><p>Skrypt możemy uruchomić w trybie interaktywnym poleceniem</p><pre><code>python -i quant.py</code></pre><p>a następnie wywołać funkcję, która pobierze dane i zapisze je do bazy:</p><pre><code>&gt;&gt;&gt; get_all_resources()</code></pre><p>Dla rezerwy mamy dane:</p><pre><code class=\"language-json\">{\n    \"_id\":{\"$oid\":\"60749560134562392b920278\"},\n    \"blockheight\":201299,\n    \"datetime\":{\"$date\":\"2012-09-30T22:31:19.000Z\"},\n    \"reserve\":27.523675060000194,\n    \"reserve_usd\":341.2935707440024\n}</code></pre><p>Dla ceny</p><pre><code>{\n    \"_id\":{\"$oid\":\"607490d472b29b2a5863bfab\"},\n    \"blockheight\":82996,\n    \"datetime\":{\"$date\":\"2010-09-30T23:56:42.000Z\"},\n    \"price_usd_open\":0.0619,\n    \"price_usd_high\":0.0619,\n    \"price_usd_low\":0.0619,\n    \"price_usd_close\":0.0619\n}</code></pre><h2 id=\"czym-jest-nag%C5%82y-wzrost-rezerwy\">Czym jest \"nagły\" wzrost rezerwy</h2><p>Aby nadać słowom \"nagły\", \"szybki\", \"gwałtywny\", \"znaczny\", \"istotny\" wzrost rezerwy sens matematyczny należy rozłożyć je na dwa wymiary:</p><ul><li>tempo wzrostu ( pochodna logarytmiczna rezerwy względem numeracji bloków )</li><li>czas trwania wzrostu ( liczony w ilości bloków )</li></ul><p>Para tych parametrów pozwala na wskazanie zakresów w których wzrost rezerwy wart był obserwacji.</p><p>Żeby pobrać dane z Mongo do programu Mathematica możemy używać pakietu <code>MongoLinks</code>, ale okazuje się on bardzo źle zoptymalizowany.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://reference.wolfram.com/language/MongoLink/tutorial/MongoLinkSimpleTutorial.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">MongoLink Introduction—Wolfram Language Documentation</div><div class=\"kg-bookmark-description\">MongoLink is a set of tools for working with MongoDB. This tutorial shows how to perform the most common MongoDB operations using MongoLink. This tutorial assumes that a MongoDB server is running on your local machine at the default host and port. For platform-dependent instructions for running a Mo…</div><div class=\"kg-bookmark-metadata\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://reference.wolfram.com/common/framework/img/spikey.en.png\"></div></a></figure><p>Dlatego w tym przypadku lepiej wyeksportować dane z mongo do csv na przykład przez mongo compass.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-14-15-47-48.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1156\" height=\"632\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-14-15-47-48.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-14-15-47-48.png 1000w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-14-15-47-48.png 1156w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Te pliki nie są posortowane, ponieważ <code>cryptoquant</code> zwraca je w kolejności odwrotnej niż upływ czasu. Sortujemy je poleceniami:</p><pre><code>sed -n '1!p' quant_btc_exchange_flow_reserve.csv | sort -t$',' -k 1,1 -n &gt; sorted_quant_btc_exchange_flow_reserve.csv\nsed -n '1!p' quant_btc_market_data_price_usd.csv | sort -t$',' -k 1,1 -n &gt; sorted_quant_btc_market_data_price_usd.csv</code></pre><p>które przy okazji kasują nagłówki. Opcja <code>-n</code> to sortowanie numeryczne. Gdyby nie ona stosowane było by sortowanie alfabetyczne:</p><pre><code class=\"language-csv\">100000,0.3,2010-12-29T11:57:43.000Z,0.3,0.3,0.3\n10000,0,2009-04-06T03:23:33.000Z,0,0,0\n100001,0.3,2010-12-29T12:06:44.000Z,0.3,0.3,0.3\n1000,0,2009-01-19T06:34:42.000Z,0,0,0</code></pre><p>Opcja <code>-t</code> pozwala wybrać separator a <code>-k</code> określić kolumny po których sortujemy.</p><p>Dzięki wykonaniu <code>head</code> oraz <code>tail</code> na posortowanym pliku widzimy zakres naszej analizy:</p><ul><li>Start - blok 173949 - 2012-04-02</li><li>Koniec - blok 690974 - 2021-07-14</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-14-15-58-17-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1174\" height=\"408\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-14-15-58-17-1.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-14-15-58-17-1.png 1000w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-14-15-58-17-1.png 1174w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Aby pobrać zawartość plików do nootebooka w <code>Mathematica</code> wpisujemy:</p><pre><code>(*blockheight,datetime,open,low,high,close*)\n\npriceCSV = Import[\"/home/daniel/pro/crypto/on-chain-data/sorted_quant_btc_market_data_price_usd.csv\", \"Data\"];\n(*blockheight,datetime,reserve,reserve_usd*)\n\nreserveCSV = Import[\"/home/daniel/pro/crypto/on-chain-data/sorted_quant_btc_exchange_flow_reserve.csv\", \"Data\"];</code></pre><p>Wygenerowanie tablicy z rezerwą to:</p><pre><code>(* block, reserve - array *)\nres = Transpose[{reserveCSV[[All, 1]], reserveCSV[[All, 3]]}]</code></pre><p>Następnie budujemy moduł do tworzenia tablicy tablic ze stosunkami rezerwy w okresach co ileś bloków. W tym przypadku mamy 5 okresów i krok ustawiony na 100 bloków.</p><pre><code>ratRes = Module[{parts = 5}, \n   Table[Module[{step}, step = IntegerPart[Length[res]/parts]; \n     Ratios[#[[2]] &amp; /@ res[[1 + i*step ;; (1 + i)*step ;; 100]]]\n     ], {i, 0, parts - 1}]];</code></pre><p>Ten moduł pozwoli nam zobaczyć jak ewoluowała zmienność rezerwy na przestrzeni czasu. Spodziewamy się, że kiedy bitcoin był młodszy, zmienność rezerwy była wyższa, bo rynek miał niższą kapitalizację. Zatem niewielkie transakcje mogły mocniej zaburzać wartość rezerwy.</p><p>Na histogramie nie jest to wyraźnie widoczne. Można nawet odnieść mylne wrażenie, że w początkowym okresie istnienia Bitcoina koncentracja względnej zmienności rezerwy woków jedynki (czyli jej stała wartość) była dominująca. Jest to mylne wrażenie, bo jednocześnie z wysoką koncentracją współwystępowały znacznie częstsze niż obecnie wartości skrajne. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/res-2.svg\" class=\"kg-image\" alt loading=\"lazy\" width=\"829\" height=\"513\"></figure><p>Jeśli podzielimy cały rozważany okres na 100 części i policzymy wariancję względnej zmiany rezerwy co jeden blok z tego okresu to okaże się, że początkowo ta wariancja miała nie tylko wyższe wartości ale i wyższy rozrzut. To znaczy, zdarzały się takie okresy, kiedy z rezerwą działo się bardzo niewiele.</p><p>Przedefiniujemy teraz <code>ratRes</code> jako tablicę względnych rezerw podzieloną na 100 okresów. Tym razem sprawdzamy zmienność w ramach jednego bloku co jest bardziej arbitralnym wyborem.</p><pre><code>ratRes = Module[{parts = 100}, \n   Table[Module[{step}, step = IntegerPart[Length[res]/parts]; \n     Ratios[#[[2]] &amp; /@ res[[1 + i*step ;; (1 + i)*step]]]\n     ], {i, 0, parts - 1}]];</code></pre><p>Wariancję rezerwy policzymy używając mapowania</p><pre><code>v = Variance[#] &amp; /@ ratRes;</code></pre><p>Ze względu na początkową zmienność dopasowanie krzywej wymaga specjalnego warzenia początkowych punktów wykresu. Najprostszą metodą jest ich wycięcie. Wybór granicy wycięcia niestety jest uznaniowy.</p><pre><code>w = MapIndexed[If[First[#2] &lt; 36, 0, 1] &amp;, v];</code></pre><p>W ten sposób mając wagi równe 1 dla punktów bliskich teraźniejszości i 0 dla odległej przeszłości możemy dopasować model wraz z granicami przedziału ufności.</p><pre><code>nlm = NonlinearModelFit[v, c Exp[d x], {{c, 0.01}, {d, -0.1}}, x, Weights -&gt; w];\nbands90[x_] = nlm[\"MeanPredictionBands\", ConfidenceLevel -&gt; .7];</code></pre><p>Parametry najlepszego dopasowania możemy dostać wpisując</p><pre><code>nlm[\"BestFit\"]</code></pre><p>A wykres rysujemy poleceniem</p><pre><code>Show[\n ListLogPlot[{v}, PlotRange -&gt; All], \n LogPlot[{nlm[x], bands90[x]}, {x, 1, 100}, PlotRange -&gt; All, \n  Filling -&gt; {2 -&gt; {1}}],\n Frame -&gt; True, \n PlotLabel -&gt; \n  \"Wariancja względnej zmienności rezerwy BTC w kolejnych okresach czasu\\nz dopasowaniem 7.18*10^-6*e^-0.051 x) (przy poziomie ufności 0.7)\\nx to numer przedziału czasowego od 1 do 100 z okresu 2012-04-02 - 2021-07-14\", ImageSize -&gt; Full]</code></pre><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/07/res2.svg\" class=\"kg-image\" alt loading=\"lazy\" width=\"1260\" height=\"845\"></figure><p>Z wykresu widzimy, że zmienność rezerwy systematycznie spada i można założyć, że jest to spadek wykładniczy analogiczny do znanego nam z codzienności stygnięcia herbaty.</p><p>Kluczowym wnioskiem z przedstawionych obliczeń jest:</p><blockquote>Jeśli chcemy mówić o gwałtownej zmianie rezerwy musimy określić w jakim momencie historii Bitcoina jesteśmy. Obecnie rezerwa jest znacznie bardziej stabilna niż kiedyś i stosowanie stałego kryterium niezależnie od okresu zaburzyło by obraz sytuacji.</blockquote><p>Początkowo opisałem \"tępo wzrostów\" jako pochodną logarytmiczną rezerwy. Słowo \"logarytmiczna\" pozwalało pozbyć się skali. Jednak teraz należało by zmienić nomenklaturę i zacząć myśleć o stosunku pochodnej logarytmicznej rezerwy do wariancji względnej zmienności rezerwy z danego okresu. </p><p>W ten sposób wyższa wariancja z przeszłości obniży \"znaczenie\" dużych zmian rezerwy z tamtego okresu, a niższa obecna wariancja zagwarantuje wyższą wrażliwość na obecne zmiany rezerwy.</p><h2 id=\"nag%C5%82y-wzrost-rezerwy-btc-wzgl%C4%99dem-otoczenia\">Nagły wzrost rezerwy BTC względem otoczenia</h2><p>Przypomnijmy arbitralne wybory, które są istotną wadą prowadzonego tutaj rozumowania:</p><ul><li>założyliśmy podział okresu na 100 podokresów (po około 5170 bloków - 29 dni)</li><li>wycięliśmy 36 pierwszych okresów z dopasowania modelu krzywej wykładniczej</li></ul><p>Początkowo gwałtowny wzrost rozumieliśmy jako względną zmianę rezerwy powyżej jakiegoś poziomu trwającą przynajmniej jakiś czas.</p><p>Wystawiało nas to na ryzyko nadreprezentacji gwałtownych zmian z dalekiej historii i ominięcia obecnej zmienności jako niewystarczająco \"gwałtownej\".</p><p>Teraz przechodzimy do definiowania relatywnego tępa wzrostów względem wariancji względnej zmienności.</p><p>Przez wariancję względnej zmienności rezerwy rozumiemy krzywą</p><pre><code>6.82*10^-6 E^(-5.06 t)</code></pre><p>gdzie <code>t = (x-1)/99</code>. Nie ma tu już podziału na 100 okresów. Jest tylko dopasowana do danych uśredniona wariancja względnej zmienności rezerwy. Współczynniki zmieniły się nieznacznie ze względu na to podstawienie. Ich zmiana została uwzględniona dzięki formule:</p><pre><code>Simplify[7.18*^-6 E^(-0.051 (t + 1/99)*99)]</code></pre><p>Teraz <code>t</code> zmienia się od <code>0</code> do <code>1</code>. I zależy od numeru bloku zmieniającego się od 173949 do 690974 w prosty sposób:</p><pre><code>t = ( block_number - 173949 ) / ( 690974 - 173949 )</code></pre><p>Wprowadzenie dzielnika w postaci tej wariancji jest istotną zmianą, bo <code>Exp[-0] = 1</code> ale <code>Exp[-5] = 0.0067</code> więc czułość na aktualne zmiany rezerwy jest kilkaset razy wyższa niż na te z początku istnienia Bitcoina.</p>",
            "comment_id": "60eea07650caaa182e07e399",
            "plaintext": "Każdy inwestor interesujący się kryptowalutami wie, że trzymanie środków na\ngiełdzie eksponuje go na stałe ryzyko:\n\n * upadku tej giełdy\n * zamknięcia jej za pranie pieniędzy i finansowanie terroryzmu\n * zniknięcia prezesa, który okazuje się być jedyną osobą mającą dostęp do\n   środków\n\nHistoria przekrętów i strat związanych z giełdami kryptowalut jest długa i\ninteresująca. Jeśli jej nie znacie, zachęcam do poczytania o takich giełdach ja\nCryptopia, Mt. Gox, FCoin, czy nasz polski BitMarket. Jednak dla nas stanowi ona\njedynie wyjście do sformułowania hipotezy, którą omówimy w tym artykule.\n\nRozumowanie, które przedstawię brzmi następująco:\n\nSkoro trzymając środki na giełdzie mogę je stracić, to nie powinienem ich tam\ntrzymać. Z drugiej strony aby wykonać transakcję muszę je tam przelać. Zatem\nrozsądne będzie przelewanie BTC na adres giełdy tuż przed sprzedażą, a\nwyjmowanie BTC z adresu giełdy, kiedy nie chcę ich sprzedawać dłuższy czas.\n\nZatem jeśli na adresie giełdy szybko wzrasta ilość BTC zdeponowanych przez\nużytkowników, to oznacza, że sprzedając swoje środki mogą spowodować spadek ceny\nBitcoina.\n\nTaki mechanizm predykcji cen nie może być stosowany w klasycznych rynkach z\nkilku powodów:\n\n * giełdy i maklerzy w tradycyjnych rynkach są objęci funduszami gwarancyjnymi\n * częstotliwość upadków giełd w klasycznych rynkach nie jest wysoka\n * nie ma sposobu na uzyskanie informacji o wpłatach środków na te giełdy\n\nJednak w przypadku wielu kryptowalut - w tym Bitcoina można śledzić transakcje\nprzeglądając blockchain. Można z nich odfiltrować transakcje dotyczące adresów\nnależących do giełd. W szczególności można wyszukać takich momentów, kiedy na\ngiełdy wpływają naprawdę duże ilość BTC i sprawdzić jak oddziałuje to na jego\ncenę.\n\nJeśli inwestorzy stosują się do zasady bezpieczeństwa i wpłacają środki na\ngiełdę z zamiarem ich szybkiej sprzedaży to powinniśmy się spodziewać opóźnionej\nkorelacji między gwałtownym wzrostem rezerwy a spadkiem ceny w stosunkowo\nkrótkim horyzoncie czasowym.\n\nTen wpis pokaże jak zbadałem to powiązanie i czy można to wykorzystać do\npodniesienia zwrotu z inwestycji w kryptowaluty.\n\nZebranie danych o cenie i rezerwie BTC\nAby móc postawić pytania danym należy je najpierw pobrać. Wspomniałem, że można\nśledzić dane z bezpośrednio z BlockChain. Jest to prawda, ale wymaga to\nznajomości adresów giełd, w szczególności tych historycznych. Ich zebranie i\npoprawna klasyfikacji transakcji oraz odsianie ich spośród milionów transakcji\njest technicznie możliwe, ale stanowi wyzwanie. Znacznie łatwiej jest kupić\ntakie dane w cenie kilkuset USD.\n\nDo ich pobrania posłuży nam skrypt napisany w pythonie:\n\nfrom requests import get\nimport dateutil.parser\nimport pymongo\nimport logging\nfrom print_elapsed_time import print_elapsed_time\n\ndb_user = ''\ndb_pass = ''\ndb_name = 'on_chain_data'\ndb_host = '127.0.0.1'\ndb_is_srv = False\n\napi_token = 'xxx'\n\nclient = pymongo.MongoClient(\n    \"mongodb{db_is_srv}://{db_auth}{db_host}/{db_name}?retryWrites=true&w=majority\".format(\n        db_auth='{db_user}:{db_pass}@'.format(db_user=db_user, db_pass=db_pass) if db_user and db_pass else '',\n        db_host=db_host,\n        db_name=db_name,\n        db_is_srv='+srv' if db_is_srv else ''\n    ))\n\ndb = client[db_name]\ndb.quant_btc_market_data_price_usd.create_index([('blockheight', pymongo.ASCENDING)], unique=True)\ndb.quant_btc_exchange_flow_reserve.create_index([('blockheight', pymongo.ASCENDING)], unique=True)\n\n\ndef get_resource(year, uri, params, collection):\n    url = \"https://api.cryptoquant.com/{}\".format(uri)\n\n    params = {\n                 'window': 'block',\n                 'from': '{}0101T000000'.format(year),\n                 'limit': 100000,\n                 'to': '{}0101T000000'.format(year + 1),\n             } | params\n\n    headers = {\n        'Authorization': 'Bearer {token}'.format(token=api_token),\n    }\n\n    response = get(url, headers=headers, params=params)\n\n    try:\n        logs = response.json()['result']['data']\n    except KeyError:\n        return []\n\n    for log in logs:\n        log['datetime'] = dateutil.parser.parse(log['datetime'])\n\n    if len(logs):\n        try:\n            db[collection].insert_many(logs)\n        except pymongo.errors.BulkWriteError as e:\n            logging.warning(e.details['writeErrors'])\n\n    return logs\n\n\ndef get_price(year):\n    return get_resource(\n        year,\n        'v1/btc/market-data/price-usd',\n        {},\n        'quant_btc_market_data_price_usd'\n    )\n\n\ndef get_reserve(year):\n    return get_resource(\n        year,\n        'v1/btc/exchange-flows/reserve',\n        {'exchange': 'all_exchange'},\n        'quant_btc_exchange_flow_reserve'\n    )\n\n\ndef get_all_resources():\n    for year in range(2009, 2021):\n        res1 = len(get_price(year))\n        res2 = len(get_reserve(year))\n        print_elapsed_time('from {} - to {}, {}/{} results'.format(year, year + 1, res1, res2))\n\nKorzysta on z API serwisu cryptoquant, którego klucz jest wymagany do pobrania\ntych danych. Następnie są one zapisywane dwóch kolekcjach\n\n * quant_btc_market_data_price_usd\n * quant_btc_exchange_flow_reserve\n\nSkrypt możemy uruchomić w trybie interaktywnym poleceniem\n\npython -i quant.py\n\na następnie wywołać funkcję, która pobierze dane i zapisze je do bazy:\n\n>>> get_all_resources()\n\nDla rezerwy mamy dane:\n\n{\n    \"_id\":{\"$oid\":\"60749560134562392b920278\"},\n    \"blockheight\":201299,\n    \"datetime\":{\"$date\":\"2012-09-30T22:31:19.000Z\"},\n    \"reserve\":27.523675060000194,\n    \"reserve_usd\":341.2935707440024\n}\n\nDla ceny\n\n{\n    \"_id\":{\"$oid\":\"607490d472b29b2a5863bfab\"},\n    \"blockheight\":82996,\n    \"datetime\":{\"$date\":\"2010-09-30T23:56:42.000Z\"},\n    \"price_usd_open\":0.0619,\n    \"price_usd_high\":0.0619,\n    \"price_usd_low\":0.0619,\n    \"price_usd_close\":0.0619\n}\n\nCzym jest \"nagły\" wzrost rezerwy\nAby nadać słowom \"nagły\", \"szybki\", \"gwałtywny\", \"znaczny\", \"istotny\" wzrost\nrezerwy sens matematyczny należy rozłożyć je na dwa wymiary:\n\n * tempo wzrostu ( pochodna logarytmiczna rezerwy względem numeracji bloków )\n * czas trwania wzrostu ( liczony w ilości bloków )\n\nPara tych parametrów pozwala na wskazanie zakresów w których wzrost rezerwy wart\nbył obserwacji.\n\nŻeby pobrać dane z Mongo do programu Mathematica możemy używać pakietu \nMongoLinks, ale okazuje się on bardzo źle zoptymalizowany.\n\nMongoLink Introduction—Wolfram Language DocumentationMongoLink is a set of\ntools\nfor working with MongoDB. This tutorial shows how to perform the most common\nMongoDB operations using MongoLink. This tutorial assumes that a MongoDB server\nis running on your local machine at the default host and port. For\nplatform-dependent instructions for running a Mo…\n[https://reference.wolfram.com/language/MongoLink/tutorial/MongoLinkSimpleTutorial.html]\nDlatego w tym przypadku lepiej wyeksportować dane z mongo do csv na przykład\nprzez mongo compass.\n\nTe pliki nie są posortowane, ponieważ cryptoquant zwraca je w kolejności\nodwrotnej niż upływ czasu. Sortujemy je poleceniami:\n\nsed -n '1!p' quant_btc_exchange_flow_reserve.csv | sort -t$',' -k 1,1 -n > sorted_quant_btc_exchange_flow_reserve.csv\nsed -n '1!p' quant_btc_market_data_price_usd.csv | sort -t$',' -k 1,1 -n > sorted_quant_btc_market_data_price_usd.csv\n\nktóre przy okazji kasują nagłówki. Opcja -n to sortowanie numeryczne. Gdyby nie\nona stosowane było by sortowanie alfabetyczne:\n\n100000,0.3,2010-12-29T11:57:43.000Z,0.3,0.3,0.3\n10000,0,2009-04-06T03:23:33.000Z,0,0,0\n100001,0.3,2010-12-29T12:06:44.000Z,0.3,0.3,0.3\n1000,0,2009-01-19T06:34:42.000Z,0,0,0\n\nOpcja -t pozwala wybrać separator a -k określić kolumny po których sortujemy.\n\nDzięki wykonaniu head oraz tail na posortowanym pliku widzimy zakres naszej\nanalizy:\n\n * Start - blok 173949 - 2012-04-02\n * Koniec - blok 690974 - 2021-07-14\n\nAby pobrać zawartość plików do nootebooka w Mathematica wpisujemy:\n\n(*blockheight,datetime,open,low,high,close*)\n\npriceCSV = Import[\"/home/daniel/pro/crypto/on-chain-data/sorted_quant_btc_market_data_price_usd.csv\", \"Data\"];\n(*blockheight,datetime,reserve,reserve_usd*)\n\nreserveCSV = Import[\"/home/daniel/pro/crypto/on-chain-data/sorted_quant_btc_exchange_flow_reserve.csv\", \"Data\"];\n\nWygenerowanie tablicy z rezerwą to:\n\n(* block, reserve - array *)\nres = Transpose[{reserveCSV[[All, 1]], reserveCSV[[All, 3]]}]\n\nNastępnie budujemy moduł do tworzenia tablicy tablic ze stosunkami rezerwy w\nokresach co ileś bloków. W tym przypadku mamy 5 okresów i krok ustawiony na 100\nbloków.\n\nratRes = Module[{parts = 5}, \n   Table[Module[{step}, step = IntegerPart[Length[res]/parts]; \n     Ratios[#[[2]] & /@ res[[1 + i*step ;; (1 + i)*step ;; 100]]]\n     ], {i, 0, parts - 1}]];\n\nTen moduł pozwoli nam zobaczyć jak ewoluowała zmienność rezerwy na przestrzeni\nczasu. Spodziewamy się, że kiedy bitcoin był młodszy, zmienność rezerwy była\nwyższa, bo rynek miał niższą kapitalizację. Zatem niewielkie transakcje mogły\nmocniej zaburzać wartość rezerwy.\n\nNa histogramie nie jest to wyraźnie widoczne. Można nawet odnieść mylne\nwrażenie, że w początkowym okresie istnienia Bitcoina koncentracja względnej\nzmienności rezerwy woków jedynki (czyli jej stała wartość) była dominująca. Jest\nto mylne wrażenie, bo jednocześnie z wysoką koncentracją współwystępowały\nznacznie częstsze niż obecnie wartości skrajne. \n\nJeśli podzielimy cały rozważany okres na 100 części i policzymy wariancję\nwzględnej zmiany rezerwy co jeden blok z tego okresu to okaże się, że początkowo\nta wariancja miała nie tylko wyższe wartości ale i wyższy rozrzut. To znaczy,\nzdarzały się takie okresy, kiedy z rezerwą działo się bardzo niewiele.\n\nPrzedefiniujemy teraz ratRes jako tablicę względnych rezerw podzieloną na 100\nokresów. Tym razem sprawdzamy zmienność w ramach jednego bloku co jest bardziej\narbitralnym wyborem.\n\nratRes = Module[{parts = 100}, \n   Table[Module[{step}, step = IntegerPart[Length[res]/parts]; \n     Ratios[#[[2]] & /@ res[[1 + i*step ;; (1 + i)*step]]]\n     ], {i, 0, parts - 1}]];\n\nWariancję rezerwy policzymy używając mapowania\n\nv = Variance[#] & /@ ratRes;\n\nZe względu na początkową zmienność dopasowanie krzywej wymaga specjalnego\nwarzenia początkowych punktów wykresu. Najprostszą metodą jest ich wycięcie.\nWybór granicy wycięcia niestety jest uznaniowy.\n\nw = MapIndexed[If[First[#2] < 36, 0, 1] &, v];\n\nW ten sposób mając wagi równe 1 dla punktów bliskich teraźniejszości i 0 dla\nodległej przeszłości możemy dopasować model wraz z granicami przedziału ufności.\n\nnlm = NonlinearModelFit[v, c Exp[d x], {{c, 0.01}, {d, -0.1}}, x, Weights -> w];\nbands90[x_] = nlm[\"MeanPredictionBands\", ConfidenceLevel -> .7];\n\nParametry najlepszego dopasowania możemy dostać wpisując\n\nnlm[\"BestFit\"]\n\nA wykres rysujemy poleceniem\n\nShow[\n ListLogPlot[{v}, PlotRange -> All], \n LogPlot[{nlm[x], bands90[x]}, {x, 1, 100}, PlotRange -> All, \n  Filling -> {2 -> {1}}],\n Frame -> True, \n PlotLabel -> \n  \"Wariancja względnej zmienności rezerwy BTC w kolejnych okresach czasu\\nz dopasowaniem 7.18*10^-6*e^-0.051 x) (przy poziomie ufności 0.7)\\nx to numer przedziału czasowego od 1 do 100 z okresu 2012-04-02 - 2021-07-14\", ImageSize -> Full]\n\nZ wykresu widzimy, że zmienność rezerwy systematycznie spada i można założyć, że\njest to spadek wykładniczy analogiczny do znanego nam z codzienności stygnięcia\nherbaty.\n\nKluczowym wnioskiem z przedstawionych obliczeń jest:\n\n> Jeśli chcemy mówić o gwałtownej zmianie rezerwy musimy określić w jakim momencie\nhistorii Bitcoina jesteśmy. Obecnie rezerwa jest znacznie bardziej stabilna niż\nkiedyś i stosowanie stałego kryterium niezależnie od okresu zaburzyło by obraz\nsytuacji.\nPoczątkowo opisałem \"tępo wzrostów\" jako pochodną logarytmiczną rezerwy. Słowo\n\"logarytmiczna\" pozwalało pozbyć się skali. Jednak teraz należało by zmienić\nnomenklaturę i zacząć myśleć o stosunku pochodnej logarytmicznej rezerwy do\nwariancji względnej zmienności rezerwy z danego okresu. \n\nW ten sposób wyższa wariancja z przeszłości obniży \"znaczenie\" dużych zmian\nrezerwy z tamtego okresu, a niższa obecna wariancja zagwarantuje wyższą\nwrażliwość na obecne zmiany rezerwy.\n\nNagły wzrost rezerwy BTC względem otoczenia\nPrzypomnijmy arbitralne wybory, które są istotną wadą prowadzonego tutaj\nrozumowania:\n\n * założyliśmy podział okresu na 100 podokresów (po około 5170 bloków - 29 dni)\n * wycięliśmy 36 pierwszych okresów z dopasowania modelu krzywej wykładniczej\n\nPoczątkowo gwałtowny wzrost rozumieliśmy jako względną zmianę rezerwy powyżej\njakiegoś poziomu trwającą przynajmniej jakiś czas.\n\nWystawiało nas to na ryzyko nadreprezentacji gwałtownych zmian z dalekiej\nhistorii i ominięcia obecnej zmienności jako niewystarczająco \"gwałtownej\".\n\nTeraz przechodzimy do definiowania relatywnego tępa wzrostów względem wariancji\nwzględnej zmienności.\n\nPrzez wariancję względnej zmienności rezerwy rozumiemy krzywą\n\n6.82*10^-6 E^(-5.06 t)\n\ngdzie t = (x-1)/99. Nie ma tu już podziału na 100 okresów. Jest tylko dopasowana\ndo danych uśredniona wariancja względnej zmienności rezerwy. Współczynniki\nzmieniły się nieznacznie ze względu na to podstawienie. Ich zmiana została\nuwzględniona dzięki formule:\n\nSimplify[7.18*^-6 E^(-0.051 (t + 1/99)*99)]\n\nTeraz t zmienia się od 0 do 1. I zależy od numeru bloku zmieniającego się od\n173949 do 690974 w prosty sposób:\n\nt = ( block_number - 173949 ) / ( 690974 - 173949 )\n\nWprowadzenie dzielnika w postaci tej wariancji jest istotną zmianą, bo Exp[-0] =\n1 ale Exp[-5] = 0.0067 więc czułość na aktualne zmiany rezerwy jest kilkaset\nrazy wyższa niż na te z początku istnienia Bitcoina.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-07-14T08:29:42.000Z",
            "updated_at": "2021-07-15T14:18:03.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60f18cd350caaa182e07e605",
            "uuid": "7c754f76-5c46-48ea-99e4-98cb32397127",
            "title": "Sterowanie procesami w Node JS",
            "slug": "sterowanie-obciazeniem-procesora-w-node-js",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/cpu0-12.png\",\"width\":500,\"height\":626,\"cardWidth\":\"\"}],[\"code\",{\"code\":\"const readline = require('readline');\"}],[\"code\",{\"code\":\"readline.emitKeypressEvents(process.stdin);\"}],[\"code\",{\"code\":\"process.stdin.setRawMode(true);\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://nodejs.org/api/readline.html#readline_readline_emitkeypressevents_stream_interface\",\"metadata\":{\"url\":\"https://nodejs.org/api/readline.html\",\"title\":\"Readline | Node.js v16.5.0 Documentation\",\"description\":null,\"author\":null,\"publisher\":\"Node.js v16.5.0 Documentation\",\"thumbnail\":null,\"icon\":null}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://nodejs.org/api/tty.html#tty_readstream_setrawmode_mode\",\"metadata\":{\"url\":\"https://nodejs.org/api/tty.html\",\"title\":\"TTY | Node.js v16.5.0 Documentation\",\"description\":null,\"author\":null,\"publisher\":\"Node.js v16.5.0 Documentation\",\"thumbnail\":null,\"icon\":null}}],[\"code\",{\"code\":\"process.stdin.on('keypress', (str, key) => {\\n    if (key.ctrl && key.name === 'c') {\\n        process.exit();\\n    } else {\\n        console.log('typed char', key.name);\\n    }\\n});\"}],[\"code\",{\"code\":\"{ sequence: 'v', name: 'v', ctrl: false, meta: false, shift: false }\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-16-18-15-24.png\",\"width\":273,\"height\":205,\"cardWidth\":\"\"}],[\"code\",{\"code\":\"const cp = require('child_process');\"}],[\"code\",{\"code\":\"const forks = [];\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/one-does-not-simply-kill-a-zombie-process.jpg\",\"width\":335,\"height\":335}],[\"code\",{\"code\":\"    if (key.ctrl && key.name === 'c') {\\n        while (forks.length > 0) {\\n            forks[forks.length - 1].kill()\\n            forks.pop()\\n        }\\n        process.exit();\\n    } else {\"}],[\"code\",{\"code\":\"        if (!Number.isNaN(parseInt(key.name,32))) {\\n            const req = parseInt(key.name,32);\\n\\n            if (forks.length < req) {\\n                while (forks.length < req) {\\n                    const n = cp.fork(`${__dirname}/bomb.js`);\\n                    forks.push(n)\\n                }\\n            }\\n\\n            if (forks.length > req) {\\n                while (forks.length > req) {\\n                    forks[forks.length - 1].kill()\\n                    forks.pop()\\n                }\\n            }\\n\\n            console.log('processes PIDs', forks.map(f => f.pid));\\n\\n        }\"}],[\"code\",{\"code\":\"let result = 0;\\nwhile (true) {\\n    result += Math.random() * Math.random();\\n}\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-16-18-51-17.png\",\"width\":539,\"height\":607}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-16-15-26-13.png\",\"width\":1850,\"height\":371,\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-16-15-30-03.png\",\"width\":450,\"height\":232}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://medium.com/analytics-vidhya/password-hashing-pbkdf2-scrypt-bcrypt-and-argon2-e25aaf41598e\",\"metadata\":{\"url\":\"https://medium.com/analytics-vidhya/password-hashing-pbkdf2-scrypt-bcrypt-and-argon2-e25aaf41598e\",\"title\":\"Password Hashing: PBKDF2, Scrypt, Bcrypt and ARGON2\",\"description\":\"There’s always a lot of debate in regards to how to safely store passwords and what algorithm to use: MD5, SHA1, SHA256, PBKDF2, Bcrypt, Scrypt, Argon2, plaintext?? So I tried to analyse and…\",\"author\":\"Michele Preziuso\",\"publisher\":\"Analytics Vidhya\",\"thumbnail\":\"https://miro.medium.com/max/1200/1*6AmtTHis9u0viVhIzg9tsA.png\",\"icon\":\"https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png\"}}],[\"code\",{\"code\":\"npm init -y && npm i bcrypt\"}],[\"code\",{\"code\":\"const fs = require('fs')\\nconst bc = require('bcrypt')\\n\\nconst main = async () => {\\n    return bc.hash(process.argv[2] || 'pass', 11)\\n}\\n\\nmain().then(p => {\\n    fs.writeFileSync(`${__dirname}/.pass`, p);\\n    console.log(p)\\n}).catch(console.error);\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://gustawdaniel.com/ile-rodzin-zmiesci-sie-w-samolocie/\",\"metadata\":{\"url\":\"__GHOST_URL__/ile-rodzin-zmiesci-sie-w-samolocie/\",\"title\":\"Ile rodzin zmieści się w samolocie - zadanie z algorytmiki\",\"description\":\"Porównujemy dwa rozwiązania zadania polegającego na zliczaniu wolnych zestawów przyległych miejsc. Dowiesz się jak używać Profilowania i jak wielką różnicę robi użycie pop oraz shift na tablicach w js.\",\"author\":\"Daniel Gustaw\",\"publisher\":\"Daniel Gustaw\",\"thumbnail\":\"__GHOST_URL__/content/images/2021/04/31742.jpg\",\"icon\":\"__GHOST_URL__/favicon.ico\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-13-44-09.png\",\"width\":435,\"height\":455}],[\"code\",{\"code\":\"const fs = require('fs');\\nconst bc = require('bcrypt');\\nconst alphabet = String.fromCharCode(...Array(123).keys()).slice(97);\\nconst hash = fs.readFileSync(`${__dirname}/.pass`).toString()\\nconst chalk = require('chalk')\\n\\nlet i = 0;\\nconst s = new Date().getTime();\\nconst n = () => new Date().getTime() - s;\\nlet found = false;\\n\\nconst que = [];\\n\\nasync function check(input) {\\n    if (found) return;\\n    const r = await bc.compare(input, hash)\\n\\n    console.log(`${i}\\\\t${input}\\\\t${n()}\\\\t${r}\\\\t${que.length}`)\\n    if (r) {\\n        console.log(chalk.green(`FOUND: \\\"${input}\\\"`))\\n        found = true;\\n        process.exit();\\n    }\\n    for (let n of alphabet) {\\n        que.push(input + n);\\n    }\\n}\\n\\nasync function processQue() {\\n    const phrase = que[i++]\\n    await check(phrase)\\n}\\n\\nconst main = async () => {\\n    while (!found) {\\n        await processQue()\\n    }\\n}\\n\\nconsole.log(`i\\\\tinput\\\\tn()\\\\tr\\\\tque.length`)\\ncheck('').then(() => main()).catch(console.error)\",\"language\":\"javascript\"}],[\"code\",{\"code\":\"npm i chalk\"}],[\"code\",{\"code\":\"node generate_hash.js ac\"}],[\"code\",{\"code\":\"time node force-single.js\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-13-48-47.png\",\"width\":438,\"height\":559}],[\"code\",{\"code\":\"const r = await bc.compare(input, hash)\"}],[\"code\",{\"code\":\"const r = i >= 29 // await bc.compare(input, hash)\"}],[\"code\",{\"code\":\"node force-single.js  0.17s user 0.03s system 103% cpu 0.188 total\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/bFbMbDgAT6M6T4zsVmk16Oiip7vIOWaeuEY0vTkkZoU.png\",\"width\":505,\"height\":256}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-16-35.png\",\"width\":705,\"height\":731}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-26-11.png\",\"width\":416,\"height\":652}],[\"code\",{\"code\":\"const cp = require('child_process');\\nconst fs = require('fs');\\nconst chalk = require('chalk')\\n\\nconst alphabet = String.fromCharCode(...Array(123).keys()).slice(97);\\nconst forks = [];\\n\\nlet i = 0;\\nconst s = new Date().getTime();\\nconst n = () => new Date().getTime() - s;\\nlet found = false;\"}],[\"code\",{\"code\":\"const que = alphabet.split('');\"}],[\"code\",{\"code\":\"function check(input, f) {\\n    if (found) return;\\n\\n    f.send(input);\\n\\n    for (let n of alphabet) {\\n        que.push(input + n);\\n    }\\n}\"}],[\"code\",{\"code\":\"function processQue(f) {\\n    const phrase = que[i++]\\n    check(phrase, f)\\n}\"}],[\"code\",{\"code\":\"const main = async () => {\\n    forks.forEach(f => {\\n        f.on('message', ({input, r}) => {\\n            console.log(`${i}\\\\t${input}\\\\t${n()}\\\\t${r}\\\\t${que.length}\\\\t${f.pid}`)\\n\\n            if (r) {\\n                console.log(chalk.green(`FOUND: \\\"${input}\\\"`))\\n                found = true;\\n\\n                fs.appendFileSync('logs.txt', `${forks.length},${n()}\\\\n`)\\n\\n                while (forks.length > 0) {\\n                    forks[forks.length - 1].kill()\\n                    forks.pop()\\n                }\\n\\n                process.exit();\\n            } else {\\n                processQue(f);\\n            }\\n        });\\n        processQue(f);\\n    })\\n}\"}],[\"code\",{\"code\":\"while (forks.length < (process.argv[2] || 15)) {\\n    const n = cp.fork(`${__dirname}/force-fork.js`);\\n    forks.push(n)\\n}\"}],[\"code\",{\"code\":\"console.log(chalk.blue(`Run using ${forks.length} child processes`))\\nconsole.log(`i\\\\tinput\\\\tn()\\\\tr\\\\tque.length\\\\tpid`)\\nmain().catch(console.error)\"}],[\"code\",{\"code\":\"const fs = require('fs');\\nconst bc = require('bcrypt');\\n\\nconst hash = fs.readFileSync(`${__dirname}/.pass`).toString()\\n\\nprocess.on('message', (input) => {\\n    bc.compare(input, hash).then((r) => {\\n        process.send({r, input});\\n    })\\n});\"}],[\"code\",{\"code\":\"fs.appendFileSync('logs.txt', `${forks.length},${n()}\\\\n`)\"}],[\"code\",{\"code\":\"for j in $(seq 1 20); do for i in $(seq 1 25); do time node force-child.js $i; sleep 4; done; done;\"}],[\"code\",{\"code\":\"for j in $(seq 1 5); do for i in $(seq 1 50); do time node force-child.js $i; sleep 4; done; done;\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-29.png\",\"width\":1091,\"height\":372}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-40.png\",\"width\":1108,\"height\":378}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-46.png\",\"width\":928,\"height\":441}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-51.png\",\"width\":323,\"height\":286}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/usl.svg\",\"width\":1019,\"height\":457,\"cardWidth\":\"wide\"}],[\"code\",{\"code\":\"load = Import[\\\"/home/daniel/exp/node/logs.txt\\\", \\\"Data\\\"];\"}],[\"code\",{\"code\":\"loadEff = {#[[1]], 1/#[[2]]} & /@ load;\"}],[\"code\",{\"code\":\"firstMean = GroupBy[loadEff // N, First -> Last, Mean][[1]];\"}],[\"code\",{\"code\":\"nlm = NonlinearModelFit[{#[[1]], #[[2]]/firstMean} & /@ \\n   loadEff, \\\\[Lambda] n/(1 + \\\\[Sigma] (n - 1) + \\\\[Kappa] n (n - \\n         1)), {{\\\\[Lambda], 0.9}, {\\\\[Sigma], 0.9}, {\\\\[Kappa], \\n    0.1}}, {n}]\"}],[\"code\",{\"code\":\"Show[ListPlot[{#[[1]], #[[2]]/firstMean} & /@ loadEff], \\n Plot[nlm[s], {s, 0, 50}, PlotStyle -> Orange, PlotRange -> All], \\n AxesLabel -> {\\\"processes\\\", \\\"gain of efficiency\\\"}, ImageSize -> Large,\\n  PlotLabel -> \\\"Gain of efficiency relative to single process\\\"]\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/gain-eff.svg\",\"width\":768,\"height\":457,\"cardWidth\":\"wide\"}],[\"code\",{\"code\":\"Solve[D[\\\\[Lambda] n/(1 + \\\\[Sigma] (n - 1) + \\\\[Kappa] n (n - 1)), \\n   n] == 0, n]\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-15-21-22.png\",\"width\":88,\"height\":66}],[\"code\",{\"code\":\"NSolve[D[Normal[nlm], n] == 0, n]\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://nodejs.org/api/process.html\",\"metadata\":{\"url\":\"https://nodejs.org/api/process.html\",\"title\":\"Process | Node.js v16.5.0 Documentation\",\"description\":null,\"author\":null,\"publisher\":\"Node.js v16.5.0 Documentation\",\"thumbnail\":null,\"icon\":null}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://nodejs.org/api/cluster.html\",\"metadata\":{\"url\":\"https://nodejs.org/api/cluster.html\",\"title\":\"Cluster | Node.js v16.5.0 Documentation\",\"description\":null,\"author\":null,\"publisher\":\"Node.js v16.5.0 Documentation\",\"thumbnail\":null,\"icon\":null}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://nodejs.org/api/worker_threads.html\",\"metadata\":{\"url\":\"https://nodejs.org/api/worker_threads.html\",\"title\":\"Worker threads | Node.js v16.5.0 Documentation\",\"description\":null,\"author\":null,\"publisher\":\"Node.js v16.5.0 Documentation\",\"thumbnail\":null,\"icon\":null}}]],\"markups\":[[\"code\"],[\"a\",[\"href\",\"https://cdn2.hubspot.net/hubfs/498921/eBooks/scalability_new.pdf\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"W tym wpisie nauczymy się jak tworzyć i kończyć podprocesy w Node JS oraz jak przesyłać między nimi dane.\"]]],[1,\"p\",[[0,[],0,\"Jeśli program wykonuje ciężkie obliczenia ale nie jest zrównoleglony, stan Twojego procesora może wyglądać tak:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Dlatego warto zgłębić ten temat niezależnie od języka w którym piszesz.\"]]],[1,\"p\",[[0,[],0,\"Artykuł będzie podzielony na 3 części:\"]]],[3,\"ul\",[[[0,[],0,\"sterowanie procesem za pomocą \"],[0,[0],1,\"readline\"]],[[0,[],0,\"tworzenie i zabijanie podprocesów\"]],[[0,[],0,\"komunikacja między procesami\"]]]],[1,\"p\",[[0,[],0,\"W pierwszych dwóch napiszemy skrypt do symulowania obciążenia rdzeni procesora. W ostatniej zrównoleglimy atak brutforce na hasło.\"]]],[1,\"p\",[[0,[],0,\"Na końcu przeanalizujemy skalowalność napisanego programu.\"]]],[1,\"h2\",[[0,[],0,\"Sterowanie procesem z \"],[0,[0],1,\"readline\"]]],[1,\"p\",[[0,[],0,\"Chcemy napisać program, w którym wciskając klawisz na klawiaturze będziemy ustawiać ile rdzeni procesora ma zostać obciążonych. Zaczniemy od przechwytywania zdarzeń z klawiatury w czasie rzeczywistym.\"]]],[1,\"p\",[[0,[],0,\"Pozwoli nam na to moduł \"],[0,[0],1,\"readline\"],[0,[],0,\" dostarczający interfejs do zapisu i odczytu danych ze strumieni takich jak klawiatura - \"],[0,[0],1,\"process.stdin\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od importu tego modułu\"]]],[10,1],[1,\"p\",[[0,[],0,\"Następnie ustawiamy emitowanie zdarzenia z \"],[0,[0],1,\"readline\"],[0,[],0,\" na naciśnięcie przycisku na klawiaturze poleceniem\"]]],[10,2],[1,\"p\",[[0,[],0,\"Sam \"],[0,[0],1,\"readline\"],[0,[],0,\" może pracować z różnymi strumieniami. Tą linią wskazujemy mu, żeby nasłuchiwał na klawiaturę. Od razu ustawiamy mod na \"],[0,[0],1,\"raw\"]]],[10,3],[1,\"p\",[[0,[],0,\"Pozwala to odczytywać z klawiatury znak po znaku z osobno załączanymi modyfikatorami jak ctrl czy shift. Jednocześnie ten tryb wymusza samodzielne obsłużenie wyłączenia procesu przez \"],[0,[0],1,\"ctrl+c\"],[0,[],0,\". Więcej na temat trybów strumieni i podłączania terminala do procesu możemy przeczytać w dokumentacji:\"]]],[10,4],[10,5],[1,\"p\",[[0,[],0,\"Tym czasem w naszym programie kolejne linie pozwolą obsłużyć odczyt znaków:\"]]],[10,6],[1,\"p\",[[0,[],0,\"Znak zapisany w \"],[0,[0],1,\"key\"],[0,[],0,\" jest obiektem o następujących kluczach\"]]],[10,7],[1,\"p\",[[0,[],0,\"W prezentowanym kodzie obsługujemy zamknięcie procesu kombinacją \"],[0,[0],1,\"ctrl+c\"],[0,[],0,\" oraz wypisanie w konsoli znaku wybranego na klawiaturze. Wpisywanie kolejnych znaków będzie za każdym razem pokazywało je w terminalu.\"]]],[10,8],[1,\"p\",[[0,[],0,\"Następnym krokiem jest zastąpienie wypisywania znaków przez tworzenie lub kasowanie procesów obciążających procesor.\"]]],[1,\"h2\",[[0,[],0,\"Tworzenie i zabijanie procesów w Node JS\"]]],[1,\"p\",[[0,[],0,\"W Node JS, możemy bardzo łatwo tworzyć podprocesy i zarządzać nimi. Do zarządzania podprocesami możemy użyć modułu \"],[0,[0],1,\"child_process\"],[0,[],0,\". Importujemy go jak poprzedni moduł\"]]],[10,9],[1,\"p\",[[0,[],0,\"Następnie tworzymy tablicę, do której będziemy zapisywali referencje do tworzonych procesów.\"]]],[10,10],[1,\"p\",[[0,[],0,\"Jeśli zapomnieli byśmy o nich przy zamykaniu programu to stały by się one procesami \"],[0,[0],1,\"zombie\"],[0,[],0,\" - czyli takimi, które żyją nadal i bez nadzoru pożerają zasoby komputera.\"]]],[10,11],[1,\"p\",[[0,[],0,\"Aby je usunąć przed zamknięciem naszego skryptu piszemy kod:\"]]],[10,12],[1,\"p\",[[0,[],0,\"W przypadku wybrania innych przycisków niż \"],[0,[0],1,\"c\"],[0,[],0,\" w obecności \"],[0,[0],1,\"ctrl\"],[0,[],0,\" odczytamy wartość liczbową tego przycisku i na jej podstawie dodamy lub zabijemy odpowiednią liczbę procesów aby ich ilość równa była tej liczbie.\"]]],[10,13],[1,\"p\",[[0,[],0,\"Dziwić może wybór systemu liczbowego \"],[0,[0],1,\"32\"],[0,[],0,\". Jednak jest to wygodny system jeśli założymy, że za pomocą jednego klawisza chcemy wskazać niewielką lecz przekraczającą 10 liczbę.\"]]],[1,\"p\",[[0,[],0,\"Do zmiennej \"],[0,[0],1,\"req\"],[0,[],0,\" trafia wymagana liczba procesów, a dzięki \"],[0,[0],1,\"cp.fork\"],[0,[],0,\" lub \"],[0,[0],1,\"kill\"],[0,[],0,\" tworzymy i zabijamy brakujące lub nadmiarowe procesy. \"]]],[1,\"p\",[[0,[],0,\"Do złożenia całości brakuje nam jedynie zawartości pliku \"],[0,[0],1,\"bomb.js\"],[0,[],0,\". Tam mogły by być jakiekolwiek operacje zużywające moc obliczeniową. W naszym przypadku jest to \"]]],[10,14],[1,\"p\",[[0,[],0,\"czyli kod napisany tylko po to, żeby symulować obciążenie. \"]]],[1,\"p\",[[0,[],0,\"Po włączeniu programu i wyborze kilku opcji obciążenia widzimy jak procesy są tworzone oraz kasowane. Dzięki \"],[0,[0],1,\"htop\"],[0,[],0,\" możemy zobaczyć jak w tym czasie zmienia się zużycie procesora.\"]]],[10,15],[1,\"p\",[[0,[],0,\"Nawet ładniejszy interfejs do monitoringu procesora ma \"],[0,[0],1,\"bashtop\"],[0,[],0,\", ponieważ wyświetla również historyczne zużycie. Na screenshocie poniżej widzimy, jak modyfikując ilość procesów w naszym programie mogłem symulować różne poziomy obłożenia procesora zadaniami.\"]]],[10,16],[1,\"p\",[[0,[],0,\"Oraz jak wyglądało wykorzystanie rdzeni, kiedy wybrałem opcję utworzenia 16 procesów.\"]]],[10,17],[1,\"p\",[[0,[],0,\"Tego programu możemy używać do symulowania obciążenia. W pliku \"],[0,[0],1,\"bomb.js\"],[0,[],0,\" możemy zastąpić losowanie liczb operacją wysyłania żądań http lub zużywania innych zasobów, na przykład pamięci operacyjnej lub dysku. \"]]],[1,\"h2\",[[0,[],0,\"Zrównoleglony atak brute-force na hasło\"]]],[1,\"p\",[[0,[],0,\"Do hashowania haseł w historii stosowano różne metody. Obecnie najbardziej popularny jest \"],[0,[0],1,\"bcrypt\"],[0,[],0,\", ale bardzo mocną pozycję zajmuje też nowocześniejszy \"],[0,[0],1,\"argon2i\"],[0,[],0,\". Upraszczając różnica między nimi polega na tym, że łamanie bcrypta wymaga dużej mocy obliczeniowej, a argona można tak skonfigurować, aby wymagane było posiadanie dużej ilości pamięci operacyjnej. W przypadku tego pierwszego zasobu, możemy łatwo kupić moc obliczeniową w bardzo dużych ilościach, dodatkowo nasze możliwości łamania haseł podnoszą układy graficzne i procesory strumieniowe. Jednak przy łamaniu argona znacznie trudniej jest zgromadzić wymagane do tego ilości pamięci operacyjnej w ramach jednej maszyny. Mój bardzo krótki opis warto rozszerzyć lekturą artykułu:\"]]],[10,18],[1,\"p\",[[0,[],0,\"W dalszej części wpisu pokażemy jak stosowanie wielu rdzeni przyśpiesza łamanie hasła zahashowanego algorytmem \"],[0,[0],1,\"bcrypt\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Napiszemy kod do generowania hashu hasła, złamiemy go używając jednego rdzenia, a następnie napiszemy ten sam kod korzystając z podporcesów którym będziemy zlecać sprawdzanie kolejnych fraz.\"]]],[1,\"h3\",[[0,[],0,\"Generowanie hasha hasła za pomocą bcrypt\"]]],[1,\"p\",[[0,[],0,\"Wymagana jest do tego instalacja paczki \"],[0,[0],1,\"bcrypt\"],[0,[],0,\":\"]]],[10,19],[1,\"p\",[[0,[],0,\"Hasło wygenerujemy za pomocą skryptu \"],[0,[0],1,\"generate_hash.js\"],[0,[],0,\", który przyjmuje argument będący hasłem i do pliku \"],[0,[0],1,\".pass\"],[0,[],0,\" zapisuje jego hash.\"]]],[10,20],[1,\"h3\",[[0,[],0,\"Łamanie hasła metodą brute force w jednym wątku\"]]],[1,\"p\",[[0,[],0,\"W ataku brute-force kluczowy jest zestaw znaków na których rozpinamy ciągi, które będziemy sprawdzać. Użyjemy standardowego alfabetu od \"],[0,[0],1,\"a\"],[0,[],0,\" do \"],[0,[0],1,\"z\"],[0,[],0,\". Będziemy go składać z samym sobą generując kolejne sekwencje znaków do sprawdzenia. Proces ich generowania i przetwarzania można umieścić w funkcji rekurencyjnej, ale przez to tracimy szansę na wygodne sterowanie kolejnością. Zamiast tego zastosujemy prostą kolejkę trzymaną w pamięci operacyjnej. Nie będzie ona rozładowywana, ponieważ rozładowywanie jej od przodu powodowało by zmianę indeksacji wewnątrz kolejki. Opisywałem już jak złe może to mieć skutki dla wydajności w artykule:\"]]],[10,21],[1,\"p\",[[0,[],0,\"Zamiast rozładowywać kolejkę będziemy odczytywać z niej wartości za pomocą zmiennego indeksu, który będzie przesuwał się wzdłuż niej. Schemat blokowy programu, który napiszemy jest następujący:\"]]],[10,22],[1,\"p\",[[0,[],0,\"Jego kod to:\"]]],[10,23],[1,\"p\",[[0,[],0,\"Do działania wymagana jest paczka \"],[0,[0],1,\"chalk\"],[0,[],0,\", która pozwala na łatwe kolorowanie tekstu:\"]]],[10,24],[1,\"p\",[[0,[],0,\"Przetestujmy nasz program.\"]]],[1,\"p\",[[0,[],0,\"Na początku wygenerujemy hasło. Zdecydujemy się na \\\"ac\\\", ponieważ jest proste i szybko je złamiemy\"]]],[10,25],[1,\"p\",[[0,[],0,\"Następnie włączamy nasz program i widzimy jak po kolei sprawdza hasła z kolejki\"]]],[10,26],[10,27],[1,\"p\",[[0,[],0,\"W kolumnach mamy kolejno indeks, sprawdzaną sekwencję, czas od włączenia programu w milisekundach, informację, czy hasło pasuje do hashu oraz aktualną długość kolejki.\"]]],[1,\"p\",[[0,[],0,\"Jeśli martwi Cię, że kolejka rośnie zbyt szybko i marnuje to dużo mocy, możemy zobaczyć, jak zachowa się program po zastąpieniu linii \"]]],[10,28],[1,\"p\",[[0,[],0,\"przez\"]]],[10,29],[1,\"p\",[[0,[],0,\"Okaże się wówczas, że czas wykonania skryptu spadnie z 7.27 sekundy do 0.17 sekundy.\"]]],[10,30],[1,\"p\",[[0,[],0,\"Co znaczy, że jedynie 2.3% mocy obliczeniowej jest przeznaczane na operacje inne niż samo porównywanie haseł.\"]]],[1,\"h3\",[[0,[],0,\"Wykorzystanie podprocesów do podniesienia wydajności\"]]],[1,\"p\",[[0,[],0,\"Ponieważ sprawdzanie zgodności hasła i hashu jest operacją intensywnie korzystającą z procesora spodziewamy się znacznego wzrostu wydajności tego zadania jeśli użyjemy do niego wielu rdzeni jednocześnie. Z tego względu przepiszemy nasz program tak, aby główny proces zamiast wykonywać sprawdzanie haseł zajmował się obsługą kolejki i zlecaniem sprawdzania podrzędnym procesom.\"]]],[10,31],[1,\"p\",[[0,[],0,\"Schemat naszego programu dzieli się na proces główny oraz podprocesy. W procesie głównym tworzona jest lista procesów podrzędnych, kolejka oraz nasłuchy na wiadomości z podprocesów. Na końcu każdy podproces dostaje do wykonania zadanie z kolejki. Podprocesy po ich wykonaniu zgłaszają się do głównego wątku z odpowiedzą, a ten podnosi indeks i przydziela im nowe zadania. Dzieje się tak aż do znalezienia poprawnego hasła.  \"]]],[10,32],[1,\"p\",[[0,[],0,\"Warto zwrócić uwagę na to, że niezależne dzieci będą wykonywały zadania z różną prędkością co wpłynie na kolejność zgłaszania odpowiedzi. Przykładowy output programu to:\"]]],[10,33],[1,\"p\",[[0,[],0,\"Kod dzieli się na dwa pliki:\"]]],[3,\"ul\",[[[0,[],0,\"force-child.js - proces główny używający dzieci\"]],[[0,[],0,\"force-fork.js - podproces do sprawdzania haseł przez bcrypt\"]]]],[1,\"p\",[[0,[],0,\"Zaczniemy analizę procesy głównego - \"],[0,[0],1,\"force-child.js\"],[0,[],0,\". Program startuje od zdefiniowania alfabetu oraz zmiennych pomocniczych do indeksowania i liczenia czasu.\"]]],[10,34],[1,\"p\",[[0,[],0,\" Następnie wypełniamy kolejkę alfabetem\"]]],[10,35],[1,\"p\",[[0,[],0,\"Funkcja \"],[0,[0],1,\"check\"],[0,[],0,\" w jednowątkowej wersji programu dostawała frazę, sprawdzała ją i rozszerzała kolejkę. Tym razem oprócz frazy, argumentem będzie podproces wybrany do wykonania sprawdzenia - \"],[0,[0],1,\"f\"],[0,[],0,\". Zamiast używać \"],[0,[0],1,\"bcrypt\"],[0,[],0,\" bezpośrednio wyślemy podprocesowi żądanie przetworzenia frazy i rozbudujemy kolejkę. \"]]],[10,36],[1,\"p\",[[0,[],0,\"Pozbyliśmy się tu słowa \"],[0,[0],1,\"async\"],[0,[],0,\" przez co nie musimy czekać na wykonanie tej funkcji. Jest to proste oddelegowanie zadania. Kluczowym elementem tego kodu jest wysyłka wiadomości do podprocesu realizowana przez funkcję \"],[0,[0],1,\"send\"],[0,[],0,\" wykonaną bezpośrednio na podprocesie.\"]]],[1,\"p\",[[0,[],0,\"Kolejna funkcja \"],[0,[0],1,\"processQue\"],[0,[],0,\" służy nam do wykonania pojedynczego taktowania na kolejce \"]]],[10,37],[1,\"p\",[[0,[],0,\"Jest bardzo krótka i jej głównym zadaniem zapobieganie duplikacji logiki odpowiedzialnej za iterowanie po kolejce.\"]]],[1,\"p\",[[0,[],0,\"Główną funkcją programu jest \"],[0,[0],1,\"main\"],[0,[],0,\" i odpowiada za ustawienie nasłuchów na odpowiedzi z podprocesów oraz zlecenie im początkowych zadań, które pozwalają wejść w pętlę komunikacji między nimi.\"]]],[10,38],[1,\"p\",[[0,[],0,\"Zanim wywołamy funkcję \"],[0,[0],1,\"main\"],[0,[],0,\" wymagane jest powołanie do życia procesów w tablicy \"],[0,[0],1,\"forks\"],[0,[],0,\":\"]]],[10,39],[1,\"p\",[[0,[],0,\"Zalecaną ich liczbą jest wartość zbliżona do ilości wątków procesora ale mniejsza od niej, tak, aby proces główny nie był blokowany.\"]]],[1,\"p\",[[0,[],0,\"Na końcu drukujemy informacje o programie, nazwy kolumn i startujemy funkcję \"],[0,[0],1,\"main\"]]],[10,40],[1,\"p\",[[0,[],0,\"Drugi plik - \"],[0,[0],1,\"force-fork.js\"],[0,[],0,\" jest znacznie prostszy i zawiera jedynie odczytanie \"],[0,[0],1,\"hasha\"],[0,[],0,\" oraz oczekiwanie na zadania. Kiedy je dostaje sprawdza testowane hasło \"],[0,[0],1,\"bcryptem\"],[0,[],0,\" po czym odsyła wynik tym samym kanałem komunikacji.\"]]],[10,41],[1,\"h2\",[[0,[],0,\"Analiza skalowalności\"]]],[1,\"p\",[[0,[],0,\"Wnikliwy czytelnik zapewne zauważył niepozorną ale ważną dla dalszej części artykułu linię kodu:\"]]],[10,42],[1,\"p\",[[0,[],0,\"Wykonuje się ona po znalezieniu hasła i załącza do pliku \"],[0,[0],1,\"logs.txt\"],[0,[],0,\" ilość podprocesów oraz czas znalezienia hasła. Dane do tego pliku zostały dostarczone dzięki wykonaniu podwójnej pętli w \"],[0,[0],1,\"bashu\"]]],[10,43],[1,\"p\",[[0,[],0,\"Oraz później rozbudowania tych wyników o wyższą liczbę procesów\"]]],[10,44],[1,\"p\",[[0,[],0,\"Zgodnie z Ogólnym Prawem Skalowania spodziewamy się wzrostu wydajności do pewnego etapu ( koło 15 rdzeni ) i późniejszego spadku związanego z opóźnieniami spowodowanymi wzajemnym blokowaniem się podprocesów.\"]]],[1,\"h3\",[[0,[],0,\"Uniwersalne prawo skalowania\"]]],[1,\"p\",[[0,[],0,\"Jeśli nie słyszałeś o uniwersalnym prawie skalowania, to szybko wprowadzę Cię do tego tematu. Chodzi o to, że w idealnym świecie, gdyby systemy były skalowalne liniowo, to znaczyło by, że dołożenie \"],[0,[0],1,\"n\"],[0,[],0,\" razy więcej zasobów podnosi wydajność lub przepustowość systemu \"],[0,[0],1,\"n\"],[0,[],0,\" razy. Taką sytuację może obrazować rysunek:\"]]],[10,45],[1,\"p\",[[0,[],0,\"Takich sytuacji nie spotyka się jednak w świecie rzeczywistym. Zawsze bowiem występuje pewna nieefektywność związana z przydzielaniem danych do węzłów (serwerów lub wątków) oraz z ich zbieraniem. Opóźnienia związane z przydzielaniem i odbieraniem danych nazywa się serializacją, czasami można spotkać termin \"],[0,[0],1,\"contention\"],[0,[],0,\":\"]]],[10,46],[1,\"p\",[[0,[],0,\"Uwzględnienie tego zjawiska prowadzi do modelu Amdahl`a. Okazuje się jednak, że jest on niewystarczający dla większości systemów IT ponieważ całkowicie pomija drugi główny czynnik ograniczający skalowanie - komunikację między procesami - \"],[0,[0],1,\"crosstalk\"],[0,[],0,\". Graficznie można ją przedstawić tak:\"]]],[10,47],[1,\"p\",[[0,[],0,\"O ile serializacja ma koszt proporcjonalny do ilości węzłów, to komunikacja jest proporcjonalna do ich kwadratu - tak jak liczba przekątnych wielokąta do ilości kątów\"]]],[10,48],[1,\"p\",[[0,[],0,\"Na wykresie widzimy krzywe porównujące wpływ ilości węzłów na wydajność w systemu według tych trzech modeli.\"]]],[10,49],[1,\"p\",[[0,[],0,\"Dobre (50 stron) opracowanie na ten temat znajduje się pod linkiem:\"]]],[1,\"p\",[[0,[1],1,\"https://cdn2.hubspot.net/hubfs/498921/eBooks/scalability_new.pdf\"]]],[1,\"h3\",[[0,[],0,\"Zestawienie danych pomiarowych z modelem USL\"]]],[1,\"p\",[[0,[],0,\"Zebrane dane to ilości wątków oraz czasy wykonywania programu. Ładujemy do do programu \"],[0,[0],1,\"Mathematica\"],[0,[],0,\" komendą:\"]]],[10,50],[1,\"p\",[[0,[],0,\"Ponieważ chcemy rozważać wydajność a nie czas wykonywania odwracamy drugą kolumnę poleceniem\"]]],[10,51],[1,\"p\",[[0,[],0,\"Najbardziej sensowną jednostką jest normalizacja względem czasu wykonania dla jednego podprocesu. Pozwoli nam to widzieć zysk z dokładania kolejnych procesów. Średnią z tych czasów liczymy dzięki poleceniu\"]]],[10,52],[1,\"p\",[[0,[],0,\"Następnie dopasowujemy model:\"]]],[10,53],[1,\"p\",[[0,[],0,\"I zestawiamy go z wykresem listy punktów pomiarowych\"]]],[10,54],[10,55],[1,\"p\",[[0,[],0,\"Warto pokazać tu bardzo ładny wzór na teoretyczne maksimum\"]]],[10,56],[10,57],[1,\"p\",[[0,[],0,\"Wyliczona numerycznie\"]]],[10,58],[1,\"p\",[[0,[],0,\"optymalna ilość procesów to \"],[0,[0],1,\"14.8271\"],[0,[],0,\". Kila akapitów wcześniej pisałem, że zaleca się wartość nieznacznie niższą niż ilość dostępnych wątków - u mnie było ich 16.\"]]],[1,\"h2\",[[0,[],0,\"Procesy, Workery i Klastry w Node JS\"]]],[1,\"p\",[[0,[],0,\"Ten artykuł skupiał się na procesach opisanych w dokumentacji pod linkiem\"]]],[10,59],[1,\"p\",[[0,[],0,\"Pokazaliśmy w nim jak tworzyć podprocesy, zabijać je. Jak dynamicznie zarządzać ilością podporcesów i prowadzić z nimi dwustronną komunikację. Na końcu zestawiliśmy skalowalność łamania haseł metodą bruteforce z przewidywaniami uniwersalnego prawa skalowania.\"]]],[1,\"p\",[[0,[],0,\"Jednak ten temat został przez nas jedynie delikatnie muśnięty. Nie pisałem nic na temat klastrów opisanych tutaj:\"]]],[10,60],[1,\"p\",[[0,[],0,\"Ani workerów, które również mają osobny rozdział do dokumentacji\"]]],[10,61],[1,\"p\",[[0,[],0,\"Zachęcam Was do samodzielnej lektury dokumentacji \"],[0,[0],1,\"Node JS\"],[0,[],0,\" i projektowania własnych eksperymentów.\"]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>W tym wpisie nauczymy się jak tworzyć i kończyć podprocesy w Node JS oraz jak przesyłać między nimi dane.</p><p>Jeśli program wykonuje ciężkie obliczenia ale nie jest zrównoleglony, stan Twojego procesora może wyglądać tak:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/cpu0-12.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"626\"></figure><p>Dlatego warto zgłębić ten temat niezależnie od języka w którym piszesz.</p><p>Artykuł będzie podzielony na 3 części:</p><ul><li>sterowanie procesem za pomocą <code>readline</code></li><li>tworzenie i zabijanie podprocesów</li><li>komunikacja między procesami</li></ul><p>W pierwszych dwóch napiszemy skrypt do symulowania obciążenia rdzeni procesora. W ostatniej zrównoleglimy atak brutforce na hasło.</p><p>Na końcu przeanalizujemy skalowalność napisanego programu.</p><h2 id=\"sterowanie-procesem-z-readline\">Sterowanie procesem z <code>readline</code></h2><p>Chcemy napisać program, w którym wciskając klawisz na klawiaturze będziemy ustawiać ile rdzeni procesora ma zostać obciążonych. Zaczniemy od przechwytywania zdarzeń z klawiatury w czasie rzeczywistym.</p><p>Pozwoli nam na to moduł <code>readline</code> dostarczający interfejs do zapisu i odczytu danych ze strumieni takich jak klawiatura - <code>process.stdin</code>.</p><p>Zaczniemy od importu tego modułu</p><pre><code>const readline = require('readline');</code></pre><p>Następnie ustawiamy emitowanie zdarzenia z <code>readline</code> na naciśnięcie przycisku na klawiaturze poleceniem</p><pre><code>readline.emitKeypressEvents(process.stdin);</code></pre><p>Sam <code>readline</code> może pracować z różnymi strumieniami. Tą linią wskazujemy mu, żeby nasłuchiwał na klawiaturę. Od razu ustawiamy mod na <code>raw</code></p><pre><code>process.stdin.setRawMode(true);</code></pre><p>Pozwala to odczytywać z klawiatury znak po znaku z osobno załączanymi modyfikatorami jak ctrl czy shift. Jednocześnie ten tryb wymusza samodzielne obsłużenie wyłączenia procesu przez <code>ctrl+c</code>. Więcej na temat trybów strumieni i podłączania terminala do procesu możemy przeczytać w dokumentacji:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://nodejs.org/api/readline.html#readline_readline_emitkeypressevents_stream_interface\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Readline | Node.js v16.5.0 Documentation</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">Node.js v16.5.0 Documentation</span></div></div></a></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://nodejs.org/api/tty.html#tty_readstream_setrawmode_mode\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">TTY | Node.js v16.5.0 Documentation</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">Node.js v16.5.0 Documentation</span></div></div></a></figure><p>Tym czasem w naszym programie kolejne linie pozwolą obsłużyć odczyt znaków:</p><pre><code>process.stdin.on('keypress', (str, key) =&gt; {\n    if (key.ctrl &amp;&amp; key.name === 'c') {\n        process.exit();\n    } else {\n        console.log('typed char', key.name);\n    }\n});</code></pre><p>Znak zapisany w <code>key</code> jest obiektem o następujących kluczach</p><pre><code>{ sequence: 'v', name: 'v', ctrl: false, meta: false, shift: false }</code></pre><p>W prezentowanym kodzie obsługujemy zamknięcie procesu kombinacją <code>ctrl+c</code> oraz wypisanie w konsoli znaku wybranego na klawiaturze. Wpisywanie kolejnych znaków będzie za każdym razem pokazywało je w terminalu.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-16-18-15-24.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"273\" height=\"205\"></figure><p>Następnym krokiem jest zastąpienie wypisywania znaków przez tworzenie lub kasowanie procesów obciążających procesor.</p><h2 id=\"tworzenie-i-zabijanie-proces%C3%B3w-w-node-js\">Tworzenie i zabijanie procesów w Node JS</h2><p>W Node JS, możemy bardzo łatwo tworzyć podprocesy i zarządzać nimi. Do zarządzania podprocesami możemy użyć modułu <code>child_process</code>. Importujemy go jak poprzedni moduł</p><pre><code>const cp = require('child_process');</code></pre><p>Następnie tworzymy tablicę, do której będziemy zapisywali referencje do tworzonych procesów.</p><pre><code>const forks = [];</code></pre><p>Jeśli zapomnieli byśmy o nich przy zamykaniu programu to stały by się one procesami <code>zombie</code> - czyli takimi, które żyją nadal i bez nadzoru pożerają zasoby komputera.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/one-does-not-simply-kill-a-zombie-process.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"335\" height=\"335\"></figure><p>Aby je usunąć przed zamknięciem naszego skryptu piszemy kod:</p><pre><code>    if (key.ctrl &amp;&amp; key.name === 'c') {\n        while (forks.length &gt; 0) {\n            forks[forks.length - 1].kill()\n            forks.pop()\n        }\n        process.exit();\n    } else {</code></pre><p>W przypadku wybrania innych przycisków niż <code>c</code> w obecności <code>ctrl</code> odczytamy wartość liczbową tego przycisku i na jej podstawie dodamy lub zabijemy odpowiednią liczbę procesów aby ich ilość równa była tej liczbie.</p><pre><code>        if (!Number.isNaN(parseInt(key.name,32))) {\n            const req = parseInt(key.name,32);\n\n            if (forks.length &lt; req) {\n                while (forks.length &lt; req) {\n                    const n = cp.fork(`${__dirname}/bomb.js`);\n                    forks.push(n)\n                }\n            }\n\n            if (forks.length &gt; req) {\n                while (forks.length &gt; req) {\n                    forks[forks.length - 1].kill()\n                    forks.pop()\n                }\n            }\n\n            console.log('processes PIDs', forks.map(f =&gt; f.pid));\n\n        }</code></pre><p>Dziwić może wybór systemu liczbowego <code>32</code>. Jednak jest to wygodny system jeśli założymy, że za pomocą jednego klawisza chcemy wskazać niewielką lecz przekraczającą 10 liczbę.</p><p>Do zmiennej <code>req</code> trafia wymagana liczba procesów, a dzięki <code>cp.fork</code> lub <code>kill</code> tworzymy i zabijamy brakujące lub nadmiarowe procesy. </p><p>Do złożenia całości brakuje nam jedynie zawartości pliku <code>bomb.js</code>. Tam mogły by być jakiekolwiek operacje zużywające moc obliczeniową. W naszym przypadku jest to </p><pre><code>let result = 0;\nwhile (true) {\n    result += Math.random() * Math.random();\n}</code></pre><p>czyli kod napisany tylko po to, żeby symulować obciążenie. </p><p>Po włączeniu programu i wyborze kilku opcji obciążenia widzimy jak procesy są tworzone oraz kasowane. Dzięki <code>htop</code> możemy zobaczyć jak w tym czasie zmienia się zużycie procesora.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-16-18-51-17.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"539\" height=\"607\"></figure><p>Nawet ładniejszy interfejs do monitoringu procesora ma <code>bashtop</code>, ponieważ wyświetla również historyczne zużycie. Na screenshocie poniżej widzimy, jak modyfikując ilość procesów w naszym programie mogłem symulować różne poziomy obłożenia procesora zadaniami.</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-16-15-26-13.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1850\" height=\"371\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-16-15-26-13.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-16-15-26-13.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/07/Screenshot-from-2021-07-16-15-26-13.png 1600w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-16-15-26-13.png 1850w\"></figure><p>Oraz jak wyglądało wykorzystanie rdzeni, kiedy wybrałem opcję utworzenia 16 procesów.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-16-15-30-03.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"450\" height=\"232\"></figure><p>Tego programu możemy używać do symulowania obciążenia. W pliku <code>bomb.js</code> możemy zastąpić losowanie liczb operacją wysyłania żądań http lub zużywania innych zasobów, na przykład pamięci operacyjnej lub dysku. </p><h2 id=\"zr%C3%B3wnoleglony-atak-brute-force-na-has%C5%82o\">Zrównoleglony atak brute-force na hasło</h2><p>Do hashowania haseł w historii stosowano różne metody. Obecnie najbardziej popularny jest <code>bcrypt</code>, ale bardzo mocną pozycję zajmuje też nowocześniejszy <code>argon2i</code>. Upraszczając różnica między nimi polega na tym, że łamanie bcrypta wymaga dużej mocy obliczeniowej, a argona można tak skonfigurować, aby wymagane było posiadanie dużej ilości pamięci operacyjnej. W przypadku tego pierwszego zasobu, możemy łatwo kupić moc obliczeniową w bardzo dużych ilościach, dodatkowo nasze możliwości łamania haseł podnoszą układy graficzne i procesory strumieniowe. Jednak przy łamaniu argona znacznie trudniej jest zgromadzić wymagane do tego ilości pamięci operacyjnej w ramach jednej maszyny. Mój bardzo krótki opis warto rozszerzyć lekturą artykułu:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://medium.com/analytics-vidhya/password-hashing-pbkdf2-scrypt-bcrypt-and-argon2-e25aaf41598e\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Password Hashing: PBKDF2, Scrypt, Bcrypt and ARGON2</div><div class=\"kg-bookmark-description\">There’s always a lot of debate in regards to how to safely store passwords and what algorithm to use: MD5, SHA1, SHA256, PBKDF2, Bcrypt, Scrypt, Argon2, plaintext?? So I tried to analyse and…</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png\"><span class=\"kg-bookmark-author\">Analytics Vidhya</span><span class=\"kg-bookmark-publisher\">Michele Preziuso</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://miro.medium.com/max/1200/1*6AmtTHis9u0viVhIzg9tsA.png\"></div></a></figure><p>W dalszej części wpisu pokażemy jak stosowanie wielu rdzeni przyśpiesza łamanie hasła zahashowanego algorytmem <code>bcrypt</code>. </p><p>Napiszemy kod do generowania hashu hasła, złamiemy go używając jednego rdzenia, a następnie napiszemy ten sam kod korzystając z podporcesów którym będziemy zlecać sprawdzanie kolejnych fraz.</p><h3 id=\"generowanie-hasha-has%C5%82a-za-pomoc%C4%85-bcrypt\">Generowanie hasha hasła za pomocą bcrypt</h3><p>Wymagana jest do tego instalacja paczki <code>bcrypt</code>:</p><pre><code>npm init -y &amp;&amp; npm i bcrypt</code></pre><p>Hasło wygenerujemy za pomocą skryptu <code>generate_hash.js</code>, który przyjmuje argument będący hasłem i do pliku <code>.pass</code> zapisuje jego hash.</p><pre><code>const fs = require('fs')\nconst bc = require('bcrypt')\n\nconst main = async () =&gt; {\n    return bc.hash(process.argv[2] || 'pass', 11)\n}\n\nmain().then(p =&gt; {\n    fs.writeFileSync(`${__dirname}/.pass`, p);\n    console.log(p)\n}).catch(console.error);</code></pre><h3 id=\"%C5%82amanie-has%C5%82a-metod%C4%85-brute-force-w-jednym-w%C4%85tku\">Łamanie hasła metodą brute force w jednym wątku</h3><p>W ataku brute-force kluczowy jest zestaw znaków na których rozpinamy ciągi, które będziemy sprawdzać. Użyjemy standardowego alfabetu od <code>a</code> do <code>z</code>. Będziemy go składać z samym sobą generując kolejne sekwencje znaków do sprawdzenia. Proces ich generowania i przetwarzania można umieścić w funkcji rekurencyjnej, ale przez to tracimy szansę na wygodne sterowanie kolejnością. Zamiast tego zastosujemy prostą kolejkę trzymaną w pamięci operacyjnej. Nie będzie ona rozładowywana, ponieważ rozładowywanie jej od przodu powodowało by zmianę indeksacji wewnątrz kolejki. Opisywałem już jak złe może to mieć skutki dla wydajności w artykule:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://gustawdaniel.com/ile-rodzin-zmiesci-sie-w-samolocie/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Ile rodzin zmieści się w samolocie - zadanie z algorytmiki</div><div class=\"kg-bookmark-description\">Porównujemy dwa rozwiązania zadania polegającego na zliczaniu wolnych zestawów przyległych miejsc. Dowiesz się jak używać Profilowania i jak wielką różnicę robi użycie pop oraz shift na tablicach w js.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"__GHOST_URL__/favicon.ico\"><span class=\"kg-bookmark-author\">Daniel Gustaw</span><span class=\"kg-bookmark-publisher\">Daniel Gustaw</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"__GHOST_URL__/content/images/2021/04/31742.jpg\"></div></a></figure><p>Zamiast rozładowywać kolejkę będziemy odczytywać z niej wartości za pomocą zmiennego indeksu, który będzie przesuwał się wzdłuż niej. Schemat blokowy programu, który napiszemy jest następujący:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-13-44-09.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"435\" height=\"455\"></figure><p>Jego kod to:</p><pre><code class=\"language-javascript\">const fs = require('fs');\nconst bc = require('bcrypt');\nconst alphabet = String.fromCharCode(...Array(123).keys()).slice(97);\nconst hash = fs.readFileSync(`${__dirname}/.pass`).toString()\nconst chalk = require('chalk')\n\nlet i = 0;\nconst s = new Date().getTime();\nconst n = () =&gt; new Date().getTime() - s;\nlet found = false;\n\nconst que = [];\n\nasync function check(input) {\n    if (found) return;\n    const r = await bc.compare(input, hash)\n\n    console.log(`${i}\\t${input}\\t${n()}\\t${r}\\t${que.length}`)\n    if (r) {\n        console.log(chalk.green(`FOUND: \"${input}\"`))\n        found = true;\n        process.exit();\n    }\n    for (let n of alphabet) {\n        que.push(input + n);\n    }\n}\n\nasync function processQue() {\n    const phrase = que[i++]\n    await check(phrase)\n}\n\nconst main = async () =&gt; {\n    while (!found) {\n        await processQue()\n    }\n}\n\nconsole.log(`i\\tinput\\tn()\\tr\\tque.length`)\ncheck('').then(() =&gt; main()).catch(console.error)</code></pre><p>Do działania wymagana jest paczka <code>chalk</code>, która pozwala na łatwe kolorowanie tekstu:</p><pre><code>npm i chalk</code></pre><p>Przetestujmy nasz program.</p><p>Na początku wygenerujemy hasło. Zdecydujemy się na \"ac\", ponieważ jest proste i szybko je złamiemy</p><pre><code>node generate_hash.js ac</code></pre><p>Następnie włączamy nasz program i widzimy jak po kolei sprawdza hasła z kolejki</p><pre><code>time node force-single.js</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-13-48-47.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"438\" height=\"559\"></figure><p>W kolumnach mamy kolejno indeks, sprawdzaną sekwencję, czas od włączenia programu w milisekundach, informację, czy hasło pasuje do hashu oraz aktualną długość kolejki.</p><p>Jeśli martwi Cię, że kolejka rośnie zbyt szybko i marnuje to dużo mocy, możemy zobaczyć, jak zachowa się program po zastąpieniu linii </p><pre><code>const r = await bc.compare(input, hash)</code></pre><p>przez</p><pre><code>const r = i &gt;= 29 // await bc.compare(input, hash)</code></pre><p>Okaże się wówczas, że czas wykonania skryptu spadnie z 7.27 sekundy do 0.17 sekundy.</p><pre><code>node force-single.js  0.17s user 0.03s system 103% cpu 0.188 total</code></pre><p>Co znaczy, że jedynie 2.3% mocy obliczeniowej jest przeznaczane na operacje inne niż samo porównywanie haseł.</p><h3 id=\"wykorzystanie-podproces%C3%B3w-do-podniesienia-wydajno%C5%9Bci\">Wykorzystanie podprocesów do podniesienia wydajności</h3><p>Ponieważ sprawdzanie zgodności hasła i hashu jest operacją intensywnie korzystającą z procesora spodziewamy się znacznego wzrostu wydajności tego zadania jeśli użyjemy do niego wielu rdzeni jednocześnie. Z tego względu przepiszemy nasz program tak, aby główny proces zamiast wykonywać sprawdzanie haseł zajmował się obsługą kolejki i zlecaniem sprawdzania podrzędnym procesom.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/bFbMbDgAT6M6T4zsVmk16Oiip7vIOWaeuEY0vTkkZoU.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"505\" height=\"256\"></figure><p>Schemat naszego programu dzieli się na proces główny oraz podprocesy. W procesie głównym tworzona jest lista procesów podrzędnych, kolejka oraz nasłuchy na wiadomości z podprocesów. Na końcu każdy podproces dostaje do wykonania zadanie z kolejki. Podprocesy po ich wykonaniu zgłaszają się do głównego wątku z odpowiedzą, a ten podnosi indeks i przydziela im nowe zadania. Dzieje się tak aż do znalezienia poprawnego hasła.  </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-16-35.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"705\" height=\"731\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-17-14-16-35.png 600w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-16-35.png 705w\"></figure><p>Warto zwrócić uwagę na to, że niezależne dzieci będą wykonywały zadania z różną prędkością co wpłynie na kolejność zgłaszania odpowiedzi. Przykładowy output programu to:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-26-11.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"416\" height=\"652\"></figure><p>Kod dzieli się na dwa pliki:</p><ul><li>force-child.js - proces główny używający dzieci</li><li>force-fork.js - podproces do sprawdzania haseł przez bcrypt</li></ul><p>Zaczniemy analizę procesy głównego - <code>force-child.js</code>. Program startuje od zdefiniowania alfabetu oraz zmiennych pomocniczych do indeksowania i liczenia czasu.</p><pre><code>const cp = require('child_process');\nconst fs = require('fs');\nconst chalk = require('chalk')\n\nconst alphabet = String.fromCharCode(...Array(123).keys()).slice(97);\nconst forks = [];\n\nlet i = 0;\nconst s = new Date().getTime();\nconst n = () =&gt; new Date().getTime() - s;\nlet found = false;</code></pre><p> Następnie wypełniamy kolejkę alfabetem</p><pre><code>const que = alphabet.split('');</code></pre><p>Funkcja <code>check</code> w jednowątkowej wersji programu dostawała frazę, sprawdzała ją i rozszerzała kolejkę. Tym razem oprócz frazy, argumentem będzie podproces wybrany do wykonania sprawdzenia - <code>f</code>. Zamiast używać <code>bcrypt</code> bezpośrednio wyślemy podprocesowi żądanie przetworzenia frazy i rozbudujemy kolejkę. </p><pre><code>function check(input, f) {\n    if (found) return;\n\n    f.send(input);\n\n    for (let n of alphabet) {\n        que.push(input + n);\n    }\n}</code></pre><p>Pozbyliśmy się tu słowa <code>async</code> przez co nie musimy czekać na wykonanie tej funkcji. Jest to proste oddelegowanie zadania. Kluczowym elementem tego kodu jest wysyłka wiadomości do podprocesu realizowana przez funkcję <code>send</code> wykonaną bezpośrednio na podprocesie.</p><p>Kolejna funkcja <code>processQue</code> służy nam do wykonania pojedynczego taktowania na kolejce </p><pre><code>function processQue(f) {\n    const phrase = que[i++]\n    check(phrase, f)\n}</code></pre><p>Jest bardzo krótka i jej głównym zadaniem zapobieganie duplikacji logiki odpowiedzialnej za iterowanie po kolejce.</p><p>Główną funkcją programu jest <code>main</code> i odpowiada za ustawienie nasłuchów na odpowiedzi z podprocesów oraz zlecenie im początkowych zadań, które pozwalają wejść w pętlę komunikacji między nimi.</p><pre><code>const main = async () =&gt; {\n    forks.forEach(f =&gt; {\n        f.on('message', ({input, r}) =&gt; {\n            console.log(`${i}\\t${input}\\t${n()}\\t${r}\\t${que.length}\\t${f.pid}`)\n\n            if (r) {\n                console.log(chalk.green(`FOUND: \"${input}\"`))\n                found = true;\n\n                fs.appendFileSync('logs.txt', `${forks.length},${n()}\\n`)\n\n                while (forks.length &gt; 0) {\n                    forks[forks.length - 1].kill()\n                    forks.pop()\n                }\n\n                process.exit();\n            } else {\n                processQue(f);\n            }\n        });\n        processQue(f);\n    })\n}</code></pre><p>Zanim wywołamy funkcję <code>main</code> wymagane jest powołanie do życia procesów w tablicy <code>forks</code>:</p><pre><code>while (forks.length &lt; (process.argv[2] || 15)) {\n    const n = cp.fork(`${__dirname}/force-fork.js`);\n    forks.push(n)\n}</code></pre><p>Zalecaną ich liczbą jest wartość zbliżona do ilości wątków procesora ale mniejsza od niej, tak, aby proces główny nie był blokowany.</p><p>Na końcu drukujemy informacje o programie, nazwy kolumn i startujemy funkcję <code>main</code></p><pre><code>console.log(chalk.blue(`Run using ${forks.length} child processes`))\nconsole.log(`i\\tinput\\tn()\\tr\\tque.length\\tpid`)\nmain().catch(console.error)</code></pre><p>Drugi plik - <code>force-fork.js</code> jest znacznie prostszy i zawiera jedynie odczytanie <code>hasha</code> oraz oczekiwanie na zadania. Kiedy je dostaje sprawdza testowane hasło <code>bcryptem</code> po czym odsyła wynik tym samym kanałem komunikacji.</p><pre><code>const fs = require('fs');\nconst bc = require('bcrypt');\n\nconst hash = fs.readFileSync(`${__dirname}/.pass`).toString()\n\nprocess.on('message', (input) =&gt; {\n    bc.compare(input, hash).then((r) =&gt; {\n        process.send({r, input});\n    })\n});</code></pre><h2 id=\"analiza-skalowalno%C5%9Bci\">Analiza skalowalności</h2><p>Wnikliwy czytelnik zapewne zauważył niepozorną ale ważną dla dalszej części artykułu linię kodu:</p><pre><code>fs.appendFileSync('logs.txt', `${forks.length},${n()}\\n`)</code></pre><p>Wykonuje się ona po znalezieniu hasła i załącza do pliku <code>logs.txt</code> ilość podprocesów oraz czas znalezienia hasła. Dane do tego pliku zostały dostarczone dzięki wykonaniu podwójnej pętli w <code>bashu</code></p><pre><code>for j in $(seq 1 20); do for i in $(seq 1 25); do time node force-child.js $i; sleep 4; done; done;</code></pre><p>Oraz później rozbudowania tych wyników o wyższą liczbę procesów</p><pre><code>for j in $(seq 1 5); do for i in $(seq 1 50); do time node force-child.js $i; sleep 4; done; done;</code></pre><p>Zgodnie z Ogólnym Prawem Skalowania spodziewamy się wzrostu wydajności do pewnego etapu ( koło 15 rdzeni ) i późniejszego spadku związanego z opóźnieniami spowodowanymi wzajemnym blokowaniem się podprocesów.</p><h3 id=\"uniwersalne-prawo-skalowania\">Uniwersalne prawo skalowania</h3><p>Jeśli nie słyszałeś o uniwersalnym prawie skalowania, to szybko wprowadzę Cię do tego tematu. Chodzi o to, że w idealnym świecie, gdyby systemy były skalowalne liniowo, to znaczyło by, że dołożenie <code>n</code> razy więcej zasobów podnosi wydajność lub przepustowość systemu <code>n</code> razy. Taką sytuację może obrazować rysunek:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-29.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1091\" height=\"372\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-17-14-56-29.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-17-14-56-29.png 1000w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-29.png 1091w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Takich sytuacji nie spotyka się jednak w świecie rzeczywistym. Zawsze bowiem występuje pewna nieefektywność związana z przydzielaniem danych do węzłów (serwerów lub wątków) oraz z ich zbieraniem. Opóźnienia związane z przydzielaniem i odbieraniem danych nazywa się serializacją, czasami można spotkać termin <code>contention</code>:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-40.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1108\" height=\"378\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-17-14-56-40.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-17-14-56-40.png 1000w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-40.png 1108w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Uwzględnienie tego zjawiska prowadzi do modelu Amdahl`a. Okazuje się jednak, że jest on niewystarczający dla większości systemów IT ponieważ całkowicie pomija drugi główny czynnik ograniczający skalowanie - komunikację między procesami - <code>crosstalk</code>. Graficznie można ją przedstawić tak:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-46.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"928\" height=\"441\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-17-14-56-46.png 600w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-46.png 928w\" sizes=\"(min-width: 720px) 720px\"></figure><p>O ile serializacja ma koszt proporcjonalny do ilości węzłów, to komunikacja jest proporcjonalna do ich kwadratu - tak jak liczba przekątnych wielokąta do ilości kątów</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-14-56-51.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"323\" height=\"286\"></figure><p>Na wykresie widzimy krzywe porównujące wpływ ilości węzłów na wydajność w systemu według tych trzech modeli.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"__GHOST_URL__/content/images/2021/07/usl.svg\" class=\"kg-image\" alt loading=\"lazy\" width=\"1019\" height=\"457\"></figure><p>Dobre (50 stron) opracowanie na ten temat znajduje się pod linkiem:</p><p><a href=\"https://cdn2.hubspot.net/hubfs/498921/eBooks/scalability_new.pdf\">https://cdn2.hubspot.net/hubfs/498921/eBooks/scalability_new.pdf</a></p><h3 id=\"zestawienie-danych-pomiarowych-z-modelem-usl\">Zestawienie danych pomiarowych z modelem USL</h3><p>Zebrane dane to ilości wątków oraz czasy wykonywania programu. Ładujemy do do programu <code>Mathematica</code> komendą:</p><pre><code>load = Import[\"/home/daniel/exp/node/logs.txt\", \"Data\"];</code></pre><p>Ponieważ chcemy rozważać wydajność a nie czas wykonywania odwracamy drugą kolumnę poleceniem</p><pre><code>loadEff = {#[[1]], 1/#[[2]]} &amp; /@ load;</code></pre><p>Najbardziej sensowną jednostką jest normalizacja względem czasu wykonania dla jednego podprocesu. Pozwoli nam to widzieć zysk z dokładania kolejnych procesów. Średnią z tych czasów liczymy dzięki poleceniu</p><pre><code>firstMean = GroupBy[loadEff // N, First -&gt; Last, Mean][[1]];</code></pre><p>Następnie dopasowujemy model:</p><pre><code>nlm = NonlinearModelFit[{#[[1]], #[[2]]/firstMean} &amp; /@ \n   loadEff, \\[Lambda] n/(1 + \\[Sigma] (n - 1) + \\[Kappa] n (n - \n         1)), {{\\[Lambda], 0.9}, {\\[Sigma], 0.9}, {\\[Kappa], \n    0.1}}, {n}]</code></pre><p>I zestawiamy go z wykresem listy punktów pomiarowych</p><pre><code>Show[ListPlot[{#[[1]], #[[2]]/firstMean} &amp; /@ loadEff], \n Plot[nlm[s], {s, 0, 50}, PlotStyle -&gt; Orange, PlotRange -&gt; All], \n AxesLabel -&gt; {\"processes\", \"gain of efficiency\"}, ImageSize -&gt; Large,\n  PlotLabel -&gt; \"Gain of efficiency relative to single process\"]</code></pre><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"__GHOST_URL__/content/images/2021/07/gain-eff.svg\" class=\"kg-image\" alt loading=\"lazy\" width=\"768\" height=\"457\"></figure><p>Warto pokazać tu bardzo ładny wzór na teoretyczne maksimum</p><pre><code>Solve[D[\\[Lambda] n/(1 + \\[Sigma] (n - 1) + \\[Kappa] n (n - 1)), \n   n] == 0, n]</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-17-15-21-22.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"88\" height=\"66\"></figure><p>Wyliczona numerycznie</p><pre><code>NSolve[D[Normal[nlm], n] == 0, n]</code></pre><p>optymalna ilość procesów to <code>14.8271</code>. Kila akapitów wcześniej pisałem, że zaleca się wartość nieznacznie niższą niż ilość dostępnych wątków - u mnie było ich 16.</p><h2 id=\"procesy-workery-i-klastry-w-node-js\">Procesy, Workery i Klastry w Node JS</h2><p>Ten artykuł skupiał się na procesach opisanych w dokumentacji pod linkiem</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://nodejs.org/api/process.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Process | Node.js v16.5.0 Documentation</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">Node.js v16.5.0 Documentation</span></div></div></a></figure><p>Pokazaliśmy w nim jak tworzyć podprocesy, zabijać je. Jak dynamicznie zarządzać ilością podporcesów i prowadzić z nimi dwustronną komunikację. Na końcu zestawiliśmy skalowalność łamania haseł metodą bruteforce z przewidywaniami uniwersalnego prawa skalowania.</p><p>Jednak ten temat został przez nas jedynie delikatnie muśnięty. Nie pisałem nic na temat klastrów opisanych tutaj:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://nodejs.org/api/cluster.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Cluster | Node.js v16.5.0 Documentation</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">Node.js v16.5.0 Documentation</span></div></div></a></figure><p>Ani workerów, które również mają osobny rozdział do dokumentacji</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://nodejs.org/api/worker_threads.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Worker threads | Node.js v16.5.0 Documentation</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">Node.js v16.5.0 Documentation</span></div></div></a></figure><p>Zachęcam Was do samodzielnej lektury dokumentacji <code>Node JS</code> i projektowania własnych eksperymentów.</p>",
            "comment_id": "60f18cd350caaa182e07e605",
            "plaintext": "W tym wpisie nauczymy się jak tworzyć i kończyć podprocesy w Node JS oraz jak\nprzesyłać między nimi dane.\n\nJeśli program wykonuje ciężkie obliczenia ale nie jest zrównoleglony, stan\nTwojego procesora może wyglądać tak:\n\nDlatego warto zgłębić ten temat niezależnie od języka w którym piszesz.\n\nArtykuł będzie podzielony na 3 części:\n\n * sterowanie procesem za pomocą readline\n * tworzenie i zabijanie podprocesów\n * komunikacja między procesami\n\nW pierwszych dwóch napiszemy skrypt do symulowania obciążenia rdzeni procesora.\nW ostatniej zrównoleglimy atak brutforce na hasło.\n\nNa końcu przeanalizujemy skalowalność napisanego programu.\n\nSterowanie procesem z readline\nChcemy napisać program, w którym wciskając klawisz na klawiaturze będziemy\nustawiać ile rdzeni procesora ma zostać obciążonych. Zaczniemy od\nprzechwytywania zdarzeń z klawiatury w czasie rzeczywistym.\n\nPozwoli nam na to moduł readline dostarczający interfejs do zapisu i odczytu\ndanych ze strumieni takich jak klawiatura - process.stdin.\n\nZaczniemy od importu tego modułu\n\nconst readline = require('readline');\n\nNastępnie ustawiamy emitowanie zdarzenia z readline na naciśnięcie przycisku na\nklawiaturze poleceniem\n\nreadline.emitKeypressEvents(process.stdin);\n\nSam readline może pracować z różnymi strumieniami. Tą linią wskazujemy mu, żeby\nnasłuchiwał na klawiaturę. Od razu ustawiamy mod na raw\n\nprocess.stdin.setRawMode(true);\n\nPozwala to odczytywać z klawiatury znak po znaku z osobno załączanymi\nmodyfikatorami jak ctrl czy shift. Jednocześnie ten tryb wymusza samodzielne\nobsłużenie wyłączenia procesu przez ctrl+c. Więcej na temat trybów strumieni i\npodłączania terminala do procesu możemy przeczytać w dokumentacji:\n\nReadline | Node.js v16.5.0 DocumentationNode.js v16.5.0 Documentation\n[https://nodejs.org/api/readline.html#readline_readline_emitkeypressevents_stream_interface]\nTTY | Node.js v16.5.0 DocumentationNode.js v16.5.0 Documentation\n[https://nodejs.org/api/tty.html#tty_readstream_setrawmode_mode]Tym czasem w\nnaszym programie kolejne linie pozwolą obsłużyć odczyt znaków:\n\nprocess.stdin.on('keypress', (str, key) => {\n    if (key.ctrl && key.name === 'c') {\n        process.exit();\n    } else {\n        console.log('typed char', key.name);\n    }\n});\n\nZnak zapisany w key jest obiektem o następujących kluczach\n\n{ sequence: 'v', name: 'v', ctrl: false, meta: false, shift: false }\n\nW prezentowanym kodzie obsługujemy zamknięcie procesu kombinacją ctrl+c oraz\nwypisanie w konsoli znaku wybranego na klawiaturze. Wpisywanie kolejnych znaków\nbędzie za każdym razem pokazywało je w terminalu.\n\nNastępnym krokiem jest zastąpienie wypisywania znaków przez tworzenie lub\nkasowanie procesów obciążających procesor.\n\nTworzenie i zabijanie procesów w Node JS\nW Node JS, możemy bardzo łatwo tworzyć podprocesy i zarządzać nimi. Do\nzarządzania podprocesami możemy użyć modułu child_process. Importujemy go jak\npoprzedni moduł\n\nconst cp = require('child_process');\n\nNastępnie tworzymy tablicę, do której będziemy zapisywali referencje do\ntworzonych procesów.\n\nconst forks = [];\n\nJeśli zapomnieli byśmy o nich przy zamykaniu programu to stały by się one\nprocesami zombie - czyli takimi, które żyją nadal i bez nadzoru pożerają zasoby\nkomputera.\n\nAby je usunąć przed zamknięciem naszego skryptu piszemy kod:\n\n    if (key.ctrl && key.name === 'c') {\n        while (forks.length > 0) {\n            forks[forks.length - 1].kill()\n            forks.pop()\n        }\n        process.exit();\n    } else {\n\nW przypadku wybrania innych przycisków niż c w obecności ctrl odczytamy wartość\nliczbową tego przycisku i na jej podstawie dodamy lub zabijemy odpowiednią\nliczbę procesów aby ich ilość równa była tej liczbie.\n\n        if (!Number.isNaN(parseInt(key.name,32))) {\n            const req = parseInt(key.name,32);\n\n            if (forks.length < req) {\n                while (forks.length < req) {\n                    const n = cp.fork(`${__dirname}/bomb.js`);\n                    forks.push(n)\n                }\n            }\n\n            if (forks.length > req) {\n                while (forks.length > req) {\n                    forks[forks.length - 1].kill()\n                    forks.pop()\n                }\n            }\n\n            console.log('processes PIDs', forks.map(f => f.pid));\n\n        }\n\nDziwić może wybór systemu liczbowego 32. Jednak jest to wygodny system jeśli\nzałożymy, że za pomocą jednego klawisza chcemy wskazać niewielką lecz\nprzekraczającą 10 liczbę.\n\nDo zmiennej req trafia wymagana liczba procesów, a dzięki cp.fork lub kill \ntworzymy i zabijamy brakujące lub nadmiarowe procesy. \n\nDo złożenia całości brakuje nam jedynie zawartości pliku bomb.js. Tam mogły by\nbyć jakiekolwiek operacje zużywające moc obliczeniową. W naszym przypadku jest\nto \n\nlet result = 0;\nwhile (true) {\n    result += Math.random() * Math.random();\n}\n\nczyli kod napisany tylko po to, żeby symulować obciążenie. \n\nPo włączeniu programu i wyborze kilku opcji obciążenia widzimy jak procesy są\ntworzone oraz kasowane. Dzięki htop możemy zobaczyć jak w tym czasie zmienia się\nzużycie procesora.\n\nNawet ładniejszy interfejs do monitoringu procesora ma bashtop, ponieważ\nwyświetla również historyczne zużycie. Na screenshocie poniżej widzimy, jak\nmodyfikując ilość procesów w naszym programie mogłem symulować różne poziomy\nobłożenia procesora zadaniami.\n\nOraz jak wyglądało wykorzystanie rdzeni, kiedy wybrałem opcję utworzenia 16\nprocesów.\n\nTego programu możemy używać do symulowania obciążenia. W pliku bomb.js możemy\nzastąpić losowanie liczb operacją wysyłania żądań http lub zużywania innych\nzasobów, na przykład pamięci operacyjnej lub dysku. \n\nZrównoleglony atak brute-force na hasło\nDo hashowania haseł w historii stosowano różne metody. Obecnie najbardziej\npopularny jest bcrypt, ale bardzo mocną pozycję zajmuje też nowocześniejszy \nargon2i. Upraszczając różnica między nimi polega na tym, że łamanie bcrypta\nwymaga dużej mocy obliczeniowej, a argona można tak skonfigurować, aby wymagane\nbyło posiadanie dużej ilości pamięci operacyjnej. W przypadku tego pierwszego\nzasobu, możemy łatwo kupić moc obliczeniową w bardzo dużych ilościach, dodatkowo\nnasze możliwości łamania haseł podnoszą układy graficzne i procesory\nstrumieniowe. Jednak przy łamaniu argona znacznie trudniej jest zgromadzić\nwymagane do tego ilości pamięci operacyjnej w ramach jednej maszyny. Mój bardzo\nkrótki opis warto rozszerzyć lekturą artykułu:\n\nPassword Hashing: PBKDF2, Scrypt, Bcrypt and ARGON2There’s always a lot of\ndebate in regards to how to safely store passwords and what algorithm to use:\nMD5, SHA1, SHA256, PBKDF2, Bcrypt, Scrypt, Argon2, plaintext?? So I tried to\nanalyse and…Analytics VidhyaMichele Preziuso\n[https://medium.com/analytics-vidhya/password-hashing-pbkdf2-scrypt-bcrypt-and-argon2-e25aaf41598e]\nW dalszej części wpisu pokażemy jak stosowanie wielu rdzeni przyśpiesza łamanie\nhasła zahashowanego algorytmem bcrypt. \n\nNapiszemy kod do generowania hashu hasła, złamiemy go używając jednego rdzenia,\na następnie napiszemy ten sam kod korzystając z podporcesów którym będziemy\nzlecać sprawdzanie kolejnych fraz.\n\nGenerowanie hasha hasła za pomocą bcrypt\nWymagana jest do tego instalacja paczki bcrypt:\n\nnpm init -y && npm i bcrypt\n\nHasło wygenerujemy za pomocą skryptu generate_hash.js, który przyjmuje argument\nbędący hasłem i do pliku .pass zapisuje jego hash.\n\nconst fs = require('fs')\nconst bc = require('bcrypt')\n\nconst main = async () => {\n    return bc.hash(process.argv[2] || 'pass', 11)\n}\n\nmain().then(p => {\n    fs.writeFileSync(`${__dirname}/.pass`, p);\n    console.log(p)\n}).catch(console.error);\n\nŁamanie hasła metodą brute force w jednym wątku\nW ataku brute-force kluczowy jest zestaw znaków na których rozpinamy ciągi,\nktóre będziemy sprawdzać. Użyjemy standardowego alfabetu od a do z. Będziemy go\nskładać z samym sobą generując kolejne sekwencje znaków do sprawdzenia. Proces\nich generowania i przetwarzania można umieścić w funkcji rekurencyjnej, ale\nprzez to tracimy szansę na wygodne sterowanie kolejnością. Zamiast tego\nzastosujemy prostą kolejkę trzymaną w pamięci operacyjnej. Nie będzie ona\nrozładowywana, ponieważ rozładowywanie jej od przodu powodowało by zmianę\nindeksacji wewnątrz kolejki. Opisywałem już jak złe może to mieć skutki dla\nwydajności w artykule:\n\nIle rodzin zmieści się w samolocie - zadanie z algorytmikiPorównujemy dwa\nrozwiązania zadania polegającego na zliczaniu wolnych zestawów przyległych\nmiejsc. Dowiesz się jak używać Profilowania i jak wielką różnicę robi użycie\npop\noraz shift na tablicach w js.Daniel GustawDaniel Gustaw\n[https://gustawdaniel.com/ile-rodzin-zmiesci-sie-w-samolocie/]Zamiast\nrozładowywać kolejkę będziemy odczytywać z niej wartości za pomocą zmiennego\nindeksu, który będzie przesuwał się wzdłuż niej. Schemat blokowy programu, który\nnapiszemy jest następujący:\n\nJego kod to:\n\nconst fs = require('fs');\nconst bc = require('bcrypt');\nconst alphabet = String.fromCharCode(...Array(123).keys()).slice(97);\nconst hash = fs.readFileSync(`${__dirname}/.pass`).toString()\nconst chalk = require('chalk')\n\nlet i = 0;\nconst s = new Date().getTime();\nconst n = () => new Date().getTime() - s;\nlet found = false;\n\nconst que = [];\n\nasync function check(input) {\n    if (found) return;\n    const r = await bc.compare(input, hash)\n\n    console.log(`${i}\\t${input}\\t${n()}\\t${r}\\t${que.length}`)\n    if (r) {\n        console.log(chalk.green(`FOUND: \"${input}\"`))\n        found = true;\n        process.exit();\n    }\n    for (let n of alphabet) {\n        que.push(input + n);\n    }\n}\n\nasync function processQue() {\n    const phrase = que[i++]\n    await check(phrase)\n}\n\nconst main = async () => {\n    while (!found) {\n        await processQue()\n    }\n}\n\nconsole.log(`i\\tinput\\tn()\\tr\\tque.length`)\ncheck('').then(() => main()).catch(console.error)\n\nDo działania wymagana jest paczka chalk, która pozwala na łatwe kolorowanie\ntekstu:\n\nnpm i chalk\n\nPrzetestujmy nasz program.\n\nNa początku wygenerujemy hasło. Zdecydujemy się na \"ac\", ponieważ jest proste i\nszybko je złamiemy\n\nnode generate_hash.js ac\n\nNastępnie włączamy nasz program i widzimy jak po kolei sprawdza hasła z kolejki\n\ntime node force-single.js\n\nW kolumnach mamy kolejno indeks, sprawdzaną sekwencję, czas od włączenia\nprogramu w milisekundach, informację, czy hasło pasuje do hashu oraz aktualną\ndługość kolejki.\n\nJeśli martwi Cię, że kolejka rośnie zbyt szybko i marnuje to dużo mocy, możemy\nzobaczyć, jak zachowa się program po zastąpieniu linii \n\nconst r = await bc.compare(input, hash)\n\nprzez\n\nconst r = i >= 29 // await bc.compare(input, hash)\n\nOkaże się wówczas, że czas wykonania skryptu spadnie z 7.27 sekundy do 0.17\nsekundy.\n\nnode force-single.js  0.17s user 0.03s system 103% cpu 0.188 total\n\nCo znaczy, że jedynie 2.3% mocy obliczeniowej jest przeznaczane na operacje inne\nniż samo porównywanie haseł.\n\nWykorzystanie podprocesów do podniesienia wydajności\nPonieważ sprawdzanie zgodności hasła i hashu jest operacją intensywnie\nkorzystającą z procesora spodziewamy się znacznego wzrostu wydajności tego\nzadania jeśli użyjemy do niego wielu rdzeni jednocześnie. Z tego względu\nprzepiszemy nasz program tak, aby główny proces zamiast wykonywać sprawdzanie\nhaseł zajmował się obsługą kolejki i zlecaniem sprawdzania podrzędnym procesom.\n\nSchemat naszego programu dzieli się na proces główny oraz podprocesy. W procesie\ngłównym tworzona jest lista procesów podrzędnych, kolejka oraz nasłuchy na\nwiadomości z podprocesów. Na końcu każdy podproces dostaje do wykonania zadanie\nz kolejki. Podprocesy po ich wykonaniu zgłaszają się do głównego wątku z\nodpowiedzą, a ten podnosi indeks i przydziela im nowe zadania. Dzieje się tak aż\ndo znalezienia poprawnego hasła.\n\nWarto zwrócić uwagę na to, że niezależne dzieci będą wykonywały zadania z różną\nprędkością co wpłynie na kolejność zgłaszania odpowiedzi. Przykładowy output\nprogramu to:\n\nKod dzieli się na dwa pliki:\n\n * force-child.js - proces główny używający dzieci\n * force-fork.js - podproces do sprawdzania haseł przez bcrypt\n\nZaczniemy analizę procesy głównego - force-child.js. Program startuje od\nzdefiniowania alfabetu oraz zmiennych pomocniczych do indeksowania i liczenia\nczasu.\n\nconst cp = require('child_process');\nconst fs = require('fs');\nconst chalk = require('chalk')\n\nconst alphabet = String.fromCharCode(...Array(123).keys()).slice(97);\nconst forks = [];\n\nlet i = 0;\nconst s = new Date().getTime();\nconst n = () => new Date().getTime() - s;\nlet found = false;\n\n Następnie wypełniamy kolejkę alfabetem\n\nconst que = alphabet.split('');\n\nFunkcja check w jednowątkowej wersji programu dostawała frazę, sprawdzała ją i\nrozszerzała kolejkę. Tym razem oprócz frazy, argumentem będzie podproces wybrany\ndo wykonania sprawdzenia - f. Zamiast używać bcrypt bezpośrednio wyślemy\npodprocesowi żądanie przetworzenia frazy i rozbudujemy kolejkę. \n\nfunction check(input, f) {\n    if (found) return;\n\n    f.send(input);\n\n    for (let n of alphabet) {\n        que.push(input + n);\n    }\n}\n\nPozbyliśmy się tu słowa async przez co nie musimy czekać na wykonanie tej\nfunkcji. Jest to proste oddelegowanie zadania. Kluczowym elementem tego kodu\njest wysyłka wiadomości do podprocesu realizowana przez funkcję send wykonaną\nbezpośrednio na podprocesie.\n\nKolejna funkcja processQue służy nam do wykonania pojedynczego taktowania na\nkolejce \n\nfunction processQue(f) {\n    const phrase = que[i++]\n    check(phrase, f)\n}\n\nJest bardzo krótka i jej głównym zadaniem zapobieganie duplikacji logiki\nodpowiedzialnej za iterowanie po kolejce.\n\nGłówną funkcją programu jest main i odpowiada za ustawienie nasłuchów na\nodpowiedzi z podprocesów oraz zlecenie im początkowych zadań, które pozwalają\nwejść w pętlę komunikacji między nimi.\n\nconst main = async () => {\n    forks.forEach(f => {\n        f.on('message', ({input, r}) => {\n            console.log(`${i}\\t${input}\\t${n()}\\t${r}\\t${que.length}\\t${f.pid}`)\n\n            if (r) {\n                console.log(chalk.green(`FOUND: \"${input}\"`))\n                found = true;\n\n                fs.appendFileSync('logs.txt', `${forks.length},${n()}\\n`)\n\n                while (forks.length > 0) {\n                    forks[forks.length - 1].kill()\n                    forks.pop()\n                }\n\n                process.exit();\n            } else {\n                processQue(f);\n            }\n        });\n        processQue(f);\n    })\n}\n\nZanim wywołamy funkcję main wymagane jest powołanie do życia procesów w tablicy \nforks:\n\nwhile (forks.length < (process.argv[2] || 15)) {\n    const n = cp.fork(`${__dirname}/force-fork.js`);\n    forks.push(n)\n}\n\nZalecaną ich liczbą jest wartość zbliżona do ilości wątków procesora ale\nmniejsza od niej, tak, aby proces główny nie był blokowany.\n\nNa końcu drukujemy informacje o programie, nazwy kolumn i startujemy funkcję \nmain\n\nconsole.log(chalk.blue(`Run using ${forks.length} child processes`))\nconsole.log(`i\\tinput\\tn()\\tr\\tque.length\\tpid`)\nmain().catch(console.error)\n\nDrugi plik - force-fork.js jest znacznie prostszy i zawiera jedynie odczytanie \nhasha oraz oczekiwanie na zadania. Kiedy je dostaje sprawdza testowane hasło \nbcryptem po czym odsyła wynik tym samym kanałem komunikacji.\n\nconst fs = require('fs');\nconst bc = require('bcrypt');\n\nconst hash = fs.readFileSync(`${__dirname}/.pass`).toString()\n\nprocess.on('message', (input) => {\n    bc.compare(input, hash).then((r) => {\n        process.send({r, input});\n    })\n});\n\nAnaliza skalowalności\nWnikliwy czytelnik zapewne zauważył niepozorną ale ważną dla dalszej części\nartykułu linię kodu:\n\nfs.appendFileSync('logs.txt', `${forks.length},${n()}\\n`)\n\nWykonuje się ona po znalezieniu hasła i załącza do pliku logs.txt ilość\npodprocesów oraz czas znalezienia hasła. Dane do tego pliku zostały dostarczone\ndzięki wykonaniu podwójnej pętli w bashu\n\nfor j in $(seq 1 20); do for i in $(seq 1 25); do time node force-child.js $i; sleep 4; done; done;\n\nOraz później rozbudowania tych wyników o wyższą liczbę procesów\n\nfor j in $(seq 1 5); do for i in $(seq 1 50); do time node force-child.js $i; sleep 4; done; done;\n\nZgodnie z Ogólnym Prawem Skalowania spodziewamy się wzrostu wydajności do\npewnego etapu ( koło 15 rdzeni ) i późniejszego spadku związanego z opóźnieniami\nspowodowanymi wzajemnym blokowaniem się podprocesów.\n\nUniwersalne prawo skalowania\nJeśli nie słyszałeś o uniwersalnym prawie skalowania, to szybko wprowadzę Cię do\ntego tematu. Chodzi o to, że w idealnym świecie, gdyby systemy były skalowalne\nliniowo, to znaczyło by, że dołożenie n razy więcej zasobów podnosi wydajność\nlub przepustowość systemu n razy. Taką sytuację może obrazować rysunek:\n\nTakich sytuacji nie spotyka się jednak w świecie rzeczywistym. Zawsze bowiem\nwystępuje pewna nieefektywność związana z przydzielaniem danych do węzłów\n(serwerów lub wątków) oraz z ich zbieraniem. Opóźnienia związane z\nprzydzielaniem i odbieraniem danych nazywa się serializacją, czasami można\nspotkać termin contention:\n\nUwzględnienie tego zjawiska prowadzi do modelu Amdahl`a. Okazuje się jednak, że\njest on niewystarczający dla większości systemów IT ponieważ całkowicie pomija\ndrugi główny czynnik ograniczający skalowanie - komunikację między procesami - \ncrosstalk. Graficznie można ją przedstawić tak:\n\nO ile serializacja ma koszt proporcjonalny do ilości węzłów, to komunikacja jest\nproporcjonalna do ich kwadratu - tak jak liczba przekątnych wielokąta do ilości\nkątów\n\nNa wykresie widzimy krzywe porównujące wpływ ilości węzłów na wydajność w\nsystemu według tych trzech modeli.\n\nDobre (50 stron) opracowanie na ten temat znajduje się pod linkiem:\n\nhttps://cdn2.hubspot.net/hubfs/498921/eBooks/scalability_new.pdf\n\nZestawienie danych pomiarowych z modelem USL\nZebrane dane to ilości wątków oraz czasy wykonywania programu. Ładujemy do do\nprogramu Mathematica komendą:\n\nload = Import[\"/home/daniel/exp/node/logs.txt\", \"Data\"];\n\nPonieważ chcemy rozważać wydajność a nie czas wykonywania odwracamy drugą\nkolumnę poleceniem\n\nloadEff = {#[[1]], 1/#[[2]]} & /@ load;\n\nNajbardziej sensowną jednostką jest normalizacja względem czasu wykonania dla\njednego podprocesu. Pozwoli nam to widzieć zysk z dokładania kolejnych procesów.\nŚrednią z tych czasów liczymy dzięki poleceniu\n\nfirstMean = GroupBy[loadEff // N, First -> Last, Mean][[1]];\n\nNastępnie dopasowujemy model:\n\nnlm = NonlinearModelFit[{#[[1]], #[[2]]/firstMean} & /@ \n   loadEff, \\[Lambda] n/(1 + \\[Sigma] (n - 1) + \\[Kappa] n (n - \n         1)), {{\\[Lambda], 0.9}, {\\[Sigma], 0.9}, {\\[Kappa], \n    0.1}}, {n}]\n\nI zestawiamy go z wykresem listy punktów pomiarowych\n\nShow[ListPlot[{#[[1]], #[[2]]/firstMean} & /@ loadEff], \n Plot[nlm[s], {s, 0, 50}, PlotStyle -> Orange, PlotRange -> All], \n AxesLabel -> {\"processes\", \"gain of efficiency\"}, ImageSize -> Large,\n  PlotLabel -> \"Gain of efficiency relative to single process\"]\n\nWarto pokazać tu bardzo ładny wzór na teoretyczne maksimum\n\nSolve[D[\\[Lambda] n/(1 + \\[Sigma] (n - 1) + \\[Kappa] n (n - 1)), \n   n] == 0, n]\n\nWyliczona numerycznie\n\nNSolve[D[Normal[nlm], n] == 0, n]\n\noptymalna ilość procesów to 14.8271. Kila akapitów wcześniej pisałem, że zaleca\nsię wartość nieznacznie niższą niż ilość dostępnych wątków - u mnie było ich 16.\n\nProcesy, Workery i Klastry w Node JS\nTen artykuł skupiał się na procesach opisanych w dokumentacji pod linkiem\n\nProcess | Node.js v16.5.0 DocumentationNode.js v16.5.0 Documentation\n[https://nodejs.org/api/process.html]Pokazaliśmy w nim jak tworzyć podprocesy,\nzabijać je. Jak dynamicznie zarządzać ilością podporcesów i prowadzić z nimi\ndwustronną komunikację. Na końcu zestawiliśmy skalowalność łamania haseł metodą\nbruteforce z przewidywaniami uniwersalnego prawa skalowania.\n\nJednak ten temat został przez nas jedynie delikatnie muśnięty. Nie pisałem nic\nna temat klastrów opisanych tutaj:\n\nCluster | Node.js v16.5.0 DocumentationNode.js v16.5.0 Documentation\n[https://nodejs.org/api/cluster.html]Ani workerów, które również mają osobny\nrozdział do dokumentacji\n\nWorker threads | Node.js v16.5.0 DocumentationNode.js v16.5.0 Documentation\n[https://nodejs.org/api/worker_threads.html]Zachęcam Was do samodzielnej lektury\ndokumentacji Node JS i projektowania własnych eksperymentów.",
            "feature_image": "__GHOST_URL__/content/images/2021/07/9b7d6b12693bb7906dd9b3fb3971916fcce282a1_2_690x376.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-07-16T13:42:43.000Z",
            "updated_at": "2021-07-17T13:57:27.000Z",
            "published_at": "2021-07-17T13:53:19.000Z",
            "custom_excerpt": "Naucz się jak tworzyć i zabijać podprocesy w Node JS, dynamicznie zarządzać ich ilością i prowadzić z nimi dwustronną komunikację.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "60f5e2b750caaa182e07e949",
            "uuid": "adb71744-c98d-43f8-8fd3-175014a091e1",
            "title": "Rozkład Benforda dla Ciągu Fibonacciego w Java, Rust i Node JS",
            "slug": "rozklad-benforda",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/1520213042003.jpeg\",\"width\":384,\"height\":289}],[\"hr\",{}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/BenfordBroad.png\",\"width\":500,\"height\":165,\"caption\":\"Przykład rozkładu wielkości gdzie pierwsza cyfra spełnia w przybliżeniu prawo Benforda. Wykładniczy spadek rozkładu widzimy po zagęszczaniu się osi wartości.\",\"cardWidth\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/BenfordNarrow.gif\",\"width\":401,\"height\":132,\"caption\":\"Rozkład wielkości obejmujący jedne rząd wielkości. Zwykle pierwsze cyfry nie spełniają rozkładu Benforda, jeśli początkowy rozkład nie jest wystarczająco szeroki.\",\"cardWidth\":\"\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://testingbenfordslaw.com/\",\"metadata\":{\"url\":\"https://testingbenfordslaw.com/\",\"title\":\"Testing Benford’s Law\",\"description\":\"An experiment to test Benford’s Law against large, publicly available datasets.\",\"author\":\"Jason Long (jasonlong) and Bryce Thornton (@brycethornton)\",\"publisher\":null,\"thumbnail\":null,\"icon\":null}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-20-11-49-38.png\",\"width\":172,\"height\":58}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/1012szy1_thumb_190px-1.png\",\"width\":190,\"height\":113}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/1012szy2_thumb_190px.png\",\"width\":190,\"height\":113}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/1012szy3_thumb_190px-1.png\",\"width\":190,\"height\":113}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/1012szy4_thumb_350px.png\",\"width\":350,\"height\":202,\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-20-12-02-05.png\",\"width\":259,\"height\":58}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-20-12-03-07.png\",\"width\":180,\"height\":60}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://mathworld.wolfram.com/FibonacciNumber.html\",\"metadata\":{\"url\":\"https://mathworld.wolfram.com/FibonacciNumber.html\",\"title\":\"Fibonacci Number -- from Wolfram MathWorld\",\"description\":null,\"author\":\"Eric Weisstein\",\"publisher\":\"from Wolfram MathWorld\",\"thumbnail\":\"https://mathworld.wolfram.com/images/topbar/logo.png\",\"icon\":null}}],[\"code\",{\"code\":\"1,1,2,3,5,8,13,21,34,55,89\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/868.png\",\"width\":916,\"height\":546,\"cardWidth\":\"\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://mathworld.wolfram.com/GoldenRatio.html\",\"metadata\":{\"url\":\"https://mathworld.wolfram.com/GoldenRatio.html\",\"title\":\"Golden Ratio -- from Wolfram MathWorld\",\"description\":null,\"author\":\"Eric Weisstein\",\"publisher\":\"from Wolfram MathWorld\",\"thumbnail\":\"https://mathworld.wolfram.com/images/topbar/logo.png\",\"icon\":null}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/7pp55ytrrpy31.png\",\"width\":341,\"height\":372}],[\"code\",{\"code\":\"import java.math.BigInteger;\"}],[\"code\",{\"code\":\"public class Benford {\\n    private static BigInteger[] generateFibonacci(int n) {\\n        BigInteger[] fib = new BigInteger[n];\\n        fib[0] = BigInteger.ONE;\\n        if(n == 1) return fib;\\n        fib[1] = BigInteger.ONE;\\n        for (int i = 2; i < n; i++)\\n            fib[i] = fib[i - 1].add(fib[i - 2]);\\n        return fib;\\n    }\"}],[\"code\",{\"code\":\"    public static void main(String[] args) {\\n        BigInteger[] numbers = generateFibonacci(\\n            args.length > 0 ? Integer.parseInt(args[0]) : 1000\\n        );\",\"language\":\"java\"}],[\"code\",{\"code\":\"        int[] digits = new int[10];\\n\\n        for (BigInteger number : numbers)\\n            digits[Integer.valueOf(number.toString().substring(0, 1))]++;\"}],[\"code\",{\"code\":\"        System.out.print(\\\"N   Ben        Fib\\\\n\\\");\\n        for (int i = 1; i < digits.length; i++)\\n            System.out.printf(\\\"%d %10.6f %10.6f\\\\n\\\",\\n                    i,\\n                    (double) digits[i] / numbers.length,\\n                    Math.log10(1.0 + 1.0 / i)\\n            );\\n    }\\n}\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-20-13-09-42.png\",\"width\":411,\"height\":177}],[\"code\",{\"code\":\"cargo new benford\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://doc.rust-lang.org/cargo/getting-started/first-steps.html\",\"metadata\":{\"url\":\"https://doc.rust-lang.org/cargo/getting-started/first-steps.html\",\"title\":\"First Steps with Cargo - The Cargo Book\",\"description\":null,\"author\":null,\"publisher\":\"The Cargo Book\",\"thumbnail\":null,\"icon\":\"https://doc.rust-lang.org/cargo/favicon.png\"}}],[\"code\",{\"code\":\"[package]\\nname = \\\"b\\\"\\nversion = \\\"0.1.0\\\"\\nedition = \\\"2018\\\"\\n\\n[dependencies]\\n\"}],[\"code\",{\"code\":\"fn main() {\\n    println!(\\\"Hello, world!\\\");\\n}\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/0001.png\",\"width\":1920,\"height\":1080}],[\"code\",{\"code\":\"cargo build\"}],[\"code\",{\"code\":\"./target/debug/benford\"}],[\"code\",{\"code\":\"cargo run\"}],[\"code\",{\"code\":\"num-bigint = \\\"0.4.0\\\"\\nnum-traits = \\\"0.2.14\\\"\"}],[\"code\",{\"code\":\"use num_bigint::BigUint;\\nuse num_traits::{Zero, One};\\nuse std::env;\"}],[\"code\",{\"code\":\"fn generate_fibonacci(n: usize) -> Vec<BigUint> {\\n    let mut fib = vec![Zero::zero(); n];\\n    fib[0] = One::one();\\n    if n == 1 { return fib; }\\n    fib[1] = One::one();\\n    for i in 2..n {\\n        fib[i] = &fib[i - 1] + &fib[i - 2];\\n    }\\n    return fib;\\n}\"}],[\"code\",{\"code\":\"fn main() {\\n    let args: Vec<String> = env::args().collect();\\n    \\n    let numbers = generate_fibonacci(\\n        if args.len() > 1 { (&args[1]).trim().parse().unwrap() } \\n        else { 100 }\\n    );\"}],[\"code\",{\"code\":\"    let mut digits = vec![0; 10];\"}],[\"code\",{\"code\":\"    for n in numbers.iter() {\\n        digits[n.to_string()[..1].parse::<usize>().unwrap()] += 1;\\n    }\"}],[\"code\",{\"code\":\"    println!(\\\"N   Fib        Ben\\\");\\n    for i in 1..digits.len() {\\n        println!(\\\"{:} {:10.6} {:10.6}\\\",\\n                 i,\\n                 digits[i] as f64 / numbers.len() as f64,\\n                 (1.0 + 1.0 / i as f64).log10()\\n        );\\n    }\\n}\"}],[\"code\",{\"code\":\"const generate_fibonacci = (n) => {\\n    let fib = [];\\n    fib[0] = 1n;\\n    if(n === 1) return fib;\\n    fib[1] = 1n;\\n    for (let i = 2; i < n; i++)\\n        fib[i] = fib[i - 1] + fib[i - 2];\\n    return fib;\\n};\"}],[\"code\",{\"code\":\"const generate_fibonacci = (n) => {\\n    let fib = [];\\n    fib[0] = 1;\\n    if(n === 1) return fib;\\n    fib[1] = 1;\\n    for (let i = 2; i < n; i++)\\n        fib[i] = fib[i - 1] + fib[i - 2];\\n    return fib;\\n};\"}],[\"code\",{\"code\":\"const generate_fibonacci = (n) => {\\n    let fib = [];\\n    fib[0] = process.argv[3] === '--cheat' ? 1 : 1n;\\n    if(n === 1) return fib;\\n    fib[1] = process.argv[3] === '--cheat' ? 1 : 1n;\\n    for (let i = 2; i < n; i++)\\n        fib[i] = fib[i - 1] + fib[i - 2];\\n    return fib;\\n};\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/89c452c1e596c77dbb7fe3a17371c828.jpg\",\"width\":700,\"height\":465}],[\"code\",{\"code\":\"const main = () => {\\n    const numbers = generate_fibonacci(\\n       parseInt(process.argv[2]) || 1000\\n    );\"}],[\"code\",{\"code\":\"const digits = [...new Array(10)].map(() => 0);\"}],[\"code\",{\"code\":\"numbers.forEach(n =>\\n    digits[n.toString().substr(0, 1)]++\\n)\"}],[\"code\",{\"code\":\"    process.stdout.write(\\\"N   Ben        Fib\\\\n\\\");\\n    for (let i = 1; i < digits.length; i++) {\\n        const ben = digits[i] / numbers.length;\\n        const fib = Math.log10(1 + 1 / i);\\n        process.stdout.write(\\n            `${i}   ${ben.toFixed(6)}   ${fib.toFixed(6)}\\\\n`\\n        )\\n    }\\n}\"}],[\"code\",{\"code\":\"main();\"}],[\"code\",{\"code\":\"javac Benford.java\"}],[\"code\",{\"code\":\"cargo build --release\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-11-30-41.png\",\"width\":1100,\"height\":441,\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-11-42-22.png\",\"width\":1103,\"height\":442,\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-11-48-18.png\",\"width\":1014,\"height\":600,\"cardWidth\":\"\"}],[\"code\",{\"code\":\"n.toString().substr(0, 1)\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-13-02-25.png\",\"width\":1097,\"height\":437,\"cardWidth\":\"wide\"}],[\"code\",{\"code\":\"java Benford 10\"}],[\"code\",{\"code\":\"N   Ben        Fib\\n1   0.300000   0.301030\\n2   0.200000   0.176091\\n3   0.200000   0.124939\\n4   0.000000   0.096910\\n5   0.200000   0.079181\\n6   0.000000   0.066947\\n7   0.000000   0.057992\\n8   0.100000   0.051153\\n9   0.000000   0.045757\"}],[\"code\",{\"code\":\"time java Benford 10\"}],[\"code\",{\"code\":\"N   Ben        Fib\\n1   0.300000   0.301030\\n2   0.200000   0.176091\\n3   0.200000   0.124939\\n4   0.000000   0.096910\\n5   0.200000   0.079181\\n6   0.000000   0.066947\\n7   0.000000   0.057992\\n8   0.100000   0.051153\\n9   0.000000   0.045757\\njava Benford 10  0.12s user 0.02s system 153% cpu 0.091 total\"}],[\"code\",{\"code\":\"java Benford 10  0.12s user 0.02s system 153% cpu 0.091 total\"}],[\"code\",{\"code\":\"time java Benford 10 > /dev/null\"}],[\"code\",{\"code\":\"(time java Benford 10 > /dev/null) 2>&1\"}],[\"code\",{\"code\":\"(time java Benford 10 > /dev/null) 2>&1 | awk '{print $1,10,$6,$10,$12}'\"}],[\"code\",{\"code\":\"java 10 0.11s 154% 0.090\"}],[\"code\",{\"code\":\"| tr -d \\\"s%\\\"\"}],[\"code\",{\"code\":\"| tee -a logs\"}],[\"code\",{\"code\":\"for i in $(seq 5 5 25); do echo $i; done;\"}],[\"code\",{\"code\":\"5\\n10\\n15\\n20\\n25\"}],[\"code\",{\"code\":\"for i in $(seq 5 5 25); do (time java Benford $i > /dev/null) 2>&1 | awk '{print $1,$i,$6,$10,$12}' | tr -d \\\"s%\\\" | tee -a logs; done;\"}],[\"code\",{\"code\":\"java java Benford $i > /dev/null  0.12s user 0.02s system 152% cpu 0.091 total 0.12 152 0.091\\n...\"}],[\"code\",{\"code\":\"for i in $(seq 5 5 25); do (time java Benford $i > /dev/null) 2>&1 | awk -v i=$i '{print $1,i,$6,$10,$12}' | tr -d \\\"s%\\\" | tee -a logs; done;\"}],[\"code\",{\"code\":\"java 5 0.11 150 0.090\\njava 10 0.12 153 0.089\\njava 15 0.11 152 0.088\\njava 20 0.10 154 0.087\\njava 25 0.11 153 0.089\"}],[\"code\",{\"code\":\"Module[{steps = 100, minY = 1, maxY = 50000, pow = 3}, \\n   Table[maxY (minY + maxY (n)^pow)/(minY + maxY), {n, 0, 1, \\n     1/(steps - 1)}]] // Ceiling // DeleteDuplicates\",\"language\":\"mathematica\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/n-benford.svg\",\"width\":480,\"height\":320}],[\"code\",{\"code\":\"Export[\\\"~/exp/benford/n_values.csv\\\", %]\"}],[\"code\",{\"code\":\"#!/usr/bin/zsh\\n\\nwhile IFS= read -r i\\ndo\\n (time node benford.js \\\"$i\\\" > /dev/null) 2>&1 | awk -v i=\\\"$i\\\" '{print $1,i,$6,$10,$12}' | tee -a logs;\\n (time ./target/release/benford \\\"$i\\\" > /dev/null) 2>&1 | awk -v i=\\\"$i\\\" '{print \\\"rust\\\",i,$5,$9,$11}' | tee -a logs;\\n (time java Benford \\\"$i\\\" > /dev/null) 2>&1 | awk -v i=\\\"$i\\\" '{print $1,i,$6,$10,$12}' | tee -a logs;\\ndone;\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/koalaman/shellcheck/wiki/SC2013\",\"metadata\":{\"url\":\"https://github.com/koalaman/shellcheck\",\"title\":\"SC2013 · koalaman/shellcheck Wiki\",\"description\":\"ShellCheck, a static analysis tool for shell scripts - SC2013 · koalaman/shellcheck Wiki\",\"author\":\"koalaman\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/328ce20d54f5d720f88e3303aa94c9eea7311c1be8d26db7e995d4b88173cb92/koalaman/shellcheck\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/koalaman/shellcheck/wiki/SC2086\",\"metadata\":{\"url\":\"https://github.com/koalaman/shellcheck\",\"title\":\"SC2086 · koalaman/shellcheck Wiki\",\"description\":\"ShellCheck, a static analysis tool for shell scripts - SC2086 · koalaman/shellcheck Wiki\",\"author\":\"koalaman\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/328ce20d54f5d720f88e3303aa94c9eea7311c1be8d26db7e995d4b88173cb92/koalaman/shellcheck\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"code\",{\"code\":\"time zsh measure.sh\"}],[\"code\",{\"code\":\"logs = Import[\\\"/home/daniel/exp/benford/logs\\\", \\\"Data\\\"];\"}],[\"code\",{\"code\":\"ListLogPlot[\\n Table[{#[[1]], \\n     PadLeft[ToExpression /@ StringSplit[ToString[#[[2]]], \\\":\\\"], \\n        2]*{60, 1} // Total} & /@ \\n   GroupBy[logs, First][i][[All, {2, 5}]], {i, {\\\"java\\\", \\\"rut\\\", \\n    \\\"node\\\"}}],\\n PlotLegends -> {\\\"Java\\\", \\\"Rust\\\", \\\"Node\\\"}, ImageSize -> Full, \\n Frame -> True, \\n FrameLabel -> {\\\"Fibonaccin sequence length\\\", \\\"Total time\\\"}, \\n LabelStyle -> Directive[FontSize -> 16]]\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/fib-benford-1.svg\",\"width\":1428,\"height\":816,\"cardWidth\":\"wide\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.wykop.pl/ludzie/DK13/\",\"metadata\":{\"url\":\"https://www.wykop.pl/ludzie/DK13/\",\"title\":\"DK13 - profil w Wykop.pl\",\"description\":\"Write once, debug everywhere.\",\"author\":\"DK13 12 godz. temu via Wykop Mobilny (Android) +1\",\"publisher\":\"Wykop.pl\",\"thumbnail\":\"https://www.wykop.pl/cdn/c3397992/DK13_WbosXcWahF,q250.jpg\",\"icon\":\"https://www.wykop.pl/static/wykoppl7/img/apple-touch-icon-180x180.png\"}}]],\"markups\":[[\"a\",[\"href\",\"https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&httpsredir=1&article=1083&context=rgp_rsr\"]],[\"a\",[\"href\",\"https://www.researchgate.net/publication/45873771_A_derivation_of_Benford's_Law_and_a_vindication_of_Newcomb\"]],[\"code\"],[\"a\",[\"href\",\"http://www.deltami.edu.pl/temat/matematyka/zastosowania/2016/03/21/Fenomen_rozkladu_Benforda/\"]],[\"a\",[\"href\",\"https://www.baeldung.com/linux/author/justin-albano\",\"rel\",\"author\"]],[\"a\",[\"href\",\"https://v8.dev/blog/bigint\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Java_performance\"]],[\"a\",[\"href\",\"https://github.com/tczajka/bigint-benchmark-rs#results\",\"rel\",\"nofollow\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Był rok 1992. W miasteczku Wayne (Arizona USA) zapadał wyrok na Jamesa Nelsona - głównego księgowego i zarządzającego Arizona State Treasurer. Jego fałszywe czeki, dzięki którym zdefraudował prawie 2 miliony dolarów zostały wykryte ponieważ rozkład częstości pierwszych cyfr w wyłudzonych kwotach odbiegał od rozkładu Benforta.\"]]],[10,0],[1,\"p\",[[0,[],0,\"Na pierwszych pozycjach zmyślonych przez księgowego wartości zbyt często znajdowały się 7, 8 i 9 - typowe wartości postrzegane przez nas jako \\\"bardziej\\\" losowe niż 1, 2 lub 3.\"]]],[10,1],[1,\"p\",[[0,[],0,\"Z wpisu dowiesz się czym jest Rozkład Benforta i dlaczego jest obserwowany w wielu zbiorach danych. Później omówimy ciąg Fibonacciego i jego podstawowe własności. Na końcu napiszemy program sprawdzający czy Rozkład Benforta obowiązuje dla ciągu Fibonacciego. Program zostanie napisany w trzech językach:\"]]],[3,\"ul\",[[[0,[],0,\"Java\"]],[[0,[],0,\"Rust\"]],[[0,[],0,\"Node JS\"]]]],[1,\"p\",[[0,[],0,\"Porównamy wyniki jego wydajności.\"]]],[1,\"h2\",[[0,[],0,\"Rozkład Benforda\"]]],[1,\"p\",[[0,[],0,\"Rozkład Benforda jest rozkładem prawdopodobieństwa występowania określonych liczb na pierwszych pozycjach w wielu obserwowanych zbiorach danych liczbowych. Aby występował muszą zachodzić następujące warunki:\"]]],[3,\"ul\",[[[0,[],0,\"zbiór wartości powinien rozciągać się na wiele rzędów wielkości\"]],[[0,[],0,\"prawdopodobieństwo powinno być niezmiennicze względem skali oraz bazy\"]]]],[10,2],[10,3],[1,\"p\",[[0,[],0,\"Świetne formalne wyprowadzenie rozkładu Benforda przestawili Arno Berger i Theodore P. Hill w publikacji: \"],[0,[0],1,\"\\\"A basic theory of Benford’s Law\\\"\"]]],[1,\"p\",[[0,[],0,\"Jest to ponad 100 stronnicowa publikacja bardzo obszernie omawiająca temat i polecam ją wszystkim, którzy kochają matematykę. Krótsze i prostsze wyprowadzanie warte uwagi napisał \"],[0,[1],1,\"Victor Romero-Rochin\"]]],[1,\"p\",[[0,[],0,\"Przykłady rozkładów spełniających prawo Benforda mamy w przejrzysty sposób pokazane pod linkiem:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Intuicyjnym powodem wyższej reprezentacji niższych cyfr jest wyższe prawdopodobieństwo wystąpienia wielu mniejszych wartości, które nakładając się na skokowo zmienną gęstość cyfr wraz ze wzrostem rzędu wielkości powoduje przesunięcie w stronę wyższej reprezentacji niższych cyfr na pierwszych pozycjach.\"]]],[1,\"p\",[[0,[],0,\"Ponieważ w tym artykule rozkład Benforda jest jedynie pretekstem do porównania wydajności programów pisanych w różnych językach a nie głównym tematem, pozwolę sobie ograniczyć jego opis do pokazania najlepszych publikacji, wyprowadzonej formuły i kilku przykładów. \"]]],[1,\"p\",[[0,[],0,\"Wzór na prawdopodobieństwo wystąpienia cyfry \"],[0,[2],1,\"d\"],[0,[],0,\" na pierwszej pozycji to:\"]]],[10,5],[1,\"p\",[[0,[],0,\"Przykłady, które pokażę pochodzą z serwisu \"],[0,[2,3],2,\"deltami.edu.pl\"]]],[3,\"ul\",[[[0,[],0,\"Rozkład równomierny rozkładu równomiernego\"]]]],[1,\"p\",[[0,[],0,\"Ze zbioru liczb naturalnych z zakresu od 1 do 9999 losujemy liczbę p, wykorzystując generator liczb losowych o rozkładzie równomiernym. Następnie z zakresu liczb naturalnych od 1 do p losujemy, również wykorzystując rozkład równomierny, liczbę r.\"]]],[10,6],[3,\"ul\",[[[0,[],0,\"Masa atomowa pierwiastków z układu okresowego\"]]]],[1,\"p\",[[0,[],0,\"Zobaczmy na układ okresowy pierwiastków chemicznych, a dokładniej, jeden z parametrów każdego pierwiastka - masą atomową.\"]]],[10,7],[3,\"ul\",[[[0,[],0,\"Powierzchnia państw świata w km²\"]]]],[1,\"p\",[[0,[],0,\"Ostatni przykład jest powiązany z geografią - przyjrzyjmy się powierzchni wszystkich państw świata w km2.\"]]],[10,8],[3,\"ul\",[[[0,[],0,\"Prawo Benforda\"]]]],[1,\"p\",[[0,[],0,\"Dyskretny rozkład Benforda dla układu dziesiętnego zwany również prawem pierwszych (znaczących) cyfr.\"]]],[10,9],[1,\"p\",[[0,[],0,\"Jak widzimy, wszystkie te zbiory liczb mają tą samą własność - niezmienniczość względem skali, bazy i rozciągnięcie na kilka rzędów wielkości.\"]]],[1,\"h2\",[[0,[],0,\"Ciąg Fibonacciego\"]]],[1,\"p\",[[0,[],0,\"Ciąg Fibonacciego jest ciągiem liczb naturalnych o rekurencyjnej definicji:\"]]],[10,10],[1,\"p\",[[0,[],0,\"gdzie\"]]],[10,11],[1,\"p\",[[0,[],0,\"Jego własności opisane są w Math World.\"]]],[10,12],[1,\"p\",[[0,[],0,\"Jego początkowe wartości to:\"]]],[10,13],[1,\"p\",[[0,[],0,\"Jest to ciąg, którego występowanie możemy często obserwować w przyrodzie: w wirach wodnych, w kształcie tornad, w układzie kwiatów, rozgałęzieniach roślin, podziale ciała owadów. Jego powszechność zachwyca badaczy tego zjawiska. Podobnie jak powszechność funkcji wykładniczej czy kwadratowej wynika ona z prostoty wzoru i bycia dobrym przybliżeniem dla znacznie bardziej złożonych układów obserwowanych w rzeczywistości.\"]]],[10,14],[1,\"p\",[[0,[],0,\"Stosunki kolejnych wartości ciągu dążą do złotej proporcji. Dowód wynika wprost z definicji.\"]]],[10,15],[1,\"p\",[[0,[],0,\"Pierwiastki ciągu Fibonacciego również zbiegają do stałego stosunku ze wzrostem \"],[0,[2],1,\"n\"],[0,[],0,\", a sam ciąg bardzo szybko zaczyna rosnąć tak szybko, rozciąga się na wiele rzędów wielkości.\"]]],[1,\"p\",[[0,[],0,\"Podobnie jak liczby pierwsze, tak i ciąg Fibonacciego powinien spełniać rozkład Benforda. Sprawdźmy to pisząc programy w Java, Rust i Node JS.\"]]],[1,\"h2\",[[0,[],0,\"Java\"]]],[10,16],[1,\"p\",[[0,[],0,\"Aby zrobić to w Javie wymagany jest import modułu \"],[0,[2],1,\"java.math.BigInteger\"],[0,[],0,\". \"]]],[10,17],[1,\"p\",[[0,[],0,\"W pliku \"],[0,[2],1,\"Benford.java\"],[0,[],0,\" w klasie \"],[0,[2],1,\"Benford\"],[0,[],0,\" utworzymy funkcję \"],[0,[2],1,\"generateFibonacci\"],[0,[],0,\", która pozwoli nam przygotować ciąg\"]]],[10,18],[1,\"p\",[[0,[],0,\"Warto zwrócić uwagę, że zamiast \"],[0,[2],1,\"1\"],[0,[],0,\" stosujemy tu \"],[0,[2],1,\"BigInteger.ONE\"],[0,[],0,\" aby zachować zgodność typów. Podobnie zamiast klasycznego dodawania przez \"],[0,[2],1,\"+\"],[0,[],0,\" stosujemy metodę \"],[0,[2],1,\"add\"],[0,[],0,\" określoną na obiektach \"],[0,[2],1,\"BigInteger\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"W metodzie \"],[0,[2],1,\"main\"],[0,[],0,\" przygotowujemy ciąg Fibbonaciego.\"]]],[10,19],[1,\"p\",[[0,[],0,\"Dzięki \"],[0,[2],1,\"args\"],[0,[],0,\" możemy użyć argumentu wpisanego przez użytkownika. Jeśli nie zostanie on podany domyślną wartością jest \"],[0,[2],1,\"1000\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Następnie tablica \"],[0,[2],1,\"digits\"],[0,[],0,\" zostaje wypełniona zliczeniami cyfr\"]]],[10,20],[1,\"p\",[[0,[],0,\"Na końcu wyświetlamy tablicę porównującą wyniki z przewidywaniami teoretycznymi.\"]]],[10,21],[1,\"p\",[[0,[],0,\"Kod wykonujemy wpisując \"],[0,[2],1,\"java Benford.java\"],[0,[],0,\" i dostajemy wynik potwierdzający naszą teorię:\"]]],[10,22],[1,\"h2\",[[0,[],0,\"Rust\"]]],[1,\"p\",[[0,[],0,\"Projekty w \"],[0,[2],1,\"Rust\"],[0,[],0,\" rozpoczynamy poleceniem\"]]],[10,23],[10,24],[1,\"p\",[[0,[],0,\"w katalogu \"],[0,[2],1,\"benford\"],[0,[],0,\" powstaje plik \"],[0,[2],1,\"Cargo.toml\"],[0,[],0,\" o zawartości\"]]],[10,25],[1,\"p\",[[0,[],0,\"oraz plik \"],[0,[2],1,\"src/main.rs\"],[0,[],0,\" o treści\"]]],[10,26],[1,\"p\",[[0,[],0,\"To bardzo miłe, że Rust wita nas w tak przyjemny sposób ułatwiając rozpoczęcie pracy z tym językiem.\"]]],[10,27],[1,\"p\",[[0,[],0,\"Aby skompilować program wykonujemy poleceniem\"]]],[10,28],[1,\"p\",[[0,[],0,\"Jego uruchomienie jest wówczas możliwe dzięki komendzie\"]]],[10,29],[1,\"p\",[[0,[],0,\"Aby skompilować i wykonać program jednocześnie użyjemy polecenia\"]]],[10,30],[1,\"p\",[[0,[],0,\"O ile w Javie do obsługi dużych liczb całkowitych używaliśmy jednej paczki, to w Rust potrzebujemy dwóch: \"],[0,[2],1,\"num-bigint\"],[0,[],0,\" oraz \"],[0,[2],1,\"num-traits\"],[0,[],0,\". Dodamy je do projektu dopisując linie\"]]],[10,31],[1,\"p\",[[0,[],0,\"pod kluczem \"],[0,[2],1,\"[dependencies]\"],[0,[],0,\" w pliku \"],[0,[2],1,\"Cargo.toml\"],[0,[],0,\". Wersje paczek automatycznie podpowie nam nasze \"],[0,[2],1,\"IDE\"],[0,[],0,\". Ich użycie w pliku \"],[0,[2],1,\"src/main.rs\"],[0,[],0,\" wymaga napisania\"]]],[10,32],[1,\"p\",[[0,[],0,\"Gdzie \"],[0,[2],1,\"Uint\"],[0,[],0,\" pochodzi od \"],[0,[2],1,\"unsigned integer\"],[0,[],0,\" czyli liczb całkowitych, które nie poświęcają jednego bitu na znak, bo są zawsze dodatnie. Funckja generująca ciąg Fibonacciego będzie podobna do tej z \"],[0,[2],1,\"Javy\"]]],[10,33],[1,\"p\",[[0,[],0,\"Widzimy, że główna różnica leży w nazwaniu typów. W funkcji \"],[0,[2],1,\"main\"],[0,[],0,\" tak samo generujemy ciąg zapisując go do tablicy\"]]],[10,34],[1,\"p\",[[0,[],0,\"Tym razem tablica argumentów zaczyna się od nazwy programu a przekazana wartość z linii poleceń ma indeks równy 1.\"]]],[1,\"p\",[[0,[],0,\"przygotowujemy tablicę ze zliczeniem ilości cyfr na pierwszych pozycjach\"]]],[10,35],[1,\"p\",[[0,[],0,\"Zapis analogiczny do tego z Javy pozwala nam na zliczenie cyfr i zapisanie ilości ich wystąpień do tablicy\"]]],[10,36],[1,\"p\",[[0,[],0,\"Na końcu pokazujemy wyniki w konsoli dzięki następującej pętli\"]]],[10,37],[1,\"h2\",[[0,[],0,\"Node JS\"]]],[1,\"p\",[[0,[],0,\"Wyjątkową cechą prezentowanego programu jest to, że jak mało który projekt w \"],[0,[2],1,\"node js\"],[0,[],0,\" nie zawiera on listy wymaganych paczek. Nie musimy tu importować żadnych modułów odpowiedzialnych z obsługę dużych liczb. Stałe o typie \"],[0,[2],1,\"BigInt\"],[0,[],0,\" tworzymy dodając literę \"],[0,[2],1,\"n\"],[0,[],0,\" po liczbie. Przez to funkcja do generowania ciągu Fibonacciego przybiera formę:\"]]],[10,38],[1,\"p\",[[0,[],0,\"Łatwo możemy sobie jednak wyobrazić, że ktoś piszący kod tego nie zna różnicy między \"],[0,[2],1,\"1n\"],[0,[],0,\" a \"],[0,[2],1,\"1\"],[0,[],0,\" lub po prostu zapomniał, że pracuje z dużymi liczbami i napisał by go tak:\"]]],[10,39],[1,\"p\",[[0,[],0,\"Aby symulować oba przypadki napiszmy uniwersalną funkcję sterowaną flagą \"],[0,[2],1,\"--cheat\"],[0,[],0,\".\"]]],[10,40],[1,\"p\",[[0,[],0,\"W dalszej części okaże się jak kolosalne różnice w wydajności i poprawności programu robi ten jeden znaczek \"],[0,[2],1,\"n\"],[0,[],0,\". Przy pisaniu oprogramowania ważne jest aby rozumieć na jakich zakresach wartości pracuje program i poprawnie obsługiwać ich krańce.\"]]],[10,41],[1,\"blockquote\",[[0,[],0,\"Pod tym względem \"],[0,[2],1,\"node\"],[0,[],0,\" wymaga od programisty szczególnej odpowiedzialności, bo próbując ratować program przez rzuceniem błędu idzie na kompromisy, które jak się okaże czasami są genialne, ale bywają bardzo zwodnicze.\"]]],[1,\"p\",[[0,[],0,\"Funkcji \"],[0,[2],1,\"generate_fibonacci\"],[0,[],0,\" użyjemy w funkcji \"],[0,[2],1,\"main\"],[0,[],0,\" w następujący sposób\"]]],[10,42],[1,\"p\",[[0,[],0,\"Oczywiście w \"],[0,[2],1,\"node\"],[0,[],0,\" nie mamy obowiązku definiowania funkcji \"],[0,[2],1,\"main\"],[0,[],0,\" ale uważam to za dobrą praktykę, aby program miał wyraźnie określony punkt startu i dobrze zarysowane granice między deklarowaniem funkcji oraz procedur a ich używaniem. \"]]],[1,\"p\",[[0,[],0,\"Przy okazji twoją uwagę zwróciło zapewne to, że ponownie zupełnie inaczej indeksowany jest \"],[0,[2],1,\"argv\"],[0,[],0,\". Jak widać każdy język ma tu własną konwencję i tym razem dwa pierwsze argumenty to katalog i nazwa programu.\"]]],[1,\"p\",[[0,[],0,\"Tablica dziesięciu zer, w których znajdą się ilości zliczonych pierwszych cyfr może być zadeklarowana następująco\"]]],[10,43],[1,\"p\",[[0,[],0,\"Samo zliczanie jest równie proste co w innych językach\"]]],[10,44],[1,\"p\",[[0,[],0,\"Natomiast drukowanie wyników zamiast używać szablonu do którego wkładamy wartości jako argumenty korzysta bezpośrednio z template string\"]]],[10,45],[1,\"p\",[[0,[],0,\"Na końcu za pomocą wywołania funkcji \"],[0,[2],1,\"main\"],[0,[],0,\" włączamy nasz program.\"]]],[10,46],[1,\"h2\",[[0,[],0,\"Porównanie wydajności programów\"]]],[1,\"p\",[[0,[],0,\"Przez wydajność programów mam na myśli wydajność skompilowanych programów bez liczenia czasu kompilacji. Dlatego w przypadku Javy musimy wykonać kompilację poleceniem\"]]],[10,47],[1,\"p\",[[0,[],0,\"w wyniku tego polecenia powstanie plik \"],[0,[2],1,\"Benford.class\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Dla rust kompilacja wykonana przez \"],[0,[2],1,\"cargo build\"],[0,[],0,\" tworzy deweloperską nie zoptymalizowaną wersję. W celu utworzenia zoptymalizowanej należy dodać flagę \"],[0,[2],1,\"release\"],[0,[],0,\".\"]]],[10,48],[1,\"p\",[[0,[],0,\"Na przykład dla \"],[0,[2],1,\"n=1000\"],[0,[],0,\" każdy program wyświetla to samo, ale różne są czasy obliczeń.\"]]],[10,49],[1,\"p\",[[0,[],0,\"Rust miażdży konkurencję. Node js niezależnie od tego czy operujemy zaczynaliśmy od \"],[0,[2],1,\"1\"],[0,[],0,\" czy od \"],[0,[2],1,\"1n\"],[0,[],0,\" pokazuje te same wyniki i bardzo zbliżony nawet niezły czas. Java mimo znacznego zużycia \"],[0,[2],1,\"cpu\"],[0,[],0,\" włącza się tak długo, że w tym teście wypada najgorzej.\"]]],[1,\"p\",[[0,[],0,\"Dla \"],[0,[2],1,\"n=10000\"],[0,[],0,\" wynik Javy rośnie jedynie 10 razy, mimo, że Rust wykonuje obliczenia o dwa rzędy wielkości dłużej, a node 24 razy dłużej. \"]]],[10,50],[1,\"p\",[[0,[],0,\"Niech nie będzie mylącym dla Was, że \"],[0,[2],1,\"n\"],[0,[],0,\" zwiększyło się \\\"tylko\\\" 10 razy. Wartości przetwarzane przez program mają geometryczne tępo wzrostu osiągając szybko gigantyczne wartości. Na przykład dla \"],[0,[2],1,\"n=10000\"],[0,[],0,\" wartość ciągu to:\"]]],[10,51],[1,\"p\",[[0,[],0,\"Różnica we wzroście wydajności wynika z tego, że Java ma najcięższy proces uruchamiania się. Node mimo, że całkiem lekki nadal wymaga załadowania całego interpretera przez co Rust mając najszybszy start pokazał o ile faktycznie wzrosła złożoność obliczeniowa.\"]]],[1,\"p\",[[0,[],0,\"Ponieważ głównym ciężarem jest tu dodawanie coraz większych liczb, których długość rośnie liniowo możemy spodziewać się złożoności O(n^2), którą prezentuje Rust.\"]]],[1,\"p\",[[0,[],0,\"Ostatnim wnioskiem jest, że program napisany w \"],[0,[2],1,\"Node JS\"],[0,[],0,\" z flagą \"],[0,[2],1,\"--cheat\"],[0,[],0,\" \\\"nie zauważył\\\", że działa źle. Jego wyniki pokazują, że mimo szybkiego wykonania nie zliczył on poprawie pierwszych cyfr. Znając ograniczenia typu \"],[0,[2],1,\"Number\"],[0,[],0,\" w node wiemy, że nie może on przekroczyć wartości \"],[0,[2],1,\"Number.MAX_VALUE\"],[0,[],0,\" równej \"],[0,[2],1,\"1.7976931348623157e+308\"],[0,[],0,\", tym czasem \"],[0,[2],1,\"Log10[Fibonacci[1000]]\"],[0,[],0,\" wynosi \"],[0,[2],1,\"208.638\"],[0,[],0,\" ale \"],[0,[2],1,\"Log10[Fibonacci[10000]]\"],[0,[],0,\" to już \"],[0,[2],1,\"2089.53\"],[0,[],0,\". Zatem liczby które program w Node dodaje to \"],[0,[2],1,\"Infinity\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Oczywiście \"],[0,[2],1,\"Infninity\"],[0,[],0,\" + \"],[0,[2],1,\"Infnity\"],[0,[],0,\" = \"],[0,[2],1,\"Infinity\"],[0,[],0,\" co znacznie skraca czas obliczeń, ale pierwsza \\\"cyfra\\\" nieskończoności dla Node do \"],[0,[2],1,\"I\"],[0,[],0,\" ponieważ wyliczamy ją poleceniem\"]]],[10,52],[1,\"p\",[[0,[],0,\"Gdybym zatrzymał się na zestawieniu pary wyników dla trzech programów nie był bym sobą. Ciekawość karze mi zajrzeć głębiej i przygotować wykres pokazujący jak czas obliczeń rósł wraz z długością ciągu.\"]]],[1,\"p\",[[0,[],0,\"Pokaże jeszcze punkt pomiarowy \"],[0,[2],1,\"50.000\"],[0,[],0,\".\"]]],[10,53],[1,\"p\",[[0,[],0,\"Jednak omawianie każdego z osobna nie jest tak wartościowe, jak zrobienie całej serii pomiarów i nałożenie ich na wspólny wykres. \"]]],[1,\"h3\",[[0,[],0,\"Pomiar wydajności programów w zależności od argumentu\"]]],[1,\"p\",[[0,[],0,\"Aby skutecznie zmierzyć wydajność programów musimy rozwiązać kilka problemów\"]]],[3,\"ul\",[[[0,[],0,\"rozdzielić strumienie z wynikiem programu od pomiaru wydajności\"]],[[0,[],0,\"wybrać zestaw wartości dla których dokonamy pomiaru\"]],[[0,[],0,\"narysować wykresy\"]]]],[1,\"h4\",[[0,[],0,\"Rozdzielenie strumienia programu od strumienia pomiaru czasu\"]]],[1,\"p\",[[0,[],0,\"W bashu programy komunikują się za pomocą przekierowywania strumieni danych. Wyjście jednego programu może stać się wejściem innego, który po przetworzeniu podanych mu informacji może chcieć je zapisać do pliku.\"]]],[1,\"p\",[[0,[],0,\"Dla prostego wykonania:\"]]],[10,54],[1,\"p\",[[0,[],0,\"wynik w postaci:\"]]],[10,55],[1,\"p\",[[0,[],0,\"zostanie wyświetlony w terminalu ponieważ terminal jest domyślnym wyjściem dla strumienia danych produkowanych przez ten program. Dane produkowane przez program domyślnie wychodzą z niego przez wyjście standardowe. Możemy je przekierować w inne miejsce za pomocą \"],[0,[2],1,\"1>\"],[0,[],0,\" lub po prostu \"],[0,[2],1,\">\"],[0,[],0,\" i pominąć \"],[0,[2],1,\"1\"],[0,[],0,\", która jest domyślna.\"]]],[1,\"p\",[[0,[],0,\"Wykonanie \"],[0,[2],1,\"java Benford 10 > out\"],[0,[],0,\" nic nie pokaże ale spowoduje utworzenie pliku z danymi z wyjścia standardowego.\"]]],[1,\"p\",[[0,[],0,\"Jednak kiedy program poprzedzimy poleceniem \"],[0,[2],1,\"time\"],[0,[],0,\" czyli napiszemy\"]]],[10,56],[1,\"p\",[[0,[],0,\"okaże się, że dostaniemy w terminalu\"]]],[10,57],[1,\"p\",[[0,[],0,\"jednak próba przechwycenia czasu wykonania do pliku jak poprzednio przez \"],[0,[2],1,\">\"],[0,[],0,\" zakończy się wyświetleniem linii\"]]],[10,58],[1,\"p\",[[0,[],0,\"w terminalu, a do pliku zostanie przekierowana cała reszta. Jest tak dlatego, że time nie miesza swoich danych z danymi ze strumienia standardowego. Zamiast tego używa strumienia błędów \"],[0,[2],1,\"2>\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Naszym celem jest schowanie danych ze strumienia standardowego. Możemy to zrobić przekierowując go do \"],[0,[2],1,\"/dev/null\"],[0,[],0,\". To znaczy\"]]],[10,59],[1,\"p\",[[0,[],0,\"Jednak strumień błędów jest dla nas niemożliwy do przetwarzania jeśli nie przekierujemy go na strumień główny. Osiągniemy to poleceniem\"]]],[10,60],[1,\"p\",[[0,[],0,\"Wynik tych dwóch wygląda tak samo, ale kluczową różnicą jest to, że w drugim przypadku możemy przetworzyć strumień za pomocą przekierowania go do \"],[0,[2],1,\"awk\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Na przykład polecenie zawierające przetwarzanie danych:\"]]],[10,61],[1,\"p\",[[0,[],0,\"zwróci na wyjściu standardowym jedynie\"]]],[10,62],[1,\"p\",[[0,[],0,\"aby oczyścić te wyniki ze znaku \"],[0,[2],1,\"s\"],[0,[],0,\" i \"],[0,[2],1,\"%\"],[0,[],0,\" możemy dodać \"]]],[10,63],[1,\"p\",[[0,[],0,\"Jeśli chcemy oglądać ten wynik jednocześnie zachowując go do pliku, z pomocą przychodzi nam \"],[0,[2],1,\"tee\"],[0,[],0,\" - trzecie z moich ulubionych narzędzi obok kafki i expressa.\"]]],[1,\"p\",[[0,[],0,\"Wystarczy na końcu dopisać:\"]]],[10,64],[1,\"p\",[[0,[],0,\"a pokazana linia zostanie załączona na końcu pliku \"],[0,[2],1,\"logs\"],[0,[],0,\". Teraz załóżmy, że chcemy wytworzone właśnie polecenie otoczyć pętlą przechodzącą po sekwencji:\"]]],[10,65],[1,\"p\",[[0,[],0,\"Sekwencja wyświetli nam \"]]],[10,66],[1,\"p\",[[0,[],0,\"Lecz jeśli wkleili byśmy naiwnie \"],[0,[2],1,\"$i\"],[0,[],0,\" do \"],[0,[2],1,\"print\"],[0,[],0,\" w \"],[0,[2],1,\"awk\"],[0,[],0,\" w następujący sposób:\"]]],[10,67],[1,\"p\",[[0,[],0,\"dostali byśmy kilka razy powtórzoną linię\"]]],[10,68],[1,\"p\",[[0,[],0,\"Jest tak dlatego, że \"],[0,[2],1,\"i\"],[0,[],0,\" nie istnieje wewnątrz \"],[0,[2],1,\"print\"],[0,[],0,\" jeśli go tam nie włożymy. Zatem \"],[0,[2],1,\"$i\"],[0,[],0,\" wynosi tyle samo co \"],[0,[2],1,\"$0\"],[0,[],0,\" co odpowiada całej linii, a nie wybranej kolumnie. Aby używać zmiennych wewnątrz kontekstu \"],[0,[2],1,\"print\"],[0,[],0,\" w \"],[0,[2],1,\"awk\"],[0,[],0,\" możemy użyć flagi \"],[0,[2],1,\"-v\"],[0,[],0,\". Poprawna składnia polecenia to:\"]]],[10,69],[1,\"p\",[[0,[],0,\"a jego wynikiem jest jednoczesne zapisanie do pliku \"],[0,[2],1,\"logs\"],[0,[],0,\" i pokazanie na ekranie linii:\"]]],[10,70],[1,\"p\",[[0,[],0,\"Jeśli temat strumieni w \"],[0,[2],1,\"bash\"],[0,[],0,\" cię zainteresował polecam wprowadzenie \"],[0,[4],1,\"Justina Albano\"],[0,[],0,\".\"]]],[1,\"h4\",[[0,[],0,\"Przygotowanie serii wartości \"],[0,[2],1,\"n\"],[0,[],0,\" do analizy wydajności\"]]],[1,\"p\",[[0,[],0,\"Dzieląc zakres pomiarowy na części należy zagęszczać pomiary tam gdzie ich koszt jest niski (krótki czas działania programu) a zmienność i ciekawe zachowania są spodziewane. U nas jest to zmiana stosunku czasu obliczeń do czasu uruchamiania (typowe dla niewielkich wartości \"],[0,[2],1,\"n\"],[0,[],0,\"). Mamy więc dwa powody, aby nie dzielić zakresu pomiaru na równe kawałki i nie używać \"],[0,[2],1,\"seq\"],[0,[],0,\". Zamiast tego możemy wygenerować serię, której gęstość spada wraz ze wzrostem \"],[0,[2],1,\"n\"],[0,[],0,\". Na przykład moduł w \"],[0,[2],1,\"Mathematica\"],[0,[],0,\":\"]]],[10,71],[1,\"p\",[[0,[],0,\"spowoduje powstanie serii o następującej dystrybucji\"]]],[10,72],[1,\"p\",[[0,[],0,\"Zapisujemy ją do pliku \"],[0,[2],1,\"n_values\"],[0,[],0,\" poleceniem\"]]],[10,73],[1,\"h4\",[[0,[],0,\"Przygotowanie wykresów porównujących wydajność programów\"]]],[1,\"p\",[[0,[],0,\"Kod mierzący wydajność zapiszemy w pliku \"],[0,[2],1,\"measure.sh\"],[0,[],0,\" \"]]],[10,74],[1,\"p\",[[0,[],0,\"Zamieniliśmy tu pętlę \"],[0,[2],1,\"for\"],[0,[],0,\" na \"],[0,[2],1,\"while\"],[0,[],0,\". For z \"],[0,[2],1,\"cat n_values.csv\"],[0,[],0,\" jest dopuszczalne, ale nie zalecane\"]]],[10,75],[1,\"p\",[[0,[],0,\"Warto też otoczyć \"],[0,[2],1,\"$i\"],[0,[],0,\" cudzysłowami. Kiedy braliśmy dane z sekwencji to nie miało znaczenia i teraz też nie wpłynie na program, ale dobrą praktyką jest używanie cudzysłowów ponieważ jeśli w zmiennych znajdują się wartości zawierające spacje, to słowa oddzielone spacjami mogą być traktowane jako argumenty na kolejnych pozycjach zamiast jedna wartość. \"]]],[10,76],[1,\"p\",[[0,[],0,\"Pomiar wykonujemy wpisując \"]]],[10,77],[1,\"p\",[[0,[],0,\"Ładujemy utworzony plik\"]]],[10,78],[1,\"p\",[[0,[],0,\"i rysujemy wykres\"]]],[10,79],[10,80],[1,\"p\",[[0,[],0,\"Podsumowanie:\"]]],[3,\"ul\",[[[0,[],0,\"długi czas startowania maszyny wirtualnej Javy nie pozwolił jej rozwinąć skrzydeł w początkowej fazie przez co wypadła ona najgorzej dla małych wartości \"],[0,[2],1,\"n\"],[0,[],0,\".\"]],[[0,[],0,\"zaskakująco dobrze poradził sobie \"],[0,[2],1,\"Node\"],[0,[],0,\", który mimo, że nie zalecany do zadań obciążających procesor, to ma naprawdę nieźle zoptymalizowaną implementację \"],[0,[5],1,\"BigInt\"]],[[0,[],0,\"bezkonkurencyjny dla niskich \"],[0,[2],1,\"n\"],[0,[],0,\" okazał się \"],[0,[2],1,\"Rust\"],[0,[],0,\", który ponieważ nie jest obciążony żadnym środowiskiem uruchomieniowym ani interpreterem, dla dużych \"],[0,[2],1,\"n\"],[0,[],0,\" uległ jednak Javie, której zespół od \"],[0,[6],1,\"lat poprawiał \"],[0,[],0,\"wydajność Javy w kolejnych wersjach.\"]]]],[1,\"p\",[[0,[],0,\"Zdaję sobie sprawę, że te programy można zoptymalizować, choćby pod względem zużycia pamięci - nie trzymając całych tablic z ciągami. Starałem się je napisać tak, aby we wszystkich językach były możliwie podobne i możliwie proste. Jeśli zauważyłeś w nich błąd będę bardzo wdzięczny za zwrócenie uwagi w komentarzu.\"]]],[1,\"h3\",[[0,[],0,\"Aktualizacja: Implementacje dużych liczb w Rust\"]]],[1,\"p\",[[0,[],0,\"DK13 - użytkownik serwisu wykop zwrócił uwagę na to, że w Rust mamy różne implementacje dużych liczb i ta którą z nich wybierzemy bardzo istotnie wpływa na wynik końcowy.\"]]],[10,81],[1,\"p\",[[0,[7],1,\"https://github.com/tczajka/bigint-benchmark-rs#results\"]]],[1,\"p\",[[0,[],0,\"Sprawdzę to niedługo i zaktualizuję treść tego wpisu.\"]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Był rok 1992. W miasteczku Wayne (Arizona USA) zapadał wyrok na Jamesa Nelsona - głównego księgowego i zarządzającego Arizona State Treasurer. Jego fałszywe czeki, dzięki którym zdefraudował prawie 2 miliony dolarów zostały wykryte ponieważ rozkład częstości pierwszych cyfr w wyłudzonych kwotach odbiegał od rozkładu Benforta.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/1520213042003.jpeg\" class=\"kg-image\" alt loading=\"lazy\" width=\"384\" height=\"289\"></figure><p>Na pierwszych pozycjach zmyślonych przez księgowego wartości zbyt często znajdowały się 7, 8 i 9 - typowe wartości postrzegane przez nas jako \"bardziej\" losowe niż 1, 2 lub 3.</p><hr><p>Z wpisu dowiesz się czym jest Rozkład Benforta i dlaczego jest obserwowany w wielu zbiorach danych. Później omówimy ciąg Fibonacciego i jego podstawowe własności. Na końcu napiszemy program sprawdzający czy Rozkład Benforta obowiązuje dla ciągu Fibonacciego. Program zostanie napisany w trzech językach:</p><ul><li>Java</li><li>Rust</li><li>Node JS</li></ul><p>Porównamy wyniki jego wydajności.</p><h2 id=\"rozk%C5%82ad-benforda\">Rozkład Benforda</h2><p>Rozkład Benforda jest rozkładem prawdopodobieństwa występowania określonych liczb na pierwszych pozycjach w wielu obserwowanych zbiorach danych liczbowych. Aby występował muszą zachodzić następujące warunki:</p><ul><li>zbiór wartości powinien rozciągać się na wiele rzędów wielkości</li><li>prawdopodobieństwo powinno być niezmiennicze względem skali oraz bazy</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/07/BenfordBroad.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"165\"><figcaption>Przykład rozkładu wielkości gdzie pierwsza cyfra spełnia w przybliżeniu prawo Benforda. Wykładniczy spadek rozkładu widzimy po zagęszczaniu się osi wartości.</figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/07/BenfordNarrow.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"401\" height=\"132\"><figcaption>Rozkład wielkości obejmujący jedne rząd wielkości. Zwykle pierwsze cyfry nie spełniają rozkładu Benforda, jeśli początkowy rozkład nie jest wystarczająco szeroki.</figcaption></figure><p>Świetne formalne wyprowadzenie rozkładu Benforda przestawili Arno Berger i Theodore P. Hill w publikacji: <a href=\"https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&amp;httpsredir=1&amp;article=1083&amp;context=rgp_rsr\">\"A basic theory of Benford’s Law\"</a></p><p>Jest to ponad 100 stronnicowa publikacja bardzo obszernie omawiająca temat i polecam ją wszystkim, którzy kochają matematykę. Krótsze i prostsze wyprowadzanie warte uwagi napisał <a href=\"https://www.researchgate.net/publication/45873771_A_derivation_of_Benford's_Law_and_a_vindication_of_Newcomb\">Victor Romero-Rochin</a></p><p>Przykłady rozkładów spełniających prawo Benforda mamy w przejrzysty sposób pokazane pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://testingbenfordslaw.com/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Testing Benford’s Law</div><div class=\"kg-bookmark-description\">An experiment to test Benford’s Law against large, publicly available datasets.</div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-publisher\">Jason Long (jasonlong) and Bryce Thornton (@brycethornton)</span></div></div></a></figure><p>Intuicyjnym powodem wyższej reprezentacji niższych cyfr jest wyższe prawdopodobieństwo wystąpienia wielu mniejszych wartości, które nakładając się na skokowo zmienną gęstość cyfr wraz ze wzrostem rzędu wielkości powoduje przesunięcie w stronę wyższej reprezentacji niższych cyfr na pierwszych pozycjach.</p><p>Ponieważ w tym artykule rozkład Benforda jest jedynie pretekstem do porównania wydajności programów pisanych w różnych językach a nie głównym tematem, pozwolę sobie ograniczyć jego opis do pokazania najlepszych publikacji, wyprowadzonej formuły i kilku przykładów. </p><p>Wzór na prawdopodobieństwo wystąpienia cyfry <code>d</code> na pierwszej pozycji to:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-20-11-49-38.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"172\" height=\"58\"></figure><p>Przykłady, które pokażę pochodzą z serwisu <code><a href=\"http://www.deltami.edu.pl/temat/matematyka/zastosowania/2016/03/21/Fenomen_rozkladu_Benforda/\">deltami.edu.pl</a></code></p><ul><li>Rozkład równomierny rozkładu równomiernego</li></ul><p>Ze zbioru liczb naturalnych z zakresu od 1 do 9999 losujemy liczbę p, wykorzystując generator liczb losowych o rozkładzie równomiernym. Następnie z zakresu liczb naturalnych od 1 do p losujemy, również wykorzystując rozkład równomierny, liczbę r.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/1012szy1_thumb_190px-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"190\" height=\"113\"></figure><ul><li>Masa atomowa pierwiastków z układu okresowego</li></ul><p>Zobaczmy na układ okresowy pierwiastków chemicznych, a dokładniej, jeden z parametrów każdego pierwiastka - masą atomową.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/1012szy2_thumb_190px.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"190\" height=\"113\"></figure><ul><li>Powierzchnia państw świata w km²</li></ul><p>Ostatni przykład jest powiązany z geografią - przyjrzyjmy się powierzchni wszystkich państw świata w km2.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/1012szy3_thumb_190px-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"190\" height=\"113\"></figure><ul><li>Prawo Benforda</li></ul><p>Dyskretny rozkład Benforda dla układu dziesiętnego zwany również prawem pierwszych (znaczących) cyfr.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/1012szy4_thumb_350px.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"350\" height=\"202\"></figure><p>Jak widzimy, wszystkie te zbiory liczb mają tą samą własność - niezmienniczość względem skali, bazy i rozciągnięcie na kilka rzędów wielkości.</p><h2 id=\"ci%C4%85g-fibonacciego\">Ciąg Fibonacciego</h2><p>Ciąg Fibonacciego jest ciągiem liczb naturalnych o rekurencyjnej definicji:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-20-12-02-05.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"259\" height=\"58\"></figure><p>gdzie</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-20-12-03-07.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"180\" height=\"60\"></figure><p>Jego własności opisane są w Math World.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://mathworld.wolfram.com/FibonacciNumber.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Fibonacci Number -- from Wolfram MathWorld</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">from Wolfram MathWorld</span><span class=\"kg-bookmark-publisher\">Eric Weisstein</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://mathworld.wolfram.com/images/topbar/logo.png\"></div></a></figure><p>Jego początkowe wartości to:</p><pre><code>1,1,2,3,5,8,13,21,34,55,89</code></pre><p>Jest to ciąg, którego występowanie możemy często obserwować w przyrodzie: w wirach wodnych, w kształcie tornad, w układzie kwiatów, rozgałęzieniach roślin, podziale ciała owadów. Jego powszechność zachwyca badaczy tego zjawiska. Podobnie jak powszechność funkcji wykładniczej czy kwadratowej wynika ona z prostoty wzoru i bycia dobrym przybliżeniem dla znacznie bardziej złożonych układów obserwowanych w rzeczywistości.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/868.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"916\" height=\"546\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/868.png 600w, __GHOST_URL__/content/images/2021/07/868.png 916w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Stosunki kolejnych wartości ciągu dążą do złotej proporcji. Dowód wynika wprost z definicji.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://mathworld.wolfram.com/GoldenRatio.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Golden Ratio -- from Wolfram MathWorld</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-author\">from Wolfram MathWorld</span><span class=\"kg-bookmark-publisher\">Eric Weisstein</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://mathworld.wolfram.com/images/topbar/logo.png\"></div></a></figure><p>Pierwiastki ciągu Fibonacciego również zbiegają do stałego stosunku ze wzrostem <code>n</code>, a sam ciąg bardzo szybko zaczyna rosnąć tak szybko, rozciąga się na wiele rzędów wielkości.</p><p>Podobnie jak liczby pierwsze, tak i ciąg Fibonacciego powinien spełniać rozkład Benforda. Sprawdźmy to pisząc programy w Java, Rust i Node JS.</p><h2 id=\"java\">Java</h2><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/7pp55ytrrpy31.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"341\" height=\"372\"></figure><p>Aby zrobić to w Javie wymagany jest import modułu <code>java.math.BigInteger</code>. </p><pre><code>import java.math.BigInteger;</code></pre><p>W pliku <code>Benford.java</code> w klasie <code>Benford</code> utworzymy funkcję <code>generateFibonacci</code>, która pozwoli nam przygotować ciąg</p><pre><code>public class Benford {\n    private static BigInteger[] generateFibonacci(int n) {\n        BigInteger[] fib = new BigInteger[n];\n        fib[0] = BigInteger.ONE;\n        if(n == 1) return fib;\n        fib[1] = BigInteger.ONE;\n        for (int i = 2; i &lt; n; i++)\n            fib[i] = fib[i - 1].add(fib[i - 2]);\n        return fib;\n    }</code></pre><p>Warto zwrócić uwagę, że zamiast <code>1</code> stosujemy tu <code>BigInteger.ONE</code> aby zachować zgodność typów. Podobnie zamiast klasycznego dodawania przez <code>+</code> stosujemy metodę <code>add</code> określoną na obiektach <code>BigInteger</code>.</p><p>W metodzie <code>main</code> przygotowujemy ciąg Fibbonaciego.</p><pre><code class=\"language-java\">    public static void main(String[] args) {\n        BigInteger[] numbers = generateFibonacci(\n            args.length &gt; 0 ? Integer.parseInt(args[0]) : 1000\n        );</code></pre><p>Dzięki <code>args</code> możemy użyć argumentu wpisanego przez użytkownika. Jeśli nie zostanie on podany domyślną wartością jest <code>1000</code>.</p><p>Następnie tablica <code>digits</code> zostaje wypełniona zliczeniami cyfr</p><pre><code>        int[] digits = new int[10];\n\n        for (BigInteger number : numbers)\n            digits[Integer.valueOf(number.toString().substring(0, 1))]++;</code></pre><p>Na końcu wyświetlamy tablicę porównującą wyniki z przewidywaniami teoretycznymi.</p><pre><code>        System.out.print(\"N   Ben        Fib\\n\");\n        for (int i = 1; i &lt; digits.length; i++)\n            System.out.printf(\"%d %10.6f %10.6f\\n\",\n                    i,\n                    (double) digits[i] / numbers.length,\n                    Math.log10(1.0 + 1.0 / i)\n            );\n    }\n}</code></pre><p>Kod wykonujemy wpisując <code>java Benford.java</code> i dostajemy wynik potwierdzający naszą teorię:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-20-13-09-42.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"411\" height=\"177\"></figure><h2 id=\"rust\">Rust</h2><p>Projekty w <code>Rust</code> rozpoczynamy poleceniem</p><pre><code>cargo new benford</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://doc.rust-lang.org/cargo/getting-started/first-steps.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">First Steps with Cargo - The Cargo Book</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://doc.rust-lang.org/cargo/favicon.png\"><span class=\"kg-bookmark-author\">The Cargo Book</span></div></div></a></figure><p>w katalogu <code>benford</code> powstaje plik <code>Cargo.toml</code> o zawartości</p><pre><code>[package]\nname = \"b\"\nversion = \"0.1.0\"\nedition = \"2018\"\n\n[dependencies]\n</code></pre><p>oraz plik <code>src/main.rs</code> o treści</p><pre><code>fn main() {\n    println!(\"Hello, world!\");\n}</code></pre><p>To bardzo miłe, że Rust wita nas w tak przyjemny sposób ułatwiając rozpoczęcie pracy z tym językiem.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/0001.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1920\" height=\"1080\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/0001.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/0001.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/07/0001.png 1600w, __GHOST_URL__/content/images/2021/07/0001.png 1920w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Aby skompilować program wykonujemy poleceniem</p><pre><code>cargo build</code></pre><p>Jego uruchomienie jest wówczas możliwe dzięki komendzie</p><pre><code>./target/debug/benford</code></pre><p>Aby skompilować i wykonać program jednocześnie użyjemy polecenia</p><pre><code>cargo run</code></pre><p>O ile w Javie do obsługi dużych liczb całkowitych używaliśmy jednej paczki, to w Rust potrzebujemy dwóch: <code>num-bigint</code> oraz <code>num-traits</code>. Dodamy je do projektu dopisując linie</p><pre><code>num-bigint = \"0.4.0\"\nnum-traits = \"0.2.14\"</code></pre><p>pod kluczem <code>[dependencies]</code> w pliku <code>Cargo.toml</code>. Wersje paczek automatycznie podpowie nam nasze <code>IDE</code>. Ich użycie w pliku <code>src/main.rs</code> wymaga napisania</p><pre><code>use num_bigint::BigUint;\nuse num_traits::{Zero, One};\nuse std::env;</code></pre><p>Gdzie <code>Uint</code> pochodzi od <code>unsigned integer</code> czyli liczb całkowitych, które nie poświęcają jednego bitu na znak, bo są zawsze dodatnie. Funckja generująca ciąg Fibonacciego będzie podobna do tej z <code>Javy</code></p><pre><code>fn generate_fibonacci(n: usize) -&gt; Vec&lt;BigUint&gt; {\n    let mut fib = vec![Zero::zero(); n];\n    fib[0] = One::one();\n    if n == 1 { return fib; }\n    fib[1] = One::one();\n    for i in 2..n {\n        fib[i] = &amp;fib[i - 1] + &amp;fib[i - 2];\n    }\n    return fib;\n}</code></pre><p>Widzimy, że główna różnica leży w nazwaniu typów. W funkcji <code>main</code> tak samo generujemy ciąg zapisując go do tablicy</p><pre><code>fn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n    \n    let numbers = generate_fibonacci(\n        if args.len() &gt; 1 { (&amp;args[1]).trim().parse().unwrap() } \n        else { 100 }\n    );</code></pre><p>Tym razem tablica argumentów zaczyna się od nazwy programu a przekazana wartość z linii poleceń ma indeks równy 1.</p><p>przygotowujemy tablicę ze zliczeniem ilości cyfr na pierwszych pozycjach</p><pre><code>    let mut digits = vec![0; 10];</code></pre><p>Zapis analogiczny do tego z Javy pozwala nam na zliczenie cyfr i zapisanie ilości ich wystąpień do tablicy</p><pre><code>    for n in numbers.iter() {\n        digits[n.to_string()[..1].parse::&lt;usize&gt;().unwrap()] += 1;\n    }</code></pre><p>Na końcu pokazujemy wyniki w konsoli dzięki następującej pętli</p><pre><code>    println!(\"N   Fib        Ben\");\n    for i in 1..digits.len() {\n        println!(\"{:} {:10.6} {:10.6}\",\n                 i,\n                 digits[i] as f64 / numbers.len() as f64,\n                 (1.0 + 1.0 / i as f64).log10()\n        );\n    }\n}</code></pre><h2 id=\"node-js\">Node JS</h2><p>Wyjątkową cechą prezentowanego programu jest to, że jak mało który projekt w <code>node js</code> nie zawiera on listy wymaganych paczek. Nie musimy tu importować żadnych modułów odpowiedzialnych z obsługę dużych liczb. Stałe o typie <code>BigInt</code> tworzymy dodając literę <code>n</code> po liczbie. Przez to funkcja do generowania ciągu Fibonacciego przybiera formę:</p><pre><code>const generate_fibonacci = (n) =&gt; {\n    let fib = [];\n    fib[0] = 1n;\n    if(n === 1) return fib;\n    fib[1] = 1n;\n    for (let i = 2; i &lt; n; i++)\n        fib[i] = fib[i - 1] + fib[i - 2];\n    return fib;\n};</code></pre><p>Łatwo możemy sobie jednak wyobrazić, że ktoś piszący kod tego nie zna różnicy między <code>1n</code> a <code>1</code> lub po prostu zapomniał, że pracuje z dużymi liczbami i napisał by go tak:</p><pre><code>const generate_fibonacci = (n) =&gt; {\n    let fib = [];\n    fib[0] = 1;\n    if(n === 1) return fib;\n    fib[1] = 1;\n    for (let i = 2; i &lt; n; i++)\n        fib[i] = fib[i - 1] + fib[i - 2];\n    return fib;\n};</code></pre><p>Aby symulować oba przypadki napiszmy uniwersalną funkcję sterowaną flagą <code>--cheat</code>.</p><pre><code>const generate_fibonacci = (n) =&gt; {\n    let fib = [];\n    fib[0] = process.argv[3] === '--cheat' ? 1 : 1n;\n    if(n === 1) return fib;\n    fib[1] = process.argv[3] === '--cheat' ? 1 : 1n;\n    for (let i = 2; i &lt; n; i++)\n        fib[i] = fib[i - 1] + fib[i - 2];\n    return fib;\n};</code></pre><p>W dalszej części okaże się jak kolosalne różnice w wydajności i poprawności programu robi ten jeden znaczek <code>n</code>. Przy pisaniu oprogramowania ważne jest aby rozumieć na jakich zakresach wartości pracuje program i poprawnie obsługiwać ich krańce.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/89c452c1e596c77dbb7fe3a17371c828.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"700\" height=\"465\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/89c452c1e596c77dbb7fe3a17371c828.jpg 600w, __GHOST_URL__/content/images/2021/07/89c452c1e596c77dbb7fe3a17371c828.jpg 700w\"></figure><blockquote>Pod tym względem <code>node</code> wymaga od programisty szczególnej odpowiedzialności, bo próbując ratować program przez rzuceniem błędu idzie na kompromisy, które jak się okaże czasami są genialne, ale bywają bardzo zwodnicze.</blockquote><p>Funkcji <code>generate_fibonacci</code> użyjemy w funkcji <code>main</code> w następujący sposób</p><pre><code>const main = () =&gt; {\n    const numbers = generate_fibonacci(\n       parseInt(process.argv[2]) || 1000\n    );</code></pre><p>Oczywiście w <code>node</code> nie mamy obowiązku definiowania funkcji <code>main</code> ale uważam to za dobrą praktykę, aby program miał wyraźnie określony punkt startu i dobrze zarysowane granice między deklarowaniem funkcji oraz procedur a ich używaniem. </p><p>Przy okazji twoją uwagę zwróciło zapewne to, że ponownie zupełnie inaczej indeksowany jest <code>argv</code>. Jak widać każdy język ma tu własną konwencję i tym razem dwa pierwsze argumenty to katalog i nazwa programu.</p><p>Tablica dziesięciu zer, w których znajdą się ilości zliczonych pierwszych cyfr może być zadeklarowana następująco</p><pre><code>const digits = [...new Array(10)].map(() =&gt; 0);</code></pre><p>Samo zliczanie jest równie proste co w innych językach</p><pre><code>numbers.forEach(n =&gt;\n    digits[n.toString().substr(0, 1)]++\n)</code></pre><p>Natomiast drukowanie wyników zamiast używać szablonu do którego wkładamy wartości jako argumenty korzysta bezpośrednio z template string</p><pre><code>    process.stdout.write(\"N   Ben        Fib\\n\");\n    for (let i = 1; i &lt; digits.length; i++) {\n        const ben = digits[i] / numbers.length;\n        const fib = Math.log10(1 + 1 / i);\n        process.stdout.write(\n            `${i}   ${ben.toFixed(6)}   ${fib.toFixed(6)}\\n`\n        )\n    }\n}</code></pre><p>Na końcu za pomocą wywołania funkcji <code>main</code> włączamy nasz program.</p><pre><code>main();</code></pre><h2 id=\"por%C3%B3wnanie-wydajno%C5%9Bci-program%C3%B3w\">Porównanie wydajności programów</h2><p>Przez wydajność programów mam na myśli wydajność skompilowanych programów bez liczenia czasu kompilacji. Dlatego w przypadku Javy musimy wykonać kompilację poleceniem</p><pre><code>javac Benford.java</code></pre><p>w wyniku tego polecenia powstanie plik <code>Benford.class</code>. </p><p>Dla rust kompilacja wykonana przez <code>cargo build</code> tworzy deweloperską nie zoptymalizowaną wersję. W celu utworzenia zoptymalizowanej należy dodać flagę <code>release</code>.</p><pre><code>cargo build --release</code></pre><p>Na przykład dla <code>n=1000</code> każdy program wyświetla to samo, ale różne są czasy obliczeń.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-11-30-41.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1100\" height=\"441\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-21-11-30-41.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-21-11-30-41.png 1000w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-11-30-41.png 1100w\"></figure><p>Rust miażdży konkurencję. Node js niezależnie od tego czy operujemy zaczynaliśmy od <code>1</code> czy od <code>1n</code> pokazuje te same wyniki i bardzo zbliżony nawet niezły czas. Java mimo znacznego zużycia <code>cpu</code> włącza się tak długo, że w tym teście wypada najgorzej.</p><p>Dla <code>n=10000</code> wynik Javy rośnie jedynie 10 razy, mimo, że Rust wykonuje obliczenia o dwa rzędy wielkości dłużej, a node 24 razy dłużej. </p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-11-42-22.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1103\" height=\"442\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-21-11-42-22.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-21-11-42-22.png 1000w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-11-42-22.png 1103w\"></figure><p>Niech nie będzie mylącym dla Was, że <code>n</code> zwiększyło się \"tylko\" 10 razy. Wartości przetwarzane przez program mają geometryczne tępo wzrostu osiągając szybko gigantyczne wartości. Na przykład dla <code>n=10000</code> wartość ciągu to:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-11-48-18.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1014\" height=\"600\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-21-11-48-18.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-21-11-48-18.png 1000w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-11-48-18.png 1014w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Różnica we wzroście wydajności wynika z tego, że Java ma najcięższy proces uruchamiania się. Node mimo, że całkiem lekki nadal wymaga załadowania całego interpretera przez co Rust mając najszybszy start pokazał o ile faktycznie wzrosła złożoność obliczeniowa.</p><p>Ponieważ głównym ciężarem jest tu dodawanie coraz większych liczb, których długość rośnie liniowo możemy spodziewać się złożoności O(n^2), którą prezentuje Rust.</p><p>Ostatnim wnioskiem jest, że program napisany w <code>Node JS</code> z flagą <code>--cheat</code> \"nie zauważył\", że działa źle. Jego wyniki pokazują, że mimo szybkiego wykonania nie zliczył on poprawie pierwszych cyfr. Znając ograniczenia typu <code>Number</code> w node wiemy, że nie może on przekroczyć wartości <code>Number.MAX_VALUE</code> równej <code>1.7976931348623157e+308</code>, tym czasem <code>Log10[Fibonacci[1000]]</code> wynosi <code>208.638</code> ale <code>Log10[Fibonacci[10000]]</code> to już <code>2089.53</code>. Zatem liczby które program w Node dodaje to <code>Infinity</code>.</p><p>Oczywiście <code>Infninity</code> + <code>Infnity</code> = <code>Infinity</code> co znacznie skraca czas obliczeń, ale pierwsza \"cyfra\" nieskończoności dla Node do <code>I</code> ponieważ wyliczamy ją poleceniem</p><pre><code>n.toString().substr(0, 1)</code></pre><p>Gdybym zatrzymał się na zestawieniu pary wyników dla trzech programów nie był bym sobą. Ciekawość karze mi zajrzeć głębiej i przygotować wykres pokazujący jak czas obliczeń rósł wraz z długością ciągu.</p><p>Pokaże jeszcze punkt pomiarowy <code>50.000</code>.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"__GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-13-02-25.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1097\" height=\"437\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/Screenshot-from-2021-07-21-13-02-25.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/Screenshot-from-2021-07-21-13-02-25.png 1000w, __GHOST_URL__/content/images/2021/07/Screenshot-from-2021-07-21-13-02-25.png 1097w\"></figure><p>Jednak omawianie każdego z osobna nie jest tak wartościowe, jak zrobienie całej serii pomiarów i nałożenie ich na wspólny wykres. </p><h3 id=\"pomiar-wydajno%C5%9Bci-program%C3%B3w-w-zale%C5%BCno%C5%9Bci-od-argumentu\">Pomiar wydajności programów w zależności od argumentu</h3><p>Aby skutecznie zmierzyć wydajność programów musimy rozwiązać kilka problemów</p><ul><li>rozdzielić strumienie z wynikiem programu od pomiaru wydajności</li><li>wybrać zestaw wartości dla których dokonamy pomiaru</li><li>narysować wykresy</li></ul><h4 id=\"rozdzielenie-strumienia-programu-od-strumienia-pomiaru-czasu\">Rozdzielenie strumienia programu od strumienia pomiaru czasu</h4><p>W bashu programy komunikują się za pomocą przekierowywania strumieni danych. Wyjście jednego programu może stać się wejściem innego, który po przetworzeniu podanych mu informacji może chcieć je zapisać do pliku.</p><p>Dla prostego wykonania:</p><pre><code>java Benford 10</code></pre><p>wynik w postaci:</p><pre><code>N   Ben        Fib\n1   0.300000   0.301030\n2   0.200000   0.176091\n3   0.200000   0.124939\n4   0.000000   0.096910\n5   0.200000   0.079181\n6   0.000000   0.066947\n7   0.000000   0.057992\n8   0.100000   0.051153\n9   0.000000   0.045757</code></pre><p>zostanie wyświetlony w terminalu ponieważ terminal jest domyślnym wyjściem dla strumienia danych produkowanych przez ten program. Dane produkowane przez program domyślnie wychodzą z niego przez wyjście standardowe. Możemy je przekierować w inne miejsce za pomocą <code>1&gt;</code> lub po prostu <code>&gt;</code> i pominąć <code>1</code>, która jest domyślna.</p><p>Wykonanie <code>java Benford 10 &gt; out</code> nic nie pokaże ale spowoduje utworzenie pliku z danymi z wyjścia standardowego.</p><p>Jednak kiedy program poprzedzimy poleceniem <code>time</code> czyli napiszemy</p><pre><code>time java Benford 10</code></pre><p>okaże się, że dostaniemy w terminalu</p><pre><code>N   Ben        Fib\n1   0.300000   0.301030\n2   0.200000   0.176091\n3   0.200000   0.124939\n4   0.000000   0.096910\n5   0.200000   0.079181\n6   0.000000   0.066947\n7   0.000000   0.057992\n8   0.100000   0.051153\n9   0.000000   0.045757\njava Benford 10  0.12s user 0.02s system 153% cpu 0.091 total</code></pre><p>jednak próba przechwycenia czasu wykonania do pliku jak poprzednio przez <code>&gt;</code> zakończy się wyświetleniem linii</p><pre><code>java Benford 10  0.12s user 0.02s system 153% cpu 0.091 total</code></pre><p>w terminalu, a do pliku zostanie przekierowana cała reszta. Jest tak dlatego, że time nie miesza swoich danych z danymi ze strumienia standardowego. Zamiast tego używa strumienia błędów <code>2&gt;</code>.</p><p>Naszym celem jest schowanie danych ze strumienia standardowego. Możemy to zrobić przekierowując go do <code>/dev/null</code>. To znaczy</p><pre><code>time java Benford 10 &gt; /dev/null</code></pre><p>Jednak strumień błędów jest dla nas niemożliwy do przetwarzania jeśli nie przekierujemy go na strumień główny. Osiągniemy to poleceniem</p><pre><code>(time java Benford 10 &gt; /dev/null) 2&gt;&amp;1</code></pre><p>Wynik tych dwóch wygląda tak samo, ale kluczową różnicą jest to, że w drugim przypadku możemy przetworzyć strumień za pomocą przekierowania go do <code>awk</code>.</p><p>Na przykład polecenie zawierające przetwarzanie danych:</p><pre><code>(time java Benford 10 &gt; /dev/null) 2&gt;&amp;1 | awk '{print $1,10,$6,$10,$12}'</code></pre><p>zwróci na wyjściu standardowym jedynie</p><pre><code>java 10 0.11s 154% 0.090</code></pre><p>aby oczyścić te wyniki ze znaku <code>s</code> i <code>%</code> możemy dodać </p><pre><code>| tr -d \"s%\"</code></pre><p>Jeśli chcemy oglądać ten wynik jednocześnie zachowując go do pliku, z pomocą przychodzi nam <code>tee</code> - trzecie z moich ulubionych narzędzi obok kafki i expressa.</p><p>Wystarczy na końcu dopisać:</p><pre><code>| tee -a logs</code></pre><p>a pokazana linia zostanie załączona na końcu pliku <code>logs</code>. Teraz załóżmy, że chcemy wytworzone właśnie polecenie otoczyć pętlą przechodzącą po sekwencji:</p><pre><code>for i in $(seq 5 5 25); do echo $i; done;</code></pre><p>Sekwencja wyświetli nam </p><pre><code>5\n10\n15\n20\n25</code></pre><p>Lecz jeśli wkleili byśmy naiwnie <code>$i</code> do <code>print</code> w <code>awk</code> w następujący sposób:</p><pre><code>for i in $(seq 5 5 25); do (time java Benford $i &gt; /dev/null) 2&gt;&amp;1 | awk '{print $1,$i,$6,$10,$12}' | tr -d \"s%\" | tee -a logs; done;</code></pre><p>dostali byśmy kilka razy powtórzoną linię</p><pre><code>java java Benford $i &gt; /dev/null  0.12s user 0.02s system 152% cpu 0.091 total 0.12 152 0.091\n...</code></pre><p>Jest tak dlatego, że <code>i</code> nie istnieje wewnątrz <code>print</code> jeśli go tam nie włożymy. Zatem <code>$i</code> wynosi tyle samo co <code>$0</code> co odpowiada całej linii, a nie wybranej kolumnie. Aby używać zmiennych wewnątrz kontekstu <code>print</code> w <code>awk</code> możemy użyć flagi <code>-v</code>. Poprawna składnia polecenia to:</p><pre><code>for i in $(seq 5 5 25); do (time java Benford $i &gt; /dev/null) 2&gt;&amp;1 | awk -v i=$i '{print $1,i,$6,$10,$12}' | tr -d \"s%\" | tee -a logs; done;</code></pre><p>a jego wynikiem jest jednoczesne zapisanie do pliku <code>logs</code> i pokazanie na ekranie linii:</p><pre><code>java 5 0.11 150 0.090\njava 10 0.12 153 0.089\njava 15 0.11 152 0.088\njava 20 0.10 154 0.087\njava 25 0.11 153 0.089</code></pre><p>Jeśli temat strumieni w <code>bash</code> cię zainteresował polecam wprowadzenie <a href=\"https://www.baeldung.com/linux/author/justin-albano\" rel=\"author\">Justina Albano</a>.</p><h4 id=\"przygotowanie-serii-warto%C5%9Bci-n-do-analizy-wydajno%C5%9Bci\">Przygotowanie serii wartości <code>n</code> do analizy wydajności</h4><p>Dzieląc zakres pomiarowy na części należy zagęszczać pomiary tam gdzie ich koszt jest niski (krótki czas działania programu) a zmienność i ciekawe zachowania są spodziewane. U nas jest to zmiana stosunku czasu obliczeń do czasu uruchamiania (typowe dla niewielkich wartości <code>n</code>). Mamy więc dwa powody, aby nie dzielić zakresu pomiaru na równe kawałki i nie używać <code>seq</code>. Zamiast tego możemy wygenerować serię, której gęstość spada wraz ze wzrostem <code>n</code>. Na przykład moduł w <code>Mathematica</code>:</p><pre><code class=\"language-mathematica\">Module[{steps = 100, minY = 1, maxY = 50000, pow = 3}, \n   Table[maxY (minY + maxY (n)^pow)/(minY + maxY), {n, 0, 1, \n     1/(steps - 1)}]] // Ceiling // DeleteDuplicates</code></pre><p>spowoduje powstanie serii o następującej dystrybucji</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/n-benford.svg\" class=\"kg-image\" alt loading=\"lazy\" width=\"480\" height=\"320\"></figure><p>Zapisujemy ją do pliku <code>n_values</code> poleceniem</p><pre><code>Export[\"~/exp/benford/n_values.csv\", %]</code></pre><h4 id=\"przygotowanie-wykres%C3%B3w-por%C3%B3wnuj%C4%85cych-wydajno%C5%9B%C4%87-program%C3%B3w\">Przygotowanie wykresów porównujących wydajność programów</h4><p>Kod mierzący wydajność zapiszemy w pliku <code>measure.sh</code> </p><pre><code>#!/usr/bin/zsh\n\nwhile IFS= read -r i\ndo\n (time node benford.js \"$i\" &gt; /dev/null) 2&gt;&amp;1 | awk -v i=\"$i\" '{print $1,i,$6,$10,$12}' | tee -a logs;\n (time ./target/release/benford \"$i\" &gt; /dev/null) 2&gt;&amp;1 | awk -v i=\"$i\" '{print \"rust\",i,$5,$9,$11}' | tee -a logs;\n (time java Benford \"$i\" &gt; /dev/null) 2&gt;&amp;1 | awk -v i=\"$i\" '{print $1,i,$6,$10,$12}' | tee -a logs;\ndone;</code></pre><p>Zamieniliśmy tu pętlę <code>for</code> na <code>while</code>. For z <code>cat n_values.csv</code> jest dopuszczalne, ale nie zalecane</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/koalaman/shellcheck/wiki/SC2013\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">SC2013 · koalaman/shellcheck Wiki</div><div class=\"kg-bookmark-description\">ShellCheck, a static analysis tool for shell scripts - SC2013 · koalaman/shellcheck Wiki</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">koalaman</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/328ce20d54f5d720f88e3303aa94c9eea7311c1be8d26db7e995d4b88173cb92/koalaman/shellcheck\"></div></a></figure><p>Warto też otoczyć <code>$i</code> cudzysłowami. Kiedy braliśmy dane z sekwencji to nie miało znaczenia i teraz też nie wpłynie na program, ale dobrą praktyką jest używanie cudzysłowów ponieważ jeśli w zmiennych znajdują się wartości zawierające spacje, to słowa oddzielone spacjami mogą być traktowane jako argumenty na kolejnych pozycjach zamiast jedna wartość. </p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/koalaman/shellcheck/wiki/SC2086\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">SC2086 · koalaman/shellcheck Wiki</div><div class=\"kg-bookmark-description\">ShellCheck, a static analysis tool for shell scripts - SC2086 · koalaman/shellcheck Wiki</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">koalaman</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/328ce20d54f5d720f88e3303aa94c9eea7311c1be8d26db7e995d4b88173cb92/koalaman/shellcheck\"></div></a></figure><p>Pomiar wykonujemy wpisując </p><pre><code>time zsh measure.sh</code></pre><p>Ładujemy utworzony plik</p><pre><code>logs = Import[\"/home/daniel/exp/benford/logs\", \"Data\"];</code></pre><p>i rysujemy wykres</p><pre><code>ListLogPlot[\n Table[{#[[1]], \n     PadLeft[ToExpression /@ StringSplit[ToString[#[[2]]], \":\"], \n        2]*{60, 1} // Total} &amp; /@ \n   GroupBy[logs, First][i][[All, {2, 5}]], {i, {\"java\", \"rut\", \n    \"node\"}}],\n PlotLegends -&gt; {\"Java\", \"Rust\", \"Node\"}, ImageSize -&gt; Full, \n Frame -&gt; True, \n FrameLabel -&gt; {\"Fibonaccin sequence length\", \"Total time\"}, \n LabelStyle -&gt; Directive[FontSize -&gt; 16]]</code></pre><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"__GHOST_URL__/content/images/2021/07/fib-benford-1.svg\" class=\"kg-image\" alt loading=\"lazy\" width=\"1428\" height=\"816\"></figure><p>Podsumowanie:</p><ul><li>długi czas startowania maszyny wirtualnej Javy nie pozwolił jej rozwinąć skrzydeł w początkowej fazie przez co wypadła ona najgorzej dla małych wartości <code>n</code>.</li><li>zaskakująco dobrze poradził sobie <code>Node</code>, który mimo, że nie zalecany do zadań obciążających procesor, to ma naprawdę nieźle zoptymalizowaną implementację <a href=\"https://v8.dev/blog/bigint\">BigInt</a></li><li>bezkonkurencyjny dla niskich <code>n</code> okazał się <code>Rust</code>, który ponieważ nie jest obciążony żadnym środowiskiem uruchomieniowym ani interpreterem, dla dużych <code>n</code> uległ jednak Javie, której zespół od <a href=\"https://en.wikipedia.org/wiki/Java_performance\">lat poprawiał </a>wydajność Javy w kolejnych wersjach.</li></ul><p>Zdaję sobie sprawę, że te programy można zoptymalizować, choćby pod względem zużycia pamięci - nie trzymając całych tablic z ciągami. Starałem się je napisać tak, aby we wszystkich językach były możliwie podobne i możliwie proste. Jeśli zauważyłeś w nich błąd będę bardzo wdzięczny za zwrócenie uwagi w komentarzu.</p><h3 id=\"aktualizacja-implementacje-du%C5%BCych-liczb-w-rust\">Aktualizacja: Implementacje dużych liczb w Rust</h3><p>DK13 - użytkownik serwisu wykop zwrócił uwagę na to, że w Rust mamy różne implementacje dużych liczb i ta którą z nich wybierzemy bardzo istotnie wpływa na wynik końcowy.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.wykop.pl/ludzie/DK13/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">DK13 - profil w Wykop.pl</div><div class=\"kg-bookmark-description\">Write once, debug everywhere.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.wykop.pl/static/wykoppl7/img/apple-touch-icon-180x180.png\"><span class=\"kg-bookmark-author\">Wykop.pl</span><span class=\"kg-bookmark-publisher\">DK13 12 godz. temu via Wykop Mobilny (Android) +1</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.wykop.pl/cdn/c3397992/DK13_WbosXcWahF,q250.jpg\"></div></a></figure><p><a href=\"https://github.com/tczajka/bigint-benchmark-rs#results\" rel=\"nofollow\">https://github.com/tczajka/bigint-benchmark-rs#results</a></p><p>Sprawdzę to niedługo i zaktualizuję treść tego wpisu.</p>",
            "comment_id": "60f5e2b750caaa182e07e949",
            "plaintext": "Był rok 1992. W miasteczku Wayne (Arizona USA) zapadał wyrok na Jamesa Nelsona -\ngłównego księgowego i zarządzającego Arizona State Treasurer. Jego fałszywe\nczeki, dzięki którym zdefraudował prawie 2 miliony dolarów zostały wykryte\nponieważ rozkład częstości pierwszych cyfr w wyłudzonych kwotach odbiegał od\nrozkładu Benforta.\n\nNa pierwszych pozycjach zmyślonych przez księgowego wartości zbyt często\nznajdowały się 7, 8 i 9 - typowe wartości postrzegane przez nas jako \"bardziej\"\nlosowe niż 1, 2 lub 3.\n\n\n--------------------------------------------------------------------------------\n\nZ wpisu dowiesz się czym jest Rozkład Benforta i dlaczego jest obserwowany w\nwielu zbiorach danych. Później omówimy ciąg Fibonacciego i jego podstawowe\nwłasności. Na końcu napiszemy program sprawdzający czy Rozkład Benforta\nobowiązuje dla ciągu Fibonacciego. Program zostanie napisany w trzech językach:\n\n * Java\n * Rust\n * Node JS\n\nPorównamy wyniki jego wydajności.\n\nRozkład Benforda\nRozkład Benforda jest rozkładem prawdopodobieństwa występowania określonych\nliczb na pierwszych pozycjach w wielu obserwowanych zbiorach danych liczbowych.\nAby występował muszą zachodzić następujące warunki:\n\n * zbiór wartości powinien rozciągać się na wiele rzędów wielkości\n * prawdopodobieństwo powinno być niezmiennicze względem skali oraz bazy\n\nPrzykład rozkładu wielkości gdzie pierwsza cyfra spełnia w przybliżeniu prawo\nBenforda. Wykładniczy spadek rozkładu widzimy po zagęszczaniu się osi wartości.\nRozkład wielkości obejmujący jedne rząd wielkości. Zwykle pierwsze cyfry nie\nspełniają rozkładu Benforda, jeśli początkowy rozkład nie jest wystarczająco\nszeroki.Świetne formalne wyprowadzenie rozkładu Benforda przestawili Arno Berger\ni Theodore P. Hill w publikacji: \"A basic theory of Benford’s Law\"\n[https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&httpsredir=1&article=1083&context=rgp_rsr]\n\nJest to ponad 100 stronnicowa publikacja bardzo obszernie omawiająca temat i\npolecam ją wszystkim, którzy kochają matematykę. Krótsze i prostsze\nwyprowadzanie warte uwagi napisał Victor Romero-Rochin\n[https://www.researchgate.net/publication/45873771_A_derivation_of_Benford's_Law_and_a_vindication_of_Newcomb]\n\nPrzykłady rozkładów spełniających prawo Benforda mamy w przejrzysty sposób\npokazane pod linkiem:\n\nTesting Benford’s LawAn experiment to test Benford’s Law against large,\npublicly\navailable datasets.Jason Long (jasonlong) and Bryce Thornton (@brycethornton)\n[https://testingbenfordslaw.com/]Intuicyjnym powodem wyższej reprezentacji\nniższych cyfr jest wyższe prawdopodobieństwo wystąpienia wielu mniejszych\nwartości, które nakładając się na skokowo zmienną gęstość cyfr wraz ze wzrostem\nrzędu wielkości powoduje przesunięcie w stronę wyższej reprezentacji niższych\ncyfr na pierwszych pozycjach.\n\nPonieważ w tym artykule rozkład Benforda jest jedynie pretekstem do porównania\nwydajności programów pisanych w różnych językach a nie głównym tematem, pozwolę\nsobie ograniczyć jego opis do pokazania najlepszych publikacji, wyprowadzonej\nformuły i kilku przykładów. \n\nWzór na prawdopodobieństwo wystąpienia cyfry d na pierwszej pozycji to:\n\nPrzykłady, które pokażę pochodzą z serwisu deltami.edu.pl\n[http://www.deltami.edu.pl/temat/matematyka/zastosowania/2016/03/21/Fenomen_rozkladu_Benforda/]\n\n * Rozkład równomierny rozkładu równomiernego\n\nZe zbioru liczb naturalnych z zakresu od 1 do 9999 losujemy liczbę p,\nwykorzystując generator liczb losowych o rozkładzie równomiernym. Następnie z\nzakresu liczb naturalnych od 1 do p losujemy, również wykorzystując rozkład\nrównomierny, liczbę r.\n\n * Masa atomowa pierwiastków z układu okresowego\n\nZobaczmy na układ okresowy pierwiastków chemicznych, a dokładniej, jeden z\nparametrów każdego pierwiastka - masą atomową.\n\n * Powierzchnia państw świata w km²\n\nOstatni przykład jest powiązany z geografią - przyjrzyjmy się powierzchni\nwszystkich państw świata w km2.\n\n * Prawo Benforda\n\nDyskretny rozkład Benforda dla układu dziesiętnego zwany również prawem\npierwszych (znaczących) cyfr.\n\nJak widzimy, wszystkie te zbiory liczb mają tą samą własność - niezmienniczość\nwzględem skali, bazy i rozciągnięcie na kilka rzędów wielkości.\n\nCiąg Fibonacciego\nCiąg Fibonacciego jest ciągiem liczb naturalnych o rekurencyjnej definicji:\n\ngdzie\n\nJego własności opisane są w Math World.\n\nFibonacci Number -- from Wolfram MathWorldfrom Wolfram MathWorldEric Weisstein\n[https://mathworld.wolfram.com/FibonacciNumber.html]Jego początkowe wartości to:\n\n1,1,2,3,5,8,13,21,34,55,89\n\nJest to ciąg, którego występowanie możemy często obserwować w przyrodzie: w\nwirach wodnych, w kształcie tornad, w układzie kwiatów, rozgałęzieniach roślin,\npodziale ciała owadów. Jego powszechność zachwyca badaczy tego zjawiska.\nPodobnie jak powszechność funkcji wykładniczej czy kwadratowej wynika ona z\nprostoty wzoru i bycia dobrym przybliżeniem dla znacznie bardziej złożonych\nukładów obserwowanych w rzeczywistości.\n\nStosunki kolejnych wartości ciągu dążą do złotej proporcji. Dowód wynika wprost\nz definicji.\n\nGolden Ratio -- from Wolfram MathWorldfrom Wolfram MathWorldEric Weisstein\n[https://mathworld.wolfram.com/GoldenRatio.html]Pierwiastki ciągu Fibonacciego\nrównież zbiegają do stałego stosunku ze wzrostem n, a sam ciąg bardzo szybko\nzaczyna rosnąć tak szybko, rozciąga się na wiele rzędów wielkości.\n\nPodobnie jak liczby pierwsze, tak i ciąg Fibonacciego powinien spełniać rozkład\nBenforda. Sprawdźmy to pisząc programy w Java, Rust i Node JS.\n\nJava\nAby zrobić to w Javie wymagany jest import modułu java.math.BigInteger. \n\nimport java.math.BigInteger;\n\nW pliku Benford.java w klasie Benford utworzymy funkcję generateFibonacci, która\npozwoli nam przygotować ciąg\n\npublic class Benford {\n    private static BigInteger[] generateFibonacci(int n) {\n        BigInteger[] fib = new BigInteger[n];\n        fib[0] = BigInteger.ONE;\n        if(n == 1) return fib;\n        fib[1] = BigInteger.ONE;\n        for (int i = 2; i < n; i++)\n            fib[i] = fib[i - 1].add(fib[i - 2]);\n        return fib;\n    }\n\nWarto zwrócić uwagę, że zamiast 1 stosujemy tu BigInteger.ONE aby zachować\nzgodność typów. Podobnie zamiast klasycznego dodawania przez + stosujemy metodę \nadd określoną na obiektach BigInteger.\n\nW metodzie main przygotowujemy ciąg Fibbonaciego.\n\n    public static void main(String[] args) {\n        BigInteger[] numbers = generateFibonacci(\n            args.length > 0 ? Integer.parseInt(args[0]) : 1000\n        );\n\nDzięki args możemy użyć argumentu wpisanego przez użytkownika. Jeśli nie\nzostanie on podany domyślną wartością jest 1000.\n\nNastępnie tablica digits zostaje wypełniona zliczeniami cyfr\n\n        int[] digits = new int[10];\n\n        for (BigInteger number : numbers)\n            digits[Integer.valueOf(number.toString().substring(0, 1))]++;\n\nNa końcu wyświetlamy tablicę porównującą wyniki z przewidywaniami teoretycznymi.\n\n        System.out.print(\"N   Ben        Fib\\n\");\n        for (int i = 1; i < digits.length; i++)\n            System.out.printf(\"%d %10.6f %10.6f\\n\",\n                    i,\n                    (double) digits[i] / numbers.length,\n                    Math.log10(1.0 + 1.0 / i)\n            );\n    }\n}\n\nKod wykonujemy wpisując java Benford.java i dostajemy wynik potwierdzający naszą\nteorię:\n\nRust\nProjekty w Rust rozpoczynamy poleceniem\n\ncargo new benford\n\nFirst Steps with Cargo - The Cargo BookThe Cargo Book\n[https://doc.rust-lang.org/cargo/getting-started/first-steps.html]w katalogu benford powstaje plik Cargo.toml o zawartości\n\n[package]\nname = \"b\"\nversion = \"0.1.0\"\nedition = \"2018\"\n\n[dependencies]\n\n\noraz plik src/main.rs o treści\n\nfn main() {\n    println!(\"Hello, world!\");\n}\n\nTo bardzo miłe, że Rust wita nas w tak przyjemny sposób ułatwiając rozpoczęcie\npracy z tym językiem.\n\nAby skompilować program wykonujemy poleceniem\n\ncargo build\n\nJego uruchomienie jest wówczas możliwe dzięki komendzie\n\n./target/debug/benford\n\nAby skompilować i wykonać program jednocześnie użyjemy polecenia\n\ncargo run\n\nO ile w Javie do obsługi dużych liczb całkowitych używaliśmy jednej paczki, to w\nRust potrzebujemy dwóch: num-bigint oraz num-traits. Dodamy je do projektu\ndopisując linie\n\nnum-bigint = \"0.4.0\"\nnum-traits = \"0.2.14\"\n\npod kluczem [dependencies] w pliku Cargo.toml. Wersje paczek automatycznie\npodpowie nam nasze IDE. Ich użycie w pliku src/main.rs wymaga napisania\n\nuse num_bigint::BigUint;\nuse num_traits::{Zero, One};\nuse std::env;\n\nGdzie Uint pochodzi od unsigned integer czyli liczb całkowitych, które nie\npoświęcają jednego bitu na znak, bo są zawsze dodatnie. Funckja generująca ciąg\nFibonacciego będzie podobna do tej z Javy\n\nfn generate_fibonacci(n: usize) -> Vec<BigUint> {\n    let mut fib = vec![Zero::zero(); n];\n    fib[0] = One::one();\n    if n == 1 { return fib; }\n    fib[1] = One::one();\n    for i in 2..n {\n        fib[i] = &fib[i - 1] + &fib[i - 2];\n    }\n    return fib;\n}\n\nWidzimy, że główna różnica leży w nazwaniu typów. W funkcji main tak samo\ngenerujemy ciąg zapisując go do tablicy\n\nfn main() {\n    let args: Vec<String> = env::args().collect();\n    \n    let numbers = generate_fibonacci(\n        if args.len() > 1 { (&args[1]).trim().parse().unwrap() } \n        else { 100 }\n    );\n\nTym razem tablica argumentów zaczyna się od nazwy programu a przekazana wartość\nz linii poleceń ma indeks równy 1.\n\nprzygotowujemy tablicę ze zliczeniem ilości cyfr na pierwszych pozycjach\n\n    let mut digits = vec![0; 10];\n\nZapis analogiczny do tego z Javy pozwala nam na zliczenie cyfr i zapisanie\nilości ich wystąpień do tablicy\n\n    for n in numbers.iter() {\n        digits[n.to_string()[..1].parse::<usize>().unwrap()] += 1;\n    }\n\nNa końcu pokazujemy wyniki w konsoli dzięki następującej pętli\n\n    println!(\"N   Fib        Ben\");\n    for i in 1..digits.len() {\n        println!(\"{:} {:10.6} {:10.6}\",\n                 i,\n                 digits[i] as f64 / numbers.len() as f64,\n                 (1.0 + 1.0 / i as f64).log10()\n        );\n    }\n}\n\nNode JS\nWyjątkową cechą prezentowanego programu jest to, że jak mało który projekt w \nnode js nie zawiera on listy wymaganych paczek. Nie musimy tu importować żadnych\nmodułów odpowiedzialnych z obsługę dużych liczb. Stałe o typie BigInt tworzymy\ndodając literę n po liczbie. Przez to funkcja do generowania ciągu Fibonacciego\nprzybiera formę:\n\nconst generate_fibonacci = (n) => {\n    let fib = [];\n    fib[0] = 1n;\n    if(n === 1) return fib;\n    fib[1] = 1n;\n    for (let i = 2; i < n; i++)\n        fib[i] = fib[i - 1] + fib[i - 2];\n    return fib;\n};\n\nŁatwo możemy sobie jednak wyobrazić, że ktoś piszący kod tego nie zna różnicy\nmiędzy 1n a 1 lub po prostu zapomniał, że pracuje z dużymi liczbami i napisał by\ngo tak:\n\nconst generate_fibonacci = (n) => {\n    let fib = [];\n    fib[0] = 1;\n    if(n === 1) return fib;\n    fib[1] = 1;\n    for (let i = 2; i < n; i++)\n        fib[i] = fib[i - 1] + fib[i - 2];\n    return fib;\n};\n\nAby symulować oba przypadki napiszmy uniwersalną funkcję sterowaną flagą --cheat\n.\n\nconst generate_fibonacci = (n) => {\n    let fib = [];\n    fib[0] = process.argv[3] === '--cheat' ? 1 : 1n;\n    if(n === 1) return fib;\n    fib[1] = process.argv[3] === '--cheat' ? 1 : 1n;\n    for (let i = 2; i < n; i++)\n        fib[i] = fib[i - 1] + fib[i - 2];\n    return fib;\n};\n\nW dalszej części okaże się jak kolosalne różnice w wydajności i poprawności\nprogramu robi ten jeden znaczek n. Przy pisaniu oprogramowania ważne jest aby\nrozumieć na jakich zakresach wartości pracuje program i poprawnie obsługiwać ich\nkrańce.\n\n> Pod tym względem node wymaga od programisty szczególnej odpowiedzialności, bo\npróbując ratować program przez rzuceniem błędu idzie na kompromisy, które jak\nsię okaże czasami są genialne, ale bywają bardzo zwodnicze.\nFunkcji generate_fibonacci użyjemy w funkcji main w następujący sposób\n\nconst main = () => {\n    const numbers = generate_fibonacci(\n       parseInt(process.argv[2]) || 1000\n    );\n\nOczywiście w node nie mamy obowiązku definiowania funkcji main ale uważam to za\ndobrą praktykę, aby program miał wyraźnie określony punkt startu i dobrze\nzarysowane granice między deklarowaniem funkcji oraz procedur a ich używaniem. \n\nPrzy okazji twoją uwagę zwróciło zapewne to, że ponownie zupełnie inaczej\nindeksowany jest argv. Jak widać każdy język ma tu własną konwencję i tym razem\ndwa pierwsze argumenty to katalog i nazwa programu.\n\nTablica dziesięciu zer, w których znajdą się ilości zliczonych pierwszych cyfr\nmoże być zadeklarowana następująco\n\nconst digits = [...new Array(10)].map(() => 0);\n\nSamo zliczanie jest równie proste co w innych językach\n\nnumbers.forEach(n =>\n    digits[n.toString().substr(0, 1)]++\n)\n\nNatomiast drukowanie wyników zamiast używać szablonu do którego wkładamy\nwartości jako argumenty korzysta bezpośrednio z template string\n\n    process.stdout.write(\"N   Ben        Fib\\n\");\n    for (let i = 1; i < digits.length; i++) {\n        const ben = digits[i] / numbers.length;\n        const fib = Math.log10(1 + 1 / i);\n        process.stdout.write(\n            `${i}   ${ben.toFixed(6)}   ${fib.toFixed(6)}\\n`\n        )\n    }\n}\n\nNa końcu za pomocą wywołania funkcji main włączamy nasz program.\n\nmain();\n\nPorównanie wydajności programów\nPrzez wydajność programów mam na myśli wydajność skompilowanych programów bez\nliczenia czasu kompilacji. Dlatego w przypadku Javy musimy wykonać kompilację\npoleceniem\n\njavac Benford.java\n\nw wyniku tego polecenia powstanie plik Benford.class. \n\nDla rust kompilacja wykonana przez cargo build tworzy deweloperską nie\nzoptymalizowaną wersję. W celu utworzenia zoptymalizowanej należy dodać flagę \nrelease.\n\ncargo build --release\n\nNa przykład dla n=1000 każdy program wyświetla to samo, ale różne są czasy\nobliczeń.\n\nRust miażdży konkurencję. Node js niezależnie od tego czy operujemy zaczynaliśmy\nod 1 czy od 1n pokazuje te same wyniki i bardzo zbliżony nawet niezły czas. Java\nmimo znacznego zużycia cpu włącza się tak długo, że w tym teście wypada\nnajgorzej.\n\nDla n=10000 wynik Javy rośnie jedynie 10 razy, mimo, że Rust wykonuje obliczenia\no dwa rzędy wielkości dłużej, a node 24 razy dłużej. \n\nNiech nie będzie mylącym dla Was, że n zwiększyło się \"tylko\" 10 razy. Wartości\nprzetwarzane przez program mają geometryczne tępo wzrostu osiągając szybko\ngigantyczne wartości. Na przykład dla n=10000 wartość ciągu to:\n\nRóżnica we wzroście wydajności wynika z tego, że Java ma najcięższy proces\nuruchamiania się. Node mimo, że całkiem lekki nadal wymaga załadowania całego\ninterpretera przez co Rust mając najszybszy start pokazał o ile faktycznie\nwzrosła złożoność obliczeniowa.\n\nPonieważ głównym ciężarem jest tu dodawanie coraz większych liczb, których\ndługość rośnie liniowo możemy spodziewać się złożoności O(n^2), którą prezentuje\nRust.\n\nOstatnim wnioskiem jest, że program napisany w Node JS z flagą --cheat \"nie\nzauważył\", że działa źle. Jego wyniki pokazują, że mimo szybkiego wykonania nie\nzliczył on poprawie pierwszych cyfr. Znając ograniczenia typu Number w node\nwiemy, że nie może on przekroczyć wartości Number.MAX_VALUE równej \n1.7976931348623157e+308, tym czasem Log10[Fibonacci[1000]] wynosi 208.638 ale \nLog10[Fibonacci[10000]] to już 2089.53. Zatem liczby które program w Node dodaje\nto Infinity.\n\nOczywiście Infninity + Infnity = Infinity co znacznie skraca czas obliczeń, ale\npierwsza \"cyfra\" nieskończoności dla Node do I ponieważ wyliczamy ją poleceniem\n\nn.toString().substr(0, 1)\n\nGdybym zatrzymał się na zestawieniu pary wyników dla trzech programów nie był\nbym sobą. Ciekawość karze mi zajrzeć głębiej i przygotować wykres pokazujący jak\nczas obliczeń rósł wraz z długością ciągu.\n\nPokaże jeszcze punkt pomiarowy 50.000.\n\nJednak omawianie każdego z osobna nie jest tak wartościowe, jak zrobienie całej\nserii pomiarów i nałożenie ich na wspólny wykres. \n\nPomiar wydajności programów w zależności od argumentu\nAby skutecznie zmierzyć wydajność programów musimy rozwiązać kilka problemów\n\n * rozdzielić strumienie z wynikiem programu od pomiaru wydajności\n * wybrać zestaw wartości dla których dokonamy pomiaru\n * narysować wykresy\n\nRozdzielenie strumienia programu od strumienia pomiaru czasu\nW bashu programy komunikują się za pomocą przekierowywania strumieni danych.\nWyjście jednego programu może stać się wejściem innego, który po przetworzeniu\npodanych mu informacji może chcieć je zapisać do pliku.\n\nDla prostego wykonania:\n\njava Benford 10\n\nwynik w postaci:\n\nN   Ben        Fib\n1   0.300000   0.301030\n2   0.200000   0.176091\n3   0.200000   0.124939\n4   0.000000   0.096910\n5   0.200000   0.079181\n6   0.000000   0.066947\n7   0.000000   0.057992\n8   0.100000   0.051153\n9   0.000000   0.045757\n\nzostanie wyświetlony w terminalu ponieważ terminal jest domyślnym wyjściem dla\nstrumienia danych produkowanych przez ten program. Dane produkowane przez\nprogram domyślnie wychodzą z niego przez wyjście standardowe. Możemy je\nprzekierować w inne miejsce za pomocą 1> lub po prostu > i pominąć 1, która jest\ndomyślna.\n\nWykonanie java Benford 10 > out nic nie pokaże ale spowoduje utworzenie pliku z\ndanymi z wyjścia standardowego.\n\nJednak kiedy program poprzedzimy poleceniem time czyli napiszemy\n\ntime java Benford 10\n\nokaże się, że dostaniemy w terminalu\n\nN   Ben        Fib\n1   0.300000   0.301030\n2   0.200000   0.176091\n3   0.200000   0.124939\n4   0.000000   0.096910\n5   0.200000   0.079181\n6   0.000000   0.066947\n7   0.000000   0.057992\n8   0.100000   0.051153\n9   0.000000   0.045757\njava Benford 10  0.12s user 0.02s system 153% cpu 0.091 total\n\njednak próba przechwycenia czasu wykonania do pliku jak poprzednio przez > \nzakończy się wyświetleniem linii\n\njava Benford 10  0.12s user 0.02s system 153% cpu 0.091 total\n\nw terminalu, a do pliku zostanie przekierowana cała reszta. Jest tak dlatego, że\ntime nie miesza swoich danych z danymi ze strumienia standardowego. Zamiast tego\nużywa strumienia błędów 2>.\n\nNaszym celem jest schowanie danych ze strumienia standardowego. Możemy to zrobić\nprzekierowując go do /dev/null. To znaczy\n\ntime java Benford 10 > /dev/null\n\nJednak strumień błędów jest dla nas niemożliwy do przetwarzania jeśli nie\nprzekierujemy go na strumień główny. Osiągniemy to poleceniem\n\n(time java Benford 10 > /dev/null) 2>&1\n\nWynik tych dwóch wygląda tak samo, ale kluczową różnicą jest to, że w drugim\nprzypadku możemy przetworzyć strumień za pomocą przekierowania go do awk.\n\nNa przykład polecenie zawierające przetwarzanie danych:\n\n(time java Benford 10 > /dev/null) 2>&1 | awk '{print $1,10,$6,$10,$12}'\n\nzwróci na wyjściu standardowym jedynie\n\njava 10 0.11s 154% 0.090\n\naby oczyścić te wyniki ze znaku s i % możemy dodać \n\n| tr -d \"s%\"\n\nJeśli chcemy oglądać ten wynik jednocześnie zachowując go do pliku, z pomocą\nprzychodzi nam tee - trzecie z moich ulubionych narzędzi obok kafki i expressa.\n\nWystarczy na końcu dopisać:\n\n| tee -a logs\n\na pokazana linia zostanie załączona na końcu pliku logs. Teraz załóżmy, że\nchcemy wytworzone właśnie polecenie otoczyć pętlą przechodzącą po sekwencji:\n\nfor i in $(seq 5 5 25); do echo $i; done;\n\nSekwencja wyświetli nam \n\n5\n10\n15\n20\n25\n\nLecz jeśli wkleili byśmy naiwnie $i do print w awk w następujący sposób:\n\nfor i in $(seq 5 5 25); do (time java Benford $i > /dev/null) 2>&1 | awk '{print $1,$i,$6,$10,$12}' | tr -d \"s%\" | tee -a logs; done;\n\ndostali byśmy kilka razy powtórzoną linię\n\njava java Benford $i > /dev/null  0.12s user 0.02s system 152% cpu 0.091 total 0.12 152 0.091\n...\n\nJest tak dlatego, że i nie istnieje wewnątrz print jeśli go tam nie włożymy.\nZatem $i wynosi tyle samo co $0 co odpowiada całej linii, a nie wybranej\nkolumnie. Aby używać zmiennych wewnątrz kontekstu print w awk możemy użyć flagi \n-v. Poprawna składnia polecenia to:\n\nfor i in $(seq 5 5 25); do (time java Benford $i > /dev/null) 2>&1 | awk -v i=$i '{print $1,i,$6,$10,$12}' | tr -d \"s%\" | tee -a logs; done;\n\na jego wynikiem jest jednoczesne zapisanie do pliku logs i pokazanie na ekranie\nlinii:\n\njava 5 0.11 150 0.090\njava 10 0.12 153 0.089\njava 15 0.11 152 0.088\njava 20 0.10 154 0.087\njava 25 0.11 153 0.089\n\nJeśli temat strumieni w bash cię zainteresował polecam wprowadzenie Justina\nAlbano [https://www.baeldung.com/linux/author/justin-albano].\n\nPrzygotowanie serii wartości n do analizy wydajności\nDzieląc zakres pomiarowy na części należy zagęszczać pomiary tam gdzie ich koszt\njest niski (krótki czas działania programu) a zmienność i ciekawe zachowania są\nspodziewane. U nas jest to zmiana stosunku czasu obliczeń do czasu uruchamiania\n(typowe dla niewielkich wartości n). Mamy więc dwa powody, aby nie dzielić\nzakresu pomiaru na równe kawałki i nie używać seq. Zamiast tego możemy\nwygenerować serię, której gęstość spada wraz ze wzrostem n. Na przykład moduł w \nMathematica:\n\nModule[{steps = 100, minY = 1, maxY = 50000, pow = 3}, \n   Table[maxY (minY + maxY (n)^pow)/(minY + maxY), {n, 0, 1, \n     1/(steps - 1)}]] // Ceiling // DeleteDuplicates\n\nspowoduje powstanie serii o następującej dystrybucji\n\nZapisujemy ją do pliku n_values poleceniem\n\nExport[\"~/exp/benford/n_values.csv\", %]\n\nPrzygotowanie wykresów porównujących wydajność programów\nKod mierzący wydajność zapiszemy w pliku measure.sh \n\n#!/usr/bin/zsh\n\nwhile IFS= read -r i\ndo\n (time node benford.js \"$i\" > /dev/null) 2>&1 | awk -v i=\"$i\" '{print $1,i,$6,$10,$12}' | tee -a logs;\n (time ./target/release/benford \"$i\" > /dev/null) 2>&1 | awk -v i=\"$i\" '{print \"rust\",i,$5,$9,$11}' | tee -a logs;\n (time java Benford \"$i\" > /dev/null) 2>&1 | awk -v i=\"$i\" '{print $1,i,$6,$10,$12}' | tee -a logs;\ndone;\n\nZamieniliśmy tu pętlę for na while. For z cat n_values.csv jest dopuszczalne,\nale nie zalecane\n\nSC2013 · koalaman/shellcheck WikiShellCheck, a static analysis tool for shell\nscripts - SC2013 · koalaman/shellcheck WikiGitHubkoalaman\n[https://github.com/koalaman/shellcheck/wiki/SC2013]Warto też otoczyć $i cudzysłowami. Kiedy braliśmy dane z sekwencji to nie miało\nznaczenia i teraz też nie wpłynie na program, ale dobrą praktyką jest używanie\ncudzysłowów ponieważ jeśli w zmiennych znajdują się wartości zawierające spacje,\nto słowa oddzielone spacjami mogą być traktowane jako argumenty na kolejnych\npozycjach zamiast jedna wartość. \n\nSC2086 · koalaman/shellcheck WikiShellCheck, a static analysis tool for shell\nscripts - SC2086 · koalaman/shellcheck WikiGitHubkoalaman\n[https://github.com/koalaman/shellcheck/wiki/SC2086]Pomiar wykonujemy wpisując \n\ntime zsh measure.sh\n\nŁadujemy utworzony plik\n\nlogs = Import[\"/home/daniel/exp/benford/logs\", \"Data\"];\n\ni rysujemy wykres\n\nListLogPlot[\n Table[{#[[1]], \n     PadLeft[ToExpression /@ StringSplit[ToString[#[[2]]], \":\"], \n        2]*{60, 1} // Total} & /@ \n   GroupBy[logs, First][i][[All, {2, 5}]], {i, {\"java\", \"rut\", \n    \"node\"}}],\n PlotLegends -> {\"Java\", \"Rust\", \"Node\"}, ImageSize -> Full, \n Frame -> True, \n FrameLabel -> {\"Fibonaccin sequence length\", \"Total time\"}, \n LabelStyle -> Directive[FontSize -> 16]]\n\nPodsumowanie:\n\n * długi czas startowania maszyny wirtualnej Javy nie pozwolił jej rozwinąć\n   skrzydeł w początkowej fazie przez co wypadła ona najgorzej dla małych\n   wartości n.\n * zaskakująco dobrze poradził sobie Node, który mimo, że nie zalecany do zadań\n   obciążających procesor, to ma naprawdę nieźle zoptymalizowaną implementację \n   BigInt [https://v8.dev/blog/bigint]\n * bezkonkurencyjny dla niskich n okazał się Rust, który ponieważ nie jest\n   obciążony żadnym środowiskiem uruchomieniowym ani interpreterem, dla dużych n \n   uległ jednak Javie, której zespół od lat poprawiał\n   [https://en.wikipedia.org/wiki/Java_performance]wydajność Javy w kolejnych\n   wersjach.\n\nZdaję sobie sprawę, że te programy można zoptymalizować, choćby pod względem\nzużycia pamięci - nie trzymając całych tablic z ciągami. Starałem się je napisać\ntak, aby we wszystkich językach były możliwie podobne i możliwie proste. Jeśli\nzauważyłeś w nich błąd będę bardzo wdzięczny za zwrócenie uwagi w komentarzu.\n\nAktualizacja: Implementacje dużych liczb w Rust\nDK13 - użytkownik serwisu wykop zwrócił uwagę na to, że w Rust mamy różne\nimplementacje dużych liczb i ta którą z nich wybierzemy bardzo istotnie wpływa\nna wynik końcowy.\n\nDK13 - profil w Wykop.plWrite once, debug everywhere.Wykop.plDK13 12 godz. temu\nvia Wykop Mobilny (Android) +1 [https://www.wykop.pl/ludzie/DK13/]\nhttps://github.com/tczajka/bigint-benchmark-rs#results\n\nSprawdzę to niedługo i zaktualizuję treść tego wpisu.",
            "feature_image": "__GHOST_URL__/content/images/2021/07/ciag_1446650693.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-07-19T20:38:15.000Z",
            "updated_at": "2021-07-22T10:10:14.000Z",
            "published_at": "2021-07-21T15:57:21.000Z",
            "custom_excerpt": "Programy napisane w Java, Rust i Node JS ścigają się w sprawdzeniu rozkładu pierwszych cyfr ciągu Fibonacciego. Zobacz w czym są podobne, a w czym się różnią i jak ich wydajność zależy od długości ciągu.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "611f504250caaa182e07eec0",
            "uuid": "9842b9e7-7ba1-4ebf-a437-e98755fa074f",
            "title": "Jeszcze jedna instrukcja instalacji Arch Linux (i3)",
            "slug": "jeszcze-jeden-wpis-o-instalacji-arch-linux",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://wiki.archlinux.org/title/Network_configuration_(Polski)#DHCP\",\"metadata\":{\"url\":\"https://wiki.archlinux.org/title/Network_configuration_(Polski)#DHCP\",\"title\":\"Network configuration (Polski) - ArchWiki\",\"description\":null,\"author\":null,\"publisher\":\"ArchWiki\",\"thumbnail\":\"https://wiki.archlinux.org/images/3/38/Tango-view-fullscreen.png\",\"icon\":\"https://wiki.archlinux.org/favicon.ico\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/10/Hokk8sK.jpeg\",\"width\":2170,\"height\":1070,\"cardWidth\":\"full\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://archlinux.org/download/\",\"metadata\":{\"url\":\"https://archlinux.org/download/\",\"title\":\"Arch Linux - Downloads\",\"description\":null,\"author\":null,\"publisher\":\"Downloads\",\"thumbnail\":\"https://archlinux.org/static/magnet.29ed728b8ae4.png\",\"icon\":\"https://archlinux.org/static/logos/apple-touch-icon-144x144.38cf584757c3.png\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/08/Screenshot-from-2021-08-20-09-23-06.png\",\"width\":837,\"height\":437,\"caption\":\"\"}],[\"code\",{\"code\":\"sudo umount /dev/sde1\"}],[\"code\",{\"code\":\"sudo dd bs=8M if=arch.iso of=/dev/sde status=progress\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/08/1-arch-linux.jpg\",\"width\":637,\"height\":478}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/08/Screenshot-from-2021-08-20-09-51-53.png\",\"width\":503,\"height\":168}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/08/Screenshot-from-2021-08-20-09-54-15.png\",\"width\":504,\"height\":191}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://superuser.com/questions/1581961/arch-linux-dual-boot-with-win-10-kernel-panic-not-syncing-fatal-exception/1582265#1582265\",\"metadata\":{\"url\":\"https://superuser.com/questions/1581961/arch-linux-dual-boot-with-win-10-kernel-panic-not-syncing-fatal-exception\",\"title\":\"Arch Linux (dual boot with Win 10). Kernel panic - not syncing: Fatal exception in interrupt. Caps Lock indicator blinking until reboot\",\"description\":\"On my laptop I have Arch Linux and Windows 10 installed (BIOS MBR). When I’m using Arch occasional kernel panic occurs. This happens mostly when I install some packages using pacman.\\nLast time I st...\",\"author\":\"quantumleap\",\"publisher\":\"Super User\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon@2.png?v=e869e4459439\",\"icon\":\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon.png?v=0ad5b7a83e49\"}}],[\"code\",{\"code\":\"ping -c 3 google.com\"}],[\"code\",{\"code\":\"pacman -Sy reflector\"}],[\"code\",{\"code\":\"reflector -c \\\"Poland\\\" --latest 5 --sort rate --save /etc/pacman.d/mirrorlist\"}],[\"code\",{\"code\":\"reflector -c \\\"Poland\\\" --latest 5 --sort rate --download-timeout 60 --save /etc/pacman.d/mirrorlist\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://bbs.archlinux.org/viewtopic.php?id=262621\",\"metadata\":{\"url\":\"https://bbs.archlinux.org/viewtopic.php?id=262621\",\"title\":\"Reflector returns “failed to rate http(s) download: Download ......” ! / Newbie Corner / Arch Linux Forums\",\"description\":null,\"author\":null,\"publisher\":null,\"thumbnail\":\"https://bbs.archlinux.org/img/smilies/big_smile.png\",\"icon\":\"https://bbs.archlinux.org/style/ArchLinux/favicon.ico\"}}],[\"code\",{\"code\":\"GPT PMBR size mismatch will be corrected by w(rite)\"}],[\"code\",{\"code\":\"parted -l\"}],[\"code\",{\"code\":\"cfdisk /dev/sda\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/10/IMG_20211016_155428378.jpg\",\"width\":4160,\"height\":3120}],[\"code\",{\"code\":\"mkfs.ext4 /dev/sda1\"}],[\"code\",{\"code\":\"mount /dev/sda1 /mnt\"}],[\"code\",{\"code\":\"fdisk /dev/sda\"}],[\"code\",{\"code\":\"mkfs.fat -F32 /dev/sda1\"}],[\"code\",{\"code\":\"mkfs.ext4 /dev/sda2\"}],[\"code\",{\"code\":\"mount /dev/sda2 /mnt\"}],[\"code\",{\"code\":\"mkdir /mnt/boot\"}],[\"code\",{\"code\":\"mount /dev/sda1 /mnt/boot\"}],[\"code\",{\"code\":\"pacstrap /mnt base linux linux-firmware nano\"}],[\"code\",{\"code\":\"genfstab -U /mnt >> /mnt/etc/fstab\"}],[\"code\",{\"code\":\"arch-chroot /mnt /bin/bash\"}],[\"code\",{\"code\":\"fallocate -l 2GB /swapfile\\nchmod 600 /swapfile\\nmkswap /swapfile\\nswapon /swapfile\"}],[\"code\",{\"code\":\"/swapfile none swap defaults 0 0\"}],[\"code\",{\"code\":\"ln -sf /usr/share/zoneinfo/Europe/Warsaw /etc/localtime\"}],[\"code\",{\"code\":\"hwclock --systohc\"}],[\"code\",{\"code\":\"nano /etc/locale.gen\"}],[\"code\",{\"code\":\"locale-gen\"}],[\"code\",{\"code\":\"echo LANG=pl_PL.UTF-8 > /etc/locale.conf\"}],[\"code\",{\"code\":\"KEYMAP=pl\\nFONT=Lat2-Terminus16\\nFONT_MAP=8859-2\"}],[\"code\",{\"code\":\"127.0.0.1    localhost.localdomain    preciselab\"}],[\"code\",{\"code\":\"pacman -S networkmanager dhcpcd\"}],[\"code\",{\"code\":\"systemctl enable NetworkMananger\"}],[\"code\",{\"code\":\"pacman -S network-manager-applet wireless_tools wpa_supplicant dialog netctl os-prober base-devel linux-headers reflector git cups xdg-utils xdg-user-dirs openssh iwd\"}],[\"code\",{\"code\":\"pacman -S grub\"}],[\"code\",{\"code\":\"grub-install /dev/sda\"}],[\"code\",{\"code\":\"grub-mkconfig -o /boot/grub/grub.cfg\"}],[\"code\",{\"code\":\"pacman -S grub efibootmgr\"}],[\"code\",{\"code\":\"grub-install --target=x86_64-efi --efi-direcotry=/boot --bootloader-id=GRUB\"}],[\"code\",{\"code\":\"parted /dev/sda\\nset 1 boot off\\nset 1 bios_grub on\\nq\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://superuser.com/a/1610045/1216455\",\"metadata\":{\"url\":\"https://superuser.com/questions/903112/grub2-install-this-gpt-partition-label-contains-no-bios-boot-partition\",\"title\":\"grub2-install: “this GPT partition label contains no BIOS Boot Partition”\",\"description\":\"There seems to be quite a bit of discussion about this but I can’t find a simple answer. When I try to install grub2 I get this error: # grub2-install /dev/sda\\nInstalling for i386-pc platform.\\ngr...\",\"author\":\"Robert S\",\"publisher\":\"Super User\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon@2.png?v=e869e4459439\",\"icon\":\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon.png?v=0ad5b7a83e49\"}}],[\"code\",{\"code\":\"modprobe efivars\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://unix.stackexchange.com/a/91623/431667\",\"metadata\":{\"url\":\"https://unix.stackexchange.com/questions/91620/efi-variables-are-not-supported-on-this-system\",\"title\":\"“EFI variables are not supported on this system”\",\"description\":\"I am attempting to install Arch linux to a new (and very crappy) HP Pavillion 15 Notebook. This is a UEFI-based machine. After several swings at it, I have managed to get pretty far. Legacy mode...\",\"author\":\"John Dibling\",\"publisher\":\"Unix & Linux Stack Exchange\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon@2.png?v=32fb07f7ce26\",\"icon\":\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon.png?v=5cf7fe716a89\"}}],[\"code\",{\"code\":\"efivar-tester\"}],[\"code\",{\"code\":\"grub-mkconfig -o /boot/grub/grub.cfg\"}],[\"code\",{\"code\":\"pacman -S sudo\"}],[\"code\",{\"code\":\"passwd root\"}],[\"code\",{\"code\":\"useradd -m -g users -G wheel -s /bin/bash daniel\"}],[\"code\",{\"code\":\"passwd daniel\"}],[\"code\",{\"code\":\"EDITOR=nano visudo\"}],[\"code\",{\"code\":\"%wheel ALL=(ALL) ALL\"}],[\"code\",{\"code\":\"exit\"}],[\"code\",{\"code\":\"umount /mnt\"}],[\"code\",{\"code\":\"shutdown -P now\"}],[\"code\",{\"code\":\"ip addr\"}],[\"code\",{\"code\":\"ip link set dev <interface> up\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://unix.stackexchange.com/a/613819/431667\",\"metadata\":{\"url\":\"https://unix.stackexchange.com/questions/236514/how-do-i-attach-devices-to-connections-using-nmcli\",\"title\":\"how do I attach devices to connections using nmcli?\",\"description\":\"An installation of CentOS 7 has two connections and three devices. How can I attach the device ens7 to the connection my-bridge? And how can I attach the device eth0 to the connection my-eth1? ...\",\"author\":\"CodeMed\",\"publisher\":\"Unix & Linux Stack Exchange\",\"thumbnail\":\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon@2.png?v=32fb07f7ce26\",\"icon\":\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon.png?v=5cf7fe716a89\"}}],[\"code\",{\"code\":\"/etc/resolv.conf\"}],[\"code\",{\"code\":\"nameserver 8.8.8.8\"}],[\"code\",{\"code\":\"systemctl status systemd-resolved.service\"}],[\"code\",{\"code\":\"pacman-key -l Thorsten\"}],[\"code\",{\"code\":\"pacman-key --refresh-keys\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://bbs.archlinux.org/viewtopic.php?id=207957\",\"metadata\":{\"url\":\"https://bbs.archlinux.org/viewtopic.php?id=207957\",\"title\":\"Signature is unknown trust [SOLVED] / Pacman & Package Upgrade Issues / Arch Linux Forums\",\"description\":null,\"author\":null,\"publisher\":null,\"thumbnail\":\"https://bbs.archlinux.org/img/avatars/27289.jpg?m=1572193439\",\"icon\":\"https://bbs.archlinux.org/style/ArchLinux/favicon.ico\"}}],[\"code\",{\"code\":\"git clone https://aur.archlinux.org/yay.git\"}],[\"code\",{\"code\":\"cd yay && makepkg -si\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://low-orbit.net/arch-linux-how-to-install-yay\",\"metadata\":{\"url\":\"https://low-orbit.net/arch-linux-how-to-install-yay\",\"title\":\"Arch Linux How to Install Yay - Super EASY | Low Orbit Flux\",\"description\":\"Arch Linux How to Install Yay - Super EASY | Low Orbit Flux\",\"author\":null,\"publisher\":\"Low Orbit Flux\",\"thumbnail\":\"https://low-orbit.net/low-orbit-logo-2-d.png\",\"icon\":\"https://low-orbit.net/favicon.png\"}}],[\"code\",{\"code\":\"yay -S i3-gaps\"}],[\"code\",{\"code\":\"yay -S ttf-dejavu i3status\"}],[\"code\",{\"code\":\"yay -S xorg xorg-xinit rxvt-unicode\"}],[\"code\",{\"code\":\"yay -S xf86-video-ati\"}],[\"code\",{\"code\":\"yay -S nvidia nvidia-utils\"}],[\"code\",{\"code\":\"yay -S xf86-video-intel\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://wiki.archlinux.org/title/xorg\",\"metadata\":{\"url\":\"https://wiki.archlinux.org/title/xorg\",\"title\":\"Xorg - ArchWiki\",\"description\":null,\"author\":null,\"publisher\":\"ArchWiki\",\"thumbnail\":\"https://wiki.archlinux.org/images/d/d6/Tango-inaccurate.png\",\"icon\":\"https://wiki.archlinux.org/favicon.ico\"}}],[\"code\",{\"code\":\"yay -S alsa-utils pulseaudio pavucontrol\\nspeaker-test -c2\\nalsamixer\"}],[\"code\",{\"code\":\"nano /etc/X11/xinit/xinitrc\"}],[\"code\",{\"code\":\"#twm &\\n#exec xterm ....\"}],[\"code\",{\"code\":\"exec i3\"}],[\"code\",{\"code\":\"startx\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://low-orbit.net/arch-linux-how-to-install-i3-gaps\",\"metadata\":{\"url\":\"https://low-orbit.net/arch-linux-how-to-install-i3-gaps\",\"title\":\"Arch Linux How to Install i3 Gaps - Super EASY | Low Orbit Flux\",\"description\":\"Arch Linux How to Install i3 Gaps - Super EASY | Low Orbit Flux\",\"author\":null,\"publisher\":\"Low Orbit Flux\",\"thumbnail\":\"https://low-orbit.net/low-orbit-logo-2-d.png\",\"icon\":\"https://low-orbit.net/favicon.png\"}}],[\"embed\",{\"url\":\"https://www.youtube.com/watch?v=le_Z6l-NPeo&t=486s\",\"html\":\"<iframe width=\\\"200\\\" height=\\\"113\\\" src=\\\"https://www.youtube.com/embed/le_Z6l-NPeo?start=486&feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\",\"metadata\":{\"title\":\"i3wm/i3-gaps: Podstawowa konfiguracja\",\"author_name\":\"distroverse\",\"author_url\":\"https://www.youtube.com/c/distroverse\",\"height\":113,\"width\":200,\"version\":\"1.0\",\"provider_name\":\"YouTube\",\"provider_url\":\"https://www.youtube.com/\",\"thumbnail_height\":360,\"thumbnail_width\":480,\"thumbnail_url\":\"https://i.ytimg.com/vi/le_Z6l-NPeo/hqdefault.jpg\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/gustawdaniel/my-arch-i3-config/blob/main/.config/i3/config\",\"metadata\":{\"url\":\"https://github.com/gustawdaniel/my-arch-i3-config\",\"title\":\"my-arch-i3-config/config at main · gustawdaniel/my-arch-i3-config\",\"description\":\"Contribute to gustawdaniel/my-arch-i3-config development by creating an account on GitHub.\",\"author\":\"gustawdaniel\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/c7e9ab912b1bb2522df5792cd3bf38216fc9c7e33d89de79f8f0dd67df2a6c22/gustawdaniel/my-arch-i3-config\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"embed\",{\"url\":\"https://www.youtube.com/watch?v=_kjbj-Ez1vU&t=381s\",\"html\":\"<iframe width=\\\"200\\\" height=\\\"113\\\" src=\\\"https://www.youtube.com/embed/_kjbj-Ez1vU?start=381&feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\",\"metadata\":{\"title\":\"urxvt: Jump Start (1/2)\",\"author_name\":\"Code Cast\",\"author_url\":\"https://www.youtube.com/c/CodeCast\",\"height\":113,\"width\":200,\"version\":\"1.0\",\"provider_name\":\"YouTube\",\"provider_url\":\"https://www.youtube.com/\",\"thumbnail_height\":360,\"thumbnail_width\":480,\"thumbnail_url\":\"https://i.ytimg.com/vi/_kjbj-Ez1vU/hqdefault.jpg\"}}],[\"code\",{\"code\":\"cd ~\"}],[\"code\",{\"code\":\"touch .Xresources\"}],[\"code\",{\"code\":\"curl https://raw.githubusercontent.com/gustawdaniel/my-arch-i3-config/main/.Xresources > .Xresources\"}],[\"code\",{\"code\":\"xrdb ~/.Xresources\"}],[\"code\",{\"code\":\"yay -S google-chrome\"}],[\"code\",{\"code\":\"Section \\\"InputClass\\\"\\n    Identifier \\\"system-keyboard\\\"\\n    MatchIsKeyboard \\\"on\\\"\\n    Option \\\"XkbLayout\\\" \\\"pl\\\"\\nEndSection\"}],[\"code\",{\"code\":\"yay -S dmenu\"}],[\"code\",{\"code\":\"yay -S flameshot\"}],[\"code\",{\"code\":\"bindsym Print exec flameshot gui\"}],[\"code\",{\"code\":\"yay -S barrier\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/10/2021-10-16_23-25.png\",\"width\":736,\"height\":421}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/10/2021-10-13_00-04.png\",\"width\":748,\"height\":428}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/10/2021-10-13_00-04_1.png\",\"width\":852,\"height\":571}],[\"code\",{\"code\":\"yay -S zsh\"}],[\"code\",{\"code\":\"sh -c \\\"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\\\"\"}],[\"code\",{\"code\":\" xrandr --listmonitors\"}],[\"code\",{\"code\":\".config/i3/.bg.jpeg\"}],[\"code\",{\"code\":\"yay -S feh\"}],[\"code\",{\"code\":\"#!/bin/sh\\nfeh --no-fehbg --bg-scale '/home/daniel/.config/i3/.bg.jpeg'\"}],[\"code\",{\"code\":\"sudo chmod +x ~/.fehbg\"}],[\"code\",{\"code\":\"exec --no-startup-id sh ~/.fehbg\"}],[\"code\",{\"code\":\"yay -S neovim\"}],[\"code\",{\"code\":\"sudo timedatectl set-ntp true \"}],[\"code\",{\"code\":\"yay -S bashtop\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/10/2021-10-17_00-54.png\",\"width\":1868,\"height\":1132,\"cardWidth\":\"\"}],[\"code\",{\"code\":\"yay -S ly\\nsudo systemctl enable ly.service\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/10/88958888-65efbf80-d2a1-11ea-8ae5-3f263bce9cce.png\",\"width\":1014,\"height\":700}],[\"code\",{\"code\":\"yay -S tmux ruby\\ngem install tmuxinator\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/gustawdaniel/my-arch-i3-config/blob/main/.tmux.conf\",\"metadata\":{\"url\":\"https://github.com/gustawdaniel/my-arch-i3-config\",\"title\":\"my-arch-i3-config/.tmux.conf at main · gustawdaniel/my-arch-i3-config\",\"description\":\"Contribute to gustawdaniel/my-arch-i3-config development by creating an account on GitHub.\",\"author\":\"gustawdaniel\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/329bf602abfbb3c32fc70733557d3fb9f40c7171acdb51064027ff062f032e06/gustawdaniel/my-arch-i3-config\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/10/2021-10-22_01-27.png\",\"width\":1181,\"height\":629}],[\"code\",{\"code\":\"yay -S bitwardern\"}],[\"code\",{\"code\":\"exec --no-startup-id bitwarden\\nbindsym $Mod+k [instance=\\\"bitwarden\\\"] scratchpad show; [instance=\\\"bitwarden\\\"] move position center\\nfor_window [instance=\\\"bitwarden\\\"] move scratchpad\\nfor_window [instance=\\\"bitwarden\\\"] border pixel 3\\nfor_window [instance=\\\"bitwarden\\\"] resize set 800 600\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/10/2021-10-22_01-26.png\",\"width\":1186,\"height\":815}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/10/x4akxjcv21e31-1.png\",\"width\":500,\"height\":566}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Arch Linux jest systemem, który kocham za elastyczność i wygodę użytkowania. Jego instalacja uchodzi za jedną z trudniejszych, ponieważ przenosi na nas ciężar decydowania o wielu szczegółach, którymi nie przejmujemy się podczas codziennej pracy z komputerem. \"]]],[1,\"p\",[[0,[],0,\"Za przykład niech posłuży wybór klienta DHCP, dzięki któremu możemy dostać adres IP, maskę podsieci, adres bramy domyślnej i adresy serwerów DNS. Są dwa dostępne programy do obsługi protokołu DHCP. Od Ciebie zależy, który z nich zainstalujesz:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Tego typu decyzji podejmujemy przy instalacji arch linux więcej, dlatego najlepszym źródłem wiedzy będzie zawsze ArchWiki. Ten artykuł ma na celu pokazanie mojej instalacji, którą możesz powtórzyć w całości lub wybrać z niej wartościowe dla Ciebie elementy i wkomponować je we własną pasującą do Ciebie instalację.\"]]],[1,\"p\",[[0,[],0,\"Instalacja zostanie pokazana zarówno na komputerze z UEFI jak i BIOS. \"]]],[1,\"p\",[[0,[],0,\"Kolejno omówimy:\"]]],[3,\"ol\",[[[0,[],0,\"Podłączenie do sieci wifi\"]],[[0,[],0,\"Instalację systemu\"]],[[0,[],0,\"Instalację managera okien \"],[0,[0],1,\"i3-gaps\"]],[[0,[],0,\"Konfigurację \"],[0,[0],1,\"i3\"],[0,[],0,\" i podstawowych programów\"]]]],[1,\"p\",[[0,[],0,\"Rdzeń instalacji przedstawia poniższa grafika, ale niektóre komendy będą się u nas różnić.\"]]],[10,1],[1,\"h2\",[[0,[],0,\"Przygotowanie bootowalnego pendrive\"]]],[1,\"p\",[[0,[],0,\"Obraz ISO Archa możemy pobrać z torrentów: \"]]],[10,2],[1,\"p\",[[0,[],0,\"Jednak ponieważ płyty CD nie są już używane, domyślnym działaniem jest wgranie go na USB. Żeby to zrobić wkładamy pendrive do komputera i sprawdzamy jaką nazwę dostał jednym z poleceń \"],[0,[0],1,\"dmesg | grep Attached\"],[0,[],0,\", \"],[0,[0],1,\"df -h\"],[0,[],0,\" lub \"],[0,[0],1,\"lsblk\"],[0,[],0,\".\"]]],[10,3],[1,\"p\",[[0,[],0,\"W naszym przypadku jest to \"],[0,[0],1,\"sde\"],[0,[],0,\". Odmontowujemy pendrive komedą:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Po czym z katalogu zawierającego obraz \"],[0,[0],1,\"iso\"],[0,[],0,\" wgrywamy go na pendrive.\"]]],[10,5],[1,\"p\",[[0,[],0,\"Po włożeniu pendrive do docelowej maszyny i uruchomieniu zwykle należy użyć \"],[0,[0],1,\"F12\"],[0,[],0,\" przy starcie, ale to zależy od modelu komputera i ustawień BIOS.\"]]],[1,\"p\",[[0,[],0,\"Jeśli się uda powinniśmy zobaczyć:\"]]],[10,6],[1,\"p\",[[0,[],0,\"Po zatwierdzeniu przez \"],[0,[0],1,\"ENTER\"],[0,[],0,\" trafimy do konsoli instalatora\"]]],[1,\"h2\",[[0,[],0,\"Podłączenie sieci wifi przez iwctl\"]]],[1,\"p\",[[0,[],0,\"Nawiązanie połączenia z internetem jest naszym pierwszym zadaniem.\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od listy dostępnych urządzeń, wpisujemy \"],[0,[0],1,\"iwctl\"],[0,[],0,\" a następnie \"],[0,[0],1,\"device list\"],[0,[],0,\".\"]]],[10,7],[1,\"p\",[[0,[],0,\"Lista sieci dostępna jest po wpisaniu \"],[0,[0],1,\"station wlan0 get-networks\"]]],[10,8],[1,\"p\",[[0,[],0,\"Podłączamy się do wybranej sieci poleceniem \"],[0,[0],1,\"station wlan0 connect TP-Link_CEC8\"],[0,[],0,\" i podajemy hasło.\"]]],[1,\"p\",[[0,[],0,\"W przypadku bardzo starego laptopa Acer Aspire One - miałem błąd ze sterownikami wifi i musiałem podłączyć się przez ethernet.\"]]],[10,9],[1,\"p\",[[0,[],0,\"Aby wyłączyć \"],[0,[0],1,\"iwctl\"],[0,[],0,\" wpisujemy \"],[0,[0],1,\"quit\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Do sprawdzenia, czy mamy poprawnie nawiązane połączenie możemy użyć\"]]],[10,10],[1,\"h1\",[[0,[],0,\"Instalacja Arch\"]]],[1,\"p\",[[0,[],0,\"Instalujemy \"],[0,[0],1,\"reflector\"]]],[10,11],[1,\"p\",[[0,[],0,\"Aktualizujemy listę repozytoriów\"]]],[10,12],[1,\"p\",[[0,[],0,\"Jeśli twój internet jest wolny dodaj falgę \"],[0,[0],1,\"--download-timeout\"],[0,[],0,\", np.:\"]]],[10,13],[10,14],[1,\"p\",[[0,[],0,\"Za pomocą \"],[0,[0],1,\"fdisk -l\"],[0,[],0,\" lub \"],[0,[0],1,\"lsblk\"],[0,[],0,\" wyświetlamy dostępne dyski\"]]],[1,\"p\",[[0,[],0,\"Jeśli zobaczymy błąd\"]]],[10,15],[1,\"p\",[[0,[],0,\"naprawiamy go wpisując\"]]],[10,16],[1,\"p\",[[0,[],0,\"a następnie \"],[0,[0],1,\"fix\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Partycje można poustawiać poleceniem\"]]],[10,17],[1,\"p\",[[0,[],0,\"oczywiście adres dysku może u Ciebie być inny niż \"],[0,[0],1,\"/dev/sda\"],[0,[],0,\". Wybieramy typ \"],[0,[0],1,\"linux (x86)\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Teraz musimy okreslicz czy instalujemy system bootawny z biosa czy przez uefi. Jesli nie wiemy sprawdzmy czy nasza plyta gowna obsluguje UEFI i jesli tak to lepiej wybrac uefi. Jesli masz nowy komputer mozesz pominac rozdzial \\\"BIOS\\\" i przejsc do \\\"UEFI\\\".\"]]],[1,\"h3\",[[0,[],0,\"BIOS\"]]],[1,\"p\",[[0,[],0,\"Na starszych komputerach użyjemy biosa. Programem \"],[0,[0],1,\"cfdisk\"],[0,[],0,\" lub \"],[0,[0],1,\"fdisk\"],[0,[],0,\" mozemy ustawic:\"]]],[3,\"ul\",[[[0,[],0,\"bootowalna patrycje sda1 z typem 83 Linux\"]],[[0,[],0,\"nie bootowalna partycje sda2 z typem 82 Linux Swap\"]]]],[10,18],[1,\"p\",[[0,[],0,\"Fortsmtujemy utworzona partycje\"]]],[10,19],[1,\"p\",[[0,[],0,\"Montujemy gotowa partycje do \"],[0,[0],1,\"/mnt\"]]],[10,20],[1,\"p\",[[0,[],0,\"Możemy teraz pominąć fragment \\\"UEFI\\\" i przejść do \\\"Pacstrap\\\"\"]]],[1,\"h3\",[[0,[],0,\"UEFI\"]]],[1,\"p\",[[0,[],0,\"W przypadku UEFI musimy przygotować tabelę GPT. Możesz użyć do tego bardziej przyjazdnego programu \"],[0,[0],1,\"cfdisk\"],[0,[],0,\", lub bardziej zaawansowanego \"],[0,[0],1,\"fdisk\"],[0,[],0,\". Poniżej pokazuję to w \"],[0,[0],1,\"fdisk\"],[0,[],0,\".\"]]],[10,21],[1,\"p\",[[0,[],0,\"wybieramy opcję \"],[0,[0],1,\"g\"]]],[1,\"p\",[[0,[],0,\"Tworzymy partycję \"],[0,[0],1,\"uefi\"],[0,[],0,\" wybierając kolejno \"],[0,[0],1,\"n\"],[0,[],0,\" (nowa), \"],[0,[0],1,\"ENTER\"],[0,[],0,\" (nie zmieniamy punku pierwszego sektora), \"],[0,[0],1,\"+200M\"],[0,[],0,\" (ustawiamy ostatni sektor na \"],[0,[0],1,\"+ 200 MB\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Ustawiamy typ na \"],[0,[0],1,\"EFI System\"],[0,[],0,\" przez \"],[0,[0],1,\"t\"],[0,[],0,\" (jak type), \"],[0,[0],1,\"1\"],[0,[],0,\" (numer typu \"],[0,[0],1,\"EFI System\"],[0,[],0,\").\"]]],[1,\"p\",[[0,[],0,\"Tworzymy drugą partycję \"],[0,[0],1,\"n\"],[0,[],0,\" (new), \"],[0,[0],1,\"ENTER\"],[0,[],0,\" (domyślny numer 2), \"],[0,[0],1,\"ENTER\"],[0,[],0,\" (domyślny początkowy blok), \"],[0,[0],1,\"ENTER\"],[0,[],0,\" (domyślny końcowy blok).\"]]],[1,\"p\",[[0,[],0,\"Zapisujemy zmiany wybierając \"],[0,[0],1,\"w\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Formatowanie partycji UEFI na \"],[0,[0],1,\"fat 32\"]]],[10,22],[1,\"p\",[[0,[],0,\"Formatowanie na system plików drugiej partycji na \"],[0,[0],1,\"ext4\"],[0,[],0,\":\"]]],[10,23],[1,\"p\",[[0,[],0,\"Montujemy partycję na system do katalogu \"],[0,[0],1,\"/mnt\"],[0,[],0,\".\"]]],[10,24],[1,\"p\",[[0,[],0,\"A partycję na uefi do \"],[0,[0],1,\"/mnt/boot\"],[0,[],0,\", najpierw musimy utworzyć ten katalog\"]]],[10,25],[1,\"p\",[[0,[],0,\"i teraz zamontować\"]]],[10,26],[1,\"p\",[[0,[],0,\"Dzięki poleceniu \"],[0,[0],1,\"slblk\"],[0,[],0,\" możemy sprawdzić, czy montowanie jest poprawne.\"]]],[1,\"h3\",[[0,[],0,\"Pacstrap\"]]],[1,\"p\",[[0,[],0,\"I instalujemy system poleceniem \"],[0,[0],1,\"pacstrap\"]]],[10,27],[1,\"p\",[[0,[],0,\"Generujemy plik \"],[0,[0],1,\"fstab\"],[0,[],0,\".\"]]],[10,28],[1,\"p\",[[0,[],0,\"Wchodzimy do zainstalowanego systemu\"]]],[10,29],[1,\"h3\",[[0,[],0,\"Swapfile\"]]],[1,\"p\",[[0,[],0,\"Przygotowujemy swap:\"]]],[10,30],[1,\"p\",[[0,[],0,\"Do \"],[0,[0],1,\"/etc/fstab\"],[0,[],0,\" dodajemy\"]]],[10,31],[1,\"h3\",[[0,[],0,\"Strefa czasowa\"]]],[1,\"p\",[[0,[],0,\"Ustawiamy strefę czasową\"]]],[10,32],[1,\"p\",[[0,[],0,\"Generujemy \"],[0,[0],1,\"adjtime\"],[0,[],0,\" żeby zsynchronizować zegar systemowy ze sprzętowym\"]]],[10,33],[1,\"h3\",[[0,[],0,\"Język\"]]],[1,\"p\",[[0,[],0,\"Ustawimy lokalizację kasując komentarz jednej z linii pliku \"],[0,[0],1,\"locale.gen\"]]],[10,34],[1,\"p\",[[0,[],0,\"Generujemy obsługę języków\"]]],[10,35],[1,\"p\",[[0,[],0,\"W pliku \"],[0,[0],1,\"/etc/locale.conf\"],[0,[],0,\" wpisujemy \"],[0,[0],1,\"LANG=pl_PL.UTF-8\"]]],[10,36],[1,\"p\",[[0,[],0,\"A w \"],[0,[0],1,\"/etc/vconsole.conf\"]]],[10,37],[1,\"h3\",[[0,[],0,\"Sieć\"]]],[1,\"p\",[[0,[],0,\"W \"],[0,[0],1,\"/etc/hostname\"],[0,[],0,\" ustawiamy nazwę hosta. Jest to nazwa naszego komputera - przydatna jeśli mamy kilka urządzeń w sieci lokalnej.\"]]],[1,\"p\",[[0,[],0,\"W \"],[0,[0],1,\"/etc/hosts\"],[0,[],0,\" dodajemy linie\"]]],[10,38],[1,\"p\",[[0,[],0,\"trzecia kolumna zawiera nazwę hosta wybrana poprzednio.\"]]],[1,\"p\",[[0,[],0,\"Instalujemy \"],[0,[0],1,\"networkmanager\"],[0,[],0,\".\"]]],[10,39],[1,\"p\",[[0,[],0,\"Włączamy usługę \"],[0,[0],1,\"NetworkManager\"]]],[10,40],[1,\"h3\",[[0,[],0,\"Przydatne paczki\"]]],[1,\"p\",[[0,[],0,\"Jest to indywidualna decyzja, jakie jeszcze inne pakiety powinien zawierać system. Wymienię i opiszę kilka polecanych przeze mnie.\"]]],[3,\"ul\",[[[0,[],0,\"network-manager-applet - frontend do zarządzania połączeniami z siecią\"]],[[0,[],0,\"wireless_tools - otwarty projekt sponsorowany przez HP - zawiera narzędzia takie jak iwconfig iwlist iwspy wipriv oraz ifrename do obsługi sieci wifi\"]],[[0,[],0,\"wpa_supplicant - wsparcie dla szyfrowanych wifi WEP, WPA, WPA2 and WPA3 - dzisiaj niezbędny\"]],[[0,[],0,\"dialog - paczka do wyświetlania okien dialogowych ze skryptów w bashu, wymagana do używania wifi-menu\"]],[[0,[],0,\"netctl - konsolowe narzędzie do zarządzania sieciami ( zawiera wifi-menu )\"]],[[0,[],0,\"os-prober - narzędzie do wykrywania innych systemów operacyjnych i urządzeń, przydatne jeśli grub ich nie widzi\"]],[[0,[],0,\"base-devel - zestaw paczek do kompilacji, obróbki tekstu i kompresji\"]],[[0,[],0,\"linux-headers - skrypty do budowania modułów jadra systemowego\"]],[[0,[],0,\"reflector - skrypt do automatyzacji wyboru serwerów lustrzanych\"]],[[0,[],0,\"git - system kontroli wersji używany do programowania i instalacji pakietów\"]],[[0,[],0,\"cups - rozwijany przez Apple system do obsługi drukarek\"]],[[0,[],0,\"xdg-utils - narzędzia pomocnicze dla aplikacji XDG MIME\"]],[[0,[],0,\"xdg-user-dirs - narzędzie do integracji katalogu użytkownika z innymi programami, w szczególności przydatne dla managerów plików\"]],[[0,[],0,\"openssh - oprogramowanie do połączenia się przez ssh\"]],[[0,[],0,\"iwd - narzędzie do łączenia się z siecią np przez iwctl\"]]]],[1,\"p\",[[0,[],0,\"Możemy je zainstalować poleceniem:\"]]],[10,41],[1,\"p\",[[0,[],0,\"Jeśli chcesz używać bluetooth to przydadzą Ci się jeszcze \"],[0,[0],1,\"bluez bluez-utils\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Teraz zainstalujemy bootloader, żeby system mógł poprawnie wystartować. W zależności od tego czy wybrałeś opcje BIOS czy UEFI przejdź do odpowiedniego rozdziału.\"]]],[1,\"h3\",[[0,[],0,\"Boot loader w BIOS\"]]],[1,\"p\",[[0,[],0,\"Instalujemy bootloader\"]]],[10,42],[1,\"p\",[[0,[],0,\"używamy komendy \"],[0,[0],1,\"grub-install\"]]],[10,43],[1,\"p\",[[0,[],0,\"i tworzymy plik konfiguracyjny gruba\"]]],[10,44],[1,\"h3\",[[0,[],0,\"Boot loader w UEFI\"]]],[1,\"p\",[[0,[],0,\"Instalujemy bootloader\"]]],[10,45],[1,\"p\",[[0,[],0,\"używamy komendy \"],[0,[0],1,\"grub-install\"]]],[10,46],[1,\"p\",[[0,[],0,\"w przypadku błędu\"]]],[1,\"blockquote\",[[0,[],0,\"this GPT partition label contains no BIOS Boot Partition\"]]],[1,\"p\",[[0,[],0,\"naprawiamy poleceniem\"]]],[10,47],[10,48],[1,\"p\",[[0,[],0,\"W przypadku błędu\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"EFI variables are not supported on this system\\\"\"]]],[1,\"p\",[[0,[],0,\"wychodzimy z \"],[0,[0],1,\"chroot\"],[0,[],0,\" przez \"],[0,[0],1,\"exit\"],[0,[],0,\" i wpisujemy\"]]],[10,49],[10,50],[1,\"p\",[[0,[],0,\"Jeśli zobaczymy błąd\"]]],[1,\"blockquote\",[[0,[],0,\"Module efivars not found in directory /lib/modules/5.10.3-arch1-1\"]]],[1,\"p\",[[0,[],0,\"musimy włączyć komputer ponownie w trybie efi. Jest tak dlatego, że cześć maszyn może wybierać czy włącza się w trybie bios czy efi.\"]]],[1,\"p\",[[0,[],0,\"Dokumentacja mówi, że możemy sprawdzić czy to działa wpisując:\"]]],[10,51],[1,\"p\",[[0,[],0,\"ale nie polecam tej metody, u mnie zapętla się w nieskończoność i nie da się tego wyłączyć inaczej niż sprzętowo wyłączając komputer.\"]]],[1,\"p\",[[0,[],0,\"Tworzymy plik konfiguracyjny dla gruba\"]]],[10,52],[1,\"h3\",[[0,[],0,\"Użytkownicy\"]]],[1,\"p\",[[0,[],0,\"Aby na co dzień moc poslugiwac sie systemem bez uprawnień roota a jednocześnie móc szybko nabywać, zainstalujemy sudo\"]]],[10,53],[1,\"p\",[[0,[],0,\"Ustawiamy hasło dla \"],[0,[0],1,\"root\"]]],[10,54],[1,\"p\",[[0,[],0,\"Dodajemy użytkownika do codziennego użytku\"]]],[10,55],[1,\"p\",[[0,[],0,\"Dajemy mu hasło\"]]],[10,56],[1,\"p\",[[0,[],0,\"Grupie \"],[0,[0],1,\"wheel\"],[0,[],0,\" pozwalamy na używanie \"],[0,[0],1,\"sudo\"],[0,[],0,\".\"]]],[10,57],[1,\"p\",[[0,[],0,\"kasujemy komentarz przed linią\"]]],[10,58],[1,\"p\",[[0,[],0,\"Wychodzimy z instalatora\"]]],[10,59],[1,\"p\",[[0,[],0,\"Odmontowujemy partycję\"]]],[10,60],[1,\"p\",[[0,[],0,\"Wyłączamy komputer\"]]],[10,61],[1,\"h3\",[[0,[],0,\"Problemy sieciowe\"]]],[1,\"p\",[[0,[],0,\"Jeśli po wpisaniu\"]]],[10,62],[1,\"p\",[[0,[],0,\"interfejsy są wyłączone to można je włączyć przez\"]]],[10,63],[1,\"p\",[[0,[],0,\"Do sprawdzenia, które interfejsy warto włączyć przydatne może być \"],[0,[0],1,\"nmcli\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Jeśli nie możesz włączyć interfejsu, ale znasz nazwę i hasło sieci możesz spróbować bezpośredniego połączenia podążając za zaleceniami z linku:\"]]],[10,64],[1,\"p\",[[0,[],0,\"nie mam pojęcia dlaczego to działa.\"]]],[1,\"p\",[[0,[],0,\"Jeśli tłumaczenie nazw domen na adresy ip, nie działa poprawnie musimy wybrać domyślny DNS. Ustawiamy to w\"]]],[10,65],[1,\"p\",[[0,[],0,\"wpisując\"]]],[10,66],[1,\"p\",[[0,[],0,\"Stan serwisu odpowiadającego za nadawanie domenom numerów ip sprawdzimy poleceniem\"]]],[10,67],[1,\"h3\",[[0,[],0,\"Błędy z kluczami\"]]],[1,\"p\",[[0,[],0,\"Jeśli mamy błędy typu\"]]],[1,\"blockquote\",[[0,[],0,\"Signature is unknown trust\"]]],[1,\"p\",[[0,[],0,\"Możemy sprawdzić dany klucz\"]]],[10,68],[1,\"p\",[[0,[],0,\"i jeśli wygasł, to odświeżyć listę kluczy\"]]],[10,69],[10,70],[1,\"h3\",[[0,[],0,\"Instalacja yay\"]]],[1,\"p\",[[0,[],0,\"Yay jest pomocniczym programem do zarządzania zależnościami. Jeśli zainstalowałeś \"],[0,[0],1,\"base-devel\"],[0,[],0,\" możesz pobrać yay za pomocą gita\"]]],[10,71],[1,\"p\",[[0,[],0,\"i zainstalować poleceniami\"]]],[10,72],[10,73],[1,\"h1\",[[0,[],0,\"Instalacja I3\"]]],[1,\"p\",[[0,[],0,\"Sam manager okien instaluje się poleceniem\"]]],[10,74],[1,\"p\",[[0,[],0,\"Należy do niego dodać czcionkę i pasek\"]]],[10,75],[1,\"p\",[[0,[],0,\"Instalujemy \"],[0,[0],1,\"xorg\"],[0,[],0,\".\"]]],[10,76],[1,\"p\",[[0,[],0,\"Oraz sterowniki do swojej karty. Typ karty możesz sprawdzić poleceniem \"],[0,[0],1,\"lspci | grep VGA\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Dla karty \"],[0,[0],1,\"AMD/ATI RV370 [Radeon X300]\"],[0,[],0,\" jest to\"]]],[10,77],[1,\"p\",[[0,[],0,\"Dla \"],[0,[0],1,\"nvidia\"],[0,[],0,\" będą to:\"]]],[10,78],[1,\"p\",[[0,[],0,\"Dla \"],[0,[0],1,\"Atom Processor Integrated Graphics Controller\"],[0,[],0,\" jest to\"]]],[10,79],[1,\"p\",[[0,[],0,\"Jeśli nie wiesz jaką paczkę zainstalować dla swojej karty polecam poszukać na stronie:\"]]],[10,80],[1,\"p\",[[0,[],0,\"Aby obsługiwać dźwięk dodajemy też \"],[0,[0],1,\"alsa-utils\"],[0,[],0,\", \"],[0,[0],1,\"pulseaudio\"],[0,[],0,\" i \"],[0,[0],1,\"pavucontrol\"]]],[10,81],[1,\"p\",[[0,[],0,\"Edytujemy plik\"]]],[10,82],[1,\"p\",[[0,[],0,\"komentując linie\"]]],[10,83],[1,\"p\",[[0,[],0,\"i dodając na końcu\"]]],[10,84],[1,\"p\",[[0,[],0,\"teraz możemy włączyć tryb graficzny wpisując\"]]],[10,85],[10,86],[1,\"p\",[[0,[],0,\"Potwierdzamy wygenerowanie konfiguracji przez \"],[0,[0],1,\"ENTER\"],[0,[],0,\" oraz potwierdzamy klawisz \"],[0,[0],1,\"win\"],[0,[],0,\" jako główny klawisz.\"]]],[1,\"h2\",[[0,[],0,\"Konfiguracja I3 i rxvt-unicode\"]]],[1,\"p\",[[0,[],0,\"Wartościowe wprowadzenie do \"],[0,[0],1,\"i3\"],[0,[],0,\" nagrał \"],[0,[0],1,\"Distroverse\"],[0,[],0,\":\"]]],[10,87],[1,\"p\",[[0,[],0,\"Wzorowałem się na nim tworząc swoją konfigurację. Znajdziesz ją w repozytorium\"]]],[10,88],[1,\"p\",[[0,[],0,\"ale polecam Ci przejrzeć kilka różnych konfiguracji i poczytać dokumentację i3, która jest jedną z lepszych dokumentacji managerów okien.\"]]],[1,\"p\",[[0,[],0,\"Tym czasem zajmiemy się samym terminalem \"],[0,[0],1,\"urxt-unicode\"],[0,[],0,\". Polecam Ci to video\"]]],[10,89],[1,\"p\",[[0,[],0,\"Przechodzimy do katalogu domowego\"]]],[10,90],[1,\"p\",[[0,[],0,\"Tworzymy konfigurację\"]]],[10,91],[1,\"p\",[[0,[],0,\"możemy wkleić do tego pliku jedną z gotowych konfiguracji\"]]],[10,92],[1,\"p\",[[0,[],0,\"lecz ja polecam poczytać kilka różnych zestawień lub obejrzeć filmy wyjaśniające dokładnie możliwe opcje i dobrać z nich te, które są najlepsze dla nas.\"]]],[1,\"p\",[[0,[],0,\"Do przeładowania konfiguracji służy komenda\"]]],[10,93],[1,\"h3\",[[0,[],0,\"Przeglądarka\"]]],[1,\"p\",[[0,[],0,\"Instalujemy przeglądarkę, której wybór ponownie jest Twoim wyborem. W przypadku najpopularniejszej przeglądarki - google chrome jest to:\"]]],[10,94],[1,\"p\",[[0,[],0,\"Pierwszy dodatkiem jest \"],[0,[0],1,\"Ublock Origin\"],[0,[],0,\".\"]]],[1,\"h3\",[[0,[],0,\"Polski układ klawiatury w X11\"]]],[1,\"p\",[[0,[],0,\"Aby używać polskich znaków w środowisku graficznym ustaw layout klawiatury wstawiając do pliku \"],[0,[0],1,\"/usr/share/X11/xorg.conf.d/10-keyboard.conf\"],[0,[],0,\" konfigurację\"]]],[10,95],[1,\"h3\",[[0,[],0,\"Launcher\"]]],[1,\"p\",[[0,[],0,\"Najprostszy launcher to \"],[0,[0],1,\"dmenu\"],[0,[],0,\". Instalujemy go komendą\"]]],[10,96],[1,\"p\",[[0,[],0,\"i używamy przez kombinację klawiszy \"],[0,[0],1,\"super+d\"]]],[1,\"h3\",[[0,[],0,\"Screenshoty\"]]],[1,\"p\",[[0,[],0,\"Według mnie najlepszy jest \"],[0,[0],1,\"flameshot\"],[0,[],0,\". Instalujemy go komendą\"]]],[10,97],[1,\"p\",[[0,[],0,\"W konfiguracji \"],[0,[0],1,\"i3\"],[0,[],0,\" możemy połączyć go z przyciskiem \"],[0,[0],1,\"print screen\"]]],[10,98],[1,\"h3\",[[0,[],0,\"Sterowanie innymi komputerami\"]]],[1,\"p\",[[0,[],0,\"Jeśli używamy kilku komputerów i chcemy sterować nimi używając jednej myszki i klawiatury na wszystkich komputerach możemy zainstalować \"],[0,[0],1,\"barrier\"],[0,[],0,\".\"]]],[10,99],[1,\"p\",[[0,[],0,\"Na urządzeniu klienckim ustawiamy id serwera:\"]]],[10,100],[1,\"p\",[[0,[],0,\"A na serwerze:\"]]],[10,101],[1,\"p\",[[0,[],0,\"Wskazujemy gdzie względem naszego komputera ustawi się klient\"]]],[10,102],[1,\"p\",[[0,[],0,\"W przypadku problemów z zestawieniem połączenia zawsze pomagało wyłączenie i włączeniu obu komputerów.\"]]],[1,\"h3\",[[0,[],0,\"Oh my zsh\"]]],[1,\"p\",[[0,[],0,\"Zsh jest powłoką alternatywną do \"],[0,[0],1,\"bash\"],[0,[],0,\" o więszych możliwościach customizacji i rozszerzania. Instalujemy ją poleceniem:\"]]],[10,103],[1,\"p\",[[0,[],0,\"Następnie instalujemy \"],[0,[0],1,\"oh my zsh\"],[0,[],0,\".\"]]],[10,104],[1,\"h3\",[[0,[],0,\"Tapeta\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od sprawdzenia rozdzielczości monitorów poleceniem\"]]],[10,105],[1,\"p\",[[0,[],0,\"Pobieramy tapetę w odpowiednim rozmiarze i zapisujemy ją do pliku\"]]],[10,106],[1,\"p\",[[0,[],0,\"Instalujemy \"],[0,[0],1,\"feh\"],[0,[],0,\" komendą\"]]],[10,107],[1,\"p\",[[0,[],0,\"Do pliku \"],[0,[0],1,\".fehbg\"],[0,[],0,\" zapisujemy skrypt ustawiający tapetę\"]]],[10,108],[1,\"p\",[[0,[],0,\"Dajemy mu prawa do uruchamiania\"]]],[10,109],[1,\"p\",[[0,[],0,\"w \"],[0,[0],1,\".config/i3/config\"],[0,[],0,\" włączamy go poleceniem\"]]],[10,110],[1,\"h3\",[[0,[],0,\"Neovim\"]]],[1,\"p\",[[0,[],0,\"Odrobinkę wygodniejsza wersja \"],[0,[0],1,\"vim\"],[0,[],0,\".\"]]],[10,111],[1,\"h3\",[[0,[],0,\"Synchronizacja zegara systemowego\"]]],[1,\"p\",[[0,[],0,\"Jeśli w dacie lub godzinie pojawia się rozbieżność warto włączyć synchronizację z serwerami wskazującymi poprawny czas.\"]]],[10,112],[1,\"h3\",[[0,[],0,\"Monitoring zasobów\"]]],[1,\"p\",[[0,[],0,\"Do sprawdzania użycia i temperatury procesora, zajętej pamięci operacyjnej, transferu sieci - czyli ogólnego monitoringu polecam \"],[0,[0],1,\"bashtop\"],[0,[],0,\".\"]]],[10,113],[10,114],[1,\"h3\",[[0,[],0,\"Display Manager\"]]],[1,\"p\",[[0,[],0,\"Program w którym wybieram typ sesji oraz podaję login i hasło to \"],[0,[0],1,\"ly\"],[0,[],0,\".\"]]],[10,115],[10,116],[1,\"h3\",[[0,[],0,\"Tmux i Tmuxinator\"]]],[1,\"p\",[[0,[],0,\"Do zarządzania sesjami, oknami i podziałem okien w terminalu używam tmuxa.\"]]],[10,117],[1,\"p\",[[0,[],0,\"Jego konfiguracja:\"]]],[10,118],[10,119],[1,\"h3\",[[0,[],0,\"Bitwarden\"]]],[1,\"p\",[[0,[],0,\"Do zarządzania hasłami używałem keeweb. Obecnie korzystam z bitwarden:\"]]],[10,120],[1,\"p\",[[0,[],0,\"za zarządzanie jego widocznością odpowiada następująca konfiguracja w pliku \"],[0,[0],1,\"~/.config/i3/config\"],[0,[],0,\":\"]]],[10,121],[10,122],[1,\"h2\",[[0,[],0,\"Nasz Arch Linux z i3 jest gotowy \"]]],[1,\"p\",[[0,[],0,\"Wciąż do efektywnej pracy może brakować nam \"],[0,[0],1,\"IDE\"],[0,[],0,\" jeśli jesteśmy programistami lub \"],[0,[0],1,\"obs\"],[0,[],0,\" jeśli nagrywamy video albo programów do obróbki grafiki. Jednak sam system i podstawowe programy możemy uznać za gotowe.\"]]],[1,\"p\",[[0,[],0,\"Jeśli twoim zdaniem w zestawieniu zabrakło jakichś programów, albo widzisz miejsca gdzie mógł być coś uprościć daj znać w komentarzu.\"]]],[10,123]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Arch Linux jest systemem, który kocham za elastyczność i wygodę użytkowania. Jego instalacja uchodzi za jedną z trudniejszych, ponieważ przenosi na nas ciężar decydowania o wielu szczegółach, którymi nie przejmujemy się podczas codziennej pracy z komputerem. </p><p>Za przykład niech posłuży wybór klienta DHCP, dzięki któremu możemy dostać adres IP, maskę podsieci, adres bramy domyślnej i adresy serwerów DNS. Są dwa dostępne programy do obsługi protokołu DHCP. Od Ciebie zależy, który z nich zainstalujesz:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://wiki.archlinux.org/title/Network_configuration_(Polski)#DHCP\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Network configuration (Polski) - ArchWiki</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://wiki.archlinux.org/favicon.ico\"><span class=\"kg-bookmark-author\">ArchWiki</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://wiki.archlinux.org/images/3/38/Tango-view-fullscreen.png\"></div></a></figure><p>Tego typu decyzji podejmujemy przy instalacji arch linux więcej, dlatego najlepszym źródłem wiedzy będzie zawsze ArchWiki. Ten artykuł ma na celu pokazanie mojej instalacji, którą możesz powtórzyć w całości lub wybrać z niej wartościowe dla Ciebie elementy i wkomponować je we własną pasującą do Ciebie instalację.</p><p>Instalacja zostanie pokazana zarówno na komputerze z UEFI jak i BIOS. </p><p>Kolejno omówimy:</p><ol><li>Podłączenie do sieci wifi</li><li>Instalację systemu</li><li>Instalację managera okien <code>i3-gaps</code></li><li>Konfigurację <code>i3</code> i podstawowych programów</li></ol><p>Rdzeń instalacji przedstawia poniższa grafika, ale niektóre komendy będą się u nas różnić.</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"__GHOST_URL__/content/images/2021/10/Hokk8sK.jpeg\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"986\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/10/Hokk8sK.jpeg 600w, __GHOST_URL__/content/images/size/w1000/2021/10/Hokk8sK.jpeg 1000w, __GHOST_URL__/content/images/size/w1600/2021/10/Hokk8sK.jpeg 1600w, __GHOST_URL__/content/images/2021/10/Hokk8sK.jpeg 2170w\"></figure><h2 id=\"przygotowanie-bootowalnego-pendrive\">Przygotowanie bootowalnego pendrive</h2><p>Obraz ISO Archa możemy pobrać z torrentów: </p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://archlinux.org/download/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Arch Linux - Downloads</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://archlinux.org/static/logos/apple-touch-icon-144x144.38cf584757c3.png\"><span class=\"kg-bookmark-author\">Downloads</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://archlinux.org/static/magnet.29ed728b8ae4.png\"></div></a></figure><p>Jednak ponieważ płyty CD nie są już używane, domyślnym działaniem jest wgranie go na USB. Żeby to zrobić wkładamy pendrive do komputera i sprawdzamy jaką nazwę dostał jednym z poleceń <code>dmesg | grep Attached</code>, <code>df -h</code> lub <code>lsblk</code>.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/08/Screenshot-from-2021-08-20-09-23-06.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"837\" height=\"437\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/08/Screenshot-from-2021-08-20-09-23-06.png 600w, __GHOST_URL__/content/images/2021/08/Screenshot-from-2021-08-20-09-23-06.png 837w\" sizes=\"(min-width: 720px) 720px\"></figure><p>W naszym przypadku jest to <code>sde</code>. Odmontowujemy pendrive komedą:</p><pre><code>sudo umount /dev/sde1</code></pre><p>Po czym z katalogu zawierającego obraz <code>iso</code> wgrywamy go na pendrive.</p><pre><code>sudo dd bs=8M if=arch.iso of=/dev/sde status=progress</code></pre><p>Po włożeniu pendrive do docelowej maszyny i uruchomieniu zwykle należy użyć <code>F12</code> przy starcie, ale to zależy od modelu komputera i ustawień BIOS.</p><p>Jeśli się uda powinniśmy zobaczyć:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/08/1-arch-linux.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"637\" height=\"478\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/08/1-arch-linux.jpg 600w, __GHOST_URL__/content/images/2021/08/1-arch-linux.jpg 637w\"></figure><p>Po zatwierdzeniu przez <code>ENTER</code> trafimy do konsoli instalatora</p><h2 id=\"pod%C5%82%C4%85czenie-sieci-wifi-przez-iwctl\">Podłączenie sieci wifi przez iwctl</h2><p>Nawiązanie połączenia z internetem jest naszym pierwszym zadaniem.</p><p>Zaczniemy od listy dostępnych urządzeń, wpisujemy <code>iwctl</code> a następnie <code>device list</code>.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/08/Screenshot-from-2021-08-20-09-51-53.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"503\" height=\"168\"></figure><p>Lista sieci dostępna jest po wpisaniu <code>station wlan0 get-networks</code></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/08/Screenshot-from-2021-08-20-09-54-15.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"504\" height=\"191\"></figure><p>Podłączamy się do wybranej sieci poleceniem <code>station wlan0 connect TP-Link_CEC8</code> i podajemy hasło.</p><p>W przypadku bardzo starego laptopa Acer Aspire One - miałem błąd ze sterownikami wifi i musiałem podłączyć się przez ethernet.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://superuser.com/questions/1581961/arch-linux-dual-boot-with-win-10-kernel-panic-not-syncing-fatal-exception/1582265#1582265\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Arch Linux (dual boot with Win 10). Kernel panic - not syncing: Fatal exception in interrupt. Caps Lock indicator blinking until reboot</div><div class=\"kg-bookmark-description\">On my laptop I have Arch Linux and Windows 10 installed (BIOS MBR). When I’m using Arch occasional kernel panic occurs. This happens mostly when I install some packages using pacman.Last time I st...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon.png?v&#x3D;0ad5b7a83e49\"><span class=\"kg-bookmark-author\">Super User</span><span class=\"kg-bookmark-publisher\">quantumleap</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon@2.png?v&#x3D;e869e4459439\"></div></a></figure><p>Aby wyłączyć <code>iwctl</code> wpisujemy <code>quit</code>.</p><p>Do sprawdzenia, czy mamy poprawnie nawiązane połączenie możemy użyć</p><pre><code>ping -c 3 google.com</code></pre><h1 id=\"instalacja-arch\">Instalacja Arch</h1><p>Instalujemy <code>reflector</code></p><pre><code>pacman -Sy reflector</code></pre><p>Aktualizujemy listę repozytoriów</p><pre><code>reflector -c \"Poland\" --latest 5 --sort rate --save /etc/pacman.d/mirrorlist</code></pre><p>Jeśli twój internet jest wolny dodaj falgę <code>--download-timeout</code>, np.:</p><pre><code>reflector -c \"Poland\" --latest 5 --sort rate --download-timeout 60 --save /etc/pacman.d/mirrorlist</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://bbs.archlinux.org/viewtopic.php?id&#x3D;262621\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Reflector returns “failed to rate http(s) download: Download ......” ! / Newbie Corner / Arch Linux Forums</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://bbs.archlinux.org/style/ArchLinux/favicon.ico\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://bbs.archlinux.org/img/smilies/big_smile.png\"></div></a></figure><p>Za pomocą <code>fdisk -l</code> lub <code>lsblk</code> wyświetlamy dostępne dyski</p><p>Jeśli zobaczymy błąd</p><pre><code>GPT PMBR size mismatch will be corrected by w(rite)</code></pre><p>naprawiamy go wpisując</p><pre><code>parted -l</code></pre><p>a następnie <code>fix</code>.</p><p>Partycje można poustawiać poleceniem</p><pre><code>cfdisk /dev/sda</code></pre><p>oczywiście adres dysku może u Ciebie być inny niż <code>/dev/sda</code>. Wybieramy typ <code>linux (x86)</code>.</p><p>Teraz musimy okreslicz czy instalujemy system bootawny z biosa czy przez uefi. Jesli nie wiemy sprawdzmy czy nasza plyta gowna obsluguje UEFI i jesli tak to lepiej wybrac uefi. Jesli masz nowy komputer mozesz pominac rozdzial \"BIOS\" i przejsc do \"UEFI\".</p><h3 id=\"bios\">BIOS</h3><p>Na starszych komputerach użyjemy biosa. Programem <code>cfdisk</code> lub <code>fdisk</code> mozemy ustawic:</p><ul><li>bootowalna patrycje sda1 z typem 83 Linux</li><li>nie bootowalna partycje sda2 z typem 82 Linux Swap</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/10/IMG_20211016_155428378.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1500\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/10/IMG_20211016_155428378.jpg 600w, __GHOST_URL__/content/images/size/w1000/2021/10/IMG_20211016_155428378.jpg 1000w, __GHOST_URL__/content/images/size/w1600/2021/10/IMG_20211016_155428378.jpg 1600w, __GHOST_URL__/content/images/size/w2400/2021/10/IMG_20211016_155428378.jpg 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Fortsmtujemy utworzona partycje</p><pre><code>mkfs.ext4 /dev/sda1</code></pre><p>Montujemy gotowa partycje do <code>/mnt</code></p><pre><code>mount /dev/sda1 /mnt</code></pre><p>Możemy teraz pominąć fragment \"UEFI\" i przejść do \"Pacstrap\"</p><h3 id=\"uefi\">UEFI</h3><p>W przypadku UEFI musimy przygotować tabelę GPT. Możesz użyć do tego bardziej przyjazdnego programu <code>cfdisk</code>, lub bardziej zaawansowanego <code>fdisk</code>. Poniżej pokazuję to w <code>fdisk</code>.</p><pre><code>fdisk /dev/sda</code></pre><p>wybieramy opcję <code>g</code></p><p>Tworzymy partycję <code>uefi</code> wybierając kolejno <code>n</code> (nowa), <code>ENTER</code> (nie zmieniamy punku pierwszego sektora), <code>+200M</code> (ustawiamy ostatni sektor na <code>+ 200 MB</code>.</p><p>Ustawiamy typ na <code>EFI System</code> przez <code>t</code> (jak type), <code>1</code> (numer typu <code>EFI System</code>).</p><p>Tworzymy drugą partycję <code>n</code> (new), <code>ENTER</code> (domyślny numer 2), <code>ENTER</code> (domyślny początkowy blok), <code>ENTER</code> (domyślny końcowy blok).</p><p>Zapisujemy zmiany wybierając <code>w</code>.</p><p>Formatowanie partycji UEFI na <code>fat 32</code></p><pre><code>mkfs.fat -F32 /dev/sda1</code></pre><p>Formatowanie na system plików drugiej partycji na <code>ext4</code>:</p><pre><code>mkfs.ext4 /dev/sda2</code></pre><p>Montujemy partycję na system do katalogu <code>/mnt</code>.</p><pre><code>mount /dev/sda2 /mnt</code></pre><p>A partycję na uefi do <code>/mnt/boot</code>, najpierw musimy utworzyć ten katalog</p><pre><code>mkdir /mnt/boot</code></pre><p>i teraz zamontować</p><pre><code>mount /dev/sda1 /mnt/boot</code></pre><p>Dzięki poleceniu <code>slblk</code> możemy sprawdzić, czy montowanie jest poprawne.</p><h3 id=\"pacstrap\">Pacstrap</h3><p>I instalujemy system poleceniem <code>pacstrap</code></p><pre><code>pacstrap /mnt base linux linux-firmware nano</code></pre><p>Generujemy plik <code>fstab</code>.</p><pre><code>genfstab -U /mnt &gt;&gt; /mnt/etc/fstab</code></pre><p>Wchodzimy do zainstalowanego systemu</p><pre><code>arch-chroot /mnt /bin/bash</code></pre><h3 id=\"swapfile\">Swapfile</h3><p>Przygotowujemy swap:</p><pre><code>fallocate -l 2GB /swapfile\nchmod 600 /swapfile\nmkswap /swapfile\nswapon /swapfile</code></pre><p>Do <code>/etc/fstab</code> dodajemy</p><pre><code>/swapfile none swap defaults 0 0</code></pre><h3 id=\"strefa-czasowa\">Strefa czasowa</h3><p>Ustawiamy strefę czasową</p><pre><code>ln -sf /usr/share/zoneinfo/Europe/Warsaw /etc/localtime</code></pre><p>Generujemy <code>adjtime</code> żeby zsynchronizować zegar systemowy ze sprzętowym</p><pre><code>hwclock --systohc</code></pre><h3 id=\"j%C4%99zyk\">Język</h3><p>Ustawimy lokalizację kasując komentarz jednej z linii pliku <code>locale.gen</code></p><pre><code>nano /etc/locale.gen</code></pre><p>Generujemy obsługę języków</p><pre><code>locale-gen</code></pre><p>W pliku <code>/etc/locale.conf</code> wpisujemy <code>LANG=pl_PL.UTF-8</code></p><pre><code>echo LANG=pl_PL.UTF-8 &gt; /etc/locale.conf</code></pre><p>A w <code>/etc/vconsole.conf</code></p><pre><code>KEYMAP=pl\nFONT=Lat2-Terminus16\nFONT_MAP=8859-2</code></pre><h3 id=\"sie%C4%87\">Sieć</h3><p>W <code>/etc/hostname</code> ustawiamy nazwę hosta. Jest to nazwa naszego komputera - przydatna jeśli mamy kilka urządzeń w sieci lokalnej.</p><p>W <code>/etc/hosts</code> dodajemy linie</p><pre><code>127.0.0.1    localhost.localdomain    preciselab</code></pre><p>trzecia kolumna zawiera nazwę hosta wybrana poprzednio.</p><p>Instalujemy <code>networkmanager</code>.</p><pre><code>pacman -S networkmanager dhcpcd</code></pre><p>Włączamy usługę <code>NetworkManager</code></p><pre><code>systemctl enable NetworkMananger</code></pre><h3 id=\"przydatne-paczki\">Przydatne paczki</h3><p>Jest to indywidualna decyzja, jakie jeszcze inne pakiety powinien zawierać system. Wymienię i opiszę kilka polecanych przeze mnie.</p><ul><li>network-manager-applet - frontend do zarządzania połączeniami z siecią</li><li>wireless_tools - otwarty projekt sponsorowany przez HP - zawiera narzędzia takie jak iwconfig iwlist iwspy wipriv oraz ifrename do obsługi sieci wifi</li><li>wpa_supplicant - wsparcie dla szyfrowanych wifi WEP, WPA, WPA2 and WPA3 - dzisiaj niezbędny</li><li>dialog - paczka do wyświetlania okien dialogowych ze skryptów w bashu, wymagana do używania wifi-menu</li><li>netctl - konsolowe narzędzie do zarządzania sieciami ( zawiera wifi-menu )</li><li>os-prober - narzędzie do wykrywania innych systemów operacyjnych i urządzeń, przydatne jeśli grub ich nie widzi</li><li>base-devel - zestaw paczek do kompilacji, obróbki tekstu i kompresji</li><li>linux-headers - skrypty do budowania modułów jadra systemowego</li><li>reflector - skrypt do automatyzacji wyboru serwerów lustrzanych</li><li>git - system kontroli wersji używany do programowania i instalacji pakietów</li><li>cups - rozwijany przez Apple system do obsługi drukarek</li><li>xdg-utils - narzędzia pomocnicze dla aplikacji XDG MIME</li><li>xdg-user-dirs - narzędzie do integracji katalogu użytkownika z innymi programami, w szczególności przydatne dla managerów plików</li><li>openssh - oprogramowanie do połączenia się przez ssh</li><li>iwd - narzędzie do łączenia się z siecią np przez iwctl</li></ul><p>Możemy je zainstalować poleceniem:</p><pre><code>pacman -S network-manager-applet wireless_tools wpa_supplicant dialog netctl os-prober base-devel linux-headers reflector git cups xdg-utils xdg-user-dirs openssh iwd</code></pre><p>Jeśli chcesz używać bluetooth to przydadzą Ci się jeszcze <code>bluez bluez-utils</code>.</p><p>Teraz zainstalujemy bootloader, żeby system mógł poprawnie wystartować. W zależności od tego czy wybrałeś opcje BIOS czy UEFI przejdź do odpowiedniego rozdziału.</p><h3 id=\"boot-loader-w-bios\">Boot loader w BIOS</h3><p>Instalujemy bootloader</p><pre><code>pacman -S grub</code></pre><p>używamy komendy <code>grub-install</code></p><pre><code>grub-install /dev/sda</code></pre><p>i tworzymy plik konfiguracyjny gruba</p><pre><code>grub-mkconfig -o /boot/grub/grub.cfg</code></pre><h3 id=\"boot-loader-w-uefi\">Boot loader w UEFI</h3><p>Instalujemy bootloader</p><pre><code>pacman -S grub efibootmgr</code></pre><p>używamy komendy <code>grub-install</code></p><pre><code>grub-install --target=x86_64-efi --efi-direcotry=/boot --bootloader-id=GRUB</code></pre><p>w przypadku błędu</p><blockquote>this GPT partition label contains no BIOS Boot Partition</blockquote><p>naprawiamy poleceniem</p><pre><code>parted /dev/sda\nset 1 boot off\nset 1 bios_grub on\nq</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://superuser.com/a/1610045/1216455\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">grub2-install: “this GPT partition label contains no BIOS Boot Partition”</div><div class=\"kg-bookmark-description\">There seems to be quite a bit of discussion about this but I can’t find a simple answer. When I try to install grub2 I get this error: # grub2-install /dev/sdaInstalling for i386-pc platform.gr...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon.png?v&#x3D;0ad5b7a83e49\"><span class=\"kg-bookmark-author\">Super User</span><span class=\"kg-bookmark-publisher\">Robert S</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/superuser/Img/apple-touch-icon@2.png?v&#x3D;e869e4459439\"></div></a></figure><p>W przypadku błędu</p><blockquote>\"EFI variables are not supported on this system\"</blockquote><p>wychodzimy z <code>chroot</code> przez <code>exit</code> i wpisujemy</p><pre><code>modprobe efivars</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://unix.stackexchange.com/a/91623/431667\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">“EFI variables are not supported on this system”</div><div class=\"kg-bookmark-description\">I am attempting to install Arch linux to a new (and very crappy) HP Pavillion 15 Notebook. This is a UEFI-based machine. After several swings at it, I have managed to get pretty far. Legacy mode...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon.png?v&#x3D;5cf7fe716a89\"><span class=\"kg-bookmark-author\">Unix &amp; Linux Stack Exchange</span><span class=\"kg-bookmark-publisher\">John Dibling</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon@2.png?v&#x3D;32fb07f7ce26\"></div></a></figure><p>Jeśli zobaczymy błąd</p><blockquote>Module efivars not found in directory /lib/modules/5.10.3-arch1-1</blockquote><p>musimy włączyć komputer ponownie w trybie efi. Jest tak dlatego, że cześć maszyn może wybierać czy włącza się w trybie bios czy efi.</p><p>Dokumentacja mówi, że możemy sprawdzić czy to działa wpisując:</p><pre><code>efivar-tester</code></pre><p>ale nie polecam tej metody, u mnie zapętla się w nieskończoność i nie da się tego wyłączyć inaczej niż sprzętowo wyłączając komputer.</p><p>Tworzymy plik konfiguracyjny dla gruba</p><pre><code>grub-mkconfig -o /boot/grub/grub.cfg</code></pre><h3 id=\"u%C5%BCytkownicy\">Użytkownicy</h3><p>Aby na co dzień moc poslugiwac sie systemem bez uprawnień roota a jednocześnie móc szybko nabywać, zainstalujemy sudo</p><pre><code>pacman -S sudo</code></pre><p>Ustawiamy hasło dla <code>root</code></p><pre><code>passwd root</code></pre><p>Dodajemy użytkownika do codziennego użytku</p><pre><code>useradd -m -g users -G wheel -s /bin/bash daniel</code></pre><p>Dajemy mu hasło</p><pre><code>passwd daniel</code></pre><p>Grupie <code>wheel</code> pozwalamy na używanie <code>sudo</code>.</p><pre><code>EDITOR=nano visudo</code></pre><p>kasujemy komentarz przed linią</p><pre><code>%wheel ALL=(ALL) ALL</code></pre><p>Wychodzimy z instalatora</p><pre><code>exit</code></pre><p>Odmontowujemy partycję</p><pre><code>umount /mnt</code></pre><p>Wyłączamy komputer</p><pre><code>shutdown -P now</code></pre><h3 id=\"problemy-sieciowe\">Problemy sieciowe</h3><p>Jeśli po wpisaniu</p><pre><code>ip addr</code></pre><p>interfejsy są wyłączone to można je włączyć przez</p><pre><code>ip link set dev &lt;interface&gt; up</code></pre><p>Do sprawdzenia, które interfejsy warto włączyć przydatne może być <code>nmcli</code>.</p><p>Jeśli nie możesz włączyć interfejsu, ale znasz nazwę i hasło sieci możesz spróbować bezpośredniego połączenia podążając za zaleceniami z linku:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://unix.stackexchange.com/a/613819/431667\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">how do I attach devices to connections using nmcli?</div><div class=\"kg-bookmark-description\">An installation of CentOS 7 has two connections and three devices. How can I attach the device ens7 to the connection my-bridge? And how can I attach the device eth0 to the connection my-eth1? ...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon.png?v&#x3D;5cf7fe716a89\"><span class=\"kg-bookmark-author\">Unix &amp; Linux Stack Exchange</span><span class=\"kg-bookmark-publisher\">CodeMed</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sstatic.net/Sites/unix/Img/apple-touch-icon@2.png?v&#x3D;32fb07f7ce26\"></div></a></figure><p>nie mam pojęcia dlaczego to działa.</p><p>Jeśli tłumaczenie nazw domen na adresy ip, nie działa poprawnie musimy wybrać domyślny DNS. Ustawiamy to w</p><pre><code>/etc/resolv.conf</code></pre><p>wpisując</p><pre><code>nameserver 8.8.8.8</code></pre><p>Stan serwisu odpowiadającego za nadawanie domenom numerów ip sprawdzimy poleceniem</p><pre><code>systemctl status systemd-resolved.service</code></pre><h3 id=\"b%C5%82%C4%99dy-z-kluczami\">Błędy z kluczami</h3><p>Jeśli mamy błędy typu</p><blockquote>Signature is unknown trust</blockquote><p>Możemy sprawdzić dany klucz</p><pre><code>pacman-key -l Thorsten</code></pre><p>i jeśli wygasł, to odświeżyć listę kluczy</p><pre><code>pacman-key --refresh-keys</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://bbs.archlinux.org/viewtopic.php?id&#x3D;207957\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Signature is unknown trust [SOLVED] / Pacman &amp; Package Upgrade Issues / Arch Linux Forums</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://bbs.archlinux.org/style/ArchLinux/favicon.ico\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://bbs.archlinux.org/img/avatars/27289.jpg?m&#x3D;1572193439\"></div></a></figure><h3 id=\"instalacja-yay\">Instalacja yay</h3><p>Yay jest pomocniczym programem do zarządzania zależnościami. Jeśli zainstalowałeś <code>base-devel</code> możesz pobrać yay za pomocą gita</p><pre><code>git clone https://aur.archlinux.org/yay.git</code></pre><p>i zainstalować poleceniami</p><pre><code>cd yay &amp;&amp; makepkg -si</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://low-orbit.net/arch-linux-how-to-install-yay\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Arch Linux How to Install Yay - Super EASY | Low Orbit Flux</div><div class=\"kg-bookmark-description\">Arch Linux How to Install Yay - Super EASY | Low Orbit Flux</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://low-orbit.net/favicon.png\"><span class=\"kg-bookmark-author\">Low Orbit Flux</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://low-orbit.net/low-orbit-logo-2-d.png\"></div></a></figure><h1 id=\"instalacja-i3\">Instalacja I3</h1><p>Sam manager okien instaluje się poleceniem</p><pre><code>yay -S i3-gaps</code></pre><p>Należy do niego dodać czcionkę i pasek</p><pre><code>yay -S ttf-dejavu i3status</code></pre><p>Instalujemy <code>xorg</code>.</p><pre><code>yay -S xorg xorg-xinit rxvt-unicode</code></pre><p>Oraz sterowniki do swojej karty. Typ karty możesz sprawdzić poleceniem <code>lspci | grep VGA</code>.</p><p>Dla karty <code>AMD/ATI RV370 [Radeon X300]</code> jest to</p><pre><code>yay -S xf86-video-ati</code></pre><p>Dla <code>nvidia</code> będą to:</p><pre><code>yay -S nvidia nvidia-utils</code></pre><p>Dla <code>Atom Processor Integrated Graphics Controller</code> jest to</p><pre><code>yay -S xf86-video-intel</code></pre><p>Jeśli nie wiesz jaką paczkę zainstalować dla swojej karty polecam poszukać na stronie:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://wiki.archlinux.org/title/xorg\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Xorg - ArchWiki</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://wiki.archlinux.org/favicon.ico\"><span class=\"kg-bookmark-author\">ArchWiki</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://wiki.archlinux.org/images/d/d6/Tango-inaccurate.png\"></div></a></figure><p>Aby obsługiwać dźwięk dodajemy też <code>alsa-utils</code>, <code>pulseaudio</code> i <code>pavucontrol</code></p><pre><code>yay -S alsa-utils pulseaudio pavucontrol\nspeaker-test -c2\nalsamixer</code></pre><p>Edytujemy plik</p><pre><code>nano /etc/X11/xinit/xinitrc</code></pre><p>komentując linie</p><pre><code>#twm &amp;\n#exec xterm ....</code></pre><p>i dodając na końcu</p><pre><code>exec i3</code></pre><p>teraz możemy włączyć tryb graficzny wpisując</p><pre><code>startx</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://low-orbit.net/arch-linux-how-to-install-i3-gaps\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Arch Linux How to Install i3 Gaps - Super EASY | Low Orbit Flux</div><div class=\"kg-bookmark-description\">Arch Linux How to Install i3 Gaps - Super EASY | Low Orbit Flux</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://low-orbit.net/favicon.png\"><span class=\"kg-bookmark-author\">Low Orbit Flux</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://low-orbit.net/low-orbit-logo-2-d.png\"></div></a></figure><p>Potwierdzamy wygenerowanie konfiguracji przez <code>ENTER</code> oraz potwierdzamy klawisz <code>win</code> jako główny klawisz.</p><h2 id=\"konfiguracja-i3-i-rxvt-unicode\">Konfiguracja I3 i rxvt-unicode</h2><p>Wartościowe wprowadzenie do <code>i3</code> nagrał <code>Distroverse</code>:</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/le_Z6l-NPeo?start=486&feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p>Wzorowałem się na nim tworząc swoją konfigurację. Znajdziesz ją w repozytorium</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/gustawdaniel/my-arch-i3-config/blob/main/.config/i3/config\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">my-arch-i3-config/config at main · gustawdaniel/my-arch-i3-config</div><div class=\"kg-bookmark-description\">Contribute to gustawdaniel/my-arch-i3-config development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">gustawdaniel</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/c7e9ab912b1bb2522df5792cd3bf38216fc9c7e33d89de79f8f0dd67df2a6c22/gustawdaniel/my-arch-i3-config\"></div></a></figure><p>ale polecam Ci przejrzeć kilka różnych konfiguracji i poczytać dokumentację i3, która jest jedną z lepszych dokumentacji managerów okien.</p><p>Tym czasem zajmiemy się samym terminalem <code>urxt-unicode</code>. Polecam Ci to video</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/_kjbj-Ez1vU?start=381&feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p>Przechodzimy do katalogu domowego</p><pre><code>cd ~</code></pre><p>Tworzymy konfigurację</p><pre><code>touch .Xresources</code></pre><p>możemy wkleić do tego pliku jedną z gotowych konfiguracji</p><pre><code>curl https://raw.githubusercontent.com/gustawdaniel/my-arch-i3-config/main/.Xresources &gt; .Xresources</code></pre><p>lecz ja polecam poczytać kilka różnych zestawień lub obejrzeć filmy wyjaśniające dokładnie możliwe opcje i dobrać z nich te, które są najlepsze dla nas.</p><p>Do przeładowania konfiguracji służy komenda</p><pre><code>xrdb ~/.Xresources</code></pre><h3 id=\"przegl%C4%85darka\">Przeglądarka</h3><p>Instalujemy przeglądarkę, której wybór ponownie jest Twoim wyborem. W przypadku najpopularniejszej przeglądarki - google chrome jest to:</p><pre><code>yay -S google-chrome</code></pre><p>Pierwszy dodatkiem jest <code>Ublock Origin</code>.</p><h3 id=\"polski-uk%C5%82ad-klawiatury-w-x11\">Polski układ klawiatury w X11</h3><p>Aby używać polskich znaków w środowisku graficznym ustaw layout klawiatury wstawiając do pliku <code>/usr/share/X11/xorg.conf.d/10-keyboard.conf</code> konfigurację</p><pre><code>Section \"InputClass\"\n    Identifier \"system-keyboard\"\n    MatchIsKeyboard \"on\"\n    Option \"XkbLayout\" \"pl\"\nEndSection</code></pre><h3 id=\"launcher\">Launcher</h3><p>Najprostszy launcher to <code>dmenu</code>. Instalujemy go komendą</p><pre><code>yay -S dmenu</code></pre><p>i używamy przez kombinację klawiszy <code>super+d</code></p><h3 id=\"screenshoty\">Screenshoty</h3><p>Według mnie najlepszy jest <code>flameshot</code>. Instalujemy go komendą</p><pre><code>yay -S flameshot</code></pre><p>W konfiguracji <code>i3</code> możemy połączyć go z przyciskiem <code>print screen</code></p><pre><code>bindsym Print exec flameshot gui</code></pre><h3 id=\"sterowanie-innymi-komputerami\">Sterowanie innymi komputerami</h3><p>Jeśli używamy kilku komputerów i chcemy sterować nimi używając jednej myszki i klawiatury na wszystkich komputerach możemy zainstalować <code>barrier</code>.</p><pre><code>yay -S barrier</code></pre><p>Na urządzeniu klienckim ustawiamy id serwera:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/10/2021-10-16_23-25.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"736\" height=\"421\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/10/2021-10-16_23-25.png 600w, __GHOST_URL__/content/images/2021/10/2021-10-16_23-25.png 736w\" sizes=\"(min-width: 720px) 720px\"></figure><p>A na serwerze:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/10/2021-10-13_00-04.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"748\" height=\"428\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/10/2021-10-13_00-04.png 600w, __GHOST_URL__/content/images/2021/10/2021-10-13_00-04.png 748w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Wskazujemy gdzie względem naszego komputera ustawi się klient</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/10/2021-10-13_00-04_1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"852\" height=\"571\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/10/2021-10-13_00-04_1.png 600w, __GHOST_URL__/content/images/2021/10/2021-10-13_00-04_1.png 852w\" sizes=\"(min-width: 720px) 720px\"></figure><p>W przypadku problemów z zestawieniem połączenia zawsze pomagało wyłączenie i włączeniu obu komputerów.</p><h3 id=\"oh-my-zsh\">Oh my zsh</h3><p>Zsh jest powłoką alternatywną do <code>bash</code> o więszych możliwościach customizacji i rozszerzania. Instalujemy ją poleceniem:</p><pre><code>yay -S zsh</code></pre><p>Następnie instalujemy <code>oh my zsh</code>.</p><pre><code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"</code></pre><h3 id=\"tapeta\">Tapeta</h3><p>Zaczniemy od sprawdzenia rozdzielczości monitorów poleceniem</p><pre><code> xrandr --listmonitors</code></pre><p>Pobieramy tapetę w odpowiednim rozmiarze i zapisujemy ją do pliku</p><pre><code>.config/i3/.bg.jpeg</code></pre><p>Instalujemy <code>feh</code> komendą</p><pre><code>yay -S feh</code></pre><p>Do pliku <code>.fehbg</code> zapisujemy skrypt ustawiający tapetę</p><pre><code>#!/bin/sh\nfeh --no-fehbg --bg-scale '/home/daniel/.config/i3/.bg.jpeg'</code></pre><p>Dajemy mu prawa do uruchamiania</p><pre><code>sudo chmod +x ~/.fehbg</code></pre><p>w <code>.config/i3/config</code> włączamy go poleceniem</p><pre><code>exec --no-startup-id sh ~/.fehbg</code></pre><h3 id=\"neovim\">Neovim</h3><p>Odrobinkę wygodniejsza wersja <code>vim</code>.</p><pre><code>yay -S neovim</code></pre><h3 id=\"synchronizacja-zegara-systemowego\">Synchronizacja zegara systemowego</h3><p>Jeśli w dacie lub godzinie pojawia się rozbieżność warto włączyć synchronizację z serwerami wskazującymi poprawny czas.</p><pre><code>sudo timedatectl set-ntp true </code></pre><h3 id=\"monitoring-zasob%C3%B3w\">Monitoring zasobów</h3><p>Do sprawdzania użycia i temperatury procesora, zajętej pamięci operacyjnej, transferu sieci - czyli ogólnego monitoringu polecam <code>bashtop</code>.</p><pre><code>yay -S bashtop</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/10/2021-10-17_00-54.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1868\" height=\"1132\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/10/2021-10-17_00-54.png 600w, __GHOST_URL__/content/images/size/w1000/2021/10/2021-10-17_00-54.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/10/2021-10-17_00-54.png 1600w, __GHOST_URL__/content/images/2021/10/2021-10-17_00-54.png 1868w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"display-manager\">Display Manager</h3><p>Program w którym wybieram typ sesji oraz podaję login i hasło to <code>ly</code>.</p><pre><code>yay -S ly\nsudo systemctl enable ly.service</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/10/88958888-65efbf80-d2a1-11ea-8ae5-3f263bce9cce.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1014\" height=\"700\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/10/88958888-65efbf80-d2a1-11ea-8ae5-3f263bce9cce.png 600w, __GHOST_URL__/content/images/size/w1000/2021/10/88958888-65efbf80-d2a1-11ea-8ae5-3f263bce9cce.png 1000w, __GHOST_URL__/content/images/2021/10/88958888-65efbf80-d2a1-11ea-8ae5-3f263bce9cce.png 1014w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"tmux-i-tmuxinator\">Tmux i Tmuxinator</h3><p>Do zarządzania sesjami, oknami i podziałem okien w terminalu używam tmuxa.</p><pre><code>yay -S tmux ruby\ngem install tmuxinator</code></pre><p>Jego konfiguracja:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/gustawdaniel/my-arch-i3-config/blob/main/.tmux.conf\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">my-arch-i3-config/.tmux.conf at main · gustawdaniel/my-arch-i3-config</div><div class=\"kg-bookmark-description\">Contribute to gustawdaniel/my-arch-i3-config development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">gustawdaniel</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/329bf602abfbb3c32fc70733557d3fb9f40c7171acdb51064027ff062f032e06/gustawdaniel/my-arch-i3-config\"></div></a></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/10/2021-10-22_01-27.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1181\" height=\"629\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/10/2021-10-22_01-27.png 600w, __GHOST_URL__/content/images/size/w1000/2021/10/2021-10-22_01-27.png 1000w, __GHOST_URL__/content/images/2021/10/2021-10-22_01-27.png 1181w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"bitwarden\">Bitwarden</h3><p>Do zarządzania hasłami używałem keeweb. Obecnie korzystam z bitwarden:</p><pre><code>yay -S bitwardern</code></pre><p>za zarządzanie jego widocznością odpowiada następująca konfiguracja w pliku <code>~/.config/i3/config</code>:</p><pre><code>exec --no-startup-id bitwarden\nbindsym $Mod+k [instance=\"bitwarden\"] scratchpad show; [instance=\"bitwarden\"] move position center\nfor_window [instance=\"bitwarden\"] move scratchpad\nfor_window [instance=\"bitwarden\"] border pixel 3\nfor_window [instance=\"bitwarden\"] resize set 800 600</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/10/2021-10-22_01-26.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1186\" height=\"815\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/10/2021-10-22_01-26.png 600w, __GHOST_URL__/content/images/size/w1000/2021/10/2021-10-22_01-26.png 1000w, __GHOST_URL__/content/images/2021/10/2021-10-22_01-26.png 1186w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"nasz-arch-linux-z-i3-jest-gotowy\">Nasz Arch Linux z i3 jest gotowy </h2><p>Wciąż do efektywnej pracy może brakować nam <code>IDE</code> jeśli jesteśmy programistami lub <code>obs</code> jeśli nagrywamy video albo programów do obróbki grafiki. Jednak sam system i podstawowe programy możemy uznać za gotowe.</p><p>Jeśli twoim zdaniem w zestawieniu zabrakło jakichś programów, albo widzisz miejsca gdzie mógł być coś uprościć daj znać w komentarzu.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/10/x4akxjcv21e31-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"566\"></figure>",
            "comment_id": "611f504250caaa182e07eec0",
            "plaintext": "Arch Linux jest systemem, który kocham za elastyczność i wygodę użytkowania.\nJego instalacja uchodzi za jedną z trudniejszych, ponieważ przenosi na nas\nciężar decydowania o wielu szczegółach, którymi nie przejmujemy się podczas\ncodziennej pracy z komputerem. \n\nZa przykład niech posłuży wybór klienta DHCP, dzięki któremu możemy dostać adres\nIP, maskę podsieci, adres bramy domyślnej i adresy serwerów DNS. Są dwa dostępne\nprogramy do obsługi protokołu DHCP. Od Ciebie zależy, który z nich\nzainstalujesz:\n\nNetwork configuration (Polski) - ArchWikiArchWiki\n[https://wiki.archlinux.org/title/Network_configuration_(Polski)#DHCP]Tego typu\ndecyzji podejmujemy przy instalacji arch linux więcej, dlatego najlepszym\nźródłem wiedzy będzie zawsze ArchWiki. Ten artykuł ma na celu pokazanie mojej\ninstalacji, którą możesz powtórzyć w całości lub wybrać z niej wartościowe dla\nCiebie elementy i wkomponować je we własną pasującą do Ciebie instalację.\n\nInstalacja zostanie pokazana zarówno na komputerze z UEFI jak i BIOS. \n\nKolejno omówimy:\n\n 1. Podłączenie do sieci wifi\n 2. Instalację systemu\n 3. Instalację managera okien i3-gaps\n 4. Konfigurację i3 i podstawowych programów\n\nRdzeń instalacji przedstawia poniższa grafika, ale niektóre komendy będą się u\nnas różnić.\n\nPrzygotowanie bootowalnego pendrive\nObraz ISO Archa możemy pobrać z torrentów: \n\nArch Linux - DownloadsDownloads [https://archlinux.org/download/]Jednak ponieważ\npłyty CD nie są już używane, domyślnym działaniem jest wgranie go na USB. Żeby\nto zrobić wkładamy pendrive do komputera i sprawdzamy jaką nazwę dostał jednym z\npoleceń dmesg | grep Attached, df -h lub lsblk.\n\nW naszym przypadku jest to sde. Odmontowujemy pendrive komedą:\n\nsudo umount /dev/sde1\n\nPo czym z katalogu zawierającego obraz iso wgrywamy go na pendrive.\n\nsudo dd bs=8M if=arch.iso of=/dev/sde status=progress\n\nPo włożeniu pendrive do docelowej maszyny i uruchomieniu zwykle należy użyć F12 \nprzy starcie, ale to zależy od modelu komputera i ustawień BIOS.\n\nJeśli się uda powinniśmy zobaczyć:\n\nPo zatwierdzeniu przez ENTER trafimy do konsoli instalatora\n\nPodłączenie sieci wifi przez iwctl\nNawiązanie połączenia z internetem jest naszym pierwszym zadaniem.\n\nZaczniemy od listy dostępnych urządzeń, wpisujemy iwctl a następnie device list.\n\nLista sieci dostępna jest po wpisaniu station wlan0 get-networks\n\nPodłączamy się do wybranej sieci poleceniem station wlan0 connect TP-Link_CEC8 i\npodajemy hasło.\n\nW przypadku bardzo starego laptopa Acer Aspire One - miałem błąd ze sterownikami\nwifi i musiałem podłączyć się przez ethernet.\n\nArch Linux (dual boot with Win 10). Kernel panic - not syncing: Fatal exception\nin interrupt. Caps Lock indicator blinking until rebootOn my laptop I have Arch\nLinux and Windows 10 installed (BIOS MBR). When I’m using Arch occasional\nkernel\npanic occurs. This happens mostly when I install some packages using\npacman.Last\ntime I st...Super Userquantumleap\n[https://superuser.com/questions/1581961/arch-linux-dual-boot-with-win-10-kernel-panic-not-syncing-fatal-exception/1582265#1582265]\nAby wyłączyć iwctl wpisujemy quit.\n\nDo sprawdzenia, czy mamy poprawnie nawiązane połączenie możemy użyć\n\nping -c 3 google.com\n\nInstalacja Arch\nInstalujemy reflector\n\npacman -Sy reflector\n\nAktualizujemy listę repozytoriów\n\nreflector -c \"Poland\" --latest 5 --sort rate --save /etc/pacman.d/mirrorlist\n\nJeśli twój internet jest wolny dodaj falgę --download-timeout, np.:\n\nreflector -c \"Poland\" --latest 5 --sort rate --download-timeout 60 --save /etc/pacman.d/mirrorlist\n\nReflector returns “failed to rate http(s) download: Download ......” ! / Newbie\nCorner / Arch Linux Forums [https://bbs.archlinux.org/viewtopic.php?id=262621]Za\npomocą fdisk -l lub lsblk wyświetlamy dostępne dyski\n\nJeśli zobaczymy błąd\n\nGPT PMBR size mismatch will be corrected by w(rite)\n\nnaprawiamy go wpisując\n\nparted -l\n\na następnie fix.\n\nPartycje można poustawiać poleceniem\n\ncfdisk /dev/sda\n\noczywiście adres dysku może u Ciebie być inny niż /dev/sda. Wybieramy typ linux\n(x86).\n\nTeraz musimy okreslicz czy instalujemy system bootawny z biosa czy przez uefi.\nJesli nie wiemy sprawdzmy czy nasza plyta gowna obsluguje UEFI i jesli tak to\nlepiej wybrac uefi. Jesli masz nowy komputer mozesz pominac rozdzial \"BIOS\" i\nprzejsc do \"UEFI\".\n\nBIOS\nNa starszych komputerach użyjemy biosa. Programem cfdisk lub fdisk mozemy\nustawic:\n\n * bootowalna patrycje sda1 z typem 83 Linux\n * nie bootowalna partycje sda2 z typem 82 Linux Swap\n\nFortsmtujemy utworzona partycje\n\nmkfs.ext4 /dev/sda1\n\nMontujemy gotowa partycje do /mnt\n\nmount /dev/sda1 /mnt\n\nMożemy teraz pominąć fragment \"UEFI\" i przejść do \"Pacstrap\"\n\nUEFI\nW przypadku UEFI musimy przygotować tabelę GPT. Możesz użyć do tego bardziej\nprzyjazdnego programu cfdisk, lub bardziej zaawansowanego fdisk. Poniżej\npokazuję to w fdisk.\n\nfdisk /dev/sda\n\nwybieramy opcję g\n\nTworzymy partycję uefi wybierając kolejno n (nowa), ENTER (nie zmieniamy punku\npierwszego sektora), +200M (ustawiamy ostatni sektor na + 200 MB.\n\nUstawiamy typ na EFI System przez t (jak type), 1 (numer typu EFI System).\n\nTworzymy drugą partycję n (new), ENTER (domyślny numer 2), ENTER (domyślny\npoczątkowy blok), ENTER (domyślny końcowy blok).\n\nZapisujemy zmiany wybierając w.\n\nFormatowanie partycji UEFI na fat 32\n\nmkfs.fat -F32 /dev/sda1\n\nFormatowanie na system plików drugiej partycji na ext4:\n\nmkfs.ext4 /dev/sda2\n\nMontujemy partycję na system do katalogu /mnt.\n\nmount /dev/sda2 /mnt\n\nA partycję na uefi do /mnt/boot, najpierw musimy utworzyć ten katalog\n\nmkdir /mnt/boot\n\ni teraz zamontować\n\nmount /dev/sda1 /mnt/boot\n\nDzięki poleceniu slblk możemy sprawdzić, czy montowanie jest poprawne.\n\nPacstrap\nI instalujemy system poleceniem pacstrap\n\npacstrap /mnt base linux linux-firmware nano\n\nGenerujemy plik fstab.\n\ngenfstab -U /mnt >> /mnt/etc/fstab\n\nWchodzimy do zainstalowanego systemu\n\narch-chroot /mnt /bin/bash\n\nSwapfile\nPrzygotowujemy swap:\n\nfallocate -l 2GB /swapfile\nchmod 600 /swapfile\nmkswap /swapfile\nswapon /swapfile\n\nDo /etc/fstab dodajemy\n\n/swapfile none swap defaults 0 0\n\nStrefa czasowa\nUstawiamy strefę czasową\n\nln -sf /usr/share/zoneinfo/Europe/Warsaw /etc/localtime\n\nGenerujemy adjtime żeby zsynchronizować zegar systemowy ze sprzętowym\n\nhwclock --systohc\n\nJęzyk\nUstawimy lokalizację kasując komentarz jednej z linii pliku locale.gen\n\nnano /etc/locale.gen\n\nGenerujemy obsługę języków\n\nlocale-gen\n\nW pliku /etc/locale.conf wpisujemy LANG=pl_PL.UTF-8\n\necho LANG=pl_PL.UTF-8 > /etc/locale.conf\n\nA w /etc/vconsole.conf\n\nKEYMAP=pl\nFONT=Lat2-Terminus16\nFONT_MAP=8859-2\n\nSieć\nW /etc/hostname ustawiamy nazwę hosta. Jest to nazwa naszego komputera -\nprzydatna jeśli mamy kilka urządzeń w sieci lokalnej.\n\nW /etc/hosts dodajemy linie\n\n127.0.0.1    localhost.localdomain    preciselab\n\ntrzecia kolumna zawiera nazwę hosta wybrana poprzednio.\n\nInstalujemy networkmanager.\n\npacman -S networkmanager dhcpcd\n\nWłączamy usługę NetworkManager\n\nsystemctl enable NetworkMananger\n\nPrzydatne paczki\nJest to indywidualna decyzja, jakie jeszcze inne pakiety powinien zawierać\nsystem. Wymienię i opiszę kilka polecanych przeze mnie.\n\n * network-manager-applet - frontend do zarządzania połączeniami z siecią\n * wireless_tools - otwarty projekt sponsorowany przez HP - zawiera narzędzia\n   takie jak iwconfig iwlist iwspy wipriv oraz ifrename do obsługi sieci wifi\n * wpa_supplicant - wsparcie dla szyfrowanych wifi WEP, WPA, WPA2 and WPA3 -\n   dzisiaj niezbędny\n * dialog - paczka do wyświetlania okien dialogowych ze skryptów w bashu,\n   wymagana do używania wifi-menu\n * netctl - konsolowe narzędzie do zarządzania sieciami ( zawiera wifi-menu )\n * os-prober - narzędzie do wykrywania innych systemów operacyjnych i urządzeń,\n   przydatne jeśli grub ich nie widzi\n * base-devel - zestaw paczek do kompilacji, obróbki tekstu i kompresji\n * linux-headers - skrypty do budowania modułów jadra systemowego\n * reflector - skrypt do automatyzacji wyboru serwerów lustrzanych\n * git - system kontroli wersji używany do programowania i instalacji pakietów\n * cups - rozwijany przez Apple system do obsługi drukarek\n * xdg-utils - narzędzia pomocnicze dla aplikacji XDG MIME\n * xdg-user-dirs - narzędzie do integracji katalogu użytkownika z innymi\n   programami, w szczególności przydatne dla managerów plików\n * openssh - oprogramowanie do połączenia się przez ssh\n * iwd - narzędzie do łączenia się z siecią np przez iwctl\n\nMożemy je zainstalować poleceniem:\n\npacman -S network-manager-applet wireless_tools wpa_supplicant dialog netctl os-prober base-devel linux-headers reflector git cups xdg-utils xdg-user-dirs openssh iwd\n\nJeśli chcesz używać bluetooth to przydadzą Ci się jeszcze bluez bluez-utils.\n\nTeraz zainstalujemy bootloader, żeby system mógł poprawnie wystartować. W\nzależności od tego czy wybrałeś opcje BIOS czy UEFI przejdź do odpowiedniego\nrozdziału.\n\nBoot loader w BIOS\nInstalujemy bootloader\n\npacman -S grub\n\nużywamy komendy grub-install\n\ngrub-install /dev/sda\n\ni tworzymy plik konfiguracyjny gruba\n\ngrub-mkconfig -o /boot/grub/grub.cfg\n\nBoot loader w UEFI\nInstalujemy bootloader\n\npacman -S grub efibootmgr\n\nużywamy komendy grub-install\n\ngrub-install --target=x86_64-efi --efi-direcotry=/boot --bootloader-id=GRUB\n\nw przypadku błędu\n\n> this GPT partition label contains no BIOS Boot Partition\nnaprawiamy poleceniem\n\nparted /dev/sda\nset 1 boot off\nset 1 bios_grub on\nq\n\ngrub2-install: “this GPT partition label contains no BIOS Boot Partition”There\nseems to be quite a bit of discussion about this but I can’t find a simple\nanswer. When I try to install grub2 I get this error: # grub2-install\n/dev/sdaInstalling for i386-pc platform.gr...Super UserRobert S\n[https://superuser.com/a/1610045/1216455]W przypadku błędu\n\n> \"EFI variables are not supported on this system\"\nwychodzimy z chroot przez exit i wpisujemy\n\nmodprobe efivars\n\n“EFI variables are not supported on this system”I am attempting to install Arch\nlinux to a new (and very crappy) HP Pavillion 15 Notebook. This is a UEFI-based\nmachine. After several swings at it, I have managed to get pretty far. Legacy\nmode...Unix & Linux Stack ExchangeJohn Dibling\n[https://unix.stackexchange.com/a/91623/431667]Jeśli zobaczymy błąd\n\n> Module efivars not found in directory /lib/modules/5.10.3-arch1-1\nmusimy włączyć komputer ponownie w trybie efi. Jest tak dlatego, że cześć maszyn\nmoże wybierać czy włącza się w trybie bios czy efi.\n\nDokumentacja mówi, że możemy sprawdzić czy to działa wpisując:\n\nefivar-tester\n\nale nie polecam tej metody, u mnie zapętla się w nieskończoność i nie da się\ntego wyłączyć inaczej niż sprzętowo wyłączając komputer.\n\nTworzymy plik konfiguracyjny dla gruba\n\ngrub-mkconfig -o /boot/grub/grub.cfg\n\nUżytkownicy\nAby na co dzień moc poslugiwac sie systemem bez uprawnień roota a jednocześnie\nmóc szybko nabywać, zainstalujemy sudo\n\npacman -S sudo\n\nUstawiamy hasło dla root\n\npasswd root\n\nDodajemy użytkownika do codziennego użytku\n\nuseradd -m -g users -G wheel -s /bin/bash daniel\n\nDajemy mu hasło\n\npasswd daniel\n\nGrupie wheel pozwalamy na używanie sudo.\n\nEDITOR=nano visudo\n\nkasujemy komentarz przed linią\n\n%wheel ALL=(ALL) ALL\n\nWychodzimy z instalatora\n\nexit\n\nOdmontowujemy partycję\n\numount /mnt\n\nWyłączamy komputer\n\nshutdown -P now\n\nProblemy sieciowe\nJeśli po wpisaniu\n\nip addr\n\ninterfejsy są wyłączone to można je włączyć przez\n\nip link set dev <interface> up\n\nDo sprawdzenia, które interfejsy warto włączyć przydatne może być nmcli.\n\nJeśli nie możesz włączyć interfejsu, ale znasz nazwę i hasło sieci możesz\nspróbować bezpośredniego połączenia podążając za zaleceniami z linku:\n\nhow do I attach devices to connections using nmcli?An installation of CentOS 7\nhas two connections and three devices. How can I attach the device ens7 to the\nconnection my-bridge? And how can I attach the device eth0 to the connection\nmy-eth1? ...Unix & Linux Stack ExchangeCodeMed\n[https://unix.stackexchange.com/a/613819/431667]nie mam pojęcia dlaczego to\ndziała.\n\nJeśli tłumaczenie nazw domen na adresy ip, nie działa poprawnie musimy wybrać\ndomyślny DNS. Ustawiamy to w\n\n/etc/resolv.conf\n\nwpisując\n\nnameserver 8.8.8.8\n\nStan serwisu odpowiadającego za nadawanie domenom numerów ip sprawdzimy\npoleceniem\n\nsystemctl status systemd-resolved.service\n\nBłędy z kluczami\nJeśli mamy błędy typu\n\n> Signature is unknown trust\nMożemy sprawdzić dany klucz\n\npacman-key -l Thorsten\n\ni jeśli wygasł, to odświeżyć listę kluczy\n\npacman-key --refresh-keys\n\nSignature is unknown trust [SOLVED] / Pacman & Package Upgrade Issues / Arch\nLinux Forums [https://bbs.archlinux.org/viewtopic.php?id=207957]Instalacja yay\nYay jest pomocniczym programem do zarządzania zależnościami. Jeśli\nzainstalowałeś base-devel możesz pobrać yay za pomocą gita\n\ngit clone https://aur.archlinux.org/yay.git\n\ni zainstalować poleceniami\n\ncd yay && makepkg -si\n\nArch Linux How to Install Yay - Super EASY | Low Orbit FluxArch Linux How to\nInstall Yay - Super EASY | Low Orbit FluxLow Orbit Flux\n[https://low-orbit.net/arch-linux-how-to-install-yay]Instalacja I3\nSam manager okien instaluje się poleceniem\n\nyay -S i3-gaps\n\nNależy do niego dodać czcionkę i pasek\n\nyay -S ttf-dejavu i3status\n\nInstalujemy xorg.\n\nyay -S xorg xorg-xinit rxvt-unicode\n\nOraz sterowniki do swojej karty. Typ karty możesz sprawdzić poleceniem lspci |\ngrep VGA.\n\nDla karty AMD/ATI RV370 [Radeon X300] jest to\n\nyay -S xf86-video-ati\n\nDla nvidia będą to:\n\nyay -S nvidia nvidia-utils\n\nDla Atom Processor Integrated Graphics Controller jest to\n\nyay -S xf86-video-intel\n\nJeśli nie wiesz jaką paczkę zainstalować dla swojej karty polecam poszukać na\nstronie:\n\nXorg - ArchWikiArchWiki [https://wiki.archlinux.org/title/xorg]Aby obsługiwać\ndźwięk dodajemy też alsa-utils, pulseaudio i pavucontrol\n\nyay -S alsa-utils pulseaudio pavucontrol\nspeaker-test -c2\nalsamixer\n\nEdytujemy plik\n\nnano /etc/X11/xinit/xinitrc\n\nkomentując linie\n\n#twm &\n#exec xterm ....\n\ni dodając na końcu\n\nexec i3\n\nteraz możemy włączyć tryb graficzny wpisując\n\nstartx\n\nArch Linux How to Install i3 Gaps - Super EASY | Low Orbit FluxArch Linux How\nto\nInstall i3 Gaps - Super EASY | Low Orbit FluxLow Orbit Flux\n[https://low-orbit.net/arch-linux-how-to-install-i3-gaps]Potwierdzamy\nwygenerowanie konfiguracji przez ENTER oraz potwierdzamy klawisz win jako główny\nklawisz.\n\nKonfiguracja I3 i rxvt-unicode\nWartościowe wprowadzenie do i3 nagrał Distroverse:\n\nWzorowałem się na nim tworząc swoją konfigurację. Znajdziesz ją w repozytorium\n\nmy-arch-i3-config/config at main · gustawdaniel/my-arch-i3-configContribute to\ngustawdaniel/my-arch-i3-config development by creating an account on GitHub.\nGitHubgustawdaniel\n[https://github.com/gustawdaniel/my-arch-i3-config/blob/main/.config/i3/config]\nale polecam Ci przejrzeć kilka różnych konfiguracji i poczytać dokumentację i3,\nktóra jest jedną z lepszych dokumentacji managerów okien.\n\nTym czasem zajmiemy się samym terminalem urxt-unicode. Polecam Ci to video\n\nPrzechodzimy do katalogu domowego\n\ncd ~\n\nTworzymy konfigurację\n\ntouch .Xresources\n\nmożemy wkleić do tego pliku jedną z gotowych konfiguracji\n\ncurl https://raw.githubusercontent.com/gustawdaniel/my-arch-i3-config/main/.Xresources > .Xresources\n\nlecz ja polecam poczytać kilka różnych zestawień lub obejrzeć filmy wyjaśniające\ndokładnie możliwe opcje i dobrać z nich te, które są najlepsze dla nas.\n\nDo przeładowania konfiguracji służy komenda\n\nxrdb ~/.Xresources\n\nPrzeglądarka\nInstalujemy przeglądarkę, której wybór ponownie jest Twoim wyborem. W przypadku\nnajpopularniejszej przeglądarki - google chrome jest to:\n\nyay -S google-chrome\n\nPierwszy dodatkiem jest Ublock Origin.\n\nPolski układ klawiatury w X11\nAby używać polskich znaków w środowisku graficznym ustaw layout klawiatury\nwstawiając do pliku /usr/share/X11/xorg.conf.d/10-keyboard.conf konfigurację\n\nSection \"InputClass\"\n    Identifier \"system-keyboard\"\n    MatchIsKeyboard \"on\"\n    Option \"XkbLayout\" \"pl\"\nEndSection\n\nLauncher\nNajprostszy launcher to dmenu. Instalujemy go komendą\n\nyay -S dmenu\n\ni używamy przez kombinację klawiszy super+d\n\nScreenshoty\nWedług mnie najlepszy jest flameshot. Instalujemy go komendą\n\nyay -S flameshot\n\nW konfiguracji i3 możemy połączyć go z przyciskiem print screen\n\nbindsym Print exec flameshot gui\n\nSterowanie innymi komputerami\nJeśli używamy kilku komputerów i chcemy sterować nimi używając jednej myszki i\nklawiatury na wszystkich komputerach możemy zainstalować barrier.\n\nyay -S barrier\n\nNa urządzeniu klienckim ustawiamy id serwera:\n\nA na serwerze:\n\nWskazujemy gdzie względem naszego komputera ustawi się klient\n\nW przypadku problemów z zestawieniem połączenia zawsze pomagało wyłączenie i\nwłączeniu obu komputerów.\n\nOh my zsh\nZsh jest powłoką alternatywną do bash o więszych możliwościach customizacji i\nrozszerzania. Instalujemy ją poleceniem:\n\nyay -S zsh\n\nNastępnie instalujemy oh my zsh.\n\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n\nTapeta\nZaczniemy od sprawdzenia rozdzielczości monitorów poleceniem\n\n xrandr --listmonitors\n\nPobieramy tapetę w odpowiednim rozmiarze i zapisujemy ją do pliku\n\n.config/i3/.bg.jpeg\n\nInstalujemy feh komendą\n\nyay -S feh\n\nDo pliku .fehbg zapisujemy skrypt ustawiający tapetę\n\n#!/bin/sh\nfeh --no-fehbg --bg-scale '/home/daniel/.config/i3/.bg.jpeg'\n\nDajemy mu prawa do uruchamiania\n\nsudo chmod +x ~/.fehbg\n\nw .config/i3/config włączamy go poleceniem\n\nexec --no-startup-id sh ~/.fehbg\n\nNeovim\nOdrobinkę wygodniejsza wersja vim.\n\nyay -S neovim\n\nSynchronizacja zegara systemowego\nJeśli w dacie lub godzinie pojawia się rozbieżność warto włączyć synchronizację\nz serwerami wskazującymi poprawny czas.\n\nsudo timedatectl set-ntp true \n\nMonitoring zasobów\nDo sprawdzania użycia i temperatury procesora, zajętej pamięci operacyjnej,\ntransferu sieci - czyli ogólnego monitoringu polecam bashtop.\n\nyay -S bashtop\n\nDisplay Manager\nProgram w którym wybieram typ sesji oraz podaję login i hasło to ly.\n\nyay -S ly\nsudo systemctl enable ly.service\n\nTmux i Tmuxinator\nDo zarządzania sesjami, oknami i podziałem okien w terminalu używam tmuxa.\n\nyay -S tmux ruby\ngem install tmuxinator\n\nJego konfiguracja:\n\nmy-arch-i3-config/.tmux.conf at main · gustawdaniel/my-arch-i3-configContribute\nto gustawdaniel/my-arch-i3-config development by creating an account on GitHub.\nGitHubgustawdaniel\n[https://github.com/gustawdaniel/my-arch-i3-config/blob/main/.tmux.conf]\nBitwarden\nDo zarządzania hasłami używałem keeweb. Obecnie korzystam z bitwarden:\n\nyay -S bitwardern\n\nza zarządzanie jego widocznością odpowiada następująca konfiguracja w pliku \n~/.config/i3/config:\n\nexec --no-startup-id bitwarden\nbindsym $Mod+k [instance=\"bitwarden\"] scratchpad show; [instance=\"bitwarden\"] move position center\nfor_window [instance=\"bitwarden\"] move scratchpad\nfor_window [instance=\"bitwarden\"] border pixel 3\nfor_window [instance=\"bitwarden\"] resize set 800 600\n\nNasz Arch Linux z i3 jest gotowy \nWciąż do efektywnej pracy może brakować nam IDE jeśli jesteśmy programistami lub \nobs jeśli nagrywamy video albo programów do obróbki grafiki. Jednak sam system i\npodstawowe programy możemy uznać za gotowe.\n\nJeśli twoim zdaniem w zestawieniu zabrakło jakichś programów, albo widzisz\nmiejsca gdzie mógł być coś uprościć daj znać w komentarzu.",
            "feature_image": "__GHOST_URL__/content/images/2021/08/maxresdefault--1-.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-08-20T06:48:34.000Z",
            "updated_at": "2021-10-30T12:31:37.000Z",
            "published_at": "2021-10-22T01:24:19.000Z",
            "custom_excerpt": "Instalacja Arch Linux za każdym razem uczy mnie czegoś nowego na temat dysków, sieci, systemów operacyjnych. Polecam Ci ją jeśli chcesz mieć system skrojony pod Twoje wymagania.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "619392ef50caaa182e07f646",
            "uuid": "96adb01a-bfce-467b-84ea-5986bdf93e4e",
            "title": "Najmniejsza wspólna wielokrotność - teoria liczb",
            "slug": "najmniejsza-wspolna-wielokrotnosc",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.hackerearth.com/practice/math/number-theory/basic-number-theory-1/practice-problems/algorithm/archery-1/\",\"metadata\":{\"url\":\"https://www.hackerearth.com/practice/math/number-theory/basic-number-theory-1/practice-problems/algorithm/archery-1/\",\"title\":\"Archery | Practice Problems\",\"description\":\"Prepare for your technical interviews by solving questions that are asked in interviews of various companies. HackerEarth is a global hub of 5M+ developers. We help companies accurately assess, interview, and hire top developers for a myriad of roles.\",\"author\":null,\"publisher\":\"HackerEarth\",\"thumbnail\":\"https://static-fastly.hackerearth.com/static/hackerearth/images/logo/HE_cover.jpg\",\"icon\":\"https://static-fastly.hackerearth.com/static/hackerearth/images/logo/HE_identity.png\"}}],[\"code\",{\"code\":\"1 <= T <= 5\\n1 <= N <= 15\\n1 <= k_i <= 48\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/2021-11-18_14-02.png\",\"width\":665,\"height\":123}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://en.wikipedia.org/wiki/Least_common_multiple\",\"metadata\":{\"url\":\"https://en.wikipedia.org/wiki/Least_common_multiple\",\"title\":\"Least common multiple - Wikipedia\",\"description\":null,\"author\":\"Contributors to Wikimedia projects\",\"publisher\":\"Wikimedia Foundation, Inc.\",\"thumbnail\":\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Symmetrical_5-set_Venn_diagram_LCM_2_3_4_5_7.svg/1200px-Symmetrical_5-set_Venn_diagram_LCM_2_3_4_5_7.svg.png\",\"icon\":\"https://en.wikipedia.org/static/apple-touch/wikipedia.png\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/c2064d7393a873698b08985de30ce22e9dc560a2.svg\",\"width\":246,\"height\":45}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/c902bcafbb1287727dcd0409800994923dd66388.svg\",\"width\":202,\"height\":45}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/Algorithm-PrimeFactor_clip_image002.jpeg\",\"width\":423,\"height\":427}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://people.revoledu.com/kardi/tutorial/BasicMath/Prime/Algorithm-PrimeFactor.html?txtInput=10&txtResult=4+is+a+Composite+number.%0D%0A%0D%0APrime+factorization%3A+%0D%0A4+%3D+2%5E2%0D%0A%0D%0AThere+are+3+divisors.+%0D%0ADivisors+of+4+are+1%2C2%2C4%0D%0A\",\"metadata\":{\"url\":\"https://people.revoledu.com/kardi/tutorial/BasicMath/Prime/Algorithm-PrimeFactor.html?txtInput=10&txtResult=4+is+a+Composite+number.%0D%0A%0D%0APrime+factorization%3A+%0D%0A4+%3D+2%5E2%0D%0A%0D%0AThere+are+3+divisors.+%0D%0ADivisors+of+4+are+1%2C2%2C4%0D%0A\",\"title\":\"Prime Factor: Algorithm\",\"description\":\"Step by Step Algorithm of Prime factor using spreadsheet\",\"author\":\"Kardi Teknomo\",\"publisher\":null,\"thumbnail\":\"https://people.revoledu.com/kardi/tutorial/image/Prime.png\",\"icon\":\"https://people.revoledu.com/kardi/images/favicon.ico\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://en.wikipedia.org/wiki/Integer_factorization\",\"metadata\":{\"url\":\"https://en.wikipedia.org/wiki/Integer_factorization\",\"title\":\"Integer factorization - Wikipedia\",\"description\":null,\"author\":\"Contributors to Wikimedia projects\",\"publisher\":\"Wikimedia Foundation, Inc.\",\"thumbnail\":\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/PrimeDecompositionExample.svg/220px-PrimeDecompositionExample.svg.png\",\"icon\":\"https://en.wikipedia.org/static/apple-touch/wikipedia.png\"}}],[\"code\",{\"code\":\"{\\n  2: 2,\\n  3: 1\\n}\",\"language\":\"json\"}],[\"code\",{\"code\":\"function divideTimes(n, i) {\\n    let counter = 0;\\n    while(n % i === 0) {\\n        counter++;\\n        n = n / i;\\n    }\\n    return counter;\\n}\\n\\nfunction primeFactors(n) {\\n    if(n === 1) return { 1: 1 };\\n    const res = {};\\n    let p = 2\\n    while(n >= p*p) {\\n        if(n % p === 0) {\\n            res[p] = divideTimes(n,p);\\n            n /= Math.pow(p, res[p]);\\n        } else {\\n            p++\\n        }\\n    }\\n    if(n > 1) {\\n        res[n] = 1;\\n    }\\n    return res;\\n}\",\"language\":\"javascript\"}],[\"code\",{\"code\":\"function mergeKeysChoosingMaxValue(prev, next) {\\n    for(let key of Object.keys(next)) {\\n        if(prev.hasOwnProperty(key)) {\\n            prev[key] = Math.max(prev[key], next[key]);\\n        } else {\\n            prev[key] = next[key];\\n        }\\n    }\\n    return prev;\\n}\"}],[\"code\",{\"code\":\"function evaluate(object) {\\n    return Object.keys(object).reduce((prev, key) => {\\n        return prev * Math.pow(Number(key), object[key]);\\n    },1)\\n}\"}],[\"code\",{\"code\":\"process.stdin.resume();\\nprocess.stdin.setEncoding(\\\"utf-8\\\");\\nlet stdin_input = \\\"\\\";\\n\\nprocess.stdin.on(\\\"data\\\", function (input) {\\n    stdin_input += input;\\n});\\n\\nprocess.stdin.on(\\\"end\\\", function () {\\n   main(stdin_input);\\n});\"}],[\"code\",{\"code\":\"function minCommonDiv(k) {\\n    const factorized = k.map(primeFactors);\\n    return evaluate(factorized.reduce(mergeKeysChoosingMaxValue))\\n}\\n\\nfunction main(input) {\\n    const lines = input.split('\\\\n').filter(line => Boolean(line));\\n    const T = Number.parseInt(lines.shift());\\n    const out = [];\\n    for(let i=0; i<T; i++) {\\n        lines.shift();\\n        const k = lines.shift().split(/\\\\s+/).map(n => Number.parseInt(n));\\n        const res = minCommonDiv(k);\\n        out.push(res);\\n    }\\n\\n    process.stdout.write(out.join(\\\"\\\\n\\\") + \\\"\\\\n\\\");\\n}\"}],[\"code\",{\"code\":\"cat input.txt | node app.js\"}]],\"markups\":[[\"code\"],[\"strong\"]],\"sections\":[[1,\"p\",[[0,[],0,\"W serwisie Hacker Earth można znaleźć wiele ciekawych zadań dla programistów.\"]]],[1,\"p\",[[0,[],0,\"Jedno z nich: \\\"Archery\\\" prezentuję w tym wpisie wraz z omówieniem rozwiązania.\"]]],[10,0],[1,\"h3\",[[0,[],0,\"Treść zadania\"]]],[1,\"p\",[[0,[],0,\"Problem \"]]],[1,\"p\",[[0,[0],1,\"N\"],[0,[],0,\" łuczników strzela strzałami do celów. Istnieje nieskończona liczba celów ponumerowanych od 1. Łucznik \"],[0,[0],1,\"i\"],[0,[],0,\" strzela do wszystkich celów będących wielokrotnościami \"],[0,[0],1,\"k_i\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Znajdź najmniejszy cel trafiony przez wszystkich łuczników.\"]]],[1,\"p\",[[0,[],0,\"Wejście\"]]],[1,\"p\",[[0,[],0,\"W pierwszym wierszu znajduje się liczba całkowita T - całkowita liczba przypadków testowych. \"]]],[1,\"p\",[[0,[],0,\"Poniżej znajdują się przypadki testowe T. Każdy przypadek testowy ma następujący format: \"]]],[1,\"p\",[[0,[],0,\"W pierwszym wierszu znajduje się liczba naturalna - N - liczba łuczników. Drugi wiersz zawiera N liczb całkowitych oddzielonych spacjami, gdzie każda kolejna liczba oznacza wartość \"],[0,[0],1,\"k_i\"],[0,[],0,\" dla łucznika. \"]]],[1,\"p\",[[0,[],0,\"Wyjście \"]]],[1,\"p\",[[0,[],0,\"Dla każdego przypadku testowego wypisz w nowej linii \"],[0,[1],1,\"najmniejszy cel trafiony przez wszystkich łuczników.\"]]],[1,\"p\",[[0,[],0,\"Ograniczenia\"]]],[10,1],[10,2],[1,\"p\",[[0,[],0,\"Wyjaśnienie\"]]],[1,\"p\",[[0,[],0,\"Pierwszy łucznik strzela do celów 2, 4, 6, 8, 10, 12, 14, ...\"]]],[1,\"p\",[[0,[],0,\"Drugi łucznik strzela do celów 3, 6, 9, 12, ...\"]]],[1,\"p\",[[0,[],0,\"Trzeci łucznik strzela do celów 4, 8, 12, 16, 20, ...\"]]],[1,\"p\",[[0,[],0,\"Najmniejszym celem, do którego strzelają wszyscy łucznicy, jest 12.\"]]],[1,\"h3\",[[0,[],0,\"Rozwiązanie\"]]],[1,\"p\",[[0,[],0,\"Zadzierając z problemu opowieść związaną z łucznikami zostajemy z zadaniem polegającym na znalezieniu najmniejszej wspólnej wielokrotności.\"]]],[10,3],[1,\"p\",[[0,[],0,\"Kluczowe wzory to:\"]]],[3,\"ul\",[[[0,[],0,\"Fundamentalne twierdzenie arytmetyki - każdą dodatnią całkowitą liczbę przedstawimy jako unikalny iloczyn jej czynników pierwszych z odpowiednimi potęgami\"]]]],[10,4],[3,\"ul\",[[[0,[],0,\"Najmniejszą wspólną wielokrotność (lcm) pary liczb wyliczymy używając tego rozkładu\"]]]],[10,5],[1,\"p\",[[0,[],0,\"Istnieją sposoby liczenia \"],[0,[0],1,\"lcm\"],[0,[],0,\" bez rozkładu na czynniki, np przez związek z największym wspólnym dzielnikiem (gcd) i algorytm euklidesa, tu jednak posłużymy się rozkładem na czynniki.\"]]],[1,\"h4\",[[0,[],0,\"Algorytm wyznaczania Najmniejszej Wspólnej Wielokrotności\"]]],[3,\"ol\",[[[0,[],0,\"Rozkładamy liczby na iloczyny czynników pierwszych,\"]],[[0,[],0,\"Wybieramy maksymalne krotności czynników pierwszych\"]],[[0,[],0,\"Wymnażamy czynniki pierwsze potęgując je do ilości ich wystąpień\"]]]],[1,\"p\",[[0,[],0,\"Widzimy, że pierwszym wyzwaniem jest rozłożenie liczby na czynniki.\"]]],[1,\"h4\",[[0,[],0,\"Rozkład liczby na czynniki pierwsze\"]]],[1,\"p\",[[0,[],0,\"W tym zagadnieniu bardzo pomocny jest graficzny schemat algorytmu\"]]],[10,6],[10,7],[1,\"p\",[[0,[],0,\"Ten algorytm nazywa się \\\"Trial division\\\" i jest najmniej oszczędnym, ale najprostszym do zrozumienia algorytmem faktoryzacji. Inne wymienione są tutaj:\"]]],[10,8],[1,\"p\",[[0,[],0,\"Przed implementacją ustalmy jeszcze sposób zapisu wyniku faktoryzacji. Posłużymy się obiektem, w którym klucze to czynniki, a wartości to ilości ich wystąpień. Np do zapisania liczby \"],[0,[0],1,\"12\"],[0,[],0,\" czyli \"],[0,[0],1,\"2 * 2 * 3\"],[0,[],0,\" stworzymy obiekt\"]]],[10,9],[1,\"p\",[[0,[],0,\"Do wyliczenia rozkładu na czynniki będzie służył kod\"]]],[10,10],[1,\"h4\",[[0,[],0,\"Pomijanie powtarzających się czynników w mnożeniu\"]]],[1,\"p\",[[0,[],0,\"W drugim kroku algorytmu mamy pomijanie powtarzających się czynników. Pokażę to na przykładzie.\"]]],[1,\"p\",[[0,[],0,\"Liczba \"],[0,[0],1,\"54\"],[0,[],0,\" to \"],[0,[0],1,\"2 * 3^3\"],[0,[],0,\", a \"],[0,[0],1,\"76\"],[0,[],0,\" to \"],[0,[0],1,\"2^2 * 19\"],[0,[],0,\". Ich najmniejsza wspólna wielokrotność to iloczyn \"],[0,[0],1,\"2^2\"],[0,[],0,\" ( tu wybieramy większą potęgę ) oraz \"],[0,[0],1,\"3^3\"],[0,[],0,\" i \"],[0,[0],1,\"19\"],[0,[],0,\", tu wybieramy rozłączne dzielniki ( w ogólności też jest to wyższa potęga ).\"]]],[1,\"p\",[[0,[],0,\"Funkcję, która będzie wykonywała operację wyliczania największej wspólnej wielokrotności dla pary liczb nazwiemy\"]]],[10,11],[1,\"h4\",[[0,[],0,\"Ewaluacja wartości liczby z jej czynników\"]]],[1,\"p\",[[0,[],0,\"Na koniec chcemy użytkownikowi wyświetlać liczby a nie ich rozkłady na czynniki, więc przejdziemy z formatu rozłożonego na czystą wartość liczbową\"]]],[10,12],[1,\"h4\",[[0,[],0,\"Integracja rozwiązania z formatem wejścia i wyjścia programu\"]]],[1,\"p\",[[0,[],0,\"Zostało nam jeszcze podłączenie napisanych przez nas części składowych do wymaganego przez zadanie formatu wejścia i wyjścia. Pierwsza część kodu odczytuje dane ze standardowego strumienia i uruchamia na nich funkcję \"],[0,[0],1,\"main\"]]],[10,13],[1,\"p\",[[0,[],0,\"Druga część składa się z kodu przetwarzającego linie tekstu na tablice liczb w funkcji \"],[0,[0],1,\"main\"],[0,[],0,\" i wykonującego zadanie w funkcji \"],[0,[0],1,\"minCommonDiv\"],[0,[],0,\".\"]]],[10,14],[1,\"p\",[[0,[],0,\"Program przy założeniu, że wejście zapiszemy do \"],[0,[0],1,\"input.txt\"],[0,[],0,\" a program do \"],[0,[0],1,\"app.js\"],[0,[],0,\", nasze rozwiązanie możemy sprawdzić poleceniem:\"]]],[10,15],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>W serwisie Hacker Earth można znaleźć wiele ciekawych zadań dla programistów.</p><p>Jedno z nich: \"Archery\" prezentuję w tym wpisie wraz z omówieniem rozwiązania.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.hackerearth.com/practice/math/number-theory/basic-number-theory-1/practice-problems/algorithm/archery-1/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Archery | Practice Problems</div><div class=\"kg-bookmark-description\">Prepare for your technical interviews by solving questions that are asked in interviews of various companies. HackerEarth is a global hub of 5M+ developers. We help companies accurately assess, interview, and hire top developers for a myriad of roles.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://static-fastly.hackerearth.com/static/hackerearth/images/logo/HE_identity.png\"><span class=\"kg-bookmark-author\">HackerEarth</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://static-fastly.hackerearth.com/static/hackerearth/images/logo/HE_cover.jpg\"></div></a></figure><h3 id=\"tre%C5%9B%C4%87-zadania\">Treść zadania</h3><p>Problem </p><p><code>N</code> łuczników strzela strzałami do celów. Istnieje nieskończona liczba celów ponumerowanych od 1. Łucznik <code>i</code> strzela do wszystkich celów będących wielokrotnościami <code>k_i</code>. </p><p>Znajdź najmniejszy cel trafiony przez wszystkich łuczników.</p><p>Wejście</p><p>W pierwszym wierszu znajduje się liczba całkowita T - całkowita liczba przypadków testowych. </p><p>Poniżej znajdują się przypadki testowe T. Każdy przypadek testowy ma następujący format: </p><p>W pierwszym wierszu znajduje się liczba naturalna - N - liczba łuczników. Drugi wiersz zawiera N liczb całkowitych oddzielonych spacjami, gdzie każda kolejna liczba oznacza wartość <code>k_i</code> dla łucznika. </p><p>Wyjście </p><p>Dla każdego przypadku testowego wypisz w nowej linii <strong>najmniejszy cel trafiony przez wszystkich łuczników.</strong></p><p>Ograniczenia</p><pre><code>1 &lt;= T &lt;= 5\n1 &lt;= N &lt;= 15\n1 &lt;= k_i &lt;= 48</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/2021-11-18_14-02.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"665\" height=\"123\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/2021-11-18_14-02.png 600w, __GHOST_URL__/content/images/2021/11/2021-11-18_14-02.png 665w\"></figure><p>Wyjaśnienie</p><p>Pierwszy łucznik strzela do celów 2, 4, 6, 8, 10, 12, 14, ...</p><p>Drugi łucznik strzela do celów 3, 6, 9, 12, ...</p><p>Trzeci łucznik strzela do celów 4, 8, 12, 16, 20, ...</p><p>Najmniejszym celem, do którego strzelają wszyscy łucznicy, jest 12.</p><h3 id=\"rozwi%C4%85zanie\">Rozwiązanie</h3><p>Zadzierając z problemu opowieść związaną z łucznikami zostajemy z zadaniem polegającym na znalezieniu najmniejszej wspólnej wielokrotności.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://en.wikipedia.org/wiki/Least_common_multiple\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Least common multiple - Wikipedia</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://en.wikipedia.org/static/apple-touch/wikipedia.png\"><span class=\"kg-bookmark-author\">Wikimedia Foundation, Inc.</span><span class=\"kg-bookmark-publisher\">Contributors to Wikimedia projects</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Symmetrical_5-set_Venn_diagram_LCM_2_3_4_5_7.svg/1200px-Symmetrical_5-set_Venn_diagram_LCM_2_3_4_5_7.svg.png\"></div></a></figure><p>Kluczowe wzory to:</p><ul><li>Fundamentalne twierdzenie arytmetyki - każdą dodatnią całkowitą liczbę przedstawimy jako unikalny iloczyn jej czynników pierwszych z odpowiednimi potęgami</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/c2064d7393a873698b08985de30ce22e9dc560a2.svg\" class=\"kg-image\" alt loading=\"lazy\" width=\"246\" height=\"45\"></figure><ul><li>Najmniejszą wspólną wielokrotność (lcm) pary liczb wyliczymy używając tego rozkładu</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/c902bcafbb1287727dcd0409800994923dd66388.svg\" class=\"kg-image\" alt loading=\"lazy\" width=\"202\" height=\"45\"></figure><p>Istnieją sposoby liczenia <code>lcm</code> bez rozkładu na czynniki, np przez związek z największym wspólnym dzielnikiem (gcd) i algorytm euklidesa, tu jednak posłużymy się rozkładem na czynniki.</p><h4 id=\"algorytm-wyznaczania-najmniejszej-wsp%C3%B3lnej-wielokrotno%C5%9Bci\">Algorytm wyznaczania Najmniejszej Wspólnej Wielokrotności</h4><ol><li>Rozkładamy liczby na iloczyny czynników pierwszych,</li><li>Wybieramy maksymalne krotności czynników pierwszych</li><li>Wymnażamy czynniki pierwsze potęgując je do ilości ich wystąpień</li></ol><p>Widzimy, że pierwszym wyzwaniem jest rozłożenie liczby na czynniki.</p><h4 id=\"rozk%C5%82ad-liczby-na-czynniki-pierwsze\">Rozkład liczby na czynniki pierwsze</h4><p>W tym zagadnieniu bardzo pomocny jest graficzny schemat algorytmu</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/Algorithm-PrimeFactor_clip_image002.jpeg\" class=\"kg-image\" alt loading=\"lazy\" width=\"423\" height=\"427\"></figure><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://people.revoledu.com/kardi/tutorial/BasicMath/Prime/Algorithm-PrimeFactor.html?txtInput&#x3D;10&amp;txtResult&#x3D;4+is+a+Composite+number.%0D%0A%0D%0APrime+factorization%3A+%0D%0A4+%3D+2%5E2%0D%0A%0D%0AThere+are+3+divisors.+%0D%0ADivisors+of+4+are+1%2C2%2C4%0D%0A\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Prime Factor: Algorithm</div><div class=\"kg-bookmark-description\">Step by Step Algorithm of Prime factor using spreadsheet</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://people.revoledu.com/kardi/images/favicon.ico\"><span class=\"kg-bookmark-publisher\">Kardi Teknomo</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://people.revoledu.com/kardi/tutorial/image/Prime.png\"></div></a></figure><p>Ten algorytm nazywa się \"Trial division\" i jest najmniej oszczędnym, ale najprostszym do zrozumienia algorytmem faktoryzacji. Inne wymienione są tutaj:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://en.wikipedia.org/wiki/Integer_factorization\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Integer factorization - Wikipedia</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://en.wikipedia.org/static/apple-touch/wikipedia.png\"><span class=\"kg-bookmark-author\">Wikimedia Foundation, Inc.</span><span class=\"kg-bookmark-publisher\">Contributors to Wikimedia projects</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/PrimeDecompositionExample.svg/220px-PrimeDecompositionExample.svg.png\"></div></a></figure><p>Przed implementacją ustalmy jeszcze sposób zapisu wyniku faktoryzacji. Posłużymy się obiektem, w którym klucze to czynniki, a wartości to ilości ich wystąpień. Np do zapisania liczby <code>12</code> czyli <code>2 * 2 * 3</code> stworzymy obiekt</p><pre><code class=\"language-json\">{\n  2: 2,\n  3: 1\n}</code></pre><p>Do wyliczenia rozkładu na czynniki będzie służył kod</p><pre><code class=\"language-javascript\">function divideTimes(n, i) {\n    let counter = 0;\n    while(n % i === 0) {\n        counter++;\n        n = n / i;\n    }\n    return counter;\n}\n\nfunction primeFactors(n) {\n    if(n === 1) return { 1: 1 };\n    const res = {};\n    let p = 2\n    while(n &gt;= p*p) {\n        if(n % p === 0) {\n            res[p] = divideTimes(n,p);\n            n /= Math.pow(p, res[p]);\n        } else {\n            p++\n        }\n    }\n    if(n &gt; 1) {\n        res[n] = 1;\n    }\n    return res;\n}</code></pre><h4 id=\"pomijanie-powtarzaj%C4%85cych-si%C4%99-czynnik%C3%B3w-w-mno%C5%BCeniu\">Pomijanie powtarzających się czynników w mnożeniu</h4><p>W drugim kroku algorytmu mamy pomijanie powtarzających się czynników. Pokażę to na przykładzie.</p><p>Liczba <code>54</code> to <code>2 * 3^3</code>, a <code>76</code> to <code>2^2 * 19</code>. Ich najmniejsza wspólna wielokrotność to iloczyn <code>2^2</code> ( tu wybieramy większą potęgę ) oraz <code>3^3</code> i <code>19</code>, tu wybieramy rozłączne dzielniki ( w ogólności też jest to wyższa potęga ).</p><p>Funkcję, która będzie wykonywała operację wyliczania największej wspólnej wielokrotności dla pary liczb nazwiemy</p><pre><code>function mergeKeysChoosingMaxValue(prev, next) {\n    for(let key of Object.keys(next)) {\n        if(prev.hasOwnProperty(key)) {\n            prev[key] = Math.max(prev[key], next[key]);\n        } else {\n            prev[key] = next[key];\n        }\n    }\n    return prev;\n}</code></pre><h4 id=\"ewaluacja-warto%C5%9Bci-liczby-z-jej-czynnik%C3%B3w\">Ewaluacja wartości liczby z jej czynników</h4><p>Na koniec chcemy użytkownikowi wyświetlać liczby a nie ich rozkłady na czynniki, więc przejdziemy z formatu rozłożonego na czystą wartość liczbową</p><pre><code>function evaluate(object) {\n    return Object.keys(object).reduce((prev, key) =&gt; {\n        return prev * Math.pow(Number(key), object[key]);\n    },1)\n}</code></pre><h4 id=\"integracja-rozwi%C4%85zania-z-formatem-wej%C5%9Bcia-i-wyj%C5%9Bcia-programu\">Integracja rozwiązania z formatem wejścia i wyjścia programu</h4><p>Zostało nam jeszcze podłączenie napisanych przez nas części składowych do wymaganego przez zadanie formatu wejścia i wyjścia. Pierwsza część kodu odczytuje dane ze standardowego strumienia i uruchamia na nich funkcję <code>main</code></p><pre><code>process.stdin.resume();\nprocess.stdin.setEncoding(\"utf-8\");\nlet stdin_input = \"\";\n\nprocess.stdin.on(\"data\", function (input) {\n    stdin_input += input;\n});\n\nprocess.stdin.on(\"end\", function () {\n   main(stdin_input);\n});</code></pre><p>Druga część składa się z kodu przetwarzającego linie tekstu na tablice liczb w funkcji <code>main</code> i wykonującego zadanie w funkcji <code>minCommonDiv</code>.</p><pre><code>function minCommonDiv(k) {\n    const factorized = k.map(primeFactors);\n    return evaluate(factorized.reduce(mergeKeysChoosingMaxValue))\n}\n\nfunction main(input) {\n    const lines = input.split('\\n').filter(line =&gt; Boolean(line));\n    const T = Number.parseInt(lines.shift());\n    const out = [];\n    for(let i=0; i&lt;T; i++) {\n        lines.shift();\n        const k = lines.shift().split(/\\s+/).map(n =&gt; Number.parseInt(n));\n        const res = minCommonDiv(k);\n        out.push(res);\n    }\n\n    process.stdout.write(out.join(\"\\n\") + \"\\n\");\n}</code></pre><p>Program przy założeniu, że wejście zapiszemy do <code>input.txt</code> a program do <code>app.js</code>, nasze rozwiązanie możemy sprawdzić poleceniem:</p><pre><code>cat input.txt | node app.js</code></pre>",
            "comment_id": "619392ef50caaa182e07f646",
            "plaintext": "W serwisie Hacker Earth można znaleźć wiele ciekawych zadań dla programistów.\n\nJedno z nich: \"Archery\" prezentuję w tym wpisie wraz z omówieniem rozwiązania.\n\nArchery | Practice ProblemsPrepare for your technical interviews by solving\nquestions that are asked in interviews of various companies. HackerEarth is a\nglobal hub of 5M+ developers. We help companies accurately assess, interview,\nand hire top developers for a myriad of roles.HackerEarth\n[https://www.hackerearth.com/practice/math/number-theory/basic-number-theory-1/practice-problems/algorithm/archery-1/]\nTreść zadania\nProblem \n\nN łuczników strzela strzałami do celów. Istnieje nieskończona liczba celów\nponumerowanych od 1. Łucznik i strzela do wszystkich celów będących\nwielokrotnościami k_i. \n\nZnajdź najmniejszy cel trafiony przez wszystkich łuczników.\n\nWejście\n\nW pierwszym wierszu znajduje się liczba całkowita T - całkowita liczba\nprzypadków testowych. \n\nPoniżej znajdują się przypadki testowe T. Każdy przypadek testowy ma następujący\nformat: \n\nW pierwszym wierszu znajduje się liczba naturalna - N - liczba łuczników. Drugi\nwiersz zawiera N liczb całkowitych oddzielonych spacjami, gdzie każda kolejna\nliczba oznacza wartość k_i dla łucznika. \n\nWyjście \n\nDla każdego przypadku testowego wypisz w nowej linii najmniejszy cel trafiony\nprzez wszystkich łuczników.\n\nOgraniczenia\n\n1 <= T <= 5\n1 <= N <= 15\n1 <= k_i <= 48\n\nWyjaśnienie\n\nPierwszy łucznik strzela do celów 2, 4, 6, 8, 10, 12, 14, ...\n\nDrugi łucznik strzela do celów 3, 6, 9, 12, ...\n\nTrzeci łucznik strzela do celów 4, 8, 12, 16, 20, ...\n\nNajmniejszym celem, do którego strzelają wszyscy łucznicy, jest 12.\n\nRozwiązanie\nZadzierając z problemu opowieść związaną z łucznikami zostajemy z zadaniem\npolegającym na znalezieniu najmniejszej wspólnej wielokrotności.\n\nLeast common multiple - WikipediaWikimedia Foundation, Inc.Contributors to\nWikimedia projects [https://en.wikipedia.org/wiki/Least_common_multiple]Kluczowe\nwzory to:\n\n * Fundamentalne twierdzenie arytmetyki - każdą dodatnią całkowitą liczbę\n   przedstawimy jako unikalny iloczyn jej czynników pierwszych z odpowiednimi\n   potęgami\n\n * Najmniejszą wspólną wielokrotność (lcm) pary liczb wyliczymy używając tego\n   rozkładu\n\nIstnieją sposoby liczenia lcm bez rozkładu na czynniki, np przez związek z\nnajwiększym wspólnym dzielnikiem (gcd) i algorytm euklidesa, tu jednak posłużymy\nsię rozkładem na czynniki.\n\nAlgorytm wyznaczania Najmniejszej Wspólnej Wielokrotności\n 1. Rozkładamy liczby na iloczyny czynników pierwszych,\n 2. Wybieramy maksymalne krotności czynników pierwszych\n 3. Wymnażamy czynniki pierwsze potęgując je do ilości ich wystąpień\n\nWidzimy, że pierwszym wyzwaniem jest rozłożenie liczby na czynniki.\n\nRozkład liczby na czynniki pierwsze\nW tym zagadnieniu bardzo pomocny jest graficzny schemat algorytmu\n\nPrime Factor: AlgorithmStep by Step Algorithm of Prime factor using spreadsheet\nKardi Teknomo\n[https://people.revoledu.com/kardi/tutorial/BasicMath/Prime/Algorithm-PrimeFactor.html?txtInput=10&txtResult=4+is+a+Composite+number.%0D%0A%0D%0APrime+factorization%3A+%0D%0A4+%3D+2%5E2%0D%0A%0D%0AThere+are+3+divisors.+%0D%0ADivisors+of+4+are+1%2C2%2C4%0D%0A]\nTen algorytm nazywa się \"Trial division\" i jest najmniej oszczędnym, ale\nnajprostszym do zrozumienia algorytmem faktoryzacji. Inne wymienione są tutaj:\n\nInteger factorization - WikipediaWikimedia Foundation, Inc.Contributors to\nWikimedia projects [https://en.wikipedia.org/wiki/Integer_factorization]Przed\nimplementacją ustalmy jeszcze sposób zapisu wyniku faktoryzacji. Posłużymy się\nobiektem, w którym klucze to czynniki, a wartości to ilości ich wystąpień. Np do\nzapisania liczby 12 czyli 2 * 2 * 3 stworzymy obiekt\n\n{\n  2: 2,\n  3: 1\n}\n\nDo wyliczenia rozkładu na czynniki będzie służył kod\n\nfunction divideTimes(n, i) {\n    let counter = 0;\n    while(n % i === 0) {\n        counter++;\n        n = n / i;\n    }\n    return counter;\n}\n\nfunction primeFactors(n) {\n    if(n === 1) return { 1: 1 };\n    const res = {};\n    let p = 2\n    while(n >= p*p) {\n        if(n % p === 0) {\n            res[p] = divideTimes(n,p);\n            n /= Math.pow(p, res[p]);\n        } else {\n            p++\n        }\n    }\n    if(n > 1) {\n        res[n] = 1;\n    }\n    return res;\n}\n\nPomijanie powtarzających się czynników w mnożeniu\nW drugim kroku algorytmu mamy pomijanie powtarzających się czynników. Pokażę to\nna przykładzie.\n\nLiczba 54 to 2 * 3^3, a 76 to 2^2 * 19. Ich najmniejsza wspólna wielokrotność to\niloczyn 2^2 ( tu wybieramy większą potęgę ) oraz 3^3 i 19, tu wybieramy\nrozłączne dzielniki ( w ogólności też jest to wyższa potęga ).\n\nFunkcję, która będzie wykonywała operację wyliczania największej wspólnej\nwielokrotności dla pary liczb nazwiemy\n\nfunction mergeKeysChoosingMaxValue(prev, next) {\n    for(let key of Object.keys(next)) {\n        if(prev.hasOwnProperty(key)) {\n            prev[key] = Math.max(prev[key], next[key]);\n        } else {\n            prev[key] = next[key];\n        }\n    }\n    return prev;\n}\n\nEwaluacja wartości liczby z jej czynników\nNa koniec chcemy użytkownikowi wyświetlać liczby a nie ich rozkłady na czynniki,\nwięc przejdziemy z formatu rozłożonego na czystą wartość liczbową\n\nfunction evaluate(object) {\n    return Object.keys(object).reduce((prev, key) => {\n        return prev * Math.pow(Number(key), object[key]);\n    },1)\n}\n\nIntegracja rozwiązania z formatem wejścia i wyjścia programu\nZostało nam jeszcze podłączenie napisanych przez nas części składowych do\nwymaganego przez zadanie formatu wejścia i wyjścia. Pierwsza część kodu\nodczytuje dane ze standardowego strumienia i uruchamia na nich funkcję main\n\nprocess.stdin.resume();\nprocess.stdin.setEncoding(\"utf-8\");\nlet stdin_input = \"\";\n\nprocess.stdin.on(\"data\", function (input) {\n    stdin_input += input;\n});\n\nprocess.stdin.on(\"end\", function () {\n   main(stdin_input);\n});\n\nDruga część składa się z kodu przetwarzającego linie tekstu na tablice liczb w\nfunkcji main i wykonującego zadanie w funkcji minCommonDiv.\n\nfunction minCommonDiv(k) {\n    const factorized = k.map(primeFactors);\n    return evaluate(factorized.reduce(mergeKeysChoosingMaxValue))\n}\n\nfunction main(input) {\n    const lines = input.split('\\n').filter(line => Boolean(line));\n    const T = Number.parseInt(lines.shift());\n    const out = [];\n    for(let i=0; i<T; i++) {\n        lines.shift();\n        const k = lines.shift().split(/\\s+/).map(n => Number.parseInt(n));\n        const res = minCommonDiv(k);\n        out.push(res);\n    }\n\n    process.stdout.write(out.join(\"\\n\") + \"\\n\");\n}\n\nProgram przy założeniu, że wejście zapiszemy do input.txt a program do app.js,\nnasze rozwiązanie możemy sprawdzić poleceniem:\n\ncat input.txt | node app.js",
            "feature_image": "__GHOST_URL__/content/images/2021/11/download--1-.jpeg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-11-16T11:15:59.000Z",
            "updated_at": "2021-11-22T14:38:00.000Z",
            "published_at": "2021-11-22T14:38:00.000Z",
            "custom_excerpt": "Rozwiązanie zadania \"Archery\" z działu \"Teoria Liczb\" serwisu \"Hacker Earth\". Zadanie polega na wyznaczeniu najmniejszej wspólnej wielokrotności ciągu liczb.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "61b342b650caaa182e07f79d",
            "uuid": "db068789-57ac-46ef-83d1-6d985b78fb75",
            "title": "Cookie Ws",
            "slug": "cookie-ws",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"npm init vite@latest . -- --template vue\\n\\nnest new .\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<pre><code>npm init vite@latest . -- --template vue\n\nnest new .</code></pre>",
            "comment_id": "61b342b650caaa182e07f79d",
            "plaintext": "npm init vite@latest . -- --template vue\n\nnest new .",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2021-12-10T12:06:14.000Z",
            "updated_at": "2021-12-10T12:06:33.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "61f5914f50caaa182e07f7a8",
            "uuid": "d5e5a07e-9647-4b50-b011-90e3ae46e745",
            "title": "Publikacja aktualizacji paczki w repozytorium AUR",
            "slug": "aktualizacja-paczki-aur",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://aur.archlinux.org/\",\"metadata\":{\"url\":\"https://aur.archlinux.org/\",\"title\":\"AUR (en) - Home\",\"description\":null,\"author\":null,\"publisher\":\"Home\",\"thumbnail\":\"https://aur.archlinux.org/images/rss.svg\",\"icon\":\"https://aur.archlinux.org/images/favicon.ico\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/01/2022-01-29_20-17.png\",\"width\":1895,\"height\":1147}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://aur.archlinux.org/packages/infinitywallet/\",\"metadata\":{\"url\":\"https://aur.archlinux.org/packages/infinitywallet/\",\"title\":\"AUR (en) - infinitywallet\",\"description\":\"Digital asset wallet\",\"author\":null,\"publisher\":\"infinitywallet\",\"thumbnail\":null,\"icon\":\"https://aur.archlinux.org/images/favicon.ico\"}}],[\"code\",{\"code\":\"git clone ssh://aur@aur.archlinux.org/infinitywallet.git\"}],[\"code\",{\"code\":\"infinitywallet.install  - hooki zakładane na operacje dookoła instalacji\\nPKGBUILD                - konfiguracja źródeł instalcji\\n.SRCINFO                - metadane pakietu generowane atuomatycznie\"}],[\"code\",{\"code\":\"pkgname=infinitywallet\\npkgver=1.2.1beta\\npkgrel=10\\npkgdesc=\\\"Digital asset wallet\\\"\\narch=('x86_64')\\nurl=\\\"https://infinitywallet.io\\\"\\ndepends=('gtk3' 'libnotify' 'nss' 'libxss' 'libxtst' 'xdg-utils' 'at-spi2-core' 'util-linux-libs' 'libappindicator-gtk3' 'libsecret')\\noptions=('!strip' '!emptydirs')\\ninstall=${pkgname}.install\\nsource_x86_64=(\\\"https://github.com/InfinityWallet/Releases/releases/download/v1.2.1-beta/InfinityWallet_1.2.1-beta.deb\\\")\\nsha512sums_x86_64=('f36da80cdc3d35bf6d83e573240f92ea115ab03fe7ec3b5acd699bce999df6d5e81a8ab1966ad8977773bbba2710e3fb6fba0229c3195262cd698e938fd864de')\\n\\npackage(){\\n\\n\\t# Extract package data\\n\\ttar xf data.tar.xz -C \\\"${pkgdir}\\\"\\n\\n\\tinstall -D -m644 \\\"${pkgdir}/opt/InfinityWallet/resources/app.asar.unpacked/node_modules/phantomjs-prebuilt/LICENSE.txt\\\" \\\"${pkgdir}/usr/share/licenses/${pkgname}/LICENSE\\\"\\n\\n}\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/InfinityWallet/Releases/releases\",\"metadata\":{\"url\":\"https://github.com/InfinityWallet/Releases/releases\",\"title\":\"Releases · InfinityWallet/Releases\",\"description\":\"The official Infinity Wallet releases for desktop. Contribute to InfinityWallet/Releases development by creating an account on GitHub.\",\"author\":\"InfinityWallet\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/35c9d7d692036ba82a86d7902eb4aa0e971f98303fbf7e3d573a97a339c532b2/InfinityWallet/Releases\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/01/2022-01-29_20-37.png\",\"width\":1895,\"height\":1147}],[\"code\",{\"code\":\"https://github.com/InfinityWallet/Releases/releases/download/v1.4.0-beta/InfinityWallet_1.4.0-beta.deb\"}],[\"code\",{\"code\":\"wget https://github.com/InfinityWallet/Releases/releases/download/v1.4.0-beta/InfinityWallet_1.4.0-beta.deb -O /tmp/iw.deb\"}],[\"code\",{\"code\":\"sha512sum /tmp/iw.deb\"}],[\"code\",{\"code\":\"makepkg --printsrcinfo > .SRCINFO\"}],[\"code\",{\"code\":\"makepkg -si\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/01/DbWRSGGVAAAzWgb.jpg\",\"width\":500,\"height\":610}],[\"code\",{\"code\":\" git commit -a -m \\\"Release v1.4.0-beta\\\"\"}],[\"code\",{\"code\":\"git push origin master\"}],[\"hr\",{}]],\"markups\":[[\"code\"],[\"a\",[\"href\",\"mailto:aur@aur.archlinux.org\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Znalazłem w repozytorium aur paczkę, która nie jest regularnie aktualizowana. Nauczyłem się jak mogę ją utrzymywać i ten wpis pozwoli Ci przejść przez wszystkie kroki potrzebne do tego, żebyś sam mógł utrzymywać lub publikować pakiety w repozytorium użytkowników Arch Linux.\"]]],[1,\"h3\",[[0,[],0,\"Załóż konto w aur\"]]],[1,\"p\",[[0,[],0,\"Po założeniu konta na stronie\"]]],[10,0],[1,\"p\",[[0,[],0,\"przejdź do zakładki \\\"moje konto\\\" i uzupełnij \\\"Klucz publiczny SSH\\\"\"]]],[10,1],[1,\"h3\",[[0,[],0,\"Pobierz paczkę, którą chcesz zaktualizować\"]]],[1,\"p\",[[0,[],0,\"W naszym przypadku aktualizujemy \"],[0,[0],1,\"infinitywallet\"],[0,[],0,\".\"]]],[10,2],[1,\"p\",[[0,[],0,\"Pobieramy repozytorium komendą\"]]],[10,3],[1,\"p\",[[0,[],0,\"Znajdują się w nim trzy pliki:\"]]],[10,4],[1,\"h3\",[[0,[],0,\"Zaktualizuj \\\"source\\\" w \\\"PKGBUILD\\\"\"]]],[1,\"p\",[[0,[],0,\"W pliku \"],[0,[0],1,\"PKGBUILD\"]]],[10,5],[1,\"p\",[[0,[],0,\"mamy informację o źródle. Jest to wersja z Ubuntu/Debiana o numerze 1.2.1.\"]]],[1,\"p\",[[0,[],0,\"Tym czasem pod linkiem z wydaniami z Githuba mamy wersję 1.4.0\"]]],[10,6],[10,7],[1,\"p\",[[0,[],0,\"A wersję dla Debiana znajdziemy pod adresem\"]]],[10,8],[1,\"p\",[[0,[],0,\"Po ustawieniu tej wartości pod kluczem \"],[0,[0],1,\"source_x86_64\"],[0,[],0,\" w \"],[0,[0],1,\"PKGBUILD\"],[0,[],0,\" powinniśmy przeliczyć sumę kontrolną \"],[0,[0],1,\"sha512sums_x86_64\"],[0,[],0,\". Możemy użyć linii komend do pobrania paczki\"]]],[10,9],[1,\"p\",[[0,[],0,\"i wyliczenia sumy kontrolnej\"]]],[10,10],[1,\"p\",[[0,[],0,\"wklejamy ją do pliku \"],[0,[0],1,\"PKGBUILD\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Na końcu zmieniamy opis wersji w \"],[0,[0],1,\"pkgver\"],[0,[],0,\" i podnosimy o jeden \"],[0,[0],1,\"pkgrel\"],[0,[],0,\".\"]]],[1,\"h3\",[[0,[],0,\"Generujemy \"],[0,[0],1,\".SRCINFO\"]]],[1,\"p\",[[0,[],0,\"Plik z metadanymi możemy przebudować komendą\"]]],[10,11],[1,\"h3\",[[0,[],0,\"Testujemy instalację paczki lokalnie\"]]],[1,\"p\",[[0,[],0,\"Możemy sprawdzić czy instalacja przebiega pomyślnie wpisując\"]]],[10,12],[10,13],[1,\"h3\",[[0,[],0,\"Wysyłamy zmiany do repozytorium\"]]],[1,\"p\",[[0,[],0,\"Tworzymy nowy commit\"]]],[10,14],[1,\"p\",[[0,[],0,\"i wysyłamy zmiany na głąź \\\"master\\\"\"]]],[10,15],[1,\"p\",[[0,[],0,\"To wszystko. Nasza aktualizacja jest już publicznie dostępna.\"]]],[10,16],[1,\"h2\",[[0,[],0,\"Kluczowe kroki w publikowaniu pakietu AUR:\"]]],[3,\"ul\",[[[0,[],0,\"twój klucz publiczny ssh musi się zgadzać z tym w koncie aur\"]],[[0,[],0,\"repo ma mieć adres ssh://\"],[0,[1],1,\"aur@aur.archlinux.org\"],[0,[],0,\"/package.git\"]],[[0,[],0,\"musisz podbić zarówno opis jak i numer wersji\"]],[[0,[],0,\"programem sha512sum wyliczasz sumę kontrolną\"]],[[0,[],0,\"poza PKGBUILD jest jeszcze plik .SRCINFO tworzony przez \"],[0,[0],1,\"makepkg --printsrcinfo > .SRCINFO\"]],[[0,[],0,\"lokalnie możesz przetestować instalację poleceniem \"],[0,[0],1,\"makepkg -si\"]],[[0,[],0,\"na końcu wysyłasz zmiany na master\"]]]],[1,\"p\",[[0,[],0,\"Jeśli ktoś z Was będzie wrzucał paczki na AUR i napotkacie jakieś problemy - piszcie, chętnie pomogę.\"]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Znalazłem w repozytorium aur paczkę, która nie jest regularnie aktualizowana. Nauczyłem się jak mogę ją utrzymywać i ten wpis pozwoli Ci przejść przez wszystkie kroki potrzebne do tego, żebyś sam mógł utrzymywać lub publikować pakiety w repozytorium użytkowników Arch Linux.</p><h3 id=\"za%C5%82%C3%B3%C5%BC-konto-w-aur\">Załóż konto w aur</h3><p>Po założeniu konta na stronie</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aur.archlinux.org/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AUR (en) - Home</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://aur.archlinux.org/images/favicon.ico\"><span class=\"kg-bookmark-author\">Home</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://aur.archlinux.org/images/rss.svg\"></div></a></figure><p>przejdź do zakładki \"moje konto\" i uzupełnij \"Klucz publiczny SSH\"</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/01/2022-01-29_20-17.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1895\" height=\"1147\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/01/2022-01-29_20-17.png 600w, __GHOST_URL__/content/images/size/w1000/2022/01/2022-01-29_20-17.png 1000w, __GHOST_URL__/content/images/size/w1600/2022/01/2022-01-29_20-17.png 1600w, __GHOST_URL__/content/images/2022/01/2022-01-29_20-17.png 1895w\" sizes=\"(min-width: 720px) 720px\"></figure><h3 id=\"pobierz-paczk%C4%99-kt%C3%B3r%C4%85-chcesz-zaktualizowa%C4%87\">Pobierz paczkę, którą chcesz zaktualizować</h3><p>W naszym przypadku aktualizujemy <code>infinitywallet</code>.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://aur.archlinux.org/packages/infinitywallet/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">AUR (en) - infinitywallet</div><div class=\"kg-bookmark-description\">Digital asset wallet</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://aur.archlinux.org/images/favicon.ico\"><span class=\"kg-bookmark-author\">infinitywallet</span></div></div></a></figure><p>Pobieramy repozytorium komendą</p><pre><code>git clone ssh://aur@aur.archlinux.org/infinitywallet.git</code></pre><p>Znajdują się w nim trzy pliki:</p><pre><code>infinitywallet.install  - hooki zakładane na operacje dookoła instalacji\nPKGBUILD                - konfiguracja źródeł instalcji\n.SRCINFO                - metadane pakietu generowane atuomatycznie</code></pre><h3 id=\"zaktualizuj-source-w-pkgbuild\">Zaktualizuj \"source\" w \"PKGBUILD\"</h3><p>W pliku <code>PKGBUILD</code></p><pre><code>pkgname=infinitywallet\npkgver=1.2.1beta\npkgrel=10\npkgdesc=\"Digital asset wallet\"\narch=('x86_64')\nurl=\"https://infinitywallet.io\"\ndepends=('gtk3' 'libnotify' 'nss' 'libxss' 'libxtst' 'xdg-utils' 'at-spi2-core' 'util-linux-libs' 'libappindicator-gtk3' 'libsecret')\noptions=('!strip' '!emptydirs')\ninstall=${pkgname}.install\nsource_x86_64=(\"https://github.com/InfinityWallet/Releases/releases/download/v1.2.1-beta/InfinityWallet_1.2.1-beta.deb\")\nsha512sums_x86_64=('f36da80cdc3d35bf6d83e573240f92ea115ab03fe7ec3b5acd699bce999df6d5e81a8ab1966ad8977773bbba2710e3fb6fba0229c3195262cd698e938fd864de')\n\npackage(){\n\n\t# Extract package data\n\ttar xf data.tar.xz -C \"${pkgdir}\"\n\n\tinstall -D -m644 \"${pkgdir}/opt/InfinityWallet/resources/app.asar.unpacked/node_modules/phantomjs-prebuilt/LICENSE.txt\" \"${pkgdir}/usr/share/licenses/${pkgname}/LICENSE\"\n\n}</code></pre><p>mamy informację o źródle. Jest to wersja z Ubuntu/Debiana o numerze 1.2.1.</p><p>Tym czasem pod linkiem z wydaniami z Githuba mamy wersję 1.4.0</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/InfinityWallet/Releases/releases\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Releases · InfinityWallet/Releases</div><div class=\"kg-bookmark-description\">The official Infinity Wallet releases for desktop. Contribute to InfinityWallet/Releases development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">InfinityWallet</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/35c9d7d692036ba82a86d7902eb4aa0e971f98303fbf7e3d573a97a339c532b2/InfinityWallet/Releases\"></div></a></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/01/2022-01-29_20-37.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1895\" height=\"1147\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/01/2022-01-29_20-37.png 600w, __GHOST_URL__/content/images/size/w1000/2022/01/2022-01-29_20-37.png 1000w, __GHOST_URL__/content/images/size/w1600/2022/01/2022-01-29_20-37.png 1600w, __GHOST_URL__/content/images/2022/01/2022-01-29_20-37.png 1895w\" sizes=\"(min-width: 720px) 720px\"></figure><p>A wersję dla Debiana znajdziemy pod adresem</p><pre><code>https://github.com/InfinityWallet/Releases/releases/download/v1.4.0-beta/InfinityWallet_1.4.0-beta.deb</code></pre><p>Po ustawieniu tej wartości pod kluczem <code>source_x86_64</code> w <code>PKGBUILD</code> powinniśmy przeliczyć sumę kontrolną <code>sha512sums_x86_64</code>. Możemy użyć linii komend do pobrania paczki</p><pre><code>wget https://github.com/InfinityWallet/Releases/releases/download/v1.4.0-beta/InfinityWallet_1.4.0-beta.deb -O /tmp/iw.deb</code></pre><p>i wyliczenia sumy kontrolnej</p><pre><code>sha512sum /tmp/iw.deb</code></pre><p>wklejamy ją do pliku <code>PKGBUILD</code>.</p><p>Na końcu zmieniamy opis wersji w <code>pkgver</code> i podnosimy o jeden <code>pkgrel</code>.</p><h3 id=\"generujemy-srcinfo\">Generujemy <code>.SRCINFO</code></h3><p>Plik z metadanymi możemy przebudować komendą</p><pre><code>makepkg --printsrcinfo &gt; .SRCINFO</code></pre><h3 id=\"testujemy-instalacj%C4%99-paczki-lokalnie\">Testujemy instalację paczki lokalnie</h3><p>Możemy sprawdzić czy instalacja przebiega pomyślnie wpisując</p><pre><code>makepkg -si</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/01/DbWRSGGVAAAzWgb.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"500\" height=\"610\"></figure><h3 id=\"wysy%C5%82amy-zmiany-do-repozytorium\">Wysyłamy zmiany do repozytorium</h3><p>Tworzymy nowy commit</p><pre><code> git commit -a -m \"Release v1.4.0-beta\"</code></pre><p>i wysyłamy zmiany na głąź \"master\"</p><pre><code>git push origin master</code></pre><p>To wszystko. Nasza aktualizacja jest już publicznie dostępna.</p><hr><h2 id=\"kluczowe-kroki-w-publikowaniu-pakietu-aur\">Kluczowe kroki w publikowaniu pakietu AUR:</h2><ul><li>twój klucz publiczny ssh musi się zgadzać z tym w koncie aur</li><li>repo ma mieć adres ssh://<a href=\"mailto:aur@aur.archlinux.org\">aur@aur.archlinux.org</a>/package.git</li><li>musisz podbić zarówno opis jak i numer wersji</li><li>programem sha512sum wyliczasz sumę kontrolną</li><li>poza PKGBUILD jest jeszcze plik .SRCINFO tworzony przez <code>makepkg --printsrcinfo &gt; .SRCINFO</code></li><li>lokalnie możesz przetestować instalację poleceniem <code>makepkg -si</code></li><li>na końcu wysyłasz zmiany na master</li></ul><p>Jeśli ktoś z Was będzie wrzucał paczki na AUR i napotkacie jakieś problemy - piszcie, chętnie pomogę.</p>",
            "comment_id": "61f5914f50caaa182e07f7a8",
            "plaintext": "Znalazłem w repozytorium aur paczkę, która nie jest regularnie aktualizowana.\nNauczyłem się jak mogę ją utrzymywać i ten wpis pozwoli Ci przejść przez\nwszystkie kroki potrzebne do tego, żebyś sam mógł utrzymywać lub publikować\npakiety w repozytorium użytkowników Arch Linux.\n\nZałóż konto w aur\nPo założeniu konta na stronie\n\nAUR (en) - HomeHome [https://aur.archlinux.org/]przejdź do zakładki \"moje konto\"\ni uzupełnij \"Klucz publiczny SSH\"\n\nPobierz paczkę, którą chcesz zaktualizować\nW naszym przypadku aktualizujemy infinitywallet.\n\nAUR (en) - infinitywalletDigital asset walletinfinitywallet\n[https://aur.archlinux.org/packages/infinitywallet/]Pobieramy repozytorium\nkomendą\n\ngit clone ssh://aur@aur.archlinux.org/infinitywallet.git\n\nZnajdują się w nim trzy pliki:\n\ninfinitywallet.install  - hooki zakładane na operacje dookoła instalacji\nPKGBUILD                - konfiguracja źródeł instalcji\n.SRCINFO                - metadane pakietu generowane atuomatycznie\n\nZaktualizuj \"source\" w \"PKGBUILD\"\nW pliku PKGBUILD\n\npkgname=infinitywallet\npkgver=1.2.1beta\npkgrel=10\npkgdesc=\"Digital asset wallet\"\narch=('x86_64')\nurl=\"https://infinitywallet.io\"\ndepends=('gtk3' 'libnotify' 'nss' 'libxss' 'libxtst' 'xdg-utils' 'at-spi2-core' 'util-linux-libs' 'libappindicator-gtk3' 'libsecret')\noptions=('!strip' '!emptydirs')\ninstall=${pkgname}.install\nsource_x86_64=(\"https://github.com/InfinityWallet/Releases/releases/download/v1.2.1-beta/InfinityWallet_1.2.1-beta.deb\")\nsha512sums_x86_64=('f36da80cdc3d35bf6d83e573240f92ea115ab03fe7ec3b5acd699bce999df6d5e81a8ab1966ad8977773bbba2710e3fb6fba0229c3195262cd698e938fd864de')\n\npackage(){\n\n\t# Extract package data\n\ttar xf data.tar.xz -C \"${pkgdir}\"\n\n\tinstall -D -m644 \"${pkgdir}/opt/InfinityWallet/resources/app.asar.unpacked/node_modules/phantomjs-prebuilt/LICENSE.txt\" \"${pkgdir}/usr/share/licenses/${pkgname}/LICENSE\"\n\n}\n\nmamy informację o źródle. Jest to wersja z Ubuntu/Debiana o numerze 1.2.1.\n\nTym czasem pod linkiem z wydaniami z Githuba mamy wersję 1.4.0\n\nReleases · InfinityWallet/ReleasesThe official Infinity Wallet releases for\ndesktop. Contribute to InfinityWallet/Releases development by creating an\naccount on GitHub.GitHubInfinityWallet\n[https://github.com/InfinityWallet/Releases/releases]A wersję dla Debiana\nznajdziemy pod adresem\n\nhttps://github.com/InfinityWallet/Releases/releases/download/v1.4.0-beta/InfinityWallet_1.4.0-beta.deb\n\nPo ustawieniu tej wartości pod kluczem source_x86_64 w PKGBUILD powinniśmy\nprzeliczyć sumę kontrolną sha512sums_x86_64. Możemy użyć linii komend do\npobrania paczki\n\nwget https://github.com/InfinityWallet/Releases/releases/download/v1.4.0-beta/InfinityWallet_1.4.0-beta.deb -O /tmp/iw.deb\n\ni wyliczenia sumy kontrolnej\n\nsha512sum /tmp/iw.deb\n\nwklejamy ją do pliku PKGBUILD.\n\nNa końcu zmieniamy opis wersji w pkgver i podnosimy o jeden pkgrel.\n\nGenerujemy .SRCINFO\nPlik z metadanymi możemy przebudować komendą\n\nmakepkg --printsrcinfo > .SRCINFO\n\nTestujemy instalację paczki lokalnie\nMożemy sprawdzić czy instalacja przebiega pomyślnie wpisując\n\nmakepkg -si\n\nWysyłamy zmiany do repozytorium\nTworzymy nowy commit\n\n git commit -a -m \"Release v1.4.0-beta\"\n\ni wysyłamy zmiany na głąź \"master\"\n\ngit push origin master\n\nTo wszystko. Nasza aktualizacja jest już publicznie dostępna.\n\n\n--------------------------------------------------------------------------------\n\nKluczowe kroki w publikowaniu pakietu AUR:\n * twój klucz publiczny ssh musi się zgadzać z tym w koncie aur\n * repo ma mieć adres ssh://aur@aur.archlinux.org/package.git\n * musisz podbić zarówno opis jak i numer wersji\n * programem sha512sum wyliczasz sumę kontrolną\n * poza PKGBUILD jest jeszcze plik .SRCINFO tworzony przez makepkg\n   --printsrcinfo > .SRCINFO\n * lokalnie możesz przetestować instalację poleceniem makepkg -si\n * na końcu wysyłasz zmiany na master\n\nJeśli ktoś z Was będzie wrzucał paczki na AUR i napotkacie jakieś problemy -\npiszcie, chętnie pomogę.",
            "feature_image": "__GHOST_URL__/content/images/2022/01/209_159470772.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2022-01-29T19:11:11.000Z",
            "updated_at": "2022-01-29T20:34:39.000Z",
            "published_at": "2022-01-29T20:34:39.000Z",
            "custom_excerpt": "Naucz się jak publikować aktualizację pakietów w repozytorium użytkowników Arch Linux.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "626bb8c6d9c3ae6cbd852a37",
            "uuid": "f2a3659f-4640-4b00-9755-64a2286208cf",
            "title": "Invoice",
            "slug": "invoice",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"npx nuxi init invoice\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://v3.nuxtjs.org/getting-started/quick-start\",\"metadata\":{\"url\":\"https://v3.nuxtjs.org/getting-started/quick-start\",\"title\":\"Quick Start\",\"description\":\"Starting fresh? Getting started with Nuxt 3 is straightforward!\",\"author\":null,\"publisher\":\"Nuxt 3\",\"thumbnail\":\"https://res.cloudinary.com/nuxt/image/upload/v1650870623/nuxt3-rc-social_z6qh3m.png\",\"icon\":\"https://v3.nuxtjs.org/_nuxt/icons/icon_512x512.a3b4ce.png\"}}],[\"code\",{\"code\":\"npm install -D tailwindcss@latest postcss@latest autoprefixer@latest\"}],[\"code\",{\"code\":\"npx tailwindcss init\\n\"}],[\"code\",{\"code\":\"  mode: \\\"jit\\\",\\n  purge: [\\n    \\\"./components/**/*.{vue,js}\\\",\\n    \\\"./layouts/**/*.vue\\\",\\n    \\\"./pages/**/*.vue\\\",\\n    \\\"./plugins/**/*.{js,ts}\\\",\\n    \\\"./nuxt.config.{js,ts}\\\",\\n  ],\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://www.netlify.com/blog/2021/10/29/pairing-nuxt-3-with-tailwindcss-and-supabase/\",\"metadata\":{\"url\":\"https://www.netlify.com/blog/2021/10/29/pairing-nuxt-3-with-tailwindcss-and-supabase/\",\"title\":\"Learn how to work with with TailwindCSS and Supabase in Nuxt 3 projects\",\"description\":\"Learn how to work with TailwindCSS and Supabase in Nuxt 3 projects\",\"author\":null,\"publisher\":\"Netlify\",\"thumbnail\":\"https://cdn.sanity.io/images/o0o2tn5x/production/d03a863f95cb7ddea9fc5d0728f9ceb4a4070055-1200x630.png\",\"icon\":\"https://www.netlify.com/v3/static/favicon/apple-touch-icon.png\"}}],[\"code\",{\"code\":\"@tailwind base;\\n@tailwind components;\\n@tailwind utilities;\"}],[\"code\",{\"code\":\"css: [\\\"~/assets/css/tailwind.css\\\"],\\n  build: {\\n    postcss: {\\n      postcssOptions: {\\n        plugins: {\\n          tailwindcss: {},\\n          autoprefixer: {},\\n        },\\n      },\\n    },\\n  },\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://dev.to/codybontecou/nuxt-3-and-pinia-473k\",\"metadata\":{\"url\":\"https://dev.to/codybontecou/nuxt-3-and-pinia-473k\",\"title\":\"Nuxt 3 and Pinia\",\"description\":\"Nuxt 3 and Pinia Integrate Pinia as your state management library for your Nuxt 3...\",\"author\":\"Cody Bontecou\",\"publisher\":\"DEV Community\",\"thumbnail\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--ZZtn-zfC--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://img.bloggu.io/ipfs/bafybeihgd7x2p7k7c6iws3v44w4pafegu5ezr4uvoj2rtadw63multtreq\",\"icon\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--t7tVouP9--/c_limit,f_png,fl_progressive,q_80,w_192/https://practicaldev-herokuapp-com.freetls.fastly.net/assets/devlogo-pwa-512.png\"}}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[10,5],[1,\"p\",[[0,[],0,\"assets/css/tailwind.css\"]]],[10,6],[1,\"p\",[[0,[],0,\"nuxt.config\"]]],[10,7],[10,8],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<pre><code>npx nuxi init invoice</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://v3.nuxtjs.org/getting-started/quick-start\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Quick Start</div><div class=\"kg-bookmark-description\">Starting fresh? Getting started with Nuxt 3 is straightforward!</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://v3.nuxtjs.org/_nuxt/icons/icon_512x512.a3b4ce.png\"><span class=\"kg-bookmark-author\">Nuxt 3</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://res.cloudinary.com/nuxt/image/upload/v1650870623/nuxt3-rc-social_z6qh3m.png\"></div></a></figure><pre><code>npm install -D tailwindcss@latest postcss@latest autoprefixer@latest</code></pre><pre><code>npx tailwindcss init\n</code></pre><pre><code>  mode: \"jit\",\n  purge: [\n    \"./components/**/*.{vue,js}\",\n    \"./layouts/**/*.vue\",\n    \"./pages/**/*.vue\",\n    \"./plugins/**/*.{js,ts}\",\n    \"./nuxt.config.{js,ts}\",\n  ],</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://www.netlify.com/blog/2021/10/29/pairing-nuxt-3-with-tailwindcss-and-supabase/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Learn how to work with with TailwindCSS and Supabase in Nuxt 3 projects</div><div class=\"kg-bookmark-description\">Learn how to work with TailwindCSS and Supabase in Nuxt 3 projects</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://www.netlify.com/v3/static/favicon/apple-touch-icon.png\"><span class=\"kg-bookmark-author\">Netlify</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://cdn.sanity.io/images/o0o2tn5x/production/d03a863f95cb7ddea9fc5d0728f9ceb4a4070055-1200x630.png\"></div></a></figure><p>assets/css/tailwind.css</p><pre><code>@tailwind base;\n@tailwind components;\n@tailwind utilities;</code></pre><p>nuxt.config</p><pre><code>css: [\"~/assets/css/tailwind.css\"],\n  build: {\n    postcss: {\n      postcssOptions: {\n        plugins: {\n          tailwindcss: {},\n          autoprefixer: {},\n        },\n      },\n    },\n  },</code></pre><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://dev.to/codybontecou/nuxt-3-and-pinia-473k\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Nuxt 3 and Pinia</div><div class=\"kg-bookmark-description\">Nuxt 3 and Pinia Integrate Pinia as your state management library for your Nuxt 3...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--t7tVouP9--/c_limit,f_png,fl_progressive,q_80,w_192/https://practicaldev-herokuapp-com.freetls.fastly.net/assets/devlogo-pwa-512.png\"><span class=\"kg-bookmark-author\">DEV Community</span><span class=\"kg-bookmark-publisher\">Cody Bontecou</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--ZZtn-zfC--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://img.bloggu.io/ipfs/bafybeihgd7x2p7k7c6iws3v44w4pafegu5ezr4uvoj2rtadw63multtreq\"></div></a></figure>",
            "comment_id": "626bb8c6d9c3ae6cbd852a37",
            "plaintext": "npx nuxi init invoice\n\nQuick StartStarting fresh? Getting started with Nuxt 3 is straightforward!Nuxt 3\n[https://v3.nuxtjs.org/getting-started/quick-start]npm install -D tailwindcss@latest postcss@latest autoprefixer@latest\n\nnpx tailwindcss init\n\n\n  mode: \"jit\",\n  purge: [\n    \"./components/**/*.{vue,js}\",\n    \"./layouts/**/*.vue\",\n    \"./pages/**/*.vue\",\n    \"./plugins/**/*.{js,ts}\",\n    \"./nuxt.config.{js,ts}\",\n  ],\n\nLearn how to work with with TailwindCSS and Supabase in Nuxt 3 projectsLearn\nhow\nto work with TailwindCSS and Supabase in Nuxt 3 projectsNetlify\n[https://www.netlify.com/blog/2021/10/29/pairing-nuxt-3-with-tailwindcss-and-supabase/]\nassets/css/tailwind.css\n\n@tailwind base;\n@tailwind components;\n@tailwind utilities;\n\nnuxt.config\n\ncss: [\"~/assets/css/tailwind.css\"],\n  build: {\n    postcss: {\n      postcssOptions: {\n        plugins: {\n          tailwindcss: {},\n          autoprefixer: {},\n        },\n      },\n    },\n  },\n\nNuxt 3 and PiniaNuxt 3 and Pinia Integrate Pinia as your state management\nlibrary for your Nuxt 3...DEV CommunityCody Bontecou\n[https://dev.to/codybontecou/nuxt-3-and-pinia-473k]",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2022-04-29T10:07:02.000Z",
            "updated_at": "2022-04-29T13:32:03.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "62a3415fd9c3ae6cbd852a52",
            "uuid": "548fc56d-1360-4631-8f90-05db4b6b89ad",
            "title": "Retry Policy - Jak obsługiwać losowe, nieprzewidywalne błędy",
            "slug": "retry-policy",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/do-nothing-and-5cd529.jpg\",\"width\":600,\"height\":600}],[\"code\",{\"code\":\"class Rectangle {\\n    a: number\\n    b: number\\n\\n    constructor(a: number, b: number) {\\n        this.a = a;\\n        this.b = b;\\n    }\\n\\n    async field(n: number) {\\n        if (Math.random() > n) {\\n            return this.a * this.b\\n        } else {\\n            throw new Error(`Random Fail`);\\n        }\\n    }\\n}\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"async function main() {\\n    const rec = new Rectangle(1, 2);\\n    const res = {\\n        ok: 0,\\n        fail: 0\\n    }\\n\\n    for (let i = 0; i < 10000; i++) {\\n        try {\\n            await rec.field(0.1);\\n            res.ok++;\\n        } catch {\\n            res.fail++;\\n        }\\n    }\\n\\n    console.log(res);\\n}\\n\\nmain().catch(console.error)\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"{ ok: 9035, fail: 965 }\",\"language\":\"json\"}],[\"code\",{\"code\":\"import {retryAsyncDecorator} from \\\"ts-retry/lib/cjs/retry/decorators\\\";\\nimport { RetryOptions} from \\\"ts-retry\\\";\\n\\nexport function retryPolicy<T>(obj: any, policy: RetryOptions): T {\\n    return new Proxy(obj, {\\n        get(target, handler) {\\n            if (handler in target) {\\n                if (handler === 'field') {\\n                    return retryAsyncDecorator(target[handler].bind(target), policy)\\n                }\\n                return target[handler];\\n            }\\n        }\\n    })\\n}\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"const rec = new Rectangle(1, 2);\\n\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"const rec = retryPolicy<Rectangle>(new Rectangle(1, 2), {maxTry: 6, delay: 0});\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"{ ok: 10000, fail: 0 }\",\"language\":\"json\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/1640209265.jpeg\",\"width\":860,\"height\":721}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/41b3577486839d799e669632927cdd12.jpg\",\"width\":261,\"height\":213,\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/2022-06-10_19-03.png\",\"width\":1414,\"height\":1046}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"http://dthain.blogspot.com/2009/02/exponential-backoff-in-distributed.html\",\"metadata\":{\"url\":\"http://dthain.blogspot.com/2009/02/exponential-backoff-in-distributed.html\",\"title\":\"Exponential Backoff in Distributed Systems\",\"description\":\"In response to my previous article, a commenter asked: Why exponential backoff? To put a finer point on the question, How should I choose t...\",\"author\":\"Douglas Thain\",\"publisher\":\"Prof. Douglas Thain\",\"thumbnail\":\"http://4.bp.blogspot.com/_0DkxYiRVGyA/SaIUoVsKoqI/AAAAAAAAAC0/APiyDxuzvzs/w1200-h630-p-k-no-nu/ethernet.gif\",\"icon\":\"http://dthain.blogspot.com/favicon.ico\"}}],[\"code\",{\"code\":\"import {NotRetryableError, RetryConfig, retryDecorator} from \\\"ts-retry-promise\\\";\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"    async field(n: number, m: number) {\\n        if (Math.random() > n) {\\n            return this.a * this.b\\n        } else {\\n            if(Math.random() > m) {\\n                throw new Error(`Random Fail`);\\n            } else {\\n                throw new Error(`CRITICAL`);\\n            }\\n        }\\n    }\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"return retryAsyncDecorator(target[handler].bind(target), policy)\\n\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"return retryDecorator(rethrowNotRetryableErrors(target[handler].bind(target)), policy)\\n\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"import {types} from 'util';\\n\\nfunction rethrowNotRetryableErrors(fun: any):any {\\n    return (...args:any) => {\\n        return fun(...args).catch((err: unknown) => {\\n            if(types.isNativeError(err)) {\\n                if(err.message.includes('CRITICAL')) throw new NotRetryableError(err.message);\\n            }\\n            throw err;\\n        })\\n    }\\n}\",\"language\":\"typescript\"}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://github.com/gustawdaniel/blog-retry-policy\",\"metadata\":{\"url\":\"https://github.com/gustawdaniel/blog-retry-policy\",\"title\":\"GitHub - gustawdaniel/blog-retry-policy\",\"description\":\"Contribute to gustawdaniel/blog-retry-policy development by creating an account on GitHub.\",\"author\":\"gustawdaniel\",\"publisher\":\"GitHub\",\"thumbnail\":\"https://opengraph.githubassets.com/6f9afa0b36f147e1bb2f10a10dd4521b32ed20808119c9483a2e2659717a1b65/gustawdaniel/blog-retry-policy\",\"icon\":\"https://github.githubassets.com/favicons/favicon.svg\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/aQ3oz8r_700b.jpg\",\"width\":700,\"height\":674,\"cardWidth\":\"\"}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Czasami z szeregu różnych przyczyn programy komputerowe potrafią zwracać dziwne błędy, których odtworzenie jest niezwykle trudne, a naprawienie nie możliwe. Jeśli jednak poprawne działanie programu udaje się uzyskać w skończonej ilości ponownych jego uruchomień, może to stanowić optymalny sposób rozwiązania tego problemu.\"]]],[10,0],[1,\"p\",[[0,[],0,\"Ma to znaczenie, szczególnie w złożonych systemach, gdzie wiele potencjalnych źródeł błędów akumuluje się, a ponowna próba wywołania wadliwych funkcji pozwala obniżyć prawdopodobieństwo błędu podnosząc je do kwadratu.\"]]],[1,\"p\",[[0,[],0,\"W tym artykule pokarzę jak dzięki paczce \"],[0,[0],1,\"ts-retry\"],[0,[],0,\" oraz obiektowi \"],[0,[0],1,\"Proxy\"],[0,[],0,\", możesz podnieść stabilność swojego kodu i sprawić, że kod który prawie nigdy nie działał będzie zwracał błędy tylko czasami.\"]]],[1,\"h2\",[[0,[],0,\"Program zwracający losowe błędy\"]]],[1,\"p\",[[0,[],0,\"Zacznijmy od implementacji przykładowej klasy - Prostokąta, który z pewnym prawdopodobieństwem nie radzi sobie z obliczeniem swojego pola.\"]]],[10,1],[1,\"p\",[[0,[],0,\"Argumentem funkcji \"],[0,[0],1,\"field\"],[0,[],0,\" jest prawdopodobieństwo błędu.\"]]],[1,\"p\",[[0,[],0,\"Teraz zobaczmy jak wyglądało by użycie obiektu tej klasy i policzmy ilość błędów\"]]],[10,2],[1,\"p\",[[0,[],0,\"po włączeniu tej funkcji widzimy, że co mniej więcej dziesiąty wynik jest błędny\"]]],[10,3],[1,\"p\",[[0,[],0,\"Jest niemal pewne, że w 10.000 przypadków znajdziemy przynajmniej jeden błąd. Jeśli chcieli byśmy w 10.000 przypadków mieć prawdopodobieństwo błędu na poziomie 0.1% to musieli byśmy obniżyć szansę błędu pojedynczego wywołania z 10% do 0.000001%. czyli milion razy.\"]]],[1,\"p\",[[0,[],0,\"Okazuje się, że nie tylko jest to możliwe, ale nie zajmie nawet dużo czasu. Całkowity czas działania programu, stosującego metodę ponownego próbowania dla otrzymanych błędów liczymy jako \"]]],[1,\"p\",[[0,[],0,\"\\\\[ T = T_0 \\\\sum_{n=0}^{\\\\infty} p_e^n = T_0 \\\\exp(p_e) \\\\approx (1+p_e) T_0 \\\\] \"]]],[1,\"p\",[[0,[],0,\"W naszym przypadku będzie to oznaczało, że być może zdarzą się serie 6 nie udanych prób pod rząd, ale cały program zamiast zwracać błędy po prostu będzie działał średnio jedynie o 1/10 dłużej.\"]]],[1,\"h2\",[[0,[],0,\"Redukcja ilości błędów na wyjściu\"]]],[1,\"p\",[[0,[],0,\"Zainstalujmy paczkę \"],[0,[0],1,\"ts-retry\"],[0,[],0,\" i napiszmy następujący kod:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Funkcja \"],[0,[0],1,\"retryPolicy\"],[0,[],0,\" zwraca obiekt Proxy, który zachowuje się prawie tak jak nasza wejściowa klasa, ale dla funkcji \"],[0,[0],1,\"field\"],[0,[],0,\" zwraca handler, który wykonuje próby wywołania tej funkcji zgodnie z konfiguracją przekazaną do \"],[0,[0],1,\"retryPolicy\"],[0,[],0,\" jako drugi argument.\"]]],[1,\"p\",[[0,[],0,\"Jeśli teraz wrócimy do funkcji \"],[0,[0],1,\"main\"],[0,[],0,\" i zastąpimy:\"]]],[10,5],[1,\"p\",[[0,[],0,\"przez\"]]],[10,6],[1,\"p\",[[0,[],0,\"jest prawie pewne, że zobaczymy:\"]]],[10,7],[1,\"p\",[[0,[],0,\"Jeśli chcemy aby było to pewne, można zmienić \"],[0,[0],1,\"maxTry\"],[0,[],0,\" z \"],[0,[0],1,\"6\"],[0,[],0,\" na \"],[0,[0],1,\"Infinity\"],[0,[],0,\", ale tu jest pułapka. Taka wartość owszem obniżyła by szansę, że jakiś nie reprodukowalny, losowy błąd zepsuje nam wynik końcowy, ale wraz z każdą kolejną próbą rośnie szansa, że błąd, z którym mamy do czynienia wcale nie jest losowy i wcale nie zniknie wraz z kolejną iteracją.\"]]],[1,\"p\",[[0,[],0,\"Czasami przyczyną błędu może być brak dostępu do jakiegoś zasobu właśnie dlatego, że odpytujemy o niego zbyt często. Wtedy warto przy każdej kolejnej próbie czekać coraz dłużej. Często jednak trafimy na błędy, których nie można po prostu naprawić metodą \\\"wyłącz i spróbuj jeszcze raz\\\". W ich przypadku zbyt duża wartość \"],[0,[0],1,\"maxTry\"],[0,[],0,\" podnosi nam łączny czas poświęcony przez program na bezcelowe działania.\"]]],[10,8],[1,\"p\",[[0,[],0,\"Wobec trudności z pomiarem szans na błędy i ich kategoryzacją w wielu przypadkach zamiast wyliczać parametry \"],[0,[0],1,\"retry policy\"],[0,[],0,\" ustala się je intuicyjnie. \"]]],[1,\"p\",[[0,[],0,\"Bardzo rozsądne jest zróżnicowanie polityki retry w zależności od rodzaju błędu:\"]]],[10,9],[1,\"p\",[[0,[],0,\"Niestety paczka \"],[0,[0],1,\"ts-retry\"],[0,[],0,\" nie obsługuje ani \"],[0,[0],1,\"exponential backoff\"],[0,[],0,\" ani różnego traktowania np kodów błędów, które pomagają w decydowaniu co zrobić z tym błędem. Na szczęście od lat powstają bardziej rozbudowane paczki. Wśród nich najciekawsza wydaje się \"],[0,[0],1,\"ts-retry-promise\"],[0,[],0,\", która mimo niskiej popularności daje dobry kompromis między prostotą użycia a możliwością customizacji. \"]]],[10,10],[1,\"p\",[[0,[],0,\"Więcej o optymalnych strategiach \"],[0,[0],1,\"retry\"],[0,[],0,\" możesz przeczytać w artykule Prof. Douglas Thain - Exponential Backoff in Distributed Systems z 2009.\"]]],[10,11],[1,\"p\",[[0,[],0,\"Aby użyć \"],[0,[0],1,\"ts-retry-promise\"],[0,[],0,\" do importów dodamy:\"]]],[10,12],[1,\"p\",[[0,[],0,\"zmieniamy \"],[0,[0],1,\"maxTry\"],[0,[],0,\" na \"],[0,[0],1,\"retries\"],[0,[],0,\". Możemy ustawić \"],[0,[0],1,\"backoff\"],[0,[],0,\" na \"],[0,[0],1,\"EXPONENTIAL\"],[0,[],0,\" ale został nam jeszcze problem błędów, przy których chcieli byśmy się poddać bez walki.\"]]],[1,\"p\",[[0,[],0,\"Zmieńmy ciało funkcji field następująco\"]]],[10,13],[1,\"p\",[[0,[],0,\"teraz zwraca ono dwa rodzaje błędów, \"],[0,[0],1,\"Random Fail\"],[0,[],0,\" przy którym będziemy próbować ponownie (mógł by to być kod błędu 429) oraz \"],[0,[0],1,\"CRITICAL\"],[0,[],0,\" przy którym wiemy, że nie ma to sensu (np 401). \"]]],[1,\"p\",[[0,[],0,\"W \"],[0,[0],1,\"main\"],[0,[],0,\" funkcja \"],[0,[0],1,\"field\"],[0,[],0,\" przyjmuje teraz szansę błędu (n) oraz szansę, że jest to błąd krytyczny (m).\"]]],[1,\"p\",[[0,[],0,\"Bez dalszych zmian w \"],[0,[0],1,\"Rectangle\"],[0,[],0,\" i \"],[0,[0],1,\"main\"],[0,[],0,\" zmienimy w funkcji \"],[0,[0],1,\"retryPolicy\"],[0,[],0,\" linię\"]]],[10,14],[1,\"p\",[[0,[],0,\"na\"]]],[10,15],[1,\"p\",[[0,[],0,\"i dołożymy funkcję:\"]]],[10,16],[1,\"p\",[[0,[],0,\"Jej zadaniem jest ukrycie logiki translacji błędów zwracanych przez \"],[0,[0],1,\"Rectangle\"],[0,[],0,\" na takie, które różnią się sposobem obsługi w paczce \"],[0,[0],1,\"ts-retry-promise\"],[0,[],0,\". Dzięki temu zostawiając resztę kodu nie tkniętą możemy tu napisać, że nie będziemy próbować ponownych wywołań z błędami zawierającymi \"],[0,[0],1,\"CRITICAL\"],[0,[],0,\" w polu \"],[0,[0],1,\"message\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Prezentowany tu kod znajdziesz pod linkiem:\"]]],[10,17],[1,\"h2\",[[0,[],0,\"Co jeśli błędu nie da się obsłużyć\"]]],[1,\"p\",[[0,[],0,\"Wtedy trzeba poinformować użytkownika końcowego stosując się do następujących reguł:\"]]],[3,\"ul\",[[[0,[],0,\"nie można mu powiedzieć o błędzie za dużo, bo może być hackerem i to wykorzystać\"]],[[0,[],0,\"nie można mu powiedzieć za mało, bo w dziale supportu nie będzie dało się mu pomóc\"]],[[0,[],0,\"nie można w komunikacie błędu przyznać się, że kod nie działa... wiadomo dlaczego\"]],[[0,[],0,\"pozostaje wymieszać cynizm i szczerość z humorem i wyświetlić mu to:\"]]]],[10,18],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Czasami z szeregu różnych przyczyn programy komputerowe potrafią zwracać dziwne błędy, których odtworzenie jest niezwykle trudne, a naprawienie nie możliwe. Jeśli jednak poprawne działanie programu udaje się uzyskać w skończonej ilości ponownych jego uruchomień, może to stanowić optymalny sposób rozwiązania tego problemu.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/do-nothing-and-5cd529.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"600\" height=\"600\" srcset=\"__GHOST_URL__/content/images/2022/06/do-nothing-and-5cd529.jpg 600w\"></figure><p>Ma to znaczenie, szczególnie w złożonych systemach, gdzie wiele potencjalnych źródeł błędów akumuluje się, a ponowna próba wywołania wadliwych funkcji pozwala obniżyć prawdopodobieństwo błędu podnosząc je do kwadratu.</p><p>W tym artykule pokarzę jak dzięki paczce <code>ts-retry</code> oraz obiektowi <code>Proxy</code>, możesz podnieść stabilność swojego kodu i sprawić, że kod który prawie nigdy nie działał będzie zwracał błędy tylko czasami.</p><h2 id=\"program-zwracaj%C4%85cy-losowe-b%C5%82%C4%99dy\">Program zwracający losowe błędy</h2><p>Zacznijmy od implementacji przykładowej klasy - Prostokąta, który z pewnym prawdopodobieństwem nie radzi sobie z obliczeniem swojego pola.</p><pre><code class=\"language-typescript\">class Rectangle {\n    a: number\n    b: number\n\n    constructor(a: number, b: number) {\n        this.a = a;\n        this.b = b;\n    }\n\n    async field(n: number) {\n        if (Math.random() &gt; n) {\n            return this.a * this.b\n        } else {\n            throw new Error(`Random Fail`);\n        }\n    }\n}</code></pre><p>Argumentem funkcji <code>field</code> jest prawdopodobieństwo błędu.</p><p>Teraz zobaczmy jak wyglądało by użycie obiektu tej klasy i policzmy ilość błędów</p><pre><code class=\"language-typescript\">async function main() {\n    const rec = new Rectangle(1, 2);\n    const res = {\n        ok: 0,\n        fail: 0\n    }\n\n    for (let i = 0; i &lt; 10000; i++) {\n        try {\n            await rec.field(0.1);\n            res.ok++;\n        } catch {\n            res.fail++;\n        }\n    }\n\n    console.log(res);\n}\n\nmain().catch(console.error)</code></pre><p>po włączeniu tej funkcji widzimy, że co mniej więcej dziesiąty wynik jest błędny</p><pre><code class=\"language-json\">{ ok: 9035, fail: 965 }</code></pre><p>Jest niemal pewne, że w 10.000 przypadków znajdziemy przynajmniej jeden błąd. Jeśli chcieli byśmy w 10.000 przypadków mieć prawdopodobieństwo błędu na poziomie 0.1% to musieli byśmy obniżyć szansę błędu pojedynczego wywołania z 10% do 0.000001%. czyli milion razy.</p><p>Okazuje się, że nie tylko jest to możliwe, ale nie zajmie nawet dużo czasu. Całkowity czas działania programu, stosującego metodę ponownego próbowania dla otrzymanych błędów liczymy jako </p><p>\\[ T = T_0 \\sum_{n=0}^{\\infty} p_e^n = T_0 \\exp(p_e) \\approx (1+p_e) T_0 \\] </p><p>W naszym przypadku będzie to oznaczało, że być może zdarzą się serie 6 nie udanych prób pod rząd, ale cały program zamiast zwracać błędy po prostu będzie działał średnio jedynie o 1/10 dłużej.</p><h2 id=\"redukcja-ilo%C5%9Bci-b%C5%82%C4%99d%C3%B3w-na-wyj%C5%9Bciu\">Redukcja ilości błędów na wyjściu</h2><p>Zainstalujmy paczkę <code>ts-retry</code> i napiszmy następujący kod:</p><pre><code class=\"language-typescript\">import {retryAsyncDecorator} from \"ts-retry/lib/cjs/retry/decorators\";\nimport { RetryOptions} from \"ts-retry\";\n\nexport function retryPolicy&lt;T&gt;(obj: any, policy: RetryOptions): T {\n    return new Proxy(obj, {\n        get(target, handler) {\n            if (handler in target) {\n                if (handler === 'field') {\n                    return retryAsyncDecorator(target[handler].bind(target), policy)\n                }\n                return target[handler];\n            }\n        }\n    })\n}</code></pre><p>Funkcja <code>retryPolicy</code> zwraca obiekt Proxy, który zachowuje się prawie tak jak nasza wejściowa klasa, ale dla funkcji <code>field</code> zwraca handler, który wykonuje próby wywołania tej funkcji zgodnie z konfiguracją przekazaną do <code>retryPolicy</code> jako drugi argument.</p><p>Jeśli teraz wrócimy do funkcji <code>main</code> i zastąpimy:</p><pre><code class=\"language-typescript\">const rec = new Rectangle(1, 2);\n</code></pre><p>przez</p><pre><code class=\"language-typescript\">const rec = retryPolicy&lt;Rectangle&gt;(new Rectangle(1, 2), {maxTry: 6, delay: 0});</code></pre><p>jest prawie pewne, że zobaczymy:</p><pre><code class=\"language-json\">{ ok: 10000, fail: 0 }</code></pre><p>Jeśli chcemy aby było to pewne, można zmienić <code>maxTry</code> z <code>6</code> na <code>Infinity</code>, ale tu jest pułapka. Taka wartość owszem obniżyła by szansę, że jakiś nie reprodukowalny, losowy błąd zepsuje nam wynik końcowy, ale wraz z każdą kolejną próbą rośnie szansa, że błąd, z którym mamy do czynienia wcale nie jest losowy i wcale nie zniknie wraz z kolejną iteracją.</p><p>Czasami przyczyną błędu może być brak dostępu do jakiegoś zasobu właśnie dlatego, że odpytujemy o niego zbyt często. Wtedy warto przy każdej kolejnej próbie czekać coraz dłużej. Często jednak trafimy na błędy, których nie można po prostu naprawić metodą \"wyłącz i spróbuj jeszcze raz\". W ich przypadku zbyt duża wartość <code>maxTry</code> podnosi nam łączny czas poświęcony przez program na bezcelowe działania.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/1640209265.jpeg\" class=\"kg-image\" alt loading=\"lazy\" width=\"860\" height=\"721\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/1640209265.jpeg 600w, __GHOST_URL__/content/images/2022/06/1640209265.jpeg 860w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Wobec trudności z pomiarem szans na błędy i ich kategoryzacją w wielu przypadkach zamiast wyliczać parametry <code>retry policy</code> ustala się je intuicyjnie. </p><p>Bardzo rozsądne jest zróżnicowanie polityki retry w zależności od rodzaju błędu:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/41b3577486839d799e669632927cdd12.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"261\" height=\"213\"></figure><p>Niestety paczka <code>ts-retry</code> nie obsługuje ani <code>exponential backoff</code> ani różnego traktowania np kodów błędów, które pomagają w decydowaniu co zrobić z tym błędem. Na szczęście od lat powstają bardziej rozbudowane paczki. Wśród nich najciekawsza wydaje się <code>ts-retry-promise</code>, która mimo niskiej popularności daje dobry kompromis między prostotą użycia a możliwością customizacji. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/2022-06-10_19-03.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1414\" height=\"1046\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/2022-06-10_19-03.png 600w, __GHOST_URL__/content/images/size/w1000/2022/06/2022-06-10_19-03.png 1000w, __GHOST_URL__/content/images/2022/06/2022-06-10_19-03.png 1414w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Więcej o optymalnych strategiach <code>retry</code> możesz przeczytać w artykule Prof. Douglas Thain - Exponential Backoff in Distributed Systems z 2009.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"http://dthain.blogspot.com/2009/02/exponential-backoff-in-distributed.html\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Exponential Backoff in Distributed Systems</div><div class=\"kg-bookmark-description\">In response to my previous article, a commenter asked: Why exponential backoff? To put a finer point on the question, How should I choose t...</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"http://dthain.blogspot.com/favicon.ico\"><span class=\"kg-bookmark-author\">Prof. Douglas Thain</span><span class=\"kg-bookmark-publisher\">Douglas Thain</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"http://4.bp.blogspot.com/_0DkxYiRVGyA/SaIUoVsKoqI/AAAAAAAAAC0/APiyDxuzvzs/w1200-h630-p-k-no-nu/ethernet.gif\"></div></a></figure><p>Aby użyć <code>ts-retry-promise</code> do importów dodamy:</p><pre><code class=\"language-typescript\">import {NotRetryableError, RetryConfig, retryDecorator} from \"ts-retry-promise\";</code></pre><p>zmieniamy <code>maxTry</code> na <code>retries</code>. Możemy ustawić <code>backoff</code> na <code>EXPONENTIAL</code> ale został nam jeszcze problem błędów, przy których chcieli byśmy się poddać bez walki.</p><p>Zmieńmy ciało funkcji field następująco</p><pre><code class=\"language-typescript\">    async field(n: number, m: number) {\n        if (Math.random() &gt; n) {\n            return this.a * this.b\n        } else {\n            if(Math.random() &gt; m) {\n                throw new Error(`Random Fail`);\n            } else {\n                throw new Error(`CRITICAL`);\n            }\n        }\n    }</code></pre><p>teraz zwraca ono dwa rodzaje błędów, <code>Random Fail</code> przy którym będziemy próbować ponownie (mógł by to być kod błędu 429) oraz <code>CRITICAL</code> przy którym wiemy, że nie ma to sensu (np 401). </p><p>W <code>main</code> funkcja <code>field</code> przyjmuje teraz szansę błędu (n) oraz szansę, że jest to błąd krytyczny (m).</p><p>Bez dalszych zmian w <code>Rectangle</code> i <code>main</code> zmienimy w funkcji <code>retryPolicy</code> linię</p><pre><code class=\"language-typescript\">return retryAsyncDecorator(target[handler].bind(target), policy)\n</code></pre><p>na</p><pre><code class=\"language-typescript\">return retryDecorator(rethrowNotRetryableErrors(target[handler].bind(target)), policy)\n</code></pre><p>i dołożymy funkcję:</p><pre><code class=\"language-typescript\">import {types} from 'util';\n\nfunction rethrowNotRetryableErrors(fun: any):any {\n    return (...args:any) =&gt; {\n        return fun(...args).catch((err: unknown) =&gt; {\n            if(types.isNativeError(err)) {\n                if(err.message.includes('CRITICAL')) throw new NotRetryableError(err.message);\n            }\n            throw err;\n        })\n    }\n}</code></pre><p>Jej zadaniem jest ukrycie logiki translacji błędów zwracanych przez <code>Rectangle</code> na takie, które różnią się sposobem obsługi w paczce <code>ts-retry-promise</code>. Dzięki temu zostawiając resztę kodu nie tkniętą możemy tu napisać, że nie będziemy próbować ponownych wywołań z błędami zawierającymi <code>CRITICAL</code> w polu <code>message</code>. </p><p>Prezentowany tu kod znajdziesz pod linkiem:</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/gustawdaniel/blog-retry-policy\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">GitHub - gustawdaniel/blog-retry-policy</div><div class=\"kg-bookmark-description\">Contribute to gustawdaniel/blog-retry-policy development by creating an account on GitHub.</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicons/favicon.svg\"><span class=\"kg-bookmark-author\">GitHub</span><span class=\"kg-bookmark-publisher\">gustawdaniel</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://opengraph.githubassets.com/6f9afa0b36f147e1bb2f10a10dd4521b32ed20808119c9483a2e2659717a1b65/gustawdaniel/blog-retry-policy\"></div></a></figure><h2 id=\"co-je%C5%9Bli-b%C5%82%C4%99du-nie-da-si%C4%99-obs%C5%82u%C5%BCy%C4%87\">Co jeśli błędu nie da się obsłużyć</h2><p>Wtedy trzeba poinformować użytkownika końcowego stosując się do następujących reguł:</p><ul><li>nie można mu powiedzieć o błędzie za dużo, bo może być hackerem i to wykorzystać</li><li>nie można mu powiedzieć za mało, bo w dziale supportu nie będzie dało się mu pomóc</li><li>nie można w komunikacie błędu przyznać się, że kod nie działa... wiadomo dlaczego</li><li>pozostaje wymieszać cynizm i szczerość z humorem i wyświetlić mu to:</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/aQ3oz8r_700b.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"700\" height=\"674\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/aQ3oz8r_700b.jpg 600w, __GHOST_URL__/content/images/2022/06/aQ3oz8r_700b.jpg 700w\"></figure>",
            "comment_id": "62a3415fd9c3ae6cbd852a52",
            "plaintext": "Czasami z szeregu różnych przyczyn programy komputerowe potrafią zwracać dziwne\nbłędy, których odtworzenie jest niezwykle trudne, a naprawienie nie możliwe.\nJeśli jednak poprawne działanie programu udaje się uzyskać w skończonej ilości\nponownych jego uruchomień, może to stanowić optymalny sposób rozwiązania tego\nproblemu.\n\nMa to znaczenie, szczególnie w złożonych systemach, gdzie wiele potencjalnych\nźródeł błędów akumuluje się, a ponowna próba wywołania wadliwych funkcji pozwala\nobniżyć prawdopodobieństwo błędu podnosząc je do kwadratu.\n\nW tym artykule pokarzę jak dzięki paczce ts-retry oraz obiektowi Proxy, możesz\npodnieść stabilność swojego kodu i sprawić, że kod który prawie nigdy nie\ndziałał będzie zwracał błędy tylko czasami.\n\nProgram zwracający losowe błędy\nZacznijmy od implementacji przykładowej klasy - Prostokąta, który z pewnym\nprawdopodobieństwem nie radzi sobie z obliczeniem swojego pola.\n\nclass Rectangle {\n    a: number\n    b: number\n\n    constructor(a: number, b: number) {\n        this.a = a;\n        this.b = b;\n    }\n\n    async field(n: number) {\n        if (Math.random() > n) {\n            return this.a * this.b\n        } else {\n            throw new Error(`Random Fail`);\n        }\n    }\n}\n\nArgumentem funkcji field jest prawdopodobieństwo błędu.\n\nTeraz zobaczmy jak wyglądało by użycie obiektu tej klasy i policzmy ilość błędów\n\nasync function main() {\n    const rec = new Rectangle(1, 2);\n    const res = {\n        ok: 0,\n        fail: 0\n    }\n\n    for (let i = 0; i < 10000; i++) {\n        try {\n            await rec.field(0.1);\n            res.ok++;\n        } catch {\n            res.fail++;\n        }\n    }\n\n    console.log(res);\n}\n\nmain().catch(console.error)\n\npo włączeniu tej funkcji widzimy, że co mniej więcej dziesiąty wynik jest błędny\n\n{ ok: 9035, fail: 965 }\n\nJest niemal pewne, że w 10.000 przypadków znajdziemy przynajmniej jeden błąd.\nJeśli chcieli byśmy w 10.000 przypadków mieć prawdopodobieństwo błędu na\npoziomie 0.1% to musieli byśmy obniżyć szansę błędu pojedynczego wywołania z 10%\ndo 0.000001%. czyli milion razy.\n\nOkazuje się, że nie tylko jest to możliwe, ale nie zajmie nawet dużo czasu.\nCałkowity czas działania programu, stosującego metodę ponownego próbowania dla\notrzymanych błędów liczymy jako \n\n\\[ T = T_0 \\sum_{n=0}^{\\infty} p_e^n = T_0 \\exp(p_e) \\approx (1+p_e) T_0 \\] \n\nW naszym przypadku będzie to oznaczało, że być może zdarzą się serie 6 nie\nudanych prób pod rząd, ale cały program zamiast zwracać błędy po prostu będzie\ndziałał średnio jedynie o 1/10 dłużej.\n\nRedukcja ilości błędów na wyjściu\nZainstalujmy paczkę ts-retry i napiszmy następujący kod:\n\nimport {retryAsyncDecorator} from \"ts-retry/lib/cjs/retry/decorators\";\nimport { RetryOptions} from \"ts-retry\";\n\nexport function retryPolicy<T>(obj: any, policy: RetryOptions): T {\n    return new Proxy(obj, {\n        get(target, handler) {\n            if (handler in target) {\n                if (handler === 'field') {\n                    return retryAsyncDecorator(target[handler].bind(target), policy)\n                }\n                return target[handler];\n            }\n        }\n    })\n}\n\nFunkcja retryPolicy zwraca obiekt Proxy, który zachowuje się prawie tak jak\nnasza wejściowa klasa, ale dla funkcji field zwraca handler, który wykonuje\npróby wywołania tej funkcji zgodnie z konfiguracją przekazaną do retryPolicy \njako drugi argument.\n\nJeśli teraz wrócimy do funkcji main i zastąpimy:\n\nconst rec = new Rectangle(1, 2);\n\n\nprzez\n\nconst rec = retryPolicy<Rectangle>(new Rectangle(1, 2), {maxTry: 6, delay: 0});\n\njest prawie pewne, że zobaczymy:\n\n{ ok: 10000, fail: 0 }\n\nJeśli chcemy aby było to pewne, można zmienić maxTry z 6 na Infinity, ale tu\njest pułapka. Taka wartość owszem obniżyła by szansę, że jakiś nie\nreprodukowalny, losowy błąd zepsuje nam wynik końcowy, ale wraz z każdą kolejną\npróbą rośnie szansa, że błąd, z którym mamy do czynienia wcale nie jest losowy i\nwcale nie zniknie wraz z kolejną iteracją.\n\nCzasami przyczyną błędu może być brak dostępu do jakiegoś zasobu właśnie\ndlatego, że odpytujemy o niego zbyt często. Wtedy warto przy każdej kolejnej\npróbie czekać coraz dłużej. Często jednak trafimy na błędy, których nie można po\nprostu naprawić metodą \"wyłącz i spróbuj jeszcze raz\". W ich przypadku zbyt duża\nwartość maxTry podnosi nam łączny czas poświęcony przez program na bezcelowe\ndziałania.\n\nWobec trudności z pomiarem szans na błędy i ich kategoryzacją w wielu\nprzypadkach zamiast wyliczać parametry retry policy ustala się je intuicyjnie. \n\nBardzo rozsądne jest zróżnicowanie polityki retry w zależności od rodzaju błędu:\n\nNiestety paczka ts-retry nie obsługuje ani exponential backoff ani różnego\ntraktowania np kodów błędów, które pomagają w decydowaniu co zrobić z tym\nbłędem. Na szczęście od lat powstają bardziej rozbudowane paczki. Wśród nich\nnajciekawsza wydaje się ts-retry-promise, która mimo niskiej popularności daje\ndobry kompromis między prostotą użycia a możliwością customizacji. \n\nWięcej o optymalnych strategiach retry możesz przeczytać w artykule Prof.\nDouglas Thain - Exponential Backoff in Distributed Systems z 2009.\n\nExponential Backoff in Distributed SystemsIn response to my previous article, a\ncommenter asked: Why exponential backoff? To put a finer point on the question,\nHow should I choose t...Prof. Douglas ThainDouglas Thain\n[http://dthain.blogspot.com/2009/02/exponential-backoff-in-distributed.html]Aby\nużyć ts-retry-promise do importów dodamy:\n\nimport {NotRetryableError, RetryConfig, retryDecorator} from \"ts-retry-promise\";\n\nzmieniamy maxTry na retries. Możemy ustawić backoff na EXPONENTIAL ale został\nnam jeszcze problem błędów, przy których chcieli byśmy się poddać bez walki.\n\nZmieńmy ciało funkcji field następująco\n\n    async field(n: number, m: number) {\n        if (Math.random() > n) {\n            return this.a * this.b\n        } else {\n            if(Math.random() > m) {\n                throw new Error(`Random Fail`);\n            } else {\n                throw new Error(`CRITICAL`);\n            }\n        }\n    }\n\nteraz zwraca ono dwa rodzaje błędów, Random Fail przy którym będziemy próbować\nponownie (mógł by to być kod błędu 429) oraz CRITICAL przy którym wiemy, że nie\nma to sensu (np 401). \n\nW main funkcja field przyjmuje teraz szansę błędu (n) oraz szansę, że jest to\nbłąd krytyczny (m).\n\nBez dalszych zmian w Rectangle i main zmienimy w funkcji retryPolicy linię\n\nreturn retryAsyncDecorator(target[handler].bind(target), policy)\n\n\nna\n\nreturn retryDecorator(rethrowNotRetryableErrors(target[handler].bind(target)), policy)\n\n\ni dołożymy funkcję:\n\nimport {types} from 'util';\n\nfunction rethrowNotRetryableErrors(fun: any):any {\n    return (...args:any) => {\n        return fun(...args).catch((err: unknown) => {\n            if(types.isNativeError(err)) {\n                if(err.message.includes('CRITICAL')) throw new NotRetryableError(err.message);\n            }\n            throw err;\n        })\n    }\n}\n\nJej zadaniem jest ukrycie logiki translacji błędów zwracanych przez Rectangle na\ntakie, które różnią się sposobem obsługi w paczce ts-retry-promise. Dzięki temu\nzostawiając resztę kodu nie tkniętą możemy tu napisać, że nie będziemy próbować\nponownych wywołań z błędami zawierającymi CRITICAL w polu message. \n\nPrezentowany tu kod znajdziesz pod linkiem:\n\nGitHub - gustawdaniel/blog-retry-policyContribute to\ngustawdaniel/blog-retry-policy development by creating an account on GitHub.\nGitHubgustawdaniel [https://github.com/gustawdaniel/blog-retry-policy]Co jeśli\nbłędu nie da się obsłużyć\nWtedy trzeba poinformować użytkownika końcowego stosując się do następujących\nreguł:\n\n * nie można mu powiedzieć o błędzie za dużo, bo może być hackerem i to\n   wykorzystać\n * nie można mu powiedzieć za mało, bo w dziale supportu nie będzie dało się mu\n   pomóc\n * nie można w komunikacie błędu przyznać się, że kod nie działa... wiadomo\n   dlaczego\n * pozostaje wymieszać cynizm i szczerość z humorem i wyświetlić mu to:",
            "feature_image": "__GHOST_URL__/content/images/2022/06/istockphoto-1267022464-612x612.jpg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2022-06-10T13:04:31.000Z",
            "updated_at": "2022-06-10T16:14:57.000Z",
            "published_at": "2022-06-10T16:14:57.000Z",
            "custom_excerpt": "Dowiedz się, jak sprawić, że losowe, niemożliwe do odtworzenia błędy nie będą już groźne dla Twojego programu.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "62a4cca6d9c3ae6cbd852d48",
            "uuid": "09db6fb4-27ed-4fa4-a8bd-53ce8f2b29b1",
            "title": "Wprowadzenie do Deno",
            "slug": "wprowadzenie-do-deno",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/2022-06-11_21-24.png\",\"width\":604,\"height\":325}],[\"code\",{\"code\":\"curl -fsSL https://deno.land/x/install/install.sh | sh\"}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[0],1,\"Deno\"],[0,[],0,\" jest anagramem nazwy \"],[0,[0],1,\"Node\"],[0,[],0,\". Jest to interpreter \"],[0,[0],1,\"js\"],[0,[],0,\" oraz \"],[0,[0],1,\"ts\"],[0,[],0,\" napisany przez autora \"],[0,[0],1,\"Node.js\"],[0,[],0,\". Różni się tym, że:\"]]],[3,\"ul\",[[[0,[],0,\"ma bardziej rozbudowane możliwości zarządzania uprawnieniami skryptu do korzystania z zasobów, przez co jest bezpieczniejszy\"]],[[0,[],0,\"natywnie wspiera typescript\"]],[[0,[],0,\"ma pewne problemy z częścią paczek z \"],[0,[0],1,\"npm\"],[0,[],0,\" ponieważ naprawiając błędy związane z implementacją \"],[0,[0],1,\"node_modules\"],[0,[],0,\" zerwał z kompatybilnością, której nie można zerwać w \"],[0,[0],1,\"Node.js\"]]]],[1,\"p\",[[0,[],0,\"Pod tym względem można go porównać do \"],[0,[0],1,\"php6\"],[0,[],0,\", z tą różnicą, że \"],[0,[0],1,\"deno\"],[0,[],0,\" się ukazał, albo do \"],[0,[0],1,\"perl6\"],[0,[],0,\", z tą różnicą, że poprzednik \"],[0,[0],1,\"deno\"],[0,[],0,\" nie odchodzi dzisiaj w zapomnienie.\"]]],[1,\"p\",[[0,[],0,\"Zwykle łamanie kompatybilności w celu naprawienia czegoś nie kończy się dobrze, bo ciężko o użytkowników, którzy zgodzą się nie używać swoich ulubionych paczek. Z tego powodu po tym jak usłyszałem o \"],[0,[0],1,\"deno\"],[0,[],0,\" w maju 2020, postanowiłem dać mu trochę czasu i zajrzeć do niego po dwóch latach. Na razie jego popularność nie rośnie, ale \"]]],[10,0],[1,\"p\",[[0,[],0,\"Możemy go zainstalować poleceniem:\"]]],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p><code>Deno</code> jest anagramem nazwy <code>Node</code>. Jest to interpreter <code>js</code> oraz <code>ts</code> napisany przez autora <code>Node.js</code>. Różni się tym, że:</p><ul><li>ma bardziej rozbudowane możliwości zarządzania uprawnieniami skryptu do korzystania z zasobów, przez co jest bezpieczniejszy</li><li>natywnie wspiera typescript</li><li>ma pewne problemy z częścią paczek z <code>npm</code> ponieważ naprawiając błędy związane z implementacją <code>node_modules</code> zerwał z kompatybilnością, której nie można zerwać w <code>Node.js</code></li></ul><p>Pod tym względem można go porównać do <code>php6</code>, z tą różnicą, że <code>deno</code> się ukazał, albo do <code>perl6</code>, z tą różnicą, że poprzednik <code>deno</code> nie odchodzi dzisiaj w zapomnienie.</p><p>Zwykle łamanie kompatybilności w celu naprawienia czegoś nie kończy się dobrze, bo ciężko o użytkowników, którzy zgodzą się nie używać swoich ulubionych paczek. Z tego powodu po tym jak usłyszałem o <code>deno</code> w maju 2020, postanowiłem dać mu trochę czasu i zajrzeć do niego po dwóch latach. Na razie jego popularność nie rośnie, ale </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/2022-06-11_21-24.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"604\" height=\"325\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/2022-06-11_21-24.png 600w, __GHOST_URL__/content/images/2022/06/2022-06-11_21-24.png 604w\"></figure><p>Możemy go zainstalować poleceniem:</p><pre><code>curl -fsSL https://deno.land/x/install/install.sh | sh</code></pre>",
            "comment_id": "62a4cca6d9c3ae6cbd852d48",
            "plaintext": "Deno jest anagramem nazwy Node. Jest to interpreter js oraz ts napisany przez\nautora Node.js. Różni się tym, że:\n\n * ma bardziej rozbudowane możliwości zarządzania uprawnieniami skryptu do\n   korzystania z zasobów, przez co jest bezpieczniejszy\n * natywnie wspiera typescript\n * ma pewne problemy z częścią paczek z npm ponieważ naprawiając błędy związane\n   z implementacją node_modules zerwał z kompatybilnością, której nie można\n   zerwać w Node.js\n\nPod tym względem można go porównać do php6, z tą różnicą, że deno się ukazał,\nalbo do perl6, z tą różnicą, że poprzednik deno nie odchodzi dzisiaj w\nzapomnienie.\n\nZwykle łamanie kompatybilności w celu naprawienia czegoś nie kończy się dobrze,\nbo ciężko o użytkowników, którzy zgodzą się nie używać swoich ulubionych paczek.\nZ tego powodu po tym jak usłyszałem o deno w maju 2020, postanowiłem dać mu\ntrochę czasu i zajrzeć do niego po dwóch latach. Na razie jego popularność nie\nrośnie, ale \n\nMożemy go zainstalować poleceniem:\n\ncurl -fsSL https://deno.land/x/install/install.sh | sh",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2022-06-11T17:11:02.000Z",
            "updated_at": "2022-06-11T17:29:05.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "62a4d997d9c3ae6cbd852d9a",
            "uuid": "41d1e4ea-302e-4bd3-8234-faf2c2e93bb6",
            "title": "Analiza Prawa Zipfa w Node.js",
            "slug": "prawo-zipfa-w-nodejs",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/2022-06-12_02-12.png\",\"width\":373,\"height\":335}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://en.wikipedia.org/wiki/Zipf%27s_law\",\"metadata\":{\"url\":\"https://en.wikipedia.org/wiki/Zipf's_law\",\"title\":\"Zipf’s law - Wikipedia\",\"description\":null,\"author\":\"Contributors to Wikimedia projects\",\"publisher\":\"Wikimedia Foundation, Inc.\",\"thumbnail\":\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Zipf_distribution_PMF.png/1200px-Zipf_distribution_PMF.png\",\"icon\":\"https://en.wikipedia.org/static/apple-touch/wikipedia.png\"}}],[\"bookmark\",{\"type\":\"bookmark\",\"url\":\"https://lang.org.ua/en/corpora/\",\"metadata\":{\"url\":\"https://lang.org.ua/en/corpora/\",\"title\":\"Corpora: lang-uk\",\"description\":null,\"author\":null,\"publisher\":null,\"thumbnail\":\"http://lang.org.ua/static/images/converted/lang-uk-logo-big.png\",\"icon\":null}}],[\"code\",{\"code\":\"wget https://lang.org.ua/static/downloads/corpora/laws.txt.lemmatized.bz2\",\"language\":\"bash\"}],[\"code\",{\"code\":\"tar -xf laws.txt.lemmatized.bz2\"}],[\"code\",{\"code\":\"head -n 200 laws.txt.lemmatized > laws.txt.lemmatized.head\"}],[\"code\",{\"code\":\"wc laws.txt.lemmatized\\n43230994  580844603 7538876115 laws.txt.lemmatized\\n\\ndu -h laws.txt.lemmatized\\n7,1G\\tlaws.txt.lemmatized\"}],[\"code\",{\"code\":\"npm init -y && tsc --init\"}],[\"code\",{\"code\":\"npm i -D esbuild esbuild-node-tsc\\nnpm i dayjs\"}],[\"code\",{\"code\":\"run:\\n\\tetsc && node ./dist/index.js\"}],[\"code\",{\"code\":\"import readline from \\\"readline\\\";\\nimport fs from \\\"fs\\\";\\n\\nasync function main() { \\n    const path = process.cwd() + '/laws.txt.lemmatized.head';\\n\\n    const fileStream = fs.createReadStream(path);\\n    \\n    const rl = readline.createInterface({\\n        input: fileStream,\\n        crlfDelay: Infinity\\n    });\\n\\n    for await (const line of rl) {\\n        console.log(line)\\n    }\\n}\\n\\nmain().catch(console.log)\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"    const map = new Map<string, number>()\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"        line.split(' ').forEach(word => {\\n            if (map.has(word)) {\\n                map.set(word, (map.get(word) || 0) + 1)\\n            } else {\\n                map.set(word, 1)\\n            }\\n        })\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"    const sortedAsc = new Map([...map].sort((a, b) => (a[1] < b[1] ? 1 : -1)));\\n\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"    const out = [...sortedAsc.entries()].reduce((p, n) => `${p}\\\\n${n[1]},${n[0]}`, ``)\\n\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"    fs.writeFileSync(process.cwd() + '/out', out)\\n\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"console.log('Time', dayjs().diff(s))\\n\"}],[\"code\",{\"code\":\"import dayjs from 'dayjs'\\n\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"    const s = dayjs()\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"    let i = 0;\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"        i++;\\n        if (i % 1e5 === 0) {\\n            console.log(`I`, i, `T`, dayjs().diff(s))\\n        }\",\"language\":\"typescript\"}],[\"code\",{\"code\":\"    console.log('Time', dayjs().diff(s))\",\"language\":\"typescript\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/2022-06-11_23-32.png\",\"width\":1347,\"height\":664}],[\"code\",{\"code\":\"node -e 'console.log(v8.getHeapStatistics().heap_size_limit/(1024*1024))'\\n\",\"language\":\"bash\"}],[\"code\",{\"code\":\"run:\\n\\tetsc && node --max-old-space-size=4096 ./dist/index.js\"}],[\"code\",{\"code\":\"14022692,\\n9279668,та\\n8653492,з\\n7907815,на\\n7890310,у\\n7462816,в\\n7090614,Україна\\n6233283,від\\n6075057,до\\n6042053,за\\n5698079,і\\n4811990,про\\n4300976,N\\n3969368,або\\n3863955,який\\n3547579,державний\\n3309810,що\\n3123859,1\\n3059829,для\\n3036979,закон\\n2992163,особа\\n2738219,не\\n2611769,згідно\\n2555994,стаття\\n2390347,із\\n2315387,орган\\n2275758,інший\\n2267005,2\\n2262961,а\\n2208099,рік\\n2038612,бути\\n1920091,вони\\n1836843,пункт\\n1785740,це\\n1737457,3\\n1584258,порядок\\n1573372,такий\\n1516880,частина\\n1424188,зміна\",\"language\":\"csv\"}],[\"code\",{\"code\":\"grep '\\\\S' out | awk -F',' '{print NR, $1}' > log.txt\"}],[\"code\",{\"code\":\"gnuplot -e \\\"set ylabel 'Count'; set xlabel 'Rank'; set logscale xy; plot 'log.txt' with linespoints linestyle 1\\\" -p\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/2022-06-12_01-42.png\",\"width\":887,\"height\":656}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/42fb977388_a_nie_mowilem_.jpg\",\"width\":400,\"height\":400}]],\"markups\":[[\"a\",[\"href\",\"https://medium.com/mlearning-ai/nlp-tokenization-stemming-lemmatization-and-part-of-speech-tagging-9088ac068768\"]],[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Prawo Zipfa mówi, że jeśli posortuje się słowa w danym języku względem częstości ich występowania, to to częstość będzie odwrotnie proporcjonalna do pozycji (rangi) słowa.\"]]],[1,\"p\",[[0,[],0,\"Innymi słowy występuje liniowa zależność o ujemnym współczynniku między logartymami częstotliwości i rangi, co widać na wykresie w skali logarytmiczno-logarytmicznej.\"]]],[10,0],[1,\"p\",[[0,[],0,\"lub dzięki prostemu przekształceniu:\"]]],[1,\"p\",[[0,[],0,\"\\\\[ f * r = const \\\\Leftrightarrow \\\\log(f *r) = const \\\\Leftrightarrow \\\\log(f) = const - \\\\log(r) \\\\]\"]]],[10,1],[1,\"p\",[[0,[],0,\"Wiemy, że jest to prawdą i na Wikipedii można znaleźć wykresy wykonane na podstawie korpusów z wielu języków. My sprawdzamy to dla zabawy i z miłości do nauki.\"]]],[1,\"p\",[[0,[],0,\"Teksty do wzięliśmy z Ukraińskiego prawodastwa, pół miliarda słów powinno wystarczyć.\"]]],[10,2],[1,\"p\",[[0,[],0,\"Na stronie mamy wersję z tokenizacją czyli podziałem na słowa, i lemmatyzacja, która dodatkowo scala odmian słów zastępując je domyślną nie odmienioną formą. Więcej o tokenizacji i lemmatyzacji możecie przeczytać pod linkiem:\"]]],[1,\"p\",[[0,[0],1,\"https://medium.com/mlearning-ai/nlp-tokenization-stemming-lemmatization-and-part-of-speech-tagging-9088ac068768\"]]],[1,\"h2\",[[0,[],0,\"Przygotowanie danych od analizy\"]]],[1,\"p\",[[0,[],0,\"Dla nas wygodniejsza będzie lemmatyzacja, bo nie chcemy analizować treści, a jedynie statystyki tego słownictwa. Pobieramy plik\"]]],[10,3],[1,\"p\",[[0,[],0,\"rozpakowujemy go:\"]]],[10,4],[1,\"p\",[[0,[],0,\"i przygotowujemy jego skrót aby móc testować aplikację na mniejszym pliku\"]]],[10,5],[1,\"p\",[[0,[],0,\"Statystyki pliku wejściowego prezentują się następująco\"]]],[10,6],[1,\"h2\",[[0,[],0,\"Czytanie pliku w Node.js\"]]],[1,\"p\",[[0,[],0,\"Startujemy projekt poleceniami\"]]],[10,7],[1,\"p\",[[0,[],0,\"Instalujemy paczki \"],[0,[1],1,\"esbuild esbuild-node-tsc\"],[0,[],0,\" do budowania projektu oraz \"],[0,[1],1,\"dayjs\"],[0,[],0,\" do mierzenia czasu wykonywania programu.\"]]],[10,8],[1,\"p\",[[0,[],0,\"w pliku \"],[0,[1],1,\"Makefile\"],[0,[],0,\" umieszczamy\"]]],[10,9],[1,\"p\",[[0,[],0,\"dzięki czemu poleceniem \"],[0,[1],1,\"make run\"],[0,[],0,\" będziemy mogli kompilować i włączać nasz program. Jest to co prawda więcej konfiguracji niż \"],[0,[1],1,\"ts-node\"],[0,[],0,\" ale szybkość kompilacji jest 4 razy wyższa.\"]]],[1,\"p\",[[0,[],0,\"Z uwagi na wielkość pliku nie wypada pisać \"],[0,[1],1,\"fs.readFileSync\"],[0,[],0,\" choć pewnie większość z Was ma powyżej 8GB ram. Załóżmy jednak, że chcemy napisać program, który obsłuży większe pliki nie nakładając ograniczeń związanych z koniecznością ładowania ich w całości do pamięci operacyjnej.\"]]],[1,\"p\",[[0,[],0,\"Posłuży nam do tego konstrukcja\"]]],[10,10],[1,\"p\",[[0,[],0,\"ten kod umieszczamy w pliku \"],[0,[1],1,\"src/index.ts\"],[0,[],0,\".  Opcja \"],[0,[1],1,\"crlfDelay\"],[0,[],0,\" pozwala czytać poprawnie pliki z \"],[0,[1],1,\"\\\\r\\\\n\"],[0,[],0,\", dobrze jest ją na wszelki wypadek dołączać. Widzimy, że pierwsza linia zawierająca \"],[0,[1],1,\"await\"],[0,[],0,\" to dopiero pętla \"],[0,[1],1,\"for\"],[0,[],0,\". Dzięki temu możemy zacząć przetwarzanie pliku zanim odczyt dojdzie do jego końca.\"]]],[1,\"h2\",[[0,[],0,\"Zliczanie ilości wystąpień słów\"]]],[1,\"p\",[[0,[],0,\"Teraz dołączymy zliczanie wystąpień słów i umieścimy je w mapie.\"]]],[10,11],[1,\"p\",[[0,[1],1,\"console.log\"],[0,[],0,\" w pętli \"],[0,[1],1,\"for\"],[0,[],0,\" możemy zastąpić przez\"]]],[10,12],[1,\"p\",[[0,[],0,\"po zakończeniu pętli sortujemy mapę względem częstości wystąpień\"]]],[10,13],[1,\"p\",[[0,[],0,\"formujemy tekst pliku wyjściowego\"]]],[10,14],[1,\"p\",[[0,[],0,\"i zapisujemy plik\"]]],[10,15],[1,\"p\",[[0,[],0,\"Właściwie to tyle. Po włączeniu programu z całym plikiem spodziewamy się dostać plik z dwiema kolumnami -  ilością zliczeń i słowem. Jednak bez żadnej informacji zwrotnej na jakim etapie jesteśmy, ciężko było by stwierdzić czy program działa poprawnie, czy się zawiesił i ile jeszcze będziemy czekać na wynik.\"]]],[1,\"h2\",[[0,[],0,\"Dekoracja programu logami\"]]],[1,\"p\",[[0,[],0,\"Zaczniemy od importu dayjs, w celu pokazywanie czasu. Zwykle nie należy instalować bibliotek które nie są potrzebne, ale natywny obiekt Date do niczego się nie nadaje.\"]]],[10,16],[10,17],[1,\"p\",[[0,[],0,\"Na początku funkcji \"],[0,[1],1,\"main\"],[0,[],0,\" definiujemy zmienną z czasem początku wykonywania\"]]],[10,18],[1,\"p\",[[0,[],0,\"Przed pętlą definiujemy licznik\"]]],[10,19],[1,\"p\",[[0,[],0,\"a w pętli pokazujemy jego wartość oraz czas od włączenia\"]]],[10,20],[1,\"p\",[[0,[],0,\"Dzięki temu wiedząc, że plik ma 43 miliony linii możemy szacować kiedy program się zakończy. Na samym końcu funkcji \"],[0,[1],1,\"main\"],[0,[],0,\" możemy dodać\"]]],[10,21],[1,\"p\",[[0,[],0,\"Alternatywą dla tego podejścia jest \"],[0,[1],1,\"console.time\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Uruchomienie programu i problem z pamięcią\"]]],[1,\"p\",[[0,[],0,\"Po uruchomieniu początkowo wszystko szło dobrze, aż do fatalnego błędu \"],[0,[1],1,\"heap out of memory\"],[0,[],0,\".\"]]],[10,22],[1,\"p\",[[0,[],0,\"Co istotne, komputer nie zawiesił się i miał zapas wolnej pamięci. Stało się tak dlatego, że domyślny limit ustawiony na 2GB został przekroczony. Możemy sprawdzić ten limit poleceniem:\"]]],[10,23],[1,\"p\",[[0,[],0,\"i podnieść go ustawiając odpowiednią flagę przy procesie \"],[0,[1],1,\"node\"],[0,[],0,\", w \"],[0,[1],1,\"Makefile\"]]],[10,24],[1,\"p\",[[0,[],0,\"Tym razem program zadziałał poprawnie i zapisał wynikowy plik po 5.5 minuty.\"]]],[1,\"p\",[[0,[],0,\"Jego pierwsze linie widzimy poniżej\"]]],[10,25],[1,\"h2\",[[0,[],0,\"Przygotowanie wykresu\"]]],[1,\"p\",[[0,[],0,\"Chcieli byśmy teraz zobaczyć plik, w którym pierwsza linia zawiera pozycję słowa, a druga ilość wystąpień. Tworzymy go poleceniem:\"]]],[10,26],[1,\"p\",[[0,[],0,\"W tej linii \"],[0,[1],1,\"\\\\S\"],[0,[],0,\" odpowiada za odsianie pustych linii. Flaga \"],[0,[1],1,\"-F\"],[0,[],0,\" pozwala ustawić \"],[0,[1],1,\",\"],[0,[],0,\" jako separator, a \"],[0,[1],1,\"NR\"],[0,[],0,\" wstawia numer linii zaczynając od \"],[0,[1],1,\"1\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Narysowanie wykresu wykonamy dzięki \"],[0,[1],1,\"gnuplot\"]]],[10,27],[1,\"p\",[[0,[],0,\"Flaga \"],[0,[1],1,\"-e\"],[0,[],0,\" pozwala podać komendę a \"],[0,[1],1,\"-p\"],[0,[],0,\" nie wyłącza wykresu po jego narysowaniu.\"]]],[10,28],[1,\"p\",[[0,[],0,\"Widzimy, że wykres pokrywa się z tym, który widzieliśmy na Wikipedii.\"]]],[10,29],[1,\"h2\",[[0,[],0,\"Interpretacja wyników\"]]],[1,\"p\",[[0,[],0,\"Dzięki takiemu rozkładowi częstości słów, nauka języka może zostać przedstawiona jako przesuwanie się od znajomości najczęściej do najrzadziej znanych zwrotów. Możemy też sortować teksty względem ich trudności dla czytelników i dostosowywać je do poziomu ucznia. Jesteśmy też w stanie szacować jakie jest prawdopodobieństwo napotkania nie znanego słowa w danej próbce tekstu.\"]]],[1,\"p\",[[0,[],0,\"Wygląda na to, że pogłębienie tego tematu może mieć ciekawe praktyczne zastosowania. \"]]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p>Prawo Zipfa mówi, że jeśli posortuje się słowa w danym języku względem częstości ich występowania, to to częstość będzie odwrotnie proporcjonalna do pozycji (rangi) słowa.</p><p>Innymi słowy występuje liniowa zależność o ujemnym współczynniku między logartymami częstotliwości i rangi, co widać na wykresie w skali logarytmiczno-logarytmicznej.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/2022-06-12_02-12.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"373\" height=\"335\"></figure><p>lub dzięki prostemu przekształceniu:</p><p>\\[ f * r = const \\Leftrightarrow \\log(f *r) = const \\Leftrightarrow \\log(f) = const - \\log(r) \\]</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://en.wikipedia.org/wiki/Zipf%27s_law\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Zipf’s law - Wikipedia</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://en.wikipedia.org/static/apple-touch/wikipedia.png\"><span class=\"kg-bookmark-author\">Wikimedia Foundation, Inc.</span><span class=\"kg-bookmark-publisher\">Contributors to Wikimedia projects</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Zipf_distribution_PMF.png/1200px-Zipf_distribution_PMF.png\"></div></a></figure><p>Wiemy, że jest to prawdą i na Wikipedii można znaleźć wykresy wykonane na podstawie korpusów z wielu języków. My sprawdzamy to dla zabawy i z miłości do nauki.</p><p>Teksty do wzięliśmy z Ukraińskiego prawodastwa, pół miliarda słów powinno wystarczyć.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://lang.org.ua/en/corpora/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Corpora: lang-uk</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"http://lang.org.ua/static/images/converted/lang-uk-logo-big.png\"></div></a></figure><p>Na stronie mamy wersję z tokenizacją czyli podziałem na słowa, i lemmatyzacja, która dodatkowo scala odmian słów zastępując je domyślną nie odmienioną formą. Więcej o tokenizacji i lemmatyzacji możecie przeczytać pod linkiem:</p><p><a href=\"https://medium.com/mlearning-ai/nlp-tokenization-stemming-lemmatization-and-part-of-speech-tagging-9088ac068768\">https://medium.com/mlearning-ai/nlp-tokenization-stemming-lemmatization-and-part-of-speech-tagging-9088ac068768</a></p><h2 id=\"przygotowanie-danych-od-analizy\">Przygotowanie danych od analizy</h2><p>Dla nas wygodniejsza będzie lemmatyzacja, bo nie chcemy analizować treści, a jedynie statystyki tego słownictwa. Pobieramy plik</p><pre><code class=\"language-bash\">wget https://lang.org.ua/static/downloads/corpora/laws.txt.lemmatized.bz2</code></pre><p>rozpakowujemy go:</p><pre><code>tar -xf laws.txt.lemmatized.bz2</code></pre><p>i przygotowujemy jego skrót aby móc testować aplikację na mniejszym pliku</p><pre><code>head -n 200 laws.txt.lemmatized &gt; laws.txt.lemmatized.head</code></pre><p>Statystyki pliku wejściowego prezentują się następująco</p><pre><code>wc laws.txt.lemmatized\n43230994  580844603 7538876115 laws.txt.lemmatized\n\ndu -h laws.txt.lemmatized\n7,1G\tlaws.txt.lemmatized</code></pre><h2 id=\"czytanie-pliku-w-nodejs\">Czytanie pliku w Node.js</h2><p>Startujemy projekt poleceniami</p><pre><code>npm init -y &amp;&amp; tsc --init</code></pre><p>Instalujemy paczki <code>esbuild esbuild-node-tsc</code> do budowania projektu oraz <code>dayjs</code> do mierzenia czasu wykonywania programu.</p><pre><code>npm i -D esbuild esbuild-node-tsc\nnpm i dayjs</code></pre><p>w pliku <code>Makefile</code> umieszczamy</p><pre><code>run:\n\tetsc &amp;&amp; node ./dist/index.js</code></pre><p>dzięki czemu poleceniem <code>make run</code> będziemy mogli kompilować i włączać nasz program. Jest to co prawda więcej konfiguracji niż <code>ts-node</code> ale szybkość kompilacji jest 4 razy wyższa.</p><p>Z uwagi na wielkość pliku nie wypada pisać <code>fs.readFileSync</code> choć pewnie większość z Was ma powyżej 8GB ram. Załóżmy jednak, że chcemy napisać program, który obsłuży większe pliki nie nakładając ograniczeń związanych z koniecznością ładowania ich w całości do pamięci operacyjnej.</p><p>Posłuży nam do tego konstrukcja</p><pre><code class=\"language-typescript\">import readline from \"readline\";\nimport fs from \"fs\";\n\nasync function main() { \n    const path = process.cwd() + '/laws.txt.lemmatized.head';\n\n    const fileStream = fs.createReadStream(path);\n    \n    const rl = readline.createInterface({\n        input: fileStream,\n        crlfDelay: Infinity\n    });\n\n    for await (const line of rl) {\n        console.log(line)\n    }\n}\n\nmain().catch(console.log)</code></pre><p>ten kod umieszczamy w pliku <code>src/index.ts</code>.  Opcja <code>crlfDelay</code> pozwala czytać poprawnie pliki z <code>\\r\\n</code>, dobrze jest ją na wszelki wypadek dołączać. Widzimy, że pierwsza linia zawierająca <code>await</code> to dopiero pętla <code>for</code>. Dzięki temu możemy zacząć przetwarzanie pliku zanim odczyt dojdzie do jego końca.</p><h2 id=\"zliczanie-ilo%C5%9Bci-wyst%C4%85pie%C5%84-s%C5%82%C3%B3w\">Zliczanie ilości wystąpień słów</h2><p>Teraz dołączymy zliczanie wystąpień słów i umieścimy je w mapie.</p><pre><code class=\"language-typescript\">    const map = new Map&lt;string, number&gt;()</code></pre><p><code>console.log</code> w pętli <code>for</code> możemy zastąpić przez</p><pre><code class=\"language-typescript\">        line.split(' ').forEach(word =&gt; {\n            if (map.has(word)) {\n                map.set(word, (map.get(word) || 0) + 1)\n            } else {\n                map.set(word, 1)\n            }\n        })</code></pre><p>po zakończeniu pętli sortujemy mapę względem częstości wystąpień</p><pre><code class=\"language-typescript\">    const sortedAsc = new Map([...map].sort((a, b) =&gt; (a[1] &lt; b[1] ? 1 : -1)));\n</code></pre><p>formujemy tekst pliku wyjściowego</p><pre><code class=\"language-typescript\">    const out = [...sortedAsc.entries()].reduce((p, n) =&gt; `${p}\\n${n[1]},${n[0]}`, ``)\n</code></pre><p>i zapisujemy plik</p><pre><code class=\"language-typescript\">    fs.writeFileSync(process.cwd() + '/out', out)\n</code></pre><p>Właściwie to tyle. Po włączeniu programu z całym plikiem spodziewamy się dostać plik z dwiema kolumnami -  ilością zliczeń i słowem. Jednak bez żadnej informacji zwrotnej na jakim etapie jesteśmy, ciężko było by stwierdzić czy program działa poprawnie, czy się zawiesił i ile jeszcze będziemy czekać na wynik.</p><h2 id=\"dekoracja-programu-logami\">Dekoracja programu logami</h2><p>Zaczniemy od importu dayjs, w celu pokazywanie czasu. Zwykle nie należy instalować bibliotek które nie są potrzebne, ale natywny obiekt Date do niczego się nie nadaje.</p><pre><code>console.log('Time', dayjs().diff(s))\n</code></pre><pre><code class=\"language-typescript\">import dayjs from 'dayjs'\n</code></pre><p>Na początku funkcji <code>main</code> definiujemy zmienną z czasem początku wykonywania</p><pre><code class=\"language-typescript\">    const s = dayjs()</code></pre><p>Przed pętlą definiujemy licznik</p><pre><code class=\"language-typescript\">    let i = 0;</code></pre><p>a w pętli pokazujemy jego wartość oraz czas od włączenia</p><pre><code class=\"language-typescript\">        i++;\n        if (i % 1e5 === 0) {\n            console.log(`I`, i, `T`, dayjs().diff(s))\n        }</code></pre><p>Dzięki temu wiedząc, że plik ma 43 miliony linii możemy szacować kiedy program się zakończy. Na samym końcu funkcji <code>main</code> możemy dodać</p><pre><code class=\"language-typescript\">    console.log('Time', dayjs().diff(s))</code></pre><p>Alternatywą dla tego podejścia jest <code>console.time</code>.</p><h2 id=\"uruchomienie-programu-i-problem-z-pami%C4%99ci%C4%85\">Uruchomienie programu i problem z pamięcią</h2><p>Po uruchomieniu początkowo wszystko szło dobrze, aż do fatalnego błędu <code>heap out of memory</code>.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/2022-06-11_23-32.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1347\" height=\"664\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/2022-06-11_23-32.png 600w, __GHOST_URL__/content/images/size/w1000/2022/06/2022-06-11_23-32.png 1000w, __GHOST_URL__/content/images/2022/06/2022-06-11_23-32.png 1347w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Co istotne, komputer nie zawiesił się i miał zapas wolnej pamięci. Stało się tak dlatego, że domyślny limit ustawiony na 2GB został przekroczony. Możemy sprawdzić ten limit poleceniem:</p><pre><code class=\"language-bash\">node -e 'console.log(v8.getHeapStatistics().heap_size_limit/(1024*1024))'\n</code></pre><p>i podnieść go ustawiając odpowiednią flagę przy procesie <code>node</code>, w <code>Makefile</code></p><pre><code>run:\n\tetsc &amp;&amp; node --max-old-space-size=4096 ./dist/index.js</code></pre><p>Tym razem program zadziałał poprawnie i zapisał wynikowy plik po 5.5 minuty.</p><p>Jego pierwsze linie widzimy poniżej</p><pre><code class=\"language-csv\">14022692,\n9279668,та\n8653492,з\n7907815,на\n7890310,у\n7462816,в\n7090614,Україна\n6233283,від\n6075057,до\n6042053,за\n5698079,і\n4811990,про\n4300976,N\n3969368,або\n3863955,який\n3547579,державний\n3309810,що\n3123859,1\n3059829,для\n3036979,закон\n2992163,особа\n2738219,не\n2611769,згідно\n2555994,стаття\n2390347,із\n2315387,орган\n2275758,інший\n2267005,2\n2262961,а\n2208099,рік\n2038612,бути\n1920091,вони\n1836843,пункт\n1785740,це\n1737457,3\n1584258,порядок\n1573372,такий\n1516880,частина\n1424188,зміна</code></pre><h2 id=\"przygotowanie-wykresu\">Przygotowanie wykresu</h2><p>Chcieli byśmy teraz zobaczyć plik, w którym pierwsza linia zawiera pozycję słowa, a druga ilość wystąpień. Tworzymy go poleceniem:</p><pre><code>grep '\\S' out | awk -F',' '{print NR, $1}' &gt; log.txt</code></pre><p>W tej linii <code>\\S</code> odpowiada za odsianie pustych linii. Flaga <code>-F</code> pozwala ustawić <code>,</code> jako separator, a <code>NR</code> wstawia numer linii zaczynając od <code>1</code>. </p><p>Narysowanie wykresu wykonamy dzięki <code>gnuplot</code></p><pre><code>gnuplot -e \"set ylabel 'Count'; set xlabel 'Rank'; set logscale xy; plot 'log.txt' with linespoints linestyle 1\" -p</code></pre><p>Flaga <code>-e</code> pozwala podać komendę a <code>-p</code> nie wyłącza wykresu po jego narysowaniu.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/2022-06-12_01-42.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"887\" height=\"656\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/2022-06-12_01-42.png 600w, __GHOST_URL__/content/images/2022/06/2022-06-12_01-42.png 887w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Widzimy, że wykres pokrywa się z tym, który widzieliśmy na Wikipedii.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/42fb977388_a_nie_mowilem_.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"400\" height=\"400\"></figure><h2 id=\"interpretacja-wynik%C3%B3w\">Interpretacja wyników</h2><p>Dzięki takiemu rozkładowi częstości słów, nauka języka może zostać przedstawiona jako przesuwanie się od znajomości najczęściej do najrzadziej znanych zwrotów. Możemy też sortować teksty względem ich trudności dla czytelników i dostosowywać je do poziomu ucznia. Jesteśmy też w stanie szacować jakie jest prawdopodobieństwo napotkania nie znanego słowa w danej próbce tekstu.</p><p>Wygląda na to, że pogłębienie tego tematu może mieć ciekawe praktyczne zastosowania. </p>",
            "comment_id": "62a4d997d9c3ae6cbd852d9a",
            "plaintext": "Prawo Zipfa mówi, że jeśli posortuje się słowa w danym języku względem częstości\nich występowania, to to częstość będzie odwrotnie proporcjonalna do pozycji\n(rangi) słowa.\n\nInnymi słowy występuje liniowa zależność o ujemnym współczynniku między\nlogartymami częstotliwości i rangi, co widać na wykresie w skali\nlogarytmiczno-logarytmicznej.\n\nlub dzięki prostemu przekształceniu:\n\n\\[ f * r = const \\Leftrightarrow \\log(f *r) = const \\Leftrightarrow \\log(f) =\nconst - \\log(r) \\]\n\nZipf’s law - WikipediaWikimedia Foundation, Inc.Contributors to Wikimedia\nprojects [https://en.wikipedia.org/wiki/Zipf%27s_law]Wiemy, że jest to prawdą i\nna Wikipedii można znaleźć wykresy wykonane na podstawie korpusów z wielu\njęzyków. My sprawdzamy to dla zabawy i z miłości do nauki.\n\nTeksty do wzięliśmy z Ukraińskiego prawodastwa, pół miliarda słów powinno\nwystarczyć.\n\nCorpora: lang-uk [https://lang.org.ua/en/corpora/]Na stronie mamy wersję z\ntokenizacją czyli podziałem na słowa, i lemmatyzacja, która dodatkowo scala\nodmian słów zastępując je domyślną nie odmienioną formą. Więcej o tokenizacji i\nlemmatyzacji możecie przeczytać pod linkiem:\n\nhttps://medium.com/mlearning-ai/nlp-tokenization-stemming-lemmatization-and-part-of-speech-tagging-9088ac068768\n\nPrzygotowanie danych od analizy\nDla nas wygodniejsza będzie lemmatyzacja, bo nie chcemy analizować treści, a\njedynie statystyki tego słownictwa. Pobieramy plik\n\nwget https://lang.org.ua/static/downloads/corpora/laws.txt.lemmatized.bz2\n\nrozpakowujemy go:\n\ntar -xf laws.txt.lemmatized.bz2\n\ni przygotowujemy jego skrót aby móc testować aplikację na mniejszym pliku\n\nhead -n 200 laws.txt.lemmatized > laws.txt.lemmatized.head\n\nStatystyki pliku wejściowego prezentują się następująco\n\nwc laws.txt.lemmatized\n43230994  580844603 7538876115 laws.txt.lemmatized\n\ndu -h laws.txt.lemmatized\n7,1G\tlaws.txt.lemmatized\n\nCzytanie pliku w Node.js\nStartujemy projekt poleceniami\n\nnpm init -y && tsc --init\n\nInstalujemy paczki esbuild esbuild-node-tsc do budowania projektu oraz dayjs do\nmierzenia czasu wykonywania programu.\n\nnpm i -D esbuild esbuild-node-tsc\nnpm i dayjs\n\nw pliku Makefile umieszczamy\n\nrun:\n\tetsc && node ./dist/index.js\n\ndzięki czemu poleceniem make run będziemy mogli kompilować i włączać nasz\nprogram. Jest to co prawda więcej konfiguracji niż ts-node ale szybkość\nkompilacji jest 4 razy wyższa.\n\nZ uwagi na wielkość pliku nie wypada pisać fs.readFileSync choć pewnie większość\nz Was ma powyżej 8GB ram. Załóżmy jednak, że chcemy napisać program, który\nobsłuży większe pliki nie nakładając ograniczeń związanych z koniecznością\nładowania ich w całości do pamięci operacyjnej.\n\nPosłuży nam do tego konstrukcja\n\nimport readline from \"readline\";\nimport fs from \"fs\";\n\nasync function main() { \n    const path = process.cwd() + '/laws.txt.lemmatized.head';\n\n    const fileStream = fs.createReadStream(path);\n    \n    const rl = readline.createInterface({\n        input: fileStream,\n        crlfDelay: Infinity\n    });\n\n    for await (const line of rl) {\n        console.log(line)\n    }\n}\n\nmain().catch(console.log)\n\nten kod umieszczamy w pliku src/index.ts.  Opcja crlfDelay pozwala czytać\npoprawnie pliki z \\r\\n, dobrze jest ją na wszelki wypadek dołączać. Widzimy, że\npierwsza linia zawierająca await to dopiero pętla for. Dzięki temu możemy zacząć\nprzetwarzanie pliku zanim odczyt dojdzie do jego końca.\n\nZliczanie ilości wystąpień słów\nTeraz dołączymy zliczanie wystąpień słów i umieścimy je w mapie.\n\n    const map = new Map<string, number>()\n\nconsole.log w pętli for możemy zastąpić przez\n\n        line.split(' ').forEach(word => {\n            if (map.has(word)) {\n                map.set(word, (map.get(word) || 0) + 1)\n            } else {\n                map.set(word, 1)\n            }\n        })\n\npo zakończeniu pętli sortujemy mapę względem częstości wystąpień\n\n    const sortedAsc = new Map([...map].sort((a, b) => (a[1] < b[1] ? 1 : -1)));\n\n\nformujemy tekst pliku wyjściowego\n\n    const out = [...sortedAsc.entries()].reduce((p, n) => `${p}\\n${n[1]},${n[0]}`, ``)\n\n\ni zapisujemy plik\n\n    fs.writeFileSync(process.cwd() + '/out', out)\n\n\nWłaściwie to tyle. Po włączeniu programu z całym plikiem spodziewamy się dostać\nplik z dwiema kolumnami -  ilością zliczeń i słowem. Jednak bez żadnej\ninformacji zwrotnej na jakim etapie jesteśmy, ciężko było by stwierdzić czy\nprogram działa poprawnie, czy się zawiesił i ile jeszcze będziemy czekać na\nwynik.\n\nDekoracja programu logami\nZaczniemy od importu dayjs, w celu pokazywanie czasu. Zwykle nie należy\ninstalować bibliotek które nie są potrzebne, ale natywny obiekt Date do niczego\nsię nie nadaje.\n\nconsole.log('Time', dayjs().diff(s))\n\n\nimport dayjs from 'dayjs'\n\n\nNa początku funkcji main definiujemy zmienną z czasem początku wykonywania\n\n    const s = dayjs()\n\nPrzed pętlą definiujemy licznik\n\n    let i = 0;\n\na w pętli pokazujemy jego wartość oraz czas od włączenia\n\n        i++;\n        if (i % 1e5 === 0) {\n            console.log(`I`, i, `T`, dayjs().diff(s))\n        }\n\nDzięki temu wiedząc, że plik ma 43 miliony linii możemy szacować kiedy program\nsię zakończy. Na samym końcu funkcji main możemy dodać\n\n    console.log('Time', dayjs().diff(s))\n\nAlternatywą dla tego podejścia jest console.time.\n\nUruchomienie programu i problem z pamięcią\nPo uruchomieniu początkowo wszystko szło dobrze, aż do fatalnego błędu heap out\nof memory.\n\nCo istotne, komputer nie zawiesił się i miał zapas wolnej pamięci. Stało się tak\ndlatego, że domyślny limit ustawiony na 2GB został przekroczony. Możemy\nsprawdzić ten limit poleceniem:\n\nnode -e 'console.log(v8.getHeapStatistics().heap_size_limit/(1024*1024))'\n\n\ni podnieść go ustawiając odpowiednią flagę przy procesie node, w Makefile\n\nrun:\n\tetsc && node --max-old-space-size=4096 ./dist/index.js\n\nTym razem program zadziałał poprawnie i zapisał wynikowy plik po 5.5 minuty.\n\nJego pierwsze linie widzimy poniżej\n\n14022692,\n9279668,та\n8653492,з\n7907815,на\n7890310,у\n7462816,в\n7090614,Україна\n6233283,від\n6075057,до\n6042053,за\n5698079,і\n4811990,про\n4300976,N\n3969368,або\n3863955,який\n3547579,державний\n3309810,що\n3123859,1\n3059829,для\n3036979,закон\n2992163,особа\n2738219,не\n2611769,згідно\n2555994,стаття\n2390347,із\n2315387,орган\n2275758,інший\n2267005,2\n2262961,а\n2208099,рік\n2038612,бути\n1920091,вони\n1836843,пункт\n1785740,це\n1737457,3\n1584258,порядок\n1573372,такий\n1516880,частина\n1424188,зміна\n\nPrzygotowanie wykresu\nChcieli byśmy teraz zobaczyć plik, w którym pierwsza linia zawiera pozycję\nsłowa, a druga ilość wystąpień. Tworzymy go poleceniem:\n\ngrep '\\S' out | awk -F',' '{print NR, $1}' > log.txt\n\nW tej linii \\S odpowiada za odsianie pustych linii. Flaga -F pozwala ustawić , \njako separator, a NR wstawia numer linii zaczynając od 1. \n\nNarysowanie wykresu wykonamy dzięki gnuplot\n\ngnuplot -e \"set ylabel 'Count'; set xlabel 'Rank'; set logscale xy; plot 'log.txt' with linespoints linestyle 1\" -p\n\nFlaga -e pozwala podać komendę a -p nie wyłącza wykresu po jego narysowaniu.\n\nWidzimy, że wykres pokrywa się z tym, który widzieliśmy na Wikipedii.\n\nInterpretacja wyników\nDzięki takiemu rozkładowi częstości słów, nauka języka może zostać przedstawiona\njako przesuwanie się od znajomości najczęściej do najrzadziej znanych zwrotów.\nMożemy też sortować teksty względem ich trudności dla czytelników i dostosowywać\nje do poziomu ucznia. Jesteśmy też w stanie szacować jakie jest\nprawdopodobieństwo napotkania nie znanego słowa w danej próbce tekstu.\n\nWygląda na to, że pogłębienie tego tematu może mieć ciekawe praktyczne\nzastosowania.",
            "feature_image": "__GHOST_URL__/content/images/2022/06/photo-1605429201125-37e867327609.jpeg",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2022-06-11T18:06:15.000Z",
            "updated_at": "2022-06-11T23:06:08.000Z",
            "published_at": "2022-06-11T22:50:51.000Z",
            "custom_excerpt": "Naucz się jak odczytywać duże pliki w Node.js, zliczać wystąpienia słów używając obiektu Map oraz radzić sobie z limitami pamięci.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "62a51695d9c3ae6cbd852f15",
            "uuid": "9e7b1202-dfbb-4d44-b0d8-7b63fadcb60e",
            "title": "Rust",
            "slug": "rust",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\"}],[\"code\",{\"code\":\"cargo new laws\"}],[\"code\",{\"code\":\"cargo run\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.rustup.rs/\",\"rel\",\"nofollow\"]],[\"strong\"]],\"sections\":[[1,\"p\",[]],[1,\"p\",[[0,[],0,\"Instalacja Rust\"]]],[1,\"p\",[[0,[],0,\"The official and recommended method of installing Rust for the purpose of developing software is to use the \"],[0,[0,1],2,\"Rustup toolchain manager\"],[0,[],0,\",\"]]],[10,0],[1,\"p\",[]],[10,1],[1,\"p\",[[0,[],0,\"włączenie programu\"]]],[10,2],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "html": "<p></p><p>Instalacja Rust</p><p>The official and recommended method of installing Rust for the purpose of developing software is to use the <a href=\"https://www.rustup.rs/\" rel=\"nofollow\"><strong>Rustup toolchain manager</strong></a>,</p><pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh</code></pre><p></p><pre><code>cargo new laws</code></pre><p>włączenie programu</p><pre><code>cargo run</code></pre><p></p>",
            "comment_id": "62a51695d9c3ae6cbd852f15",
            "plaintext": "Instalacja Rust\n\nThe official and recommended method of installing Rust for the purpose of developing software is to use the Rustup toolchain manager,\n\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n\n\n\ncargo new laws\n\nwłączenie programu\n\ncargo run\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2022-06-11T22:26:29.000Z",
            "updated_at": "2023-03-10T15:21:47.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "642fb2d0753b4a4d4c3cceda",
            "uuid": "691687c8-6999-410f-a535-840483c9420a",
            "title": "How to install MongoDB 6 on Fedora 37",
            "slug": "how-to-install-mongodb-6-on-fedora-37",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"https://repo.mongodb.org/yum/redhat/\"}],[\"code\",{\"code\":\"sudo tee /etc/yum.repos.d/mongodb-org-6.0.repo<\"}],[\"code\",{\"code\":\"sudo dnf install -y mongodb-org\"}],[\"image\",{\"src\":\"https://preciselab.io/content/images/2023/03/1_SwgB2rxPWgOjbh030ETxyg.png\"}],[\"code\",{\"code\":\"sudo systemctl start mongod\"}],[\"image\",{\"src\":\"https://preciselab.io/content/images/2023/03/Zrzut-ekranu-z-2023-03-02-13-19-32.png\"}],[\"code\",{\"code\":\"wget https://downloads.mongodb.com/compass/mongodb-compass-1.35.0.x86_64.rpm\"}],[\"code\",{\"code\":\"sudo dnf install -y mongodb-compass-1.35.0.x86_64.rpm\"}],[\"image\",{\"src\":\"https://preciselab.io/content/images/2023/03/Zrzut-ekranu-z-2023-03-02-13-41-28.png\"}],[\"code\",{\"code\":\"#replication:\"}],[\"code\",{\"code\":\"replication:\\n  replSetName: \\\"rs0\\\"\"}],[\"code\",{\"code\":\"sudo systemctl restart mongod\"}],[\"code\",{\"code\":\"rs.initiate()\"}],[\"code\",{\"code\":\"rs.status()\"}],[\"image\",{\"src\":\"https://preciselab.io/content/images/2023/03/Zrzut-ekranu-z-2023-03-02-13-30-41.png\"}],[\"image\",{\"src\":\"https://preciselab.io/content/images/2023/03/mongodb-is-web-scale-v0-twb0dwtz8sw81.jpeg\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-red-hat/\"]],[\"a\",[\"href\",\"https://www.mongodb.com/docs/compass/master/install/\"]],[\"a\",[\"href\",\"https://www.mongodb.com/docs/manual/replication/\"]],[\"a\",[\"href\",\"https://www.digitalocean.com/community/tutorials/how-to-configure-a-mongodb-replica-set-on-ubuntu-20-04/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"In official docs there is instruction only for Redhat\"]]],[1,\"p\",[[0,[0],1,\"https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-red-hat/\"]]],[1,\"p\",[[0,[],0,\"and it contains $releasever in repository file. But on fedora $releasever is not defined. So to fix it you can check url\"]]],[10,0],[1,\"p\",[[0,[],0,\"and see that higest version of redhat is 9. Because of Fedora is experimental polygon of Redhat you can derive conclusion that it should works if you use redhat repository on fedora like this:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Now you can install by\"]]],[10,2],[10,3],[1,\"p\",[[0,[],0,\"so there are two assumptions that are correct:\"]]],[3,\"ul\",[[[0,[],0,\"using redhat repo for fedora works\"]],[[0,[],0,\"using dnf for yum repos works\"]]]],[10,4],[1,\"p\",[[0,[],0,\"And you can connect with mongodb by mongosh\"]]],[10,5],[1,\"p\",[[0,[],0,\"Mongosh is better than mongo command because of colors and autocompletion, so use mongosh instead of mongo.\"]]],[1,\"h2\",[[0,[],0,\"Mongo compass\"]]],[1,\"p\",[[0,[],0,\"To browse mongo in graphic mode you will probably choose compass. Following after\"]]],[1,\"p\",[[0,[1],1,\"https://www.mongodb.com/docs/compass/master/install/\"]]],[1,\"p\",[[0,[],0,\"you can download rpm packages\"]]],[10,6],[1,\"p\",[[0,[],0,\"and install it\"]]],[10,7],[10,8],[1,\"h2\",[[0,[],0,\"Enable Mongo Replica Set locally\"]]],[1,\"p\",[[0,[],0,\"Replication described here:\"]]],[1,\"p\",[[0,[2],1,\"https://www.mongodb.com/docs/manual/replication/\"]]],[1,\"p\",[[0,[],0,\"is required by prisma so I am enabling it locally.\"]]],[1,\"p\",[[0,[],0,\"In file /etc/mongod.conf you have to replace\"]]],[10,9],[1,\"p\",[[0,[],0,\"by\"]]],[10,10],[1,\"p\",[[0,[],0,\"then reload mongod service\"]]],[10,11],[1,\"p\",[[0,[],0,\"Login to database by mongosh and use command\"]]],[10,12],[1,\"p\",[[0,[],0,\"then you can confirm changes by\"]]],[10,13],[10,14],[1,\"p\",[[0,[],0,\"If you experiencing more complications there is great article with advanced config\"]]],[1,\"p\",[[0,[3],1,\"https://www.digitalocean.com/community/tutorials/how-to-configure-a-mongodb-replica-set-on-ubuntu-20-04/\"]]],[10,15]]}",
            "html": "<p>In official docs there is instruction only for Redhat</p><p><a href=\"https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-red-hat/\">https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-red-hat/</a></p><p>and it contains $releasever in repository file. But on fedora $releasever is not defined. So to fix it you can check url</p><pre><code>https://repo.mongodb.org/yum/redhat/</code></pre><p>and see that higest version of redhat is 9. Because of Fedora is experimental polygon of Redhat you can derive conclusion that it should works if you use redhat repository on fedora like this:</p><pre><code>sudo tee /etc/yum.repos.d/mongodb-org-6.0.repo&lt;</code></pre><p>Now you can install by</p><pre><code>sudo dnf install -y mongodb-org</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://preciselab.io/content/images/2023/03/1_SwgB2rxPWgOjbh030ETxyg.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>so there are two assumptions that are correct:</p><ul><li>using redhat repo for fedora works</li><li>using dnf for yum repos works</li></ul><pre><code>sudo systemctl start mongod</code></pre><p>And you can connect with mongodb by mongosh</p><figure class=\"kg-card kg-image-card\"><img src=\"https://preciselab.io/content/images/2023/03/Zrzut-ekranu-z-2023-03-02-13-19-32.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Mongosh is better than mongo command because of colors and autocompletion, so use mongosh instead of mongo.</p><h2 id=\"mongo-compass\">Mongo compass</h2><p>To browse mongo in graphic mode you will probably choose compass. Following after</p><p><a href=\"https://www.mongodb.com/docs/compass/master/install/\">https://www.mongodb.com/docs/compass/master/install/</a></p><p>you can download rpm packages</p><pre><code>wget https://downloads.mongodb.com/compass/mongodb-compass-1.35.0.x86_64.rpm</code></pre><p>and install it</p><pre><code>sudo dnf install -y mongodb-compass-1.35.0.x86_64.rpm</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://preciselab.io/content/images/2023/03/Zrzut-ekranu-z-2023-03-02-13-41-28.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><h2 id=\"enable-mongo-replica-set-locally\">Enable Mongo Replica Set locally</h2><p>Replication described here:</p><p><a href=\"https://www.mongodb.com/docs/manual/replication/\">https://www.mongodb.com/docs/manual/replication/</a></p><p>is required by prisma so I am enabling it locally.</p><p>In file /etc/mongod.conf you have to replace</p><pre><code>#replication:</code></pre><p>by</p><pre><code>replication:\n  replSetName: \"rs0\"</code></pre><p>then reload mongod service</p><pre><code>sudo systemctl restart mongod</code></pre><p>Login to database by mongosh and use command</p><pre><code>rs.initiate()</code></pre><p>then you can confirm changes by</p><pre><code>rs.status()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://preciselab.io/content/images/2023/03/Zrzut-ekranu-z-2023-03-02-13-30-41.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>If you experiencing more complications there is great article with advanced config</p><p><a href=\"https://www.digitalocean.com/community/tutorials/how-to-configure-a-mongodb-replica-set-on-ubuntu-20-04/\">https://www.digitalocean.com/community/tutorials/how-to-configure-a-mongodb-replica-set-on-ubuntu-20-04/</a></p><figure class=\"kg-card kg-image-card\"><img src=\"https://preciselab.io/content/images/2023/03/mongodb-is-web-scale-v0-twb0dwtz8sw81.jpeg\" class=\"kg-image\" alt loading=\"lazy\"></figure>",
            "comment_id": "642fb2d0753b4a4d4c3cceda",
            "plaintext": "In official docs there is instruction only for Redhat\n\nhttps://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-red-hat/\n\nand it contains $releasever in repository file. But on fedora $releasever is not defined. So to fix it you can check url\n\nhttps://repo.mongodb.org/yum/redhat/\n\nand see that higest version of redhat is 9. Because of Fedora is experimental polygon of Redhat you can derive conclusion that it should works if you use redhat repository on fedora like this:\n\nsudo tee /etc/yum.repos.d/mongodb-org-6.0.repo<\n\nNow you can install by\n\nsudo dnf install -y mongodb-org\n\nso there are two assumptions that are correct:\n\n * using redhat repo for fedora works\n * using dnf for yum repos works\n\nsudo systemctl start mongod\n\nAnd you can connect with mongodb by mongosh\n\nMongosh is better than mongo command because of colors and autocompletion, so use mongosh instead of mongo.\n\n\nMongo compass\n\nTo browse mongo in graphic mode you will probably choose compass. Following after\n\nhttps://www.mongodb.com/docs/compass/master/install/\n\nyou can download rpm packages\n\nwget https://downloads.mongodb.com/compass/mongodb-compass-1.35.0.x86_64.rpm\n\nand install it\n\nsudo dnf install -y mongodb-compass-1.35.0.x86_64.rpm\n\n\nEnable Mongo Replica Set locally\n\nReplication described here:\n\nhttps://www.mongodb.com/docs/manual/replication/\n\nis required by prisma so I am enabling it locally.\n\nIn file /etc/mongod.conf you have to replace\n\n#replication:\n\nby\n\nreplication:\n  replSetName: \"rs0\"\n\nthen reload mongod service\n\nsudo systemctl restart mongod\n\nLogin to database by mongosh and use command\n\nrs.initiate()\n\nthen you can confirm changes by\n\nrs.status()\n\nIf you experiencing more complications there is great article with advanced config\n\nhttps://www.digitalocean.com/community/tutorials/how-to-configure-a-mongodb-replica-set-on-ubuntu-20-04/",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-07T06:06:08.000Z",
            "updated_at": "2023-04-07T06:06:08.000Z",
            "published_at": "2023-04-07T06:06:07.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          },
          {
            "id": "642fc8c7753b4a4d4c3ccef5",
            "uuid": "d9ec8be1-a9a8-426c-9334-ae71bf71c19a",
            "title": "Jak przygotować się do apokalipsy zombie",
            "slug": "jak-przygotowac-sie-do-apokalipsy-zombie-2",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"W ostatnich 2 latach, coraz częściej słychać o zagrożeniu wywołanym przez apokalipsę zombie. Chociaż dla wielu brzmi to absurdalnie, to fakty mówią same za siebie. W ciągu ostatniej dekady, zarówno w mediach jak i kulturze popularnej, temat ten przysłania inne, bardziej realistyczne zagrożenia.\"]]],[1,\"p\",[[0,[],0,\"Zombie, to fikcyjne istoty, które zwykle zrodziły się jako efekt nieznanych wirusowych chorób. Z otaczającej rzeczywistości, można jednak wywnioskować, że podobna sytuacja może mieć miejsce na skutek pandemii, wirusów odpowiedzialnych za wiele chorób, które już teraz stanowią poważne zagrożenie. Wraz z rosnącą zdolnością ludzkości do przenoszenia się po całym świecie w krótkim czasie, rośnie też ryzyko rozprzestrzenienia się chorób związanych z pandemią.\"]]],[1,\"p\",[[0,[],0,\"Jeśli apokalipsa zombie rzeczywiście nastąpi, skutki będą miały druzgocący wpływ na życie ludzkie. Według badań przeprowadzonych przez naukowców z Uniwersytetu w Leicester, Wielka Brytania, jedna z najpopularniejszych hipotez mówi, że apokalipsą mogą być wywołane wirusy przenoszone przez krótkie łuki. W przypadku takiego wirusa, 75% populacji Ziemi byłoby skazane na wyginięcie już w ciągu pierwszych kilku miesięcy od wybuchu epidemii.\"]]],[1,\"p\",[[0,[],0,\"Z jednej strony, spowodowane apokalipsą zombie, chaos, panika i walka o przetrwanie odcisnęłyby piętno na ludzkim postrzeganiu rzeczywistości. Z drugiej, zmusiłyby ludzi do bardziej efektywnej i mądrej organizacji środowiska i zasobów, aby przetrwać.\"]]],[1,\"p\",[[0,[],0,\"Podsumowując, problem apokalipsy zombie - choć dotychczas wydawał się być jednym z elementów kultury popularnej - wraz z postępem nauki oraz przemieszczaniem się ludzi na całym świecie, zyskuje na realności. Warto zwracać uwagę na zagrożenia pandemią, która może wpłynąć na całą ludzkość. Jedno jest pewne, apokalipsa zombie to tylko czarna wizja. Również podczas rzeczywistych epidemii ludziom udaje się przetrwać i wrócić do normalności.\"]]],[1,\"p\",[[0,[],0,\"II. Zbieranie i przygotowywanie zapasów – jak dobrze przygotować się do przetrwania?\"]]],[1,\"p\",[[0,[],0,\"Jak każdy wie, situacje nadzwyczajne mogą zdarzyć się w każdej chwili. Mogą to być zarówno kataklizmy naturalne, jak i kryzysy polityczne czy pandemie. W takich sytuacjach bardzo ważne jest, aby mieć przygotowane odpowiednie zapasy i narzędzia do przetrwania.\"]]],[1,\"p\",[[0,[],0,\"Wymagane produkty\"]]],[1,\"p\",[[0,[],0,\"Zacznijmy od wymaganych produktów. Każdy zestaw przygotowania do przetrwania powinien zawierać co najmniej te elementy:\"]]],[3,\"ul\",[[[0,[],0,\"Woda – każdy powinien mieć zapas wody pitnej na około 3 dni. Dla większej ilości osób warto pomyśleć o zbiornikach z wodą deszczową lub rozwiązaniach do jej odzyskiwania.\"]],[[0,[],0,\"Żywność – warto postawić na długotrwałe produkty, takie jak konserwy czy suszone owoce i warzywa. Istotne są też produkty bogate w białko, tłuszcze i węglowodany, które zapewnią energię i siłę. Warto zadbać też o przysmaki, które pomogą podnieść morale w trudnych sytuacjach.\"]],[[0,[],0,\"Leki i materiały opatrunkowe – nawet mała ran, która nie będzie wyleczona, może stać się bardzo poważnym problemem w sytuacjach nadzwyczajnych. Dlatego, warto zaopatrzyć się w zestawy pierwszej pomocy i wszystkie niezbędne leki.\"]],[[0,[],0,\"Materiały do uzdatniania wody – w przypadku braku wody pitnej warto zadbać o uzdatnianie wody, co pozwoli zachować uprzednio zgromadzone zapasy wody na dłużej.\"]],[[0,[],0,\"Materiały wybuchowe – w przypadku potrzeby szybkiego, skutecznego i bezkompromisowego działania, warto zainwestować w materiały wybuchowe. Pozwolą one na natychmiastową możliwość niszczenia przeszkód lub otwieranie dróg ewakuacyjnych, co w krytycznych sytuacjach może uratować życie i zdrowie ludzkie.\"]]]],[1,\"p\",[[0,[],0,\"Narzędzia do przetrwania\"]]],[1,\"p\",[[0,[],0,\"Kolejnym elementem są narzędzia, które pomogą przetrwać w różnych sytuacjach. Do najważniejszych należą:\"]]],[3,\"ul\",[[[0,[],0,\"Lampa naftowa lub latarka – w czasie awarii prądu, warto mieć przy sobie latarkę lub lampę naftową, co pozwoli zachować porządek i bezpieczeństwo.\"]],[[0,[],0,\"Radio zasilane bateriami – warto mieć dostęp do informacji, zwłaszcza w czasie kryzysu. Radio zasilane bateriami to bardzo dobre rozwiązanie w takiej sytuacji.\"]],[[0,[],0,\"Namiot lub dostęp do bezpiecznego schronienia – bezpieczna przestrzeń jest kluczowa, zwłaszcza w przypadku sytuacji kryzysowych.\"]],[[0,[],0,\"Kuchenka na biopaliwo – w przypadku braku prądu i gazu, warto mieć alternatywną metodę gotowania. Kuchenka na biopaliwo spełni swoją rolę idealnie.\"]]]],[1,\"p\",[[0,[],0,\"Jak przechowywać zapasy?\"]]],[1,\"p\",[[0,[],0,\"Kiedy mamy już wszystkie niezbędne produkty i narzędzia, warto zadbać o ich odpowiednie przechowywanie. Najlepiej, aby zapasy były przechowywane w suchym, zaciemnionym i chłodnym miejscu, najlepiej zabezpieczonym przed dostępem owadów i gryzoni. Jeśli posiadasz zapasy żywności w puszkach, warto również regularnie sprawdzać, czy nie ma pęknięć lub wypukłości na ich powierzchni.\"]]],[1,\"p\",[[0,[],0,\"Podsumowanie\"]]],[1,\"p\",[[0,[],0,\"Wniosek z powyższych danych jest prosty - na wszelki wypadek warto mieć przygotowane zapasy żywności, wody i narzędzi potrzebnych do przetrwania. W przypadku awarii prądu, braku dostępu do wody pitnej czy żywności, posiadanie takiego zapasu jest kluczowe. Pamiętaj, aby odpowiednio przechowywać swoje zapasy, aby utrzymać ich długotrwałe użytkowanie.\"]]],[1,\"p\",[[0,[],0,\"Schronienie to miejsce, które zapewnia nam bezpieczeństwo w sytuacjach kryzysowych, takich jak trzęsienia ziemi, huragany, tornada czy ataki terrorystyczne. Budowa schronienia wymaga starannego zaplanowania i przygotowania, aby spełniało swoją funkcję i chroniło nas przed zagrożeniami.\"]]],[1,\"p\",[[0,[],0,\"Materiały potrzebne do budowy schronienia zależą od wybranej metody budowy oraz indywidualnych potrzeb. Najczęściej stosowanymi materiałami są: beton, cegła, bloki budowlane oraz drewno. W przypadku budowy schronienia podziemnego, stosuje się także specjalne materiały, jak stalowe płyty czy specjalne bloczki betonowe.\"]]],[1,\"p\",[[0,[],0,\"Punkty, które należy wziąć pod uwagę przy budowie schronienia to przede wszystkim jego lokalizacja. Schronienie powinno być umieszczone w miejscu, które zapewnia maksymalne bezpieczeństwo przed zagrożeniami. Należy także wziąć pod uwagę kwestie dostaw wody i energii elektrycznej, jak również możliwość szybkiego i bezpiecznego ewakuowania się z schronienia.\"]]],[1,\"p\",[[0,[],0,\"W przypadku budowy schronienia podziemnego, należy pamiętać o dostosowaniu go do indywidualnych potrzeb. W takim schronieniu powinny znaleźć się: zapasowa żywność, woda pitna, medykamenty oraz sprzęt i narzędzia potrzebne do przetrwania. Należy także zapewnić odpowiednią wentylację oraz system alarmowy, który umożliwi ostrzeżenie przed zagrożeniem.\"]]],[1,\"p\",[[0,[],0,\"Podsumowując, budowa schronienia jest procesem, który wymaga starannego przygotowania i zaplanowania. Właściwie dobrane materiały oraz lokalizacja, a także uwzględnienie potrzeb indywidualnych, pozwala osiągnąć maksymalne bezpieczeństwo w trudnych sytuacjach.\"]]],[1,\"p\",[[0,[],0,\"Według teorii zombie apokalipsy, jednym z najważniejszych aspektów przetrwania jest uzbrojenie się i obrona przed zombie. Istnieje wiele rodzajów broni, które mogą być skuteczne przeciwko zombie, włączając w to broń palną, narzędzia ręczne i ostrza.\"]]],[1,\"p\",[[0,[],0,\"Broń palna to najczęściej stosowane narzędzie w walce z zombie. Najpopularniejszymi rodzajami broni palnej są karabiny i pistolety, a także strzelby. Niezwykle ważne jest jednak, aby zdać sobie sprawę, że broń palna jest jedynie tymczasowym rozwiązaniem, ponieważ amunicja może się wyczerpać, a broni trzeba będzie używać w sposób ostrożny, aby uniknąć przyciągnięcia większej liczby zombie.\"]]],[1,\"p\",[[0,[],0,\"Oprócz broni palnej, istnieją również narzędzia ręczne, które mogą być wykorzystane w walce z zombie. Najpopularniejsze w tym przypadku są topory, siekiery, noże i piły. Narzędzia te są bardziej trwałe niż broń palna i nie wymagają amunicji, zapewniając przede wszystkim większą kontrolę w walce.\"]]],[1,\"p\",[[0,[],0,\"Jednym z najważniejszych aspektów walki z zombie jest samoobrona i techniki walki. W przypadku samoobrony należy unikać bezpośredniego kontaktu i próbować utrzymać dystans między sobą a zombie. Techniki walki obejmują uderzanie i kopanie, ale również układanie pułapek i blokowanie przejść.\"]]],[1,\"p\",[[0,[],0,\"Kolejnym ważnym aspektem uzbrojenia się i obrony są schrony antyzombie. W ostatnich latach popularność zdobyły schrony betonowe, które zapewniają odporność na ataki zombie i są w stanie pomieścić większą liczbę ludzi. Istnieją również schrony podziemne, ale ich budowa wymaga większej wiedzy technicznej i finansowej.\"]]],[1,\"p\",[[0,[],0,\"Dostępność broni i wyposażenia obrony przed zombie zależy od kraju i jego przepisów dotyczących broni. W Stanach Zjednoczonych dostępność broni jest stosunkowo łatwa, ale w Europie jak również w Polsce, wymagane są specjalne pozwolenia i odebranie egzaminów na ich posiadanie. Cena broni i wyposażenia zależy od rodzaju broni, producenta oraz sposobu jej użytkowania.\"]]],[1,\"p\",[[0,[],0,\"Podsumowując, aby przeżyć w świecie zombie, konieczne jest uzbrojenie się i obrona. Istnieje wiele narzędzi, które mogą być skuteczne w walce z zombie. Należy jednak zdać sobie sprawę, że broń jest jedynie tymczasowym rozwiązaniem, a samoobrona i techniki walki, jak również schrony antyzombie są równie ważne w przetrwaniu zombie apokalipsy.\"]]],[1,\"p\",[[0,[],0,\"Temat ewakuacji przed zombie stanowi niezwykle ważny aspekt, który powinien zostać uwzględniony przez każdego mieszkańca miasta. Szacuje się, że zombie stanowią realne zagrożenie dla społeczeństwa, a ich wystąpienie może nieść za sobą ogromne konsekwencje dla ludzi i infrastruktury miasta.\"]]],[1,\"p\",[[0,[],0,\"W pierwszej kolejności, aby przygotować plan ewakuacji, należy zastanowić się, gdzie schronić się przed zombie. Najlepszą opcją jest zawsze ucieczka z miejsca, w którym widzimy pierwsze oznaki pojawienia się żywych trupów. W przypadku ocalałych miast, warto w pierwszej kolejności skontaktować się z lokalną strażą pożarną, aby uzyskać informacje na temat dedykowanych miejsc schronienia w przypadku wystąpienia pandemii zombie.\"]]],[1,\"p\",[[0,[],0,\"Jeśli jednak nie ma takiej możliwości, warto zapoznać się z przestrzenią wokół nas - w poszukiwaniu możliwych miejsc schronienia zwracajmy uwagę na ukryte miejsca, które zapewnią nam bezpieczeństwo, będących poza zasięgiem zombie. Być może znajdziemy dzielnicę mieszkaniową z wielkimi, ogrodzonymi posesjami lub gęste lasy, w których będzie niemożliwe do przebycia dla zombiaków.\"]]],[1,\"p\",[[0,[],0,\"Po ustaleniu lokalizacji schronienia warto pomyśleć o sposobie szybkiego i bezpiecznego opuszczenia miasta. Warto mieć przygotowaną dobrze zaopatrzoną torbę z niezbędnymi do przetrwania przedmiotami, np. wodą, żywnością, ubraniem i podstawowymi narzędziami.Dobre okulary przeciwsłoneczne,szalik albo chusta i kurtka zimowa również pomogą w przeżyciu.\"]]],[1,\"p\",[[0,[],0,\"Warto również zapoznać się z drogami ucieczki i trasami, które prowadzą poza miasto. Jeśli masz samochód, należy upewnić się, że jest w dobrym stanie technicznym, z pełnym zbiornikiem paliwa i odpowiednim narzędziem wydobywczym w bagażniku.\"]]],[1,\"p\",[[0,[],0,\"Podsumowując, kluczowe znaczenie ma dobrze przygotowany plan ewakuacji przed zombie. Warto wiedzieć, gdzie szukać schronienia i jak szybko i bezpiecznie opuścić miasto. Dzięki temu każdy z nas może zminimalizować ryzyko i podjąć odpowiednie kroki w przypadku wystąpienia pandemii zombie.\"]]],[1,\"p\",[[0,[],0,\"Przygotowanie psychiczne jest kluczowe w sytuacjach kryzysowych, takich jak wypadki drogowe, katastrofy naturalne czy ataki terroryzmu. Bez odpowiedniego przygotowania, nawet najbardziej doświadczeni ratownicy czy pracownicy służb ratunkowych mogą zapanować nad stresem i traumą, co utrudni osiągnięcie celów w sytuacji kryzysowej.\"]]],[1,\"p\",[[0,[],0,\"Stres i trauma to naturalne reakcje organizmu w sytuacjach, w których zagrożone jest życie lub zdrowie, bądź też mają miejsce traumatyczne zdarzenia. Wśród objawów można wymienić trudności w koncentracji, kłopoty z pamięcią, zwiększone poczucie lęku, drażliwość, zmiany nastroju czy kłopoty ze snem.\"]]],[1,\"p\",[[0,[],0,\"Aby zachować spokój w przypadku apokalipsy zombie, warto zwrócić uwagę na kilka kluczowych elementów. Pierwszym krokiem jest przygotowanie fizyczne i mentalne. Trzeba zadbać o odpowiednie przygotowanie pod względem kondycji fizycznej, tak by być gotowym do biegu i walki. Oprócz tego warto opracować plan działania, tak by nie tracić czasu na zbędne decyzje.\"]]],[1,\"p\",[[0,[],0,\"Kolejnym ważnym elementem przygotowania psychicznego jest identyfikacja własnych reakcji na stres oraz umiejętność radzenia sobie z nimi. Warto opracować techniki relaksacyjne, które pomogą w redukcji poziomu lęku i stresu. Do popularnych metod zalicza się medytację, jogę, oddechowe techniki relaksacyjne czy klasyczną terapię.\"]]],[1,\"p\",[[0,[],0,\"Warto pamiętać, że przygotowanie psychiczne w przypadku sytuacji kryzysowej jest procesem długotrwałym. Nie da się nauczyć się wszystkiego w ciągu jednego dnia czy tygodnia. Trzeba poświęcać czas i wysiłek, by osiągnąć poziom przygotowania odpowiedni do zaistniałych okoliczności.\"]]],[1,\"p\",[[0,[],0,\"Podsumowując, przygotowanie psychiczne to kluczowy element w sytuacjach kryzysowych. Należy poświęcić czas na przygotowanie się fizyczne i mentalne przed zagrożeniem. Warto zwrócić uwagę na identyfikację swoich reakcji na stres oraz umiejętność radzenia sobie z nimi. Pamiętajmy, że przygotowanie psychiczne to proces długotrwały, wymagający czasu i pracy.\"]]],[1,\"p\",[[0,[],0,\"Z przygotowaniem się do apokalipsy zombie wiąże się wiele kroków i aspektów, których nie można pominąć. Przede wszystkim konieczne jest zaopatrzenie się w odpowiednie rzeczy, takie jak żywność, wodę czy lekarstwa. Zgodnie z zasadą „lepiej mieć i nie potrzebować, niż potrzebować i nie mieć”, warto również wziąć pod uwagę materiały budowlane, narzędzia i sprzęt, które mogą przydać się w czasie kryzysu.\"]]],[1,\"p\",[[0,[],0,\"Dane pokazują, że wiele osób bagatelizuje potrzebę przygotowania się do takiej sytuacji, ale gdy już coś się wydarzy, często jest już za późno na działanie. W Stanach Zjednoczonych, gdzie kultura horrorów i popkultury związanej z apokalipsami jest wyjątkowo popularna, tylko około 20% ludzi przygotowuje się na wypadek kryzysu, w tym zombie. Tymczasem, jak pokazują badania, przygotowanie się do sytuacji kryzysowej pozwala zwiększyć szanse na przeżycie o ponad trzykrotnie.\"]]],[1,\"p\",[[0,[],0,\"Nie można też zapominać o przygotowaniu psychicznym. Psychologowie podkreślają, że bez pewnej formy przygotowania nie jesteśmy w stanie skutecznie radzić sobie w sytuacjach ekstremalnych. Ważna jest tu przede wszystkim umiejętność radzenia sobie ze stresem i kryzysem emocjonalnym, a także właściwe podejście do zagrożeń i podejmowanie racjonalnych decyzji.\"]]],[1,\"p\",[[0,[],0,\"Podsumowując, przygotowanie się do sytuacji apokalipsy zombie jest skomplikowanym procesem, wymagającym zarówno odpowiedniego zaopatrzenia, jak i przygotowania psychicznego. Pomimo tego, że nie należy do łatwych i przyjemnych, może okazać się kluczowe dla przetrwania w sytuacjach kryzysowych.\"]]]]}",
            "html": "<p>W ostatnich 2 latach, coraz częściej słychać o zagrożeniu wywołanym przez apokalipsę zombie. Chociaż dla wielu brzmi to absurdalnie, to fakty mówią same za siebie. W ciągu ostatniej dekady, zarówno w mediach jak i kulturze popularnej, temat ten przysłania inne, bardziej realistyczne zagrożenia.</p><p>Zombie, to fikcyjne istoty, które zwykle zrodziły się jako efekt nieznanych wirusowych chorób. Z otaczającej rzeczywistości, można jednak wywnioskować, że podobna sytuacja może mieć miejsce na skutek pandemii, wirusów odpowiedzialnych za wiele chorób, które już teraz stanowią poważne zagrożenie. Wraz z rosnącą zdolnością ludzkości do przenoszenia się po całym świecie w krótkim czasie, rośnie też ryzyko rozprzestrzenienia się chorób związanych z pandemią.</p><p>Jeśli apokalipsa zombie rzeczywiście nastąpi, skutki będą miały druzgocący wpływ na życie ludzkie. Według badań przeprowadzonych przez naukowców z Uniwersytetu w Leicester, Wielka Brytania, jedna z najpopularniejszych hipotez mówi, że apokalipsą mogą być wywołane wirusy przenoszone przez krótkie łuki. W przypadku takiego wirusa, 75% populacji Ziemi byłoby skazane na wyginięcie już w ciągu pierwszych kilku miesięcy od wybuchu epidemii.</p><p>Z jednej strony, spowodowane apokalipsą zombie, chaos, panika i walka o przetrwanie odcisnęłyby piętno na ludzkim postrzeganiu rzeczywistości. Z drugiej, zmusiłyby ludzi do bardziej efektywnej i mądrej organizacji środowiska i zasobów, aby przetrwać.</p><p>Podsumowując, problem apokalipsy zombie - choć dotychczas wydawał się być jednym z elementów kultury popularnej - wraz z postępem nauki oraz przemieszczaniem się ludzi na całym świecie, zyskuje na realności. Warto zwracać uwagę na zagrożenia pandemią, która może wpłynąć na całą ludzkość. Jedno jest pewne, apokalipsa zombie to tylko czarna wizja. Również podczas rzeczywistych epidemii ludziom udaje się przetrwać i wrócić do normalności.</p><p>II. Zbieranie i przygotowywanie zapasów – jak dobrze przygotować się do przetrwania?</p><p>Jak każdy wie, situacje nadzwyczajne mogą zdarzyć się w każdej chwili. Mogą to być zarówno kataklizmy naturalne, jak i kryzysy polityczne czy pandemie. W takich sytuacjach bardzo ważne jest, aby mieć przygotowane odpowiednie zapasy i narzędzia do przetrwania.</p><p>Wymagane produkty</p><p>Zacznijmy od wymaganych produktów. Każdy zestaw przygotowania do przetrwania powinien zawierać co najmniej te elementy:</p><ul><li>Woda – każdy powinien mieć zapas wody pitnej na około 3 dni. Dla większej ilości osób warto pomyśleć o zbiornikach z wodą deszczową lub rozwiązaniach do jej odzyskiwania.</li><li>Żywność – warto postawić na długotrwałe produkty, takie jak konserwy czy suszone owoce i warzywa. Istotne są też produkty bogate w białko, tłuszcze i węglowodany, które zapewnią energię i siłę. Warto zadbać też o przysmaki, które pomogą podnieść morale w trudnych sytuacjach.</li><li>Leki i materiały opatrunkowe – nawet mała ran, która nie będzie wyleczona, może stać się bardzo poważnym problemem w sytuacjach nadzwyczajnych. Dlatego, warto zaopatrzyć się w zestawy pierwszej pomocy i wszystkie niezbędne leki.</li><li>Materiały do uzdatniania wody – w przypadku braku wody pitnej warto zadbać o uzdatnianie wody, co pozwoli zachować uprzednio zgromadzone zapasy wody na dłużej.</li><li>Materiały wybuchowe – w przypadku potrzeby szybkiego, skutecznego i bezkompromisowego działania, warto zainwestować w materiały wybuchowe. Pozwolą one na natychmiastową możliwość niszczenia przeszkód lub otwieranie dróg ewakuacyjnych, co w krytycznych sytuacjach może uratować życie i zdrowie ludzkie.</li></ul><p>Narzędzia do przetrwania</p><p>Kolejnym elementem są narzędzia, które pomogą przetrwać w różnych sytuacjach. Do najważniejszych należą:</p><ul><li>Lampa naftowa lub latarka – w czasie awarii prądu, warto mieć przy sobie latarkę lub lampę naftową, co pozwoli zachować porządek i bezpieczeństwo.</li><li>Radio zasilane bateriami – warto mieć dostęp do informacji, zwłaszcza w czasie kryzysu. Radio zasilane bateriami to bardzo dobre rozwiązanie w takiej sytuacji.</li><li>Namiot lub dostęp do bezpiecznego schronienia – bezpieczna przestrzeń jest kluczowa, zwłaszcza w przypadku sytuacji kryzysowych.</li><li>Kuchenka na biopaliwo – w przypadku braku prądu i gazu, warto mieć alternatywną metodę gotowania. Kuchenka na biopaliwo spełni swoją rolę idealnie.</li></ul><p>Jak przechowywać zapasy?</p><p>Kiedy mamy już wszystkie niezbędne produkty i narzędzia, warto zadbać o ich odpowiednie przechowywanie. Najlepiej, aby zapasy były przechowywane w suchym, zaciemnionym i chłodnym miejscu, najlepiej zabezpieczonym przed dostępem owadów i gryzoni. Jeśli posiadasz zapasy żywności w puszkach, warto również regularnie sprawdzać, czy nie ma pęknięć lub wypukłości na ich powierzchni.</p><p>Podsumowanie</p><p>Wniosek z powyższych danych jest prosty - na wszelki wypadek warto mieć przygotowane zapasy żywności, wody i narzędzi potrzebnych do przetrwania. W przypadku awarii prądu, braku dostępu do wody pitnej czy żywności, posiadanie takiego zapasu jest kluczowe. Pamiętaj, aby odpowiednio przechowywać swoje zapasy, aby utrzymać ich długotrwałe użytkowanie.</p><p>Schronienie to miejsce, które zapewnia nam bezpieczeństwo w sytuacjach kryzysowych, takich jak trzęsienia ziemi, huragany, tornada czy ataki terrorystyczne. Budowa schronienia wymaga starannego zaplanowania i przygotowania, aby spełniało swoją funkcję i chroniło nas przed zagrożeniami.</p><p>Materiały potrzebne do budowy schronienia zależą od wybranej metody budowy oraz indywidualnych potrzeb. Najczęściej stosowanymi materiałami są: beton, cegła, bloki budowlane oraz drewno. W przypadku budowy schronienia podziemnego, stosuje się także specjalne materiały, jak stalowe płyty czy specjalne bloczki betonowe.</p><p>Punkty, które należy wziąć pod uwagę przy budowie schronienia to przede wszystkim jego lokalizacja. Schronienie powinno być umieszczone w miejscu, które zapewnia maksymalne bezpieczeństwo przed zagrożeniami. Należy także wziąć pod uwagę kwestie dostaw wody i energii elektrycznej, jak również możliwość szybkiego i bezpiecznego ewakuowania się z schronienia.</p><p>W przypadku budowy schronienia podziemnego, należy pamiętać o dostosowaniu go do indywidualnych potrzeb. W takim schronieniu powinny znaleźć się: zapasowa żywność, woda pitna, medykamenty oraz sprzęt i narzędzia potrzebne do przetrwania. Należy także zapewnić odpowiednią wentylację oraz system alarmowy, który umożliwi ostrzeżenie przed zagrożeniem.</p><p>Podsumowując, budowa schronienia jest procesem, który wymaga starannego przygotowania i zaplanowania. Właściwie dobrane materiały oraz lokalizacja, a także uwzględnienie potrzeb indywidualnych, pozwala osiągnąć maksymalne bezpieczeństwo w trudnych sytuacjach.</p><p>Według teorii zombie apokalipsy, jednym z najważniejszych aspektów przetrwania jest uzbrojenie się i obrona przed zombie. Istnieje wiele rodzajów broni, które mogą być skuteczne przeciwko zombie, włączając w to broń palną, narzędzia ręczne i ostrza.</p><p>Broń palna to najczęściej stosowane narzędzie w walce z zombie. Najpopularniejszymi rodzajami broni palnej są karabiny i pistolety, a także strzelby. Niezwykle ważne jest jednak, aby zdać sobie sprawę, że broń palna jest jedynie tymczasowym rozwiązaniem, ponieważ amunicja może się wyczerpać, a broni trzeba będzie używać w sposób ostrożny, aby uniknąć przyciągnięcia większej liczby zombie.</p><p>Oprócz broni palnej, istnieją również narzędzia ręczne, które mogą być wykorzystane w walce z zombie. Najpopularniejsze w tym przypadku są topory, siekiery, noże i piły. Narzędzia te są bardziej trwałe niż broń palna i nie wymagają amunicji, zapewniając przede wszystkim większą kontrolę w walce.</p><p>Jednym z najważniejszych aspektów walki z zombie jest samoobrona i techniki walki. W przypadku samoobrony należy unikać bezpośredniego kontaktu i próbować utrzymać dystans między sobą a zombie. Techniki walki obejmują uderzanie i kopanie, ale również układanie pułapek i blokowanie przejść.</p><p>Kolejnym ważnym aspektem uzbrojenia się i obrony są schrony antyzombie. W ostatnich latach popularność zdobyły schrony betonowe, które zapewniają odporność na ataki zombie i są w stanie pomieścić większą liczbę ludzi. Istnieją również schrony podziemne, ale ich budowa wymaga większej wiedzy technicznej i finansowej.</p><p>Dostępność broni i wyposażenia obrony przed zombie zależy od kraju i jego przepisów dotyczących broni. W Stanach Zjednoczonych dostępność broni jest stosunkowo łatwa, ale w Europie jak również w Polsce, wymagane są specjalne pozwolenia i odebranie egzaminów na ich posiadanie. Cena broni i wyposażenia zależy od rodzaju broni, producenta oraz sposobu jej użytkowania.</p><p>Podsumowując, aby przeżyć w świecie zombie, konieczne jest uzbrojenie się i obrona. Istnieje wiele narzędzi, które mogą być skuteczne w walce z zombie. Należy jednak zdać sobie sprawę, że broń jest jedynie tymczasowym rozwiązaniem, a samoobrona i techniki walki, jak również schrony antyzombie są równie ważne w przetrwaniu zombie apokalipsy.</p><p>Temat ewakuacji przed zombie stanowi niezwykle ważny aspekt, który powinien zostać uwzględniony przez każdego mieszkańca miasta. Szacuje się, że zombie stanowią realne zagrożenie dla społeczeństwa, a ich wystąpienie może nieść za sobą ogromne konsekwencje dla ludzi i infrastruktury miasta.</p><p>W pierwszej kolejności, aby przygotować plan ewakuacji, należy zastanowić się, gdzie schronić się przed zombie. Najlepszą opcją jest zawsze ucieczka z miejsca, w którym widzimy pierwsze oznaki pojawienia się żywych trupów. W przypadku ocalałych miast, warto w pierwszej kolejności skontaktować się z lokalną strażą pożarną, aby uzyskać informacje na temat dedykowanych miejsc schronienia w przypadku wystąpienia pandemii zombie.</p><p>Jeśli jednak nie ma takiej możliwości, warto zapoznać się z przestrzenią wokół nas - w poszukiwaniu możliwych miejsc schronienia zwracajmy uwagę na ukryte miejsca, które zapewnią nam bezpieczeństwo, będących poza zasięgiem zombie. Być może znajdziemy dzielnicę mieszkaniową z wielkimi, ogrodzonymi posesjami lub gęste lasy, w których będzie niemożliwe do przebycia dla zombiaków.</p><p>Po ustaleniu lokalizacji schronienia warto pomyśleć o sposobie szybkiego i bezpiecznego opuszczenia miasta. Warto mieć przygotowaną dobrze zaopatrzoną torbę z niezbędnymi do przetrwania przedmiotami, np. wodą, żywnością, ubraniem i podstawowymi narzędziami.Dobre okulary przeciwsłoneczne,szalik albo chusta i kurtka zimowa również pomogą w przeżyciu.</p><p>Warto również zapoznać się z drogami ucieczki i trasami, które prowadzą poza miasto. Jeśli masz samochód, należy upewnić się, że jest w dobrym stanie technicznym, z pełnym zbiornikiem paliwa i odpowiednim narzędziem wydobywczym w bagażniku.</p><p>Podsumowując, kluczowe znaczenie ma dobrze przygotowany plan ewakuacji przed zombie. Warto wiedzieć, gdzie szukać schronienia i jak szybko i bezpiecznie opuścić miasto. Dzięki temu każdy z nas może zminimalizować ryzyko i podjąć odpowiednie kroki w przypadku wystąpienia pandemii zombie.</p><p>Przygotowanie psychiczne jest kluczowe w sytuacjach kryzysowych, takich jak wypadki drogowe, katastrofy naturalne czy ataki terroryzmu. Bez odpowiedniego przygotowania, nawet najbardziej doświadczeni ratownicy czy pracownicy służb ratunkowych mogą zapanować nad stresem i traumą, co utrudni osiągnięcie celów w sytuacji kryzysowej.</p><p>Stres i trauma to naturalne reakcje organizmu w sytuacjach, w których zagrożone jest życie lub zdrowie, bądź też mają miejsce traumatyczne zdarzenia. Wśród objawów można wymienić trudności w koncentracji, kłopoty z pamięcią, zwiększone poczucie lęku, drażliwość, zmiany nastroju czy kłopoty ze snem.</p><p>Aby zachować spokój w przypadku apokalipsy zombie, warto zwrócić uwagę na kilka kluczowych elementów. Pierwszym krokiem jest przygotowanie fizyczne i mentalne. Trzeba zadbać o odpowiednie przygotowanie pod względem kondycji fizycznej, tak by być gotowym do biegu i walki. Oprócz tego warto opracować plan działania, tak by nie tracić czasu na zbędne decyzje.</p><p>Kolejnym ważnym elementem przygotowania psychicznego jest identyfikacja własnych reakcji na stres oraz umiejętność radzenia sobie z nimi. Warto opracować techniki relaksacyjne, które pomogą w redukcji poziomu lęku i stresu. Do popularnych metod zalicza się medytację, jogę, oddechowe techniki relaksacyjne czy klasyczną terapię.</p><p>Warto pamiętać, że przygotowanie psychiczne w przypadku sytuacji kryzysowej jest procesem długotrwałym. Nie da się nauczyć się wszystkiego w ciągu jednego dnia czy tygodnia. Trzeba poświęcać czas i wysiłek, by osiągnąć poziom przygotowania odpowiedni do zaistniałych okoliczności.</p><p>Podsumowując, przygotowanie psychiczne to kluczowy element w sytuacjach kryzysowych. Należy poświęcić czas na przygotowanie się fizyczne i mentalne przed zagrożeniem. Warto zwrócić uwagę na identyfikację swoich reakcji na stres oraz umiejętność radzenia sobie z nimi. Pamiętajmy, że przygotowanie psychiczne to proces długotrwały, wymagający czasu i pracy.</p><p>Z przygotowaniem się do apokalipsy zombie wiąże się wiele kroków i aspektów, których nie można pominąć. Przede wszystkim konieczne jest zaopatrzenie się w odpowiednie rzeczy, takie jak żywność, wodę czy lekarstwa. Zgodnie z zasadą „lepiej mieć i nie potrzebować, niż potrzebować i nie mieć”, warto również wziąć pod uwagę materiały budowlane, narzędzia i sprzęt, które mogą przydać się w czasie kryzysu.</p><p>Dane pokazują, że wiele osób bagatelizuje potrzebę przygotowania się do takiej sytuacji, ale gdy już coś się wydarzy, często jest już za późno na działanie. W Stanach Zjednoczonych, gdzie kultura horrorów i popkultury związanej z apokalipsami jest wyjątkowo popularna, tylko około 20% ludzi przygotowuje się na wypadek kryzysu, w tym zombie. Tymczasem, jak pokazują badania, przygotowanie się do sytuacji kryzysowej pozwala zwiększyć szanse na przeżycie o ponad trzykrotnie.</p><p>Nie można też zapominać o przygotowaniu psychicznym. Psychologowie podkreślają, że bez pewnej formy przygotowania nie jesteśmy w stanie skutecznie radzić sobie w sytuacjach ekstremalnych. Ważna jest tu przede wszystkim umiejętność radzenia sobie ze stresem i kryzysem emocjonalnym, a także właściwe podejście do zagrożeń i podejmowanie racjonalnych decyzji.</p><p>Podsumowując, przygotowanie się do sytuacji apokalipsy zombie jest skomplikowanym procesem, wymagającym zarówno odpowiedniego zaopatrzenia, jak i przygotowania psychicznego. Pomimo tego, że nie należy do łatwych i przyjemnych, może okazać się kluczowe dla przetrwania w sytuacjach kryzysowych.</p>",
            "comment_id": "642fc8c7753b4a4d4c3ccef5",
            "plaintext": "W ostatnich 2 latach, coraz częściej słychać o zagrożeniu wywołanym przez apokalipsę zombie. Chociaż dla wielu brzmi to absurdalnie, to fakty mówią same za siebie. W ciągu ostatniej dekady, zarówno w mediach jak i kulturze popularnej, temat ten przysłania inne, bardziej realistyczne zagrożenia.\n\nZombie, to fikcyjne istoty, które zwykle zrodziły się jako efekt nieznanych wirusowych chorób. Z otaczającej rzeczywistości, można jednak wywnioskować, że podobna sytuacja może mieć miejsce na skutek pandemii, wirusów odpowiedzialnych za wiele chorób, które już teraz stanowią poważne zagrożenie. Wraz z rosnącą zdolnością ludzkości do przenoszenia się po całym świecie w krótkim czasie, rośnie też ryzyko rozprzestrzenienia się chorób związanych z pandemią.\n\nJeśli apokalipsa zombie rzeczywiście nastąpi, skutki będą miały druzgocący wpływ na życie ludzkie. Według badań przeprowadzonych przez naukowców z Uniwersytetu w Leicester, Wielka Brytania, jedna z najpopularniejszych hipotez mówi, że apokalipsą mogą być wywołane wirusy przenoszone przez krótkie łuki. W przypadku takiego wirusa, 75% populacji Ziemi byłoby skazane na wyginięcie już w ciągu pierwszych kilku miesięcy od wybuchu epidemii.\n\nZ jednej strony, spowodowane apokalipsą zombie, chaos, panika i walka o przetrwanie odcisnęłyby piętno na ludzkim postrzeganiu rzeczywistości. Z drugiej, zmusiłyby ludzi do bardziej efektywnej i mądrej organizacji środowiska i zasobów, aby przetrwać.\n\nPodsumowując, problem apokalipsy zombie - choć dotychczas wydawał się być jednym z elementów kultury popularnej - wraz z postępem nauki oraz przemieszczaniem się ludzi na całym świecie, zyskuje na realności. Warto zwracać uwagę na zagrożenia pandemią, która może wpłynąć na całą ludzkość. Jedno jest pewne, apokalipsa zombie to tylko czarna wizja. Również podczas rzeczywistych epidemii ludziom udaje się przetrwać i wrócić do normalności.\n\nII. Zbieranie i przygotowywanie zapasów – jak dobrze przygotować się do przetrwania?\n\nJak każdy wie, situacje nadzwyczajne mogą zdarzyć się w każdej chwili. Mogą to być zarówno kataklizmy naturalne, jak i kryzysy polityczne czy pandemie. W takich sytuacjach bardzo ważne jest, aby mieć przygotowane odpowiednie zapasy i narzędzia do przetrwania.\n\nWymagane produkty\n\nZacznijmy od wymaganych produktów. Każdy zestaw przygotowania do przetrwania powinien zawierać co najmniej te elementy:\n\n * Woda – każdy powinien mieć zapas wody pitnej na około 3 dni. Dla większej ilości osób warto pomyśleć o zbiornikach z wodą deszczową lub rozwiązaniach do jej odzyskiwania.\n * Żywność – warto postawić na długotrwałe produkty, takie jak konserwy czy suszone owoce i warzywa. Istotne są też produkty bogate w białko, tłuszcze i węglowodany, które zapewnią energię i siłę. Warto zadbać też o przysmaki, które pomogą podnieść morale w trudnych sytuacjach.\n * Leki i materiały opatrunkowe – nawet mała ran, która nie będzie wyleczona, może stać się bardzo poważnym problemem w sytuacjach nadzwyczajnych. Dlatego, warto zaopatrzyć się w zestawy pierwszej pomocy i wszystkie niezbędne leki.\n * Materiały do uzdatniania wody – w przypadku braku wody pitnej warto zadbać o uzdatnianie wody, co pozwoli zachować uprzednio zgromadzone zapasy wody na dłużej.\n * Materiały wybuchowe – w przypadku potrzeby szybkiego, skutecznego i bezkompromisowego działania, warto zainwestować w materiały wybuchowe. Pozwolą one na natychmiastową możliwość niszczenia przeszkód lub otwieranie dróg ewakuacyjnych, co w krytycznych sytuacjach może uratować życie i zdrowie ludzkie.\n\nNarzędzia do przetrwania\n\nKolejnym elementem są narzędzia, które pomogą przetrwać w różnych sytuacjach. Do najważniejszych należą:\n\n * Lampa naftowa lub latarka – w czasie awarii prądu, warto mieć przy sobie latarkę lub lampę naftową, co pozwoli zachować porządek i bezpieczeństwo.\n * Radio zasilane bateriami – warto mieć dostęp do informacji, zwłaszcza w czasie kryzysu. Radio zasilane bateriami to bardzo dobre rozwiązanie w takiej sytuacji.\n * Namiot lub dostęp do bezpiecznego schronienia – bezpieczna przestrzeń jest kluczowa, zwłaszcza w przypadku sytuacji kryzysowych.\n * Kuchenka na biopaliwo – w przypadku braku prądu i gazu, warto mieć alternatywną metodę gotowania. Kuchenka na biopaliwo spełni swoją rolę idealnie.\n\nJak przechowywać zapasy?\n\nKiedy mamy już wszystkie niezbędne produkty i narzędzia, warto zadbać o ich odpowiednie przechowywanie. Najlepiej, aby zapasy były przechowywane w suchym, zaciemnionym i chłodnym miejscu, najlepiej zabezpieczonym przed dostępem owadów i gryzoni. Jeśli posiadasz zapasy żywności w puszkach, warto również regularnie sprawdzać, czy nie ma pęknięć lub wypukłości na ich powierzchni.\n\nPodsumowanie\n\nWniosek z powyższych danych jest prosty - na wszelki wypadek warto mieć przygotowane zapasy żywności, wody i narzędzi potrzebnych do przetrwania. W przypadku awarii prądu, braku dostępu do wody pitnej czy żywności, posiadanie takiego zapasu jest kluczowe. Pamiętaj, aby odpowiednio przechowywać swoje zapasy, aby utrzymać ich długotrwałe użytkowanie.\n\nSchronienie to miejsce, które zapewnia nam bezpieczeństwo w sytuacjach kryzysowych, takich jak trzęsienia ziemi, huragany, tornada czy ataki terrorystyczne. Budowa schronienia wymaga starannego zaplanowania i przygotowania, aby spełniało swoją funkcję i chroniło nas przed zagrożeniami.\n\nMateriały potrzebne do budowy schronienia zależą od wybranej metody budowy oraz indywidualnych potrzeb. Najczęściej stosowanymi materiałami są: beton, cegła, bloki budowlane oraz drewno. W przypadku budowy schronienia podziemnego, stosuje się także specjalne materiały, jak stalowe płyty czy specjalne bloczki betonowe.\n\nPunkty, które należy wziąć pod uwagę przy budowie schronienia to przede wszystkim jego lokalizacja. Schronienie powinno być umieszczone w miejscu, które zapewnia maksymalne bezpieczeństwo przed zagrożeniami. Należy także wziąć pod uwagę kwestie dostaw wody i energii elektrycznej, jak również możliwość szybkiego i bezpiecznego ewakuowania się z schronienia.\n\nW przypadku budowy schronienia podziemnego, należy pamiętać o dostosowaniu go do indywidualnych potrzeb. W takim schronieniu powinny znaleźć się: zapasowa żywność, woda pitna, medykamenty oraz sprzęt i narzędzia potrzebne do przetrwania. Należy także zapewnić odpowiednią wentylację oraz system alarmowy, który umożliwi ostrzeżenie przed zagrożeniem.\n\nPodsumowując, budowa schronienia jest procesem, który wymaga starannego przygotowania i zaplanowania. Właściwie dobrane materiały oraz lokalizacja, a także uwzględnienie potrzeb indywidualnych, pozwala osiągnąć maksymalne bezpieczeństwo w trudnych sytuacjach.\n\nWedług teorii zombie apokalipsy, jednym z najważniejszych aspektów przetrwania jest uzbrojenie się i obrona przed zombie. Istnieje wiele rodzajów broni, które mogą być skuteczne przeciwko zombie, włączając w to broń palną, narzędzia ręczne i ostrza.\n\nBroń palna to najczęściej stosowane narzędzie w walce z zombie. Najpopularniejszymi rodzajami broni palnej są karabiny i pistolety, a także strzelby. Niezwykle ważne jest jednak, aby zdać sobie sprawę, że broń palna jest jedynie tymczasowym rozwiązaniem, ponieważ amunicja może się wyczerpać, a broni trzeba będzie używać w sposób ostrożny, aby uniknąć przyciągnięcia większej liczby zombie.\n\nOprócz broni palnej, istnieją również narzędzia ręczne, które mogą być wykorzystane w walce z zombie. Najpopularniejsze w tym przypadku są topory, siekiery, noże i piły. Narzędzia te są bardziej trwałe niż broń palna i nie wymagają amunicji, zapewniając przede wszystkim większą kontrolę w walce.\n\nJednym z najważniejszych aspektów walki z zombie jest samoobrona i techniki walki. W przypadku samoobrony należy unikać bezpośredniego kontaktu i próbować utrzymać dystans między sobą a zombie. Techniki walki obejmują uderzanie i kopanie, ale również układanie pułapek i blokowanie przejść.\n\nKolejnym ważnym aspektem uzbrojenia się i obrony są schrony antyzombie. W ostatnich latach popularność zdobyły schrony betonowe, które zapewniają odporność na ataki zombie i są w stanie pomieścić większą liczbę ludzi. Istnieją również schrony podziemne, ale ich budowa wymaga większej wiedzy technicznej i finansowej.\n\nDostępność broni i wyposażenia obrony przed zombie zależy od kraju i jego przepisów dotyczących broni. W Stanach Zjednoczonych dostępność broni jest stosunkowo łatwa, ale w Europie jak również w Polsce, wymagane są specjalne pozwolenia i odebranie egzaminów na ich posiadanie. Cena broni i wyposażenia zależy od rodzaju broni, producenta oraz sposobu jej użytkowania.\n\nPodsumowując, aby przeżyć w świecie zombie, konieczne jest uzbrojenie się i obrona. Istnieje wiele narzędzi, które mogą być skuteczne w walce z zombie. Należy jednak zdać sobie sprawę, że broń jest jedynie tymczasowym rozwiązaniem, a samoobrona i techniki walki, jak również schrony antyzombie są równie ważne w przetrwaniu zombie apokalipsy.\n\nTemat ewakuacji przed zombie stanowi niezwykle ważny aspekt, który powinien zostać uwzględniony przez każdego mieszkańca miasta. Szacuje się, że zombie stanowią realne zagrożenie dla społeczeństwa, a ich wystąpienie może nieść za sobą ogromne konsekwencje dla ludzi i infrastruktury miasta.\n\nW pierwszej kolejności, aby przygotować plan ewakuacji, należy zastanowić się, gdzie schronić się przed zombie. Najlepszą opcją jest zawsze ucieczka z miejsca, w którym widzimy pierwsze oznaki pojawienia się żywych trupów. W przypadku ocalałych miast, warto w pierwszej kolejności skontaktować się z lokalną strażą pożarną, aby uzyskać informacje na temat dedykowanych miejsc schronienia w przypadku wystąpienia pandemii zombie.\n\nJeśli jednak nie ma takiej możliwości, warto zapoznać się z przestrzenią wokół nas - w poszukiwaniu możliwych miejsc schronienia zwracajmy uwagę na ukryte miejsca, które zapewnią nam bezpieczeństwo, będących poza zasięgiem zombie. Być może znajdziemy dzielnicę mieszkaniową z wielkimi, ogrodzonymi posesjami lub gęste lasy, w których będzie niemożliwe do przebycia dla zombiaków.\n\nPo ustaleniu lokalizacji schronienia warto pomyśleć o sposobie szybkiego i bezpiecznego opuszczenia miasta. Warto mieć przygotowaną dobrze zaopatrzoną torbę z niezbędnymi do przetrwania przedmiotami, np. wodą, żywnością, ubraniem i podstawowymi narzędziami.Dobre okulary przeciwsłoneczne,szalik albo chusta i kurtka zimowa również pomogą w przeżyciu.\n\nWarto również zapoznać się z drogami ucieczki i trasami, które prowadzą poza miasto. Jeśli masz samochód, należy upewnić się, że jest w dobrym stanie technicznym, z pełnym zbiornikiem paliwa i odpowiednim narzędziem wydobywczym w bagażniku.\n\nPodsumowując, kluczowe znaczenie ma dobrze przygotowany plan ewakuacji przed zombie. Warto wiedzieć, gdzie szukać schronienia i jak szybko i bezpiecznie opuścić miasto. Dzięki temu każdy z nas może zminimalizować ryzyko i podjąć odpowiednie kroki w przypadku wystąpienia pandemii zombie.\n\nPrzygotowanie psychiczne jest kluczowe w sytuacjach kryzysowych, takich jak wypadki drogowe, katastrofy naturalne czy ataki terroryzmu. Bez odpowiedniego przygotowania, nawet najbardziej doświadczeni ratownicy czy pracownicy służb ratunkowych mogą zapanować nad stresem i traumą, co utrudni osiągnięcie celów w sytuacji kryzysowej.\n\nStres i trauma to naturalne reakcje organizmu w sytuacjach, w których zagrożone jest życie lub zdrowie, bądź też mają miejsce traumatyczne zdarzenia. Wśród objawów można wymienić trudności w koncentracji, kłopoty z pamięcią, zwiększone poczucie lęku, drażliwość, zmiany nastroju czy kłopoty ze snem.\n\nAby zachować spokój w przypadku apokalipsy zombie, warto zwrócić uwagę na kilka kluczowych elementów. Pierwszym krokiem jest przygotowanie fizyczne i mentalne. Trzeba zadbać o odpowiednie przygotowanie pod względem kondycji fizycznej, tak by być gotowym do biegu i walki. Oprócz tego warto opracować plan działania, tak by nie tracić czasu na zbędne decyzje.\n\nKolejnym ważnym elementem przygotowania psychicznego jest identyfikacja własnych reakcji na stres oraz umiejętność radzenia sobie z nimi. Warto opracować techniki relaksacyjne, które pomogą w redukcji poziomu lęku i stresu. Do popularnych metod zalicza się medytację, jogę, oddechowe techniki relaksacyjne czy klasyczną terapię.\n\nWarto pamiętać, że przygotowanie psychiczne w przypadku sytuacji kryzysowej jest procesem długotrwałym. Nie da się nauczyć się wszystkiego w ciągu jednego dnia czy tygodnia. Trzeba poświęcać czas i wysiłek, by osiągnąć poziom przygotowania odpowiedni do zaistniałych okoliczności.\n\nPodsumowując, przygotowanie psychiczne to kluczowy element w sytuacjach kryzysowych. Należy poświęcić czas na przygotowanie się fizyczne i mentalne przed zagrożeniem. Warto zwrócić uwagę na identyfikację swoich reakcji na stres oraz umiejętność radzenia sobie z nimi. Pamiętajmy, że przygotowanie psychiczne to proces długotrwały, wymagający czasu i pracy.\n\nZ przygotowaniem się do apokalipsy zombie wiąże się wiele kroków i aspektów, których nie można pominąć. Przede wszystkim konieczne jest zaopatrzenie się w odpowiednie rzeczy, takie jak żywność, wodę czy lekarstwa. Zgodnie z zasadą „lepiej mieć i nie potrzebować, niż potrzebować i nie mieć”, warto również wziąć pod uwagę materiały budowlane, narzędzia i sprzęt, które mogą przydać się w czasie kryzysu.\n\nDane pokazują, że wiele osób bagatelizuje potrzebę przygotowania się do takiej sytuacji, ale gdy już coś się wydarzy, często jest już za późno na działanie. W Stanach Zjednoczonych, gdzie kultura horrorów i popkultury związanej z apokalipsami jest wyjątkowo popularna, tylko około 20% ludzi przygotowuje się na wypadek kryzysu, w tym zombie. Tymczasem, jak pokazują badania, przygotowanie się do sytuacji kryzysowej pozwala zwiększyć szanse na przeżycie o ponad trzykrotnie.\n\nNie można też zapominać o przygotowaniu psychicznym. Psychologowie podkreślają, że bez pewnej formy przygotowania nie jesteśmy w stanie skutecznie radzić sobie w sytuacjach ekstremalnych. Ważna jest tu przede wszystkim umiejętność radzenia sobie ze stresem i kryzysem emocjonalnym, a także właściwe podejście do zagrożeń i podejmowanie racjonalnych decyzji.\n\nPodsumowując, przygotowanie się do sytuacji apokalipsy zombie jest skomplikowanym procesem, wymagającym zarówno odpowiedniego zaopatrzenia, jak i przygotowania psychicznego. Pomimo tego, że nie należy do łatwych i przyjemnych, może okazać się kluczowe dla przetrwania w sytuacjach kryzysowych.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-07T07:39:51.000Z",
            "updated_at": "2023-04-07T07:39:51.000Z",
            "published_at": "2023-04-07T07:39:51.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null,
            "lexical": null
          }
        ],
        "posts_authors": [
          {
            "id": "601940361446cd10bd8d9daf",
            "post_id": "601940361446cd10bd8d9dae",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "601d65141446cd10bd8da406",
            "post_id": "601d65141446cd10bd8da405",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60225c2d1446cd10bd8da59b",
            "post_id": "60225c2d1446cd10bd8da59a",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "6025a6251446cd10bd8da615",
            "post_id": "6025a6251446cd10bd8da614",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "602d352c1446cd10bd8da86a",
            "post_id": "602d352c1446cd10bd8da869",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "602d8a1a194a5b778b1ab9f0",
            "post_id": "602d8a1a194a5b778b1ab9ef",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "6038c0b18e39617ce723d821",
            "post_id": "6038c0b18e39617ce723d820",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "603a4b758e39617ce723d8e7",
            "post_id": "603a4b758e39617ce723d8e6",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "604118a88e39617ce723d8f4",
            "post_id": "604118a88e39617ce723d8f3",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "6052116b8e39617ce723d9c9",
            "post_id": "6052116b8e39617ce723d9c8",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60705d372013ee207d135483",
            "post_id": "60705d372013ee207d135482",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607c1b012fb35425592d0771",
            "post_id": "607c1b012fb35425592d0770",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607ebd292fb35425592d0861",
            "post_id": "607ebd292fb35425592d0860",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f1a3a2fb35425592d0a7b",
            "post_id": "607f1a3a2fb35425592d0a7a",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f216e2fb35425592d0af6",
            "post_id": "607f216e2fb35425592d0af5",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f2d392fb35425592d0b23",
            "post_id": "607f2d392fb35425592d0b22",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f31a42fb35425592d0b2f",
            "post_id": "607f31a42fb35425592d0b2e",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f32492fb35425592d0b3f",
            "post_id": "607f32492fb35425592d0b3e",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f33be2fb35425592d0b4f",
            "post_id": "607f33be2fb35425592d0b4e",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f36072fb35425592d0b72",
            "post_id": "607f36072fb35425592d0b71",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f36b62fb35425592d0b7c",
            "post_id": "607f36b62fb35425592d0b7b",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f37552fb35425592d0b90",
            "post_id": "607f37552fb35425592d0b8f",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f39282fb35425592d0ba9",
            "post_id": "607f39282fb35425592d0ba8",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f39a92fb35425592d0baf",
            "post_id": "607f39a92fb35425592d0bae",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f3a1c2fb35425592d0bb6",
            "post_id": "607f3a1c2fb35425592d0bb5",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f3a8e2fb35425592d0bbd",
            "post_id": "607f3a8e2fb35425592d0bbc",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f3ae92fb35425592d0bc7",
            "post_id": "607f3ae92fb35425592d0bc6",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f3b3b2fb35425592d0bcf",
            "post_id": "607f3b3b2fb35425592d0bce",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f3ced2fb35425592d0bea",
            "post_id": "607f3ced2fb35425592d0be9",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f3d2b2fb35425592d0bf7",
            "post_id": "607f3d2b2fb35425592d0bf6",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f3db82fb35425592d0c02",
            "post_id": "607f3db82fb35425592d0c01",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f3ec02fb35425592d0c11",
            "post_id": "607f3ec02fb35425592d0c10",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "607f4f042fb35425592d0c55",
            "post_id": "607f4f042fb35425592d0c54",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60801d0b2fb35425592d0ce7",
            "post_id": "60801d0b2fb35425592d0ce6",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "608173b82fb35425592d0d67",
            "post_id": "608173b82fb35425592d0d66",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "608718422fb35425592d0da7",
            "post_id": "608718422fb35425592d0da6",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "608879632fb35425592d0f98",
            "post_id": "608879632fb35425592d0f97",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "608980982fb35425592d11c7",
            "post_id": "608980982fb35425592d11c6",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "608a9c962fb35425592d1324",
            "post_id": "608a9c962fb35425592d1323",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "608aa9202fb35425592d138e",
            "post_id": "608aa9202fb35425592d138d",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "609d1c74c52f4a12ffdfc579",
            "post_id": "609d1c74c52f4a12ffdfc578",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60ae3d5bc52f4a12ffdfc588",
            "post_id": "60ae3d5bc52f4a12ffdfc587",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60c7453bc52f4a12ffdfc596",
            "post_id": "60c7453bc52f4a12ffdfc595",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60d6e8ff72a5cb20e224a225",
            "post_id": "60d6e8ff72a5cb20e224a224",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60e08131ae5f887e40118130",
            "post_id": "60e08131ae5f887e4011812f",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60e4e4c1ae5f887e4011818b",
            "post_id": "60e4e4c1ae5f887e4011818a",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60eea07650caaa182e07e39a",
            "post_id": "60eea07650caaa182e07e399",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60f18cd350caaa182e07e606",
            "post_id": "60f18cd350caaa182e07e605",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "60f5e2b750caaa182e07e94a",
            "post_id": "60f5e2b750caaa182e07e949",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "611f504250caaa182e07eec1",
            "post_id": "611f504250caaa182e07eec0",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "619392ef50caaa182e07f647",
            "post_id": "619392ef50caaa182e07f646",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "61b342b650caaa182e07f79e",
            "post_id": "61b342b650caaa182e07f79d",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "61f5914f50caaa182e07f7a9",
            "post_id": "61f5914f50caaa182e07f7a8",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "626bb8c6d9c3ae6cbd852a38",
            "post_id": "626bb8c6d9c3ae6cbd852a37",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "62a3415fd9c3ae6cbd852a53",
            "post_id": "62a3415fd9c3ae6cbd852a52",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "62a4cca6d9c3ae6cbd852d49",
            "post_id": "62a4cca6d9c3ae6cbd852d48",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "62a4d997d9c3ae6cbd852d9b",
            "post_id": "62a4d997d9c3ae6cbd852d9a",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "62a51695d9c3ae6cbd852f16",
            "post_id": "62a51695d9c3ae6cbd852f15",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "642fb2d0753b4a4d4c3ccedb",
            "post_id": "642fb2d0753b4a4d4c3cceda",
            "author_id": "1",
            "sort_order": 0
          },
          {
            "id": "642fc8c7753b4a4d4c3ccef6",
            "post_id": "642fc8c7753b4a4d4c3ccef5",
            "author_id": "1",
            "sort_order": 0
          }
        ],
        "posts_meta": [],
        "posts_products": [
          {
            "id": "640b4b0034d6052b1eeb863b",
            "post_id": "62a51695d9c3ae6cbd852f15",
            "product_id": "640b49db34d6052b1eeb85d9",
            "sort_order": 0
          },
          {
            "id": "640b4b0034d6052b1eeb863c",
            "post_id": "62a51695d9c3ae6cbd852f15",
            "product_id": "608b1e9bc19b240f06532731",
            "sort_order": 1
          }
        ],
        "posts_tags": [
          {
            "id": "601b8f9f1446cd10bd8da386",
            "post_id": "601940361446cd10bd8d9dae",
            "tag_id": "601b8f9f1446cd10bd8da37f",
            "sort_order": 0
          },
          {
            "id": "601b8f9f1446cd10bd8da387",
            "post_id": "601940361446cd10bd8d9dae",
            "tag_id": "601b8f9f1446cd10bd8da380",
            "sort_order": 1
          },
          {
            "id": "601b8f9f1446cd10bd8da388",
            "post_id": "601940361446cd10bd8d9dae",
            "tag_id": "601b8f9f1446cd10bd8da381",
            "sort_order": 2
          },
          {
            "id": "601b8f9f1446cd10bd8da389",
            "post_id": "601940361446cd10bd8d9dae",
            "tag_id": "601b8f9f1446cd10bd8da382",
            "sort_order": 3
          },
          {
            "id": "601b8f9f1446cd10bd8da38a",
            "post_id": "601940361446cd10bd8d9dae",
            "tag_id": "601b8f9f1446cd10bd8da383",
            "sort_order": 4
          },
          {
            "id": "601b8f9f1446cd10bd8da38b",
            "post_id": "601940361446cd10bd8d9dae",
            "tag_id": "601b8f9f1446cd10bd8da384",
            "sort_order": 5
          },
          {
            "id": "601b8f9f1446cd10bd8da38c",
            "post_id": "601940361446cd10bd8d9dae",
            "tag_id": "601b8f9f1446cd10bd8da385",
            "sort_order": 6
          },
          {
            "id": "602d8459194a5b778b1ab9e9",
            "post_id": "601d65141446cd10bd8da405",
            "tag_id": "602d8459194a5b778b1ab9e7",
            "sort_order": 0
          },
          {
            "id": "602d8459194a5b778b1ab9ea",
            "post_id": "601d65141446cd10bd8da405",
            "tag_id": "602d8459194a5b778b1ab9e8",
            "sort_order": 1
          },
          {
            "id": "6038cd1c8e39617ce723d8df",
            "post_id": "6038c0b18e39617ce723d820",
            "tag_id": "6038cd1c8e39617ce723d8de",
            "sort_order": 0
          },
          {
            "id": "607ebca42fb35425592d085a",
            "post_id": "607c1b012fb35425592d0770",
            "tag_id": "607ebca42fb35425592d0858",
            "sort_order": 0
          },
          {
            "id": "607ebca42fb35425592d085b",
            "post_id": "607c1b012fb35425592d0770",
            "tag_id": "607ebca42fb35425592d0859",
            "sort_order": 1
          },
          {
            "id": "607ec5b32fb35425592d08e4",
            "post_id": "607ebd292fb35425592d0860",
            "tag_id": "602d8459194a5b778b1ab9e8",
            "sort_order": 0
          },
          {
            "id": "607f203f2fb35425592d0aee",
            "post_id": "603a4b758e39617ce723d8e6",
            "tag_id": "607f203f2fb35425592d0aed",
            "sort_order": 0
          },
          {
            "id": "607f31da2fb35425592d0b35",
            "post_id": "607f31a42fb35425592d0b2e",
            "tag_id": "607f31da2fb35425592d0b32",
            "sort_order": 0
          },
          {
            "id": "607f31da2fb35425592d0b36",
            "post_id": "607f31a42fb35425592d0b2e",
            "tag_id": "607f31da2fb35425592d0b33",
            "sort_order": 1
          },
          {
            "id": "607f31da2fb35425592d0b37",
            "post_id": "607f31a42fb35425592d0b2e",
            "tag_id": "607f31da2fb35425592d0b34",
            "sort_order": 2
          },
          {
            "id": "607f33932fb35425592d0b46",
            "post_id": "607f32492fb35425592d0b3e",
            "tag_id": "607f33932fb35425592d0b43",
            "sort_order": 0
          },
          {
            "id": "607f33932fb35425592d0b47",
            "post_id": "607f32492fb35425592d0b3e",
            "tag_id": "607f33932fb35425592d0b44",
            "sort_order": 1
          },
          {
            "id": "607f33932fb35425592d0b48",
            "post_id": "607f32492fb35425592d0b3e",
            "tag_id": "607f33932fb35425592d0b45",
            "sort_order": 2
          },
          {
            "id": "607f35f62fb35425592d0b6b",
            "post_id": "607f33be2fb35425592d0b4e",
            "tag_id": "607f31da2fb35425592d0b33",
            "sort_order": 0
          },
          {
            "id": "607f35f62fb35425592d0b6c",
            "post_id": "607f33be2fb35425592d0b4e",
            "tag_id": "607f35f62fb35425592d0b69",
            "sort_order": 1
          },
          {
            "id": "607f35f62fb35425592d0b6d",
            "post_id": "607f33be2fb35425592d0b4e",
            "tag_id": "607f35f62fb35425592d0b6a",
            "sort_order": 2
          },
          {
            "id": "607f363a2fb35425592d0b76",
            "post_id": "607f36072fb35425592d0b71",
            "tag_id": "607f363a2fb35425592d0b75",
            "sort_order": 0
          },
          {
            "id": "607f363a2fb35425592d0b77",
            "post_id": "607f36072fb35425592d0b71",
            "tag_id": "607f31da2fb35425592d0b33",
            "sort_order": 1
          },
          {
            "id": "607f36d52fb35425592d0b82",
            "post_id": "607f36b62fb35425592d0b7b",
            "tag_id": "607f36d52fb35425592d0b7f",
            "sort_order": 0
          },
          {
            "id": "607f36d52fb35425592d0b83",
            "post_id": "607f36b62fb35425592d0b7b",
            "tag_id": "607f36d52fb35425592d0b80",
            "sort_order": 1
          },
          {
            "id": "607f36d52fb35425592d0b84",
            "post_id": "607f36b62fb35425592d0b7b",
            "tag_id": "607f36d52fb35425592d0b81",
            "sort_order": 2
          },
          {
            "id": "607f3d072fb35425592d0bef",
            "post_id": "607f3ced2fb35425592d0be9",
            "tag_id": "601b8f9f1446cd10bd8da385",
            "sort_order": 0
          },
          {
            "id": "607f3d072fb35425592d0bf0",
            "post_id": "607f3ced2fb35425592d0be9",
            "tag_id": "607f3d072fb35425592d0bed",
            "sort_order": 1
          },
          {
            "id": "607f3d072fb35425592d0bf1",
            "post_id": "607f3ced2fb35425592d0be9",
            "tag_id": "607f3d072fb35425592d0bee",
            "sort_order": 2
          },
          {
            "id": "607f3d4e2fb35425592d0bfb",
            "post_id": "607f3d2b2fb35425592d0bf6",
            "tag_id": "607f3d4e2fb35425592d0bfa",
            "sort_order": 0
          },
          {
            "id": "607f3d4e2fb35425592d0bfc",
            "post_id": "607f3d2b2fb35425592d0bf6",
            "tag_id": "607f3d072fb35425592d0bed",
            "sort_order": 1
          },
          {
            "id": "607f3d4e2fb35425592d0bfd",
            "post_id": "607f3d2b2fb35425592d0bf6",
            "tag_id": "607f3d072fb35425592d0bee",
            "sort_order": 2
          },
          {
            "id": "607f3ddb2fb35425592d0c05",
            "post_id": "607f3db82fb35425592d0c01",
            "tag_id": "607f3d4e2fb35425592d0bfa",
            "sort_order": 0
          },
          {
            "id": "607f3ddb2fb35425592d0c06",
            "post_id": "607f3db82fb35425592d0c01",
            "tag_id": "607f3d072fb35425592d0bed",
            "sort_order": 1
          },
          {
            "id": "607f3ddb2fb35425592d0c07",
            "post_id": "607f3db82fb35425592d0c01",
            "tag_id": "607f3d072fb35425592d0bee",
            "sort_order": 2
          },
          {
            "id": "607f478c2fb35425592d0c4a",
            "post_id": "607f39282fb35425592d0ba8",
            "tag_id": "607f478c2fb35425592d0c47",
            "sort_order": 0
          },
          {
            "id": "607f478c2fb35425592d0c4b",
            "post_id": "607f39282fb35425592d0ba8",
            "tag_id": "607f3d4e2fb35425592d0bfa",
            "sort_order": 1
          },
          {
            "id": "607f478c2fb35425592d0c4c",
            "post_id": "607f39282fb35425592d0ba8",
            "tag_id": "607f478c2fb35425592d0c48",
            "sort_order": 2
          },
          {
            "id": "607f478c2fb35425592d0c4d",
            "post_id": "607f39282fb35425592d0ba8",
            "tag_id": "607f478c2fb35425592d0c49",
            "sort_order": 3
          },
          {
            "id": "6083f9c32fb35425592d0d9c",
            "post_id": "60801d0b2fb35425592d0ce6",
            "tag_id": "6083f9c32fb35425592d0d9a",
            "sort_order": 0
          },
          {
            "id": "6083f9c32fb35425592d0d9d",
            "post_id": "60801d0b2fb35425592d0ce6",
            "tag_id": "6083f9c32fb35425592d0d9b",
            "sort_order": 1
          },
          {
            "id": "6083f9c32fb35425592d0d9e",
            "post_id": "60801d0b2fb35425592d0ce6",
            "tag_id": "601b8f9f1446cd10bd8da37f",
            "sort_order": 2
          },
          {
            "id": "60d0bf3872a5cb20e224a06f",
            "post_id": "60c7453bc52f4a12ffdfc595",
            "tag_id": "60d0bf3872a5cb20e224a06c",
            "sort_order": 0
          },
          {
            "id": "60d0bf3872a5cb20e224a070",
            "post_id": "60c7453bc52f4a12ffdfc595",
            "tag_id": "60d0bf3872a5cb20e224a06d",
            "sort_order": 1
          },
          {
            "id": "60d0bf3872a5cb20e224a071",
            "post_id": "60c7453bc52f4a12ffdfc595",
            "tag_id": "602d8459194a5b778b1ab9e8",
            "sort_order": 2
          },
          {
            "id": "60d0bf3872a5cb20e224a072",
            "post_id": "60c7453bc52f4a12ffdfc595",
            "tag_id": "602d8459194a5b778b1ab9e7",
            "sort_order": 3
          },
          {
            "id": "60d0bf3872a5cb20e224a073",
            "post_id": "60c7453bc52f4a12ffdfc595",
            "tag_id": "60d0bf3872a5cb20e224a06e",
            "sort_order": 4
          },
          {
            "id": "60d0c63b72a5cb20e224a087",
            "post_id": "607f37552fb35425592d0b8f",
            "tag_id": "60d0c63b72a5cb20e224a084",
            "sort_order": 0
          },
          {
            "id": "60d0c63b72a5cb20e224a088",
            "post_id": "607f37552fb35425592d0b8f",
            "tag_id": "60d0c63b72a5cb20e224a085",
            "sort_order": 1
          },
          {
            "id": "60d0c63b72a5cb20e224a089",
            "post_id": "607f37552fb35425592d0b8f",
            "tag_id": "60d0c63b72a5cb20e224a086",
            "sort_order": 2
          },
          {
            "id": "60d1a62772a5cb20e224a08f",
            "post_id": "607f39a92fb35425592d0bae",
            "tag_id": "607f35f62fb35425592d0b6a",
            "sort_order": 0
          },
          {
            "id": "60d1a62772a5cb20e224a090",
            "post_id": "607f39a92fb35425592d0bae",
            "tag_id": "602d8459194a5b778b1ab9e8",
            "sort_order": 1
          },
          {
            "id": "60d1a74772a5cb20e224a09a",
            "post_id": "607f3a1c2fb35425592d0bb5",
            "tag_id": "60d1a74772a5cb20e224a096",
            "sort_order": 0
          },
          {
            "id": "60d1a74772a5cb20e224a09b",
            "post_id": "607f3a1c2fb35425592d0bb5",
            "tag_id": "60d1a74772a5cb20e224a097",
            "sort_order": 1
          },
          {
            "id": "60d1a74772a5cb20e224a09c",
            "post_id": "607f3a1c2fb35425592d0bb5",
            "tag_id": "60d1a74772a5cb20e224a098",
            "sort_order": 2
          },
          {
            "id": "60d1a74772a5cb20e224a09d",
            "post_id": "607f3a1c2fb35425592d0bb5",
            "tag_id": "60d1a74772a5cb20e224a099",
            "sort_order": 3
          },
          {
            "id": "60d1ac1972a5cb20e224a0b3",
            "post_id": "607f3b3b2fb35425592d0bce",
            "tag_id": "60d1ac1972a5cb20e224a0af",
            "sort_order": 0
          },
          {
            "id": "60d1ac1972a5cb20e224a0b4",
            "post_id": "607f3b3b2fb35425592d0bce",
            "tag_id": "60d1ac1972a5cb20e224a0b0",
            "sort_order": 1
          },
          {
            "id": "60d1ac1972a5cb20e224a0b5",
            "post_id": "607f3b3b2fb35425592d0bce",
            "tag_id": "60d1ac1972a5cb20e224a0b1",
            "sort_order": 2
          },
          {
            "id": "60d1ac1972a5cb20e224a0b6",
            "post_id": "607f3b3b2fb35425592d0bce",
            "tag_id": "60d1ac1972a5cb20e224a0b2",
            "sort_order": 3
          },
          {
            "id": "60d1ac1972a5cb20e224a0b7",
            "post_id": "607f3b3b2fb35425592d0bce",
            "tag_id": "607f478c2fb35425592d0c49",
            "sort_order": 4
          },
          {
            "id": "60d36f4e72a5cb20e224a201",
            "post_id": "607f36072fb35425592d0b71",
            "tag_id": "60d36f4e72a5cb20e224a200",
            "sort_order": 2
          },
          {
            "id": "60d983d3ae5f887e40118128",
            "post_id": "60d6e8ff72a5cb20e224a224",
            "tag_id": "60d983d3ae5f887e40118127",
            "sort_order": 0
          },
          {
            "id": "60d983d3ae5f887e40118129",
            "post_id": "60d6e8ff72a5cb20e224a224",
            "tag_id": "601b8f9f1446cd10bd8da37f",
            "sort_order": 1
          },
          {
            "id": "60e58b10ae5f887e4011836f",
            "post_id": "60e4e4c1ae5f887e4011818a",
            "tag_id": "60e58b10ae5f887e4011836c",
            "sort_order": 0
          },
          {
            "id": "60e58b10ae5f887e40118370",
            "post_id": "60e4e4c1ae5f887e4011818a",
            "tag_id": "60e58b10ae5f887e4011836d",
            "sort_order": 1
          },
          {
            "id": "60e58b10ae5f887e40118371",
            "post_id": "60e4e4c1ae5f887e4011818a",
            "tag_id": "60e58b10ae5f887e4011836e",
            "sort_order": 2
          },
          {
            "id": "60f1bd7b50caaa182e07e755",
            "post_id": "60f18cd350caaa182e07e605",
            "tag_id": "60d0bf3872a5cb20e224a06e",
            "sort_order": 0
          },
          {
            "id": "60f1bd7b50caaa182e07e756",
            "post_id": "60f18cd350caaa182e07e605",
            "tag_id": "60f1bd7b50caaa182e07e754",
            "sort_order": 1
          },
          {
            "id": "60f843df50caaa182e07eeaa",
            "post_id": "60f5e2b750caaa182e07e949",
            "tag_id": "60f843df50caaa182e07eea8",
            "sort_order": 0
          },
          {
            "id": "60f843df50caaa182e07eeab",
            "post_id": "60f5e2b750caaa182e07e949",
            "tag_id": "60f843df50caaa182e07eea9",
            "sort_order": 1
          },
          {
            "id": "60f843df50caaa182e07eeac",
            "post_id": "60f5e2b750caaa182e07e949",
            "tag_id": "60d0bf3872a5cb20e224a06e",
            "sort_order": 2
          },
          {
            "id": "617206d750caaa182e07f4c0",
            "post_id": "611f504250caaa182e07eec0",
            "tag_id": "617206d750caaa182e07f4be",
            "sort_order": 0
          },
          {
            "id": "617206d750caaa182e07f4c1",
            "post_id": "611f504250caaa182e07eec0",
            "tag_id": "617206d750caaa182e07f4bf",
            "sort_order": 1
          },
          {
            "id": "61928bf050caaa182e07f632",
            "post_id": "608aa9202fb35425592d138d",
            "tag_id": "60d1a74772a5cb20e224a097",
            "sort_order": 0
          },
          {
            "id": "61928bf050caaa182e07f633",
            "post_id": "608aa9202fb35425592d138d",
            "tag_id": "60d1a74772a5cb20e224a096",
            "sort_order": 1
          },
          {
            "id": "61928bf050caaa182e07f634",
            "post_id": "608aa9202fb35425592d138d",
            "tag_id": "61928bf050caaa182e07f631",
            "sort_order": 2
          },
          {
            "id": "6196600150caaa182e07f75b",
            "post_id": "619392ef50caaa182e07f646",
            "tag_id": "6196600150caaa182e07f759",
            "sort_order": 0
          },
          {
            "id": "6196600150caaa182e07f75c",
            "post_id": "619392ef50caaa182e07f646",
            "tag_id": "6196600150caaa182e07f75a",
            "sort_order": 1
          },
          {
            "id": "6196600150caaa182e07f75d",
            "post_id": "619392ef50caaa182e07f646",
            "tag_id": "607f363a2fb35425592d0b75",
            "sort_order": 2
          },
          {
            "id": "61f5a38f50caaa182e07f827",
            "post_id": "61f5914f50caaa182e07f7a8",
            "tag_id": "617206d750caaa182e07f4be",
            "sort_order": 0
          },
          {
            "id": "61f5a38f50caaa182e07f828",
            "post_id": "61f5914f50caaa182e07f7a8",
            "tag_id": "61f5a38f50caaa182e07f826",
            "sort_order": 1
          },
          {
            "id": "61f5a38f50caaa182e07f829",
            "post_id": "61f5914f50caaa182e07f7a8",
            "tag_id": "617206d750caaa182e07f4bf",
            "sort_order": 2
          },
          {
            "id": "62a36df0d9c3ae6cbd852c58",
            "post_id": "62a3415fd9c3ae6cbd852a52",
            "tag_id": "601b8f9f1446cd10bd8da37f",
            "sort_order": 0
          },
          {
            "id": "62a36df0d9c3ae6cbd852c59",
            "post_id": "62a3415fd9c3ae6cbd852a52",
            "tag_id": "60d0bf3872a5cb20e224a06e",
            "sort_order": 1
          },
          {
            "id": "62a36df0d9c3ae6cbd852c5a",
            "post_id": "62a3415fd9c3ae6cbd852a52",
            "tag_id": "62a36df0d9c3ae6cbd852c57",
            "sort_order": 2
          },
          {
            "id": "62a51c47d9c3ae6cbd852f60",
            "post_id": "62a4d997d9c3ae6cbd852d9a",
            "tag_id": "60d0bf3872a5cb20e224a06e",
            "sort_order": 0
          },
          {
            "id": "62a51c47d9c3ae6cbd852f61",
            "post_id": "62a4d997d9c3ae6cbd852d9a",
            "tag_id": "62a51c47d9c3ae6cbd852f5f",
            "sort_order": 1
          },
          {
            "id": "62a51c47d9c3ae6cbd852f62",
            "post_id": "62a4d997d9c3ae6cbd852d9a",
            "tag_id": "601b8f9f1446cd10bd8da37f",
            "sort_order": 2
          }
        ],
        "products": [
          {
            "id": "608b1e9bc19b240f06532731",
            "name": "Daniel Gustaw",
            "slug": "daniel-gustaw",
            "created_at": "2021-04-29T21:01:15.000Z",
            "updated_at": "2023-03-10T15:17:04.000Z",
            "description": null,
            "monthly_price_id": "640b49f034d6052b1eeb8639",
            "yearly_price_id": "640b49f034d6052b1eeb863a",
            "type": "paid",
            "active": 1,
            "welcome_page_url": "/",
            "visibility": "public",
            "trial_days": 0,
            "monthly_price": 500,
            "yearly_price": 5000,
            "currency": "usd"
          },
          {
            "id": "640b49db34d6052b1eeb85d9",
            "name": "Free",
            "slug": "640b49db34d6052b1eeb85d9",
            "created_at": "2023-03-10T15:16:43.000Z",
            "updated_at": null,
            "description": null,
            "monthly_price_id": null,
            "yearly_price_id": null,
            "type": "free",
            "active": 1,
            "welcome_page_url": "/",
            "visibility": "public",
            "trial_days": 0,
            "monthly_price": null,
            "yearly_price": null,
            "currency": null
          }
        ],
        "products_benefits": [],
        "roles": [
          {
            "id": "60193dcf1446cd10bd8d9c07",
            "name": "Administrator",
            "description": "Administrators",
            "created_at": "2021-02-02T11:55:59.000Z",
            "updated_at": "2021-02-02T11:55:59.000Z"
          },
          {
            "id": "60193dcf1446cd10bd8d9c08",
            "name": "Editor",
            "description": "Editors",
            "created_at": "2021-02-02T11:55:59.000Z",
            "updated_at": "2021-02-02T11:55:59.000Z"
          },
          {
            "id": "60193dcf1446cd10bd8d9c09",
            "name": "Author",
            "description": "Authors",
            "created_at": "2021-02-02T11:55:59.000Z",
            "updated_at": "2021-02-02T11:55:59.000Z"
          },
          {
            "id": "60193dcf1446cd10bd8d9c0a",
            "name": "Contributor",
            "description": "Contributors",
            "created_at": "2021-02-02T11:55:59.000Z",
            "updated_at": "2021-02-02T11:55:59.000Z"
          },
          {
            "id": "60193dcf1446cd10bd8d9c0b",
            "name": "Owner",
            "description": "Blog Owner",
            "created_at": "2021-02-02T11:55:59.000Z",
            "updated_at": "2021-02-02T11:55:59.000Z"
          },
          {
            "id": "60193dcf1446cd10bd8d9c0c",
            "name": "Admin Integration",
            "description": "External Apps",
            "created_at": "2021-02-02T11:55:59.000Z",
            "updated_at": "2021-02-02T11:55:59.000Z"
          },
          {
            "id": "60193dcf1446cd10bd8d9c0d",
            "name": "DB Backup Integration",
            "description": "Internal DB Backup Client",
            "created_at": "2021-02-02T11:55:59.000Z",
            "updated_at": "2021-02-02T11:55:59.000Z"
          },
          {
            "id": "60193dcf1446cd10bd8d9c0e",
            "name": "Scheduler Integration",
            "description": "Internal Scheduler Client",
            "created_at": "2021-02-02T11:55:59.000Z",
            "updated_at": "2021-02-02T11:55:59.000Z"
          },
          {
            "id": "640b49e234d6052b1eeb8613",
            "name": "Ghost Explore Integration",
            "description": "Internal Integration for the Ghost Explore directory",
            "created_at": "2023-03-10T15:16:50.000Z",
            "updated_at": null
          },
          {
            "id": "642e2979a0adf54be8dbe242",
            "name": "Self-Serve Migration Integration",
            "description": "Core Integration for the Ghost Explore directory",
            "created_at": "2023-04-06T02:07:53.000Z",
            "updated_at": null
          }
        ],
        "roles_users": [
          {
            "id": "60193dd11446cd10bd8d9d56",
            "role_id": "60193dcf1446cd10bd8d9c0b",
            "user_id": "1"
          }
        ],
        "settings": [
          {
            "id": "60193dd21446cd10bd8d9d57",
            "group": "core",
            "key": "db_hash",
            "value": "45bae4bf-bc8e-4b5b-9436-0efdd701bfbb",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd21446cd10bd8d9d58",
            "group": "core",
            "key": "routes_hash",
            "value": "fd573775449ee56dc6cbfb013d2729ca",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2023-02-16T06:14:23.000Z"
          },
          {
            "id": "60193dd21446cd10bd8d9d59",
            "group": "core",
            "key": "next_update_check",
            "value": "1693742463",
            "type": "number",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2023-09-02T12:01:03.000Z"
          },
          {
            "id": "60193dd21446cd10bd8d9d5a",
            "group": "core",
            "key": "notifications",
            "value": "[]",
            "type": "array",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2023-03-10T15:18:31.000Z"
          },
          {
            "id": "60193dd21446cd10bd8d9d5b",
            "group": "core",
            "key": "admin_session_secret",
            "value": "a1212b85d1fb38f406681469806cdbde428bdd6c192ffc1c168c3700cb7b2b06",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd21446cd10bd8d9d5c",
            "group": "core",
            "key": "theme_session_secret",
            "value": "37a61fa14046c569da16fb612bb04dba43b7d8342b68f2639d3400388ed33237",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd21446cd10bd8d9d5d",
            "group": "core",
            "key": "ghost_public_key",
            "value": "-----BEGIN RSA PUBLIC KEY-----\nMIGJAoGBAL7reQ8R/Dg/+75a3MFkNSQZgZQvZ6H8qxhYfn96Wrl65FB+C8Rz6XWiAH+FVIue\nEPyXPd7dY3Qrv/VTZwpnP1ibtCtX/GPdLt6Hc6jkgADC3WGXd+xHOjyUOMCLKceX9s8ZgjjJ\nlNGRcdE5xwo58xI9fSMeDdDZefdhD870LjKDAgMBAAE=\n-----END RSA PUBLIC KEY-----\n",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd21446cd10bd8d9d5e",
            "group": "core",
            "key": "ghost_private_key",
            "value": "-----BEGIN RSA PRIVATE KEY-----\nMIICXQIBAAKBgQC+63kPEfw4P/u+WtzBZDUkGYGUL2eh/KsYWH5/elq5euRQfgvEc+l1ogB/\nhVSLnhD8lz3e3WN0K7/1U2cKZz9Ym7QrV/xj3S7eh3Oo5IAAwt1hl3fsRzo8lDjAiynHl/bP\nGYI4yZTRkXHROccKOfMSPX0jHg3Q2Xn3YQ/O9C4ygwIDAQABAoGAJiXY15kJY5ftTljLeVzz\nfVYXXSunsmdRLJkqFYC2Ng+HJUo6QbPDdzy6isByZz9bN41k0G4+HA1N2tAia6K7tjj3EQZF\n2RlaohCD0e+dl1kWrG+6hkknPw2Y8x+z6bFngEIq74VNu0TxOE8MnyIG8v4w1KzChXH30VeV\nAiDznXkCQQD1rdwsbmCoc54Dp0Cy0MQBlZMkkBotxoM8yWBRDQLvLDB8Wq/jS/LFE3N6/PJX\ntUcAgRrVq/YvFse2htR1LCBfAkEAxvC1EyPVC7jR16/5KgzIOh19vanUQZOf6SgVohNbcCIm\nKBusoZo+UsLxdKPF13LPxV1pKINHmuYuVDeokK+QXQJBAIfqvLE0C3OGKzg4Mpn610VNG8+R\njXofpgFeI1QTz7jECLrzbPVh0hhnj27OO8B8QKCtzEvDy/n3L1vysd11IR8CQQCYXa8xs5Xu\nXmVJfpulGxkXeZLeen34o6osFulKsuyrW1xCB8AWHV5yYKAxp2VVd7et/7cUskdbWcRN+DsA\nZZZ5AkA88JU9U3/f68K/1OLy8I/ULZkXjgVwbvk1VMcx2vslTlTWw8CwIluidMi6KsvWq78y\nslZ/V8uZyiaulLlkhzdX\n-----END RSA PRIVATE KEY-----\n",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d5f",
            "group": "core",
            "key": "members_public_key",
            "value": "-----BEGIN RSA PUBLIC KEY-----\nMIGJAoGBAOG3ZynoH0qQ9cejFYlMDLI8O3e+F5ts+cVlRPKQS2CoDHVGYa1ZD9Uyqp9qc19F\nzlhvZPAwqt40U7Ivfdf93GuYw4lgMe80+QmAxctLXwFBtw47pKFG4g6yubgKwRbnviXFDmYp\n4SySm9eSfEEQh005IvcLr/f9UYp6wJjmQjvtAgMBAAE=\n-----END RSA PUBLIC KEY-----\n",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d60",
            "group": "core",
            "key": "members_private_key",
            "value": "-----BEGIN RSA PRIVATE KEY-----\nMIICWwIBAAKBgQDht2cp6B9KkPXHoxWJTAyyPDt3vhebbPnFZUTykEtgqAx1RmGtWQ/VMqqf\nanNfRc5Yb2TwMKreNFOyL33X/dxrmMOJYDHvNPkJgMXLS18BQbcOO6ShRuIOsrm4CsEW574l\nxQ5mKeEskpvXknxBEIdNOSL3C6/3/VGKesCY5kI77QIDAQABAoGAbRo3lXwL1AEprCvaNxk5\ncdXHcOPDiW8tdAq1PwIcTUYtb2prwFyyWH07F/9ecQjO6tQ9WBROI0Xrxs9J5uNgbQFc9u/x\ncmCiHmnOqUt7BKsYOABM2IGu1yIxfTuz3Qpb8jeOpVHyV1f8t7OdLgPoQ8w2PlcozFP7p9yc\ndnBtFMECQQD2y4r4EdQy5iT+hFUI8dZhJFWfb1D3o+dsMyog23Tayxa9rpI7A2a5Ed6cgDlX\n8r5D4MXbdDSeCFbNvukVGpUlAkEA6iKYl0juAruCSgBE5cu73xAV+kB1m897MyAaodGmZYNB\n0NnM2VtIDaWUr2lK5nrcupJatw2O7y6ZcyRIUgolKQJAUvSWEM6FYlqDwt2ea7RGmD6LXV0g\nfS0l4/PKzGKYA9dSHI4qbxW0mK7OAhMDs3FPzScnup1z9k7dRqlOVZ6q1QJATNwyj2dHiuoX\nKUfRVkZ9VAqpzE8gzJdd8DiXxYtXPnfKQU9eafQHQUOb/cFo7yRiFXU6BmGTDH2VrjC49QWT\nkQJAcvS7LLPldkWidgSnlCKQRV7Gv62Cv/wV38oWWYPFgAfeIlh9AA/7s7lOMYPDWaIhnyH8\nK7AlCV5YVknzC7fgNA==\n-----END RSA PRIVATE KEY-----\n",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d61",
            "group": "core",
            "key": "members_email_auth_secret",
            "value": "426677cf98f5ff9bcf7ae29b1130d1db572e8ef91b4acc56dca4d771aa261410ac36a12aada63775822af1f700319ad55e674c30f405771ccb87bcd891a9b9fb",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d64",
            "group": "site",
            "key": "title",
            "value": "Daniel Gustaw",
            "type": "string",
            "flags": "PUBLIC",
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:57:24.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d65",
            "group": "site",
            "key": "description",
            "value": "Blog Programisty",
            "type": "string",
            "flags": "PUBLIC",
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-04T06:03:35.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d66",
            "group": "site",
            "key": "logo",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T12:00:15.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d67",
            "group": "site",
            "key": "cover_image",
            "value": "https://static.ghost.org/v3.0.0/images/publication-cover.png",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d68",
            "group": "site",
            "key": "icon",
            "value": "",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d69",
            "group": "site",
            "key": "accent_color",
            "value": "#15171A",
            "type": "string",
            "flags": "PUBLIC",
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d6a",
            "group": "site",
            "key": "locale",
            "value": "pl",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-06-22T09:36:48.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d6b",
            "group": "site",
            "key": "timezone",
            "value": "Europe/Warsaw",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-06-22T09:36:48.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d6c",
            "group": "site",
            "key": "codeinjection_head",
            "value": "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/plugins/diff-highlight/prism-diff-highlight.min.css\" integrity=\"sha512-rErSjI34XKsATVf+BW6GnuWVmj7imdMR7AIyb4ydHhiMFewUiJOeN9bYO35iCgdG+3Bxkl0GkAs0E8hrDYooLA==\" crossorigin=\"anonymous\" />\n<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism-tomorrow.min.css\" integrity=\"sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==\" crossorigin=\"anonymous\" />\n\n<style>\npre[class*=language-] {\n    font-size: 1.4rem;\n}\n.post-full-content p {\n    margin: 0.75em 0 0.75em;\n}\n</style>\n\n<!-- Global site tag (gtag.js) - Google Analytics -->\n<script async src=\"https://www.googletagmanager.com/gtag/js?id=G-D33M5PYSPH\"></script>\n<script>\n  window.dataLayer = window.dataLayer || [];\n  function gtag(){dataLayer.push(arguments);}\n  gtag('js', new Date());\n\n  gtag('config', 'G-D33M5PYSPH');\n</script>\n\n<!-- Facebook Pixel Code -->\n<script>!function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function(){n.callMethod?n.callMethod.apply(n,arguments):n.queue.push(arguments)};if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,document,'script','https://connect.facebook.net/en_US/fbevents.js'); fbq('init', '529409568247833'); fbq('track', 'PageView');</script><noscript> <img height=\"1\" width=\"1\" src=\"https://www.facebook.com/tr?id=529409568247833&ev=PageView&noscript=1\"/></noscript>\n<!-- End Facebook Pixel Code -->\n\n<!-- Google Tag Manager -->\n<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\nnew Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\nj=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n})(window,document,'script','dataLayer','GTM-KZBH42N');</script>\n<!-- End Google Tag Manager -->\n\n<!-- Latex in \\[ \\] -->\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.css\" crossorigin=\"anonymous\">\n<script defer src=\"https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.js\" crossorigin=\"anonymous\"></script>\n<script defer src=\"https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js\" crossorigin=\"anonymous\" onload=\"renderMathInElement(document.body);\"></script>\n<!-- Latex in \\[ \\] -->\n",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2022-06-10T13:44:22.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d6d",
            "group": "site",
            "key": "codeinjection_foot",
            "value": "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js\" integrity=\"sha512-YBk7HhgDZvBxmtOfUdvX0z8IH2d10Hp3aEygaMNhtF8fSOvBZ16D/1bXZTJV6ndk/L/DlXxYStP8jrF77v2MIg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-diff.min.js\" integrity=\"sha512-QHFQ4+gqPck5hEy4UhfKynXlq3U58GuSQli0/+i6o1AcC/6ht6PtwhtkNIurLfshVbaXkPDXdVp8p/eGXfRKIA==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-json.min.js\" integrity=\"sha512-IC7rV8RslChgByOdUFC6ePqOGn+OwJhnKC3S5AezM8DAiOdGhJMwgsIvBChsa2yuxxoPbH2+W/kjNUM1cc+jUQ==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-bash.min.js\" integrity=\"sha512-JvRd44DHaJAv/o3wxi/dxhz2TO/jwwX8V5/LTr3gj6QMQ6qNNGXk/psoingLDuc5yZmccOq7XhpVaelIZE4tsQ==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-typescript.min.js\" integrity=\"sha512-9CvArJQPTJqAXN0HJ9DrggF3yNXh09H/pDkKya7eo7Csk2ZisKOiTdJthVFPKyNc3M0m9ofpgfDwGei0V7pgJw==\" crossorigin=\"anonymous\"></script>\n\n<script>\n    System = {Console:{WriteLine:console.log}}\n</script>\n\n<!-- Google Tag Manager (noscript) -->\n<noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-KZBH42N\"\nheight=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>\n<!-- End Google Tag Manager (noscript) -->",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-07-18T13:42:15.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d6e",
            "group": "site",
            "key": "facebook",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-04T06:22:40.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d6f",
            "group": "site",
            "key": "twitter",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-04T06:22:40.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d70",
            "group": "site",
            "key": "navigation",
            "value": "[{\"label\":\"Strona główna\",\"url\":\"/\"},{\"label\":\"Wyślij zapytanie\",\"url\":\"https://forms.clickup.com/f/21qbj-1478/E3Q6WHD0DK4M4UIVFN\"},{\"label\":\"Umów konsultację\",\"url\":\"https://calendly.com/gustaw-daniel\"}]",
            "type": "array",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-04-26T08:02:05.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d71",
            "group": "site",
            "key": "secondary_navigation",
            "value": "[]",
            "type": "array",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d72",
            "group": "site",
            "key": "meta_title",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d73",
            "group": "site",
            "key": "meta_description",
            "value": "Blog o scrapingu, przetwarzaniu danych i programowaniu w technologiach node js, typescript, perl, php, python.",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-06-22T09:36:48.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d74",
            "group": "site",
            "key": "og_image",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d75",
            "group": "site",
            "key": "og_title",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d76",
            "group": "site",
            "key": "og_description",
            "value": "Blog o przetwarzaniu danych, opisujący case studies w technologiach node js oraz typescript.",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-04-26T08:10:43.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d77",
            "group": "site",
            "key": "twitter_image",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d78",
            "group": "site",
            "key": "twitter_title",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d79",
            "group": "site",
            "key": "twitter_description",
            "value": "Blog o przetwarzaniu danych, opisujący case studies w technologiach node js oraz typescript.",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-04-26T08:10:43.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d7a",
            "group": "theme",
            "key": "active_theme",
            "value": "casper-rss",
            "type": "string",
            "flags": "RO",
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2023-02-16T05:41:14.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d7b",
            "group": "private",
            "key": "is_private",
            "value": "false",
            "type": "boolean",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d7c",
            "group": "private",
            "key": "password",
            "value": "",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d7d",
            "group": "private",
            "key": "public_hash",
            "value": "d419aa131028e438880867abedddbf",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d7e",
            "group": "members",
            "key": "default_content_visibility",
            "value": "public",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d81",
            "group": "members",
            "key": "members_support_address",
            "value": "noreply",
            "type": "string",
            "flags": "PUBLIC,RO",
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d88",
            "group": "members",
            "key": "stripe_plans",
            "value": "[{\"name\":\"Monthly\",\"currency\":\"usd\",\"interval\":\"month\",\"amount\":500},{\"name\":\"Yearly\",\"currency\":\"usd\",\"interval\":\"year\",\"amount\":5000}]",
            "type": "array",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-07-08T16:36:20.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d8b",
            "group": "members",
            "key": "stripe_connect_livemode",
            "value": "true",
            "type": "boolean",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-04-22T13:14:34.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d8c",
            "group": "members",
            "key": "stripe_connect_display_name",
            "value": "precise.sale",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-04-22T13:14:34.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d8e",
            "group": "portal",
            "key": "portal_name",
            "value": "true",
            "type": "boolean",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d8f",
            "group": "portal",
            "key": "portal_button",
            "value": "true",
            "type": "boolean",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d90",
            "group": "portal",
            "key": "portal_plans",
            "value": "[\"free\",\"monthly\",\"yearly\"]",
            "type": "array",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T12:00:16.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d91",
            "group": "portal",
            "key": "portal_button_style",
            "value": "icon-and-text",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d92",
            "group": "portal",
            "key": "portal_button_icon",
            "value": "icon-3",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-04T12:43:37.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d93",
            "group": "portal",
            "key": "portal_button_signup_text",
            "value": "Subscribe",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d94",
            "group": "email",
            "key": "mailgun_domain",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d95",
            "group": "email",
            "key": "mailgun_api_key",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d96",
            "group": "email",
            "key": "mailgun_base_url",
            "value": "https://api.eu.mailgun.net/v3",
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-04-26T08:10:43.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d97",
            "group": "email",
            "key": "email_track_opens",
            "value": "true",
            "type": "boolean",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d98",
            "group": "amp",
            "key": "amp",
            "value": "true",
            "type": "boolean",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d99",
            "group": "amp",
            "key": "amp_gtag_id",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d9a",
            "group": "firstpromoter",
            "key": "firstpromoter",
            "value": "false",
            "type": "boolean",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d9b",
            "group": "firstpromoter",
            "key": "firstpromoter_id",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d9e",
            "group": "unsplash",
            "key": "unsplash",
            "value": "true",
            "type": "boolean",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T12:00:15.000Z"
          },
          {
            "id": "60193dd31446cd10bd8d9d9f",
            "group": "views",
            "key": "shared_views",
            "value": "[]",
            "type": "array",
            "flags": null,
            "created_at": "2021-02-02T11:56:03.000Z",
            "updated_at": "2021-02-02T11:56:03.000Z"
          },
          {
            "id": "606d7fcac3dc7c7169c6e6be",
            "group": "slack",
            "key": "slack_url",
            "value": "",
            "type": "string",
            "flags": null,
            "created_at": "2021-04-07T09:47:54.000Z",
            "updated_at": "2022-06-10T13:44:22.000Z"
          },
          {
            "id": "606d7fcac3dc7c7169c6e6bf",
            "group": "slack",
            "key": "slack_username",
            "value": "Ghost",
            "type": "string",
            "flags": null,
            "created_at": "2021-04-07T09:47:54.000Z",
            "updated_at": "2022-06-10T13:44:22.000Z"
          },
          {
            "id": "608b1e9bc19b240f06532740",
            "group": "members",
            "key": "members_signup_access",
            "value": "all",
            "type": "string",
            "flags": null,
            "created_at": "2021-04-29T21:01:15.000Z",
            "updated_at": "2021-04-29T21:01:15.000Z"
          },
          {
            "id": "640b49d834d6052b1eeb85c6",
            "group": "labs",
            "key": "labs",
            "value": "{}",
            "type": "object",
            "flags": null,
            "created_at": "2023-03-10T15:16:40.000Z",
            "updated_at": "2023-03-10T15:16:40.000Z"
          },
          {
            "id": "640b49d834d6052b1eeb85c7",
            "group": "portal",
            "key": "portal_products",
            "value": "[\"608b1e9bc19b240f06532731\"]",
            "type": "array",
            "flags": null,
            "created_at": "2023-03-10T15:16:40.000Z",
            "updated_at": "2023-03-10T15:16:40.000Z"
          },
          {
            "id": "640b49dc34d6052b1eeb85da",
            "group": "members",
            "key": "default_content_visibility_tiers",
            "value": "[]",
            "type": "array",
            "flags": null,
            "created_at": "2023-03-10T15:16:44.000Z",
            "updated_at": null
          },
          {
            "id": "640b49de34d6052b1eeb85eb",
            "group": "core",
            "key": "version_notifications",
            "value": "[]",
            "type": "array",
            "flags": null,
            "created_at": "2023-03-10T15:16:46.000Z",
            "updated_at": null
          },
          {
            "id": "640b49e234d6052b1eeb8612",
            "group": "comments",
            "key": "comments_enabled",
            "value": "off",
            "type": "string",
            "flags": null,
            "created_at": "2023-03-10T15:16:50.000Z",
            "updated_at": null
          },
          {
            "id": "640b49e434d6052b1eeb861e",
            "group": "email",
            "key": "email_track_clicks",
            "value": "true",
            "type": "boolean",
            "flags": null,
            "created_at": "2023-03-10T15:16:52.000Z",
            "updated_at": null
          },
          {
            "id": "640b49e734d6052b1eeb8625",
            "group": "members",
            "key": "members_track_sources",
            "value": "true",
            "type": "boolean",
            "flags": null,
            "created_at": "2023-03-10T15:16:55.000Z",
            "updated_at": null
          },
          {
            "id": "640b49e934d6052b1eeb862b",
            "group": "analytics",
            "key": "outbound_link_tagging",
            "value": "true",
            "type": "boolean",
            "flags": null,
            "created_at": "2023-03-10T15:16:57.000Z",
            "updated_at": null
          },
          {
            "id": "640b49ea34d6052b1eeb862f",
            "group": "members",
            "key": "members_monthly_price_id",
            "value": "640b49f034d6052b1eeb8639",
            "type": "string",
            "flags": null,
            "created_at": "2023-03-10T15:16:58.000Z",
            "updated_at": "2023-03-10T15:17:04.000Z"
          },
          {
            "id": "640b49ea34d6052b1eeb8630",
            "group": "members",
            "key": "members_yearly_price_id",
            "value": "640b49f034d6052b1eeb863a",
            "type": "string",
            "flags": null,
            "created_at": "2023-03-10T15:16:58.000Z",
            "updated_at": "2023-03-10T15:17:04.000Z"
          },
          {
            "id": "640b49ea34d6052b1eeb8631",
            "group": "editor",
            "key": "editor_default_email_recipients",
            "value": "visibility",
            "type": "string",
            "flags": null,
            "created_at": "2023-03-10T15:16:58.000Z",
            "updated_at": "2023-03-10T15:16:58.000Z"
          },
          {
            "id": "640b49ea34d6052b1eeb8632",
            "group": "editor",
            "key": "editor_default_email_recipients_filter",
            "value": "all",
            "type": "string",
            "flags": null,
            "created_at": "2023-03-10T15:16:58.000Z",
            "updated_at": "2023-03-10T15:16:58.000Z"
          },
          {
            "id": "642e2979a0adf54be8dbe241",
            "group": "core",
            "key": "last_mentions_report_email_timestamp",
            "value": null,
            "type": "number",
            "flags": null,
            "created_at": "2023-04-06T02:07:53.000Z",
            "updated_at": null
          },
          {
            "id": "642e297aa0adf54be8dbe248",
            "group": "portal",
            "key": "portal_signup_terms_html",
            "value": null,
            "type": "string",
            "flags": null,
            "created_at": "2023-04-06T02:07:54.000Z",
            "updated_at": null
          },
          {
            "id": "642e297aa0adf54be8dbe249",
            "group": "portal",
            "key": "portal_signup_checkbox_required",
            "value": "false",
            "type": "boolean",
            "flags": null,
            "created_at": "2023-04-06T02:07:54.000Z",
            "updated_at": null
          }
        ],
        "snippets": [],
        "stripe_prices": [
          {
            "id": "640b49f034d6052b1eeb8639",
            "stripe_price_id": "price_1Mk7gqB0zlKri9ISi2LziNIf",
            "stripe_product_id": "prod_NV7wWc0eL8h70T",
            "active": 1,
            "nickname": "Monthly",
            "currency": "usd",
            "amount": 500,
            "type": "recurring",
            "interval": "month",
            "created_at": "2023-03-10T15:17:04.000Z",
            "updated_at": "2023-03-10T15:17:04.000Z",
            "description": null
          },
          {
            "id": "640b49f034d6052b1eeb863a",
            "stripe_price_id": "price_1Mk7gqB0zlKri9IS0qHaCKCi",
            "stripe_product_id": "prod_NV7wWc0eL8h70T",
            "active": 1,
            "nickname": "Yearly",
            "currency": "usd",
            "amount": 5000,
            "type": "recurring",
            "interval": "year",
            "created_at": "2023-03-10T15:17:04.000Z",
            "updated_at": "2023-03-10T15:17:04.000Z",
            "description": null
          }
        ],
        "stripe_products": [
          {
            "id": "640b49ef34d6052b1eeb8638",
            "product_id": "608b1e9bc19b240f06532731",
            "stripe_product_id": "prod_NV7wWc0eL8h70T",
            "created_at": "2023-03-10T15:17:03.000Z",
            "updated_at": "2023-03-10T15:17:03.000Z"
          }
        ],
        "tags": [
          {
            "id": "60193dcf1446cd10bd8d9c06",
            "name": "Getting Started",
            "slug": "getting-started",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-02T11:55:59.000Z",
            "updated_at": "2021-02-02T11:55:59.000Z"
          },
          {
            "id": "601b8f9f1446cd10bd8da37f",
            "name": "typescript",
            "slug": "typescript",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-04T06:09:35.000Z",
            "updated_at": "2021-02-04T06:09:35.000Z"
          },
          {
            "id": "601b8f9f1446cd10bd8da380",
            "name": "parcel",
            "slug": "parcel",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-04T06:09:35.000Z",
            "updated_at": "2021-02-04T06:09:35.000Z"
          },
          {
            "id": "601b8f9f1446cd10bd8da381",
            "name": "data-processing",
            "slug": "data-processing",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-04T06:09:35.000Z",
            "updated_at": "2021-02-04T06:09:35.000Z"
          },
          {
            "id": "601b8f9f1446cd10bd8da382",
            "name": "apexcharts",
            "slug": "apexcharts",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-04T06:09:35.000Z",
            "updated_at": "2021-02-04T06:09:35.000Z"
          },
          {
            "id": "601b8f9f1446cd10bd8da383",
            "name": "xls",
            "slug": "xls",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-04T06:09:35.000Z",
            "updated_at": "2021-02-04T06:09:35.000Z"
          },
          {
            "id": "601b8f9f1446cd10bd8da384",
            "name": "csv",
            "slug": "csv",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-04T06:09:35.000Z",
            "updated_at": "2021-02-04T06:09:35.000Z"
          },
          {
            "id": "601b8f9f1446cd10bd8da385",
            "name": "json",
            "slug": "json",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-04T06:09:35.000Z",
            "updated_at": "2021-02-04T06:09:35.000Z"
          },
          {
            "id": "602d8459194a5b778b1ab9e7",
            "name": "mongo",
            "slug": "mongo",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-17T21:02:17.000Z",
            "updated_at": "2021-02-17T21:02:17.000Z"
          },
          {
            "id": "602d8459194a5b778b1ab9e8",
            "name": "scraping",
            "slug": "scraping",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-17T21:02:17.000Z",
            "updated_at": "2021-02-17T21:02:17.000Z"
          },
          {
            "id": "6038cd1c8e39617ce723d8de",
            "name": "i18next",
            "slug": "i18next",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-02-26T10:27:40.000Z",
            "updated_at": "2021-02-26T10:27:40.000Z"
          },
          {
            "id": "607ebca42fb35425592d0858",
            "name": "rails",
            "slug": "rails",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T11:36:04.000Z",
            "updated_at": "2021-04-20T11:36:04.000Z"
          },
          {
            "id": "607ebca42fb35425592d0859",
            "name": "ruby",
            "slug": "ruby",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T11:36:04.000Z",
            "updated_at": "2021-04-20T11:36:04.000Z"
          },
          {
            "id": "607f203f2fb35425592d0aed",
            "name": "alghoritms",
            "slug": "alghoritms",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T18:41:03.000Z",
            "updated_at": "2021-04-20T18:41:03.000Z"
          },
          {
            "id": "607f31da2fb35425592d0b32",
            "name": "ajax",
            "slug": "ajax",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T19:56:10.000Z",
            "updated_at": "2021-04-20T19:56:10.000Z"
          },
          {
            "id": "607f31da2fb35425592d0b33",
            "name": "mysql",
            "slug": "mysql",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T19:56:10.000Z",
            "updated_at": "2021-04-20T19:56:10.000Z"
          },
          {
            "id": "607f31da2fb35425592d0b34",
            "name": "selenium",
            "slug": "selenium",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T19:56:10.000Z",
            "updated_at": "2021-04-20T19:56:10.000Z"
          },
          {
            "id": "607f33932fb35425592d0b43",
            "name": "python",
            "slug": "python",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:03:31.000Z",
            "updated_at": "2021-04-20T20:03:31.000Z"
          },
          {
            "id": "607f33932fb35425592d0b44",
            "name": "stock",
            "slug": "stock",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:03:31.000Z",
            "updated_at": "2021-04-20T20:03:31.000Z"
          },
          {
            "id": "607f33932fb35425592d0b45",
            "name": "visualisation",
            "slug": "visualisation",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:03:31.000Z",
            "updated_at": "2021-04-20T20:03:31.000Z"
          },
          {
            "id": "607f35f62fb35425592d0b69",
            "name": "behat",
            "slug": "behat",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:13:42.000Z",
            "updated_at": "2021-04-20T20:13:42.000Z"
          },
          {
            "id": "607f35f62fb35425592d0b6a",
            "name": "perl",
            "slug": "perl",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:13:42.000Z",
            "updated_at": "2021-04-20T20:13:42.000Z"
          },
          {
            "id": "607f363a2fb35425592d0b75",
            "name": "mathematica",
            "slug": "mathematica",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:14:50.000Z",
            "updated_at": "2021-04-20T20:14:50.000Z"
          },
          {
            "id": "607f36d52fb35425592d0b7f",
            "name": "spa",
            "slug": "spa",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:17:25.000Z",
            "updated_at": "2021-04-20T20:17:25.000Z"
          },
          {
            "id": "607f36d52fb35425592d0b80",
            "name": "mustache",
            "slug": "mustache",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:17:25.000Z",
            "updated_at": "2021-04-20T20:17:25.000Z"
          },
          {
            "id": "607f36d52fb35425592d0b81",
            "name": "log",
            "slug": "log",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:17:25.000Z",
            "updated_at": "2021-04-20T20:17:25.000Z"
          },
          {
            "id": "607f3d072fb35425592d0bed",
            "name": "game",
            "slug": "game",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:43:51.000Z",
            "updated_at": "2021-04-20T20:43:51.000Z"
          },
          {
            "id": "607f3d072fb35425592d0bee",
            "name": "snake",
            "slug": "snake",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:43:51.000Z",
            "updated_at": "2021-04-20T20:43:51.000Z"
          },
          {
            "id": "607f3d4e2fb35425592d0bfa",
            "name": "js",
            "slug": "js",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T20:45:02.000Z",
            "updated_at": "2021-04-20T20:45:02.000Z"
          },
          {
            "id": "607f478c2fb35425592d0c47",
            "name": "es6",
            "slug": "es6",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T21:28:44.000Z",
            "updated_at": "2021-04-20T21:28:44.000Z"
          },
          {
            "id": "607f478c2fb35425592d0c48",
            "name": "html",
            "slug": "html",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T21:28:44.000Z",
            "updated_at": "2021-04-20T21:28:44.000Z"
          },
          {
            "id": "607f478c2fb35425592d0c49",
            "name": "css",
            "slug": "css",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-20T21:28:44.000Z",
            "updated_at": "2021-04-20T21:28:44.000Z"
          },
          {
            "id": "6083f9c32fb35425592d0d9a",
            "name": "telegram",
            "slug": "telegram",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-24T10:58:11.000Z",
            "updated_at": "2021-04-24T10:58:11.000Z"
          },
          {
            "id": "6083f9c32fb35425592d0d9b",
            "name": "bot",
            "slug": "bot",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-04-24T10:58:11.000Z",
            "updated_at": "2021-04-24T10:58:11.000Z"
          },
          {
            "id": "60d0bf3872a5cb20e224a06c",
            "name": "twitter",
            "slug": "twitter",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-21T16:32:56.000Z",
            "updated_at": "2021-06-21T16:32:56.000Z"
          },
          {
            "id": "60d0bf3872a5cb20e224a06d",
            "name": "cheerio",
            "slug": "cheerio",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-21T16:32:56.000Z",
            "updated_at": "2021-06-21T16:32:56.000Z"
          },
          {
            "id": "60d0bf3872a5cb20e224a06e",
            "name": "nodejs",
            "slug": "nodejs",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-21T16:32:56.000Z",
            "updated_at": "2021-06-21T16:32:56.000Z"
          },
          {
            "id": "60d0c63b72a5cb20e224a084",
            "name": "php",
            "slug": "php",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-21T17:02:51.000Z",
            "updated_at": "2021-06-21T17:02:51.000Z"
          },
          {
            "id": "60d0c63b72a5cb20e224a085",
            "name": "compilation",
            "slug": "compilation",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-21T17:02:51.000Z",
            "updated_at": "2021-06-21T17:02:51.000Z"
          },
          {
            "id": "60d0c63b72a5cb20e224a086",
            "name": "bunsenlabs",
            "slug": "bunsenlabs",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-21T17:02:51.000Z",
            "updated_at": "2021-06-21T17:02:51.000Z"
          },
          {
            "id": "60d1a74772a5cb20e224a096",
            "name": "https",
            "slug": "https",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-22T09:03:03.000Z",
            "updated_at": "2021-06-22T09:03:03.000Z"
          },
          {
            "id": "60d1a74772a5cb20e224a097",
            "name": "ssl",
            "slug": "ssl",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-22T09:03:03.000Z",
            "updated_at": "2021-06-22T09:03:03.000Z"
          },
          {
            "id": "60d1a74772a5cb20e224a098",
            "name": "certbot",
            "slug": "certbot",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-22T09:03:03.000Z",
            "updated_at": "2021-06-22T09:03:03.000Z"
          },
          {
            "id": "60d1a74772a5cb20e224a099",
            "name": "ubuntu",
            "slug": "ubuntu",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-22T09:03:03.000Z",
            "updated_at": "2021-06-22T09:03:03.000Z"
          },
          {
            "id": "60d1ac1972a5cb20e224a0af",
            "name": "symfony",
            "slug": "symfony",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-22T09:23:37.000Z",
            "updated_at": "2021-06-22T09:23:37.000Z"
          },
          {
            "id": "60d1ac1972a5cb20e224a0b0",
            "name": "fosuserbundle",
            "slug": "fosuserbundle",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-22T09:23:37.000Z",
            "updated_at": "2021-06-22T09:23:37.000Z"
          },
          {
            "id": "60d1ac1972a5cb20e224a0b1",
            "name": "google maps",
            "slug": "google-maps",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-22T09:23:37.000Z",
            "updated_at": "2021-06-22T09:23:37.000Z"
          },
          {
            "id": "60d1ac1972a5cb20e224a0b2",
            "name": "twig",
            "slug": "twig",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-22T09:23:37.000Z",
            "updated_at": "2021-06-22T09:23:37.000Z"
          },
          {
            "id": "60d36f4e72a5cb20e224a200",
            "name": "profiling",
            "slug": "profiling",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-23T17:28:46.000Z",
            "updated_at": "2021-06-23T17:28:46.000Z"
          },
          {
            "id": "60d983d3ae5f887e40118127",
            "name": "maxdata",
            "slug": "maxdata",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-06-28T08:09:55.000Z",
            "updated_at": "2021-06-28T08:09:55.000Z"
          },
          {
            "id": "60e58b10ae5f887e4011836c",
            "name": "web api",
            "slug": "web-api",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-07-07T11:08:00.000Z",
            "updated_at": "2021-07-07T11:08:00.000Z"
          },
          {
            "id": "60e58b10ae5f887e4011836d",
            "name": "broadcast",
            "slug": "broadcast",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-07-07T11:08:00.000Z",
            "updated_at": "2021-07-07T11:08:00.000Z"
          },
          {
            "id": "60e58b10ae5f887e4011836e",
            "name": "channel",
            "slug": "channel",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-07-07T11:08:00.000Z",
            "updated_at": "2021-07-07T11:08:00.000Z"
          },
          {
            "id": "60f1bd7b50caaa182e07e754",
            "name": "cpu",
            "slug": "cpu",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-07-16T17:10:19.000Z",
            "updated_at": "2021-07-16T17:10:19.000Z"
          },
          {
            "id": "60f843df50caaa182e07eea8",
            "name": "rust",
            "slug": "rust",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-07-21T15:57:19.000Z",
            "updated_at": "2021-07-21T15:57:19.000Z"
          },
          {
            "id": "60f843df50caaa182e07eea9",
            "name": "java",
            "slug": "java",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-07-21T15:57:19.000Z",
            "updated_at": "2021-07-21T15:57:19.000Z"
          },
          {
            "id": "617206d750caaa182e07f4be",
            "name": "arch",
            "slug": "arch",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-10-22T00:33:27.000Z",
            "updated_at": "2021-10-22T00:33:27.000Z"
          },
          {
            "id": "617206d750caaa182e07f4bf",
            "name": "linux",
            "slug": "linux",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-10-22T00:33:27.000Z",
            "updated_at": "2021-10-22T00:33:27.000Z"
          },
          {
            "id": "61928bf050caaa182e07f631",
            "name": "security",
            "slug": "security",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-11-15T16:33:52.000Z",
            "updated_at": "2021-11-15T16:33:52.000Z"
          },
          {
            "id": "6196600150caaa182e07f759",
            "name": "javascript",
            "slug": "javascript",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-11-18T14:15:29.000Z",
            "updated_at": "2021-11-18T14:15:29.000Z"
          },
          {
            "id": "6196600150caaa182e07f75a",
            "name": "numbers-therory",
            "slug": "numbers-therory",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2021-11-18T14:15:29.000Z",
            "updated_at": "2021-11-18T14:15:29.000Z"
          },
          {
            "id": "61f5a38f50caaa182e07f826",
            "name": "aur",
            "slug": "aur",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2022-01-29T20:29:03.000Z",
            "updated_at": "2022-01-29T20:29:03.000Z"
          },
          {
            "id": "62a36df0d9c3ae6cbd852c57",
            "name": "error",
            "slug": "error",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2022-06-10T16:14:40.000Z",
            "updated_at": "2022-06-10T16:14:40.000Z"
          },
          {
            "id": "62a51c47d9c3ae6cbd852f5f",
            "name": "zipf",
            "slug": "zipf",
            "description": null,
            "feature_image": null,
            "parent_id": null,
            "visibility": "public",
            "og_image": null,
            "og_title": null,
            "og_description": null,
            "twitter_image": null,
            "twitter_title": null,
            "twitter_description": null,
            "meta_title": null,
            "meta_description": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "canonical_url": null,
            "accent_color": null,
            "created_at": "2022-06-11T22:50:47.000Z",
            "updated_at": "2022-06-11T22:50:47.000Z"
          }
        ],
        "users": [
          {
            "id": "1",
            "name": "Daniel Gustaw",
            "slug": "daniel",
            "password": "$2a$10$lefknZqYz6pZk9TwOSc9G.OVYoIGCeHsE.E1wL5uiw9BL1oIf/r3u",
            "email": "gustaw.daniel@gmail.com",
            "profile_image": "__GHOST_URL__/content/images/2021/02/1608291457588.jpeg",
            "cover_image": null,
            "bio": null,
            "website": null,
            "location": "Warszawa",
            "facebook": null,
            "twitter": null,
            "accessibility": "{\"whatsNew\":{\"lastSeenDate\":\"2020-12-08T14:38:25.000+00:00\"},\"nightShift\":false,\"launchComplete\":true}",
            "status": "active",
            "locale": null,
            "visibility": "public",
            "meta_title": null,
            "meta_description": null,
            "tour": "[\"featured-post\",\"getting-started\"]",
            "last_seen": "2023-09-02T17:44:53.000Z",
            "created_at": "2021-02-02T11:55:59.000Z",
            "updated_at": "2023-09-02T17:44:53.000Z",
            "comment_notifications": 1,
            "free_member_signup_notification": 1,
            "paid_subscription_canceled_notification": 0,
            "paid_subscription_started_notification": 1,
            "mention_notifications": 1,
            "milestone_notifications": 1
          }
        ]
      }
    }
  ]
}
