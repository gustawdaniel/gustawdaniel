---
author: Daniel Gustaw
canonicalName: langchain-exemplary-use-cases
coverImage: https://ucarecdn.com/f618a5e8-e72d-4c62-920f-3ee29b98f8c9/-/preview/640x360/
description: Extrayendo datos estructurados de facturas en PDF y construyendo un sistema de b√∫squeda de documentos flexible con LangChain y FAISS.
excerpt: Extrayendo datos estructurados de facturas en PDF y construyendo un sistema de b√∫squeda de documentos flexible con LangChain y FAISS.
publishDate: 2025-04-20 00:00:00+00:00
slug: es/casos-de-uso-ejemplares-de-langchain
tags:
- langchain
- openai
- rag
title: Casos de Uso Ejemplares de LangChain
updateDate: 2025-04-20 00:00:00+00:00
---

# En este art√≠culo veremos 2 ejemplos:
- Extraer Datos Estructurados de PDF
- RAG (Respuesta a Preguntas) con LangChain

## Extraer Datos Estructurados de Facturas PDF Usando LangChain

La digitalizaci√≥n de facturas es una tarea com√∫n en la automatizaci√≥n empresarial, especialmente cuando se env√≠an como PDFs escaneados. En este art√≠culo, mostraremos c√≥mo usar LangChain, 
OpenAI y Pydantic para extraer datos estructurados como el nombre del cliente, la fecha, el n√∫mero de factura y el valor total de archivos PDF.

¬°Profundicemos! üöÄ

### üí° Objetivo

Queremos construir un script que acepte:

- Una factura PDF
- Un modelo de datos que describa los campos que esperamos

Y devuelva:

- Una salida JSON estructurada con los valores extra√≠dos

Esto puede ser muy √∫til en escenarios como:

- Automatizaci√≥n de contabilidad
- Integraci√≥n de facturas en CRMs o ERPs
- Reemplazo de la entrada de datos manual

Usaremos los siguientes paquetes:

```bash
pip install langchain openai pydantic pdfplumber langchain-community
```

Y la siguiente factura:

<embed src="https://fra1.digitaloceanspaces.com/preciselab/blog/doc/invoice1.pdf" width="800" height="1180" type="application/pdf">


### üß± Paso 1: Definir el Modelo de Datos

Usaremos Pydantic para definir qu√© queremos extraer de cada factura.

```python
from pydantic import BaseModel

class InvoiceData(BaseModel):
    client: str
    date: str
    invoice_number: str
    total_amount: str
```

### üìÑ Paso 2: Extraer texto del PDF

Usaremos pdfplumber para obtener el contenido de texto del PDF:

```python
import pdfplumber

def extract_text_from_pdf(path):
    with pdfplumber.open(path) as pdf:
        return "\n".join(page.extract_text() for page in pdf.pages if page.extract_text())
```

### üß† Paso 3: Configurar LangChain para la Estructuraci√≥n de Respuestas

LangChain + OpenAI + un aviso + el modelo de datos = magia ‚ú®

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser
```

Usaremos un aviso para decirle al modelo lo que queremos:

```python
template = """
Extract the following information from the text below:
- Client name
- Date
- Invoice number
- Total value for payment

{format_instructions}

Text:
{text}
"""
```

### üîó Paso 4: Crear la Cadena y Analizar

Combinamos el aviso, el modelo y el analizador:

```python
from langchain_core.runnables import Runnable

def parse(invoice_path):
    llm = ChatOpenAI(temperature=0)
    parser = PydanticOutputParser(pydantic_object=InvoiceData)

    prompt = PromptTemplate(
        input_variables=["text"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
        template=template
    )

    chain = prompt | llm | parser

    pdf_text = extract_text_from_pdf(invoice_path)
    return chain.invoke({"text": pdf_text})
```

### üß™ Paso 5: Ejecutar e Imprimir como JSON

Finalmente, ejecutamos toda la tuber√≠a y imprimimos el resultado:

```python
import json

if __name__ == '__main__':
    result = parse("invoice1.pdf")
    print(json.dumps(result.dict(), indent=2))
```

### ‚úÖ Ejemplo de Salida

```json
{
  "client": "Test Business",
  "date": "January 25, 2016",
  "invoice_number": "INV-3337",
  "total_amount": "$93.50"
}
```

# Construyendo un Sistema de B√∫squeda de Documentos Flexible con Langchain y FAISS

Ahora vamos a recorrer la construcci√≥n de un sistema de b√∫squeda de documentos flexible utilizando Langchain, FAISS y las incrustaciones de OpenAI. Nuestro objetivo es crear un sistema que te permita consultar PDFs de manera eficiente, sin codificar nombres de archivos, y f√°cilmente extensible para diversos casos de uso.

Vamos a explorar c√≥mo podemos construir dicho sistema, manteniendo el c√≥digo limpio y escalable.

### Lo Que Aprender√°s
- C√≥mo usar Langchain para cargar e indexar documentos PDF.
- C√≥mo crear un sistema de preguntas y respuestas basado en recuperaci√≥n utilizando FAISS y las incrustaciones de OpenAI.
- C√≥mo refactorizar el c√≥digo para hacerlo flexible y modular.
- C√≥mo consultar tus documentos din√°micamente pasando el nombre del archivo y la pregunta en tiempo de ejecuci√≥n.

### ¬øPor Qu√© Usar Langchain y FAISS?

Antes de sumergirnos en el c√≥digo, discutamos brevemente por qu√© estamos usando Langchain y FAISS para esta tarea.

- **Langchain**: Simplifica la construcci√≥n de aplicaciones alrededor de LLMs (Modelos de Lenguaje Grande) proporcionando herramientas poderosas para la carga de documentos, divisi√≥n de texto, incrustaciones y m√°s.
- **FAISS**: La B√∫squeda de Similitud AI de Facebook (FAISS) es una biblioteca para la b√∫squeda de similitud y agrupamiento de vectores densos de manera eficiente. Nos permite encontrar r√°pidamente pasajes relevantes de grandes colecciones de documentos basados en incrustaciones.

Configurando el Proyecto

Empecemos por instalar los paquetes necesarios. Puedes instalarlos a trav√©s de pip:

```python
pip install langchain langchain-openai faiss-cpu
```

Tambi√©n necesitas una clave de API de OpenAI para usar su modelo de incrustaci√≥n.

### Conceptos Clave en el C√≥digo

Antes de saltar al c√≥digo, desglos√©moslo:

- Carga de Documentos: Usamos PyPDFLoader para cargar el contenido del PDF.
- Divisi√≥n de Texto: Los PDFs grandes pueden contener demasiado texto para procesar de una vez. Usamos RecursiveCharacterTextSplitter para dividir el texto en fragmentos m√°s peque√±os.
- Incrustaciones: Usamos incrustaciones de OpenAI (OpenAIEmbeddings) para convertir texto en representaciones vectoriales.
- √çndice FAISS: Este almacena y gestiona texto vectorizado, permitiendo una b√∫squeda de similitud r√°pida.
- Recuperaci√≥n QA: La funcionalidad principal nos permite hacer preguntas contra el documento indexado usando una cadena RetrievalQA.

Ahora, sumerj√°monos en el c√≥digo mismo.

### El C√≥digo Refactorizado

Aqu√≠ est√° el c√≥digo refactorizado que logra esto:

```python
import os
import logging
from typing import Optional

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

INDEX_PATH = "faiss_book_index"

def load_or_create_vectorstore(pdf_path: str, embeddings: OpenAIEmbeddings) -> FAISS:
    """Load FAISS index if it exists; otherwise create it from the PDF."""
    if os.path.exists(INDEX_PATH):
        logger.info("Loading existing FAISS index...")
        return FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)

    logger.info("Creating new FAISS index from PDF...")
    loader = PyPDFLoader(pdf_path)
    docs = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    doc_chunks = text_splitter.split_documents(docs)

    vectorstore = FAISS.from_documents(doc_chunks, embeddings)
    vectorstore.save_local(INDEX_PATH)
    return vectorstore

def parse(pdf_path: str, question: str) -> str:
    """Process PDF and ask question using retrieval QA."""
    embeddings = OpenAIEmbeddings()
    vectorstore = load_or_create_vectorstore(pdf_path, embeddings)

    retriever = vectorstore.as_retriever()
    qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model_name="gpt-4-turbo"),
        retriever=retriever
    )

    response = qa_chain.invoke(question)
    return response["result"]

if __name__ == '__main__':
    question = 'ALEKSANDER FREDRO w utworze "Zemsta" umie≈õci≈Ç werset: "je≈õli nie chcesz mojej zguby, ___ daj mi luby", czym jest ___? Co luby ma daƒá osobie wypowiadajƒÖcej ten cytat?'
    pdf_file = "zemsta.pdf"
    answer = parse(pdf_file, question)
    print(answer)
```

### Desglose del C√≥digo

```python
load_or_create_vectorstore(pdf_path, embeddings):
```

Esta funci√≥n verifica si existe un √≠ndice FAISS existente. Si es as√≠, lo carga. De lo contrario, procesa el PDF, lo divide en partes m√°s peque√±as y crea un nuevo √≠ndice FAISS.

```python
parse(pdf_path, question):
```

Este es el punto de entrada donde puedes pasar cualquier ruta de PDF y una pregunta. Carga el documento, recupera la informaci√≥n relevante y responde a la pregunta utilizando la cadena RetrievalQA potenciada por OpenAI.

```python
main():
```

En el bloque __main__, especificamos el documento y la pregunta din√°micamente. Puedes cambiar el nombre del archivo y la pregunta sobre la marcha, lo que hace que este c√≥digo sea flexible para varios casos de uso.

### Respuestas

En este momento, los chats disponibles en navegadores como chatgpt tienen 
la posibilidad de responder preguntas basadas en el contexto del documento encontrado en internet. 
Esto se hace utilizando embeddings y almacenamientos de vectores para encontrar pasajes relevantes 
en el documento.

As√≠ que si haces una pregunta sobre un documento bien conocido como el libro "Zemsta" de nuestro ejemplo, recibir√°s una respuesta correcta, pero hace poco tiempo los chats web respond√≠an sin acceso a fuentes y la calidad de las respuestas era mucho peor.

La t√©cnica presentada sigue siendo √∫til para documentos que no est√°n disponibles p√∫blicamente.

### Conclusi√≥n

En este post, hemos construido un sistema de b√∫squeda de documentos flexible utilizando Langchain, FAISS y embeddings de OpenAI. Hemos refactorizado el c√≥digo para hacerlo m√°s modular y din√°mico, permitiendo la consulta de cualquier documento PDF.

Este enfoque se puede extender a muchos otros casos de uso, como consultar diferentes formatos de documentos, aplicar t√©cnicas de PNL m√°s avanzadas o escalar a un corpus de documentos m√°s grande. ¬°El cielo es el l√≠mite!
